Using TensorFlow backend.
[2019-03-23 21:01:13,681] A3C_AGENT_MAIN INFO:Namespace(action_repeat_n=1, action_space='part3_v1', activation='relu', agent_num=5, check_args_only=False, clip_norm=5.0, debug_log_prob=0.0005, decay_steps=1000000, dropout_prob=0.0, end_e=0.0, env='Part3-NA-Bej-Train-v1', eval_act_func='part3_bej_det_v1', eval_env_res_max_keep=50, eval_epi_num=1, eval_freq=25000, forecast_dim=0, gamma=0.99, h_decay_bounds=[], h_regu_frac=[0.0], init_e=0.0, isNoisyNet=True, isNoisyNetEval_rmNoise=True, is_greedy_policy=False, is_learning_rate_decay_staircase=False, is_warm_start=False, job_mode='Train', learning_rate=0.0005, learning_rate_decay_rate=1.0, learning_rate_decay_steps=100000, max_interactions=2500000, metric_func='part3_v1', model_dir='None', model_param=[256, 8], model_type='nn', num_threads=16, output='./Part3-NA-Bej-Train-v1-res1', p_loss_frac=1.0, raw_state_prcs_func='cslDx_1', reward_func='part3_v3', rmsprop_decay=0.99, rmsprop_epsil=1e-10, rmsprop_momet=0.0, rwd_e_para=1.0, rwd_p_para=1.0, save_freq=500000, save_max_to_keep=5, save_scope='all', sharedNet_type='Dense', state_dim=17, test_env=['Part3-NA-Bej-Test-v1', 'Part3-NA-Bej-Test-v2', 'Part3-NA-Bej-Test-v3', 'Part3-NA-Bej-Test-v4'], test_mode='Multiple', train_act_func='part3_bej_sto_v1', train_freq=5, v_loss_frac=0.5, violation_penalty_scl=50.0, weight_initer='glorot_uniform', window_len=26)
[2019-03-23 21:01:13,681] A3C_AGENT_MAIN INFO:Start compiling...
2019-03-23 21:01:13.770588: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[2019-03-23 21:01:43,251] A3C_AGENT_MAIN INFO:Start the learning...
[2019-03-23 21:01:43,251] A3C_AGENT_MAIN INFO:Prepare the evaluation environments ['Part3-NA-Bej-Train-v1', 'Part3-NA-Bej-Test-v1', 'Part3-NA-Bej-Test-v2', 'Part3-NA-Bej-Test-v3', 'Part3-NA-Bej-Test-v4'] ...
[2019-03-23 21:01:43,264] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation worker starts!
[2019-03-23 21:01:43,267] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation worker starts!
[2019-03-23 21:01:43,270] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation worker starts!
[2019-03-23 21:01:43,273] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation worker starts!
[2019-03-23 21:01:43,279] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation worker starts!
[2019-03-23 21:01:43,279] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 21:01:43,280] A3C_AGENT_WORKER-Thread-2 INFO:Local worker starts!
[2019-03-23 21:01:43,371] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:01:43,372] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run1
[2019-03-23 21:01:44,281] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 21:01:44,284] A3C_AGENT_WORKER-Thread-3 INFO:Local worker starts!
[2019-03-23 21:01:44,385] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:01:44,386] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run1
[2019-03-23 21:01:44,856] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 21:01:44,856] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:01:44,857] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:01:44,857] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:01:44,858] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:01:44,857] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:01:44,858] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:01:44,859] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:01:44,859] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:01:44,859] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:01:44,860] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:01:44,864] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run1
[2019-03-23 21:01:44,864] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run1
[2019-03-23 21:01:44,876] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run1
[2019-03-23 21:01:44,877] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run1
[2019-03-23 21:01:44,913] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run1
[2019-03-23 21:01:45,285] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 21:01:45,286] A3C_AGENT_WORKER-Thread-9 INFO:Local worker starts!
[2019-03-23 21:01:45,394] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:01:45,395] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run1
[2019-03-23 21:01:46,287] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 21:01:46,290] A3C_AGENT_WORKER-Thread-10 INFO:Local worker starts!
[2019-03-23 21:01:46,506] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:01:46,508] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run1
[2019-03-23 21:01:47,291] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 21:01:47,298] A3C_AGENT_WORKER-Thread-11 INFO:Local worker starts!
[2019-03-23 21:01:47,418] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:01:47,447] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run1
[2019-03-23 21:01:48,296] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 21:01:48,303] A3C_AGENT_WORKER-Thread-12 INFO:Local worker starts!
[2019-03-23 21:01:48,438] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:01:48,465] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run1
[2019-03-23 21:01:49,301] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 21:01:49,304] A3C_AGENT_WORKER-Thread-13 INFO:Local worker starts!
[2019-03-23 21:01:49,429] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:01:49,453] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run1
[2019-03-23 21:01:50,304] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 21:01:50,310] A3C_AGENT_WORKER-Thread-14 INFO:Local worker starts!
[2019-03-23 21:01:50,426] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:01:50,456] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run1
[2019-03-23 21:01:51,309] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 21:01:51,313] A3C_AGENT_WORKER-Thread-15 INFO:Local worker starts!
[2019-03-23 21:01:51,433] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:01:51,448] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run1
[2019-03-23 21:01:52,314] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 21:01:52,316] A3C_AGENT_WORKER-Thread-16 INFO:Local worker starts!
[2019-03-23 21:01:52,438] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:01:52,466] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run1
[2019-03-23 21:01:53,317] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 21:01:53,322] A3C_AGENT_WORKER-Thread-17 INFO:Local worker starts!
[2019-03-23 21:01:53,457] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:01:53,471] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run1
[2019-03-23 21:01:54,323] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 21:01:54,332] A3C_AGENT_WORKER-Thread-18 INFO:Local worker starts!
[2019-03-23 21:01:54,459] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:01:54,482] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run1
[2019-03-23 21:01:55,332] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 21:01:55,335] A3C_AGENT_WORKER-Thread-19 INFO:Local worker starts!
[2019-03-23 21:01:55,445] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:01:55,446] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run1
[2019-03-23 21:01:56,336] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 21:01:56,339] A3C_AGENT_WORKER-Thread-20 INFO:Local worker starts!
[2019-03-23 21:01:56,453] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:01:56,454] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run1
[2019-03-23 21:01:57,341] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 21:01:57,345] A3C_AGENT_WORKER-Thread-21 INFO:Local worker starts!
[2019-03-23 21:01:57,463] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:01:57,477] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run1
[2019-03-23 21:01:58,345] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-23 21:01:58,348] A3C_AGENT_WORKER-Thread-22 INFO:Local worker starts!
[2019-03-23 21:01:58,464] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:01:58,481] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run1
[2019-03-23 21:01:59,271] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 21:01:59,272] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.63333333333333, 37.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5787162809524702, 6.911199999999999, 6.9112, 121.9260426156618, 430013.8228766702, 430013.8228766706, 128736.1140451406]
[2019-03-23 21:01:59,274] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:01:59,278] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0.20414376 0.20651454 0.19320466 0.19969183 0.19644517], sampled 0.6244708755635053
[2019-03-23 21:02:14,689] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 21:02:14,691] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [20.75, 91.50000000000001, 1.0, 2.0, 0.583260837323178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 718007.4461233984, 718007.4461233984, 157306.5173327476]
[2019-03-23 21:02:14,691] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:02:14,693] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [0.20194083 0.20967402 0.19466878 0.19906001 0.19465642], sampled 0.936462190035109
[2019-03-23 21:02:20,096] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 21:02:20,097] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [19.776853425, 109.6988282, 1.0, 2.0, 0.1814328360435169, 1.0, 2.0, 0.1814328360435169, 1.0, 2.0, 0.2941085884562261, 6.9112, 6.9112, 121.94756008, 657289.3848525924, 657289.3848525924, 213772.9336818954]
[2019-03-23 21:02:20,097] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:02:20,101] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [0.20596208 0.20290266 0.19207506 0.20282474 0.19623551], sampled 0.33734353763722724
[2019-03-23 21:02:27,507] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 21:02:27,509] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.05, 92.5, 1.0, 2.0, 0.325484409671265, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5181817804838322, 6.911200000000001, 6.9112, 121.9260426156618, 741893.2584416635, 741893.258441663, 202219.789057575]
[2019-03-23 21:02:27,510] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:02:27,513] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0.20316742 0.20383446 0.19112815 0.19994755 0.20192248], sampled 0.6727676611443344
[2019-03-23 21:02:39,063] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 21:02:39,064] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.90154506333333, 93.18638579166667, 1.0, 2.0, 0.5492850597480022, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8744797040843217, 6.911200000000001, 6.9112, 121.9260426156618, 1252430.400853283, 1252430.400853283, 274650.8250308285]
[2019-03-23 21:02:39,065] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:02:39,067] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [0.19908723 0.20787176 0.19306299 0.20139298 0.19858506], sampled 0.17485337956887026
[2019-03-23 21:02:39,068] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1252430.400853283 W.
[2019-03-23 21:02:46,886] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 21:02:46,886] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.69023534, 110.2916505, 1.0, 2.0, 0.5977840511670879, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 696563.5592406149, 696563.5592406149, 158421.0252160822]
[2019-03-23 21:02:46,887] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:02:46,888] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0.19970353 0.20720789 0.1914201  0.20387511 0.19779342], sampled 0.3429319433967364
[2019-03-23 21:03:12,836] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 21:03:12,838] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.48893175, 52.929928625, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6582072236492532, 6.911199999999999, 6.9112, 121.9260426156618, 491191.8175128714, 491191.8175128719, 138460.6491551074]
[2019-03-23 21:03:12,840] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:03:12,843] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [0.20245826 0.20420663 0.19317654 0.20110528 0.19905329], sampled 0.9003512169765836
[2019-03-23 21:03:20,919] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-23 21:03:20,920] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.5, 63.0, 1.0, 2.0, 0.7252384836455305, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 904680.890374803, 904680.890374803, 183977.5221133022]
[2019-03-23 21:03:20,922] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:03:20,923] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0.20375662 0.20783524 0.19291921 0.19933286 0.19615607], sampled 0.3815030427358498
[2019-03-23 21:03:29,903] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 3829.0606 2536804663.6171 334.0000
[2019-03-23 21:03:30,017] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 3883.6131 2497504090.1415 332.0000
[2019-03-23 21:03:30,337] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 4016.3942 2465358560.6841 269.0000
[2019-03-23 21:03:30,398] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 4005.8494 2434015758.8541 234.0000
[2019-03-23 21:03:30,678] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 3841.5262 2711875496.3083 439.0000
[2019-03-23 21:03:31,692] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 0, evaluation results [0.0, 3841.526215094531, 2711875496.308266, 439.0, 4016.3942328395856, 2465358560.684087, 269.0, 4005.8494281700678, 2434015758.8540616, 234.0, 3829.0605788372877, 2536804663.6171355, 334.0, 3883.613125177368, 2497504090.141514, 332.0]
[2019-03-23 21:03:38,199] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [0.00132541 0.01956541 0.06767374 0.8314421  0.07999334], sum to 1.0000
[2019-03-23 21:03:38,205] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8987
[2019-03-23 21:03:38,355] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.4, 40.5, 1.0, 2.0, 0.1919655729374856, 1.0, 1.0, 0.1919655729374856, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 469884.135078115, 469884.135078115, 158061.8215061745], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 63000.0000, 
sim time next is 63600.0000, 
raw observation next is [29.3, 41.0, 1.0, 2.0, 0.1949852200744991, 1.0, 2.0, 0.1949852200744991, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 477036.4859898906, 477036.4859898911, 158681.2872299162], 
processed observation next is [1.0, 0.7391304347826086, 0.6407407407407407, 0.41, 1.0, 1.0, 0.04164907151726082, 1.0, 1.0, 0.04164907151726082, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17037017356781806, 0.17037017356781825, 0.3051563215959927], 
reward next is 0.6948, 
noisyNet noise sample is [array([-1.0804359], dtype=float32), 0.11051878]. 
=============================================
[2019-03-23 21:03:42,303] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.01667855 0.07038371 0.10268697 0.73335886 0.07689194], sum to 1.0000
[2019-03-23 21:03:42,313] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8591
[2019-03-23 21:03:42,477] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [35.48333333333333, 22.5, 1.0, 2.0, 0.5117303157150861, 1.0, 2.0, 0.5117303157150861, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1233529.743886726, 1233529.743886726, 241847.6426109298], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 133800.0000, 
sim time next is 134400.0000, 
raw observation next is [35.86666666666667, 21.0, 1.0, 2.0, 0.5545272768076484, 1.0, 2.0, 0.5545272768076484, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1338453.399402145, 1338453.399402145, 255894.9366676866], 
processed observation next is [1.0, 0.5652173913043478, 0.8839506172839506, 0.21, 1.0, 1.0, 0.4696753295329147, 1.0, 1.0, 0.4696753295329147, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.4780190712150518, 0.4780190712150518, 0.49210564743785884], 
reward next is 0.5079, 
noisyNet noise sample is [array([-1.4257289], dtype=float32), -1.2947276]. 
=============================================
[2019-03-23 21:03:47,111] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 5.2387445e-23 5.8772378e-24 1.0723755e-25 1.4036525e-36], sum to 1.0000
[2019-03-23 21:03:47,119] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0956
[2019-03-23 21:03:47,274] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [33.1, 13.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6732881347285367, 6.9112, 6.9112, 121.9260426156618, 481007.7906979043, 481007.7906979043, 128746.4623962361], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 222600.0000, 
sim time next is 223200.0000, 
raw observation next is [33.3, 13.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6766958970377627, 6.9112, 6.9112, 121.9260426156618, 483225.5931543391, 483225.5931543391, 127787.6722762387], 
processed observation next is [0.0, 0.6086956521739131, 0.7888888888888888, 0.13, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5958698712972033, 0.0, 0.0, 0.8094621288201359, 0.17258056898369253, 0.17258056898369253, 0.24574552360815136], 
reward next is 0.7543, 
noisyNet noise sample is [array([-0.85194886], dtype=float32), 0.27671805]. 
=============================================
[2019-03-23 21:03:49,849] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 8.8455866e-18 1.8264628e-18 6.3904013e-23 1.3303643e-32], sum to 1.0000
[2019-03-23 21:03:49,855] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3716
[2019-03-23 21:03:50,006] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.26666666666667, 51.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4576099278958024, 6.911199999999999, 6.9112, 121.9260426156618, 326731.4727316826, 326731.4727316831, 95655.52774154139], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 271200.0000, 
sim time next is 271800.0000, 
raw observation next is [20.2, 51.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4557899002865432, 6.911199999999999, 6.9112, 121.9260426156618, 325431.7053372575, 325431.7053372579, 95308.6136579814], 
processed observation next is [0.0, 0.13043478260869565, 0.3037037037037037, 0.515, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.319737375358179, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.11622560904902053, 0.11622560904902067, 0.1832857954961181], 
reward next is 0.8167, 
noisyNet noise sample is [array([0.03893128], dtype=float32), 0.25813752]. 
=============================================
[2019-03-23 21:03:51,395] A3C_AGENT_WORKER-Thread-2 INFO:Local step 500, global step 7921: loss 0.1029
[2019-03-23 21:03:51,476] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 500, global step 7921: learning rate 0.0005
[2019-03-23 21:03:51,490] A3C_AGENT_WORKER-Thread-16 INFO:Local step 500, global step 7931: loss 1.1032
[2019-03-23 21:03:51,491] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 500, global step 7931: learning rate 0.0005
[2019-03-23 21:03:51,506] A3C_AGENT_WORKER-Thread-13 INFO:Local step 500, global step 7939: loss 1.4592
[2019-03-23 21:03:51,508] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 500, global step 7940: learning rate 0.0005
[2019-03-23 21:03:51,529] A3C_AGENT_WORKER-Thread-9 INFO:Local step 500, global step 7952: loss 2.1658
[2019-03-23 21:03:51,531] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 500, global step 7952: learning rate 0.0005
[2019-03-23 21:03:51,547] A3C_AGENT_WORKER-Thread-3 INFO:Local step 500, global step 7963: loss 2.5004
[2019-03-23 21:03:51,550] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 500, global step 7963: learning rate 0.0005
[2019-03-23 21:03:51,556] A3C_AGENT_WORKER-Thread-11 INFO:Local step 500, global step 7965: loss 3.6315
[2019-03-23 21:03:51,559] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 500, global step 7965: learning rate 0.0005
[2019-03-23 21:03:51,567] A3C_AGENT_WORKER-Thread-10 INFO:Local step 500, global step 7970: loss 2.9323
[2019-03-23 21:03:51,570] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 500, global step 7970: learning rate 0.0005
[2019-03-23 21:03:51,584] A3C_AGENT_WORKER-Thread-15 INFO:Local step 500, global step 7981: loss 3.2930
[2019-03-23 21:03:51,589] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 500, global step 7981: learning rate 0.0005
[2019-03-23 21:03:51,593] A3C_AGENT_WORKER-Thread-12 INFO:Local step 500, global step 7982: loss 4.1140
[2019-03-23 21:03:51,594] A3C_AGENT_WORKER-Thread-18 INFO:Local step 500, global step 7983: loss 4.1849
[2019-03-23 21:03:51,595] A3C_AGENT_WORKER-Thread-21 INFO:Local step 500, global step 7983: loss 4.6327
[2019-03-23 21:03:51,596] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 500, global step 7983: learning rate 0.0005
[2019-03-23 21:03:51,596] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 500, global step 7983: learning rate 0.0005
[2019-03-23 21:03:51,599] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 500, global step 7984: learning rate 0.0005
[2019-03-23 21:03:51,621] A3C_AGENT_WORKER-Thread-14 INFO:Local step 500, global step 7994: loss 4.0706
[2019-03-23 21:03:51,622] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 500, global step 7994: learning rate 0.0005
[2019-03-23 21:03:51,682] A3C_AGENT_WORKER-Thread-22 INFO:Local step 500, global step 8024: loss 2.5062
[2019-03-23 21:03:51,686] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 500, global step 8025: learning rate 0.0005
[2019-03-23 21:03:51,706] A3C_AGENT_WORKER-Thread-20 INFO:Local step 500, global step 8036: loss 1.6163
[2019-03-23 21:03:51,708] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 500, global step 8037: learning rate 0.0005
[2019-03-23 21:03:51,780] A3C_AGENT_WORKER-Thread-19 INFO:Local step 500, global step 8070: loss 0.0883
[2019-03-23 21:03:51,781] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 500, global step 8070: learning rate 0.0005
[2019-03-23 21:03:51,850] A3C_AGENT_WORKER-Thread-17 INFO:Local step 500, global step 8110: loss 1.5558
[2019-03-23 21:03:51,851] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 500, global step 8110: learning rate 0.0005
[2019-03-23 21:03:55,027] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 7.7511064e-09 1.4164447e-08 5.7119011e-11 1.4617348e-14], sum to 1.0000
[2019-03-23 21:03:55,033] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1518
[2019-03-23 21:03:55,186] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.36666666666667, 60.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4251886884594126, 6.9112, 6.9112, 121.9260426156618, 303578.2692670079, 303578.2692670079, 95105.27473776267], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 366000.0000, 
sim time next is 366600.0000, 
raw observation next is [19.78333333333333, 58.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4339487488342347, 6.9112, 6.9112, 121.9260426156618, 309834.0827249566, 309834.0827249566, 96552.48103113184], 
processed observation next is [1.0, 0.21739130434782608, 0.28827160493827153, 0.58, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.29243593604279333, 0.0, 0.0, 0.8094621288201359, 0.11065502954462736, 0.11065502954462736, 0.185677848136792], 
reward next is 0.8143, 
noisyNet noise sample is [array([0.34746504], dtype=float32), -1.1597347]. 
=============================================
[2019-03-23 21:04:01,143] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9998569e-01 1.4650797e-07 6.7274837e-06 6.3276716e-06 1.2262517e-06], sum to 1.0000
[2019-03-23 21:04:01,151] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2288
[2019-03-23 21:04:01,158] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1247498.607797324 W.
[2019-03-23 21:04:01,165] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.16666666666667, 37.5, 1.0, 2.0, 0.3426688811374026, 1.0, 1.0, 0.3426688811374026, 1.0, 2.0, 0.5572246128397046, 6.9112, 6.9112, 121.94756008, 1247498.607797324, 1247498.607797324, 271950.0289871566], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 472200.0000, 
sim time next is 472800.0000, 
raw observation next is [29.33333333333334, 37.0, 1.0, 2.0, 0.517965942667298, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8485763677794023, 6.911199999999999, 6.9112, 121.9260426156618, 1268628.815768757, 1268628.815768757, 260207.8531224148], 
processed observation next is [1.0, 0.4782608695652174, 0.6419753086419755, 0.37, 1.0, 1.0, 0.42614993174678334, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.8107204597242529, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4530817199174132, 0.4530817199174132, 0.5003997175431054], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.87268454], dtype=float32), -0.98355424]. 
=============================================
[2019-03-23 21:04:05,616] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.1862969e-01 5.3269684e-04 5.9533175e-02 3.0007124e-01 2.1233236e-02], sum to 1.0000
[2019-03-23 21:04:05,620] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3094
[2019-03-23 21:04:05,625] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1254630.259562982 W.
[2019-03-23 21:04:05,780] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 50.0, 1.0, 2.0, 0.5184614916477402, 1.0, 2.0, 0.5184614916477402, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1254630.259562982, 1254630.259562982, 244168.3245099406], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 558000.0000, 
sim time next is 558600.0000, 
raw observation next is [27.33333333333333, 49.16666666666667, 1.0, 2.0, 0.9892727785117121, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.540753971828392, 6.9112, 121.9234486699725, 1535936.688144006, 1213555.644393381, 242119.0419237545], 
processed observation next is [1.0, 0.4782608695652174, 0.5679012345679011, 0.4916666666666667, 1.0, 1.0, 0.9872294982282287, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.06295539718283916, 0.0, 0.8094449077182724, 0.5485488171942878, 0.4334127301404932, 0.4656135421610663], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.03276342], dtype=float32), 1.0617085]. 
=============================================
[2019-03-23 21:04:07,934] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1000, global step 15918: loss 2.5487
[2019-03-23 21:04:07,936] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1000, global step 15918: learning rate 0.0005
[2019-03-23 21:04:07,952] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1000, global step 15923: loss 3.0415
[2019-03-23 21:04:07,956] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1000, global step 15924: learning rate 0.0005
[2019-03-23 21:04:07,973] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1000, global step 15931: loss 3.5894
[2019-03-23 21:04:07,974] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1000, global step 15932: learning rate 0.0005
[2019-03-23 21:04:08,007] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1000, global step 15949: loss 3.1066
[2019-03-23 21:04:08,008] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1000, global step 15950: learning rate 0.0005
[2019-03-23 21:04:08,018] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1000, global step 15955: loss 2.7547
[2019-03-23 21:04:08,019] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1000, global step 15955: learning rate 0.0005
[2019-03-23 21:04:08,033] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1000, global step 15963: loss 3.8977
[2019-03-23 21:04:08,040] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1000, global step 15966: learning rate 0.0005
[2019-03-23 21:04:08,061] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1000, global step 15978: loss 2.8880
[2019-03-23 21:04:08,063] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1000, global step 15978: learning rate 0.0005
[2019-03-23 21:04:08,065] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1000, global step 15979: loss 1.0253
[2019-03-23 21:04:08,069] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1000, global step 15979: learning rate 0.0005
[2019-03-23 21:04:08,103] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1000, global step 16000: loss 1.0557
[2019-03-23 21:04:08,106] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1000, global step 16000: learning rate 0.0005
[2019-03-23 21:04:08,111] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1000, global step 16000: loss 0.1775
[2019-03-23 21:04:08,112] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1000, global step 16000: loss 0.3516
[2019-03-23 21:04:08,114] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1000, global step 16000: learning rate 0.0005
[2019-03-23 21:04:08,116] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1000, global step 16000: learning rate 0.0005
[2019-03-23 21:04:08,122] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1000, global step 16001: loss 0.0694
[2019-03-23 21:04:08,124] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1000, global step 16001: learning rate 0.0005
[2019-03-23 21:04:08,151] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1000, global step 16017: loss 0.0051
[2019-03-23 21:04:08,156] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1000, global step 16017: learning rate 0.0005
[2019-03-23 21:04:08,209] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1000, global step 16045: loss 4.0122
[2019-03-23 21:04:08,212] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1000, global step 16046: learning rate 0.0005
[2019-03-23 21:04:08,236] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1000, global step 16058: loss 11.5796
[2019-03-23 21:04:08,236] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1000, global step 16058: learning rate 0.0005
[2019-03-23 21:04:08,311] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1000, global step 16094: loss 48.9738
[2019-03-23 21:04:08,312] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1000, global step 16094: learning rate 0.0005
[2019-03-23 21:04:10,069] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.7205274e-09 7.9073550e-19 3.7812683e-08 9.9999678e-01 3.1983934e-06], sum to 1.0000
[2019-03-23 21:04:10,077] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8065
[2019-03-23 21:04:10,243] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.13333333333334, 44.33333333333334, 1.0, 2.0, 0.5523609810824796, 1.0, 2.0, 0.5523609810824796, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1338679.622035908, 1338679.622035908, 255353.0548127792], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 638400.0000, 
sim time next is 639000.0000, 
raw observation next is [28.5, 43.5, 1.0, 2.0, 0.5669437500977577, 1.0, 2.0, 0.5669437500977577, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1370494.018816667, 1370494.018816668, 260145.6744549482], 
processed observation next is [1.0, 0.391304347826087, 0.6111111111111112, 0.435, 1.0, 1.0, 0.48445684535447336, 1.0, 1.0, 0.48445684535447336, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.48946214957738104, 0.48946214957738143, 0.5002801431825927], 
reward next is 0.4997, 
noisyNet noise sample is [array([0.40969154], dtype=float32), -1.4435012]. 
=============================================
[2019-03-23 21:04:10,283] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[59.71416 ]
 [59.703197]
 [59.469856]
 [59.72766 ]
 [59.57231 ]], R is [[59.65309143]
 [59.56549835]
 [59.48556137]
 [59.44329834]
 [59.40667725]].
[2019-03-23 21:04:24,229] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1500, global step 23894: loss 4.5918
[2019-03-23 21:04:24,230] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1500, global step 23895: learning rate 0.0005
[2019-03-23 21:04:24,232] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1500, global step 23895: loss 2.5777
[2019-03-23 21:04:24,236] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1500, global step 23895: learning rate 0.0005
[2019-03-23 21:04:24,268] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1500, global step 23912: loss 4.5697
[2019-03-23 21:04:24,271] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1500, global step 23912: learning rate 0.0005
[2019-03-23 21:04:24,288] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1500, global step 23920: loss 4.8873
[2019-03-23 21:04:24,290] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1500, global step 23921: learning rate 0.0005
[2019-03-23 21:04:24,318] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1500, global step 23938: loss 2.1376
[2019-03-23 21:04:24,320] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1500, global step 23940: learning rate 0.0005
[2019-03-23 21:04:24,345] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1500, global step 23954: loss 1.9239
[2019-03-23 21:04:24,347] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1500, global step 23956: learning rate 0.0005
[2019-03-23 21:04:24,373] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1500, global step 23969: loss 0.1954
[2019-03-23 21:04:24,374] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1500, global step 23969: learning rate 0.0005
[2019-03-23 21:04:24,377] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1500, global step 23969: loss 0.2453
[2019-03-23 21:04:24,380] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1500, global step 23969: loss 0.0391
[2019-03-23 21:04:24,380] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1500, global step 23969: learning rate 0.0005
[2019-03-23 21:04:24,381] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1500, global step 23969: loss 0.0820
[2019-03-23 21:04:24,381] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1500, global step 23969: learning rate 0.0005
[2019-03-23 21:04:24,384] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1500, global step 23969: learning rate 0.0005
[2019-03-23 21:04:24,479] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1500, global step 24019: loss 0.1978
[2019-03-23 21:04:24,482] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1500, global step 24020: learning rate 0.0005
[2019-03-23 21:04:24,518] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1500, global step 24040: loss 0.7298
[2019-03-23 21:04:24,522] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1500, global step 24040: learning rate 0.0005
[2019-03-23 21:04:24,565] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1500, global step 24061: loss 1.4076
[2019-03-23 21:04:24,567] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1500, global step 24061: learning rate 0.0005
[2019-03-23 21:04:24,610] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1500, global step 24081: loss 1.1698
[2019-03-23 21:04:24,613] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1500, global step 24082: learning rate 0.0005
[2019-03-23 21:04:24,633] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1500, global step 24096: loss 0.6961
[2019-03-23 21:04:24,635] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1500, global step 24097: learning rate 0.0005
[2019-03-23 21:04:24,693] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1500, global step 24126: loss 0.2368
[2019-03-23 21:04:24,701] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1500, global step 24128: learning rate 0.0005
[2019-03-23 21:04:26,571] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 21:04:26,572] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:04:26,572] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:04:26,573] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:04:26,574] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:04:26,573] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:04:26,574] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:04:26,577] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:04:26,576] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:04:26,575] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:04:26,577] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:04:26,584] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run2
[2019-03-23 21:04:26,584] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run2
[2019-03-23 21:04:26,629] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run2
[2019-03-23 21:04:26,651] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run2
[2019-03-23 21:04:26,674] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run2
[2019-03-23 21:04:35,108] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.03970693], dtype=float32), 0.19428973]
[2019-03-23 21:04:35,108] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [34.21319234, 25.78862378, 1.0, 2.0, 0.9345862443039026, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.172891638220921, 6.9112, 121.9249707793971, 1279306.508302535, 1145298.177860682, 228949.6343564453]
[2019-03-23 21:04:35,109] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:04:35,112] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.1649921e-29 6.6950877e-24 3.4535344e-24 4.7697070e-18], sampled 0.4914011890242105
[2019-03-23 21:04:35,114] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1279306.508302535 W.
[2019-03-23 21:04:40,319] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.03970693], dtype=float32), 0.19428973]
[2019-03-23 21:04:40,321] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.55, 57.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5730894275301268, 6.9112, 6.9112, 121.9260426156618, 423093.8315448696, 423093.8315448696, 126462.1616972362]
[2019-03-23 21:04:40,321] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:04:40,324] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.1675814e-29 6.7073064e-24 3.4585441e-24 4.7767716e-18], sampled 0.1912922005240031
[2019-03-23 21:05:03,445] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.03970693], dtype=float32), 0.19428973]
[2019-03-23 21:05:03,446] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.19342839333333, 78.71542778333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7351453698003821, 6.911200000000001, 6.9112, 121.9260426156618, 549018.1399906646, 549018.1399906641, 150038.133382368]
[2019-03-23 21:05:03,446] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:05:03,448] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.0746093e-29 6.2775875e-24 3.2277047e-24 4.5489255e-18], sampled 0.32914351876490844
[2019-03-23 21:06:01,911] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.03970693], dtype=float32), 0.19428973]
[2019-03-23 21:06:01,912] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.694363505, 80.080852525, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6896028648210651, 6.9112, 6.9112, 121.9260426156618, 514493.6682331615, 514493.6682331615, 141552.8156712634]
[2019-03-23 21:06:01,914] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:06:01,918] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.0014855e-29 5.8800856e-24 3.0530047e-24 4.3332200e-18], sampled 0.9899439873226291
[2019-03-23 21:06:04,851] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-23 21:06:04,888] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-23 21:06:04,950] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-23 21:06:04,983] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-23 21:06:05,248] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-23 21:06:06,266] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 25000, evaluation results [25000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-23 21:06:06,810] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 2.1162066e-17 3.9841017e-13 1.8746551e-13 2.5060590e-10], sum to 1.0000
[2019-03-23 21:06:06,817] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5975
[2019-03-23 21:06:06,988] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.91666666666666, 51.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5019448079236557, 6.911200000000001, 6.9112, 121.9260426156618, 361761.0121232748, 361761.0121232743, 116431.8546249511], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 949800.0000, 
sim time next is 950400.0000, 
raw observation next is [22.8, 52.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4999962773617797, 6.911199999999999, 6.9112, 121.9260426156618, 360203.8783045569, 360203.8783045574, 116225.4293405314], 
processed observation next is [1.0, 0.0, 0.4, 0.52, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3749953467022246, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12864424225162746, 0.12864424225162766, 0.22351044103948345], 
reward next is 0.7765, 
noisyNet noise sample is [array([0.47848582], dtype=float32), -0.20645913]. 
=============================================
[2019-03-23 21:06:09,493] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 3.9592299e-14 8.0114916e-12 4.9336497e-11 7.9620360e-10], sum to 1.0000
[2019-03-23 21:06:09,498] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1492
[2019-03-23 21:06:09,501] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1198576.358288039 W.
[2019-03-23 21:06:09,660] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.36666666666667, 52.66666666666667, 1.0, 2.0, 0.9023262525378868, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.057171826102709, 6.9112, 121.9255237878111, 1198576.358288039, 1123826.054593527, 221954.5835909942], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 998400.0000, 
sim time next is 999000.0000, 
raw observation next is [25.4, 52.5, 1.0, 2.0, 0.9320558238471349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.277537834466556, 6.9112, 121.9244095997842, 1352311.03561862, 1164715.834056748, 228969.4156854912], 
processed observation next is [1.0, 0.5652173913043478, 0.49629629629629624, 0.525, 1.0, 1.0, 0.9191140760084939, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0366337834466556, 0.0, 0.8094512872929255, 0.48296822700665, 0.4159699407345529, 0.4403257993951754], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6127403], dtype=float32), 0.52917516]. 
=============================================
[2019-03-23 21:06:09,702] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[34.816505]
 [34.828064]
 [34.851486]
 [34.859917]
 [34.853813]], R is [[34.4791069 ]
 [34.13431549]
 [34.39091492]
 [34.63581085]
 [34.2894516 ]].
[2019-03-23 21:06:15,406] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.8283634e-13 8.8097377e-11 3.2538756e-13 2.5358968e-12], sum to 1.0000
[2019-03-23 21:06:15,415] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8612
[2019-03-23 21:06:15,585] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.05, 65.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5739899170114661, 6.9112, 6.9112, 121.9260426156618, 422823.4142250275, 422823.4142250275, 126043.8042370973], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1108200.0000, 
sim time next is 1108800.0000, 
raw observation next is [21.8, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5669870804247066, 6.9112, 6.9112, 121.9260426156618, 417457.0829316775, 417457.0829316775, 125315.6016477834], 
processed observation next is [1.0, 0.8695652173913043, 0.362962962962963, 0.67, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.45873385053088317, 0.0, 0.0, 0.8094621288201359, 0.14909181533274196, 0.14909181533274196, 0.2409915416303527], 
reward next is 0.7590, 
noisyNet noise sample is [array([2.3067644], dtype=float32), -0.15451534]. 
=============================================
[2019-03-23 21:06:15,646] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.6374063e-17 1.4613668e-14 1.7581018e-17 9.4761513e-17], sum to 1.0000
[2019-03-23 21:06:15,653] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0843
[2019-03-23 21:06:15,662] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1060642.028901259 W.
[2019-03-23 21:06:15,667] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.3, 46.0, 1.0, 2.0, 0.4278358113549584, 1.0, 1.0, 0.4278358113549584, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1060642.028901259, 1060642.02890126, 217145.6554139162], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1098000.0000, 
sim time next is 1098600.0000, 
raw observation next is [26.05, 47.0, 1.0, 2.0, 0.2257192012563985, 0.0, 1.0, 0.0, 1.0, 1.0, 0.3768140309204709, 6.911199999999999, 6.9112, 121.9260426156618, 562044.0682297314, 562044.0682297319, 173019.6702782957], 
processed observation next is [1.0, 0.7391304347826086, 0.5203703703703704, 0.47, 1.0, 1.0, 0.07823714435285535, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.2210175386505886, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20073002436776122, 0.20073002436776138, 0.33273013515056865], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.1476145], dtype=float32), -0.3329688]. 
=============================================
[2019-03-23 21:06:16,742] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.3556142e-26 6.5005509e-23 1.9346873e-24 7.9269571e-25], sum to 1.0000
[2019-03-23 21:06:16,751] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3571
[2019-03-23 21:06:16,754] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.7, 73.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.523869868658807, 6.911199999999999, 6.9112, 121.9260426156618, 379304.7682267182, 379304.7682267186, 118795.7541380386], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1117800.0000, 
sim time next is 1118400.0000, 
raw observation next is [19.56666666666667, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5231932027568298, 6.9112, 6.9112, 121.9260426156618, 378375.5765610061, 378375.5765610061, 118575.9109621067], 
processed observation next is [1.0, 0.9565217391304348, 0.28024691358024706, 0.74, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4039915034460372, 0.0, 0.0, 0.8094621288201359, 0.1351341344860736, 0.1351341344860736, 0.22803059800405134], 
reward next is 0.7720, 
noisyNet noise sample is [array([-0.36117104], dtype=float32), 0.4378426]. 
=============================================
[2019-03-23 21:06:18,070] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 8.3587706e-20 2.0358892e-17 9.2787491e-21 8.2101739e-21], sum to 1.0000
[2019-03-23 21:06:18,078] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8575
[2019-03-23 21:06:18,085] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.78333333333333, 76.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.500665918220615, 6.911199999999999, 6.9112, 121.9260426156618, 358684.1325584982, 358684.1325584986, 115575.2423213773], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1141800.0000, 
sim time next is 1142400.0000, 
raw observation next is [18.86666666666667, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4869897825110018, 6.911200000000001, 6.9112, 121.9260426156618, 349015.4611896213, 349015.4611896209, 114582.6552107197], 
processed observation next is [1.0, 0.21739130434782608, 0.25432098765432115, 0.76, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3587372281387522, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12464837899629332, 0.12464837899629318, 0.2203512600206148], 
reward next is 0.7796, 
noisyNet noise sample is [array([1.3353084], dtype=float32), 2.184225]. 
=============================================
[2019-03-23 21:06:20,486] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2000, global step 31800: loss 0.1983
[2019-03-23 21:06:20,488] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2000, global step 31800: learning rate 0.0005
[2019-03-23 21:06:20,588] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2000, global step 31854: loss 0.0015
[2019-03-23 21:06:20,592] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2000, global step 31854: learning rate 0.0005
[2019-03-23 21:06:20,614] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2000, global step 31865: loss 0.0001
[2019-03-23 21:06:20,617] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2000, global step 31866: learning rate 0.0005
[2019-03-23 21:06:20,656] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2000, global step 31881: loss 0.0873
[2019-03-23 21:06:20,659] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2000, global step 31881: learning rate 0.0005
[2019-03-23 21:06:20,675] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2000, global step 31891: loss 0.2661
[2019-03-23 21:06:20,680] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2000, global step 31893: learning rate 0.0005
[2019-03-23 21:06:20,704] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2000, global step 31906: loss 0.1891
[2019-03-23 21:06:20,705] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2000, global step 31906: learning rate 0.0005
[2019-03-23 21:06:20,776] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2000, global step 31942: loss 0.0143
[2019-03-23 21:06:20,781] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2000, global step 31944: learning rate 0.0005
[2019-03-23 21:06:20,798] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 5.3461601e-18 1.7405385e-13 9.0866048e-17 1.4315747e-17], sum to 1.0000
[2019-03-23 21:06:20,807] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5795
[2019-03-23 21:06:20,815] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.13333333333333, 90.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5951059529308314, 6.911200000000001, 6.9112, 121.9260426156618, 440330.1255956802, 440330.1255956798, 129022.31255813], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1203000.0000, 
sim time next is 1203600.0000, 
raw observation next is [19.06666666666667, 91.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5972060142790258, 6.9112, 6.9112, 121.9260426156618, 441932.1160951412, 441932.1160951412, 129245.5482135977], 
processed observation next is [1.0, 0.9565217391304348, 0.2617283950617285, 0.9133333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.49650751784878216, 0.0, 0.0, 0.8094621288201359, 0.15783289860540758, 0.15783289860540758, 0.24854913117999558], 
reward next is 0.7515, 
noisyNet noise sample is [array([-0.48184478], dtype=float32), 1.1696433]. 
=============================================
[2019-03-23 21:06:20,828] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2000, global step 31967: loss 0.1162
[2019-03-23 21:06:20,828] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2000, global step 31967: learning rate 0.0005
[2019-03-23 21:06:20,861] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2000, global step 31981: loss 0.2331
[2019-03-23 21:06:20,863] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2000, global step 31981: learning rate 0.0005
[2019-03-23 21:06:20,878] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2000, global step 31990: loss 0.2505
[2019-03-23 21:06:20,878] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2000, global step 31990: learning rate 0.0005
[2019-03-23 21:06:21,038] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2000, global step 32066: loss 0.2123
[2019-03-23 21:06:21,040] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2000, global step 32066: learning rate 0.0005
[2019-03-23 21:06:21,102] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2000, global step 32099: loss 0.0002
[2019-03-23 21:06:21,104] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2000, global step 32099: learning rate 0.0005
[2019-03-23 21:06:21,156] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2000, global step 32125: loss 0.0002
[2019-03-23 21:06:21,157] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2000, global step 32125: learning rate 0.0005
[2019-03-23 21:06:21,178] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2000, global step 32135: loss 0.1042
[2019-03-23 21:06:21,179] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2000, global step 32135: learning rate 0.0005
[2019-03-23 21:06:21,220] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2000, global step 32155: loss 0.6677
[2019-03-23 21:06:21,226] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2000, global step 32156: learning rate 0.0005
[2019-03-23 21:06:21,250] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2000, global step 32171: loss 0.5861
[2019-03-23 21:06:21,252] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2000, global step 32173: learning rate 0.0005
[2019-03-23 21:06:21,581] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.00000000e+00 1.32521604e-20 2.06770060e-14 5.96632244e-19
 1.86999610e-19], sum to 1.0000
[2019-03-23 21:06:21,588] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9401
[2019-03-23 21:06:21,592] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.3, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5604457425477941, 6.911199999999999, 6.9112, 121.9260426156618, 412642.8571621415, 412642.8571621419, 124740.7079866557], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1213200.0000, 
sim time next is 1213800.0000, 
raw observation next is [18.26666666666667, 93.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5585723268338015, 6.9112, 6.9112, 121.9260426156618, 410992.4739848207, 410992.4739848207, 124439.289871485], 
processed observation next is [1.0, 0.043478260869565216, 0.23209876543209887, 0.9383333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4482154085422519, 0.0, 0.0, 0.8094621288201359, 0.14678302642315025, 0.14678302642315025, 0.23930632667593268], 
reward next is 0.7607, 
noisyNet noise sample is [array([0.9313453], dtype=float32), -0.12737174]. 
=============================================
[2019-03-23 21:06:23,018] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.00000000e+00 1.07036182e-23 1.04436916e-19 1.08631897e-21
 1.38590305e-21], sum to 1.0000
[2019-03-23 21:06:23,026] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0781
[2019-03-23 21:06:23,034] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.45, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6246559126329172, 6.9112, 6.9112, 121.9260426156618, 457823.5562529006, 457823.5562529006, 129548.5431648708], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1233000.0000, 
sim time next is 1233600.0000, 
raw observation next is [18.53333333333333, 89.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5756490871831841, 6.911200000000001, 6.9112, 121.9260426156618, 422164.3434182303, 422164.3434182298, 125275.80923431], 
processed observation next is [1.0, 0.2608695652173913, 0.24197530864197525, 0.8966666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.46956135897898005, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15077297979222512, 0.15077297979222493, 0.24091501775828847], 
reward next is 0.7591, 
noisyNet noise sample is [array([-0.6328316], dtype=float32), -0.335975]. 
=============================================
[2019-03-23 21:06:36,008] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 4.5071033e-35 2.7757862e-32 1.5113646e-31 6.1001321e-32], sum to 1.0000
[2019-03-23 21:06:36,014] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3148
[2019-03-23 21:06:36,017] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 66.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.582139108139568, 6.9112, 6.9112, 121.9260426156618, 428853.0606733223, 428853.0606733223, 126786.0208648141], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1482000.0000, 
sim time next is 1482600.0000, 
raw observation next is [21.9, 67.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5824456673953191, 6.911200000000001, 6.9112, 121.9260426156618, 429217.0298702572, 429217.0298702568, 126885.1441628305], 
processed observation next is [0.0, 0.13043478260869565, 0.36666666666666664, 0.6716666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.47805708424414883, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15329179638223472, 0.15329179638223456, 0.2440098926208279], 
reward next is 0.7560, 
noisyNet noise sample is [array([-0.13676183], dtype=float32), -0.025356563]. 
=============================================
[2019-03-23 21:06:36,622] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2500, global step 39765: loss 0.0187
[2019-03-23 21:06:36,630] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2500, global step 39765: learning rate 0.0005
[2019-03-23 21:06:36,684] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2500, global step 39794: loss 0.3393
[2019-03-23 21:06:36,686] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2500, global step 39794: learning rate 0.0005
[2019-03-23 21:06:36,694] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2500, global step 39799: loss 0.3246
[2019-03-23 21:06:36,695] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2500, global step 39799: learning rate 0.0005
[2019-03-23 21:06:36,905] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2500, global step 39902: loss 0.0015
[2019-03-23 21:06:36,907] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2500, global step 39903: learning rate 0.0005
[2019-03-23 21:06:36,929] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2500, global step 39915: loss 0.0029
[2019-03-23 21:06:36,932] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2500, global step 39917: learning rate 0.0005
[2019-03-23 21:06:36,945] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2500, global step 39925: loss 0.0000
[2019-03-23 21:06:36,948] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2500, global step 39926: learning rate 0.0005
[2019-03-23 21:06:36,961] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2500, global step 39931: loss 0.0110
[2019-03-23 21:06:36,963] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2500, global step 39931: learning rate 0.0005
[2019-03-23 21:06:37,032] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2500, global step 39963: loss 0.2195
[2019-03-23 21:06:37,034] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2500, global step 39964: learning rate 0.0005
[2019-03-23 21:06:37,040] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2500, global step 39965: loss 0.3107
[2019-03-23 21:06:37,046] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2500, global step 39966: learning rate 0.0005
[2019-03-23 21:06:37,123] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2500, global step 40009: loss 0.3767
[2019-03-23 21:06:37,125] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2500, global step 40011: learning rate 0.0005
[2019-03-23 21:06:37,167] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2500, global step 40028: loss 0.0775
[2019-03-23 21:06:37,169] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2500, global step 40028: learning rate 0.0005
[2019-03-23 21:06:37,309] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2500, global step 40102: loss 0.0803
[2019-03-23 21:06:37,313] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2500, global step 40103: learning rate 0.0005
[2019-03-23 21:06:37,384] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2500, global step 40133: loss 0.5790
[2019-03-23 21:06:37,387] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2500, global step 40133: learning rate 0.0005
[2019-03-23 21:06:37,461] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2500, global step 40176: loss 0.1235
[2019-03-23 21:06:37,463] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2500, global step 40176: learning rate 0.0005
[2019-03-23 21:06:37,499] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2500, global step 40191: loss 0.0353
[2019-03-23 21:06:37,502] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2500, global step 40192: learning rate 0.0005
[2019-03-23 21:06:37,519] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2500, global step 40199: loss 0.0279
[2019-03-23 21:06:37,523] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2500, global step 40200: learning rate 0.0005
[2019-03-23 21:06:42,358] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 5.9340071e-17 3.7683625e-16 9.0792636e-16 1.8266117e-15], sum to 1.0000
[2019-03-23 21:06:42,365] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6020
[2019-03-23 21:06:42,372] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1139563.770519798 W.
[2019-03-23 21:06:42,375] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.13333333333333, 45.0, 1.0, 2.0, 0.3117054900920002, 1.0, 2.0, 0.3117054900920002, 1.0, 1.0, 0.5085534051638727, 6.9112, 6.9112, 121.94756008, 1139563.770519798, 1139563.770519798, 259417.1323067228], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1604400.0000, 
sim time next is 1605000.0000, 
raw observation next is [27.21666666666667, 44.5, 1.0, 2.0, 0.9117598334653059, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.09590484412958, 6.9112, 121.9252275901868, 1225598.192758013, 1131013.436096476, 224021.8101017412], 
processed observation next is [1.0, 0.5652173913043478, 0.5635802469135803, 0.445, 1.0, 1.0, 0.8949521826967927, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.018470484412957955, 0.0, 0.8094567178985487, 0.43771364027071896, 0.4039333700344557, 0.43081117327257923], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.112365], dtype=float32), 0.47454154]. 
=============================================
[2019-03-23 21:06:42,393] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[40.724846]
 [40.78589 ]
 [40.514347]
 [40.57051 ]
 [40.23706 ]], R is [[40.66833496]
 [40.2616539 ]
 [40.43352127]
 [40.5983429 ]
 [40.79899979]].
[2019-03-23 21:06:43,405] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 3.4583393e-13 5.7000253e-08 1.3810554e-10 2.7654964e-10], sum to 1.0000
[2019-03-23 21:06:43,411] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0512
[2019-03-23 21:06:43,563] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.86666666666667, 41.50000000000001, 1.0, 2.0, 0.2315338866731908, 1.0, 1.0, 0.2315338866731908, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156602, 571711.219232459, 571711.2192324594, 166683.7454195494], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1617000.0000, 
sim time next is 1617600.0000, 
raw observation next is [27.73333333333333, 42.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5881199527737302, 6.9112, 6.9112, 121.9260426156618, 438276.0559546595, 438276.0559546595, 130738.0450596945], 
processed observation next is [1.0, 0.7391304347826086, 0.5827160493827159, 0.42, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.4851499409671627, 0.0, 0.0, 0.8094621288201359, 0.1565271628409498, 0.1565271628409498, 0.2514193174224894], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.37175268], dtype=float32), 0.81704515]. 
=============================================
[2019-03-23 21:06:51,820] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 2.1076968e-19 7.2689549e-14 3.1039726e-15 3.7155944e-14], sum to 1.0000
[2019-03-23 21:06:51,828] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6868
[2019-03-23 21:06:51,833] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1065743.863576787 W.
[2019-03-23 21:06:51,835] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.4, 65.0, 1.0, 2.0, 0.444440384606596, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7172309978802625, 6.911199999999999, 6.9112, 121.9260426156618, 1065743.863576787, 1065743.863576787, 236663.7760464432], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1774800.0000, 
sim time next is 1775400.0000, 
raw observation next is [25.46666666666667, 64.66666666666667, 1.0, 2.0, 0.2723626040289586, 1.0, 1.0, 0.2723626040289586, 1.0, 2.0, 0.4373689556349609, 6.9112, 6.9112, 121.94756008, 969601.2662674825, 969601.2662674825, 245402.1941402956], 
processed observation next is [1.0, 0.5652173913043478, 0.4987654320987655, 0.6466666666666667, 1.0, 1.0, 0.13376500479637932, 1.0, 0.5, 0.13376500479637932, 1.0, 1.0, 0.2967111945437011, 0.0, 0.0, 0.8096049824067558, 0.3462861665241009, 0.3462861665241009, 0.4719272964236454], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.07997622], dtype=float32), -0.15856645]. 
=============================================
[2019-03-23 21:06:52,001] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 5.1873579e-16 6.0577810e-12 1.7712321e-13 7.3634614e-12], sum to 1.0000
[2019-03-23 21:06:52,006] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7635
[2019-03-23 21:06:52,011] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1003261.465116297 W.
[2019-03-23 21:06:52,175] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.35, 69.0, 1.0, 2.0, 0.8236289893263263, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 1003261.465116297, 1003261.465116298, 203738.49087748], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1765800.0000, 
sim time next is 1766400.0000, 
raw observation next is [24.46666666666667, 68.66666666666666, 1.0, 2.0, 0.4470237524398439, 1.0, 1.0, 0.4470237524398439, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1075189.202423345, 1075189.202423345, 221846.8225025844], 
processed observation next is [1.0, 0.43478260869565216, 0.46172839506172847, 0.6866666666666665, 1.0, 1.0, 0.34169494338076656, 1.0, 0.5, 0.34169494338076656, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.38399614372262325, 0.38399614372262325, 0.4266285048126623], 
reward next is 0.5734, 
noisyNet noise sample is [array([0.6360136], dtype=float32), 1.3963127]. 
=============================================
[2019-03-23 21:06:53,083] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 2.5492875e-15 1.2754361e-11 1.7799987e-11 1.2161014e-11], sum to 1.0000
[2019-03-23 21:06:53,091] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9135
[2019-03-23 21:06:53,099] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1462097.61064483 W.
[2019-03-23 21:06:53,102] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.66666666666667, 60.66666666666667, 1.0, 2.0, 0.6301775021891768, 1.0, 1.0, 0.6301775021891768, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1462097.61064483, 1462097.61064483, 279795.8169957682], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1783200.0000, 
sim time next is 1783800.0000, 
raw observation next is [27.5, 62.0, 1.0, 2.0, 0.4279885212105116, 1.0, 2.0, 0.4279885212105116, 1.0, 1.0, 0.6814818552239448, 6.9112, 6.9112, 121.94756008, 1468442.726172391, 1468442.726172391, 309591.1193681], 
processed observation next is [1.0, 0.6521739130434783, 0.5740740740740741, 0.62, 1.0, 1.0, 0.3190339538220377, 1.0, 1.0, 0.3190339538220377, 1.0, 0.5, 0.601852319029931, 0.0, 0.0, 0.8096049824067558, 0.524443830775854, 0.524443830775854, 0.5953675372463462], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8198594], dtype=float32), -1.1311215]. 
=============================================
[2019-03-23 21:06:53,120] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3000, global step 47722: loss 2.8138
[2019-03-23 21:06:53,121] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3000, global step 47722: learning rate 0.0005
[2019-03-23 21:06:53,278] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3000, global step 47800: loss 2.3789
[2019-03-23 21:06:53,282] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3000, global step 47800: learning rate 0.0005
[2019-03-23 21:06:53,329] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3000, global step 47826: loss 2.3443
[2019-03-23 21:06:53,332] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3000, global step 47826: learning rate 0.0005
[2019-03-23 21:06:53,404] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3000, global step 47864: loss 2.2313
[2019-03-23 21:06:53,405] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3000, global step 47864: learning rate 0.0005
[2019-03-23 21:06:53,449] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3000, global step 47886: loss 2.0601
[2019-03-23 21:06:53,451] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3000, global step 47886: learning rate 0.0005
[2019-03-23 21:06:53,514] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3000, global step 47919: loss 2.2275
[2019-03-23 21:06:53,516] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3000, global step 47920: learning rate 0.0005
[2019-03-23 21:06:53,560] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3000, global step 47939: loss 1.8420
[2019-03-23 21:06:53,561] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3000, global step 47939: learning rate 0.0005
[2019-03-23 21:06:53,684] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3000, global step 48000: loss 1.4170
[2019-03-23 21:06:53,687] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3000, global step 48001: learning rate 0.0005
[2019-03-23 21:06:53,691] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3000, global step 48002: loss 1.2661
[2019-03-23 21:06:53,699] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3000, global step 48003: learning rate 0.0005
[2019-03-23 21:06:53,705] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3000, global step 48006: loss 1.1712
[2019-03-23 21:06:53,708] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3000, global step 48007: learning rate 0.0005
[2019-03-23 21:06:53,890] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3000, global step 48100: loss 0.2100
[2019-03-23 21:06:53,892] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3000, global step 48100: learning rate 0.0005
[2019-03-23 21:06:53,912] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3000, global step 48112: loss 0.2491
[2019-03-23 21:06:53,913] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3000, global step 48112: learning rate 0.0005
[2019-03-23 21:06:53,968] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3000, global step 48141: loss 0.0061
[2019-03-23 21:06:53,971] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3000, global step 48141: learning rate 0.0005
[2019-03-23 21:06:54,003] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3000, global step 48157: loss 0.0491
[2019-03-23 21:06:54,009] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3000, global step 48158: learning rate 0.0005
[2019-03-23 21:06:54,027] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3000, global step 48166: loss 0.0069
[2019-03-23 21:06:54,031] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3000, global step 48166: learning rate 0.0005
[2019-03-23 21:06:54,116] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3000, global step 48213: loss 0.3235
[2019-03-23 21:06:54,117] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3000, global step 48213: learning rate 0.0005
[2019-03-23 21:06:57,808] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 21:06:57,810] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:06:57,812] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:06:57,814] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:06:57,816] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:06:57,819] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:06:57,819] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:06:57,821] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:06:57,822] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:06:57,823] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:06:57,824] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:06:57,833] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run3
[2019-03-23 21:06:57,867] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run3
[2019-03-23 21:06:57,869] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run3
[2019-03-23 21:06:57,914] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run3
[2019-03-23 21:06:57,945] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run3
[2019-03-23 21:07:03,385] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.03970693], dtype=float32), 0.05452023]
[2019-03-23 21:07:03,386] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.0, 29.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8206966315814249, 6.9112, 6.9112, 121.9260426156618, 600202.9139640869, 600202.9139640869, 148513.1188143787]
[2019-03-23 21:07:03,387] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:07:03,391] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.9584110e-17 2.5518502e-12 8.2449469e-14 1.6196579e-13], sampled 0.7489169522366533
[2019-03-23 21:07:32,144] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.03970693], dtype=float32), 0.05452023]
[2019-03-23 21:07:32,146] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.04436084, 89.84738512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8518514918522334, 6.911200000000001, 6.9112, 121.9260426156618, 623768.4521296566, 623768.4521296561, 169580.2091870756]
[2019-03-23 21:07:32,147] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:07:32,149] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.9584110e-17 2.5518502e-12 8.2449469e-14 1.6196579e-13], sampled 0.10660511940402462
[2019-03-23 21:07:35,773] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.03970693], dtype=float32), 0.05452023]
[2019-03-23 21:07:35,774] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.0, 79.00000000000001, 1.0, 2.0, 0.6496723932633917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 740415.0397378244, 740415.0397378244, 166834.0647213006]
[2019-03-23 21:07:35,775] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:07:35,778] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.9584110e-17 2.5518502e-12 8.2449469e-14 1.6196579e-13], sampled 0.7204732493290704
[2019-03-23 21:07:35,778] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 740415.0397378244 W.
[2019-03-23 21:07:49,662] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.03970693], dtype=float32), 0.05452023]
[2019-03-23 21:07:49,663] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.297441865, 95.45543008, 1.0, 2.0, 0.637020480573143, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 725989.1497749178, 725989.1497749173, 164561.6328600437]
[2019-03-23 21:07:49,663] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:07:49,666] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.9584110e-17 2.5518502e-12 8.2449469e-14 1.6196579e-13], sampled 0.8218166571914615
[2019-03-23 21:07:49,669] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 725989.1497749178 W.
[2019-03-23 21:07:49,920] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.03970693], dtype=float32), 0.05452023]
[2019-03-23 21:07:49,921] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.82430660333333, 101.2016496333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.837339720320185, 6.911199999999999, 6.9112, 121.9260426156618, 619471.101330895, 619471.1013308954, 166016.3180987903]
[2019-03-23 21:07:49,923] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:07:49,927] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.9584110e-17 2.5518502e-12 8.2449469e-14 1.6196579e-13], sampled 0.8979193590900234
[2019-03-23 21:08:35,616] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-23 21:08:36,095] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-23 21:08:36,106] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-23 21:08:36,181] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-23 21:08:36,182] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-23 21:08:37,197] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 50000, evaluation results [50000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-23 21:08:39,275] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 7.6520894e-34 6.8622739e-26 9.7842621e-26 5.6180262e-27], sum to 1.0000
[2019-03-23 21:08:39,280] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1801
[2019-03-23 21:08:39,286] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.6, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.605569041863236, 6.911199999999999, 6.9112, 121.9260426156618, 450479.5538233489, 450479.5538233494, 131670.6754496494], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1912800.0000, 
sim time next is 1913400.0000, 
raw observation next is [19.6, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.603160334417735, 6.911200000000001, 6.9112, 121.9260426156618, 448686.7308319131, 448686.7308319126, 131439.3257512118], 
processed observation next is [1.0, 0.13043478260869565, 0.28148148148148155, 0.92, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5039504180221687, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16024526101139755, 0.16024526101139736, 0.2527679341369458], 
reward next is 0.7472, 
noisyNet noise sample is [array([1.102246], dtype=float32), 0.26134187]. 
=============================================
[2019-03-23 21:08:39,563] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.4855185e-29 2.8514603e-25 8.7225277e-22 1.5924983e-25], sum to 1.0000
[2019-03-23 21:08:39,570] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3710
[2019-03-23 21:08:39,574] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.66666666666667, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6383622138564529, 6.9112, 6.9112, 121.9260426156618, 475076.600390973, 475076.600390973, 135031.8808633009], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1917600.0000, 
sim time next is 1918200.0000, 
raw observation next is [19.68333333333333, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6352656621577787, 6.911200000000001, 6.9112, 121.9260426156618, 472823.0166646215, 472823.016664621, 134770.7084833345], 
processed observation next is [1.0, 0.17391304347826086, 0.28456790123456777, 0.92, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5440820776972233, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16886536309450767, 0.1688653630945075, 0.2591744393910279], 
reward next is 0.7408, 
noisyNet noise sample is [array([-1.0181801], dtype=float32), -0.94740504]. 
=============================================
[2019-03-23 21:08:43,287] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 1.3211222e-28 9.5559695e-26 1.2888736e-23 2.3896840e-25], sum to 1.0000
[2019-03-23 21:08:43,292] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4578
[2019-03-23 21:08:43,297] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.45, 90.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6090071172170761, 6.911199999999999, 6.9112, 121.9260426156618, 451950.1315878597, 451950.1315878602, 131174.0378227436], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1992600.0000, 
sim time next is 1993200.0000, 
raw observation next is [19.43333333333333, 90.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6058066761269064, 6.911200000000001, 6.9112, 121.9260426156618, 449433.3822047869, 449433.3822047865, 130772.9791128971], 
processed observation next is [0.0, 0.043478260869565216, 0.2753086419753085, 0.9033333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.507258345158633, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1605119222159953, 0.1605119222159952, 0.25148649829403286], 
reward next is 0.7485, 
noisyNet noise sample is [array([-0.03355186], dtype=float32), -1.4067415]. 
=============================================
[2019-03-23 21:08:46,779] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.7078358e-26 7.1665886e-21 1.0717444e-20 3.5716413e-23], sum to 1.0000
[2019-03-23 21:08:46,789] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8315
[2019-03-23 21:08:46,795] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.0, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9436004796640478, 6.9112, 6.9112, 121.9260426156618, 682341.0912417672, 682341.0912417672, 183169.023109563], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2047200.0000, 
sim time next is 2047800.0000, 
raw observation next is [29.05, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9460734294502178, 6.9112, 6.9112, 121.9260426156618, 683538.7708054628, 683538.7708054628, 183587.0178714982], 
processed observation next is [0.0, 0.6956521739130435, 0.6314814814814815, 0.63, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9325917868127722, 0.0, 0.0, 0.8094621288201359, 0.24412098957337958, 0.24412098957337958, 0.3530519574451888], 
reward next is 0.6469, 
noisyNet noise sample is [array([-1.0203626], dtype=float32), -0.66895986]. 
=============================================
[2019-03-23 21:08:46,914] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 2.9431329e-24 3.7598725e-18 2.1308106e-18 1.6192167e-20], sum to 1.0000
[2019-03-23 21:08:46,921] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0609
[2019-03-23 21:08:46,926] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 696547.387841146 W.
[2019-03-23 21:08:46,930] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.86666666666667, 69.66666666666666, 1.0, 2.0, 0.2037328448156137, 1.0, 1.0, 0.2037328448156137, 1.0, 2.0, 0.3243493240619912, 6.911199999999999, 6.9112, 121.94756008, 696547.387841146, 696547.3878411464, 221817.8308042131], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2054400.0000, 
sim time next is 2055000.0000, 
raw observation next is [27.73333333333333, 70.33333333333334, 1.0, 2.0, 0.3057404097321377, 1.0, 2.0, 0.3057404097321377, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 696869.2937297772, 696869.2937297772, 181843.9396468231], 
processed observation next is [0.0, 0.782608695652174, 0.5827160493827159, 0.7033333333333335, 1.0, 1.0, 0.17350048777635438, 1.0, 1.0, 0.17350048777635438, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24888189061777757, 0.24888189061777757, 0.3496998839361983], 
reward next is 0.6503, 
noisyNet noise sample is [array([-1.5304817], dtype=float32), -0.17275381]. 
=============================================
[2019-03-23 21:08:46,946] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[56.723286]
 [56.723286]
 [56.723286]
 [56.723286]
 [56.723286]], R is [[56.80635071]
 [56.23828888]
 [55.67590714]
 [55.11914825]
 [54.56795883]].
[2019-03-23 21:08:48,805] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3500, global step 55699: loss 0.0592
[2019-03-23 21:08:48,809] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3500, global step 55700: learning rate 0.0005
[2019-03-23 21:08:48,868] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3500, global step 55732: loss 0.2465
[2019-03-23 21:08:48,870] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3500, global step 55733: learning rate 0.0005
[2019-03-23 21:08:48,999] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 3.6120741e-31 7.7550611e-26 1.6738397e-25 1.9908138e-26], sum to 1.0000
[2019-03-23 21:08:49,011] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9531
[2019-03-23 21:08:49,016] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.08333333333334, 92.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7010728193285627, 6.911200000000001, 6.9112, 121.9260426156618, 523842.4251697067, 523842.4251697062, 145477.9160594924], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2094600.0000, 
sim time next is 2095200.0000, 
raw observation next is [21.2, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7041791682828537, 6.911199999999999, 6.9112, 121.9260426156618, 526126.4833966142, 526126.4833966147, 145964.3796153402], 
processed observation next is [0.0, 0.2608695652173913, 0.34074074074074073, 0.92, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.630223960353567, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1879023154987908, 0.18790231549879094, 0.2807007300295004], 
reward next is 0.7193, 
noisyNet noise sample is [array([-0.89552665], dtype=float32), 0.30174765]. 
=============================================
[2019-03-23 21:08:49,124] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3500, global step 55858: loss 0.0923
[2019-03-23 21:08:49,131] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3500, global step 55858: learning rate 0.0005
[2019-03-23 21:08:49,173] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3500, global step 55875: loss 0.2789
[2019-03-23 21:08:49,175] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3500, global step 55875: learning rate 0.0005
[2019-03-23 21:08:49,267] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3500, global step 55928: loss 0.2391
[2019-03-23 21:08:49,272] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3500, global step 55929: loss 0.3403
[2019-03-23 21:08:49,273] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3500, global step 55928: learning rate 0.0005
[2019-03-23 21:08:49,276] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3500, global step 55930: learning rate 0.0005
[2019-03-23 21:08:49,294] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3500, global step 55939: loss 0.0489
[2019-03-23 21:08:49,296] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3500, global step 55940: learning rate 0.0005
[2019-03-23 21:08:49,361] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3500, global step 55971: loss 0.0003
[2019-03-23 21:08:49,364] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3500, global step 55971: learning rate 0.0005
[2019-03-23 21:08:49,437] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3500, global step 55990: loss 0.0294
[2019-03-23 21:08:49,448] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3500, global step 55991: learning rate 0.0005
[2019-03-23 21:08:49,509] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3500, global step 56025: loss 0.1331
[2019-03-23 21:08:49,513] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3500, global step 56025: learning rate 0.0005
[2019-03-23 21:08:49,580] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3500, global step 56053: loss 0.1921
[2019-03-23 21:08:49,582] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3500, global step 56053: learning rate 0.0005
[2019-03-23 21:08:49,668] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3500, global step 56102: loss 0.0089
[2019-03-23 21:08:49,671] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3500, global step 56103: learning rate 0.0005
[2019-03-23 21:08:49,707] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3500, global step 56115: loss 0.0003
[2019-03-23 21:08:49,710] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3500, global step 56117: learning rate 0.0005
[2019-03-23 21:08:49,763] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3500, global step 56144: loss 0.0273
[2019-03-23 21:08:49,766] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3500, global step 56145: learning rate 0.0005
[2019-03-23 21:08:49,843] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3500, global step 56182: loss 0.1240
[2019-03-23 21:08:49,846] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3500, global step 56183: learning rate 0.0005
[2019-03-23 21:08:49,972] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3500, global step 56247: loss 0.0478
[2019-03-23 21:08:49,977] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3500, global step 56247: learning rate 0.0005
[2019-03-23 21:08:53,992] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.8512470e-16 8.2886752e-13 6.9117368e-13 2.7849437e-14], sum to 1.0000
[2019-03-23 21:08:53,999] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2378
[2019-03-23 21:08:54,004] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 777706.5778470929 W.
[2019-03-23 21:08:54,013] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.85, 89.5, 1.0, 2.0, 0.6678279781968054, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260425101879, 777706.5778470929, 777706.5778470929, 170942.7874631817], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2179800.0000, 
sim time next is 2180400.0000, 
raw observation next is [23.9, 89.33333333333333, 1.0, 2.0, 0.3406840540569381, 1.0, 1.0, 0.3406840540569381, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156297, 788077.020677976, 788077.020677976, 191060.649043313], 
processed observation next is [1.0, 0.21739130434782608, 0.4407407407407407, 0.8933333333333333, 1.0, 1.0, 0.2151000643534977, 1.0, 0.5, 0.2151000643534977, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288199229, 0.2814560788135628, 0.2814560788135628, 0.3674243250832942], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9642867], dtype=float32), -1.0938898]. 
=============================================
[2019-03-23 21:08:55,238] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 4.2031287e-15 8.1264775e-14 2.1708046e-13 6.1360980e-13], sum to 1.0000
[2019-03-23 21:08:55,243] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5556
[2019-03-23 21:08:55,249] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1475504.268738565 W.
[2019-03-23 21:08:55,255] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.63333333333333, 83.66666666666667, 1.0, 2.0, 0.6673218868559798, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426156618, 1475504.268738565, 1475504.268738565, 311394.8673357129], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2208000.0000, 
sim time next is 2208600.0000, 
raw observation next is [26.8, 83.0, 1.0, 2.0, 0.7005996847390702, 1.0, 1.0, 0.7005996847390702, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1597801.91064033, 1597801.91064033, 304392.3912327748], 
processed observation next is [1.0, 0.5652173913043478, 0.5481481481481482, 0.83, 1.0, 1.0, 0.6435710532607979, 1.0, 0.5, 0.6435710532607979, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5706435395144036, 0.5706435395144036, 0.5853699831399516], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3820004], dtype=float32), -0.8166895]. 
=============================================
[2019-03-23 21:08:58,068] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 4.1815430e-28 5.2299762e-24 3.0035061e-24 7.9054867e-25], sum to 1.0000
[2019-03-23 21:08:58,077] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1107
[2019-03-23 21:08:58,269] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.05, 97.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8227967653444525, 6.911200000000001, 6.9112, 121.9260426156618, 608879.8050069142, 608879.8050069137, 164143.7942809033], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2257800.0000, 
sim time next is 2258400.0000, 
raw observation next is [21.9, 97.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8004461918889932, 6.911200000000001, 6.9112, 121.9260426156618, 593336.343823263, 593336.3438232625, 160925.8028645462], 
processed observation next is [1.0, 0.13043478260869565, 0.36666666666666664, 0.9766666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7505577398612414, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21190583707973676, 0.2119058370797366, 0.309472697816435], 
reward next is 0.6905, 
noisyNet noise sample is [array([0.3693417], dtype=float32), 1.9819773]. 
=============================================
[2019-03-23 21:08:58,604] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 6.4501916e-36 4.5829816e-31 3.6031070e-28 5.0900339e-31], sum to 1.0000
[2019-03-23 21:08:58,616] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6201
[2019-03-23 21:08:58,770] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.4, 95.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6775388133674536, 6.911200000000001, 6.9112, 121.9260426156618, 506299.8214316124, 506299.821431612, 142109.5647297219], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2266200.0000, 
sim time next is 2266800.0000, 
raw observation next is [20.4, 95.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6781874902623505, 6.911200000000001, 6.9112, 121.9260426156618, 506789.5223158078, 506789.5223158073, 142229.2880852231], 
processed observation next is [1.0, 0.21739130434782608, 0.31111111111111106, 0.9566666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.597734362827938, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18099625796993135, 0.18099625796993118, 0.2735178617023521], 
reward next is 0.7265, 
noisyNet noise sample is [array([-0.51316416], dtype=float32), 0.2732219]. 
=============================================
[2019-03-23 21:09:05,411] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4000, global step 63725: loss 2.7584
[2019-03-23 21:09:05,413] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4000, global step 63725: learning rate 0.0005
[2019-03-23 21:09:05,520] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4000, global step 63777: loss 2.5509
[2019-03-23 21:09:05,521] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4000, global step 63777: learning rate 0.0005
[2019-03-23 21:09:05,697] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4000, global step 63863: loss 2.4457
[2019-03-23 21:09:05,699] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4000, global step 63863: learning rate 0.0005
[2019-03-23 21:09:05,735] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4000, global step 63881: loss 2.2574
[2019-03-23 21:09:05,739] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4000, global step 63882: learning rate 0.0005
[2019-03-23 21:09:05,807] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4000, global step 63918: loss 2.2218
[2019-03-23 21:09:05,813] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4000, global step 63919: learning rate 0.0005
[2019-03-23 21:09:05,831] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4000, global step 63931: loss 2.1067
[2019-03-23 21:09:05,836] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4000, global step 63933: learning rate 0.0005
[2019-03-23 21:09:05,872] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4000, global step 63948: loss 1.7885
[2019-03-23 21:09:05,874] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4000, global step 63948: learning rate 0.0005
[2019-03-23 21:09:05,911] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4000, global step 63968: loss 1.7655
[2019-03-23 21:09:05,917] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4000, global step 63969: learning rate 0.0005
[2019-03-23 21:09:05,959] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4000, global step 63993: loss 1.4998
[2019-03-23 21:09:05,961] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4000, global step 63993: learning rate 0.0005
[2019-03-23 21:09:05,964] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4000, global step 63995: loss 1.5613
[2019-03-23 21:09:05,966] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4000, global step 63996: learning rate 0.0005
[2019-03-23 21:09:06,015] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4000, global step 64017: loss 1.3800
[2019-03-23 21:09:06,018] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4000, global step 64019: learning rate 0.0005
[2019-03-23 21:09:06,099] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4000, global step 64059: loss 1.0978
[2019-03-23 21:09:06,105] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4000, global step 64062: learning rate 0.0005
[2019-03-23 21:09:06,196] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4000, global step 64108: loss 0.5948
[2019-03-23 21:09:06,199] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4000, global step 64109: learning rate 0.0005
[2019-03-23 21:09:06,270] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4000, global step 64146: loss 0.3818
[2019-03-23 21:09:06,272] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4000, global step 64146: learning rate 0.0005
[2019-03-23 21:09:06,466] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4000, global step 64244: loss 0.0208
[2019-03-23 21:09:06,468] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4000, global step 64245: learning rate 0.0005
[2019-03-23 21:09:06,555] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4000, global step 64288: loss 0.0011
[2019-03-23 21:09:06,560] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4000, global step 64288: learning rate 0.0005
[2019-03-23 21:09:07,942] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.2456223e-37 3.8004941e-33 2.1719847e-32 3.7522929e-33], sum to 1.0000
[2019-03-23 21:09:07,950] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8320
[2019-03-23 21:09:07,954] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.76666666666667, 76.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4961306998076809, 6.9112, 6.9112, 121.9260426156618, 355137.9412800932, 355137.9412800932, 115128.6557659573], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2434800.0000, 
sim time next is 2435400.0000, 
raw observation next is [18.6, 77.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5074805563675011, 6.9112, 6.9112, 121.9260426156618, 363138.2944253299, 363138.2944253299, 115952.3784263481], 
processed observation next is [1.0, 0.17391304347826086, 0.2444444444444445, 0.775, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.38435069545937633, 0.0, 0.0, 0.8094621288201359, 0.12969224800904638, 0.12969224800904638, 0.22298534312759252], 
reward next is 0.7770, 
noisyNet noise sample is [array([0.6780849], dtype=float32), -0.20234731]. 
=============================================
[2019-03-23 21:09:08,091] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 5.7415589e-29 2.6690280e-26 1.3215225e-25 2.9792983e-27], sum to 1.0000
[2019-03-23 21:09:08,097] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7070
[2019-03-23 21:09:08,101] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.1, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5460815189181336, 6.9112, 6.9112, 121.9260426156618, 390277.3472577312, 390277.3472577312, 118806.5275654492], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2437200.0000, 
sim time next is 2437800.0000, 
raw observation next is [18.66666666666667, 78.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5529490842318389, 6.911200000000001, 6.9112, 121.9260426156618, 396365.0269854174, 396365.0269854169, 119745.2406756504], 
processed observation next is [1.0, 0.21739130434782608, 0.24691358024691376, 0.7833333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.44118635528979855, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14155893820907764, 0.14155893820907747, 0.2302793089916354], 
reward next is 0.7697, 
noisyNet noise sample is [array([-0.58067065], dtype=float32), 1.2854121]. 
=============================================
[2019-03-23 21:09:08,310] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 5.5198709e-31 9.3442866e-28 8.8833519e-27 1.2212612e-27], sum to 1.0000
[2019-03-23 21:09:08,321] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4407
[2019-03-23 21:09:08,326] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.9, 52.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6351524021427818, 6.9112, 6.9112, 121.9260426156618, 469644.5156403034, 469644.5156403034, 132605.529116896], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2444400.0000, 
sim time next is 2445000.0000, 
raw observation next is [25.46666666666667, 50.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6506966513105453, 6.911200000000001, 6.9112, 121.9260426156618, 482000.0335909771, 482000.0335909767, 134620.0230551955], 
processed observation next is [1.0, 0.30434782608695654, 0.4987654320987655, 0.5033333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5633708141381816, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17214286913963467, 0.17214286913963453, 0.2588846597215298], 
reward next is 0.7411, 
noisyNet noise sample is [array([0.8161467], dtype=float32), 1.8809091]. 
=============================================
[2019-03-23 21:09:08,344] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[64.64305]
 [64.64305]
 [64.64305]
 [64.64305]
 [64.64305]], R is [[64.73773956]
 [64.83535004]
 [64.9380188 ]
 [65.04187012]
 [65.14520264]].
[2019-03-23 21:09:09,542] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 7.5172639e-19 6.3751613e-15 2.7752504e-14 1.2609439e-16], sum to 1.0000
[2019-03-23 21:09:09,548] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1994
[2019-03-23 21:09:09,554] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1602592.024083158 W.
[2019-03-23 21:09:09,559] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [34.76666666666667, 23.0, 1.0, 2.0, 0.4481886807176169, 1.0, 2.0, 0.4481886807176169, 1.0, 1.0, 0.7209878749560072, 6.911199999999999, 6.9112, 121.94756008, 1602592.024083158, 1602592.024083159, 318643.2182977824], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2468400.0000, 
sim time next is 2469000.0000, 
raw observation next is [34.88333333333333, 23.0, 1.0, 2.0, 0.4503111864153179, 1.0, 2.0, 0.4503111864153179, 1.0, 2.0, 0.7232861568107006, 6.911200000000001, 6.9112, 121.94756008, 1604605.196471652, 1604605.196471651, 319708.9399431993], 
processed observation next is [1.0, 0.5652173913043478, 0.8475308641975309, 0.23, 1.0, 1.0, 0.3456085552563309, 1.0, 1.0, 0.3456085552563309, 1.0, 1.0, 0.6541076960133757, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5730732844541614, 0.5730732844541611, 0.6148248845061525], 
reward next is 0.3852, 
noisyNet noise sample is [array([0.81653], dtype=float32), -0.4800711]. 
=============================================
[2019-03-23 21:09:09,574] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[32.349293]
 [32.349293]
 [32.349293]
 [32.349293]
 [32.349293]], R is [[32.4109726 ]
 [32.47409058]
 [32.54491806]
 [32.21947098]
 [31.89727592]].
[2019-03-23 21:09:10,086] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.4838741e-13 6.0399212e-12 1.4167216e-10 1.0642641e-13], sum to 1.0000
[2019-03-23 21:09:10,093] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9693
[2019-03-23 21:09:10,100] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1442555.393218876 W.
[2019-03-23 21:09:10,265] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [34.8, 23.0, 1.0, 2.0, 0.4035963845277038, 1.0, 2.0, 0.4035963845277038, 1.0, 2.0, 0.6491617607563906, 6.9112, 6.9112, 121.94756008, 1442555.393218876, 1442555.393218876, 298417.1098404612], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2471400.0000, 
sim time next is 2472000.0000, 
raw observation next is [34.73333333333333, 23.0, 1.0, 2.0, 0.4049895992307578, 1.0, 2.0, 0.4049895992307578, 1.0, 2.0, 0.6518193689386731, 6.9112, 6.9112, 121.94756008, 1449509.737961176, 1449509.737961176, 298999.4022112273], 
processed observation next is [1.0, 0.6086956521739131, 0.8419753086419751, 0.23, 1.0, 1.0, 0.2916542847985212, 1.0, 1.0, 0.2916542847985212, 1.0, 1.0, 0.5647742111733414, 0.0, 0.0, 0.8096049824067558, 0.5176820492718486, 0.5176820492718486, 0.5749988504062064], 
reward next is 0.4250, 
noisyNet noise sample is [array([-0.64722764], dtype=float32), 0.10101343]. 
=============================================
[2019-03-23 21:09:10,281] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[27.164124]
 [27.164124]
 [27.164124]
 [27.164124]
 [27.164124]], R is [[27.3174839 ]
 [27.47043037]
 [27.6041584 ]
 [27.32811737]
 [27.43894386]].
[2019-03-23 21:09:10,317] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 8.2429890e-16 2.7437617e-13 6.9185915e-14 8.3931039e-16], sum to 1.0000
[2019-03-23 21:09:10,325] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2411
[2019-03-23 21:09:10,331] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1483123.43781785 W.
[2019-03-23 21:09:10,335] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [34.45, 23.5, 1.0, 2.0, 0.6313890126466063, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9567919537918742, 6.911199999999999, 6.9112, 121.9260426156618, 1483123.43781785, 1483123.43781785, 293600.6946524629], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2475000.0000, 
sim time next is 2475600.0000, 
raw observation next is [34.4, 23.66666666666667, 1.0, 2.0, 0.4266276669627878, 1.0, 1.0, 0.4266276669627878, 1.0, 2.0, 0.6878770322671497, 6.911200000000001, 6.9112, 121.94756008, 1532491.898958962, 1532491.898958962, 308601.6902902023], 
processed observation next is [1.0, 0.6521739130434783, 0.8296296296296296, 0.23666666666666672, 1.0, 1.0, 0.3174138892414141, 1.0, 0.5, 0.3174138892414141, 1.0, 1.0, 0.6098462903339371, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5473185353424864, 0.5473185353424864, 0.5934647890196199], 
reward next is 0.4065, 
noisyNet noise sample is [array([-1.1306344], dtype=float32), -0.27029377]. 
=============================================
[2019-03-23 21:09:10,559] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.0981332e-17 2.1675226e-14 4.4419026e-12 1.5509462e-16], sum to 1.0000
[2019-03-23 21:09:10,569] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4596
[2019-03-23 21:09:10,574] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1442588.368874079 W.
[2019-03-23 21:09:10,579] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [34.8, 23.0, 1.0, 2.0, 0.4021852929386448, 1.0, 1.0, 0.4021852929386448, 1.0, 2.0, 0.6479983111110625, 6.9112, 6.9112, 121.94756008, 1442588.368874079, 1442588.368874079, 297705.2743558219], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2471400.0000, 
sim time next is 2472000.0000, 
raw observation next is [34.73333333333333, 23.0, 1.0, 2.0, 0.4048551378461436, 1.0, 2.0, 0.4048551378461436, 1.0, 2.0, 0.6517071506588181, 6.9112, 6.9112, 121.94756008, 1449509.748556507, 1449509.748556507, 298931.6037541348], 
processed observation next is [1.0, 0.6086956521739131, 0.8419753086419751, 0.23, 1.0, 1.0, 0.2914942117215995, 1.0, 1.0, 0.2914942117215995, 1.0, 1.0, 0.5646339383235226, 0.0, 0.0, 0.8096049824067558, 0.5176820530558954, 0.5176820530558954, 0.5748684687579515], 
reward next is 0.4251, 
noisyNet noise sample is [array([0.425811], dtype=float32), 1.771266]. 
=============================================
[2019-03-23 21:09:10,598] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[32.757942]
 [32.757942]
 [32.757942]
 [32.757942]
 [32.757942]], R is [[32.85549545]
 [32.52693939]
 [32.62472534]
 [32.72644424]
 [32.77576828]].
[2019-03-23 21:09:12,023] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 3.7047756e-32 2.0623224e-27 2.6554310e-25 8.7685642e-30], sum to 1.0000
[2019-03-23 21:09:12,031] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5246
[2019-03-23 21:09:12,041] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.76666666666667, 42.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.627476894559512, 6.911199999999999, 6.9112, 121.9260426156618, 466986.9778884696, 466986.97788847, 133970.3500885312], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2499600.0000, 
sim time next is 2500200.0000, 
raw observation next is [27.6, 43.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6275055303695084, 6.9112, 6.9112, 121.9260426156618, 467086.0185037118, 467086.0185037118, 134041.8672451213], 
processed observation next is [1.0, 0.9565217391304348, 0.5777777777777778, 0.435, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5343819129618854, 0.0, 0.0, 0.8094621288201359, 0.16681643517989705, 0.16681643517989705, 0.2577728216252333], 
reward next is 0.7422, 
noisyNet noise sample is [array([1.9865581], dtype=float32), 1.4657593]. 
=============================================
[2019-03-23 21:09:14,588] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 6.7429678e-16 1.2670502e-13 3.4396190e-12 5.2328665e-14], sum to 1.0000
[2019-03-23 21:09:14,596] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6994
[2019-03-23 21:09:14,596] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1658136.367533937 W.
[2019-03-23 21:09:14,603] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.5, 30.0, 1.0, 2.0, 0.6999981916542791, 1.0, 2.0, 0.6999981916542791, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1658136.367533937, 1658136.367533938, 307068.1917604607], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2554200.0000, 
sim time next is 2554800.0000, 
raw observation next is [33.6, 30.0, 1.0, 2.0, 0.7315907756549672, 1.0, 2.0, 0.7315907756549672, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1732357.282835861, 1732357.282835861, 319338.2354427878], 
processed observation next is [1.0, 0.5652173913043478, 0.8, 0.3, 1.0, 1.0, 0.6804652091130562, 1.0, 1.0, 0.6804652091130562, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6186990295842361, 0.6186990295842361, 0.6141119912361304], 
reward next is 0.3859, 
noisyNet noise sample is [array([0.12477142], dtype=float32), -0.06875322]. 
=============================================
[2019-03-23 21:09:16,623] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.1069304e-27 2.6523446e-24 9.6493292e-21 6.9132201e-26], sum to 1.0000
[2019-03-23 21:09:16,631] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5632
[2019-03-23 21:09:16,640] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.6, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7685365422880568, 6.911199999999999, 6.9112, 121.9260426156618, 572984.2352414648, 572984.2352414653, 155087.1769102272], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2595600.0000, 
sim time next is 2596200.0000, 
raw observation next is [22.45, 86.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.766171456250902, 6.9112, 6.9112, 121.9260426156618, 571340.7734158846, 571340.7734158846, 154696.4570655738], 
processed observation next is [0.0, 0.043478260869565216, 0.387037037037037, 0.8683333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7077143203136274, 0.0, 0.0, 0.8094621288201359, 0.20405027621995878, 0.20405027621995878, 0.29749318666456503], 
reward next is 0.7025, 
noisyNet noise sample is [array([-0.9148181], dtype=float32), -1.0999962]. 
=============================================
[2019-03-23 21:09:17,587] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 7.1249174e-34 4.4476457e-29 1.6585156e-25 3.1697466e-31], sum to 1.0000
[2019-03-23 21:09:17,594] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2633
[2019-03-23 21:09:17,599] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.45, 98.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7252194078433776, 6.9112, 6.9112, 121.9260426156618, 541821.1949175097, 541821.1949175097, 148417.4606958439], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2611800.0000, 
sim time next is 2612400.0000, 
raw observation next is [20.4, 99.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7261191552316664, 6.9112, 6.9112, 121.9260426156618, 542487.2112780936, 542487.2112780936, 148537.9979952934], 
processed observation next is [0.0, 0.21739130434782608, 0.31111111111111106, 0.99, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.657648944039583, 0.0, 0.0, 0.8094621288201359, 0.19374543259931915, 0.19374543259931915, 0.285649996144795], 
reward next is 0.7144, 
noisyNet noise sample is [array([-1.1782957], dtype=float32), 0.9282443]. 
=============================================
[2019-03-23 21:09:21,748] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4500, global step 71702: loss 0.0096
[2019-03-23 21:09:21,751] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4500, global step 71703: learning rate 0.0005
[2019-03-23 21:09:21,813] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4500, global step 71736: loss 0.0217
[2019-03-23 21:09:21,814] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4500, global step 71736: learning rate 0.0005
[2019-03-23 21:09:21,882] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4500, global step 71768: loss 0.0120
[2019-03-23 21:09:21,886] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4500, global step 71769: learning rate 0.0005
[2019-03-23 21:09:22,002] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4500, global step 71826: loss 0.0278
[2019-03-23 21:09:22,004] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4500, global step 71826: learning rate 0.0005
[2019-03-23 21:09:22,178] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4500, global step 71913: loss 0.2122
[2019-03-23 21:09:22,179] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4500, global step 71913: learning rate 0.0005
[2019-03-23 21:09:22,258] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4500, global step 71954: loss 0.1343
[2019-03-23 21:09:22,260] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4500, global step 71955: learning rate 0.0005
[2019-03-23 21:09:22,277] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4500, global step 71964: loss 0.1434
[2019-03-23 21:09:22,278] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4500, global step 71964: learning rate 0.0005
[2019-03-23 21:09:22,288] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4500, global step 71969: loss 0.0469
[2019-03-23 21:09:22,291] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4500, global step 71970: learning rate 0.0005
[2019-03-23 21:09:22,316] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4500, global step 71980: loss 0.0309
[2019-03-23 21:09:22,319] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4500, global step 71981: learning rate 0.0005
[2019-03-23 21:09:22,415] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4500, global step 72031: loss 0.0180
[2019-03-23 21:09:22,415] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4500, global step 72031: learning rate 0.0005
[2019-03-23 21:09:22,484] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4500, global step 72061: loss 0.0833
[2019-03-23 21:09:22,487] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4500, global step 72061: learning rate 0.0005
[2019-03-23 21:09:22,554] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4500, global step 72097: loss 0.0559
[2019-03-23 21:09:22,557] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4500, global step 72099: learning rate 0.0005
[2019-03-23 21:09:22,611] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4500, global step 72127: loss 0.0088
[2019-03-23 21:09:22,616] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4500, global step 72128: loss 0.0008
[2019-03-23 21:09:22,616] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4500, global step 72128: learning rate 0.0005
[2019-03-23 21:09:22,618] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4500, global step 72129: learning rate 0.0005
[2019-03-23 21:09:22,844] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4500, global step 72238: loss 0.1288
[2019-03-23 21:09:22,845] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4500, global step 72238: learning rate 0.0005
[2019-03-23 21:09:23,005] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4500, global step 72317: loss 0.0096
[2019-03-23 21:09:23,006] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4500, global step 72318: learning rate 0.0005
[2019-03-23 21:09:27,399] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 9.9275504e-17 2.4034094e-15 1.3227600e-11 3.6563117e-16], sum to 1.0000
[2019-03-23 21:09:27,403] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1892
[2019-03-23 21:09:27,404] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 737496.3467030433 W.
[2019-03-23 21:09:27,409] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.33333333333333, 94.0, 1.0, 2.0, 0.2143521787880373, 1.0, 1.0, 0.2143521787880373, 1.0, 2.0, 0.3413967140192287, 6.9112, 6.9112, 121.94756008, 737496.3467030433, 737496.3467030433, 225351.9768199435], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2781600.0000, 
sim time next is 2782200.0000, 
raw observation next is [23.16666666666667, 94.0, 1.0, 2.0, 0.3104930904166261, 0.0, 1.0, 0.0, 1.0, 2.0, 0.4953345340747253, 6.911199999999999, 6.9112, 121.9260426156618, 720689.4931743705, 720689.4931743708, 197803.0240471147], 
processed observation next is [1.0, 0.17391304347826086, 0.4135802469135804, 0.94, 1.0, 1.0, 0.17915844097217393, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.36916816759340654, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2573891047051323, 0.25738910470513243, 0.380390430859836], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8939449], dtype=float32), 0.5329046]. 
=============================================
[2019-03-23 21:09:28,483] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 21:09:28,487] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:09:28,487] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:09:28,487] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:09:28,488] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:09:28,489] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:09:28,492] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:09:28,492] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:09:28,492] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:09:28,493] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:09:28,496] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:09:28,502] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run4
[2019-03-23 21:09:28,526] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run4
[2019-03-23 21:09:28,527] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run4
[2019-03-23 21:09:28,573] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run4
[2019-03-23 21:09:28,574] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run4
[2019-03-23 21:10:33,320] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.03970693], dtype=float32), 0.09092871]
[2019-03-23 21:10:33,321] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.85, 90.0, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 7.055254569430295, 6.9112, 121.9254551710516, 1951922.568809627, 1878154.109231141, 383622.1205802971]
[2019-03-23 21:10:33,321] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:10:33,324] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 8.4918947e-12 6.4727529e-11 2.9037692e-11 1.0035311e-11], sampled 0.2389177862602998
[2019-03-23 21:10:33,325] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1951922.568809627 W.
[2019-03-23 21:10:59,995] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.03970693], dtype=float32), 0.09092871]
[2019-03-23 21:10:59,996] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.08333333333333, 48.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5008557900368865, 6.911199999999999, 6.9112, 121.9260426156618, 357752.3803121746, 357752.380312175, 115230.3820630468]
[2019-03-23 21:10:59,997] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:11:00,002] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 8.4918947e-12 6.4727529e-11 2.9037692e-11 1.0035311e-11], sampled 0.37018832616552055
[2019-03-23 21:11:07,003] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-23 21:11:07,091] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-23 21:11:07,187] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-23 21:11:07,215] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-23 21:11:07,475] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-23 21:11:08,490] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 75000, evaluation results [75000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-23 21:11:14,469] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.9979001e-01 1.8698281e-04 6.4281716e-07 1.5622098e-05 6.8183549e-06], sum to 1.0000
[2019-03-23 21:11:14,476] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9476
[2019-03-23 21:11:14,486] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 781473.846202098 W.
[2019-03-23 21:11:14,491] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.16666666666667, 88.16666666666667, 1.0, 2.0, 0.3428404111190885, 1.0, 2.0, 0.3428404111190885, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 781473.846202098, 781473.8462020984, 191059.5007171032], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2919000.0000, 
sim time next is 2919600.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.228421954413251, 1.0, 2.0, 0.228421954413251, 1.0, 1.0, 0.3636551906095944, 6.911199999999999, 6.9112, 121.94756008, 781000.6042195705, 781000.604219571, 230104.15293114], 
processed observation next is [1.0, 0.8260869565217391, 0.5185185185185185, 0.89, 1.0, 1.0, 0.08145470763482261, 1.0, 1.0, 0.08145470763482261, 1.0, 0.5, 0.20456898826199296, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2789287872212752, 0.27892878722127534, 0.4425079864060385], 
reward next is 0.5575, 
noisyNet noise sample is [array([-1.0002131], dtype=float32), 0.19258751]. 
=============================================
[2019-03-23 21:11:16,186] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.31679392e-03 9.94176030e-01 1.45419326e-05 1.40959355e-05
 4.78612317e-04], sum to 1.0000
[2019-03-23 21:11:16,193] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7845
[2019-03-23 21:11:16,197] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.7563079578788232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 862013.2089937247, 862013.2089937237, 187074.1400492771], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2950800.0000, 
sim time next is 2951400.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.7465314062799003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 850864.0540189222, 850864.0540189222, 185136.5179772108], 
processed observation next is [1.0, 0.13043478260869565, 0.48148148148148145, 0.94, 1.0, 1.0, 0.6982516741427385, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3038800192924722, 0.3038800192924722, 0.35603176534079], 
reward next is 0.6440, 
noisyNet noise sample is [array([0.20570941], dtype=float32), 0.26744705]. 
=============================================
[2019-03-23 21:11:17,047] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.5715788e-06 9.9999738e-01 5.8741423e-12 6.3470458e-11 3.6861656e-09], sum to 1.0000
[2019-03-23 21:11:17,055] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8452
[2019-03-23 21:11:17,060] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.95, 93.33333333333334, 1.0, 2.0, 0.6718633060765714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 765718.0883946986, 765718.0883946986, 170883.5531994498], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2958600.0000, 
sim time next is 2959200.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.6771012031888323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 771690.6894540576, 771690.6894540571, 171852.5039159501], 
processed observation next is [1.0, 0.2608695652173913, 0.48148148148148145, 0.94, 1.0, 1.0, 0.6155966704628956, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2756038176621634, 0.27560381766216324, 0.3304855844537502], 
reward next is 0.6695, 
noisyNet noise sample is [array([1.2821208], dtype=float32), 0.64880455]. 
=============================================
[2019-03-23 21:11:18,217] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5000, global step 79765: loss 50.2454
[2019-03-23 21:11:18,220] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5000, global step 79765: learning rate 0.0005
[2019-03-23 21:11:18,226] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5000, global step 79767: loss -4.0747
[2019-03-23 21:11:18,352] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5000, global step 79767: learning rate 0.0005
[2019-03-23 21:11:18,584] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5000, global step 79831: loss 59.4711
[2019-03-23 21:11:18,585] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5000, global step 79832: learning rate 0.0005
[2019-03-23 21:11:18,786] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5000, global step 79876: loss 22.1839
[2019-03-23 21:11:18,787] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5000, global step 79876: learning rate 0.0005
[2019-03-23 21:11:18,934] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5000, global step 79894: loss 5.6040
[2019-03-23 21:11:18,939] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5000, global step 79894: learning rate 0.0005
[2019-03-23 21:11:19,093] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5000, global step 79915: loss 51.1501
[2019-03-23 21:11:19,095] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5000, global step 79915: learning rate 0.0005
[2019-03-23 21:11:19,292] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5000, global step 79959: loss 9.4315
[2019-03-23 21:11:19,297] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5000, global step 79959: learning rate 0.0005
[2019-03-23 21:11:19,473] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5000, global step 79990: loss 54.5815
[2019-03-23 21:11:19,474] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5000, global step 79990: learning rate 0.0005
[2019-03-23 21:11:19,622] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5000, global step 80009: loss -60.3225
[2019-03-23 21:11:19,624] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5000, global step 80010: loss 63.3822
[2019-03-23 21:11:19,626] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5000, global step 80010: learning rate 0.0005
[2019-03-23 21:11:19,629] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5000, global step 80010: learning rate 0.0005
[2019-03-23 21:11:19,905] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5000, global step 80033: loss -36.9877
[2019-03-23 21:11:19,906] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5000, global step 80033: learning rate 0.0005
[2019-03-23 21:11:20,050] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5000, global step 80047: loss -43.5657
[2019-03-23 21:11:20,054] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5000, global step 80048: learning rate 0.0005
[2019-03-23 21:11:20,196] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5000, global step 80069: loss 40.4366
[2019-03-23 21:11:20,201] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5000, global step 80070: learning rate 0.0005
[2019-03-23 21:11:20,339] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5000, global step 80089: loss 40.9795
[2019-03-23 21:11:20,345] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5000, global step 80090: learning rate 0.0005
[2019-03-23 21:11:20,728] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5000, global step 80223: loss -30.8279
[2019-03-23 21:11:20,730] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5000, global step 80225: learning rate 0.0005
[2019-03-23 21:11:21,018] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5000, global step 80312: loss -43.3786
[2019-03-23 21:11:21,021] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5000, global step 80312: learning rate 0.0005
[2019-03-23 21:11:28,542] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.1259162e-12 1.0000000e+00 1.1265426e-20 9.4804713e-21 2.1196107e-22], sum to 1.0000
[2019-03-23 21:11:28,547] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7418
[2019-03-23 21:11:28,553] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1742037.096528773 W.
[2019-03-23 21:11:28,563] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.26666666666667, 35.66666666666667, 1.0, 2.0, 0.8663575015816505, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9674203034176048, 6.911199999999999, 6.9112, 121.9260426156618, 1742037.096528773, 1742037.096528773, 343908.1832798613], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3148800.0000, 
sim time next is 3149400.0000, 
raw observation next is [32.58333333333334, 33.83333333333334, 1.0, 2.0, 0.4963529490124994, 1.0, 1.0, 0.4963529490124994, 1.0, 2.0, 0.7923654123075917, 6.9112, 6.9112, 121.94756008, 1734886.303649752, 1734886.303649752, 341916.3297525669], 
processed observation next is [1.0, 0.43478260869565216, 0.7623456790123461, 0.33833333333333343, 1.0, 1.0, 0.4004201773958326, 1.0, 0.5, 0.4004201773958326, 1.0, 1.0, 0.7404567653844896, 0.0, 0.0, 0.8096049824067558, 0.6196022513034828, 0.6196022513034828, 0.6575314033703209], 
reward next is 0.3425, 
noisyNet noise sample is [array([2.021401], dtype=float32), 0.40201285]. 
=============================================
[2019-03-23 21:11:32,765] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.8385584e-16 1.0000000e+00 8.0332580e-25 5.6245723e-25 2.6793722e-26], sum to 1.0000
[2019-03-23 21:11:32,770] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6522
[2019-03-23 21:11:32,775] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 81.33333333333334, 1.0, 2.0, 0.4731051477948013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 571240.9294934982, 571240.9294934982, 138975.7482786729], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3219600.0000, 
sim time next is 3220200.0000, 
raw observation next is [23.5, 80.5, 1.0, 2.0, 0.4749967716696988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 573053.8262096572, 573053.8262096572, 139249.8188188967], 
processed observation next is [0.0, 0.2608695652173913, 0.42592592592592593, 0.805, 1.0, 1.0, 0.3749961567496414, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20466208078916331, 0.20466208078916331, 0.26778811311326284], 
reward next is 0.7322, 
noisyNet noise sample is [array([0.597396], dtype=float32), 0.41890675]. 
=============================================
[2019-03-23 21:11:36,274] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5500, global step 87728: loss 0.0800
[2019-03-23 21:11:36,277] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5500, global step 87729: learning rate 0.0005
[2019-03-23 21:11:36,382] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5500, global step 87786: loss 0.0150
[2019-03-23 21:11:36,383] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5500, global step 87786: learning rate 0.0005
[2019-03-23 21:11:36,394] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5500, global step 87788: loss 0.0013
[2019-03-23 21:11:36,396] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5500, global step 87788: learning rate 0.0005
[2019-03-23 21:11:36,450] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5500, global step 87813: loss 0.0443
[2019-03-23 21:11:36,453] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5500, global step 87813: learning rate 0.0005
[2019-03-23 21:11:36,587] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5500, global step 87883: loss 0.1507
[2019-03-23 21:11:36,589] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5500, global step 87883: learning rate 0.0005
[2019-03-23 21:11:36,690] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5500, global step 87933: loss 0.0065
[2019-03-23 21:11:36,692] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5500, global step 87933: learning rate 0.0005
[2019-03-23 21:11:36,757] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5500, global step 87965: loss 0.0019
[2019-03-23 21:11:36,759] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5500, global step 87966: learning rate 0.0005
[2019-03-23 21:11:36,785] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5500, global step 87979: loss 0.0044
[2019-03-23 21:11:36,786] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5500, global step 87979: learning rate 0.0005
[2019-03-23 21:11:36,811] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5500, global step 87991: loss 0.0326
[2019-03-23 21:11:36,812] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5500, global step 87991: learning rate 0.0005
[2019-03-23 21:11:36,821] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5500, global step 87991: loss 0.1572
[2019-03-23 21:11:36,822] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5500, global step 87991: learning rate 0.0005
[2019-03-23 21:11:36,932] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5500, global step 88050: loss 0.1426
[2019-03-23 21:11:36,937] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5500, global step 88050: learning rate 0.0005
[2019-03-23 21:11:36,982] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5500, global step 88073: loss 0.0006
[2019-03-23 21:11:36,986] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5500, global step 88074: learning rate 0.0005
[2019-03-23 21:11:37,056] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5500, global step 88111: loss 0.0013
[2019-03-23 21:11:37,057] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5500, global step 88111: learning rate 0.0005
[2019-03-23 21:11:37,131] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5500, global step 88146: loss 0.0812
[2019-03-23 21:11:37,135] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5500, global step 88146: learning rate 0.0005
[2019-03-23 21:11:37,213] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5500, global step 88185: loss 0.1491
[2019-03-23 21:11:37,218] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5500, global step 88187: learning rate 0.0005
[2019-03-23 21:11:37,618] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5500, global step 88388: loss 0.0004
[2019-03-23 21:11:37,622] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5500, global step 88389: learning rate 0.0005
[2019-03-23 21:11:52,644] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6000, global step 95762: loss -56.1635
[2019-03-23 21:11:52,653] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6000, global step 95762: learning rate 0.0005
[2019-03-23 21:11:52,658] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6000, global step 95768: loss -86.3594
[2019-03-23 21:11:52,660] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6000, global step 95768: learning rate 0.0005
[2019-03-23 21:11:52,794] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6000, global step 95835: loss 29.3145
[2019-03-23 21:11:52,795] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6000, global step 95836: learning rate 0.0005
[2019-03-23 21:11:52,796] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6000, global step 95836: loss -34.1776
[2019-03-23 21:11:52,800] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6000, global step 95837: learning rate 0.0005
[2019-03-23 21:11:52,901] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6000, global step 95881: loss 18.2927
[2019-03-23 21:11:52,902] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6000, global step 95882: learning rate 0.0005
[2019-03-23 21:11:52,913] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.2652329e-09 1.0000000e+00 5.5132628e-16 3.3339278e-15 4.3585391e-16], sum to 1.0000
[2019-03-23 21:11:52,918] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3172
[2019-03-23 21:11:52,928] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1376664.807575917 W.
[2019-03-23 21:11:52,931] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6000, global step 95897: loss 12.5582
[2019-03-23 21:11:52,934] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6000, global step 95899: learning rate 0.0005
[2019-03-23 21:11:52,938] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.05, 81.16666666666667, 1.0, 2.0, 0.4024815865146446, 1.0, 2.0, 0.4024815865146446, 1.0, 1.0, 0.6407637936414762, 6.911200000000001, 6.9112, 121.94756008, 1376664.807575917, 1376664.807575916, 298170.9130415566], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3595800.0000, 
sim time next is 3596400.0000, 
raw observation next is [25.0, 83.0, 1.0, 2.0, 0.6219808192862519, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9904020567100434, 6.911199999999999, 6.9112, 121.9260426156618, 1423259.766763049, 1423259.766763049, 302444.640518357], 
processed observation next is [1.0, 0.6521739130434783, 0.48148148148148145, 0.83, 1.0, 1.0, 0.5499771658169665, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9880025708875542, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5083070595582317, 0.5083070595582317, 0.581624308689148], 
reward next is 0.4184, 
noisyNet noise sample is [array([0.66017336], dtype=float32), -0.3000799]. 
=============================================
[2019-03-23 21:11:53,142] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6000, global step 95998: loss 14.7657
[2019-03-23 21:11:53,146] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6000, global step 95999: learning rate 0.0005
[2019-03-23 21:11:53,153] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6000, global step 96000: loss -9.8915
[2019-03-23 21:11:53,155] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6000, global step 96000: learning rate 0.0005
[2019-03-23 21:11:53,204] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6000, global step 96025: loss 37.0247
[2019-03-23 21:11:53,206] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6000, global step 96025: loss 0.3655
[2019-03-23 21:11:53,207] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6000, global step 96025: learning rate 0.0005
[2019-03-23 21:11:53,209] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6000, global step 96025: learning rate 0.0005
[2019-03-23 21:11:53,226] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6000, global step 96039: loss -40.0067
[2019-03-23 21:11:53,227] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6000, global step 96039: learning rate 0.0005
[2019-03-23 21:11:53,315] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6000, global step 96084: loss -5.4369
[2019-03-23 21:11:53,316] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6000, global step 96084: learning rate 0.0005
[2019-03-23 21:11:53,508] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6000, global step 96179: loss -16.4121
[2019-03-23 21:11:53,510] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6000, global step 96179: learning rate 0.0005
[2019-03-23 21:11:53,532] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6000, global step 96189: loss -9.4767
[2019-03-23 21:11:53,532] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6000, global step 96189: loss 32.2412
[2019-03-23 21:11:53,534] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6000, global step 96189: learning rate 0.0005
[2019-03-23 21:11:53,540] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6000, global step 96190: learning rate 0.0005
[2019-03-23 21:11:53,793] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6000, global step 96291: loss -60.2464
[2019-03-23 21:11:53,795] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6000, global step 96291: learning rate 0.0005
[2019-03-23 21:11:55,640] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.9153814e-19 1.0000000e+00 7.6411294e-32 1.6244276e-33 8.1116751e-36], sum to 1.0000
[2019-03-23 21:11:55,646] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9005
[2019-03-23 21:11:55,653] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.03333333333333, 99.16666666666667, 1.0, 2.0, 0.5734237508443099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 666203.5797305404, 666203.5797305404, 154171.4308800645], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3633000.0000, 
sim time next is 3633600.0000, 
raw observation next is [23.06666666666667, 98.33333333333334, 1.0, 2.0, 0.5701363051641054, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 663324.7216760825, 663324.7216760825, 153660.3906101057], 
processed observation next is [1.0, 0.043478260869565216, 0.40987654320987665, 0.9833333333333334, 1.0, 1.0, 0.4882575061477445, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2369016863128866, 0.2369016863128866, 0.29550075117328023], 
reward next is 0.7045, 
noisyNet noise sample is [array([-0.5127475], dtype=float32), 0.7607996]. 
=============================================
[2019-03-23 21:11:56,924] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.3941661e-16 1.0000000e+00 9.2450996e-24 2.6647084e-23 2.7322819e-25], sum to 1.0000
[2019-03-23 21:11:56,934] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2500
[2019-03-23 21:11:56,941] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1506337.545112746 W.
[2019-03-23 21:11:56,945] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.33333333333334, 100.0, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.526349416802801, 6.9112, 121.9236195994236, 1506337.545112746, 1191332.322450244, 247148.854456576], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3666000.0000, 
sim time next is 3666600.0000, 
raw observation next is [22.5, 100.0, 1.0, 2.0, 0.5653441624666736, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9014504720314728, 6.911199999999999, 6.9112, 121.9256721829861, 1309016.40257307, 1309016.402573071, 280299.3144083568], 
processed observation next is [1.0, 0.43478260869565216, 0.3888888888888889, 1.0, 1.0, 1.0, 0.48255257436508764, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.8768130900393408, -8.881784197001253e-17, 0.0, 0.8094596695323921, 0.4675058580618107, 0.46750585806181105, 0.5390371430929938], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.6554854], dtype=float32), 1.0243353]. 
=============================================
[2019-03-23 21:12:01,229] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.8980366e-15 1.0000000e+00 9.4654502e-26 1.2536467e-27 1.1864659e-29], sum to 1.0000
[2019-03-23 21:12:01,241] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4703
[2019-03-23 21:12:01,245] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.7, 97.0, 1.0, 2.0, 0.736522942016139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 839450.5944212601, 839450.5944212601, 183170.4996122172], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3742200.0000, 
sim time next is 3742800.0000, 
raw observation next is [24.93333333333333, 96.0, 1.0, 2.0, 0.7945144737659888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 905585.3795799563, 905585.3795799563, 194806.0582168947], 
processed observation next is [1.0, 0.30434782608695654, 0.47901234567901224, 0.96, 1.0, 1.0, 0.7553743735309391, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3234233498499844, 0.3234233498499844, 0.3746270350324898], 
reward next is 0.6254, 
noisyNet noise sample is [array([0.90450567], dtype=float32), -0.69240516]. 
=============================================
[2019-03-23 21:12:01,333] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 21:12:01,334] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:12:01,334] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:12:01,335] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:12:01,337] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:12:01,337] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:12:01,335] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:12:01,338] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:12:01,338] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:12:01,338] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:12:01,340] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:12:01,352] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run5
[2019-03-23 21:12:01,375] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run5
[2019-03-23 21:12:01,399] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run5
[2019-03-23 21:12:01,400] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run5
[2019-03-23 21:12:01,400] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run5
[2019-03-23 21:12:08,506] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02631148], dtype=float32), 0.17640932]
[2019-03-23 21:12:08,507] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [19.805897065, 58.34301727, 1.0, 2.0, 0.2379579344014769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 306942.1538918792, 306942.1538918792, 94177.10517081022]
[2019-03-23 21:12:08,508] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:12:08,512] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.16735370e-15 1.00000000e+00 3.34796833e-25 1.15926295e-24
 2.09559051e-27], sampled 0.9633968024889507
[2019-03-23 21:12:10,811] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02631148], dtype=float32), 0.17640932]
[2019-03-23 21:12:10,812] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.63507607, 55.24048925, 1.0, 2.0, 0.5462431614806272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 693936.0164959192, 693936.0164959192, 151395.2745109384]
[2019-03-23 21:12:10,812] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:12:10,815] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.16735370e-15 1.00000000e+00 3.34796833e-25 1.15926295e-24
 2.09559051e-27], sampled 0.6759224642420308
[2019-03-23 21:12:32,635] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02631148], dtype=float32), 0.17640932]
[2019-03-23 21:12:32,636] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.36666666666667, 76.0, 1.0, 2.0, 0.5375494076989127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 634872.1314689261, 634872.1314689256, 148675.9566911247]
[2019-03-23 21:12:32,636] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:12:32,639] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.16735370e-15 1.00000000e+00 3.34796833e-25 1.15926295e-24
 2.09559051e-27], sampled 0.7907206065608609
[2019-03-23 21:12:59,451] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02631148], dtype=float32), 0.17640932]
[2019-03-23 21:12:59,452] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.61962843666667, 68.56757410666667, 1.0, 2.0, 0.3997445130069539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 489737.1473295307, 489737.1473295307, 128445.8503481568]
[2019-03-23 21:12:59,454] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:12:59,457] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.16735370e-15 1.00000000e+00 3.34796833e-25 1.15926295e-24
 2.09559051e-27], sampled 0.1219888249147536
[2019-03-23 21:13:39,256] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 21:13:39,552] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 21:13:39,696] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 21:13:39,746] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 21:13:39,817] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02631148], dtype=float32), 0.17640932]
[2019-03-23 21:13:39,817] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.7, 50.5, 1.0, 2.0, 0.9631833293706464, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.23723047193185, 6.9112, 121.9246550302447, 1324191.322856344, 1157236.481013861, 234894.9702545835]
[2019-03-23 21:13:39,819] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:13:39,820] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.16735370e-15 1.00000000e+00 3.34796833e-25 1.15926295e-24
 2.09559051e-27], sampled 0.4167491469456511
[2019-03-23 21:13:39,820] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1324191.322856344 W.
[2019-03-23 21:13:39,984] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 21:13:40,998] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 100000, evaluation results [100000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 21:13:41,507] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.1839822e-11 1.0000000e+00 1.2240477e-16 3.9964765e-17 8.3319696e-19], sum to 1.0000
[2019-03-23 21:13:41,513] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8840
[2019-03-23 21:13:41,517] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2120095.079882264 W.
[2019-03-23 21:13:41,521] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.76666666666667, 78.33333333333333, 1.0, 2.0, 0.6195613584533807, 1.0, 2.0, 0.6195613584533807, 1.0, 1.0, 0.9863618603625479, 6.911199999999999, 6.9112, 121.94756008, 2120095.079882264, 2120095.079882265, 406136.5960048107], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3757200.0000, 
sim time next is 3757800.0000, 
raw observation next is [29.88333333333333, 78.66666666666667, 1.0, 2.0, 0.6227162348536716, 1.0, 2.0, 0.6227162348536716, 1.0, 2.0, 0.9913845263389622, 6.911200000000001, 6.9112, 121.94756008, 2130903.723170285, 2130903.723170284, 407891.4143456588], 
processed observation next is [1.0, 0.4782608695652174, 0.6623456790123455, 0.7866666666666667, 1.0, 1.0, 0.5508526605400852, 1.0, 1.0, 0.5508526605400852, 1.0, 1.0, 0.9892306579237028, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7610370439893875, 0.7610370439893872, 0.7844065660493438], 
reward next is 0.2156, 
noisyNet noise sample is [array([0.4665929], dtype=float32), 1.2003182]. 
=============================================
[2019-03-23 21:13:42,460] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.6499732e-08 9.9999988e-01 8.0766201e-12 2.3838542e-12 1.9022861e-12], sum to 1.0000
[2019-03-23 21:13:42,465] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5747
[2019-03-23 21:13:42,634] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.66666666666667, 50.0, 1.0, 2.0, 0.6767163096264884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 771251.8064544583, 771251.8064544583, 171784.9213989225], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3781200.0000, 
sim time next is 3781800.0000, 
raw observation next is [33.5, 51.5, 1.0, 2.0, 0.6822093581227593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 777515.3946169119, 777515.3946169127, 172806.0948031659], 
processed observation next is [1.0, 0.782608695652174, 0.7962962962962963, 0.515, 1.0, 1.0, 0.6216778072889991, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.27768406950603997, 0.27768406950604024, 0.3323194130830114], 
reward next is 0.6677, 
noisyNet noise sample is [array([0.00793766], dtype=float32), -1.0601985]. 
=============================================
[2019-03-23 21:13:48,619] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6500, global step 103662: loss 0.0145
[2019-03-23 21:13:48,620] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6500, global step 103662: learning rate 0.0005
[2019-03-23 21:13:48,835] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6500, global step 103773: loss 0.0316
[2019-03-23 21:13:48,838] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6500, global step 103775: learning rate 0.0005
[2019-03-23 21:13:48,904] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6500, global step 103805: loss 0.0052
[2019-03-23 21:13:48,907] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6500, global step 103805: learning rate 0.0005
[2019-03-23 21:13:48,912] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6500, global step 103806: loss 0.0000
[2019-03-23 21:13:48,914] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6500, global step 103806: learning rate 0.0005
[2019-03-23 21:13:49,053] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6500, global step 103875: loss 0.2687
[2019-03-23 21:13:49,054] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6500, global step 103875: learning rate 0.0005
[2019-03-23 21:13:49,067] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6500, global step 103881: loss 0.1926
[2019-03-23 21:13:49,068] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6500, global step 103881: learning rate 0.0005
[2019-03-23 21:13:49,191] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6500, global step 103943: loss 0.0506
[2019-03-23 21:13:49,192] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6500, global step 103943: learning rate 0.0005
[2019-03-23 21:13:49,196] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6500, global step 103946: loss 0.0046
[2019-03-23 21:13:49,200] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6500, global step 103947: learning rate 0.0005
[2019-03-23 21:13:49,283] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6500, global step 103982: loss 0.0434
[2019-03-23 21:13:49,286] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6500, global step 103982: learning rate 0.0005
[2019-03-23 21:13:49,364] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6500, global step 104024: loss 0.0804
[2019-03-23 21:13:49,366] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6500, global step 104025: learning rate 0.0005
[2019-03-23 21:13:49,543] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6500, global step 104118: loss 0.0032
[2019-03-23 21:13:49,549] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6500, global step 104119: learning rate 0.0005
[2019-03-23 21:13:49,580] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6500, global step 104132: loss 0.0204
[2019-03-23 21:13:49,583] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6500, global step 104132: learning rate 0.0005
[2019-03-23 21:13:49,604] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6500, global step 104141: loss 0.0627
[2019-03-23 21:13:49,605] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6500, global step 104141: learning rate 0.0005
[2019-03-23 21:13:49,714] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6500, global step 104198: loss 0.1397
[2019-03-23 21:13:49,718] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6500, global step 104198: learning rate 0.0005
[2019-03-23 21:13:49,853] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6500, global step 104263: loss 0.0015
[2019-03-23 21:13:49,857] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6500, global step 104266: learning rate 0.0005
[2019-03-23 21:13:49,942] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6500, global step 104302: loss 0.0694
[2019-03-23 21:13:49,944] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6500, global step 104302: learning rate 0.0005
[2019-03-23 21:13:52,186] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.1378492e-23 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:13:52,195] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2590
[2019-03-23 21:13:52,201] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.86666666666667, 76.66666666666667, 1.0, 2.0, 0.7351026381146009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 837830.9210187398, 837830.9210187398, 182899.1805364188], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3961200.0000, 
sim time next is 3961800.0000, 
raw observation next is [28.65, 78.5, 1.0, 2.0, 0.7536414457582943, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 858972.3091598018, 858972.3091598013, 186551.2161234498], 
processed observation next is [0.0, 0.8695652173913043, 0.6166666666666666, 0.785, 1.0, 1.0, 0.7067160068551123, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3067758246999292, 0.30677582469992903, 0.3587523386989419], 
reward next is 0.6412, 
noisyNet noise sample is [array([-0.8298455], dtype=float32), 0.97550106]. 
=============================================
[2019-03-23 21:13:52,897] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1656192e-21 1.0000000e+00 5.1917223e-35 1.8947611e-35 1.1889762e-36], sum to 1.0000
[2019-03-23 21:13:52,907] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2369
[2019-03-23 21:13:52,915] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.1, 77.0, 1.0, 2.0, 0.7564257513915291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 862147.5414096413, 862147.5414096413, 187105.9063872585], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3957600.0000, 
sim time next is 3958200.0000, 
raw observation next is [29.15, 76.0, 1.0, 2.0, 0.7691149365758765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 876618.5008408854, 876618.5008408854, 189645.1020437579], 
processed observation next is [0.0, 0.8260869565217391, 0.6351851851851852, 0.76, 1.0, 1.0, 0.7251368292569959, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31307803601460193, 0.31307803601460193, 0.3647021193149191], 
reward next is 0.6353, 
noisyNet noise sample is [array([-1.195015], dtype=float32), -0.5463893]. 
=============================================
[2019-03-23 21:13:58,890] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.391601e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:13:58,897] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5969
[2019-03-23 21:13:58,902] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.11666666666667, 99.16666666666667, 1.0, 2.0, 0.4741672276709151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 581323.453749698, 581323.453749698, 139402.5349148626], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4071000.0000, 
sim time next is 4071600.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.4726363262192942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 579667.6791280742, 579667.6791280737, 139173.4008050747], 
processed observation next is [1.0, 0.13043478260869565, 0.2962962962962963, 1.0, 1.0, 1.0, 0.37218610264201685, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20702417111716936, 0.2070241711171692, 0.2676411553943744], 
reward next is 0.7324, 
noisyNet noise sample is [array([-0.27190107], dtype=float32), -0.25561288]. 
=============================================
[2019-03-23 21:13:59,918] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.298140e-23 1.000000e+00 5.519817e-35 5.806841e-38 8.052296e-36], sum to 1.0000
[2019-03-23 21:13:59,925] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9600
[2019-03-23 21:13:59,932] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1546258.667792077 W.
[2019-03-23 21:13:59,937] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.25, 68.33333333333334, 1.0, 2.0, 0.727439286921501, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9953427956249252, 6.911199999999999, 6.9112, 121.9260426156618, 1546258.667792077, 1546258.667792078, 321870.813446698], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4101000.0000, 
sim time next is 4101600.0000, 
raw observation next is [27.4, 68.66666666666667, 1.0, 2.0, 0.7334467299129754, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9954400974660439, 6.911199999999999, 6.9112, 121.9260426156618, 1553046.040768414, 1553046.040768415, 323009.86556859], 
processed observation next is [1.0, 0.4782608695652174, 0.5703703703703703, 0.6866666666666668, 1.0, 1.0, 0.6826746784678279, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9943001218325548, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5546593002744336, 0.5546593002744339, 0.6211728184011346], 
reward next is 0.3788, 
noisyNet noise sample is [array([-0.5860447], dtype=float32), 1.6314601]. 
=============================================
[2019-03-23 21:14:01,254] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.1643797e-07 9.9999976e-01 1.0911748e-12 4.6409388e-13 1.7814161e-13], sum to 1.0000
[2019-03-23 21:14:01,260] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2559
[2019-03-23 21:14:01,269] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2015427.620862054 W.
[2019-03-23 21:14:01,276] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 70.66666666666667, 1.0, 2.0, 0.8835126718680345, 1.0, 2.0, 0.8835126718680345, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2015427.620862054, 2015427.620862055, 379471.6277634648], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4117800.0000, 
sim time next is 4118400.0000, 
raw observation next is [29.0, 70.0, 1.0, 2.0, 0.8745474356100511, 1.0, 2.0, 0.8745474356100511, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1994953.70168153, 1994953.70168153, 375521.4396180196], 
processed observation next is [1.0, 0.6956521739130435, 0.6296296296296297, 0.7, 1.0, 1.0, 0.8506517090595846, 1.0, 1.0, 0.8506517090595846, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7124834648862608, 0.7124834648862608, 0.7221566146500378], 
reward next is 0.2778, 
noisyNet noise sample is [array([-1.5891447], dtype=float32), 0.80508566]. 
=============================================
[2019-03-23 21:14:02,026] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.7124511e-13 1.0000000e+00 1.3496330e-20 4.0520238e-21 3.0563668e-20], sum to 1.0000
[2019-03-23 21:14:02,033] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7185
[2019-03-23 21:14:02,037] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.91666666666667, 94.66666666666667, 1.0, 2.0, 0.4486708098693553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 547935.7871252374, 547935.7871252369, 135481.9195651854], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4133400.0000, 
sim time next is 4134000.0000, 
raw observation next is [21.13333333333333, 93.33333333333333, 1.0, 2.0, 0.4490837532047278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 547949.9132574591, 547949.9132574586, 135529.3983372082], 
processed observation next is [1.0, 0.8695652173913043, 0.33827160493827146, 0.9333333333333332, 1.0, 1.0, 0.34414732524372355, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19569639759194968, 0.1956963975919495, 0.260633458340785], 
reward next is 0.7394, 
noisyNet noise sample is [array([-1.7159655], dtype=float32), 0.37168205]. 
=============================================
[2019-03-23 21:14:02,052] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[31.539116]
 [31.539116]
 [31.539116]
 [31.539116]
 [31.539116]], R is [[31.9630909 ]
 [32.38291931]
 [32.79892731]
 [33.21126175]
 [33.6197052 ]].
[2019-03-23 21:14:03,961] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.116957e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:14:03,969] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5202
[2019-03-23 21:14:03,974] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.58333333333333, 97.5, 1.0, 2.0, 0.599814376827198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 732046.9172706469, 732046.9172706469, 160019.9919539138], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4155000.0000, 
sim time next is 4155600.0000, 
raw observation next is [20.46666666666667, 98.0, 1.0, 2.0, 0.4988975135626824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 609378.9501984813, 609378.9501984813, 143194.7498903514], 
processed observation next is [1.0, 0.08695652173913043, 0.31358024691358033, 0.98, 1.0, 1.0, 0.4034494209079552, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21763533935660048, 0.21763533935660048, 0.27537451901990656], 
reward next is 0.7246, 
noisyNet noise sample is [array([-1.4541456], dtype=float32), 0.6943895]. 
=============================================
[2019-03-23 21:14:04,016] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.016732e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:14:04,025] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2055
[2019-03-23 21:14:04,031] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 96.0, 1.0, 2.0, 0.4628969855769003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 560446.5946044732, 560446.5946044732, 137473.5029473535], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4171200.0000, 
sim time next is 4171800.0000, 
raw observation next is [21.66666666666667, 95.0, 1.0, 2.0, 0.4731726755455377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 570796.6174283976, 570796.6174283976, 138968.9604922141], 
processed observation next is [1.0, 0.2608695652173913, 0.3580246913580249, 0.95, 1.0, 1.0, 0.3728246137446878, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20385593479585631, 0.20385593479585631, 0.2672480009465656], 
reward next is 0.7328, 
noisyNet noise sample is [array([0.49681738], dtype=float32), 0.013805991]. 
=============================================
[2019-03-23 21:14:05,059] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7000, global step 111700: loss -73.5080
[2019-03-23 21:14:05,061] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7000, global step 111702: learning rate 0.0005
[2019-03-23 21:14:05,332] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7000, global step 111836: loss 2.6581
[2019-03-23 21:14:05,335] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7000, global step 111837: learning rate 0.0005
[2019-03-23 21:14:05,337] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7000, global step 111838: loss -11.8301
[2019-03-23 21:14:05,343] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7000, global step 111840: learning rate 0.0005
[2019-03-23 21:14:05,381] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7000, global step 111859: loss 8.2419
[2019-03-23 21:14:05,385] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7000, global step 111859: learning rate 0.0005
[2019-03-23 21:14:05,388] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7000, global step 111859: loss -30.1458
[2019-03-23 21:14:05,391] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7000, global step 111859: learning rate 0.0005
[2019-03-23 21:14:05,446] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7000, global step 111890: loss -7.1607
[2019-03-23 21:14:05,448] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7000, global step 111890: learning rate 0.0005
[2019-03-23 21:14:05,469] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7000, global step 111901: loss 34.9910
[2019-03-23 21:14:05,470] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7000, global step 111901: learning rate 0.0005
[2019-03-23 21:14:05,611] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7000, global step 111971: loss -35.0950
[2019-03-23 21:14:05,613] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7000, global step 111971: learning rate 0.0005
[2019-03-23 21:14:05,634] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7000, global step 111982: loss 1.3851
[2019-03-23 21:14:05,638] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7000, global step 111984: learning rate 0.0005
[2019-03-23 21:14:05,726] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7000, global step 112027: loss -54.2936
[2019-03-23 21:14:05,731] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7000, global step 112027: learning rate 0.0005
[2019-03-23 21:14:05,742] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7000, global step 112031: loss 22.9916
[2019-03-23 21:14:05,746] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7000, global step 112033: learning rate 0.0005
[2019-03-23 21:14:05,849] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7000, global step 112090: loss 3.1914
[2019-03-23 21:14:05,854] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7000, global step 112091: learning rate 0.0005
[2019-03-23 21:14:05,900] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7000, global step 112109: loss 28.7122
[2019-03-23 21:14:05,902] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7000, global step 112109: learning rate 0.0005
[2019-03-23 21:14:05,988] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7000, global step 112156: loss 24.6202
[2019-03-23 21:14:05,990] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7000, global step 112157: learning rate 0.0005
[2019-03-23 21:14:06,164] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7000, global step 112238: loss -8.6290
[2019-03-23 21:14:06,167] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7000, global step 112240: learning rate 0.0005
[2019-03-23 21:14:06,425] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7000, global step 112363: loss -38.3289
[2019-03-23 21:14:06,429] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7000, global step 112365: learning rate 0.0005
[2019-03-23 21:14:11,169] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.3676438e-12 1.0000000e+00 5.8372352e-19 4.0785284e-20 1.1793834e-18], sum to 1.0000
[2019-03-23 21:14:11,176] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5708
[2019-03-23 21:14:11,182] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.3, 49.33333333333333, 1.0, 2.0, 0.5339030579045814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 621799.3009477133, 621799.3009477133, 147713.6880605647], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4297200.0000, 
sim time next is 4297800.0000, 
raw observation next is [31.15, 50.66666666666667, 1.0, 2.0, 0.550973051505415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 639795.6786626767, 639795.6786626762, 150417.1425253514], 
processed observation next is [1.0, 0.7391304347826086, 0.7092592592592593, 0.5066666666666667, 1.0, 1.0, 0.4654441089350178, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22849845666524168, 0.22849845666524152, 0.28926373562567576], 
reward next is 0.7107, 
noisyNet noise sample is [array([-0.32596228], dtype=float32), 0.40980494]. 
=============================================
[2019-03-23 21:14:12,925] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.9824199e-23 1.0000000e+00 0.0000000e+00 0.0000000e+00 4.6346711e-38], sum to 1.0000
[2019-03-23 21:14:12,932] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9731
[2019-03-23 21:14:12,944] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.4, 89.5, 1.0, 2.0, 0.5119930685320222, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 616934.2831047607, 616934.2831047607, 145014.3975075021], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4339800.0000, 
sim time next is 4340400.0000, 
raw observation next is [22.6, 89.33333333333333, 1.0, 2.0, 0.5185622600818428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 622931.4718840994, 622931.4718840994, 146001.5364854894], 
processed observation next is [1.0, 0.21739130434782608, 0.39259259259259266, 0.8933333333333333, 1.0, 1.0, 0.4268598334307652, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22247552567289264, 0.22247552567289264, 0.28077218554901806], 
reward next is 0.7192, 
noisyNet noise sample is [array([1.1935755], dtype=float32), -0.11127723]. 
=============================================
[2019-03-23 21:14:13,897] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0893608e-21 1.0000000e+00 1.2147467e-35 2.3895704e-36 1.1040714e-34], sum to 1.0000
[2019-03-23 21:14:13,901] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2103
[2019-03-23 21:14:13,906] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2544914.640474097 W.
[2019-03-23 21:14:13,911] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.8, 83.66666666666667, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 9.598635144257635, 6.9112, 121.9151782039413, 2544914.640474097, 1168830.275474539, 245878.00926207], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4350000.0000, 
sim time next is 4350600.0000, 
raw observation next is [26.1, 82.5, 1.0, 2.0, 0.8766702270600228, 1.0, 1.0, 0.8766702270600228, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9244242709836, 1999801.509986957, 1999801.509986956, 376453.2173611857], 
processed observation next is [1.0, 0.34782608695652173, 0.5222222222222223, 0.825, 1.0, 1.0, 0.8531788417381224, 1.0, 0.5, 0.8531788417381224, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094513846944325, 0.7142148249953418, 0.7142148249953414, 0.7239484949253571], 
reward next is 0.2761, 
noisyNet noise sample is [array([0.5200097], dtype=float32), -0.123826414]. 
=============================================
[2019-03-23 21:14:17,079] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.0297544e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:14:17,089] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7539
[2019-03-23 21:14:17,099] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 83.33333333333334, 1.0, 2.0, 0.5127554782571664, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 612428.8256038601, 612428.8256038601, 144945.0718299522], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4404000.0000, 
sim time next is 4404600.0000, 
raw observation next is [23.25, 86.0, 1.0, 2.0, 0.5092171707109018, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 608733.8759557354, 608733.8759557354, 144401.4112709802], 
processed observation next is [1.0, 1.0, 0.4166666666666667, 0.86, 1.0, 1.0, 0.4157347270367878, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21740495569847695, 0.21740495569847695, 0.2776950216749619], 
reward next is 0.7223, 
noisyNet noise sample is [array([0.40789014], dtype=float32), -0.6025573]. 
=============================================
[2019-03-23 21:14:18,292] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.3869587e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:14:18,298] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3375
[2019-03-23 21:14:18,304] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 97.0, 1.0, 2.0, 0.525160428178715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 621362.4872059821, 621362.4872059821, 146712.4712905357], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4429800.0000, 
sim time next is 4430400.0000, 
raw observation next is [22.66666666666666, 98.0, 1.0, 2.0, 0.5400534006777605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 635370.080430419, 635370.080430419, 148985.4546041971], 
processed observation next is [0.0, 0.2608695652173913, 0.3950617283950615, 0.98, 1.0, 1.0, 0.45244452461638157, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22691788586800676, 0.22691788586800676, 0.28651048962345593], 
reward next is 0.7135, 
noisyNet noise sample is [array([1.4490175], dtype=float32), -0.27372527]. 
=============================================
[2019-03-23 21:14:18,318] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7828392e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:14:18,320] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9009
[2019-03-23 21:14:18,326] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 95.0, 1.0, 2.0, 0.5000421484794327, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 598039.0915673464, 598039.0915673464, 142961.7301078527], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4428600.0000, 
sim time next is 4429200.0000, 
raw observation next is [22.33333333333334, 96.0, 1.0, 2.0, 0.5117335462083925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 608809.8357551324, 608809.8357551324, 144693.4772053296], 
processed observation next is [0.0, 0.2608695652173913, 0.38271604938271625, 0.96, 1.0, 1.0, 0.41873041215284823, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21743208419826157, 0.21743208419826157, 0.27825668693332617], 
reward next is 0.7217, 
noisyNet noise sample is [array([0.29716924], dtype=float32), 0.120854445]. 
=============================================
[2019-03-23 21:14:19,656] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.01637975e-22 1.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00], sum to 1.0000
[2019-03-23 21:14:19,666] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2966
[2019-03-23 21:14:19,673] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.33333333333334, 71.0, 1.0, 2.0, 0.6513164823279147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 742289.6732965625, 742289.673296562, 167131.263466623], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4454400.0000, 
sim time next is 4455000.0000, 
raw observation next is [28.5, 69.5, 1.0, 2.0, 0.6556908863727261, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 747277.506076592, 747277.506076592, 167923.5854077713], 
processed observation next is [0.0, 0.5652173913043478, 0.6111111111111112, 0.695, 1.0, 1.0, 0.5901081980627692, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26688482359878285, 0.26688482359878285, 0.3229299719380217], 
reward next is 0.6771, 
noisyNet noise sample is [array([0.9916805], dtype=float32), -0.27369747]. 
=============================================
[2019-03-23 21:14:19,698] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[72.463524]
 [72.463524]
 [72.463524]
 [72.463524]
 [72.463524]], R is [[72.41596222]
 [72.37039948]
 [72.32363129]
 [72.27419281]
 [72.2271347 ]].
[2019-03-23 21:14:20,035] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.2453727e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:14:20,043] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4192
[2019-03-23 21:14:20,047] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.66666666666667, 68.33333333333333, 1.0, 2.0, 0.6910765522900006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 787626.5461416054, 787626.5461416049, 174462.5655347174], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4459200.0000, 
sim time next is 4459800.0000, 
raw observation next is [29.83333333333333, 69.16666666666667, 1.0, 2.0, 0.7054895257809093, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 804061.7656457409, 804061.7656457409, 177188.0442975709], 
processed observation next is [0.0, 0.6086956521739131, 0.6604938271604937, 0.6916666666666668, 1.0, 1.0, 0.6493922925963206, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2871649163020503, 0.2871649163020503, 0.34074623903379014], 
reward next is 0.6593, 
noisyNet noise sample is [array([1.3398612], dtype=float32), 2.0089545]. 
=============================================
[2019-03-23 21:14:21,201] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.0507043e-21 1.0000000e+00 7.6855154e-37 2.4247230e-34 7.8239033e-35], sum to 1.0000
[2019-03-23 21:14:21,210] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3825
[2019-03-23 21:14:21,217] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.06666666666667, 92.66666666666667, 1.0, 2.0, 0.6620547199603439, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 754533.80681221, 754533.80681221, 169083.2482220833], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4492200.0000, 
sim time next is 4492800.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.6685883110358026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 761983.7433745877, 761983.7433745877, 170281.2153306215], 
processed observation next is [0.0, 0.0, 0.48148148148148145, 0.94, 1.0, 1.0, 0.6054622750426222, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2721370512052099, 0.2721370512052099, 0.32746387563581053], 
reward next is 0.6725, 
noisyNet noise sample is [array([-0.10242455], dtype=float32), -0.18178238]. 
=============================================
[2019-03-23 21:14:21,534] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7500, global step 119738: loss 0.0747
[2019-03-23 21:14:21,535] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7500, global step 119738: learning rate 0.0005
[2019-03-23 21:14:21,563] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7500, global step 119755: loss 0.0787
[2019-03-23 21:14:21,567] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7500, global step 119757: learning rate 0.0005
[2019-03-23 21:14:21,626] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7500, global step 119779: loss 0.0144
[2019-03-23 21:14:21,630] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7500, global step 119779: learning rate 0.0005
[2019-03-23 21:14:21,681] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7500, global step 119807: loss 0.0000
[2019-03-23 21:14:21,685] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7500, global step 119808: learning rate 0.0005
[2019-03-23 21:14:21,731] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7500, global step 119835: loss 0.0406
[2019-03-23 21:14:21,734] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7500, global step 119836: learning rate 0.0005
[2019-03-23 21:14:21,781] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7500, global step 119855: loss 0.1439
[2019-03-23 21:14:21,785] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7500, global step 119855: learning rate 0.0005
[2019-03-23 21:14:21,786] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7500, global step 119856: loss 0.0843
[2019-03-23 21:14:21,790] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7500, global step 119859: learning rate 0.0005
[2019-03-23 21:14:21,905] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7500, global step 119916: loss 0.0738
[2019-03-23 21:14:21,909] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7500, global step 119916: learning rate 0.0005
[2019-03-23 21:14:22,105] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7500, global step 120014: loss 0.0737
[2019-03-23 21:14:22,109] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7500, global step 120016: learning rate 0.0005
[2019-03-23 21:14:22,290] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7500, global step 120106: loss 0.0043
[2019-03-23 21:14:22,291] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7500, global step 120106: learning rate 0.0005
[2019-03-23 21:14:22,315] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7500, global step 120114: loss 0.0001
[2019-03-23 21:14:22,317] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7500, global step 120115: learning rate 0.0005
[2019-03-23 21:14:22,333] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7500, global step 120122: loss 0.0160
[2019-03-23 21:14:22,335] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7500, global step 120123: learning rate 0.0005
[2019-03-23 21:14:22,364] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7500, global step 120138: loss 0.0504
[2019-03-23 21:14:22,365] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7500, global step 120138: learning rate 0.0005
[2019-03-23 21:14:22,409] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7500, global step 120162: loss 0.0652
[2019-03-23 21:14:22,412] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7500, global step 120163: learning rate 0.0005
[2019-03-23 21:14:22,542] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7500, global step 120227: loss 0.0219
[2019-03-23 21:14:22,545] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7500, global step 120228: learning rate 0.0005
[2019-03-23 21:14:22,855] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7500, global step 120382: loss 0.0738
[2019-03-23 21:14:22,860] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7500, global step 120382: learning rate 0.0005
[2019-03-23 21:14:26,123] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.6327335e-20 1.0000000e+00 1.1912996e-38 3.0005101e-36 5.5468299e-37], sum to 1.0000
[2019-03-23 21:14:26,133] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9140
[2019-03-23 21:14:26,139] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 96.0, 1.0, 2.0, 0.5643933267800965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 661232.6186815702, 661232.6186815702, 152898.152503876], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4570800.0000, 
sim time next is 4571400.0000, 
raw observation next is [23.0, 95.0, 1.0, 2.0, 0.5570007237497971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 654202.4822001728, 654202.4822001728, 151733.8341790337], 
processed observation next is [0.0, 0.9130434782608695, 0.4074074074074074, 0.95, 1.0, 1.0, 0.472619909225949, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23364374364291887, 0.23364374364291887, 0.2917958349596802], 
reward next is 0.7082, 
noisyNet noise sample is [array([-0.20900878], dtype=float32), -1.7343199]. 
=============================================
[2019-03-23 21:14:27,262] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.7503078e-22 1.0000000e+00 8.9238302e-36 1.6579260e-34 2.3651028e-36], sum to 1.0000
[2019-03-23 21:14:27,268] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0621
[2019-03-23 21:14:27,273] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.2, 99.33333333333333, 1.0, 2.0, 0.5103164803864626, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 614137.8671771949, 614137.8671771949, 144720.2199701189], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4588800.0000, 
sim time next is 4589400.0000, 
raw observation next is [21.1, 99.66666666666667, 1.0, 2.0, 0.4969721460669747, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 598774.2776331048, 598774.2776331048, 142633.0498082114], 
processed observation next is [1.0, 0.08695652173913043, 0.3370370370370371, 0.9966666666666667, 1.0, 1.0, 0.40115731674639843, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21384795629753744, 0.21384795629753744, 0.2742943265542527], 
reward next is 0.7257, 
noisyNet noise sample is [array([1.6187078], dtype=float32), 0.07026251]. 
=============================================
[2019-03-23 21:14:27,735] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.3515484e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:14:27,742] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2594
[2019-03-23 21:14:27,749] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.26666666666667, 99.33333333333334, 1.0, 2.0, 0.4944036306303334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 594381.4311792044, 594381.4311792044, 142186.1121619031], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4598400.0000, 
sim time next is 4599000.0000, 
raw observation next is [21.2, 99.5, 1.0, 2.0, 0.4915601988732447, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 591479.1175363577, 591479.1175363577, 141759.4939517889], 
processed observation next is [1.0, 0.21739130434782608, 0.34074074074074073, 0.995, 1.0, 1.0, 0.3947145224681485, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2112425419772706, 0.2112425419772706, 0.2726144114457479], 
reward next is 0.7274, 
noisyNet noise sample is [array([-2.2127755], dtype=float32), 0.45486817]. 
=============================================
[2019-03-23 21:14:27,767] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[74.827896]
 [74.827896]
 [74.827896]
 [74.827896]
 [74.827896]], R is [[74.80700684]
 [74.78549957]
 [74.75379944]
 [74.7324295 ]
 [74.70468903]].
[2019-03-23 21:14:29,392] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.4901358e-09 1.0000000e+00 2.3643910e-13 8.6096413e-13 1.6774710e-13], sum to 1.0000
[2019-03-23 21:14:29,402] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6069
[2019-03-23 21:14:29,405] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1867910.611925437 W.
[2019-03-23 21:14:29,408] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.73333333333333, 66.66666666666666, 1.0, 2.0, 0.5459417603938924, 1.0, 2.0, 0.5459417603938924, 1.0, 1.0, 0.8691570626289207, 6.911199999999999, 6.9112, 121.94756008, 1867910.611925437, 1867910.611925437, 366709.5942417373], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4639200.0000, 
sim time next is 4639800.0000, 
raw observation next is [29.66666666666667, 65.83333333333334, 1.0, 2.0, 0.7848471222386005, 1.0, 2.0, 0.7848471222386005, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1790130.841562262, 1790130.841562262, 337532.6903681955], 
processed observation next is [1.0, 0.6956521739130435, 0.6543209876543211, 0.6583333333333334, 1.0, 1.0, 0.7438656217126197, 1.0, 1.0, 0.7438656217126197, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6393324434150935, 0.6393324434150935, 0.6491013276311451], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.63106364], dtype=float32), 0.9192835]. 
=============================================
[2019-03-23 21:14:29,451] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.2959352e-08 1.0000000e+00 4.6819720e-13 6.0837148e-13 3.3792066e-13], sum to 1.0000
[2019-03-23 21:14:29,459] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4294
[2019-03-23 21:14:29,463] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.8, 72.0, 1.0, 2.0, 0.6352837461523524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 724008.9217924075, 724008.9217924075, 164256.9639598108], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4642200.0000, 
sim time next is 4642800.0000, 
raw observation next is [28.53333333333333, 74.33333333333333, 1.0, 2.0, 0.6488217205597145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 739445.0821647838, 739445.0821647838, 166684.1324344074], 
processed observation next is [1.0, 0.7391304347826086, 0.6123456790123456, 0.7433333333333333, 1.0, 1.0, 0.5819306197139459, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26408752934456564, 0.26408752934456564, 0.32054640852770655], 
reward next is 0.6795, 
noisyNet noise sample is [array([-0.37331104], dtype=float32), -0.29304492]. 
=============================================
[2019-03-23 21:14:32,213] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 21:14:32,214] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:14:32,215] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:14:32,215] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:14:32,215] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:14:32,216] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:14:32,216] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:14:32,216] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:14:32,217] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:14:32,217] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:14:32,221] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:14:32,234] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run6
[2019-03-23 21:14:32,234] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run6
[2019-03-23 21:14:32,255] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run6
[2019-03-23 21:14:32,310] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run6
[2019-03-23 21:14:32,333] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run6
[2019-03-23 21:15:10,055] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.15414432], dtype=float32), 0.16930687]
[2019-03-23 21:15:10,057] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.40000000000001, 83.33333333333334, 1.0, 2.0, 0.719090349200815, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 819571.2076533643, 819571.2076533643, 179790.9049632539]
[2019-03-23 21:15:10,057] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:15:10,060] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.3933988e-23 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.7621077403064991
[2019-03-23 21:15:14,203] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.15414432], dtype=float32), 0.16930687]
[2019-03-23 21:15:14,205] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.51088283666667, 105.2716946733333, 1.0, 2.0, 0.5756160074195906, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 676176.9984979723, 676176.9984979723, 154865.4215441435]
[2019-03-23 21:15:14,205] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:15:14,208] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.3933988e-23 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.16754013988279137
[2019-03-23 21:15:18,636] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.15414432], dtype=float32), 0.16930687]
[2019-03-23 21:15:18,637] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.44284922, 97.63086277, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.399861576277894, 6.9112, 121.9241250192247, 1413212.574236965, 1162978.106740536, 245604.6972759304]
[2019-03-23 21:15:18,638] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:15:18,642] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.3933988e-23 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.14082825959356293
[2019-03-23 21:15:18,643] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1413212.574236965 W.
[2019-03-23 21:15:34,017] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.15414432], dtype=float32), 0.16930687]
[2019-03-23 21:15:34,018] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.5, 78.0, 1.0, 2.0, 0.5635184638132578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 660631.793073836, 660631.793073836, 152770.1148813727]
[2019-03-23 21:15:34,018] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:15:34,022] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.3933988e-23 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.9417837672295254
[2019-03-23 21:15:45,186] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.15414432], dtype=float32), 0.16930687]
[2019-03-23 21:15:45,190] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.122433885, 53.82785836166667, 1.0, 2.0, 0.4379263713756755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 534716.4958720095, 534716.4958720095, 133887.6544862419]
[2019-03-23 21:15:45,191] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:15:45,195] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.3933988e-23 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.3714223956060315
[2019-03-23 21:16:03,312] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.15414432], dtype=float32), 0.16930687]
[2019-03-23 21:16:03,313] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.33333333333334, 64.66666666666666, 1.0, 2.0, 0.2764036829544281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 355910.7261682075, 355910.7261682075, 112701.8889782936]
[2019-03-23 21:16:03,315] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:16:03,320] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.3933988e-23 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.8805336569102624
[2019-03-23 21:16:11,466] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 21:16:11,527] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 21:16:11,547] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 21:16:11,584] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 21:16:11,641] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 21:16:12,657] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 125000, evaluation results [125000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 21:16:16,794] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.1321622e-17 1.0000000e+00 8.1651980e-36 7.2942844e-30 1.0845025e-34], sum to 1.0000
[2019-03-23 21:16:16,801] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5917
[2019-03-23 21:16:16,805] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.1, 92.33333333333334, 1.0, 2.0, 0.6517325000101698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 742764.028317804, 742764.028317804, 167206.4870051115], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4750800.0000, 
sim time next is 4751400.0000, 
raw observation next is [25.05, 93.16666666666667, 1.0, 2.0, 0.65494717910632, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 746429.5054207097, 746429.5054207097, 167789.2738715453], 
processed observation next is [1.0, 1.0, 0.48333333333333334, 0.9316666666666668, 1.0, 1.0, 0.5892228322694286, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26658196622168207, 0.26658196622168207, 0.3226716805222025], 
reward next is 0.6773, 
noisyNet noise sample is [array([1.2484096], dtype=float32), 0.3812708]. 
=============================================
[2019-03-23 21:16:17,906] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.0882726e-18 1.0000000e+00 3.0026887e-34 1.4640760e-25 9.4617033e-32], sum to 1.0000
[2019-03-23 21:16:17,916] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1156
[2019-03-23 21:16:17,928] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1346580.570332323 W.
[2019-03-23 21:16:17,933] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.95, 94.0, 1.0, 2.0, 0.5905407341819977, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9401600813867572, 6.9112, 6.9112, 121.9254479091114, 1346580.570332323, 1346580.570332323, 290196.2323355471], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4786200.0000, 
sim time next is 4786800.0000, 
raw observation next is [23.96666666666667, 94.0, 1.0, 2.0, 0.5246857049511146, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8353167301026219, 6.911199999999999, 6.9112, 121.9260424343151, 1196297.368602941, 1196297.368602942, 265699.5336668083], 
processed observation next is [1.0, 0.391304347826087, 0.4432098765432099, 0.94, 1.0, 1.0, 0.43414964875132683, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7941459126282774, -8.881784197001253e-17, 0.0, 0.8094621276161824, 0.4272490602153361, 0.42724906021533643, 0.510960641666939], 
reward next is 0.4890, 
noisyNet noise sample is [array([2.3707688], dtype=float32), -0.4751687]. 
=============================================
[2019-03-23 21:16:18,280] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8000, global step 127748: loss -104.5950
[2019-03-23 21:16:18,281] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8000, global step 127749: learning rate 0.0005
[2019-03-23 21:16:18,313] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8000, global step 127761: loss -58.9420
[2019-03-23 21:16:18,315] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8000, global step 127762: learning rate 0.0005
[2019-03-23 21:16:18,338] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8000, global step 127776: loss -81.9585
[2019-03-23 21:16:18,342] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8000, global step 127777: learning rate 0.0005
[2019-03-23 21:16:18,417] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8000, global step 127815: loss -72.7507
[2019-03-23 21:16:18,418] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8000, global step 127816: learning rate 0.0005
[2019-03-23 21:16:18,481] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8000, global step 127840: loss -49.2571
[2019-03-23 21:16:18,484] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8000, global step 127840: learning rate 0.0005
[2019-03-23 21:16:18,516] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8000, global step 127858: loss -32.6683
[2019-03-23 21:16:18,518] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8000, global step 127859: learning rate 0.0005
[2019-03-23 21:16:18,542] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.1392742e-10 1.0000000e+00 6.1244121e-22 3.2710981e-18 2.8506844e-20], sum to 1.0000
[2019-03-23 21:16:18,548] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8430
[2019-03-23 21:16:18,551] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.96666666666667, 94.0, 1.0, 2.0, 0.5246849708879181, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8353155614501063, 6.911199999999999, 6.9112, 121.9260424343543, 1196295.693612529, 1196295.693612529, 265699.2571978645], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4786800.0000, 
sim time next is 4787400.0000, 
raw observation next is [23.98333333333333, 94.0, 1.0, 2.0, 1.003622442998396, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.221317148605474, 6.9112, 121.9247303760262, 1313089.702559612, 1154283.713699053, 242171.3148778233], 
processed observation next is [1.0, 0.391304347826087, 0.4438271604938271, 0.94, 1.0, 1.0, 1.0043124321409476, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.03101171486054737, 0.0, 0.8094534169135886, 0.4689606080570043, 0.41224418346394753, 0.4657140670727371], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.1662805], dtype=float32), -0.82955545]. 
=============================================
[2019-03-23 21:16:18,709] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8000, global step 127950: loss -22.3605
[2019-03-23 21:16:18,711] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8000, global step 127951: learning rate 0.0005
[2019-03-23 21:16:18,758] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8000, global step 127977: loss 6.3277
[2019-03-23 21:16:18,762] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8000, global step 127977: learning rate 0.0005
[2019-03-23 21:16:18,929] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8000, global step 128055: loss 13.8331
[2019-03-23 21:16:18,932] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8000, global step 128056: learning rate 0.0005
[2019-03-23 21:16:18,944] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8000, global step 128061: loss -2.2830
[2019-03-23 21:16:18,945] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8000, global step 128061: loss -3.5829
[2019-03-23 21:16:18,947] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8000, global step 128061: learning rate 0.0005
[2019-03-23 21:16:18,948] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8000, global step 128061: learning rate 0.0005
[2019-03-23 21:16:19,015] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8000, global step 128097: loss -7.9569
[2019-03-23 21:16:19,018] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8000, global step 128099: learning rate 0.0005
[2019-03-23 21:16:19,037] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8000, global step 128108: loss -1.1119
[2019-03-23 21:16:19,041] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8000, global step 128108: learning rate 0.0005
[2019-03-23 21:16:19,278] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8000, global step 128220: loss 1.8536
[2019-03-23 21:16:19,279] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8000, global step 128220: learning rate 0.0005
[2019-03-23 21:16:19,299] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8000, global step 128228: loss -11.4706
[2019-03-23 21:16:19,300] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8000, global step 128228: learning rate 0.0005
[2019-03-23 21:16:19,434] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8000, global step 128296: loss 22.8501
[2019-03-23 21:16:19,436] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8000, global step 128296: learning rate 0.0005
[2019-03-23 21:16:19,954] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.1315724e-07 9.9999905e-01 2.0381749e-14 2.8852951e-10 2.0841075e-13], sum to 1.0000
[2019-03-23 21:16:20,008] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4054
[2019-03-23 21:16:20,013] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.1, 92.0, 1.0, 2.0, 0.7659836521009717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 873047.5061576838, 873047.5061576838, 189017.9623957552], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4822200.0000, 
sim time next is 4822800.0000, 
raw observation next is [27.13333333333333, 91.33333333333334, 1.0, 2.0, 0.775397689074088, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 883783.5582130993, 883783.5582130989, 190914.8241853414], 
processed observation next is [1.0, 0.8260869565217391, 0.5604938271604937, 0.9133333333333334, 1.0, 1.0, 0.7326162965167714, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3156369850761069, 0.31563698507610677, 0.36714389266411807], 
reward next is 0.6329, 
noisyNet noise sample is [array([1.0486091], dtype=float32), 0.886055]. 
=============================================
[2019-03-23 21:16:22,846] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.5579724e-14 1.0000000e+00 1.4965365e-28 6.8474425e-20 1.0625822e-25], sum to 1.0000
[2019-03-23 21:16:22,852] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6619
[2019-03-23 21:16:22,857] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1553997.124954276 W.
[2019-03-23 21:16:22,862] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.93333333333333, 93.66666666666667, 1.0, 2.0, 0.6814107367454468, 1.0, 2.0, 0.6814107367454468, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260425161248, 1553997.124954276, 1553997.124954276, 297188.5332865738], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4869600.0000, 
sim time next is 4870200.0000, 
raw observation next is [25.96666666666667, 93.83333333333334, 1.0, 2.0, 0.466816084541648, 1.0, 2.0, 0.466816084541648, 1.0, 1.0, 0.7431864097287908, 6.911199999999999, 6.9112, 121.94756008, 1596944.388281633, 1596944.388281633, 327586.7714751605], 
processed observation next is [1.0, 0.34782608695652173, 0.517283950617284, 0.9383333333333335, 1.0, 1.0, 0.3652572435019619, 1.0, 1.0, 0.3652572435019619, 1.0, 0.5, 0.6789830121609886, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5703372815291546, 0.5703372815291546, 0.6299745605291548], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.13300118], dtype=float32), 1.8102983]. 
=============================================
[2019-03-23 21:16:23,844] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.04888722e-05 9.99989510e-01 4.42334259e-11 8.13416712e-09
 1.06505464e-10], sum to 1.0000
[2019-03-23 21:16:23,853] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0722
[2019-03-23 21:16:23,861] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2585236.291388398 W.
[2019-03-23 21:16:23,864] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.13333333333333, 78.66666666666667, 1.0, 2.0, 0.8838594253411073, 1.0, 2.0, 0.7552943746469883, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2585236.291388398, 2585236.291388398, 482300.3113110865], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4891800.0000, 
sim time next is 4892400.0000, 
raw observation next is [31.0, 79.0, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 8.481473678415467, 6.9112, 121.919740304055, 3132309.531873967, 2328230.623743398, 443050.956501888], 
processed observation next is [1.0, 0.6521739130434783, 0.7037037037037037, 0.79, 1.0, 1.0, 1.0238095238095237, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.25, 0.15702736784154672, 0.0, 0.8094202880250089, 1.1186819756692739, 0.8315109370512136, 0.8520210701959384], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.81314844], dtype=float32), 2.0536978]. 
=============================================
[2019-03-23 21:16:25,607] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.8087276e-19 1.0000000e+00 3.0698074e-33 2.3067645e-30 5.0206119e-38], sum to 1.0000
[2019-03-23 21:16:25,615] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2885
[2019-03-23 21:16:25,620] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.23333333333333, 92.66666666666667, 1.0, 2.0, 0.8074051819512356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 920286.9946751249, 920286.9946751249, 197481.7697285013], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4918800.0000, 
sim time next is 4919400.0000, 
raw observation next is [27.35, 92.0, 1.0, 2.0, 0.8055452544933036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 918165.7642792154, 918165.7642792154, 197095.543244247], 
processed observation next is [1.0, 0.9565217391304348, 0.5685185185185185, 0.92, 1.0, 1.0, 0.7685062553491709, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.32791634438543404, 0.32791634438543404, 0.37902989085432115], 
reward next is 0.6210, 
noisyNet noise sample is [array([-1.1303353], dtype=float32), 0.16794543]. 
=============================================
[2019-03-23 21:16:31,560] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.1965845e-22 1.0000000e+00 2.6314154e-37 2.9894996e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 21:16:31,567] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5258
[2019-03-23 21:16:31,571] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 98.66666666666666, 1.0, 2.0, 0.5626508162788303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 657630.1992034715, 657630.1992034715, 152539.5739044454], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5028000.0000, 
sim time next is 5028600.0000, 
raw observation next is [22.75, 98.33333333333334, 1.0, 2.0, 0.55710116307148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 652355.9523323834, 652355.9523323829, 151667.4454500878], 
processed observation next is [0.0, 0.17391304347826086, 0.39814814814814814, 0.9833333333333334, 1.0, 1.0, 0.47273947984700004, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23298426869013691, 0.23298426869013675, 0.2916681643270919], 
reward next is 0.7083, 
noisyNet noise sample is [array([-0.32187444], dtype=float32), 0.2321462]. 
=============================================
[2019-03-23 21:16:34,591] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8500, global step 135695: loss 0.0035
[2019-03-23 21:16:34,594] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8500, global step 135697: learning rate 0.0005
[2019-03-23 21:16:34,659] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8500, global step 135726: loss 0.1664
[2019-03-23 21:16:34,663] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8500, global step 135728: learning rate 0.0005
[2019-03-23 21:16:34,704] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8500, global step 135744: loss 0.1947
[2019-03-23 21:16:34,710] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8500, global step 135744: learning rate 0.0005
[2019-03-23 21:16:34,811] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8500, global step 135797: loss 0.0214
[2019-03-23 21:16:34,814] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8500, global step 135797: learning rate 0.0005
[2019-03-23 21:16:34,904] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8500, global step 135848: loss 0.0277
[2019-03-23 21:16:34,907] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8500, global step 135848: learning rate 0.0005
[2019-03-23 21:16:34,992] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8500, global step 135887: loss 0.1455
[2019-03-23 21:16:34,993] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8500, global step 135888: learning rate 0.0005
[2019-03-23 21:16:35,129] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8500, global step 135955: loss 0.0071
[2019-03-23 21:16:35,133] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8500, global step 135956: learning rate 0.0005
[2019-03-23 21:16:35,181] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8500, global step 135982: loss 0.0059
[2019-03-23 21:16:35,182] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8500, global step 135982: loss 0.0050
[2019-03-23 21:16:35,185] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8500, global step 135985: learning rate 0.0005
[2019-03-23 21:16:35,188] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8500, global step 135984: learning rate 0.0005
[2019-03-23 21:16:35,235] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8500, global step 136008: loss 0.0980
[2019-03-23 21:16:35,237] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8500, global step 136008: learning rate 0.0005
[2019-03-23 21:16:35,286] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8500, global step 136031: loss 0.1868
[2019-03-23 21:16:35,288] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8500, global step 136032: learning rate 0.0005
[2019-03-23 21:16:35,474] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8500, global step 136128: loss 0.0014
[2019-03-23 21:16:35,476] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8500, global step 136129: learning rate 0.0005
[2019-03-23 21:16:35,555] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8500, global step 136169: loss 0.0664
[2019-03-23 21:16:35,562] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8500, global step 136170: learning rate 0.0005
[2019-03-23 21:16:35,718] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8500, global step 136248: loss 0.0080
[2019-03-23 21:16:35,720] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8500, global step 136249: learning rate 0.0005
[2019-03-23 21:16:35,767] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8500, global step 136272: loss 0.0177
[2019-03-23 21:16:35,771] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8500, global step 136274: learning rate 0.0005
[2019-03-23 21:16:35,912] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8500, global step 136345: loss 0.2638
[2019-03-23 21:16:35,914] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8500, global step 136345: learning rate 0.0005
[2019-03-23 21:16:35,930] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.992253e-24 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:16:35,940] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3679
[2019-03-23 21:16:35,944] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.9, 99.0, 1.0, 2.0, 0.7040897128019638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 802465.5331758194, 802465.5331758185, 176919.6373791492], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5113800.0000, 
sim time next is 5114400.0000, 
raw observation next is [24.86666666666667, 98.66666666666666, 1.0, 2.0, 0.7010723915822474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 799024.8376327868, 799024.8376327868, 176346.7895425045], 
processed observation next is [0.0, 0.17391304347826086, 0.47654320987654336, 0.9866666666666666, 1.0, 1.0, 0.6441337995026755, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.285366013440281, 0.285366013440281, 0.3391284414278933], 
reward next is 0.6609, 
noisyNet noise sample is [array([0.10678408], dtype=float32), -0.48484856]. 
=============================================
[2019-03-23 21:16:36,364] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.6153872e-23 1.0000000e+00 0.0000000e+00 7.4810648e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 21:16:36,368] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1674
[2019-03-23 21:16:36,380] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333333, 93.16666666666667, 1.0, 2.0, 0.784767601005829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 894469.4380812166, 894469.4380812166, 192820.997223883], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5130600.0000, 
sim time next is 5131200.0000, 
raw observation next is [27.66666666666667, 92.33333333333334, 1.0, 2.0, 0.8161782652675524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 930292.6957894792, 930292.6957894792, 199314.5011193809], 
processed observation next is [0.0, 0.391304347826087, 0.580246913580247, 0.9233333333333335, 1.0, 1.0, 0.781164601508991, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.33224739135338544, 0.33224739135338544, 0.38329711753727097], 
reward next is 0.6167, 
noisyNet noise sample is [array([-1.1691985], dtype=float32), -2.143831]. 
=============================================
[2019-03-23 21:16:48,143] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.5767957e-11 1.0000000e+00 7.4104623e-20 3.9362902e-16 9.8306685e-23], sum to 1.0000
[2019-03-23 21:16:48,150] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2196
[2019-03-23 21:16:48,158] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1748779.850281467 W.
[2019-03-23 21:16:48,163] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.31666666666667, 64.33333333333334, 1.0, 2.0, 0.9067413461119398, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426156618, 1748779.850281467, 1748779.850281467, 358422.4697048261], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5325000.0000, 
sim time next is 5325600.0000, 
raw observation next is [28.33333333333334, 64.66666666666667, 1.0, 2.0, 0.9412974239626256, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1788227.270215277, 1788227.270215278, 366030.1338522481], 
processed observation next is [1.0, 0.6521739130434783, 0.6049382716049385, 0.6466666666666667, 1.0, 1.0, 0.9301159809078876, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6386525965054561, 0.6386525965054565, 0.7039041035620155], 
reward next is 0.2961, 
noisyNet noise sample is [array([0.41519597], dtype=float32), 1.0103713]. 
=============================================
[2019-03-23 21:16:48,615] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.1904431e-14 1.0000000e+00 9.5919846e-25 5.8871034e-19 3.5062804e-28], sum to 1.0000
[2019-03-23 21:16:48,620] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2020
[2019-03-23 21:16:48,623] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.9, 72.0, 1.0, 2.0, 0.628064610334469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 715777.7038419133, 715777.7038419133, 162971.8800049903], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5342400.0000, 
sim time next is 5343000.0000, 
raw observation next is [27.81666666666667, 72.33333333333333, 1.0, 2.0, 0.6305724586429464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 718637.1283224084, 718637.128322408, 163415.7363284892], 
processed observation next is [1.0, 0.8695652173913043, 0.5858024691358026, 0.7233333333333333, 1.0, 1.0, 0.5602053079082695, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.256656117258003, 0.25665611725800286, 0.3142610314009408], 
reward next is 0.6857, 
noisyNet noise sample is [array([0.7075035], dtype=float32), -1.0608371]. 
=============================================
[2019-03-23 21:16:48,651] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[46.7994]
 [46.7994]
 [46.7994]
 [46.7994]
 [46.7994]], R is [[47.01714325]
 [47.23356247]
 [47.44691849]
 [47.65842056]
 [47.86821365]].
[2019-03-23 21:16:50,889] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.3151556e-16 1.0000000e+00 1.5052082e-31 7.5970076e-25 4.1720160e-35], sum to 1.0000
[2019-03-23 21:16:50,896] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9732
[2019-03-23 21:16:50,901] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.3, 91.0, 1.0, 2.0, 0.6259090137355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 724014.4993251206, 724014.4993251206, 163111.4576653071], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5377200.0000, 
sim time next is 5377800.0000, 
raw observation next is [24.35, 91.0, 1.0, 2.0, 0.6467919221254247, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 747343.3467945544, 747343.3467945544, 166815.3077044935], 
processed observation next is [1.0, 0.21739130434782608, 0.4574074074074075, 0.91, 1.0, 1.0, 0.5795141930064579, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2669083381409123, 0.2669083381409123, 0.32079866866248746], 
reward next is 0.6792, 
noisyNet noise sample is [array([-0.30547643], dtype=float32), -0.34338775]. 
=============================================
[2019-03-23 21:16:50,945] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9000, global step 143686: loss -132.9195
[2019-03-23 21:16:50,951] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9000, global step 143688: learning rate 0.0005
[2019-03-23 21:16:51,051] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9000, global step 143744: loss -141.1618
[2019-03-23 21:16:51,052] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9000, global step 143744: learning rate 0.0005
[2019-03-23 21:16:51,229] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9000, global step 143830: loss -111.9279
[2019-03-23 21:16:51,230] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9000, global step 143830: learning rate 0.0005
[2019-03-23 21:16:51,264] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9000, global step 143843: loss -121.4834
[2019-03-23 21:16:51,266] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9000, global step 143843: learning rate 0.0005
[2019-03-23 21:16:51,384] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9000, global step 143901: loss -72.6432
[2019-03-23 21:16:51,391] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9000, global step 143903: learning rate 0.0005
[2019-03-23 21:16:51,407] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9000, global step 143911: loss -109.1533
[2019-03-23 21:16:51,408] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9000, global step 143911: learning rate 0.0005
[2019-03-23 21:16:51,444] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9000, global step 143930: loss -107.3529
[2019-03-23 21:16:51,445] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9000, global step 143930: learning rate 0.0005
[2019-03-23 21:16:51,484] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9000, global step 143944: loss -101.2057
[2019-03-23 21:16:51,487] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9000, global step 143948: learning rate 0.0005
[2019-03-23 21:16:51,548] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9000, global step 143983: loss -92.5775
[2019-03-23 21:16:51,551] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9000, global step 143984: learning rate 0.0005
[2019-03-23 21:16:51,636] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9000, global step 144020: loss -50.4687
[2019-03-23 21:16:51,641] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9000, global step 144020: learning rate 0.0005
[2019-03-23 21:16:51,685] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9000, global step 144051: loss -40.9095
[2019-03-23 21:16:51,686] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9000, global step 144052: learning rate 0.0005
[2019-03-23 21:16:51,708] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9000, global step 144063: loss -68.0916
[2019-03-23 21:16:51,711] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9000, global step 144063: learning rate 0.0005
[2019-03-23 21:16:51,942] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9000, global step 144167: loss -24.2009
[2019-03-23 21:16:51,944] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9000, global step 144167: learning rate 0.0005
[2019-03-23 21:16:52,097] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9000, global step 144242: loss 9.7483
[2019-03-23 21:16:52,098] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9000, global step 144242: learning rate 0.0005
[2019-03-23 21:16:52,183] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9000, global step 144287: loss -3.3620
[2019-03-23 21:16:52,187] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9000, global step 144290: learning rate 0.0005
[2019-03-23 21:16:52,194] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9000, global step 144293: loss -0.7217
[2019-03-23 21:16:52,198] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9000, global step 144293: learning rate 0.0005
[2019-03-23 21:16:55,969] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.2272525e-16 1.0000000e+00 3.2442994e-29 1.8193133e-19 1.4860691e-28], sum to 1.0000
[2019-03-23 21:16:55,975] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5179
[2019-03-23 21:16:55,983] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2425753.800794742 W.
[2019-03-23 21:16:55,991] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.5, 73.0, 1.0, 2.0, 0.7907980773460698, 1.0, 2.0, 0.7087637006494695, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2425753.800794742, 2425753.800794742, 454530.2275167617], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5487600.0000, 
sim time next is 5488200.0000, 
raw observation next is [31.7, 72.0, 1.0, 2.0, 0.8069511405082407, 1.0, 2.0, 0.716840232230555, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2453433.827281412, 2453433.827281412, 459216.114319285], 
processed observation next is [1.0, 0.5217391304347826, 0.7296296296296296, 0.72, 1.0, 1.0, 0.770179929176477, 1.0, 1.0, 0.6629050383697084, 1.0, 1.0, 0.9972168686025908, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.8762263668862187, 0.8762263668862187, 0.8831079121524712], 
reward next is 0.1169, 
noisyNet noise sample is [array([0.5781539], dtype=float32), -0.7816273]. 
=============================================
[2019-03-23 21:16:56,005] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.3845405e-12 1.0000000e+00 4.2434596e-27 9.5182543e-16 6.5822338e-27], sum to 1.0000
[2019-03-23 21:16:56,013] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1349
[2019-03-23 21:16:56,023] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2687306.801044143 W.
[2019-03-23 21:16:56,026] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.0, 82.0, 1.0, 2.0, 0.9434109636807003, 1.0, 2.0, 0.7850701438167849, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2687306.801044143, 2687306.801044144, 501053.2671395878], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5482800.0000, 
sim time next is 5483400.0000, 
raw observation next is [30.18333333333333, 80.83333333333334, 1.0, 2.0, 0.7549742254240985, 1.0, 2.0, 0.6908517746884839, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2364368.80535064, 2364368.80535064, 444339.262475026], 
processed observation next is [1.0, 0.4782608695652174, 0.6734567901234567, 0.8083333333333335, 1.0, 1.0, 0.708302649314403, 1.0, 1.0, 0.6319663984386713, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8096049824067558, 0.8444174304823714, 0.8444174304823714, 0.8544985816827423], 
reward next is 0.1455, 
noisyNet noise sample is [array([1.5770493], dtype=float32), -1.2440902]. 
=============================================
[2019-03-23 21:16:59,936] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.5020874e-24 1.0000000e+00 0.0000000e+00 2.7767519e-38 0.0000000e+00], sum to 1.0000
[2019-03-23 21:16:59,946] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2986
[2019-03-23 21:16:59,953] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.3, 90.0, 1.0, 2.0, 0.6574176297603279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 749246.4020143951, 749246.4020143951, 168237.2808901216], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5551200.0000, 
sim time next is 5551800.0000, 
raw observation next is [25.31666666666667, 89.5, 1.0, 2.0, 0.693884279313101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 790828.1902440904, 790828.1902440904, 174985.6510359269], 
processed observation next is [1.0, 0.2608695652173913, 0.49320987654321, 0.895, 1.0, 1.0, 0.6355765229917869, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28243863937288943, 0.28243863937288943, 0.3365108673767825], 
reward next is 0.6635, 
noisyNet noise sample is [array([0.69795793], dtype=float32), -1.1584803]. 
=============================================
[2019-03-23 21:17:00,091] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.5915013e-24 1.0000000e+00 0.0000000e+00 3.8787106e-38 0.0000000e+00], sum to 1.0000
[2019-03-23 21:17:00,097] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9050
[2019-03-23 21:17:00,103] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1590526.133201452 W.
[2019-03-23 21:17:00,108] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.1, 82.0, 1.0, 2.0, 0.4649415793045674, 1.0, 2.0, 0.4649415793045674, 1.0, 2.0, 0.7402021363429849, 6.9112, 6.9112, 121.94756008, 1590526.133201452, 1590526.133201452, 326697.3261280715], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5563800.0000, 
sim time next is 5564400.0000, 
raw observation next is [26.16666666666666, 81.66666666666667, 1.0, 2.0, 0.7764042319427659, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1600009.458051511, 1600009.458051512, 331590.4766285591], 
processed observation next is [1.0, 0.391304347826087, 0.5246913580246911, 0.8166666666666668, 1.0, 1.0, 0.733814561836626, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5714319493041111, 0.5714319493041115, 0.6376739935164598], 
reward next is 0.3623, 
noisyNet noise sample is [array([0.88559145], dtype=float32), -2.2878609]. 
=============================================
[2019-03-23 21:17:01,034] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.7772579e-18 1.0000000e+00 1.6736758e-30 7.3904000e-25 8.9490544e-29], sum to 1.0000
[2019-03-23 21:17:01,040] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0812
[2019-03-23 21:17:01,051] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1595648.282367695 W.
[2019-03-23 21:17:01,055] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.96666666666667, 82.66666666666667, 1.0, 2.0, 0.6996562103885448, 1.0, 2.0, 0.6996562103885448, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426155843, 1595648.282367695, 1595648.282367695, 304034.4357185979], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5562600.0000, 
sim time next is 5563200.0000, 
raw observation next is [26.03333333333333, 82.33333333333334, 1.0, 2.0, 0.7365095200017976, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426156618, 1554473.526930023, 1554473.526930023, 323964.6816877549], 
processed observation next is [1.0, 0.391304347826087, 0.519753086419753, 0.8233333333333335, 1.0, 1.0, 0.6863208571449971, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5551691167607224, 0.5551691167607224, 0.6230090032456825], 
reward next is 0.3770, 
noisyNet noise sample is [array([-0.05548676], dtype=float32), -0.7464414]. 
=============================================
[2019-03-23 21:17:01,472] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.3238582e-11 1.0000000e+00 2.5073191e-19 9.1965956e-16 5.7421136e-19], sum to 1.0000
[2019-03-23 21:17:01,476] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0064
[2019-03-23 21:17:01,481] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1953091.013356629 W.
[2019-03-23 21:17:01,485] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.8, 85.0, 1.0, 2.0, 0.8562157235927678, 1.0, 2.0, 0.8562157235927678, 0.0, 1.0, 0.0, 6.911199999999997, 6.9112, 121.9260426156618, 1953091.013356629, 1953091.01335663, 367531.3482874515], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5587200.0000, 
sim time next is 5587800.0000, 
raw observation next is [26.5, 86.00000000000001, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 8.007639175645163, 6.9112, 121.9217140009232, 2440122.039628092, 1878667.116539938, 380191.696265871], 
processed observation next is [1.0, 0.6956521739130435, 0.5370370370370371, 0.8600000000000001, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, 0.10964391756451634, 0.0, 0.8094333913197137, 0.8714721570100329, 0.6709525416214064, 0.7311378774343673], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.13998997], dtype=float32), 0.33872148]. 
=============================================
[2019-03-23 21:17:02,417] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.316321e-13 1.000000e+00 8.116968e-21 6.569149e-17 8.333801e-22], sum to 1.0000
[2019-03-23 21:17:02,427] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5967
[2019-03-23 21:17:02,431] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.68333333333333, 93.16666666666667, 1.0, 2.0, 0.6975119125361281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 794964.7911373801, 794964.7911373801, 175673.7941017581], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5602200.0000, 
sim time next is 5602800.0000, 
raw observation next is [25.56666666666667, 93.33333333333334, 1.0, 2.0, 0.6937312972677965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 790653.7448559483, 790653.7448559483, 174960.5993993781], 
processed observation next is [1.0, 0.8695652173913043, 0.5024691358024692, 0.9333333333333335, 1.0, 1.0, 0.6353944015092815, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28237633744855295, 0.28237633744855295, 0.33646269115265015], 
reward next is 0.6635, 
noisyNet noise sample is [array([-0.34155813], dtype=float32), 2.0307221]. 
=============================================
[2019-03-23 21:17:03,832] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 21:17:03,833] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:17:03,833] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:17:03,833] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:17:03,834] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:17:03,834] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:17:03,835] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:17:03,836] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:17:03,836] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:17:03,837] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:17:03,838] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:17:03,850] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run7
[2019-03-23 21:17:03,852] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run7
[2019-03-23 21:17:03,898] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run7
[2019-03-23 21:17:03,926] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run7
[2019-03-23 21:17:03,926] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run7
[2019-03-23 21:17:22,330] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.10934628]
[2019-03-23 21:17:22,331] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.91402416666667, 52.64201011333334, 1.0, 2.0, 0.50582898674811, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 596336.8658652493, 596336.8658652493, 143544.7739171521]
[2019-03-23 21:17:22,332] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:17:22,334] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.9521081e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.5927271258022652
[2019-03-23 21:17:32,564] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.10934628]
[2019-03-23 21:17:32,565] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.47699932333333, 36.06519727166666, 1.0, 2.0, 0.4363316866145371, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 532861.0993560156, 532861.0993560156, 133655.9663407845]
[2019-03-23 21:17:32,566] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:17:32,569] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.9521081e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.6033581186239185
[2019-03-23 21:17:52,040] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.10934628]
[2019-03-23 21:17:52,040] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.96666666666667, 88.83333333333334, 1.0, 2.0, 0.7626865985205763, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 869287.48224748, 869287.48224748, 188353.8434669524]
[2019-03-23 21:17:52,041] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:17:52,044] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.9521081e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.04402308880625272
[2019-03-23 21:17:56,252] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.10934628]
[2019-03-23 21:17:56,253] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.0, 68.5, 1.0, 2.0, 0.5994411369683859, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 688862.7126254154, 688862.7126254154, 158261.9907620088]
[2019-03-23 21:17:56,254] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:17:56,258] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.9521081e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.5111541573805115
[2019-03-23 21:18:18,025] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.10934628]
[2019-03-23 21:18:18,026] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.3, 63.83333333333334, 1.0, 2.0, 0.9118517397178519, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1754613.499879665, 1754613.499879665, 359534.2852254179]
[2019-03-23 21:18:18,028] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:18:18,032] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.9521081e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.07280460021909252
[2019-03-23 21:18:18,036] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1754613.499879665 W.
[2019-03-23 21:18:23,661] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.10934628]
[2019-03-23 21:18:23,662] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.46666666666667, 68.66666666666667, 1.0, 2.0, 0.9675187563642754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.944542774051874, 6.9112, 121.9254874468189, 1120003.783844195, 1102929.381131958, 232980.2686039538]
[2019-03-23 21:18:23,663] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:18:23,666] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.9521081e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.19663901854307408
[2019-03-23 21:18:42,970] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 21:18:43,120] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 21:18:43,251] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 21:18:43,327] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 21:18:43,804] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 21:18:44,819] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 150000, evaluation results [150000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 21:18:48,100] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9500, global step 151630: loss 0.0173
[2019-03-23 21:18:48,103] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9500, global step 151632: learning rate 0.0005
[2019-03-23 21:18:48,282] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9500, global step 151720: loss 0.2627
[2019-03-23 21:18:48,284] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9500, global step 151720: learning rate 0.0005
[2019-03-23 21:18:48,469] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9500, global step 151806: loss 0.0042
[2019-03-23 21:18:48,472] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9500, global step 151806: learning rate 0.0005
[2019-03-23 21:18:48,531] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9500, global step 151837: loss 0.0030
[2019-03-23 21:18:48,533] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9500, global step 151837: learning rate 0.0005
[2019-03-23 21:18:48,598] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9500, global step 151873: loss 0.0501
[2019-03-23 21:18:48,602] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9500, global step 151873: learning rate 0.0005
[2019-03-23 21:18:48,613] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9500, global step 151878: loss 0.1260
[2019-03-23 21:18:48,614] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9500, global step 151878: learning rate 0.0005
[2019-03-23 21:18:48,761] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9500, global step 151952: loss 0.0021
[2019-03-23 21:18:48,762] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9500, global step 151952: loss 0.0000
[2019-03-23 21:18:48,764] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9500, global step 151952: learning rate 0.0005
[2019-03-23 21:18:48,766] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9500, global step 151954: learning rate 0.0005
[2019-03-23 21:18:48,792] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9500, global step 151963: loss 0.0543
[2019-03-23 21:18:48,796] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9500, global step 151964: learning rate 0.0005
[2019-03-23 21:18:48,869] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9500, global step 152000: loss 0.1532
[2019-03-23 21:18:48,872] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9500, global step 152000: learning rate 0.0005
[2019-03-23 21:18:48,875] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9500, global step 152000: loss 0.1018
[2019-03-23 21:18:48,876] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9500, global step 152000: learning rate 0.0005
[2019-03-23 21:18:49,115] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9500, global step 152127: loss 0.0308
[2019-03-23 21:18:49,116] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9500, global step 152127: learning rate 0.0005
[2019-03-23 21:18:49,205] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9500, global step 152166: loss 0.0462
[2019-03-23 21:18:49,207] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9500, global step 152166: learning rate 0.0005
[2019-03-23 21:18:49,313] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9500, global step 152219: loss 0.0001
[2019-03-23 21:18:49,313] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9500, global step 152219: learning rate 0.0005
[2019-03-23 21:18:49,488] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9500, global step 152306: loss 0.1111
[2019-03-23 21:18:49,489] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9500, global step 152306: learning rate 0.0005
[2019-03-23 21:18:49,620] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9500, global step 152372: loss 0.0019
[2019-03-23 21:18:49,622] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9500, global step 152372: learning rate 0.0005
[2019-03-23 21:18:49,756] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.170548e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:18:49,768] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8625
[2019-03-23 21:18:49,773] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.18333333333334, 93.66666666666667, 1.0, 2.0, 0.5533873227214262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 650048.0915623149, 650048.0915623144, 151137.8781468041], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5701800.0000, 
sim time next is 5702400.0000, 
raw observation next is [23.1, 94.0, 1.0, 2.0, 0.5505829811972482, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 647286.0818777919, 647286.0818777919, 150696.1030139421], 
processed observation next is [0.0, 0.0, 0.41111111111111115, 0.94, 1.0, 1.0, 0.4649797395205336, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23117360067063997, 0.23117360067063997, 0.2898001981037348], 
reward next is 0.7102, 
noisyNet noise sample is [array([-0.42183736], dtype=float32), -0.023746021]. 
=============================================
[2019-03-23 21:18:49,813] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.9654179e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:18:49,822] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5834
[2019-03-23 21:18:49,826] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.46666666666667, 87.5, 1.0, 2.0, 0.4278328193513551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 524921.4351576674, 524921.4351576674, 132481.4344130966], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5730600.0000, 
sim time next is 5731200.0000, 
raw observation next is [21.5, 87.0, 1.0, 2.0, 0.4261064130373477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 523040.1732337791, 523040.1732337791, 132236.7576461], 
processed observation next is [0.0, 0.34782608695652173, 0.35185185185185186, 0.87, 1.0, 1.0, 0.3167933488539854, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1868000618692068, 0.1868000618692068, 0.2543014570117308], 
reward next is 0.7457, 
noisyNet noise sample is [array([-0.4203278], dtype=float32), 1.3792821]. 
=============================================
[2019-03-23 21:18:51,599] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.421204e-30 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:18:51,610] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1669
[2019-03-23 21:18:51,615] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.96666666666667, 62.0, 1.0, 2.0, 0.5384129084865275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 633363.1154420188, 633363.1154420188, 148714.0303334832], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5755200.0000, 
sim time next is 5755800.0000, 
raw observation next is [27.98333333333333, 62.0, 1.0, 2.0, 0.540726059850053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 635895.6502764587, 635895.6502764587, 149084.0841116886], 
processed observation next is [0.0, 0.6086956521739131, 0.5919753086419752, 0.62, 1.0, 1.0, 0.4532453093453011, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22710558938444952, 0.22710558938444952, 0.2867001617532473], 
reward next is 0.7133, 
noisyNet noise sample is [array([-0.41164425], dtype=float32), -0.22207405]. 
=============================================
[2019-03-23 21:18:52,549] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.175193e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:18:52,558] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6032
[2019-03-23 21:18:52,563] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.73333333333333, 76.66666666666667, 1.0, 2.0, 0.5608975985520462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 656377.8886854188, 656377.8886854188, 152281.4079255293], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5773200.0000, 
sim time next is 5773800.0000, 
raw observation next is [25.56666666666667, 77.33333333333333, 1.0, 2.0, 0.5576102316513055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 653332.2396659272, 653332.2396659269, 151768.3118516342], 
processed observation next is [0.0, 0.8260869565217391, 0.5024691358024692, 0.7733333333333333, 1.0, 1.0, 0.4733455138706018, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23333294273783117, 0.23333294273783103, 0.29186213817621964], 
reward next is 0.7081, 
noisyNet noise sample is [array([0.71685195], dtype=float32), -0.12264918]. 
=============================================
[2019-03-23 21:19:03,720] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.8180108e-22 1.0000000e+00 0.0000000e+00 2.0195957e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 21:19:03,725] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2583
[2019-03-23 21:19:03,735] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.91666666666667, 80.5, 1.0, 2.0, 0.472976958507797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 584141.5067039237, 584141.5067039242, 139329.4189319175], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5973000.0000, 
sim time next is 5973600.0000, 
raw observation next is [21.83333333333334, 81.0, 1.0, 2.0, 0.4343272330427351, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 536555.9515231199, 536555.9515231199, 133523.1124676533], 
processed observation next is [1.0, 0.13043478260869565, 0.36419753086419776, 0.81, 1.0, 1.0, 0.3265800393365894, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1916271255439714, 0.1916271255439714, 0.2567752162839486], 
reward next is 0.7432, 
noisyNet noise sample is [array([-0.8678866], dtype=float32), -1.2771131]. 
=============================================
[2019-03-23 21:19:04,446] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10000, global step 159638: loss -62.8638
[2019-03-23 21:19:04,449] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10000, global step 159638: learning rate 0.0005
[2019-03-23 21:19:04,555] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10000, global step 159686: loss -60.1144
[2019-03-23 21:19:04,561] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10000, global step 159687: learning rate 0.0005
[2019-03-23 21:19:04,805] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10000, global step 159810: loss -77.1558
[2019-03-23 21:19:04,806] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10000, global step 159810: learning rate 0.0005
[2019-03-23 21:19:04,862] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10000, global step 159835: loss -81.3800
[2019-03-23 21:19:04,865] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10000, global step 159835: learning rate 0.0005
[2019-03-23 21:19:04,869] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10000, global step 159842: loss -76.3493
[2019-03-23 21:19:04,871] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10000, global step 159842: learning rate 0.0005
[2019-03-23 21:19:05,119] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10000, global step 159963: loss -83.2758
[2019-03-23 21:19:05,119] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10000, global step 159963: loss -63.0840
[2019-03-23 21:19:05,122] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10000, global step 159964: learning rate 0.0005
[2019-03-23 21:19:05,119] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10000, global step 159963: loss -57.3038
[2019-03-23 21:19:05,125] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10000, global step 159965: learning rate 0.0005
[2019-03-23 21:19:05,129] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10000, global step 159967: loss -53.7222
[2019-03-23 21:19:05,134] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10000, global step 159967: learning rate 0.0005
[2019-03-23 21:19:05,141] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10000, global step 159968: learning rate 0.0005
[2019-03-23 21:19:05,203] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10000, global step 159996: loss -71.4151
[2019-03-23 21:19:05,205] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10000, global step 159998: learning rate 0.0005
[2019-03-23 21:19:05,254] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10000, global step 160022: loss -64.5535
[2019-03-23 21:19:05,255] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10000, global step 160023: learning rate 0.0005
[2019-03-23 21:19:05,324] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10000, global step 160064: loss -40.0033
[2019-03-23 21:19:05,328] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10000, global step 160065: learning rate 0.0005
[2019-03-23 21:19:05,341] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10000, global step 160070: loss -45.6307
[2019-03-23 21:19:05,343] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10000, global step 160070: learning rate 0.0005
[2019-03-23 21:19:05,635] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10000, global step 160213: loss -32.4001
[2019-03-23 21:19:05,639] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10000, global step 160214: learning rate 0.0005
[2019-03-23 21:19:05,677] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10000, global step 160234: loss -27.5205
[2019-03-23 21:19:05,678] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10000, global step 160234: learning rate 0.0005
[2019-03-23 21:19:05,941] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10000, global step 160371: loss -29.4875
[2019-03-23 21:19:05,944] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10000, global step 160371: learning rate 0.0005
[2019-03-23 21:19:05,952] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.8500831e-14 1.0000000e+00 2.7106394e-23 2.1193401e-18 5.8829832e-23], sum to 1.0000
[2019-03-23 21:19:05,961] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5312
[2019-03-23 21:19:05,971] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1588006.179942023 W.
[2019-03-23 21:19:05,980] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.0, 58.33333333333333, 1.0, 2.0, 0.76417202106343, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9956513670057785, 6.911199999999999, 6.9112, 121.9260426156618, 1588006.179942023, 1588006.179942024, 328882.1261932622], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6014400.0000, 
sim time next is 6015000.0000, 
raw observation next is [29.0, 58.16666666666666, 1.0, 2.0, 0.4582768029082195, 1.0, 1.0, 0.4582768029082195, 1.0, 2.0, 0.7295915952633854, 6.9112, 6.9112, 121.94756008, 1567704.399962983, 1567704.399962983, 323550.6298760413], 
processed observation next is [1.0, 0.6086956521739131, 0.6296296296296297, 0.5816666666666666, 1.0, 1.0, 0.3550914320335946, 1.0, 0.5, 0.3550914320335946, 1.0, 1.0, 0.6619894940792317, 0.0, 0.0, 0.8096049824067558, 0.5598944285582083, 0.5598944285582083, 0.6222127497616179], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.32048783], dtype=float32), 1.1995462]. 
=============================================
[2019-03-23 21:19:05,989] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[26.76353]
 [26.76353]
 [26.76353]
 [26.76353]
 [26.76353]], R is [[26.49589348]
 [26.59846878]
 [26.68150711]
 [26.76622391]
 [26.84844208]].
[2019-03-23 21:19:06,221] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.2004230e-12 1.0000000e+00 1.7747359e-20 1.5614655e-16 1.0649948e-21], sum to 1.0000
[2019-03-23 21:19:06,227] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6308
[2019-03-23 21:19:06,234] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1618703.048399651 W.
[2019-03-23 21:19:06,241] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.43333333333333, 67.33333333333334, 1.0, 2.0, 0.4731707835658461, 1.0, 2.0, 0.4731707835658461, 1.0, 2.0, 0.7533032975334129, 6.9112, 6.9112, 121.94756008, 1618703.048399651, 1618703.048399651, 330616.2248638554], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6003600.0000, 
sim time next is 6004200.0000, 
raw observation next is [27.71666666666667, 66.66666666666666, 1.0, 2.0, 0.4781722448366988, 1.0, 2.0, 0.4781722448366988, 1.0, 2.0, 0.7612657867628323, 6.911199999999999, 6.9112, 121.94756008, 1635828.558718082, 1635828.558718082, 333004.9561723855], 
processed observation next is [1.0, 0.4782608695652174, 0.5820987654320988, 0.6666666666666665, 1.0, 1.0, 0.378776481948451, 1.0, 1.0, 0.378776481948451, 1.0, 1.0, 0.7015822334535404, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5842244852564579, 0.5842244852564579, 0.6403941464853568], 
reward next is 0.3596, 
noisyNet noise sample is [array([0.09808463], dtype=float32), -0.19307368]. 
=============================================
[2019-03-23 21:19:06,362] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1463833e-11 1.0000000e+00 1.7536181e-20 4.4501994e-18 9.9834652e-22], sum to 1.0000
[2019-03-23 21:19:06,370] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9384
[2019-03-23 21:19:06,378] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.08333333333333, 59.66666666666667, 1.0, 2.0, 0.5191020835014246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 614117.1614733814, 614117.1614733814, 145736.0839963662], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6027000.0000, 
sim time next is 6027600.0000, 
raw observation next is [27.96666666666667, 60.33333333333334, 1.0, 2.0, 0.5208543608715525, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 616065.9925804767, 616065.9925804767, 146011.9151047106], 
processed observation next is [1.0, 0.782608695652174, 0.5913580246913581, 0.6033333333333334, 1.0, 1.0, 0.42958852484708626, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22002356877874168, 0.22002356877874168, 0.2807921444321358], 
reward next is 0.7192, 
noisyNet noise sample is [array([1.6010883], dtype=float32), 1.2604105]. 
=============================================
[2019-03-23 21:19:09,241] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.2663542e-23 1.0000000e+00 0.0000000e+00 1.0198524e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 21:19:09,246] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4927
[2019-03-23 21:19:09,255] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 82.0, 1.0, 2.0, 0.5341099516856982, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 634009.3364841038, 634009.3364841038, 148241.7047620619], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6073200.0000, 
sim time next is 6073800.0000, 
raw observation next is [24.25, 81.66666666666667, 1.0, 2.0, 0.5898776773317613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 700134.0591730981, 700134.0591730981, 157595.1093846333], 
processed observation next is [1.0, 0.30434782608695654, 0.4537037037037037, 0.8166666666666668, 1.0, 1.0, 0.5117591396806682, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25004787827610647, 0.25004787827610647, 0.30306751804737175], 
reward next is 0.6969, 
noisyNet noise sample is [array([-1.7397875], dtype=float32), 0.34676173]. 
=============================================
[2019-03-23 21:19:10,554] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.9834264e-13 1.0000000e+00 2.9917422e-22 1.0349031e-18 3.3085897e-22], sum to 1.0000
[2019-03-23 21:19:10,559] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9158
[2019-03-23 21:19:10,564] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1958388.713772658 W.
[2019-03-23 21:19:10,570] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.33333333333334, 52.66666666666667, 1.0, 2.0, 0.5723572034498767, 1.0, 1.0, 0.5723572034498767, 1.0, 2.0, 0.9112113082649679, 6.9112, 6.9112, 121.94756008, 1958388.713772658, 1958388.713772658, 380520.2095918813], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6097200.0000, 
sim time next is 6097800.0000, 
raw observation next is [30.46666666666667, 51.83333333333333, 1.0, 2.0, 0.8434415437793892, 1.0, 2.0, 0.8434415437793892, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260425546524, 1923920.78413066, 1923920.784130659, 362030.5647116243], 
processed observation next is [1.0, 0.5652173913043478, 0.6839506172839507, 0.5183333333333333, 1.0, 1.0, 0.8136208854516538, 1.0, 1.0, 0.8136208854516538, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621284150969, 0.68711456576095, 0.6871145657609496, 0.6962126244454313], 
reward next is 0.3038, 
noisyNet noise sample is [array([-0.3793672], dtype=float32), -0.7813043]. 
=============================================
[2019-03-23 21:19:20,632] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10500, global step 167551: loss 0.0041
[2019-03-23 21:19:20,635] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10500, global step 167552: learning rate 0.0005
[2019-03-23 21:19:20,832] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10500, global step 167644: loss 0.0697
[2019-03-23 21:19:20,837] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10500, global step 167645: learning rate 0.0005
[2019-03-23 21:19:21,109] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10500, global step 167784: loss 0.0360
[2019-03-23 21:19:21,111] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10500, global step 167784: learning rate 0.0005
[2019-03-23 21:19:21,224] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10500, global step 167843: loss 0.0231
[2019-03-23 21:19:21,230] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10500, global step 167843: learning rate 0.0005
[2019-03-23 21:19:21,305] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10500, global step 167882: loss 0.1126
[2019-03-23 21:19:21,306] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10500, global step 167882: learning rate 0.0005
[2019-03-23 21:19:21,311] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10500, global step 167885: loss 0.1489
[2019-03-23 21:19:21,312] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10500, global step 167885: learning rate 0.0005
[2019-03-23 21:19:21,373] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10500, global step 167918: loss 0.1114
[2019-03-23 21:19:21,374] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10500, global step 167920: learning rate 0.0005
[2019-03-23 21:19:21,475] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10500, global step 167966: loss 0.0073
[2019-03-23 21:19:21,477] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10500, global step 167967: learning rate 0.0005
[2019-03-23 21:19:21,582] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10500, global step 168017: loss 0.0429
[2019-03-23 21:19:21,585] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10500, global step 168018: learning rate 0.0005
[2019-03-23 21:19:21,710] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10500, global step 168081: loss 0.1566
[2019-03-23 21:19:21,711] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10500, global step 168081: loss 0.1883
[2019-03-23 21:19:21,715] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10500, global step 168084: learning rate 0.0005
[2019-03-23 21:19:21,716] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10500, global step 168084: learning rate 0.0005
[2019-03-23 21:19:21,821] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10500, global step 168137: loss 0.0001
[2019-03-23 21:19:21,822] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10500, global step 168137: learning rate 0.0005
[2019-03-23 21:19:21,835] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10500, global step 168144: loss 0.0003
[2019-03-23 21:19:21,837] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10500, global step 168145: learning rate 0.0005
[2019-03-23 21:19:21,862] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10500, global step 168159: loss 0.0003
[2019-03-23 21:19:21,864] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10500, global step 168159: learning rate 0.0005
[2019-03-23 21:19:22,045] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.023669e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:19:22,055] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9468
[2019-03-23 21:19:22,059] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.36666666666667, 87.33333333333334, 1.0, 2.0, 0.5750433126808678, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 670894.5574300095, 670894.5574300095, 154569.6681542604], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6313200.0000, 
sim time next is 6313800.0000, 
raw observation next is [24.33333333333333, 87.66666666666667, 1.0, 2.0, 0.5754261203286125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 671178.2816124414, 671178.2816124414, 154627.2458202479], 
processed observation next is [0.0, 0.043478260869565216, 0.45679012345678993, 0.8766666666666667, 1.0, 1.0, 0.4945549051531101, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2397065291473005, 0.2397065291473005, 0.29736008811586134], 
reward next is 0.7026, 
noisyNet noise sample is [array([-0.782651], dtype=float32), 1.2261776]. 
=============================================
[2019-03-23 21:19:22,060] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10500, global step 168250: loss 0.0173
[2019-03-23 21:19:22,062] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10500, global step 168250: learning rate 0.0005
[2019-03-23 21:19:22,226] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.265887e-32 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:19:22,233] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3103
[2019-03-23 21:19:22,238] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.73333333333333, 83.83333333333333, 1.0, 2.0, 0.5683444778887883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 664575.8375985255, 664575.837598525, 153506.0803658933], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6306600.0000, 
sim time next is 6307200.0000, 
raw observation next is [24.7, 84.0, 1.0, 2.0, 0.5676207622377275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 663858.251045723, 663858.251045723, 153390.069447801], 
processed observation next is [0.0, 0.0, 0.4703703703703703, 0.84, 1.0, 1.0, 0.48526281218777084, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23709223251632963, 0.23709223251632963, 0.2949809027842327], 
reward next is 0.7050, 
noisyNet noise sample is [array([0.49297276], dtype=float32), -1.5947928]. 
=============================================
[2019-03-23 21:19:22,521] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10500, global step 168479: loss 0.0163
[2019-03-23 21:19:22,522] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10500, global step 168479: learning rate 0.0005
[2019-03-23 21:19:35,747] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 21:19:35,749] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:19:35,749] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:19:35,750] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:19:35,750] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:19:35,751] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:19:35,753] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:19:35,755] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:19:35,754] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:19:35,757] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:19:35,758] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:19:35,767] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run8
[2019-03-23 21:19:35,768] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run8
[2019-03-23 21:19:35,790] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run8
[2019-03-23 21:19:35,791] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run8
[2019-03-23 21:19:35,813] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run8
[2019-03-23 21:19:43,313] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.11878757]
[2019-03-23 21:19:43,313] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.95, 38.5, 1.0, 2.0, 0.3751176471369673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 467474.8147864613, 467474.8147864618, 125225.3377607664]
[2019-03-23 21:19:43,314] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:19:43,316] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.189236e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.663733942501914
[2019-03-23 21:20:12,111] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.11878757]
[2019-03-23 21:20:12,113] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.33333333333334, 61.33333333333334, 1.0, 2.0, 0.5607430041104352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 656200.9401330429, 656200.9401330429, 152255.5915831457]
[2019-03-23 21:20:12,113] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:20:12,116] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.189236e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.44938661466347907
[2019-03-23 21:20:16,769] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.11878757]
[2019-03-23 21:20:16,770] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.8, 62.66666666666667, 1.0, 2.0, 0.5676086863799455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 657092.5991486618, 657092.5991486618, 153087.8121688741]
[2019-03-23 21:20:16,771] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:20:16,774] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.189236e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.04263913861671065
[2019-03-23 21:20:22,791] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.11878757]
[2019-03-23 21:20:22,792] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.95093819666667, 90.77592990000001, 1.0, 2.0, 0.5074271588448507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 602274.315502599, 602274.315502599, 143955.5955968762]
[2019-03-23 21:20:22,794] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:20:22,796] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.189236e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.965129934817405
[2019-03-23 21:20:24,738] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.11878757]
[2019-03-23 21:20:24,741] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.925905105, 53.800878455, 1.0, 2.0, 0.5417646197010717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 660277.46882963, 660277.46882963, 150088.19438186]
[2019-03-23 21:20:24,741] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:20:24,744] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.189236e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.7050343342082316
[2019-03-23 21:21:07,920] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.11878757]
[2019-03-23 21:21:07,921] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [19.33333333333334, 76.33333333333334, 1.0, 2.0, 0.2902460100931698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 371659.7699927638, 371659.7699927638, 114379.9724654135]
[2019-03-23 21:21:07,923] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:21:07,926] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.189236e-29 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.6230815288615845
[2019-03-23 21:21:14,493] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 21:21:14,687] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 21:21:14,811] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 21:21:14,956] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 21:21:15,155] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 21:21:16,171] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 175000, evaluation results [175000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 21:21:16,931] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.4040274e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:21:16,941] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0651
[2019-03-23 21:21:16,945] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.36666666666667, 82.66666666666667, 1.0, 2.0, 0.660406725485966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 752654.690192324, 752654.690192324, 168781.9056613451], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6559800.0000, 
sim time next is 6560400.0000, 
raw observation next is [26.33333333333334, 82.33333333333334, 1.0, 2.0, 0.6536380427297025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 744936.7852858426, 744936.7852858426, 167550.7283345227], 
processed observation next is [1.0, 0.9565217391304348, 0.5308641975308644, 0.8233333333333335, 1.0, 1.0, 0.5876643365829791, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2660488518878009, 0.2660488518878009, 0.3222129391048513], 
reward next is 0.6778, 
noisyNet noise sample is [array([-1.0907918], dtype=float32), -0.18220335]. 
=============================================
[2019-03-23 21:21:17,305] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11000, global step 175557: loss 0.0272
[2019-03-23 21:21:17,308] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11000, global step 175557: learning rate 0.0005
[2019-03-23 21:21:17,410] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11000, global step 175613: loss 0.0009
[2019-03-23 21:21:17,417] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11000, global step 175614: learning rate 0.0005
[2019-03-23 21:21:17,611] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.2489204e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:21:17,623] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5305
[2019-03-23 21:21:17,629] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.46666666666667, 41.16666666666666, 1.0, 2.0, 0.737784928338689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 934630.6456138123, 934630.6456138123, 186717.379517668], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6603000.0000, 
sim time next is 6603600.0000, 
raw observation next is [26.63333333333333, 40.33333333333334, 1.0, 2.0, 0.8054625884842693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1020327.648662016, 1020327.648662016, 200767.763243668], 
processed observation next is [1.0, 0.43478260869565216, 0.5419753086419752, 0.40333333333333343, 1.0, 1.0, 0.768407843433654, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3644027316650057, 0.3644027316650057, 0.38609185239166927], 
reward next is 0.6139, 
noisyNet noise sample is [array([1.0470413], dtype=float32), 0.5582012]. 
=============================================
[2019-03-23 21:21:17,779] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11000, global step 175791: loss 0.0646
[2019-03-23 21:21:17,784] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11000, global step 175791: learning rate 0.0005
[2019-03-23 21:21:17,795] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11000, global step 175795: loss 0.0663
[2019-03-23 21:21:17,804] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11000, global step 175797: learning rate 0.0005
[2019-03-23 21:21:17,825] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11000, global step 175806: loss 0.0002
[2019-03-23 21:21:17,828] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11000, global step 175807: learning rate 0.0005
[2019-03-23 21:21:18,073] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11000, global step 175933: loss 0.0214
[2019-03-23 21:21:18,079] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11000, global step 175933: learning rate 0.0005
[2019-03-23 21:21:18,109] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11000, global step 175948: loss 0.0379
[2019-03-23 21:21:18,116] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11000, global step 175949: learning rate 0.0005
[2019-03-23 21:21:18,141] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11000, global step 175962: loss 0.0966
[2019-03-23 21:21:18,144] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11000, global step 175962: loss 0.0696
[2019-03-23 21:21:18,145] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11000, global step 175962: learning rate 0.0005
[2019-03-23 21:21:18,148] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11000, global step 175962: learning rate 0.0005
[2019-03-23 21:21:18,253] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11000, global step 176018: loss 0.1232
[2019-03-23 21:21:18,255] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11000, global step 176019: learning rate 0.0005
[2019-03-23 21:21:18,474] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11000, global step 176120: loss 0.0585
[2019-03-23 21:21:18,476] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11000, global step 176120: learning rate 0.0005
[2019-03-23 21:21:18,571] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11000, global step 176172: loss 0.0219
[2019-03-23 21:21:18,573] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11000, global step 176172: learning rate 0.0005
[2019-03-23 21:21:18,653] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11000, global step 176208: loss 0.0658
[2019-03-23 21:21:18,655] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11000, global step 176208: learning rate 0.0005
[2019-03-23 21:21:18,707] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11000, global step 176239: loss 0.0693
[2019-03-23 21:21:18,711] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11000, global step 176240: learning rate 0.0005
[2019-03-23 21:21:18,716] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11000, global step 176243: loss 0.0267
[2019-03-23 21:21:18,719] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11000, global step 176243: learning rate 0.0005
[2019-03-23 21:21:19,117] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11000, global step 176437: loss 0.2663
[2019-03-23 21:21:19,118] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11000, global step 176438: learning rate 0.0005
[2019-03-23 21:21:19,699] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.67640166e-18 1.00000000e+00 2.34005146e-32 1.27693554e-26
 1.14168243e-31], sum to 1.0000
[2019-03-23 21:21:19,707] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6811
[2019-03-23 21:21:19,710] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.66666666666667, 28.66666666666666, 1.0, 2.0, 0.3490061868250482, 1.0, 1.0, 0.3490061868250482, 1.0, 2.0, 0.5768941044629676, 6.9112, 6.9112, 121.94756008, 1293650.105418029, 1293650.105418029, 273569.0721532321], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6627000.0000, 
sim time next is 6627600.0000, 
raw observation next is [29.8, 27.0, 1.0, 2.0, 0.9308709067241843, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.335153280283857, 6.9112, 121.9242295759678, 1392505.006275023, 1175406.262560806, 228909.4050998659], 
processed observation next is [1.0, 0.7391304347826086, 0.6592592592592593, 0.27, 1.0, 1.0, 0.9177034603859336, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.04239532802838566, 0.0, 0.8094500921219961, 0.49732321652679395, 0.41978795091457355, 0.440210394422819], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.31724676], dtype=float32), 0.5580449]. 
=============================================
[2019-03-23 21:21:20,492] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4047249e-27 1.0000000e+00 0.0000000e+00 2.1480215e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 21:21:20,503] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2533
[2019-03-23 21:21:20,510] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.4, 45.5, 1.0, 2.0, 0.2752256789636366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 354978.0535064289, 354978.0535064284, 112555.8276076939], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6658200.0000, 
sim time next is 6658800.0000, 
raw observation next is [23.3, 46.0, 1.0, 2.0, 0.2739588352551078, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 353346.3279128077, 353346.3279128081, 112405.0406513598], 
processed observation next is [1.0, 0.043478260869565216, 0.41851851851851857, 0.46, 1.0, 1.0, 0.1356652800656045, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12619511711171705, 0.1261951171117172, 0.21616353971415345], 
reward next is 0.7838, 
noisyNet noise sample is [array([0.04020089], dtype=float32), -1.3406254]. 
=============================================
[2019-03-23 21:21:21,897] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1614623e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:21:21,903] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8202
[2019-03-23 21:21:21,906] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.05, 46.5, 1.0, 2.0, 0.3319409276759566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 428195.9636084027, 428195.9636084027, 118687.3253338917], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6661800.0000, 
sim time next is 6662400.0000, 
raw observation next is [23.03333333333333, 46.33333333333333, 1.0, 2.0, 0.3050017611553217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 393444.0332392146, 393444.0332392146, 114332.665448672], 
processed observation next is [1.0, 0.08695652173913043, 0.4086419753086419, 0.46333333333333326, 1.0, 1.0, 0.1726211442325258, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14051572615686236, 0.14051572615686236, 0.2198705104782154], 
reward next is 0.7801, 
noisyNet noise sample is [array([0.8634078], dtype=float32), -0.29827586]. 
=============================================
[2019-03-23 21:21:30,135] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.1400238e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:21:30,147] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2486
[2019-03-23 21:21:30,152] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.58333333333334, 72.5, 1.0, 2.0, 0.472693027146266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 570990.2293020121, 570990.2293020117, 138920.7494028698], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6814200.0000, 
sim time next is 6814800.0000, 
raw observation next is [24.5, 73.0, 1.0, 2.0, 0.4747483954741283, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 573521.5870802063, 573521.5870802058, 139236.9184631214], 
processed observation next is [1.0, 0.9130434782608695, 0.46296296296296297, 0.73, 1.0, 1.0, 0.37470047080253366, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2048291382429308, 0.20482913824293064, 0.2677633047367719], 
reward next is 0.7322, 
noisyNet noise sample is [array([2.3042653], dtype=float32), -1.2577667]. 
=============================================
[2019-03-23 21:21:31,051] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2088755e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:21:31,058] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2617
[2019-03-23 21:21:31,062] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.4, 76.0, 1.0, 2.0, 0.39191182204633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 485315.3502119426, 485315.3502119426, 127479.3294077478], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6848400.0000, 
sim time next is 6849000.0000, 
raw observation next is [22.5, 76.0, 1.0, 2.0, 0.3954570203674297, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 489044.6079551654, 489044.6079551654, 127959.5200885413], 
processed observation next is [0.0, 0.2608695652173913, 0.3888888888888889, 0.76, 1.0, 1.0, 0.2803059766278925, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1746587885554162, 0.1746587885554162, 0.24607600017027173], 
reward next is 0.7539, 
noisyNet noise sample is [array([-1.0251672], dtype=float32), 1.2517972]. 
=============================================
[2019-03-23 21:21:31,090] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[71.3059]
 [71.3059]
 [71.3059]
 [71.3059]
 [71.3059]], R is [[71.34676361]
 [71.38813782]
 [71.42999268]
 [71.47228241]
 [71.51489258]].
[2019-03-23 21:21:33,627] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11500, global step 183536: loss 0.1505
[2019-03-23 21:21:33,630] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11500, global step 183536: learning rate 0.0005
[2019-03-23 21:21:33,935] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11500, global step 183691: loss 0.1098
[2019-03-23 21:21:33,937] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11500, global step 183692: learning rate 0.0005
[2019-03-23 21:21:34,072] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11500, global step 183756: loss 0.0001
[2019-03-23 21:21:34,074] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11500, global step 183756: learning rate 0.0005
[2019-03-23 21:21:34,125] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11500, global step 183788: loss 0.0269
[2019-03-23 21:21:34,129] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11500, global step 183789: learning rate 0.0005
[2019-03-23 21:21:34,251] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11500, global step 183847: loss 0.1589
[2019-03-23 21:21:34,255] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11500, global step 183847: learning rate 0.0005
[2019-03-23 21:21:34,353] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11500, global step 183897: loss 0.0167
[2019-03-23 21:21:34,359] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11500, global step 183897: learning rate 0.0005
[2019-03-23 21:21:34,376] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11500, global step 183907: loss 0.0094
[2019-03-23 21:21:34,379] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11500, global step 183908: learning rate 0.0005
[2019-03-23 21:21:34,509] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11500, global step 183973: loss 0.0463
[2019-03-23 21:21:34,510] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11500, global step 183973: learning rate 0.0005
[2019-03-23 21:21:34,557] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11500, global step 183994: loss 0.1899
[2019-03-23 21:21:34,560] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11500, global step 183994: learning rate 0.0005
[2019-03-23 21:21:34,635] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11500, global step 184033: loss 0.0384
[2019-03-23 21:21:34,638] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11500, global step 184033: learning rate 0.0005
[2019-03-23 21:21:34,857] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11500, global step 184140: loss 0.1188
[2019-03-23 21:21:34,860] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11500, global step 184140: learning rate 0.0005
[2019-03-23 21:21:34,876] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11500, global step 184150: loss 0.0834
[2019-03-23 21:21:34,877] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11500, global step 184150: learning rate 0.0005
[2019-03-23 21:21:35,018] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11500, global step 184219: loss 0.0100
[2019-03-23 21:21:35,020] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11500, global step 184219: learning rate 0.0005
[2019-03-23 21:21:35,083] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11500, global step 184251: loss 0.0825
[2019-03-23 21:21:35,087] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11500, global step 184252: learning rate 0.0005
[2019-03-23 21:21:35,090] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11500, global step 184254: loss 0.1471
[2019-03-23 21:21:35,092] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11500, global step 184254: learning rate 0.0005
[2019-03-23 21:21:35,329] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11500, global step 184369: loss 0.0009
[2019-03-23 21:21:35,331] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11500, global step 184369: learning rate 0.0005
[2019-03-23 21:21:41,582] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.5515997e-25 1.0000000e+00 0.0000000e+00 1.5879033e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 21:21:41,592] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9105
[2019-03-23 21:21:41,596] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.68333333333334, 85.66666666666667, 1.0, 2.0, 0.5236880976788152, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 642792.285785404, 642792.2857854036, 147252.6986156656], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7024200.0000, 
sim time next is 7024800.0000, 
raw observation next is [21.76666666666667, 85.33333333333334, 1.0, 2.0, 0.5411091741482005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 663680.1257801737, 663680.1257801737, 150097.7586922327], 
processed observation next is [1.0, 0.30434782608695654, 0.3617283950617285, 0.8533333333333334, 1.0, 1.0, 0.45370139779547675, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23702861635006203, 0.23702861635006203, 0.2886495359466013], 
reward next is 0.7114, 
noisyNet noise sample is [array([-1.3396158], dtype=float32), 0.2408165]. 
=============================================
[2019-03-23 21:21:49,867] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12000, global step 191534: loss 0.2082
[2019-03-23 21:21:49,868] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12000, global step 191534: learning rate 0.0005
[2019-03-23 21:21:50,270] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12000, global step 191734: loss 0.0426
[2019-03-23 21:21:50,272] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12000, global step 191735: learning rate 0.0005
[2019-03-23 21:21:50,378] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12000, global step 191784: loss 0.0004
[2019-03-23 21:21:50,384] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12000, global step 191785: learning rate 0.0005
[2019-03-23 21:21:50,401] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12000, global step 191793: loss 0.0011
[2019-03-23 21:21:50,406] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12000, global step 191794: learning rate 0.0005
[2019-03-23 21:21:50,414] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12000, global step 191798: loss 0.0268
[2019-03-23 21:21:50,416] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12000, global step 191798: learning rate 0.0005
[2019-03-23 21:21:50,458] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12000, global step 191822: loss 0.0670
[2019-03-23 21:21:50,459] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12000, global step 191822: learning rate 0.0005
[2019-03-23 21:21:50,608] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12000, global step 191898: loss 0.0198
[2019-03-23 21:21:50,613] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12000, global step 191900: learning rate 0.0005
[2019-03-23 21:21:50,687] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12000, global step 191936: loss 0.0219
[2019-03-23 21:21:50,690] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12000, global step 191938: learning rate 0.0005
[2019-03-23 21:21:50,830] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12000, global step 192005: loss 0.1451
[2019-03-23 21:21:50,836] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12000, global step 192005: learning rate 0.0005
[2019-03-23 21:21:50,971] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12000, global step 192071: loss 0.0978
[2019-03-23 21:21:50,974] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12000, global step 192071: learning rate 0.0005
[2019-03-23 21:21:51,108] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12000, global step 192139: loss 0.0831
[2019-03-23 21:21:51,111] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12000, global step 192140: learning rate 0.0005
[2019-03-23 21:21:51,167] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12000, global step 192169: loss 0.0419
[2019-03-23 21:21:51,171] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12000, global step 192170: learning rate 0.0005
[2019-03-23 21:21:51,237] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12000, global step 192201: loss 0.0368
[2019-03-23 21:21:51,241] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12000, global step 192201: learning rate 0.0005
[2019-03-23 21:21:51,327] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12000, global step 192244: loss 0.0761
[2019-03-23 21:21:51,332] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12000, global step 192245: learning rate 0.0005
[2019-03-23 21:21:51,339] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12000, global step 192252: loss 0.0638
[2019-03-23 21:21:51,341] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12000, global step 192252: learning rate 0.0005
[2019-03-23 21:21:51,716] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12000, global step 192440: loss 0.1995
[2019-03-23 21:21:51,722] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12000, global step 192440: learning rate 0.0005
[2019-03-23 21:21:54,842] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.7699664e-26 1.0000000e+00 0.0000000e+00 2.8806667e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 21:21:54,849] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1144
[2019-03-23 21:21:54,855] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.45, 87.0, 1.0, 2.0, 0.377824482356769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 470804.9671626744, 470804.9671626744, 125594.9737258816], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7270200.0000, 
sim time next is 7270800.0000, 
raw observation next is [20.43333333333333, 87.33333333333334, 1.0, 2.0, 0.3778095166899872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 470637.4411611676, 470637.4411611676, 125589.9885384235], 
processed observation next is [1.0, 0.13043478260869565, 0.31234567901234556, 0.8733333333333334, 1.0, 1.0, 0.25929704367855616, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1680848004147027, 0.1680848004147027, 0.2415192087277375], 
reward next is 0.7585, 
noisyNet noise sample is [array([-2.2419767], dtype=float32), -0.058085445]. 
=============================================
[2019-03-23 21:22:04,523] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.845845e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:22:04,528] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1909
[2019-03-23 21:22:04,531] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.01666666666667, 91.83333333333333, 1.0, 2.0, 0.3801742025811176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 472726.0505190501, 472726.0505190501, 125897.2362208883], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7433400.0000, 
sim time next is 7434000.0000, 
raw observation next is [20.0, 92.0, 1.0, 2.0, 0.3798584749638689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 472314.5424131319, 472314.5424131319, 125853.4557543542], 
processed observation next is [0.0, 0.043478260869565216, 0.2962962962962963, 0.92, 1.0, 1.0, 0.2617362797188915, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16868376514754713, 0.16868376514754713, 0.24202587645068116], 
reward next is 0.7580, 
noisyNet noise sample is [array([0.8080054], dtype=float32), 0.5264477]. 
=============================================
[2019-03-23 21:22:04,556] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[76.17158]
 [76.17158]
 [76.17158]
 [76.17158]
 [76.17158]], R is [[76.16783905]
 [76.16404724]
 [76.16016388]
 [76.15614319]
 [76.15200043]].
[2019-03-23 21:22:06,099] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12500, global step 199511: loss 0.0556
[2019-03-23 21:22:06,101] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12500, global step 199512: learning rate 0.0005
[2019-03-23 21:22:06,443] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12500, global step 199697: loss 0.1237
[2019-03-23 21:22:06,444] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12500, global step 199698: learning rate 0.0005
[2019-03-23 21:22:06,484] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12500, global step 199719: loss 0.0716
[2019-03-23 21:22:06,485] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12500, global step 199719: learning rate 0.0005
[2019-03-23 21:22:06,684] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12500, global step 199817: loss 0.0759
[2019-03-23 21:22:06,685] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12500, global step 199817: learning rate 0.0005
[2019-03-23 21:22:06,695] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12500, global step 199821: loss 0.1034
[2019-03-23 21:22:06,698] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12500, global step 199823: learning rate 0.0005
[2019-03-23 21:22:06,801] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12500, global step 199882: loss 0.0570
[2019-03-23 21:22:06,805] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12500, global step 199882: learning rate 0.0005
[2019-03-23 21:22:06,815] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12500, global step 199887: loss 0.0438
[2019-03-23 21:22:06,816] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12500, global step 199888: learning rate 0.0005
[2019-03-23 21:22:06,821] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12500, global step 199888: loss 0.0034
[2019-03-23 21:22:06,823] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12500, global step 199890: learning rate 0.0005
[2019-03-23 21:22:07,040] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 21:22:07,042] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:22:07,043] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:22:07,043] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:22:07,044] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:22:07,045] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:22:07,044] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:22:07,046] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:22:07,048] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:22:07,049] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:22:07,049] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:22:07,059] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run9
[2019-03-23 21:22:07,060] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run9
[2019-03-23 21:22:07,079] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run9
[2019-03-23 21:22:07,103] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run9
[2019-03-23 21:22:07,145] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run9
[2019-03-23 21:22:16,027] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.20971371]
[2019-03-23 21:22:16,028] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.84618927333333, 54.217955685, 1.0, 2.0, 0.3186414402364994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 406520.8960370411, 406520.8960370406, 117908.7902024689]
[2019-03-23 21:22:16,032] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:22:16,034] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.1201372e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.962651913891729
[2019-03-23 21:22:35,575] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.20971371]
[2019-03-23 21:22:35,577] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.0, 66.0, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.494025006375399, 6.9112, 121.923645294427, 1461467.344093486, 1163014.716840133, 245585.4518010139]
[2019-03-23 21:22:35,579] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:22:35,580] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.1201372e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.5257514433388654
[2019-03-23 21:22:35,581] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1461467.344093486 W.
[2019-03-23 21:23:10,607] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.20971371]
[2019-03-23 21:23:10,610] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.75, 88.5, 1.0, 2.0, 0.7891603373393773, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260425360185, 899479.168564202, 899479.168564202, 193706.5197606758]
[2019-03-23 21:23:10,612] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:23:10,614] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.1201372e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.48566540406521097
[2019-03-23 21:23:45,885] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 21:23:45,893] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 21:23:46,061] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 21:23:46,168] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 21:23:46,303] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 21:23:47,320] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 200000, evaluation results [200000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 21:23:47,467] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12500, global step 200072: loss 0.0008
[2019-03-23 21:23:47,474] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12500, global step 200073: learning rate 0.0005
[2019-03-23 21:23:47,505] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12500, global step 200087: loss 0.0001
[2019-03-23 21:23:47,509] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12500, global step 200087: learning rate 0.0005
[2019-03-23 21:23:47,594] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12500, global step 200129: loss 0.0491
[2019-03-23 21:23:47,597] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12500, global step 200130: learning rate 0.0005
[2019-03-23 21:23:47,630] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12500, global step 200145: loss 0.1212
[2019-03-23 21:23:47,634] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12500, global step 200146: learning rate 0.0005
[2019-03-23 21:23:47,674] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12500, global step 200163: loss 0.0716
[2019-03-23 21:23:47,677] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12500, global step 200163: learning rate 0.0005
[2019-03-23 21:23:47,853] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12500, global step 200252: loss 0.0005
[2019-03-23 21:23:47,854] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12500, global step 200252: learning rate 0.0005
[2019-03-23 21:23:47,956] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12500, global step 200305: loss 0.0606
[2019-03-23 21:23:47,961] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12500, global step 200305: learning rate 0.0005
[2019-03-23 21:23:48,175] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12500, global step 200410: loss 0.0019
[2019-03-23 21:23:48,178] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12500, global step 200411: learning rate 0.0005
[2019-03-23 21:23:48,799] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.2565594e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:23:48,810] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6203
[2019-03-23 21:23:48,816] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.2, 96.0, 1.0, 2.0, 0.4538887796130949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 550094.4537530483, 550094.4537530483, 136135.4869646743], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7520400.0000, 
sim time next is 7521000.0000, 
raw observation next is [21.15, 96.0, 1.0, 2.0, 0.4521709072016236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 548422.7231916204, 548422.7231916204, 135891.4139870474], 
processed observation next is [0.0, 0.043478260869565216, 0.33888888888888885, 0.96, 1.0, 1.0, 0.3478225085733615, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19586525828272158, 0.19586525828272158, 0.26132964228278344], 
reward next is 0.7387, 
noisyNet noise sample is [array([-0.6439786], dtype=float32), -0.17800735]. 
=============================================
[2019-03-23 21:23:48,838] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[72.41511]
 [72.41511]
 [72.41511]
 [72.41511]
 [72.41511]], R is [[72.42962646]
 [72.44352722]
 [72.45664215]
 [72.46907043]
 [72.48107147]].
[2019-03-23 21:23:51,163] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.569491e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:23:51,171] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2540
[2019-03-23 21:23:51,179] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.88333333333334, 62.0, 1.0, 2.0, 0.5346325100913126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 629579.1059708699, 629579.1059708699, 148125.619177783], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7575000.0000, 
sim time next is 7575600.0000, 
raw observation next is [27.76666666666667, 62.0, 1.0, 2.0, 0.5300227987728848, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 625425.2358546399, 625425.2358546399, 147429.9848112595], 
processed observation next is [0.0, 0.6956521739130435, 0.5839506172839507, 0.62, 1.0, 1.0, 0.4405033318724819, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2233661556623714, 0.2233661556623714, 0.2835192015601144], 
reward next is 0.7165, 
noisyNet noise sample is [array([-1.7793986], dtype=float32), -1.2419403]. 
=============================================
[2019-03-23 21:23:52,376] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.293119e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:23:52,384] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8131
[2019-03-23 21:23:52,391] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.96666666666667, 77.33333333333334, 1.0, 2.0, 0.5161157677850269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 611864.2530964919, 611864.2530964919, 145309.0092605137], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7586400.0000, 
sim time next is 7587000.0000, 
raw observation next is [24.8, 78.5, 1.0, 2.0, 0.5162448837938803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 611921.5841124976, 611921.5841124976, 145325.8971434121], 
processed observation next is [0.0, 0.8260869565217391, 0.4740740740740741, 0.785, 1.0, 1.0, 0.4241010521355718, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2185434228973206, 0.2185434228973206, 0.27947287912194635], 
reward next is 0.7205, 
noisyNet noise sample is [array([0.8931571], dtype=float32), 0.3138235]. 
=============================================
[2019-03-23 21:23:52,405] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[77.5999]
 [77.5999]
 [77.5999]
 [77.5999]
 [77.5999]], R is [[77.54442596]
 [77.4895401 ]
 [77.43525696]
 [77.38162231]
 [77.32857513]].
[2019-03-23 21:23:52,856] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.84295e-32 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00], sum to 1.0000
[2019-03-23 21:23:52,864] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8529
[2019-03-23 21:23:52,867] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.1, 83.0, 1.0, 2.0, 0.51758781431491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 613976.1040458686, 613976.1040458686, 145558.3927005146], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7590600.0000, 
sim time next is 7591200.0000, 
raw observation next is [24.03333333333333, 83.33333333333334, 1.0, 2.0, 0.515677485915133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 611933.3422622832, 611933.3422622832, 145261.8125859998], 
processed observation next is [0.0, 0.8695652173913043, 0.4456790123456789, 0.8333333333333335, 1.0, 1.0, 0.42342557847039636, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2185476222365297, 0.2185476222365297, 0.27934963958846115], 
reward next is 0.7207, 
noisyNet noise sample is [array([-0.31494847], dtype=float32), -1.2237434]. 
=============================================
[2019-03-23 21:23:55,263] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.651239e-23 1.000000e+00 0.000000e+00 7.054523e-33 0.000000e+00], sum to 1.0000
[2019-03-23 21:23:55,271] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3315
[2019-03-23 21:23:55,274] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.26666666666667, 81.33333333333334, 1.0, 2.0, 0.37212392237855, 1.0, 1.0, 0.37212392237855, 1.0, 1.0, 0.5931261097588101, 6.9112, 6.9112, 121.94756008, 1289145.292360622, 1289145.292360622, 285149.220555908], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7639800.0000, 
sim time next is 7640400.0000, 
raw observation next is [24.53333333333333, 80.66666666666667, 1.0, 2.0, 1.001486398375512, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.3392770964702, 6.9112, 121.924215250113, 1395381.882746093, 1176171.433720654, 242938.9332114728], 
processed observation next is [1.0, 0.43478260869565216, 0.46419753086419746, 0.8066666666666668, 1.0, 1.0, 1.0017695218756095, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.042807709647019986, 0.0, 0.8094499970132181, 0.4983506724093189, 0.42006122632880505, 0.4671902561759092], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6555977], dtype=float32), 1.0865862]. 
=============================================
[2019-03-23 21:24:01,016] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.03120775e-16 1.00000000e+00 4.77655547e-32 8.42294984e-27
 8.77538154e-32], sum to 1.0000
[2019-03-23 21:24:01,024] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0356
[2019-03-23 21:24:01,031] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1479186.446921241 W.
[2019-03-23 21:24:01,034] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.46666666666667, 47.0, 1.0, 2.0, 0.6291993231005819, 1.0, 2.0, 0.6291993231005819, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1479186.446921241, 1479186.446921242, 280314.0370951609], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7742400.0000, 
sim time next is 7743000.0000, 
raw observation next is [29.43333333333333, 47.5, 1.0, 2.0, 0.6506700631057839, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9683242999559858, 6.9112, 6.9112, 121.9260426156618, 1484864.211221624, 1484864.211221624, 302200.6698300762], 
processed observation next is [1.0, 0.6086956521739131, 0.6456790123456789, 0.475, 1.0, 1.0, 0.5841310275068856, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9604053749449822, 0.0, 0.0, 0.8094621288201359, 0.5303086468648657, 0.5303086468648657, 0.5811551342886081], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.17975652], dtype=float32), -0.0791574]. 
=============================================
[2019-03-23 21:24:01,053] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[42.372242]
 [42.372242]
 [42.372242]
 [42.372242]
 [42.372242]], R is [[41.94852066]
 [41.98997116]
 [41.97691727]
 [41.55714798]
 [41.14157867]].
[2019-03-23 21:24:02,754] A3C_AGENT_WORKER-Thread-13 INFO:Local step 13000, global step 207542: loss 0.0441
[2019-03-23 21:24:02,758] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 13000, global step 207543: learning rate 0.0005
[2019-03-23 21:24:02,993] A3C_AGENT_WORKER-Thread-18 INFO:Local step 13000, global step 207654: loss 0.0620
[2019-03-23 21:24:02,994] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 13000, global step 207654: learning rate 0.0005
[2019-03-23 21:24:02,995] A3C_AGENT_WORKER-Thread-15 INFO:Local step 13000, global step 207654: loss 0.0413
[2019-03-23 21:24:02,997] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 13000, global step 207654: learning rate 0.0005
[2019-03-23 21:24:03,231] A3C_AGENT_WORKER-Thread-9 INFO:Local step 13000, global step 207772: loss 0.1030
[2019-03-23 21:24:03,238] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 13000, global step 207772: learning rate 0.0005
[2019-03-23 21:24:03,266] A3C_AGENT_WORKER-Thread-20 INFO:Local step 13000, global step 207790: loss 0.0670
[2019-03-23 21:24:03,269] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 13000, global step 207790: learning rate 0.0005
[2019-03-23 21:24:03,367] A3C_AGENT_WORKER-Thread-16 INFO:Local step 13000, global step 207838: loss 0.0111
[2019-03-23 21:24:03,370] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 13000, global step 207838: learning rate 0.0005
[2019-03-23 21:24:03,480] A3C_AGENT_WORKER-Thread-11 INFO:Local step 13000, global step 207899: loss 0.0142
[2019-03-23 21:24:03,485] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 13000, global step 207900: learning rate 0.0005
[2019-03-23 21:24:03,493] A3C_AGENT_WORKER-Thread-19 INFO:Local step 13000, global step 207901: loss 0.0265
[2019-03-23 21:24:03,495] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 13000, global step 207901: learning rate 0.0005
[2019-03-23 21:24:03,900] A3C_AGENT_WORKER-Thread-2 INFO:Local step 13000, global step 208107: loss 0.1505
[2019-03-23 21:24:03,905] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 13000, global step 208108: learning rate 0.0005
[2019-03-23 21:24:03,930] A3C_AGENT_WORKER-Thread-10 INFO:Local step 13000, global step 208124: loss 0.1694
[2019-03-23 21:24:03,933] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 13000, global step 208124: learning rate 0.0005
[2019-03-23 21:24:03,942] A3C_AGENT_WORKER-Thread-3 INFO:Local step 13000, global step 208129: loss 0.1132
[2019-03-23 21:24:03,944] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 13000, global step 208130: learning rate 0.0005
[2019-03-23 21:24:03,973] A3C_AGENT_WORKER-Thread-21 INFO:Local step 13000, global step 208144: loss 0.0811
[2019-03-23 21:24:03,976] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 13000, global step 208144: learning rate 0.0005
[2019-03-23 21:24:04,111] A3C_AGENT_WORKER-Thread-14 INFO:Local step 13000, global step 208214: loss 0.0781
[2019-03-23 21:24:04,115] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 13000, global step 208215: learning rate 0.0005
[2019-03-23 21:24:04,156] A3C_AGENT_WORKER-Thread-22 INFO:Local step 13000, global step 208234: loss 0.0987
[2019-03-23 21:24:04,161] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 13000, global step 208234: learning rate 0.0005
[2019-03-23 21:24:04,312] A3C_AGENT_WORKER-Thread-12 INFO:Local step 13000, global step 208309: loss 0.0555
[2019-03-23 21:24:04,315] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 13000, global step 208309: learning rate 0.0005
[2019-03-23 21:24:04,553] A3C_AGENT_WORKER-Thread-17 INFO:Local step 13000, global step 208430: loss 0.1164
[2019-03-23 21:24:04,558] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 13000, global step 208432: learning rate 0.0005
[2019-03-23 21:24:07,085] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0777504e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:24:07,092] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2984
[2019-03-23 21:24:07,098] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.75, 85.5, 1.0, 2.0, 0.4114172587218946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 511613.6507919726, 511613.6507919726, 130279.1432415095], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7876200.0000, 
sim time next is 7876800.0000, 
raw observation next is [20.6, 86.0, 1.0, 2.0, 0.4009683936533078, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 499200.724612508, 499200.724612508, 128806.3900835369], 
processed observation next is [1.0, 0.17391304347826086, 0.3185185185185186, 0.86, 1.0, 1.0, 0.2868671353015569, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17828597307589572, 0.17828597307589572, 0.24770459631449404], 
reward next is 0.7523, 
noisyNet noise sample is [array([-1.308343], dtype=float32), -0.58235]. 
=============================================
[2019-03-23 21:24:07,552] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.2586054e-26 1.0000000e+00 0.0000000e+00 7.4267798e-38 0.0000000e+00], sum to 1.0000
[2019-03-23 21:24:07,562] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5150
[2019-03-23 21:24:07,568] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.06666666666667, 88.0, 1.0, 2.0, 0.3876767349954444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 484488.8662833261, 484488.8662833261, 126980.6138106732], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7879200.0000, 
sim time next is 7879800.0000, 
raw observation next is [19.93333333333333, 88.5, 1.0, 2.0, 0.3816554851367576, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 477415.2927029453, 477415.2927029448, 126155.4848403371], 
processed observation next is [1.0, 0.17391304347826086, 0.293827160493827, 0.885, 1.0, 1.0, 0.26387557754375907, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17050546167962333, 0.17050546167962313, 0.24260670161603287], 
reward next is 0.7574, 
noisyNet noise sample is [array([0.8408638], dtype=float32), -1.7999251]. 
=============================================
[2019-03-23 21:24:11,791] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:24:11,791] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:24:11,792] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run2
[2019-03-23 21:24:11,988] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:24:11,988] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:24:11,991] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run2
[2019-03-23 21:24:12,070] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:24:12,070] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:24:12,071] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run2
[2019-03-23 21:24:12,237] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:24:12,237] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:24:12,239] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run2
[2019-03-23 21:24:12,349] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:24:12,349] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:24:12,350] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run2
[2019-03-23 21:24:12,480] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:24:12,480] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:24:12,481] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:24:12,481] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:24:12,482] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run2
[2019-03-23 21:24:12,511] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:24:12,512] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:24:12,513] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run2
[2019-03-23 21:24:12,555] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run2
[2019-03-23 21:24:12,647] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:24:12,647] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:24:12,649] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run2
[2019-03-23 21:24:12,678] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:24:12,679] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:24:12,680] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run2
[2019-03-23 21:24:12,678] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:24:12,707] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:24:12,706] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:24:12,721] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:24:12,715] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:24:12,722] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:24:12,723] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run2
[2019-03-23 21:24:12,708] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run2
[2019-03-23 21:24:12,831] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run2
[2019-03-23 21:24:12,857] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:24:12,858] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:24:12,859] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run2
[2019-03-23 21:24:12,889] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:24:12,889] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:24:12,891] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run2
[2019-03-23 21:24:12,921] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:24:12,922] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:24:12,924] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run2
[2019-03-23 21:24:14,707] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.94296e-25 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00], sum to 1.0000
[2019-03-23 21:24:14,713] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9651
[2019-03-23 21:24:14,719] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.63333333333333, 75.0, 1.0, 2.0, 0.2692745886659936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 347346.6718483305, 347346.6718483309, 111197.9572949527], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6000.0000, 
sim time next is 6600.0000, 
raw observation next is [18.61666666666667, 75.0, 1.0, 2.0, 0.2676749722897908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 345282.8161442537, 345282.8161442537, 110722.9398107293], 
processed observation next is [1.0, 0.043478260869565216, 0.24506172839506188, 0.75, 1.0, 1.0, 0.12818449082117955, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.12331529148009061, 0.12331529148009061, 0.21292873040524865], 
reward next is 0.7871, 
noisyNet noise sample is [array([2.364744], dtype=float32), -1.7621124]. 
=============================================
[2019-03-23 21:24:16,789] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.9457467e-21 1.0000000e+00 2.0458092e-38 1.3678380e-32 4.4752131e-38], sum to 1.0000
[2019-03-23 21:24:16,795] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4446
[2019-03-23 21:24:16,798] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.18333333333334, 38.83333333333334, 1.0, 2.0, 0.5000503458003935, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8298392255859242, 6.911200000000001, 6.9112, 121.9258091803903, 1239871.750516851, 1239871.75051685, 252877.4377057701], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 43800.0000, 
sim time next is 44400.0000, 
raw observation next is [28.36666666666667, 38.66666666666667, 1.0, 2.0, 0.7801458916255458, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260425444808, 973407.3167852402, 973407.3167852402, 195173.4859431832], 
processed observation next is [1.0, 0.5217391304347826, 0.606172839506173, 0.3866666666666667, 1.0, 1.0, 0.7382689186018403, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.809462128347568, 0.3476454702804429, 0.3476454702804429, 0.3753336268138138], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3798078], dtype=float32), -0.9377447]. 
=============================================
[2019-03-23 21:24:24,020] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.003347e-30 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:24:24,027] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0627
[2019-03-23 21:24:24,033] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.9, 14.0, 1.0, 2.0, 0.3252522671312516, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 419573.9939030354, 419573.9939030349, 98567.28169610891], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 176400.0000, 
sim time next is 177000.0000, 
raw observation next is [27.65, 14.5, 1.0, 2.0, 0.3235100725565564, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 417325.9590405229, 417325.9590405229, 98182.76276014521], 
processed observation next is [0.0, 0.043478260869565216, 0.5796296296296296, 0.145, 1.0, 1.0, 0.19465484828161475, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14904498537161534, 0.14904498537161534, 0.18881300530797157], 
reward next is 0.8112, 
noisyNet noise sample is [array([-0.8007185], dtype=float32), -0.33810523]. 
=============================================
[2019-03-23 21:24:24,059] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[88.70095]
 [88.70095]
 [88.70095]
 [88.70095]
 [88.70095]], R is [[88.6251297 ]
 [88.54932404]
 [88.47312927]
 [88.39651489]
 [88.31947327]].
[2019-03-23 21:24:27,572] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.1019184e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:24:27,581] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8738
[2019-03-23 21:24:27,584] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.03333333333333, 39.33333333333334, 1.0, 2.0, 0.3058587372962785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 393567.2671975353, 393567.2671975353, 116296.4946495438], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 253200.0000, 
sim time next is 253800.0000, 
raw observation next is [24.7, 40.5, 1.0, 2.0, 0.3026470685052543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 389618.7878034792, 389618.7878034792, 115895.871277462], 
processed observation next is [0.0, 0.9565217391304348, 0.4703703703703703, 0.405, 1.0, 1.0, 0.1698179386967313, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13914956707267115, 0.13914956707267115, 0.2228766755335808], 
reward next is 0.7771, 
noisyNet noise sample is [array([0.4312191], dtype=float32), 2.1658444]. 
=============================================
[2019-03-23 21:24:34,869] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.501131e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:24:34,875] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0912
[2019-03-23 21:24:34,879] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.65, 36.5, 1.0, 2.0, 0.6923815796424679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 890324.1815792727, 890324.1815792727, 177791.4373056368], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 376200.0000, 
sim time next is 376800.0000, 
raw observation next is [25.83333333333334, 36.0, 1.0, 2.0, 0.6509779399814067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 836608.1421276532, 836608.1421276532, 169931.7114405165], 
processed observation next is [1.0, 0.34782608695652173, 0.5123456790123458, 0.36, 1.0, 1.0, 0.5844975475969127, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2987886221884476, 0.2987886221884476, 0.32679175277022404], 
reward next is 0.6732, 
noisyNet noise sample is [array([0.6071317], dtype=float32), -1.1125367]. 
=============================================
[2019-03-23 21:24:36,908] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.8644484e-18 1.0000000e+00 2.6048036e-34 2.8829681e-27 5.9877748e-35], sum to 1.0000
[2019-03-23 21:24:36,914] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2882
[2019-03-23 21:24:36,924] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.95, 34.33333333333334, 1.0, 2.0, 0.3329472870055465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 423051.2240079078, 423051.2240079078, 119734.494002285], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 418200.0000, 
sim time next is 418800.0000, 
raw observation next is [27.8, 34.66666666666667, 1.0, 2.0, 0.3295868928892845, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 418983.9382123344, 418983.9382123344, 119301.9522239365], 
processed observation next is [1.0, 0.8695652173913043, 0.5851851851851853, 0.34666666666666673, 1.0, 1.0, 0.20188915820152917, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14963712079011943, 0.14963712079011943, 0.2294268311998779], 
reward next is 0.7706, 
noisyNet noise sample is [array([-1.387067], dtype=float32), 0.4463917]. 
=============================================
[2019-03-23 21:24:40,406] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 21:24:40,409] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:24:40,409] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:24:40,410] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:24:40,411] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:24:40,412] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:24:40,413] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:24:40,414] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:24:40,414] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:24:40,416] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:24:40,416] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:24:40,429] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run10
[2019-03-23 21:24:40,451] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run10
[2019-03-23 21:24:40,478] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run10
[2019-03-23 21:24:40,478] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run10
[2019-03-23 21:24:40,543] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run10
[2019-03-23 21:24:43,372] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.16988085]
[2019-03-23 21:24:43,374] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [18.0, 53.0, 1.0, 2.0, 0.2173224113582582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 280319.5099709439, 280319.5099709439, 80671.113513402]
[2019-03-23 21:24:43,374] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:24:43,379] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.5645049e-14 1.0000000e+00 4.1708600e-25 9.4336807e-21 2.2650203e-25], sampled 0.41478099085712117
[2019-03-23 21:24:44,345] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.16988085]
[2019-03-23 21:24:44,347] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [30.23066168, 5.216005786, 1.0, 2.0, 0.348298873714125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 449312.5126130217, 449312.5126130217, 99582.69347369508]
[2019-03-23 21:24:44,348] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:24:44,350] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.5645049e-14 1.0000000e+00 4.1708600e-25 9.4336807e-21 2.2650203e-25], sampled 0.35503438022257994
[2019-03-23 21:24:57,766] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.16988085]
[2019-03-23 21:24:57,767] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.35650464166667, 17.86928589833333, 1.0, 2.0, 0.3171840448553176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 409163.2460524448, 409163.2460524448, 102164.5552520516]
[2019-03-23 21:24:57,768] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:24:57,770] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.5645049e-14 1.0000000e+00 4.1708600e-25 9.4336807e-21 2.2650203e-25], sampled 0.6109101245611056
[2019-03-23 21:25:02,061] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.16988085]
[2019-03-23 21:25:02,061] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [18.63333333333334, 90.83333333333334, 1.0, 2.0, 0.3889382948671427, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 492694.9808900431, 492694.9808900431, 127248.0297610252]
[2019-03-23 21:25:02,063] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:25:02,065] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.5645049e-14 1.0000000e+00 4.1708600e-25 9.4336807e-21 2.2650203e-25], sampled 0.5338915472342391
[2019-03-23 21:25:14,224] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.16988085]
[2019-03-23 21:25:14,225] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.27399732, 92.70017549166667, 1.0, 2.0, 0.4952332999933864, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 592298.1493060233, 592298.1493060233, 142207.1501305754]
[2019-03-23 21:25:14,229] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:25:14,233] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.5645049e-14 1.0000000e+00 4.1708600e-25 9.4336807e-21 2.2650203e-25], sampled 0.9340859063676619
[2019-03-23 21:26:06,259] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.16988085]
[2019-03-23 21:26:06,260] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [31.61038935833334, 52.56814485333334, 1.0, 2.0, 0.6017124359550039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 685731.8533646818, 685731.8533646818, 158372.1001323419]
[2019-03-23 21:26:06,262] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:26:06,264] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.5645049e-14 1.0000000e+00 4.1708600e-25 9.4336807e-21 2.2650203e-25], sampled 0.5375263170119204
[2019-03-23 21:26:08,203] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.16988085]
[2019-03-23 21:26:08,206] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.68333333333333, 90.66666666666667, 1.0, 2.0, 0.5715613862406655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 705282.2293120772, 705282.2293120772, 155334.9857008482]
[2019-03-23 21:26:08,207] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:26:08,210] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.5645049e-14 1.0000000e+00 4.1708600e-25 9.4336807e-21 2.2650203e-25], sampled 0.36289657993098523
[2019-03-23 21:26:19,952] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 21:26:20,348] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 21:26:20,374] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 21:26:20,547] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 21:26:20,574] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 21:26:21,588] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 225000, evaluation results [225000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 21:26:24,180] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.13043506e-26 1.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00], sum to 1.0000
[2019-03-23 21:26:24,190] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8035
[2019-03-23 21:26:24,195] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1409291.743818349 W.
[2019-03-23 21:26:24,198] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.6, 35.0, 1.0, 2.0, 0.5813678534375026, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9444832388550832, 6.9112, 6.9112, 121.9260425233998, 1409291.743818349, 1409291.743818349, 284193.9488962242], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 550800.0000, 
sim time next is 551400.0000, 
raw observation next is [30.3, 36.16666666666667, 1.0, 2.0, 0.5591371983961398, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9107379881924901, 6.9112, 6.9112, 121.9260426156337, 1360125.264842908, 1360125.264842908, 275616.682725785], 
processed observation next is [1.0, 0.391304347826087, 0.6777777777777778, 0.3616666666666667, 1.0, 1.0, 0.475163331423976, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8884224852406125, 0.0, 0.0, 0.8094621288199494, 0.48575902315818137, 0.48575902315818137, 0.5300320821649712], 
reward next is 0.4700, 
noisyNet noise sample is [array([-1.7551129], dtype=float32), -0.3845524]. 
=============================================
[2019-03-23 21:26:27,253] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.5437202e-19 1.0000000e+00 1.4081865e-33 3.4129409e-28 1.0523956e-34], sum to 1.0000
[2019-03-23 21:26:27,264] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0747
[2019-03-23 21:26:27,270] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.4, 40.0, 1.0, 2.0, 0.3703346438562604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 462309.7809312706, 462309.7809312706, 124589.2094247234], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 594000.0000, 
sim time next is 594600.0000, 
raw observation next is [28.2, 40.5, 1.0, 2.0, 0.3692431109173621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 461282.6686672778, 461282.6686672778, 124447.2761202111], 
processed observation next is [1.0, 0.9130434782608695, 0.6, 0.405, 1.0, 1.0, 0.24909894156828824, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1647438102383135, 0.1647438102383135, 0.2393216848465598], 
reward next is 0.7607, 
noisyNet noise sample is [array([0.58568853], dtype=float32), -1.0393744]. 
=============================================
[2019-03-23 21:26:29,848] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.1173728e-24 1.0000000e+00 0.0000000e+00 6.1468583e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 21:26:29,858] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8140
[2019-03-23 21:26:29,868] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1425187.062987936 W.
[2019-03-23 21:26:29,871] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.35, 36.83333333333333, 1.0, 2.0, 0.5946049527536026, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9592061224613261, 6.911199999999999, 6.9112, 121.9260426156618, 1425187.062987936, 1425187.062987936, 289982.9292947151], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 643800.0000, 
sim time next is 644400.0000, 
raw observation next is [31.7, 36.0, 1.0, 2.0, 0.4397890953860459, 1.0, 1.0, 0.4397890953860459, 1.0, 2.0, 0.7038362471112526, 6.9112, 6.9112, 121.94756008, 1551681.342256385, 1551681.342256385, 314977.0145629547], 
processed observation next is [1.0, 0.4782608695652174, 0.7296296296296296, 0.36, 1.0, 1.0, 0.33308225641195943, 1.0, 0.5, 0.33308225641195943, 1.0, 1.0, 0.6297953088890657, 0.0, 0.0, 0.8096049824067558, 0.5541719079487089, 0.5541719079487089, 0.6057250280056822], 
reward next is 0.3943, 
noisyNet noise sample is [array([-0.00404183], dtype=float32), -1.3576114]. 
=============================================
[2019-03-23 21:26:32,488] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5511244e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:26:32,496] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5617
[2019-03-23 21:26:32,500] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.03333333333333, 28.33333333333334, 1.0, 2.0, 0.3549437989720486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 449969.3936065601, 449969.3936065601, 122616.3635201407], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 681600.0000, 
sim time next is 682200.0000, 
raw observation next is [29.85, 29.0, 1.0, 2.0, 0.3546987703458571, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 449559.9777917764, 449559.9777917759, 122582.8386937402], 
processed observation next is [1.0, 0.9130434782608695, 0.6611111111111112, 0.29, 1.0, 1.0, 0.23178425041173467, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16055713492563442, 0.16055713492563425, 0.23573622825719268], 
reward next is 0.7643, 
noisyNet noise sample is [array([-0.07991799], dtype=float32), -0.79645306]. 
=============================================
[2019-03-23 21:26:37,987] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3550693e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:26:37,998] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4027
[2019-03-23 21:26:38,006] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.73333333333333, 57.0, 1.0, 2.0, 0.3021062966861082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 385227.3456431892, 385227.3456431892, 115835.2718066264], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 794400.0000, 
sim time next is 795000.0000, 
raw observation next is [22.66666666666667, 57.5, 1.0, 2.0, 0.3030698202637355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 386387.4712092523, 386387.4712092523, 115954.5195345708], 
processed observation next is [0.0, 0.17391304347826086, 0.39506172839506193, 0.575, 1.0, 1.0, 0.17032121459968516, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13799552543187582, 0.13799552543187582, 0.22298946064340538], 
reward next is 0.7770, 
noisyNet noise sample is [array([-0.897747], dtype=float32), 0.19298498]. 
=============================================
[2019-03-23 21:26:38,028] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[66.94624]
 [66.94624]
 [66.94624]
 [66.94624]
 [66.94624]], R is [[67.0537796 ]
 [67.16047668]
 [67.26620483]
 [67.37091064]
 [67.47459412]].
[2019-03-23 21:26:42,475] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1233062e-29 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:26:42,477] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3457
[2019-03-23 21:26:42,482] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.2, 65.33333333333333, 1.0, 2.0, 0.3161350322033156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 403542.6595819312, 403542.6595819317, 117592.6313066157], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 880800.0000, 
sim time next is 881400.0000, 
raw observation next is [21.1, 65.16666666666667, 1.0, 2.0, 0.3110051599545788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 397449.5981047476, 397449.5981047471, 116947.2232612936], 
processed observation next is [0.0, 0.17391304347826086, 0.3370370370370371, 0.6516666666666667, 1.0, 1.0, 0.17976804756497475, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14194628503740986, 0.1419462850374097, 0.22489850627171848], 
reward next is 0.7751, 
noisyNet noise sample is [array([0.39266005], dtype=float32), -0.48367897]. 
=============================================
[2019-03-23 21:26:48,182] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.1403424e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:26:48,190] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6522
[2019-03-23 21:26:48,195] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.25, 58.5, 1.0, 2.0, 0.3435342441714257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 438858.9259908839, 438858.9259908839, 121124.9441980624], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 977400.0000, 
sim time next is 978000.0000, 
raw observation next is [22.36666666666667, 58.33333333333333, 1.0, 2.0, 0.3540991673909709, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 451998.358413533, 451998.358413533, 122521.6496809829], 
processed observation next is [1.0, 0.30434782608695654, 0.38395061728395075, 0.5833333333333333, 1.0, 1.0, 0.23107043737020347, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16142798514769036, 0.16142798514769036, 0.23561855707881327], 
reward next is 0.7644, 
noisyNet noise sample is [array([0.4302601], dtype=float32), 0.17977667]. 
=============================================
[2019-03-23 21:26:48,218] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[82.37053]
 [82.37053]
 [82.37053]
 [82.37053]
 [82.37053]], R is [[82.31121063]
 [82.2551651 ]
 [82.20005798]
 [82.1385498 ]
 [82.09208679]].
[2019-03-23 21:26:51,150] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.4671151e-24 1.0000000e+00 0.0000000e+00 5.4572343e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 21:26:51,155] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2045
[2019-03-23 21:26:51,161] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.86666666666667, 68.66666666666667, 1.0, 2.0, 0.2954638403588669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 376780.1631774027, 376780.1631774027, 115016.0791787641], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1057800.0000, 
sim time next is 1058400.0000, 
raw observation next is [21.0, 68.0, 1.0, 2.0, 0.295511405008904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 376712.1809358224, 376712.1809358224, 115021.4489430297], 
processed observation next is [1.0, 0.2608695652173913, 0.3333333333333333, 0.68, 1.0, 1.0, 0.16132310120107618, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1345400646199366, 0.1345400646199366, 0.22119509412121097], 
reward next is 0.7788, 
noisyNet noise sample is [array([1.5484042], dtype=float32), -0.3301245]. 
=============================================
[2019-03-23 21:26:56,138] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.931362e-31 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:26:56,146] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9795
[2019-03-23 21:26:56,150] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.3, 75.0, 1.0, 2.0, 0.2892488898256245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 371049.9269674128, 371049.9269674128, 114257.2517508903], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1119600.0000, 
sim time next is 1120200.0000, 
raw observation next is [19.28333333333333, 75.0, 1.0, 2.0, 0.2867344858935714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 367928.1274377487, 367928.1274377482, 113951.6446843914], 
processed observation next is [1.0, 1.0, 0.26975308641975304, 0.75, 1.0, 1.0, 0.15087438796853742, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13140290265633883, 0.13140290265633864, 0.21913777823921424], 
reward next is 0.7809, 
noisyNet noise sample is [array([1.0811182], dtype=float32), -1.093359]. 
=============================================
[2019-03-23 21:26:58,563] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.5411382e-25 1.0000000e+00 0.0000000e+00 1.9652451e-38 0.0000000e+00], sum to 1.0000
[2019-03-23 21:26:58,569] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4968
[2019-03-23 21:26:58,574] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.23333333333333, 65.0, 1.0, 2.0, 0.4754970817506106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 606912.2697046704, 606912.2697046704, 140008.4231883542], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1164000.0000, 
sim time next is 1164600.0000, 
raw observation next is [21.3, 65.0, 1.0, 2.0, 0.4652843679836323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 593611.3552084351, 593611.3552084346, 138435.1955293682], 
processed observation next is [1.0, 0.4782608695652174, 0.3444444444444445, 0.65, 1.0, 1.0, 0.3634337714090861, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21200405543158396, 0.2120040554315838, 0.26622152986416964], 
reward next is 0.7338, 
noisyNet noise sample is [array([-2.458276], dtype=float32), -0.98725337]. 
=============================================
[2019-03-23 21:27:03,863] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.795961e-24 1.000000e+00 0.000000e+00 2.612147e-34 0.000000e+00], sum to 1.0000
[2019-03-23 21:27:03,867] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6291
[2019-03-23 21:27:03,870] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.25, 66.5, 1.0, 2.0, 0.8439029894429422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.926042608599, 1051613.354354949, 1051613.354354949, 208813.3153887548], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1251000.0000, 
sim time next is 1251600.0000, 
raw observation next is [23.43333333333333, 66.0, 1.0, 2.0, 0.8389075221416558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156597, 1043966.269895872, 1043966.269895873, 207683.8925785494], 
processed observation next is [1.0, 0.4782608695652174, 0.42345679012345666, 0.66, 1.0, 1.0, 0.8082232406448283, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.809462128820122, 0.37284509639138286, 0.37284509639138325, 0.399392101112595], 
reward next is 0.6006, 
noisyNet noise sample is [array([-2.2354877], dtype=float32), -0.48169798]. 
=============================================
[2019-03-23 21:27:04,904] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.1529358e-27 1.0000000e+00 0.0000000e+00 2.0200119e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 21:27:04,913] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4861
[2019-03-23 21:27:04,921] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.76666666666667, 86.0, 1.0, 2.0, 0.3507572022679769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 441391.2680962301, 441391.2680962301, 122022.5261088725], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1300800.0000, 
sim time next is 1301400.0000, 
raw observation next is [19.7, 86.0, 1.0, 2.0, 0.347122980868833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 437165.7858235738, 437165.7858235738, 121547.057884526], 
processed observation next is [1.0, 0.043478260869565216, 0.28518518518518515, 0.86, 1.0, 1.0, 0.22276545341527734, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1561306377941335, 0.1561306377941335, 0.23374434208562692], 
reward next is 0.7663, 
noisyNet noise sample is [array([0.59679407], dtype=float32), 0.7557528]. 
=============================================
[2019-03-23 21:27:08,759] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.7738823e-16 1.0000000e+00 3.2072011e-28 4.6297057e-23 3.5184579e-29], sum to 1.0000
[2019-03-23 21:27:08,765] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9046
[2019-03-23 21:27:08,768] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.13333333333333, 37.33333333333334, 1.0, 2.0, 0.7282535585702701, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156615, 908094.5579339586, 908094.5579339586, 184571.5240042108], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1341600.0000, 
sim time next is 1342200.0000, 
raw observation next is [29.31666666666667, 36.66666666666666, 1.0, 2.0, 0.7382802577890281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 920575.1121414388, 920575.1121414388, 186579.9109965861], 
processed observation next is [1.0, 0.5217391304347826, 0.6413580246913582, 0.3666666666666666, 1.0, 1.0, 0.6884288783202714, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.32877682576479955, 0.32877682576479955, 0.358807521147281], 
reward next is 0.6412, 
noisyNet noise sample is [array([1.4831116], dtype=float32), -0.09667784]. 
=============================================
[2019-03-23 21:27:12,482] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 21:27:12,483] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:27:12,484] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:27:12,485] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:27:12,486] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:27:12,486] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:27:12,487] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:27:12,488] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:27:12,487] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:27:12,489] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:27:12,489] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:27:12,503] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run11
[2019-03-23 21:27:12,526] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run11
[2019-03-23 21:27:12,527] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run11
[2019-03-23 21:27:12,547] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run11
[2019-03-23 21:27:12,602] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run11
[2019-03-23 21:27:18,079] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.13953623]
[2019-03-23 21:27:18,080] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.0, 29.66666666666666, 1.0, 2.0, 0.4717254128500061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 600202.9139640869, 600202.9139640869, 139417.0772679514]
[2019-03-23 21:27:18,081] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:27:18,085] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.3827372e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.03270481922870394
[2019-03-23 21:27:55,665] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.13953623]
[2019-03-23 21:27:55,667] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.3, 80.16666666666667, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.545786075333643, 6.9112, 121.9234566319233, 1512802.831240549, 1187844.934332861, 246966.7839534274]
[2019-03-23 21:27:55,668] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:27:55,671] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.3827372e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.3616324546178106
[2019-03-23 21:27:55,672] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1512802.831240549 W.
[2019-03-23 21:28:13,008] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.13953623]
[2019-03-23 21:28:13,010] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [30.840453605, 83.98336928, 1.0, 2.0, 0.989095207952319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.077471467855777, 6.9112, 121.9251010959883, 1212738.989275369, 1127593.794059054, 238126.3595128305]
[2019-03-23 21:28:13,011] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:28:13,016] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [5.3827372e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.5977737695088573
[2019-03-23 21:28:20,444] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.13953623]
[2019-03-23 21:28:20,444] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.6, 92.33333333333334, 1.0, 2.0, 0.6818652924545818, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 777123.0634912108, 777123.0634912113, 172739.1697887163]
[2019-03-23 21:28:20,446] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:28:20,448] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.3827372e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.0229536066334588
[2019-03-23 21:28:49,773] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.13953623]
[2019-03-23 21:28:49,776] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [30.63104767, 61.43024115666667, 1.0, 2.0, 0.58364715438942, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9291852778487535, 6.9112, 6.9112, 121.9260425144725, 1330847.822360659, 1330847.822360659, 287553.9941721336]
[2019-03-23 21:28:49,776] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:28:49,780] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [5.3827372e-30 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.9342045136111118
[2019-03-23 21:28:49,781] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1330847.822360659 W.
[2019-03-23 21:28:51,872] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 21:28:51,997] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 21:28:52,212] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 21:28:52,277] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 21:28:52,311] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 21:28:53,326] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 250000, evaluation results [250000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 21:29:04,651] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.5151410e-22 1.0000000e+00 0.0000000e+00 1.2674324e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 21:29:04,664] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5414
[2019-03-23 21:29:04,671] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.23333333333333, 47.0, 1.0, 2.0, 0.3551704909779502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 445948.3592934466, 445948.3592934461, 122594.3186701373], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1624800.0000, 
sim time next is 1625400.0000, 
raw observation next is [26.1, 47.5, 1.0, 2.0, 0.3550584062810238, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 445926.6518210773, 445926.6518210773, 122581.2039178194], 
processed observation next is [1.0, 0.8260869565217391, 0.5222222222222223, 0.475, 1.0, 1.0, 0.23221238842979025, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1592595185075276, 0.1592595185075276, 0.235733084457345], 
reward next is 0.7643, 
noisyNet noise sample is [array([-1.5490044], dtype=float32), 0.35429138]. 
=============================================
[2019-03-23 21:29:08,220] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0966150e-22 1.0000000e+00 0.0000000e+00 1.3819193e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 21:29:08,231] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7714
[2019-03-23 21:29:08,236] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333333, 80.66666666666667, 1.0, 2.0, 0.3790934535925704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 471938.9603949608, 471938.9603949604, 125760.1662097239], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1730400.0000, 
sim time next is 1731000.0000, 
raw observation next is [21.31666666666667, 80.83333333333333, 1.0, 2.0, 0.3787889983034531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 471526.4231619025, 471526.4231619025, 125717.7013505005], 
processed observation next is [1.0, 0.0, 0.34506172839506183, 0.8083333333333332, 1.0, 1.0, 0.26046309321839656, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16840229398639375, 0.16840229398639375, 0.24176481028942404], 
reward next is 0.7582, 
noisyNet noise sample is [array([1.1127119], dtype=float32), -0.13810682]. 
=============================================
[2019-03-23 21:29:08,258] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[66.12832]
 [66.12832]
 [66.12832]
 [66.12832]
 [66.12832]], R is [[66.22525787]
 [66.32115936]
 [66.41598511]
 [66.50980377]
 [66.6027832 ]].
[2019-03-23 21:29:12,220] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.9152812e-21 1.0000000e+00 3.5152124e-36 1.3745825e-29 2.2529091e-36], sum to 1.0000
[2019-03-23 21:29:12,226] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5890
[2019-03-23 21:29:12,238] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1456880.530186991 W.
[2019-03-23 21:29:12,246] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.15, 66.66666666666667, 1.0, 2.0, 0.6215925667994479, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9635657828253644, 6.9112, 6.9112, 121.9257299290951, 1456880.530186991, 1456880.530186991, 295575.4986941707], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1771800.0000, 
sim time next is 1772400.0000, 
raw observation next is [25.2, 66.33333333333334, 1.0, 2.0, 0.4676512137894263, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7539571327565826, 6.911200000000001, 6.9112, 121.9260425203144, 1119417.880262279, 1119417.880262279, 244401.1299537572], 
processed observation next is [1.0, 0.5217391304347826, 0.4888888888888889, 0.6633333333333334, 1.0, 1.0, 0.36625144498741224, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6924464159457283, 8.881784197001253e-17, 0.0, 0.8094621281871284, 0.39979210009367105, 0.39979210009367105, 0.47000217298799457], 
reward next is 0.5300, 
noisyNet noise sample is [array([-0.9425806], dtype=float32), -0.8254995]. 
=============================================
[2019-03-23 21:29:12,719] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.2012142e-15 1.0000000e+00 3.5146519e-27 7.7048643e-21 2.6036306e-27], sum to 1.0000
[2019-03-23 21:29:12,725] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6689
[2019-03-23 21:29:12,732] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1531434.418828457 W.
[2019-03-23 21:29:12,738] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.9, 60.5, 1.0, 2.0, 0.6931116369409535, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9711470864509293, 6.911200000000001, 6.9112, 121.9260426156353, 1531434.418828457, 1531434.418828456, 310596.95681023], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1780200.0000, 
sim time next is 1780800.0000, 
raw observation next is [27.26666666666667, 59.66666666666667, 1.0, 2.0, 0.6708890965180797, 1.0, 1.0, 0.6708890965180797, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1570142.234126238, 1570142.234126238, 295227.1639890876], 
processed observation next is [1.0, 0.6086956521739131, 0.5654320987654322, 0.5966666666666667, 1.0, 1.0, 0.6082013053786663, 1.0, 0.5, 0.6082013053786663, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5607650836165136, 0.5607650836165136, 0.5677445461328609], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7114759], dtype=float32), -0.44568327]. 
=============================================
[2019-03-23 21:29:15,817] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.1311596e-27 1.0000000e+00 0.0000000e+00 1.2145017e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 21:29:15,822] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5327
[2019-03-23 21:29:15,831] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.23333333333333, 82.33333333333334, 1.0, 2.0, 0.3586523463831733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 451444.6773719257, 451444.6773719257, 123075.6441675862], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1838400.0000, 
sim time next is 1839000.0000, 
raw observation next is [20.36666666666667, 81.66666666666666, 1.0, 2.0, 0.3586146710446833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 451150.3303973478, 451150.3303973473, 123067.1620622136], 
processed observation next is [1.0, 0.2608695652173913, 0.3098765432098767, 0.8166666666666665, 1.0, 1.0, 0.23644603695795632, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1611251179990528, 0.1611251179990526, 0.23666761935041075], 
reward next is 0.7633, 
noisyNet noise sample is [array([-2.8248258], dtype=float32), -0.8245476]. 
=============================================
[2019-03-23 21:29:15,852] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[78.06508]
 [78.06508]
 [78.06508]
 [78.06508]
 [78.06508]], R is [[78.04776001]
 [78.03059387]
 [78.01248169]
 [77.99372864]
 [77.97158813]].
[2019-03-23 21:29:16,717] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.0970393e-24 1.0000000e+00 0.0000000e+00 1.8673951e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 21:29:16,723] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2859
[2019-03-23 21:29:16,727] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.88333333333333, 82.33333333333334, 1.0, 2.0, 0.5633046309584263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 693586.0208831154, 693586.0208831154, 153888.7456176037], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1861800.0000, 
sim time next is 1862400.0000, 
raw observation next is [21.86666666666667, 82.66666666666667, 1.0, 2.0, 0.6952761516331016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 855664.0010903981, 855664.0010903981, 177816.788434387], 
processed observation next is [1.0, 0.5652173913043478, 0.36543209876543226, 0.8266666666666667, 1.0, 1.0, 0.6372335138489305, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3055942861037136, 0.3055942861037136, 0.3419553623738212], 
reward next is 0.6580, 
noisyNet noise sample is [array([-0.39382708], dtype=float32), 1.499867]. 
=============================================
[2019-03-23 21:29:18,013] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.6610364e-25 1.0000000e+00 0.0000000e+00 4.0239339e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 21:29:18,022] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2457
[2019-03-23 21:29:18,025] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.61666666666667, 86.83333333333333, 1.0, 2.0, 0.5050366778714157, 1.0, 1.0, 0.5050366778714157, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9258198028527, 1216246.986311828, 1216246.986311828, 239679.2412012354], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1871400.0000, 
sim time next is 1872000.0000, 
raw observation next is [21.6, 87.0, 1.0, 2.0, 0.9384704841535779, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.163798152341809, 6.9112, 121.9249482406549, 1272962.748680047, 1143611.078750215, 229647.5393780759], 
processed observation next is [1.0, 0.6956521739130435, 0.3555555555555556, 0.87, 1.0, 1.0, 0.926750576373307, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.025259815234180926, 0.0, 0.80945486330816, 0.4546295531000168, 0.4084325281250768, 0.4416298834193767], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.03301873], dtype=float32), -0.86870605]. 
=============================================
[2019-03-23 21:29:18,042] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[64.11101]
 [64.11101]
 [64.11101]
 [64.11101]
 [64.11101]], R is [[63.46989822]
 [63.37427902]
 [62.74053574]
 [62.11313248]
 [61.62456512]].
[2019-03-23 21:29:22,480] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.5436331e-16 1.0000000e+00 2.5049463e-28 2.9462781e-24 2.0273363e-29], sum to 1.0000
[2019-03-23 21:29:22,485] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3962
[2019-03-23 21:29:22,492] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1544648.755534453 W.
[2019-03-23 21:29:22,496] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.21666666666667, 60.16666666666666, 1.0, 2.0, 0.6718025460271455, 1.0, 1.0, 0.6718025460271455, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1544648.755534453, 1544648.755534453, 294262.3916710421], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1957800.0000, 
sim time next is 1958400.0000, 
raw observation next is [28.3, 60.0, 1.0, 2.0, 0.4293530644499824, 1.0, 2.0, 0.4293530644499824, 1.0, 1.0, 0.6835440616574734, 6.9112, 6.9112, 121.94756008, 1468665.245131989, 1468665.245131989, 310179.0192997654], 
processed observation next is [1.0, 0.6956521739130435, 0.6037037037037037, 0.6, 1.0, 1.0, 0.3206584100595029, 1.0, 1.0, 0.3206584100595029, 1.0, 0.5, 0.6044300770718417, 0.0, 0.0, 0.8096049824067558, 0.5245233018328532, 0.5245233018328532, 0.5964981140380105], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.97833866], dtype=float32), -0.05657549]. 
=============================================
[2019-03-23 21:29:23,148] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.6002891e-17 1.0000000e+00 4.2596737e-29 4.2934189e-25 1.1552950e-30], sum to 1.0000
[2019-03-23 21:29:23,157] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7452
[2019-03-23 21:29:23,163] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.73333333333333, 67.0, 1.0, 2.0, 0.569218282476308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 661537.5250217651, 661537.5250217647, 153474.1724354975], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1966800.0000, 
sim time next is 1967400.0000, 
raw observation next is [27.6, 68.0, 1.0, 2.0, 0.5714357738075659, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 663548.7602385518, 663548.7602385518, 153821.3030320368], 
processed observation next is [1.0, 0.782608695652174, 0.5777777777777778, 0.68, 1.0, 1.0, 0.48980449262805464, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23698170008519706, 0.23698170008519706, 0.2958101981385323], 
reward next is 0.7042, 
noisyNet noise sample is [array([-0.02232703], dtype=float32), 1.0306383]. 
=============================================
[2019-03-23 21:29:25,242] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2778169e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:29:25,250] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1581
[2019-03-23 21:29:25,254] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.3, 93.66666666666667, 1.0, 2.0, 0.3637807994185449, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 455400.4990456486, 455400.4990456486, 123725.9013506426], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2004000.0000, 
sim time next is 2004600.0000, 
raw observation next is [19.3, 93.83333333333334, 1.0, 2.0, 0.3636160546771721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 455083.1247349414, 455083.1247349414, 123701.805630009], 
processed observation next is [0.0, 0.17391304347826086, 0.27037037037037037, 0.9383333333333335, 1.0, 1.0, 0.24240006509187156, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16252968740533622, 0.16252968740533622, 0.2378880877500173], 
reward next is 0.7621, 
noisyNet noise sample is [array([0.25883815], dtype=float32), -0.18811224]. 
=============================================
[2019-03-23 21:29:26,084] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.3727230e-24 1.0000000e+00 0.0000000e+00 1.2227485e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 21:29:26,091] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8543
[2019-03-23 21:29:26,098] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.63333333333334, 68.66666666666667, 1.0, 2.0, 0.4300229350445351, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 524263.1166849273, 524263.1166849273, 132707.2884209015], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2024400.0000, 
sim time next is 2025000.0000, 
raw observation next is [24.85, 68.0, 1.0, 2.0, 0.4343936267295858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 528742.4676384603, 528742.4676384603, 133320.6969751974], 
processed observation next is [0.0, 0.43478260869565216, 0.475925925925926, 0.68, 1.0, 1.0, 0.32665907943998307, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1888365955851644, 0.1888365955851644, 0.2563859557215335], 
reward next is 0.7436, 
noisyNet noise sample is [array([-0.44532517], dtype=float32), 0.013260033]. 
=============================================
[2019-03-23 21:29:26,121] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[67.4905]
 [67.4905]
 [67.4905]
 [67.4905]
 [67.4905]], R is [[67.55922699]
 [67.62843323]
 [67.69803619]
 [67.76794434]
 [67.83807373]].
[2019-03-23 21:29:28,050] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.8699042e-22 1.0000000e+00 0.0000000e+00 4.2799881e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 21:29:28,051] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3311
[2019-03-23 21:29:28,058] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.48333333333333, 71.66666666666667, 1.0, 2.0, 0.6054629135036604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 695725.1395598896, 695725.1395598896, 159300.5369897904], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2056200.0000, 
sim time next is 2056800.0000, 
raw observation next is [27.36666666666667, 72.33333333333334, 1.0, 2.0, 0.6058757837380789, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 696267.4917137771, 696267.4917137771, 159375.4272312747], 
processed observation next is [0.0, 0.8260869565217391, 0.569135802469136, 0.7233333333333334, 1.0, 1.0, 0.530804504450094, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24866696132634894, 0.24866696132634894, 0.3064912062139898], 
reward next is 0.6935, 
noisyNet noise sample is [array([0.225562], dtype=float32), 1.2199603]. 
=============================================
[2019-03-23 21:29:35,228] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.3476512e-21 1.0000000e+00 1.7785964e-38 6.2457725e-31 1.5619723e-38], sum to 1.0000
[2019-03-23 21:29:35,236] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3956
[2019-03-23 21:29:35,245] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1341970.839474673 W.
[2019-03-23 21:29:35,252] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.4, 91.0, 1.0, 2.0, 0.5885209161140984, 1.0, 2.0, 0.5885209161140984, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1341970.839474673, 1341970.839474673, 264115.5561905509], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2196000.0000, 
sim time next is 2196600.0000, 
raw observation next is [24.38333333333333, 91.33333333333334, 1.0, 2.0, 0.4059245709852749, 1.0, 2.0, 0.4059245709852749, 1.0, 1.0, 0.6462451370488955, 6.9112, 6.9112, 121.94756008, 1388452.007906725, 1388452.007906725, 299687.1502277193], 
processed observation next is [1.0, 0.43478260869565216, 0.4586419753086418, 0.9133333333333334, 1.0, 1.0, 0.2927673464110416, 1.0, 1.0, 0.2927673464110416, 1.0, 0.5, 0.5578064213111193, 0.0, 0.0, 0.8096049824067558, 0.49587571710954464, 0.49587571710954464, 0.576321442745614], 
reward next is 0.4237, 
noisyNet noise sample is [array([-0.76438516], dtype=float32), 1.4688913]. 
=============================================
[2019-03-23 21:29:37,074] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.8099458e-13 1.0000000e+00 4.0089260e-22 1.6130164e-18 4.0988006e-22], sum to 1.0000
[2019-03-23 21:29:37,082] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4318
[2019-03-23 21:29:37,086] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.9, 95.0, 1.0, 2.0, 0.5443240035397413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 640891.8095727265, 640891.8095727265, 149705.078481016], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2228400.0000, 
sim time next is 2229000.0000, 
raw observation next is [22.86666666666667, 94.83333333333334, 1.0, 2.0, 0.54223027001937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 639093.1528455222, 639093.1528455217, 149388.8782150359], 
processed observation next is [1.0, 0.8260869565217391, 0.4024691358024693, 0.9483333333333335, 1.0, 1.0, 0.4550360357373452, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22824755458768647, 0.2282475545876863, 0.2872863042596844], 
reward next is 0.7127, 
noisyNet noise sample is [array([-0.26742944], dtype=float32), -0.94434243]. 
=============================================
[2019-03-23 21:29:37,110] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[29.620266]
 [29.620266]
 [29.620266]
 [29.620266]
 [29.620266]], R is [[30.0367775 ]
 [30.44851494]
 [30.85547066]
 [31.25728607]
 [31.65369034]].
[2019-03-23 21:29:40,965] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.48539797e-16 1.00000000e+00 1.24993034e-29 5.21774615e-22
 2.06892446e-28], sum to 1.0000
[2019-03-23 21:29:40,972] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8046
[2019-03-23 21:29:40,985] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1698113.852064571 W.
[2019-03-23 21:29:40,990] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.9, 80.33333333333334, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.882506691057035, 6.9112, 121.922309942068, 1698113.852064571, 1200733.239233958, 247620.5761167869], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2294400.0000, 
sim time next is 2295000.0000, 
raw observation next is [25.0, 80.0, 1.0, 2.0, 0.6789976455207898, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9831361628314611, 6.911200000000001, 6.9112, 121.9254576583662, 1501756.631202517, 1501756.631202517, 310795.5193424091], 
processed observation next is [1.0, 0.5652173913043478, 0.48148148148148145, 0.8, 1.0, 1.0, 0.6178543399057022, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.9789202035393263, 8.881784197001253e-17, 0.0, 0.8094582453120058, 0.536341654000899, 0.536341654000899, 0.5976836910430944], 
reward next is 0.4023, 
noisyNet noise sample is [array([-0.04172191], dtype=float32), -0.37944248]. 
=============================================
[2019-03-23 21:29:41,009] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[39.111897]
 [39.111897]
 [39.111897]
 [39.111897]
 [39.111897]], R is [[39.12310028]
 [38.73186874]
 [38.34455109]
 [37.96110535]
 [38.18460083]].
[2019-03-23 21:29:41,794] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.7798820e-15 1.0000000e+00 1.0824987e-25 5.8478802e-22 1.7064551e-26], sum to 1.0000
[2019-03-23 21:29:41,799] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9713
[2019-03-23 21:29:41,807] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.73333333333333, 96.0, 1.0, 2.0, 0.5033125377124583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 604401.6493859722, 604401.6493859722, 143563.4620408373], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2346600.0000, 
sim time next is 2347200.0000, 
raw observation next is [21.7, 96.0, 1.0, 2.0, 0.4896094906252275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 588301.5979496023, 588301.5979496023, 141426.9974333128], 
processed observation next is [1.0, 0.17391304347826086, 0.3592592592592592, 0.96, 1.0, 1.0, 0.39239225074431844, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2101077135534294, 0.2101077135534294, 0.2719749950640631], 
reward next is 0.7280, 
noisyNet noise sample is [array([0.38175693], dtype=float32), -0.7063192]. 
=============================================
[2019-03-23 21:29:43,935] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.6244744e-25 1.0000000e+00 0.0000000e+00 1.8303170e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 21:29:43,944] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1957
[2019-03-23 21:29:43,948] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 75.0, 1.0, 2.0, 0.4493073575288818, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 548405.7892223023, 548405.7892223023, 135567.7050223666], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2354400.0000, 
sim time next is 2355000.0000, 
raw observation next is [23.83333333333334, 72.0, 1.0, 2.0, 0.4379235201548969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 535642.7369949273, 535642.7369949273, 133913.477242679], 
processed observation next is [1.0, 0.2608695652173913, 0.43827160493827183, 0.72, 1.0, 1.0, 0.33086133351773434, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1913009774981883, 0.1913009774981883, 0.25752591777438266], 
reward next is 0.7425, 
noisyNet noise sample is [array([-1.8301508], dtype=float32), 0.1986897]. 
=============================================
[2019-03-23 21:29:43,965] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[78.800995]
 [78.800995]
 [78.800995]
 [78.800995]
 [78.800995]], R is [[78.75546265]
 [78.70720673]
 [78.65518951]
 [78.60174561]
 [78.54781342]].
[2019-03-23 21:29:44,199] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 21:29:44,201] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:29:44,201] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:29:44,202] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:29:44,203] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:29:44,203] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:29:44,203] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:29:44,204] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:29:44,205] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:29:44,206] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:29:44,204] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:29:44,223] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run12
[2019-03-23 21:29:44,223] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run12
[2019-03-23 21:29:44,224] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run12
[2019-03-23 21:29:44,224] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run12
[2019-03-23 21:29:44,245] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run12
[2019-03-23 21:29:56,107] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.12639208]
[2019-03-23 21:29:56,108] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.08333333333334, 43.5, 1.0, 2.0, 0.4708189151005142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 122.5323518238326, 607427.5182404419, 607427.5182404416, 121422.3364088337]
[2019-03-23 21:29:56,109] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:29:56,112] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.1132751e-23 1.0000000e+00 0.0000000e+00 5.2483366e-34 0.0000000e+00], sampled 0.5752003300420108
[2019-03-23 21:30:10,486] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.12639208]
[2019-03-23 21:30:10,487] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.30378249, 92.4055035, 1.0, 2.0, 0.4981120966870339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 597939.2579255578, 597939.2579255578, 142737.0353600766]
[2019-03-23 21:30:10,488] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:30:10,491] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.1132751e-23 1.0000000e+00 0.0000000e+00 5.2483366e-34 0.0000000e+00], sampled 0.3199854664060534
[2019-03-23 21:30:38,133] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.12639208]
[2019-03-23 21:30:38,134] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.07621519666667, 105.4852071266667, 1.0, 2.0, 0.5528553533266418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 652471.1545524851, 652471.1545524846, 151174.7918205982]
[2019-03-23 21:30:38,136] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:30:38,139] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.1132751e-23 1.0000000e+00 0.0000000e+00 5.2483366e-34 0.0000000e+00], sampled 0.951902112790339
[2019-03-23 21:31:23,565] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 21:31:23,878] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 21:31:23,961] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 21:31:24,032] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 21:31:24,438] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 21:31:25,455] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 275000, evaluation results [275000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 21:31:25,667] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.7881432e-25 1.0000000e+00 0.0000000e+00 4.6933727e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 21:31:25,672] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8979
[2019-03-23 21:31:25,678] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.6, 38.5, 1.0, 2.0, 0.9199150790311689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.134070545348666, 6.9112, 121.9249297868062, 1252224.175056611, 1138095.577565241, 225839.0035918244], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2374200.0000, 
sim time next is 2374800.0000, 
raw observation next is [29.7, 38.33333333333334, 1.0, 2.0, 0.9276104424021446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.182075360153291, 6.9112, 121.9246705148956, 1285713.953072349, 1147003.119115715, 227621.4286391583], 
processed observation next is [1.0, 0.4782608695652174, 0.6555555555555556, 0.3833333333333334, 1.0, 1.0, 0.9138219552406484, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.02708753601532914, 0.0, 0.8094530194979326, 0.4591835546686961, 0.4096439711127553, 0.4377335166137659], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8242622], dtype=float32), 0.28174752]. 
=============================================
[2019-03-23 21:31:27,483] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.0643341e-15 1.0000000e+00 2.2334498e-29 6.1387677e-24 2.7698776e-29], sum to 1.0000
[2019-03-23 21:31:27,491] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8100
[2019-03-23 21:31:27,495] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.36666666666667, 41.0, 1.0, 2.0, 0.4043665549657034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 498394.2374046114, 498394.2374046114, 129173.7418376046], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2398800.0000, 
sim time next is 2399400.0000, 
raw observation next is [29.2, 41.5, 1.0, 2.0, 0.4019276355075755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 495609.8301924938, 495609.8301924938, 128834.6364094527], 
processed observation next is [1.0, 0.782608695652174, 0.637037037037037, 0.415, 1.0, 1.0, 0.2880090898899708, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1770035107830335, 0.1770035107830335, 0.24775891617202442], 
reward next is 0.7522, 
noisyNet noise sample is [array([0.8217415], dtype=float32), 0.754684]. 
=============================================
[2019-03-23 21:31:28,766] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.8147668e-27 1.0000000e+00 0.0000000e+00 1.6385447e-38 0.0000000e+00], sum to 1.0000
[2019-03-23 21:31:28,776] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7641
[2019-03-23 21:31:28,781] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.93333333333334, 69.0, 1.0, 2.0, 0.2995793535418291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 385035.8896417869, 385035.8896417873, 115520.4314902293], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2430600.0000, 
sim time next is 2431200.0000, 
raw observation next is [19.76666666666667, 70.0, 1.0, 2.0, 0.2840291791510407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 365128.6244776495, 365128.6244776495, 113621.2891189465], 
processed observation next is [1.0, 0.13043478260869565, 0.2876543209876544, 0.7, 1.0, 1.0, 0.1476537847036199, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1304030801705891, 0.1304030801705891, 0.21850247907489712], 
reward next is 0.7815, 
noisyNet noise sample is [array([1.905642], dtype=float32), 0.34577802]. 
=============================================
[2019-03-23 21:31:31,767] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.9405493e-12 1.0000000e+00 2.9725838e-23 6.4664824e-19 4.0043233e-23], sum to 1.0000
[2019-03-23 21:31:31,771] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8733
[2019-03-23 21:31:31,775] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.46666666666667, 25.0, 1.0, 2.0, 0.4035395709884195, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 500204.0606268407, 500204.0606268407, 129122.7320494359], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2481600.0000, 
sim time next is 2482200.0000, 
raw observation next is [33.25, 25.5, 1.0, 2.0, 0.3904260684830919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 485521.4256747947, 485521.4256747942, 127316.6439541729], 
processed observation next is [1.0, 0.7391304347826086, 0.7870370370370371, 0.255, 1.0, 1.0, 0.274316748194157, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17340050916956953, 0.17340050916956934, 0.24483969991187096], 
reward next is 0.7552, 
noisyNet noise sample is [array([-0.2926207], dtype=float32), 0.43807006]. 
=============================================
[2019-03-23 21:31:32,634] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.0165541e-16 1.0000000e+00 5.4637500e-30 2.6290450e-24 1.8442135e-30], sum to 1.0000
[2019-03-23 21:31:32,648] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4867
[2019-03-23 21:31:32,653] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.6, 54.0, 1.0, 2.0, 0.4214216082804845, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 524731.2009297631, 524731.2009297631, 131732.6862286552], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2527200.0000, 
sim time next is 2527800.0000, 
raw observation next is [25.86666666666667, 53.16666666666666, 1.0, 2.0, 0.4349292468753029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 540936.7562627655, 540936.7562627655, 133692.683212371], 
processed observation next is [1.0, 0.2608695652173913, 0.5135802469135804, 0.5316666666666666, 1.0, 1.0, 0.32729672247059866, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1931916986652734, 0.1931916986652734, 0.2571013138699442], 
reward next is 0.7429, 
noisyNet noise sample is [array([0.94570327], dtype=float32), 2.0274818]. 
=============================================
[2019-03-23 21:31:34,882] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3163653e-25 1.0000000e+00 0.0000000e+00 5.2879611e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 21:31:34,890] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4358
[2019-03-23 21:31:34,893] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.6, 54.0, 1.0, 2.0, 0.4214216082804845, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 524731.2009297631, 524731.2009297631, 131732.6862286552], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2527200.0000, 
sim time next is 2527800.0000, 
raw observation next is [25.86666666666667, 53.16666666666666, 1.0, 2.0, 0.4349292468753029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 540936.7562627655, 540936.7562627655, 133692.683212371], 
processed observation next is [1.0, 0.2608695652173913, 0.5135802469135804, 0.5316666666666666, 1.0, 1.0, 0.32729672247059866, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1931916986652734, 0.1931916986652734, 0.2571013138699442], 
reward next is 0.7429, 
noisyNet noise sample is [array([0.38166234], dtype=float32), -1.0335485]. 
=============================================
[2019-03-23 21:31:36,725] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.8015088e-12 1.0000000e+00 5.1075846e-21 1.7383809e-18 3.5955130e-21], sum to 1.0000
[2019-03-23 21:31:36,735] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2182
[2019-03-23 21:31:36,749] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1725921.198518538 W.
[2019-03-23 21:31:36,753] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.7, 30.5, 1.0, 2.0, 0.4935859905647588, 1.0, 1.0, 0.4935859905647588, 1.0, 2.0, 0.7880204392022719, 6.911199999999999, 6.9112, 121.94756008, 1725921.198518538, 1725921.198518539, 340562.7271044008], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2557800.0000, 
sim time next is 2558400.0000, 
raw observation next is [33.66666666666666, 30.66666666666666, 1.0, 2.0, 0.5058838784363415, 1.0, 2.0, 0.5058838784363415, 1.0, 2.0, 0.8068880200440504, 6.911200000000001, 6.9112, 121.94756008, 1760636.237737704, 1760636.237737704, 346610.7887270127], 
processed observation next is [1.0, 0.6086956521739131, 0.8024691358024688, 0.3066666666666666, 1.0, 1.0, 0.4117665219480256, 1.0, 1.0, 0.4117665219480256, 1.0, 1.0, 0.7586100250550628, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6287986563348943, 0.6287986563348943, 0.666559209090409], 
reward next is 0.3334, 
noisyNet noise sample is [array([-2.3288732], dtype=float32), 0.15335666]. 
=============================================
[2019-03-23 21:31:40,704] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1605733e-23 1.0000000e+00 0.0000000e+00 1.2676578e-38 0.0000000e+00], sum to 1.0000
[2019-03-23 21:31:40,714] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8159
[2019-03-23 21:31:40,720] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666666, 76.33333333333333, 1.0, 2.0, 0.5497191196272908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 645336.6819356454, 645336.6819356454, 150514.5785114196], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2641800.0000, 
sim time next is 2642400.0000, 
raw observation next is [25.8, 76.0, 1.0, 2.0, 0.553439819058254, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 648697.0099043174, 648697.009904317, 151087.2150764519], 
processed observation next is [0.0, 0.6086956521739131, 0.5111111111111112, 0.76, 1.0, 1.0, 0.4683807369741119, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23167750353725622, 0.23167750353725605, 0.2905523366854844], 
reward next is 0.7094, 
noisyNet noise sample is [array([-0.24645275], dtype=float32), -0.29412922]. 
=============================================
[2019-03-23 21:31:46,726] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.3173103e-24 1.0000000e+00 0.0000000e+00 4.5666481e-38 0.0000000e+00], sum to 1.0000
[2019-03-23 21:31:46,733] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5382
[2019-03-23 21:31:46,744] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.91666666666667, 84.83333333333333, 1.0, 2.0, 0.6449019684677452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 734975.7019669173, 734975.7019669173, 165973.6906181919], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2758200.0000, 
sim time next is 2758800.0000, 
raw observation next is [25.83333333333334, 85.66666666666667, 1.0, 2.0, 0.6523135559985128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 743426.5651325795, 743426.5651325795, 167310.7446097803], 
processed observation next is [0.0, 0.9565217391304348, 0.5123456790123458, 0.8566666666666667, 1.0, 1.0, 0.5860875666648961, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2655094875473498, 0.2655094875473498, 0.32175143194188516], 
reward next is 0.6782, 
noisyNet noise sample is [array([-0.6076163], dtype=float32), -0.070270814]. 
=============================================
[2019-03-23 21:31:54,945] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.2574218e-16 1.0000000e+00 8.4505997e-26 6.4332326e-22 3.1131453e-26], sum to 1.0000
[2019-03-23 21:31:54,950] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6133
[2019-03-23 21:31:54,956] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1936433.047328357 W.
[2019-03-23 21:31:54,961] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.75, 81.5, 1.0, 2.0, 0.5659474048320835, 1.0, 2.0, 0.5659474048320835, 1.0, 1.0, 0.901006700112874, 6.911200000000001, 6.9112, 121.94756008, 1936433.047328357, 1936433.047328357, 377134.3976093216], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2901000.0000, 
sim time next is 2901600.0000, 
raw observation next is [27.1, 80.0, 1.0, 2.0, 0.5409215972140974, 1.0, 2.0, 0.5409215972140974, 1.0, 2.0, 0.8611647993513863, 6.9112, 6.9112, 121.94756008, 1850716.599265571, 1850716.599265571, 364127.5648011952], 
processed observation next is [1.0, 0.6086956521739131, 0.5592592592592593, 0.8, 1.0, 1.0, 0.4534780919215445, 1.0, 1.0, 0.4534780919215445, 1.0, 1.0, 0.8264559991892328, 0.0, 0.0, 0.8096049824067558, 0.6609702140234182, 0.6609702140234182, 0.7002453169253754], 
reward next is 0.2998, 
noisyNet noise sample is [array([-0.48398638], dtype=float32), 0.8766457]. 
=============================================
[2019-03-23 21:32:03,385] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.5486381e-19 1.0000000e+00 1.0062463e-35 7.3285900e-30 1.1855975e-36], sum to 1.0000
[2019-03-23 21:32:03,394] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7528
[2019-03-23 21:32:03,402] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2222298.790246883 W.
[2019-03-23 21:32:03,406] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.43333333333333, 72.33333333333334, 1.0, 2.0, 0.6720537159223479, 1.0, 2.0, 0.6493915199376086, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2222298.790246883, 2222298.790246883, 421814.8551099436], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3072000.0000, 
sim time next is 3072600.0000, 
raw observation next is [31.65, 71.0, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 7.125857129390991, 6.9112, 121.9252370729496, 2437248.080582765, 2327325.170743105, 443050.1090183046], 
processed observation next is [1.0, 0.5652173913043478, 0.7277777777777777, 0.71, 1.0, 1.0, 1.0238095238095237, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.25, 0.021465712939099112, 0.0, 0.8094567808542323, 0.8704457430652732, 0.8311875609796804, 0.8520194404198166], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0373024], dtype=float32), -2.1951509]. 
=============================================
[2019-03-23 21:32:03,708] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3745535e-18 1.0000000e+00 4.1738946e-35 2.4054284e-29 3.3226054e-36], sum to 1.0000
[2019-03-23 21:32:03,718] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2333
[2019-03-23 21:32:03,725] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2138852.040375426 W.
[2019-03-23 21:32:03,730] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.16666666666666, 76.5, 1.0, 2.0, 0.6250362017883437, 1.0, 2.0, 0.6250362017883437, 1.0, 1.0, 0.9950779892550087, 6.911199999999999, 6.9112, 121.94756008, 2138852.040375426, 2138852.040375426, 409185.2494943431], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3064200.0000, 
sim time next is 3064800.0000, 
raw observation next is [30.33333333333334, 77.0, 1.0, 2.0, 0.9405640628389546, 1.0, 2.0, 0.9405640628389546, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.926042545033, 2145726.940111903, 2145726.940111903, 405263.1692040779], 
processed observation next is [1.0, 0.4782608695652174, 0.6790123456790126, 0.77, 1.0, 1.0, 0.9292429319511364, 1.0, 1.0, 0.9292429319511364, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621283512341, 0.7663310500399654, 0.7663310500399654, 0.7793522484693806], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8907788], dtype=float32), -0.35841233]. 
=============================================
[2019-03-23 21:32:16,516] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 21:32:16,518] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:32:16,518] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:32:16,519] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:32:16,519] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:32:16,520] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:32:16,521] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:32:16,523] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:32:16,521] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:32:16,526] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:32:16,528] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:32:16,537] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run13
[2019-03-23 21:32:16,559] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run13
[2019-03-23 21:32:16,582] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run13
[2019-03-23 21:32:16,584] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run13
[2019-03-23 21:32:16,627] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run13
[2019-03-23 21:32:37,156] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.13273919]
[2019-03-23 21:32:37,157] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.90615078, 76.461792585, 1.0, 2.0, 0.322636936424497, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 408403.7741933502, 408403.7741933502, 118398.0964728456]
[2019-03-23 21:32:37,159] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:32:37,161] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.3113135e-24 1.0000000e+00 0.0000000e+00 5.2960535e-37 0.0000000e+00], sampled 0.9685728644318743
[2019-03-23 21:32:45,600] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.13273919]
[2019-03-23 21:32:45,602] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.66666666666667, 63.66666666666667, 1.0, 2.0, 0.580760288904121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 670989.0110969135, 670989.0110969135, 155241.7048993433]
[2019-03-23 21:32:45,603] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:32:45,606] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.3113135e-24 1.0000000e+00 0.0000000e+00 5.2960535e-37 0.0000000e+00], sampled 0.8916487068067711
[2019-03-23 21:32:49,886] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.13273919]
[2019-03-23 21:32:49,887] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.66666666666667, 69.33333333333334, 1.0, 2.0, 0.5924926513924373, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.926042604884, 675220.0475266285, 675220.0475266285, 156793.1331543267]
[2019-03-23 21:32:49,888] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:32:49,890] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.3113135e-24 1.0000000e+00 0.0000000e+00 5.2960535e-37 0.0000000e+00], sampled 0.7377945270976206
[2019-03-23 21:33:05,435] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.13273919]
[2019-03-23 21:33:05,437] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.61622176, 78.33743309333333, 1.0, 2.0, 0.5640524419289394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 657896.4919635216, 657896.4919635216, 152713.8719890511]
[2019-03-23 21:33:05,438] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:33:05,441] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.3113135e-24 1.0000000e+00 0.0000000e+00 5.2960535e-37 0.0000000e+00], sampled 0.8790233444735245
[2019-03-23 21:33:07,142] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.13273919]
[2019-03-23 21:33:07,144] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.95, 82.33333333333333, 1.0, 2.0, 0.6106390508065095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 700878.1381464239, 700878.1381464234, 160162.4608681803]
[2019-03-23 21:33:07,146] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:33:07,148] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.3113135e-24 1.0000000e+00 0.0000000e+00 5.2960535e-37 0.0000000e+00], sampled 0.00022059163012388971
[2019-03-23 21:33:20,779] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.13273919]
[2019-03-23 21:33:20,780] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.28460893666667, 76.18444219333333, 1.0, 2.0, 0.6408788219488787, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 730388.4564622398, 730388.4564622398, 165252.2522233289]
[2019-03-23 21:33:20,781] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:33:20,784] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.3113135e-24 1.0000000e+00 0.0000000e+00 5.2960535e-37 0.0000000e+00], sampled 0.5800372089729405
[2019-03-23 21:33:29,602] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.13273919]
[2019-03-23 21:33:29,603] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.41666666666666, 60.0, 1.0, 2.0, 0.6581303549785283, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426155754, 1465013.867127811, 1465013.86712781, 309784.0551926882]
[2019-03-23 21:33:29,603] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:33:29,608] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.3113135e-24 1.0000000e+00 0.0000000e+00 5.2960535e-37 0.0000000e+00], sampled 0.34884903399610334
[2019-03-23 21:33:29,611] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1465013.867127811 W.
[2019-03-23 21:33:48,665] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.13273919]
[2019-03-23 21:33:48,666] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.5, 19.0, 1.0, 2.0, 0.751126832620898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 962139.9361728535, 962139.9361728535, 189480.7748643401]
[2019-03-23 21:33:48,667] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:33:48,670] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.3113135e-24 1.0000000e+00 0.0000000e+00 5.2960535e-37 0.0000000e+00], sampled 0.362780709048246
[2019-03-23 21:33:56,039] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 21:33:56,071] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 21:33:56,286] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 21:33:56,387] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 21:33:56,413] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 21:33:57,427] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 300000, evaluation results [300000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 21:34:02,532] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.3475200e-22 1.0000000e+00 0.0000000e+00 4.5484073e-32 0.0000000e+00], sum to 1.0000
[2019-03-23 21:34:02,538] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1786
[2019-03-23 21:34:02,545] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.91666666666666, 95.0, 1.0, 2.0, 0.6501909115890347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 765902.3546756374, 765902.3546756374, 168089.2948455675], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3388200.0000, 
sim time next is 3388800.0000, 
raw observation next is [22.93333333333333, 96.0, 1.0, 2.0, 0.625019625369211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 734227.102072507, 734227.102072507, 163457.5180483424], 
processed observation next is [1.0, 0.21739130434782608, 0.40493827160493817, 0.96, 1.0, 1.0, 0.5535947921062035, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26222396502589534, 0.26222396502589534, 0.31434138086219693], 
reward next is 0.6857, 
noisyNet noise sample is [array([-0.5413917], dtype=float32), -0.4279318]. 
=============================================
[2019-03-23 21:34:06,427] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.2808515e-22 1.0000000e+00 8.9154214e-37 3.6232801e-31 7.9230698e-37], sum to 1.0000
[2019-03-23 21:34:06,436] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4290
[2019-03-23 21:34:06,439] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.6655087292612415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 758472.2368332723, 758472.2368332723, 169715.8918246026], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3459000.0000, 
sim time next is 3459600.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.6658284007805595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 758836.7429282625, 758836.7429282625, 169774.4979504457], 
processed observation next is [1.0, 0.043478260869565216, 0.48148148148148145, 0.94, 1.0, 1.0, 0.6021766675959042, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2710131224743794, 0.2710131224743794, 0.32648941913547247], 
reward next is 0.6735, 
noisyNet noise sample is [array([-1.7672606], dtype=float32), -0.68966043]. 
=============================================
[2019-03-23 21:34:06,994] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.2983231e-23 1.0000000e+00 0.0000000e+00 3.1728785e-32 0.0000000e+00], sum to 1.0000
[2019-03-23 21:34:07,002] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9099
[2019-03-23 21:34:07,011] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 91.0, 1.0, 2.0, 0.6147613657161599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 707218.8974127766, 707218.8974127766, 160959.4492349096], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3463200.0000, 
sim time next is 3463800.0000, 
raw observation next is [24.41666666666667, 92.5, 1.0, 2.0, 1.009109170064276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.266816884624073, 6.9112, 122.7944335829488, 1343154.155126064, 1159749.504662291, 243586.128243926], 
processed observation next is [1.0, 0.08695652173913043, 0.4598765432098767, 0.925, 1.0, 1.0, 1.0108442500765191, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0355616884624073, 0.0, 0.8152273417799636, 0.47969791254502286, 0.4141962516651039, 0.46843486200755], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.6466689], dtype=float32), 1.4405723]. 
=============================================
[2019-03-23 21:34:19,774] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.846394e-21 1.000000e+00 7.513931e-36 8.380274e-31 6.766008e-37], sum to 1.0000
[2019-03-23 21:34:19,782] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9457
[2019-03-23 21:34:19,786] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.8, 89.5, 1.0, 2.0, 0.71586348645465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 815891.4872938138, 815891.4872938138, 179172.031678622], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3695400.0000, 
sim time next is 3696000.0000, 
raw observation next is [26.73333333333333, 89.66666666666667, 1.0, 2.0, 0.7217989426768721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 822659.9385202851, 822659.9385202846, 180314.6247122931], 
processed observation next is [1.0, 0.782608695652174, 0.545679012345679, 0.8966666666666667, 1.0, 1.0, 0.6688082650915144, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2938071209001018, 0.29380712090010164, 0.34675889367748675], 
reward next is 0.6532, 
noisyNet noise sample is [array([-0.46151137], dtype=float32), -0.78487056]. 
=============================================
[2019-03-23 21:34:19,813] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[59.342056]
 [59.342056]
 [59.342056]
 [59.342056]
 [59.342056]], R is [[59.40187836]
 [59.4632988 ]
 [59.52335739]
 [59.58435822]
 [59.64837265]].
[2019-03-23 21:34:29,283] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.2958339e-22 1.0000000e+00 1.1559792e-36 1.0980829e-32 4.7601181e-37], sum to 1.0000
[2019-03-23 21:34:29,291] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3778
[2019-03-23 21:34:29,297] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 89.0, 1.0, 2.0, 0.8176001568953689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 931914.3754272321, 931914.375427233, 199611.6080953157], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3880800.0000, 
sim time next is 3881400.0000, 
raw observation next is [27.78333333333333, 89.0, 1.0, 2.0, 0.7817049349450454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 890976.616011591, 890976.616011591, 192196.3192013887], 
processed observation next is [0.0, 0.9565217391304348, 0.5845679012345678, 0.89, 1.0, 1.0, 0.7401249225536255, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31820593428985394, 0.31820593428985394, 0.3696083061565167], 
reward next is 0.6304, 
noisyNet noise sample is [array([0.15251943], dtype=float32), -1.0904597]. 
=============================================
[2019-03-23 21:34:48,476] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 21:34:48,478] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:34:48,478] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:34:48,479] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:34:48,479] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:34:48,480] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:34:48,480] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:34:48,481] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:34:48,482] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:34:48,483] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:34:48,484] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:34:48,493] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run14
[2019-03-23 21:34:48,494] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run14
[2019-03-23 21:34:48,537] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run14
[2019-03-23 21:34:48,561] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run14
[2019-03-23 21:34:48,583] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run14
[2019-03-23 21:34:55,103] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.15240479]
[2019-03-23 21:34:55,104] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [32.4, 24.66666666666667, 1.0, 2.0, 0.5492451765111516, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9077330374296462, 6.9112, 6.9112, 121.9260426156618, 1357102.467765729, 1357102.467765729, 270670.010571191]
[2019-03-23 21:34:55,105] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:34:55,108] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.02814085e-22 1.00000000e+00 0.00000000e+00 2.34411309e-35
 0.00000000e+00], sampled 0.04157630181981209
[2019-03-23 21:34:55,110] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1357102.467765729 W.
[2019-03-23 21:35:12,556] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.15240479]
[2019-03-23 21:35:12,556] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.29356141166667, 56.19991069833333, 1.0, 2.0, 0.4750192326140608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 568420.6841117146, 568420.6841117146, 139093.5351383278]
[2019-03-23 21:35:12,557] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:35:12,559] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.02814085e-22 1.00000000e+00 0.00000000e+00 2.34411309e-35
 0.00000000e+00], sampled 0.27785143431442116
[2019-03-23 21:35:14,761] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.15240479]
[2019-03-23 21:35:14,763] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.25, 43.0, 1.0, 2.0, 0.4861434642808177, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 580135.622023803, 580135.622023803, 140746.1654716925]
[2019-03-23 21:35:14,766] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:35:14,767] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.02814085e-22 1.00000000e+00 0.00000000e+00 2.34411309e-35
 0.00000000e+00], sampled 0.7066298918669022
[2019-03-23 21:36:10,624] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.15240479]
[2019-03-23 21:36:10,626] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.86509195666667, 45.457877115, 1.0, 2.0, 0.3326214151494732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 423022.9000181, 423022.9000181, 119693.9617313397]
[2019-03-23 21:36:10,627] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:36:10,629] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.02814085e-22 1.00000000e+00 0.00000000e+00 2.34411309e-35
 0.00000000e+00], sampled 0.9894443425201047
[2019-03-23 21:36:27,134] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 21:36:28,120] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 21:36:28,192] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 21:36:28,357] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 21:36:28,428] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 21:36:29,443] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 325000, evaluation results [325000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 21:36:31,502] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.3701934e-20 1.0000000e+00 1.5451750e-33 7.1460234e-31 9.2599780e-35], sum to 1.0000
[2019-03-23 21:36:31,507] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4099
[2019-03-23 21:36:31,514] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1646018.189359148 W.
[2019-03-23 21:36:31,523] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.0, 38.0, 1.0, 2.0, 0.7884928949411585, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9697362822967556, 6.911200000000001, 6.9112, 121.9260426156618, 1646018.189359148, 1646018.189359147, 328455.143441694], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4276800.0000, 
sim time next is 4277400.0000, 
raw observation next is [32.0, 38.0, 1.0, 2.0, 0.7427062232701606, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9693527087938554, 6.911199999999999, 6.9112, 121.9260426156618, 1592433.283744944, 1592433.283744945, 319394.7720569794], 
processed observation next is [1.0, 0.5217391304347826, 0.7407407407407407, 0.38, 1.0, 1.0, 0.6936978848454293, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9616908859923192, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5687261727660514, 0.5687261727660518, 0.6142207154941912], 
reward next is 0.3858, 
noisyNet noise sample is [array([1.632491], dtype=float32), 0.4772657]. 
=============================================
[2019-03-23 21:36:38,151] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2063137e-14 1.0000000e+00 8.5470776e-27 3.0019482e-24 1.1049186e-26], sum to 1.0000
[2019-03-23 21:36:38,158] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1389
[2019-03-23 21:36:38,162] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 62.5, 1.0, 2.0, 0.6813474211527047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 776532.5456936976, 776532.5456936976, 172645.3065369135], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4386600.0000, 
sim time next is 4387200.0000, 
raw observation next is [31.0, 63.66666666666667, 1.0, 2.0, 0.6959154953220626, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 793144.3891161422, 793144.3891161422, 175375.2857435367], 
processed observation next is [1.0, 0.782608695652174, 0.7037037037037037, 0.6366666666666667, 1.0, 1.0, 0.6379946372881699, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2832658532557651, 0.2832658532557651, 0.3372601648914167], 
reward next is 0.6627, 
noisyNet noise sample is [array([-0.3120155], dtype=float32), -2.070394]. 
=============================================
[2019-03-23 21:36:46,420] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.5134843e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:36:46,430] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2002
[2019-03-23 21:36:46,435] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.28333333333333, 92.66666666666667, 1.0, 2.0, 0.554292886235663, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 651205.0135238642, 651205.0135238642, 151291.79618265], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4535400.0000, 
sim time next is 4536000.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.5482734601888475, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 645585.5706407265, 645585.5706407265, 150356.7761478007], 
processed observation next is [0.0, 0.5217391304347826, 0.4074074074074074, 0.94, 1.0, 1.0, 0.46223030974862794, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23056627522883089, 0.23056627522883089, 0.2891476464380783], 
reward next is 0.7109, 
noisyNet noise sample is [array([2.140299], dtype=float32), -0.3724641]. 
=============================================
[2019-03-23 21:36:46,457] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[79.15182]
 [79.15182]
 [79.15182]
 [79.15182]
 [79.15182]], R is [[79.0711441 ]
 [78.98948669]
 [78.90687561]
 [78.82337189]
 [78.73899841]].
[2019-03-23 21:36:50,551] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0778370e-20 1.0000000e+00 4.5896406e-34 9.4440025e-31 8.8342476e-35], sum to 1.0000
[2019-03-23 21:36:50,563] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8775
[2019-03-23 21:36:50,572] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1796213.28102835 W.
[2019-03-23 21:36:50,576] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.36666666666667, 64.83333333333333, 1.0, 2.0, 0.9482930116269712, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426156618, 1796213.28102835, 1796213.281028349, 367597.7849428838], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4629000.0000, 
sim time next is 4629600.0000, 
raw observation next is [29.5, 64.0, 1.0, 2.0, 0.5279008332337731, 1.0, 1.0, 0.5279008332337731, 1.0, 2.0, 0.8404353190380323, 6.911200000000001, 6.9112, 121.94756008, 1806122.14476955, 1806122.144769549, 357494.0968838408], 
processed observation next is [1.0, 0.6086956521739131, 0.6481481481481481, 0.64, 1.0, 1.0, 0.43797718242115846, 1.0, 0.5, 0.43797718242115846, 1.0, 1.0, 0.8005441487975403, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6450436231319822, 0.6450436231319817, 0.68748864785354], 
reward next is 0.3125, 
noisyNet noise sample is [array([-0.40761635], dtype=float32), -0.09813008]. 
=============================================
[2019-03-23 21:36:50,742] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.9692444e-16 1.0000000e+00 2.3409110e-30 6.0390226e-27 1.7905305e-30], sum to 1.0000
[2019-03-23 21:36:50,749] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2215
[2019-03-23 21:36:50,758] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1356170.278875021 W.
[2019-03-23 21:36:50,764] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.83333333333334, 68.16666666666667, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.288552069651509, 6.9112, 121.9244378803633, 1356170.278875021, 1162934.835178963, 245581.9638333702], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4626600.0000, 
sim time next is 4627200.0000, 
raw observation next is [28.96666666666667, 67.33333333333334, 1.0, 2.0, 0.8452071991847675, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.9258153807879, 1678539.986293856, 1678539.986293856, 345390.1455855774], 
processed observation next is [1.0, 0.5652173913043478, 0.6283950617283951, 0.6733333333333335, 1.0, 1.0, 0.8157228561723423, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, 0.0, 0.0, 0.8094606202168808, 0.59947856653352, 0.59947856653352, 0.6642118184338027], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.00901778], dtype=float32), -0.18053693]. 
=============================================
[2019-03-23 21:36:51,531] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.43936685e-12 1.00000000e+00 1.23197670e-19 1.57594616e-17
 1.10966966e-20], sum to 1.0000
[2019-03-23 21:36:51,536] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8267
[2019-03-23 21:36:51,546] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.46666666666667, 70.66666666666667, 1.0, 2.0, 0.374991662632373, 1.0, 2.0, 0.374991662632373, 1.0, 2.0, 0.596998939536582, 6.9112, 6.9112, 121.94756008, 1282558.415912347, 1282558.415912347, 286300.4738989697], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4624800.0000, 
sim time next is 4625400.0000, 
raw observation next is [28.58333333333334, 69.83333333333333, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.630060428286988, 6.9112, 121.9231782154529, 1531179.750984252, 1163067.608921953, 245582.2273458659], 
processed observation next is [1.0, 0.5217391304347826, 0.6141975308641977, 0.6983333333333333, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.07188604282869884, 0.0, 0.8094431121815151, 0.5468499110658043, 0.41538128890069753, 0.4722735141266652], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1596246], dtype=float32), -0.30669138]. 
=============================================
[2019-03-23 21:36:52,516] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4459089e-19 1.0000000e+00 9.4392288e-35 3.8995690e-31 2.0662681e-34], sum to 1.0000
[2019-03-23 21:36:52,528] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4344
[2019-03-23 21:36:52,531] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.6665026514875679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 759605.5592259066, 759605.5592259066, 169898.1704886136], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4668600.0000, 
sim time next is 4669200.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.6667898871059881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 759933.0806957921, 759933.0806957921, 169950.8790615674], 
processed observation next is [1.0, 0.043478260869565216, 0.48148148148148145, 0.94, 1.0, 1.0, 0.6033212941737953, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2714046716770686, 0.2714046716770686, 0.3268286135799373], 
reward next is 0.6732, 
noisyNet noise sample is [array([-0.28438777], dtype=float32), 0.04199271]. 
=============================================
[2019-03-23 21:36:52,950] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.250544e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:36:52,958] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0770
[2019-03-23 21:36:52,963] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.6, 94.33333333333334, 1.0, 2.0, 0.6906755176941031, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156468, 801547.951432071, 801547.951432071, 175091.1921495934], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4675200.0000, 
sim time next is 4675800.0000, 
raw observation next is [23.3, 94.16666666666667, 1.0, 2.0, 0.6543483292857246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 764507.2306976496, 764507.2306976496, 168576.3868112946], 
processed observation next is [1.0, 0.08695652173913043, 0.41851851851851857, 0.9416666666666668, 1.0, 1.0, 0.5885099158163388, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.273038296677732, 0.273038296677732, 0.3241853592524896], 
reward next is 0.6758, 
noisyNet noise sample is [array([0.3522516], dtype=float32), 1.4115393]. 
=============================================
[2019-03-23 21:36:55,885] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.3540986e-13 1.0000000e+00 2.1512234e-23 5.6901027e-21 1.4290714e-23], sum to 1.0000
[2019-03-23 21:36:55,892] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9839
[2019-03-23 21:36:55,895] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 94.0, 1.0, 2.0, 0.6473629807312333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 737781.7946191367, 737781.7946191367, 166416.5761687525], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4753200.0000, 
sim time next is 4753800.0000, 
raw observation next is [24.5, 94.0, 1.0, 2.0, 0.6355521823479904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 724637.9157864511, 724637.9157864511, 164316.4209351063], 
processed observation next is [1.0, 0.0, 0.46296296296296297, 0.94, 1.0, 1.0, 0.5661335504142743, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25879925563801826, 0.25879925563801826, 0.3159931171828967], 
reward next is 0.6840, 
noisyNet noise sample is [array([0.25391597], dtype=float32), -0.99827516]. 
=============================================
[2019-03-23 21:37:00,852] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0416077e-12 1.0000000e+00 2.5145510e-19 1.7598531e-17 7.0623782e-20], sum to 1.0000
[2019-03-23 21:37:00,860] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1611
[2019-03-23 21:37:00,868] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1936233.954852902 W.
[2019-03-23 21:37:00,874] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.08333333333333, 88.33333333333334, 1.0, 2.0, 0.5658892804976134, 1.0, 2.0, 0.5658892804976134, 1.0, 1.0, 0.9009141642794202, 6.911200000000002, 6.9112, 121.94756008, 1936233.954852902, 1936233.954852901, 377103.7963607576], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4805400.0000, 
sim time next is 4806000.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.8253583355084951, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1655884.122729214, 1655884.122729214, 341329.6279284834], 
processed observation next is [1.0, 0.6521739130434783, 0.5555555555555556, 0.89, 1.0, 1.0, 0.7920932565577323, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8094621288201359, 0.5913871866890049, 0.5913871866890049, 0.6564031306316989], 
reward next is 0.3436, 
noisyNet noise sample is [array([-1.8442018], dtype=float32), 0.04493599]. 
=============================================
[2019-03-23 21:37:00,895] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[26.660252]
 [26.660252]
 [26.660252]
 [26.660252]
 [26.660252]], R is [[26.73724556]
 [26.74467468]
 [26.77786064]
 [26.81270599]
 [26.54457855]].
[2019-03-23 21:37:02,139] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.4035658e-22 1.0000000e+00 2.7072215e-36 1.0538786e-33 3.5906163e-38], sum to 1.0000
[2019-03-23 21:37:02,146] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0754
[2019-03-23 21:37:02,151] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.13333333333333, 91.33333333333334, 1.0, 2.0, 0.775397689074088, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 883783.5582130993, 883783.5582130989, 190914.8241853414], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4822800.0000, 
sim time next is 4823400.0000, 
raw observation next is [27.16666666666667, 90.66666666666666, 1.0, 2.0, 0.7750822882967356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 883423.8632069572, 883423.8632069572, 190850.6687165044], 
processed observation next is [1.0, 0.8260869565217391, 0.5617283950617286, 0.9066666666666666, 1.0, 1.0, 0.7322408194008757, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3155085225739133, 0.3155085225739133, 0.36702051676250846], 
reward next is 0.6330, 
noisyNet noise sample is [array([-0.84872204], dtype=float32), 0.45942247]. 
=============================================
[2019-03-23 21:37:05,638] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.7444336e-11 1.0000000e+00 1.1542493e-18 1.1496408e-16 1.6990702e-18], sum to 1.0000
[2019-03-23 21:37:05,645] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0687
[2019-03-23 21:37:05,651] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.03333333333333, 88.0, 1.0, 2.0, 0.8905574222817126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1015127.370278929, 1015127.370278929, 215373.7755569844], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4908000.0000, 
sim time next is 4908600.0000, 
raw observation next is [29.05, 87.5, 1.0, 2.0, 0.8860704450001174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1010009.390021018, 1010009.390021018, 214377.7434731473], 
processed observation next is [1.0, 0.8260869565217391, 0.6314814814814815, 0.875, 1.0, 1.0, 0.8643695773810922, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3607176392932207, 0.3607176392932207, 0.41226489129451405], 
reward next is 0.5877, 
noisyNet noise sample is [array([-1.541368], dtype=float32), -0.4498649]. 
=============================================
[2019-03-23 21:37:06,854] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.3724545e-19 1.0000000e+00 2.8782122e-33 6.8241956e-31 2.9022252e-33], sum to 1.0000
[2019-03-23 21:37:06,861] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9955
[2019-03-23 21:37:06,867] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.25, 81.0, 1.0, 2.0, 0.5657163138015461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 672723.7386355778, 672723.7386355774, 153523.5975621759], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4944600.0000, 
sim time next is 4945200.0000, 
raw observation next is [24.16666666666667, 81.66666666666666, 1.0, 2.0, 0.5780585595251345, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 687248.4399504284, 687248.4399504284, 155611.0570887134], 
processed observation next is [1.0, 0.21739130434782608, 0.45061728395061745, 0.8166666666666665, 1.0, 1.0, 0.49768876133944584, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2454458714108673, 0.2454458714108673, 0.29925203286291036], 
reward next is 0.7007, 
noisyNet noise sample is [array([-0.45153868], dtype=float32), -0.12891321]. 
=============================================
[2019-03-23 21:37:07,736] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.03264874e-23 1.00000000e+00 0.00000000e+00 4.02675109e-37
 0.00000000e+00], sum to 1.0000
[2019-03-23 21:37:07,746] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0656
[2019-03-23 21:37:07,752] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1775982.501769376 W.
[2019-03-23 21:37:07,758] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 84.0, 1.0, 2.0, 0.5191002413820635, 1.0, 2.0, 0.5191002413820635, 1.0, 2.0, 0.8264244901948435, 6.9112, 6.9112, 121.94756008, 1775982.501769376, 1775982.501769376, 353062.5752719082], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4968000.0000, 
sim time next is 4968600.0000, 
raw observation next is [26.0, 84.83333333333333, 1.0, 2.0, 0.8519707368939649, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1686260.141815721, 1686260.141815722, 346790.5549770077], 
processed observation next is [1.0, 0.5217391304347826, 0.5185185185185185, 0.8483333333333333, 1.0, 1.0, 0.8237746867785296, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6022357649341861, 0.6022357649341864, 0.6669049134173225], 
reward next is 0.3331, 
noisyNet noise sample is [array([-1.4187809], dtype=float32), 0.0602337]. 
=============================================
[2019-03-23 21:37:10,812] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.5239614e-15 1.0000000e+00 1.1501099e-24 1.0224774e-22 7.4217878e-25], sum to 1.0000
[2019-03-23 21:37:10,819] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3814
[2019-03-23 21:37:10,824] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 95.0, 1.0, 2.0, 0.6165560002350581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 709056.9207743221, 709056.9207743217, 161263.1311855725], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5003400.0000, 
sim time next is 5004000.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.6076214846200618, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 700740.6411611964, 700740.6411611964, 159796.2523177299], 
processed observation next is [1.0, 0.9565217391304348, 0.4444444444444444, 0.94, 1.0, 1.0, 0.5328827197857878, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25026451470042727, 0.25026451470042727, 0.30730048522640363], 
reward next is 0.6927, 
noisyNet noise sample is [array([2.3662035], dtype=float32), -1.856564]. 
=============================================
[2019-03-23 21:37:10,841] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[36.18291]
 [36.18291]
 [36.18291]
 [36.18291]
 [36.18291]], R is [[36.51378632]
 [36.83852768]
 [37.15721512]
 [37.4700737 ]
 [37.77754974]].
[2019-03-23 21:37:14,658] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0408895e-18 1.0000000e+00 4.9886040e-35 6.4148485e-31 3.5081544e-35], sum to 1.0000
[2019-03-23 21:37:14,666] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9184
[2019-03-23 21:37:14,670] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.6, 69.0, 1.0, 2.0, 0.7740356275453253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 882230.2128074856, 882230.2128074856, 190638.7156037066], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5060400.0000, 
sim time next is 5061000.0000, 
raw observation next is [30.75, 67.5, 1.0, 2.0, 0.7659019811227014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000003, 6.9112, 121.9260426156618, 872954.366765738, 872954.3667657367, 188999.8739331034], 
processed observation next is [0.0, 0.5652173913043478, 0.6944444444444444, 0.675, 1.0, 1.0, 0.7213118822889302, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 2.6645352591003756e-16, 0.0, 0.8094621288201359, 0.3117694167020493, 0.31176941670204883, 0.36346129602519883], 
reward next is 0.6365, 
noisyNet noise sample is [array([-0.01029602], dtype=float32), 1.6894006]. 
=============================================
[2019-03-23 21:37:14,686] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[56.510326]
 [56.510326]
 [56.510326]
 [56.510326]
 [56.510326]], R is [[56.58176041]
 [56.64933014]
 [56.71543884]
 [56.78282166]
 [56.83912659]].
[2019-03-23 21:37:20,409] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 21:37:20,411] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:37:20,412] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:37:20,412] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:37:20,413] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:37:20,413] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:37:20,414] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:37:20,414] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:37:20,415] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:37:20,416] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:37:20,414] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:37:20,436] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run15
[2019-03-23 21:37:20,436] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run15
[2019-03-23 21:37:20,456] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run15
[2019-03-23 21:37:20,500] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run15
[2019-03-23 21:37:20,500] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run15
[2019-03-23 21:37:24,256] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.14668502]
[2019-03-23 21:37:24,257] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [31.93333333333333, 19.33333333333334, 1.0, 2.0, 0.3706512586053405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 474308.9644928267, 474308.9644928267, 124752.6699334582]
[2019-03-23 21:37:24,258] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:37:24,261] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.689077e-23 1.000000e+00 0.000000e+00 1.558148e-35 0.000000e+00], sampled 0.025936414705802546
[2019-03-23 21:38:01,622] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.14668502]
[2019-03-23 21:38:01,623] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [34.5, 59.0, 1.0, 2.0, 0.8294142674026868, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999998, 6.9112, 121.9260426156618, 1660513.591806961, 1660513.591806962, 342160.7380483218]
[2019-03-23 21:38:01,624] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:38:01,626] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.689077e-23 1.000000e+00 0.000000e+00 1.558148e-35 0.000000e+00], sampled 0.8629017307076049
[2019-03-23 21:38:01,628] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1660513.591806961 W.
[2019-03-23 21:38:03,048] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.14668502]
[2019-03-23 21:38:03,049] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.0, 89.0, 1.0, 2.0, 0.5028412261177393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 600233.361398929, 600233.3613989286, 143360.4362465475]
[2019-03-23 21:38:03,050] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:38:03,052] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.689077e-23 1.000000e+00 0.000000e+00 1.558148e-35 0.000000e+00], sampled 0.550523762881628
[2019-03-23 21:38:17,266] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.14668502]
[2019-03-23 21:38:17,266] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.69578205, 99.60382266, 1.0, 2.0, 0.5283603672758729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 618941.077556314, 618941.0775563135, 146974.8379736047]
[2019-03-23 21:38:17,267] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:38:17,268] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [5.689077e-23 1.000000e+00 0.000000e+00 1.558148e-35 0.000000e+00], sampled 0.821282253873787
[2019-03-23 21:38:22,679] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.14668502]
[2019-03-23 21:38:22,681] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [31.0, 69.0, 1.0, 2.0, 0.8117256801840731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 925214.5063828866, 925214.5063828861, 198381.4075003505]
[2019-03-23 21:38:22,682] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:38:22,685] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.689077e-23 1.000000e+00 0.000000e+00 1.558148e-35 0.000000e+00], sampled 0.3032795558492518
[2019-03-23 21:38:35,629] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.14668502]
[2019-03-23 21:38:35,630] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.0, 82.33333333333334, 1.0, 2.0, 0.8574895654025106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 977409.9877031134, 977409.9877031134, 208106.9557595952]
[2019-03-23 21:38:35,631] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:38:35,632] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.689077e-23 1.000000e+00 0.000000e+00 1.558148e-35 0.000000e+00], sampled 0.7022627416654377
[2019-03-23 21:38:42,692] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.14668502]
[2019-03-23 21:38:42,692] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.0, 94.0, 1.0, 2.0, 0.4206105123482934, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 513851.8169924033, 513851.8169924037, 131374.5080756885]
[2019-03-23 21:38:42,695] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:38:42,698] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.689077e-23 1.000000e+00 0.000000e+00 1.558148e-35 0.000000e+00], sampled 0.2888746993068785
[2019-03-23 21:38:47,370] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.14668502]
[2019-03-23 21:38:47,372] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.0, 72.0, 1.0, 2.0, 0.7260273152531289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 827481.7666780286, 827481.7666780286, 181129.8519002096]
[2019-03-23 21:38:47,373] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:38:47,377] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.689077e-23 1.000000e+00 0.000000e+00 1.558148e-35 0.000000e+00], sampled 0.8472822976343117
[2019-03-23 21:38:59,879] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 21:39:00,027] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 21:39:00,423] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 21:39:00,468] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 21:39:00,530] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 21:39:01,544] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 350000, evaluation results [350000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 21:39:06,919] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.2355276e-27 1.0000000e+00 0.0000000e+00 1.9914015e-38 0.0000000e+00], sum to 1.0000
[2019-03-23 21:39:06,925] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0952
[2019-03-23 21:39:06,929] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.25, 84.5, 1.0, 2.0, 0.8915854294160697, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260424825589, 1024801.9769941, 1024801.9769941, 216047.13700693], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5279400.0000, 
sim time next is 5280000.0000, 
raw observation next is [25.2, 84.33333333333334, 1.0, 2.0, 0.8428065406196676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156212, 973976.3639935497, 973976.3639935502, 205641.4772852031], 
processed observation next is [1.0, 0.08695652173913043, 0.4888888888888889, 0.8433333333333334, 1.0, 1.0, 0.8128649293091281, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288198663, 0.3478487014262678, 0.34784870142626795, 0.3954643793946213], 
reward next is 0.6045, 
noisyNet noise sample is [array([0.8667065], dtype=float32), 1.0462632]. 
=============================================
[2019-03-23 21:39:06,948] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[77.773224]
 [77.773224]
 [77.773224]
 [77.773224]
 [77.773224]], R is [[77.60002899]
 [76.82402802]
 [76.51753998]
 [75.75236511]
 [75.68552399]].
[2019-03-23 21:39:07,123] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3250688e-21 1.0000000e+00 1.8291922e-37 3.1270464e-34 1.6563170e-38], sum to 1.0000
[2019-03-23 21:39:07,128] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7575
[2019-03-23 21:39:07,133] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.6, 85.0, 1.0, 2.0, 0.6716486894706646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 784542.5142433527, 784542.5142433527, 171761.3289079002], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5284800.0000, 
sim time next is 5285400.0000, 
raw observation next is [24.48333333333334, 85.33333333333334, 1.0, 2.0, 0.6459977723135669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 755605.9060927734, 755605.9060927734, 167092.3842393419], 
processed observation next is [1.0, 0.17391304347826086, 0.46234567901234597, 0.8533333333333334, 1.0, 1.0, 0.5785687765637701, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2698592521759905, 0.2698592521759905, 0.32133150815258055], 
reward next is 0.6787, 
noisyNet noise sample is [array([1.5451578], dtype=float32), -1.2982992]. 
=============================================
[2019-03-23 21:39:10,189] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1704953e-11 1.0000000e+00 2.9311040e-21 6.1064619e-18 5.4050251e-21], sum to 1.0000
[2019-03-23 21:39:10,194] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6834
[2019-03-23 21:39:10,198] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.23333333333333, 79.66666666666667, 1.0, 2.0, 0.6153129890868128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 706456.9126558809, 706456.9126558809, 160988.7772989157], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5354400.0000, 
sim time next is 5355000.0000, 
raw observation next is [26.15, 80.0, 1.0, 2.0, 0.6135671389300862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 704941.8946112752, 704941.8946112752, 160707.0756351371], 
processed observation next is [1.0, 1.0, 0.524074074074074, 0.8, 1.0, 1.0, 0.539960879678674, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2517649623611697, 0.2517649623611697, 0.3090520685291098], 
reward next is 0.6909, 
noisyNet noise sample is [array([1.1996031], dtype=float32), 0.8411293]. 
=============================================
[2019-03-23 21:39:10,210] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[29.47895]
 [29.47895]
 [29.47895]
 [29.47895]
 [29.47895]], R is [[29.87510872]
 [30.26676559]
 [30.65392876]
 [31.03660202]
 [31.41504288]].
[2019-03-23 21:39:12,960] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.524612e-23 1.000000e+00 0.000000e+00 9.189318e-35 0.000000e+00], sum to 1.0000
[2019-03-23 21:39:12,969] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0694
[2019-03-23 21:39:12,975] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1836560.032384465 W.
[2019-03-23 21:39:12,980] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.66666666666666, 77.66666666666667, 1.0, 2.0, 0.8051821681468723, 1.0, 2.0, 0.8051821681468723, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1836560.032384465, 1836560.032384465, 345900.3442241622], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5395200.0000, 
sim time next is 5395800.0000, 
raw observation next is [27.83333333333334, 76.83333333333333, 1.0, 2.0, 0.8236338960707611, 1.0, 2.0, 0.8236338960707611, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1878691.300383059, 1878691.300383059, 353617.051078835], 
processed observation next is [1.0, 0.43478260869565216, 0.58641975308642, 0.7683333333333333, 1.0, 1.0, 0.7900403524651918, 1.0, 1.0, 0.7900403524651918, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6709611787082354, 0.6709611787082354, 0.6800327905362211], 
reward next is 0.3200, 
noisyNet noise sample is [array([-0.20398226], dtype=float32), -0.45089275]. 
=============================================
[2019-03-23 21:39:21,650] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.5050792e-21 1.0000000e+00 5.4627094e-37 2.2592899e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 21:39:21,656] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6896
[2019-03-23 21:39:21,662] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.36666666666667, 93.0, 1.0, 2.0, 0.7687934814458343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 876251.9046503331, 876251.9046503326, 189573.8803037528], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5545200.0000, 
sim time next is 5545800.0000, 
raw observation next is [25.35, 93.0, 1.0, 2.0, 0.7548191582407742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 860315.3751440179, 860315.3751440179, 186779.0651612997], 
processed observation next is [1.0, 0.17391304347826086, 0.4944444444444445, 0.93, 1.0, 1.0, 0.7081180455247311, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.30725549112286354, 0.30725549112286354, 0.35919050992557633], 
reward next is 0.6408, 
noisyNet noise sample is [array([-1.2647654], dtype=float32), -0.12053792]. 
=============================================
[2019-03-23 21:39:22,996] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.3219991e-21 1.0000000e+00 1.3415426e-36 1.6997492e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 21:39:23,005] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3316
[2019-03-23 21:39:23,012] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1649906.689029097 W.
[2019-03-23 21:39:23,016] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.2, 78.66666666666667, 1.0, 2.0, 0.7234253644697018, 1.0, 1.0, 0.7234253644697018, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1649906.689029097, 1649906.689029098, 313128.1622838145], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5570400.0000, 
sim time next is 5571000.0000, 
raw observation next is [27.4, 78.5, 1.0, 2.0, 0.8660887398334801, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1702375.180803479, 1702375.180803479, 349740.9829656064], 
processed observation next is [1.0, 0.4782608695652174, 0.5703703703703703, 0.785, 1.0, 1.0, 0.8405818331350954, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, 0.0, 0.0, 0.8094621288201359, 0.6079911360012424, 0.6079911360012424, 0.6725788133953969], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5045181], dtype=float32), -0.98898476]. 
=============================================
[2019-03-23 21:39:23,031] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[57.060505]
 [57.060505]
 [57.060505]
 [57.060505]
 [57.060505]], R is [[56.48989487]
 [56.32282639]
 [56.1170578 ]
 [55.55588913]
 [55.00033188]].
[2019-03-23 21:39:30,758] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0172698e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:39:30,772] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0398
[2019-03-23 21:39:30,781] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 94.0, 1.0, 2.0, 0.5505829811972482, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 647286.0818777919, 647286.0818777919, 150696.1030139421], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5702400.0000, 
sim time next is 5703000.0000, 
raw observation next is [23.0, 94.33333333333334, 1.0, 2.0, 0.549012748052397, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 646126.5283136271, 646126.5283136271, 150465.2529770861], 
processed observation next is [0.0, 0.0, 0.4074074074074074, 0.9433333333333335, 1.0, 1.0, 0.46311041434809164, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23075947439772396, 0.23075947439772396, 0.28935625572516555], 
reward next is 0.7106, 
noisyNet noise sample is [array([1.7565404], dtype=float32), -0.77011466]. 
=============================================
[2019-03-23 21:39:30,793] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[79.00437]
 [79.00437]
 [79.00437]
 [79.00437]
 [79.00437]], R is [[78.92497253]
 [78.84592438]
 [78.76681519]
 [78.68781281]
 [78.60909271]].
[2019-03-23 21:39:38,467] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.5559095e-17 1.0000000e+00 1.6707853e-31 4.0143136e-29 2.7647536e-32], sum to 1.0000
[2019-03-23 21:39:38,475] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8394
[2019-03-23 21:39:38,478] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.21666666666667, 46.83333333333334, 1.0, 2.0, 0.6515033359358132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 809135.2734918176, 809135.2734918181, 169717.0940889971], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5835000.0000, 
sim time next is 5835600.0000, 
raw observation next is [27.3, 47.0, 1.0, 2.0, 0.6484585954557933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 804258.9868667234, 804258.9868667234, 169127.5124436018], 
processed observation next is [1.0, 0.5652173913043478, 0.5666666666666667, 0.47, 1.0, 1.0, 0.5814983279235635, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2872353524524012, 0.2872353524524012, 0.32524521623769576], 
reward next is 0.6748, 
noisyNet noise sample is [array([0.71829927], dtype=float32), -0.13830873]. 
=============================================
[2019-03-23 21:39:41,838] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.5705948e-23 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:39:41,845] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0412
[2019-03-23 21:39:41,853] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.1, 73.0, 1.0, 2.0, 0.3837821640829172, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 479625.7139215429, 479625.7139215425, 126441.2073877151], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5904000.0000, 
sim time next is 5904600.0000, 
raw observation next is [22.35, 72.16666666666667, 1.0, 2.0, 0.4056772676021537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 506267.9693721088, 506267.9693721083, 129496.8024067949], 
processed observation next is [1.0, 0.34782608695652173, 0.38333333333333336, 0.7216666666666667, 1.0, 1.0, 0.2924729376216116, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18080998906146745, 0.18080998906146725, 0.24903231232075942], 
reward next is 0.7510, 
noisyNet noise sample is [array([-0.89438725], dtype=float32), -0.26259974]. 
=============================================
[2019-03-23 21:39:43,669] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.6701884e-19 1.0000000e+00 3.7902231e-36 4.4667968e-34 5.2638045e-38], sum to 1.0000
[2019-03-23 21:39:43,676] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0411
[2019-03-23 21:39:43,681] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.6, 68.33333333333333, 1.0, 2.0, 0.4899221221304359, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 588593.999987, 588593.999987, 141472.8592579244], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5949600.0000, 
sim time next is 5950200.0000, 
raw observation next is [25.4, 69.66666666666667, 1.0, 2.0, 0.4912396989409512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 589979.5869789051, 589979.5869789051, 141671.2884409814], 
processed observation next is [1.0, 0.8695652173913043, 0.49629629629629624, 0.6966666666666668, 1.0, 1.0, 0.3943329749297038, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.210706995349609, 0.210706995349609, 0.2724447854634258], 
reward next is 0.7276, 
noisyNet noise sample is [array([-1.0322576], dtype=float32), -0.6603018]. 
=============================================
[2019-03-23 21:39:45,181] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.0879833e-22 1.0000000e+00 0.0000000e+00 1.9750453e-38 0.0000000e+00], sum to 1.0000
[2019-03-23 21:39:45,194] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0346
[2019-03-23 21:39:45,200] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 81.0, 1.0, 2.0, 0.4128936045076517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 511118.7475398088, 511118.7475398084, 130439.7511947408], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5983200.0000, 
sim time next is 5983800.0000, 
raw observation next is [21.81666666666667, 80.33333333333333, 1.0, 2.0, 0.4713760609782722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 583309.4987617891, 583309.4987617891, 139110.6248964141], 
processed observation next is [1.0, 0.2608695652173913, 0.3635802469135804, 0.8033333333333332, 1.0, 1.0, 0.3706857868788955, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20832482098635324, 0.20832482098635324, 0.2675204324931041], 
reward next is 0.7325, 
noisyNet noise sample is [array([-0.2433631], dtype=float32), -0.35063183]. 
=============================================
[2019-03-23 21:39:45,524] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.397851e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:39:45,540] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0257
[2019-03-23 21:39:45,544] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.86666666666667, 74.33333333333333, 1.0, 2.0, 0.4514145809004704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 556948.1218721712, 556948.1218721712, 136041.7992018514], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5989200.0000, 
sim time next is 5989800.0000, 
raw observation next is [22.98333333333333, 73.66666666666667, 1.0, 2.0, 0.4384946334381089, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 540922.530056348, 540922.530056348, 134117.9544134422], 
processed observation next is [1.0, 0.30434782608695654, 0.40679012345679005, 0.7366666666666667, 1.0, 1.0, 0.33154123028346294, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19318661787726712, 0.19318661787726712, 0.2579191431027735], 
reward next is 0.7421, 
noisyNet noise sample is [array([-0.1486045], dtype=float32), -0.18084222]. 
=============================================
[2019-03-23 21:39:45,876] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.577536e-22 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:39:45,886] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8646
[2019-03-23 21:39:45,894] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.75, 81.5, 1.0, 2.0, 0.4224077360204338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 521987.2963273998, 521987.2963273998, 131788.5213069802], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5974200.0000, 
sim time next is 5974800.0000, 
raw observation next is [21.66666666666666, 82.0, 1.0, 2.0, 0.4212090016962305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 520641.3458957724, 520641.3458957724, 131618.2909835347], 
processed observation next is [1.0, 0.13043478260869565, 0.35802469135802445, 0.82, 1.0, 1.0, 0.3109630972574173, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1859433378199187, 0.1859433378199187, 0.2531120980452591], 
reward next is 0.7469, 
noisyNet noise sample is [array([-0.20613493], dtype=float32), -0.4620312]. 
=============================================
[2019-03-23 21:39:46,592] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.8850194e-22 1.0000000e+00 1.5642619e-38 2.6468154e-32 0.0000000e+00], sum to 1.0000
[2019-03-23 21:39:46,602] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1959
[2019-03-23 21:39:46,616] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1480786.899110224 W.
[2019-03-23 21:39:46,619] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.93333333333333, 70.33333333333333, 1.0, 2.0, 0.6543466287246396, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9755002326636384, 6.911199999999999, 6.9112, 121.9256005550493, 1480786.899110224, 1480786.899110225, 304750.2128557807], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6000000.0000, 
sim time next is 6000600.0000, 
raw observation next is [26.11666666666667, 70.16666666666667, 1.0, 2.0, 0.6312380655197194, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9792341235077785, 6.911200000000001, 6.9112, 121.9260424808633, 1449975.740107649, 1449975.740107649, 301606.9417201556], 
processed observation next is [1.0, 0.43478260869565216, 0.5228395061728397, 0.7016666666666667, 1.0, 1.0, 0.560997697047285, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.974042654384723, 8.881784197001253e-17, 0.0, 0.8094621279252141, 0.5178484786098746, 0.5178484786098746, 0.5800133494618377], 
reward next is 0.4200, 
noisyNet noise sample is [array([0.26926738], dtype=float32), -0.001512]. 
=============================================
[2019-03-23 21:39:50,496] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.1066304e-24 1.0000000e+00 0.0000000e+00 3.8529077e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 21:39:50,503] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7738
[2019-03-23 21:39:50,508] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.55, 90.0, 1.0, 2.0, 0.5922829493553897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 710111.4878193743, 710111.4878193743, 158279.7568211124], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6057000.0000, 
sim time next is 6057600.0000, 
raw observation next is [22.6, 89.66666666666666, 1.0, 2.0, 0.5614489590967575, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 673154.6223671817, 673154.6223671817, 153010.3815619303], 
processed observation next is [1.0, 0.08695652173913043, 0.39259259259259266, 0.8966666666666666, 1.0, 1.0, 0.47791542749613986, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2404123651311363, 0.2404123651311363, 0.29425073377294286], 
reward next is 0.7057, 
noisyNet noise sample is [array([-0.3127556], dtype=float32), -1.0960164]. 
=============================================
[2019-03-23 21:39:52,519] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 21:39:52,521] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:39:52,522] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:39:52,522] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:39:52,524] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:39:52,524] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:39:52,525] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:39:52,526] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:39:52,528] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:39:52,527] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:39:52,529] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:39:52,542] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run16
[2019-03-23 21:39:52,543] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run16
[2019-03-23 21:39:52,565] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run16
[2019-03-23 21:39:52,610] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run16
[2019-03-23 21:39:52,636] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run16
[2019-03-23 21:40:34,600] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.18942255]
[2019-03-23 21:40:34,601] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [19.97046044, 97.1388505, 1.0, 2.0, 0.4157570124711784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 511427.4590331988, 511427.4590331992, 130771.0672850536]
[2019-03-23 21:40:34,602] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:40:34,604] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [5.0790730e-13 1.0000000e+00 5.1545580e-22 2.4912436e-20 2.4111316e-23], sampled 0.19903577933392147
[2019-03-23 21:41:04,290] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.18942255]
[2019-03-23 21:41:04,291] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.53333333333333, 45.0, 1.0, 2.0, 0.3629899101808459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 451634.0122678951, 451634.0122678951, 123567.2316480514]
[2019-03-23 21:41:04,292] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:41:04,294] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.0790730e-13 1.0000000e+00 5.1545580e-22 2.4912436e-20 2.4111316e-23], sampled 0.7614100679405792
[2019-03-23 21:41:24,867] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.18942255]
[2019-03-23 21:41:24,868] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [19.72859084, 79.79604339333335, 1.0, 2.0, 0.3625274043424406, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 459776.814350138, 459776.814350138, 123633.7129304231]
[2019-03-23 21:41:24,869] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:41:24,873] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [5.0790730e-13 1.0000000e+00 5.1545580e-22 2.4912436e-20 2.4111316e-23], sampled 0.7828942309494779
[2019-03-23 21:41:27,721] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.18942255]
[2019-03-23 21:41:27,722] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [17.1, 94.5, 1.0, 2.0, 0.2880617143493983, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 369154.147193694, 369154.147193694, 114113.8848984189]
[2019-03-23 21:41:27,723] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:41:27,727] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.0790730e-13 1.0000000e+00 5.1545580e-22 2.4912436e-20 2.4111316e-23], sampled 0.3551667096151161
[2019-03-23 21:41:32,148] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 21:41:32,303] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 21:41:32,438] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 21:41:32,462] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 21:41:32,535] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 21:41:33,552] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 375000, evaluation results [375000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 21:41:40,140] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.3090415e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:41:40,154] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2390
[2019-03-23 21:41:40,159] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.13333333333333, 86.33333333333334, 1.0, 2.0, 0.4937418765900969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 591291.9303601391, 591291.9303601386, 142002.4580575171], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6243600.0000, 
sim time next is 6244200.0000, 
raw observation next is [23.25, 86.0, 1.0, 2.0, 0.4975834271406459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 595132.6421985315, 595132.6421985315, 142576.583015704], 
processed observation next is [0.0, 0.2608695652173913, 0.4166666666666667, 0.86, 1.0, 1.0, 0.40188503231029277, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21254737221376127, 0.21254737221376127, 0.2741857365686615], 
reward next is 0.7258, 
noisyNet noise sample is [array([1.9458014], dtype=float32), 1.6562629]. 
=============================================
[2019-03-23 21:41:43,369] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.8164878e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:41:43,378] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7013
[2019-03-23 21:41:43,383] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.9, 83.0, 1.0, 2.0, 0.5724344258834972, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 668607.05726827, 668607.05726827, 154162.1612150317], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6303600.0000, 
sim time next is 6304200.0000, 
raw observation next is [24.86666666666667, 83.16666666666667, 1.0, 2.0, 0.5713169825878418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 667535.1512033342, 667535.1512033342, 153983.9570384516], 
processed observation next is [0.0, 1.0, 0.47654320987654336, 0.8316666666666667, 1.0, 1.0, 0.48966307450933544, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23840541114404792, 0.23840541114404792, 0.2961229943047146], 
reward next is 0.7039, 
noisyNet noise sample is [array([-0.6766939], dtype=float32), 1.3143117]. 
=============================================
[2019-03-23 21:41:46,984] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.972386e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:41:46,991] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4251
[2019-03-23 21:41:46,996] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 55.83333333333334, 1.0, 2.0, 0.677905864892625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 772608.2227392163, 772608.2227392163, 172004.2384542454], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6365400.0000, 
sim time next is 6366000.0000, 
raw observation next is [32.0, 55.66666666666667, 1.0, 2.0, 0.6699811151173071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 763571.8995823086, 763571.8995823086, 170539.8480111847], 
processed observation next is [0.0, 0.6956521739130435, 0.7407407407407407, 0.5566666666666668, 1.0, 1.0, 0.6071203751396512, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2727042498508245, 0.2727042498508245, 0.32796124617535516], 
reward next is 0.6720, 
noisyNet noise sample is [array([-0.622719], dtype=float32), 1.4994972]. 
=============================================
[2019-03-23 21:41:47,024] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[69.53117]
 [69.53117]
 [69.53117]
 [69.53117]
 [69.53117]], R is [[69.50790405]
 [69.48204803]
 [69.45261383]
 [69.42371368]
 [69.39537811]].
[2019-03-23 21:41:53,116] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.7872435e-14 1.0000000e+00 1.4841792e-25 1.8410149e-23 5.9629280e-28], sum to 1.0000
[2019-03-23 21:41:53,125] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2062
[2019-03-23 21:41:53,131] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.31666666666667, 71.5, 1.0, 2.0, 0.6608800867646907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 753194.437310878, 753194.4373108775, 168869.0684668426], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6475800.0000, 
sim time next is 6476400.0000, 
raw observation next is [28.2, 72.0, 1.0, 2.0, 0.6592427036458807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 751327.4234782578, 751327.4234782578, 168570.3303488005], 
processed observation next is [1.0, 1.0, 0.6, 0.72, 1.0, 1.0, 0.5943365519593817, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2683312226708064, 0.2683312226708064, 0.3241737122092317], 
reward next is 0.6758, 
noisyNet noise sample is [array([-0.07111621], dtype=float32), 1.353239]. 
=============================================
[2019-03-23 21:41:57,448] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0160316e-13 1.0000000e+00 3.6042159e-23 7.3722291e-20 5.9648707e-25], sum to 1.0000
[2019-03-23 21:41:57,456] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8070
[2019-03-23 21:41:57,459] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.8, 88.0, 1.0, 2.0, 0.7186584678984852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 819078.7151458251, 819078.7151458251, 179708.2425807707], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6552000.0000, 
sim time next is 6552600.0000, 
raw observation next is [26.76666666666667, 87.66666666666667, 1.0, 2.0, 0.7166406155269234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 816777.6769718251, 816777.6769718251, 179319.6758538402], 
processed observation next is [1.0, 0.8695652173913043, 0.5469135802469137, 0.8766666666666667, 1.0, 1.0, 0.6626673994368135, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29170631320422324, 0.29170631320422324, 0.3448455304881542], 
reward next is 0.6552, 
noisyNet noise sample is [array([0.4684167], dtype=float32), 1.2316176]. 
=============================================
[2019-03-23 21:42:08,375] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.204264e-24 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:42:08,382] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3534
[2019-03-23 21:42:08,391] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.71666666666667, 45.5, 1.0, 2.0, 0.3293298713191384, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 416937.2491633601, 416937.2491633601, 119255.0599798773], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6725400.0000, 
sim time next is 6726000.0000, 
raw observation next is [25.43333333333334, 47.0, 1.0, 2.0, 0.330255976534747, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 417965.4919039343, 417965.4919039347, 119372.9297596885], 
processed observation next is [1.0, 0.8695652173913043, 0.4975308641975311, 0.47, 1.0, 1.0, 0.20268568635088927, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1492733899656908, 0.14927338996569095, 0.22956332646093944], 
reward next is 0.7704, 
noisyNet noise sample is [array([-0.40767583], dtype=float32), 0.20634028]. 
=============================================
[2019-03-23 21:42:08,415] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[74.020256]
 [74.020256]
 [74.020256]
 [74.020256]
 [74.020256]], R is [[74.05049133]
 [74.08065033]
 [74.11185455]
 [74.14417267]
 [74.17577362]].
[2019-03-23 21:42:24,544] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 21:42:24,548] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:42:24,550] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:42:24,550] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:42:24,553] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:42:24,553] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:42:24,554] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:42:24,555] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:42:24,554] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:42:24,556] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:42:24,561] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:42:24,573] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run17
[2019-03-23 21:42:24,596] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run17
[2019-03-23 21:42:24,619] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run17
[2019-03-23 21:42:24,639] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run17
[2019-03-23 21:42:24,640] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run17
[2019-03-23 21:43:44,874] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.1589532]
[2019-03-23 21:43:44,876] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.66666666666666, 94.0, 1.0, 2.0, 0.9112074761651431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1038681.878986548, 1038681.878986548, 219981.9447885161]
[2019-03-23 21:43:44,877] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:43:44,882] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0731662e-16 1.0000000e+00 5.2558859e-28 4.3804355e-26 5.8705647e-30], sampled 0.40582130935750227
[2019-03-23 21:43:57,937] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.1589532]
[2019-03-23 21:43:57,938] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.711912665, 86.623135835, 1.0, 2.0, 0.5201457892839737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 614588.4411487565, 614588.4411487565, 145872.4485548711]
[2019-03-23 21:43:57,939] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:43:57,942] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0731662e-16 1.0000000e+00 5.2558859e-28 4.3804355e-26 5.8705647e-30], sampled 0.12491662384227586
[2019-03-23 21:44:03,275] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 21:44:03,696] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 21:44:03,949] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 21:44:04,004] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 21:44:04,156] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 21:44:05,172] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 400000, evaluation results [400000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 21:44:06,137] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.34421629e-19 1.00000000e+00 9.20776348e-30 1.06900544e-26
 4.21696814e-32], sum to 1.0000
[2019-03-23 21:44:06,146] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9366
[2019-03-23 21:44:06,153] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.9, 73.33333333333334, 1.0, 2.0, 0.3278077384094519, 1.0, 2.0, 0.3278077384094519, 1.0, 1.0, 0.5230387467071721, 6.911200000000001, 6.9112, 121.94756008, 1142558.113774642, 1142558.113774641, 266930.1683947499], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7057200.0000, 
sim time next is 7057800.0000, 
raw observation next is [24.65, 74.5, 1.0, 2.0, 0.9031959409926117, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260253498539, 1075010.050976458, 1075010.050976457, 220447.5986406065], 
processed observation next is [1.0, 0.6956521739130435, 0.46851851851851845, 0.745, 1.0, 1.0, 0.884757072610252, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094620141931267, 0.3839321610630207, 0.38393216106302036, 0.42393768969347406], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.47354484], dtype=float32), 0.1249052]. 
=============================================
[2019-03-23 21:44:07,620] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5055179e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:44:07,626] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3088
[2019-03-23 21:44:07,631] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.85, 84.5, 1.0, 2.0, 0.4116482655247432, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 512177.3611633233, 512177.3611633233, 130317.9078284309], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7108200.0000, 
sim time next is 7108800.0000, 
raw observation next is [20.83333333333334, 84.33333333333334, 1.0, 2.0, 0.4033088581095526, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 502058.3452419378, 502058.3452419374, 129136.2228907432], 
processed observation next is [1.0, 0.2608695652173913, 0.3271604938271607, 0.8433333333333334, 1.0, 1.0, 0.2896534025113721, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17930655187212063, 0.1793065518721205, 0.24833889017450617], 
reward next is 0.7517, 
noisyNet noise sample is [array([0.11028756], dtype=float32), 1.1237602]. 
=============================================
[2019-03-23 21:44:14,196] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.1887375e-23 1.0000000e+00 6.2027983e-38 4.2163205e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 21:44:14,201] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5486
[2019-03-23 21:44:14,205] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 79.0, 1.0, 2.0, 0.6622496754931159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 820840.9066638724, 820840.9066638716, 171684.4740493951], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7203000.0000, 
sim time next is 7203600.0000, 
raw observation next is [22.0, 78.0, 1.0, 2.0, 0.6223426551620285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 771104.550076071, 771104.550076071, 164336.7761245793], 
processed observation next is [1.0, 0.391304347826087, 0.37037037037037035, 0.78, 1.0, 1.0, 0.5504079228119386, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2753944821700254, 0.2753944821700254, 0.3160322617780371], 
reward next is 0.6840, 
noisyNet noise sample is [array([-1.3359699], dtype=float32), 0.038414676]. 
=============================================
[2019-03-23 21:44:17,643] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.256257e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:44:17,653] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6387
[2019-03-23 21:44:17,656] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.6, 90.0, 1.0, 2.0, 0.3863114255693202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 478042.398132476, 478042.398132476, 126693.4745558437], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7280400.0000, 
sim time next is 7281000.0000, 
raw observation next is [20.65, 90.0, 1.0, 2.0, 0.3881425250638256, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 479969.4109619539, 479969.4109619539, 126939.3495385118], 
processed observation next is [1.0, 0.2608695652173913, 0.3203703703703703, 0.9, 1.0, 1.0, 0.27159824412360195, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1714176467721264, 0.1714176467721264, 0.2441141337279073], 
reward next is 0.7559, 
noisyNet noise sample is [array([0.7851122], dtype=float32), 0.038175818]. 
=============================================
[2019-03-23 21:44:17,667] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[66.17742]
 [66.17742]
 [66.17742]
 [66.17742]
 [66.17742]], R is [[66.27153778]
 [66.36518097]
 [66.45772552]
 [66.54918671]
 [66.64092255]].
[2019-03-23 21:44:18,111] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.5948643e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:44:18,118] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6052
[2019-03-23 21:44:18,124] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 72.0, 1.0, 2.0, 0.8995668985157994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260096732844, 1090489.992009619, 1090489.992009619, 220415.0882639873], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7300800.0000, 
sim time next is 7301400.0000, 
raw observation next is [24.6, 71.16666666666667, 1.0, 2.0, 0.923396790350832, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.026816198038689, 6.9112, 121.9255250086907, 1177399.55129531, 1118193.975584731, 225864.735770015], 
processed observation next is [1.0, 0.5217391304347826, 0.46666666666666673, 0.7116666666666667, 1.0, 1.0, 0.9088057027986095, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.011561619803868873, 0.0, 0.8094586924481212, 0.420499839748325, 0.3993549912802611, 0.43435526109618267], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5288471], dtype=float32), 0.052431725]. 
=============================================
[2019-03-23 21:44:27,852] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1803064e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:44:27,853] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4925
[2019-03-23 21:44:27,858] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666666, 94.33333333333334, 1.0, 2.0, 0.372261010647395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 463345.9992650067, 463345.9992650067, 124824.5912623287], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7454400.0000, 
sim time next is 7455000.0000, 
raw observation next is [19.73333333333333, 94.16666666666667, 1.0, 2.0, 0.3740170062083767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 465229.4147697355, 465229.4147697355, 125057.6343968954], 
processed observation next is [0.0, 0.2608695652173913, 0.28641975308641965, 0.9416666666666668, 1.0, 1.0, 0.2547821502480675, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16615336241776268, 0.16615336241776268, 0.2404954507632604], 
reward next is 0.7595, 
noisyNet noise sample is [array([-0.7712354], dtype=float32), -1.4155358]. 
=============================================
[2019-03-23 21:44:27,894] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[74.292465]
 [74.292465]
 [74.292465]
 [74.292465]
 [74.292465]], R is [[74.30904388]
 [74.32591248]
 [74.34308624]
 [74.36053467]
 [74.3782196 ]].
[2019-03-23 21:44:29,818] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.3601013e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:44:29,826] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5993
[2019-03-23 21:44:29,835] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.36666666666667, 91.66666666666667, 1.0, 2.0, 0.484689675748523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 581004.6217878967, 581004.6217878964, 140615.1608776627], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7507200.0000, 
sim time next is 7507800.0000, 
raw observation next is [22.3, 92.0, 1.0, 2.0, 0.4833249085386391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 579623.7617983086, 579623.7617983086, 140413.2361201159], 
processed observation next is [0.0, 0.9130434782608695, 0.38148148148148153, 0.92, 1.0, 1.0, 0.38491060540314176, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2070084863565388, 0.2070084863565388, 0.27002545407714595], 
reward next is 0.7300, 
noisyNet noise sample is [array([-1.3789674], dtype=float32), -0.5965439]. 
=============================================
[2019-03-23 21:44:32,377] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.6618241e-24 1.0000000e+00 3.9406672e-36 5.4514085e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 21:44:32,384] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3785
[2019-03-23 21:44:32,389] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333333, 68.66666666666667, 1.0, 2.0, 0.555509550605777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 647134.6803561316, 647134.6803561316, 151257.7424783309], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7562400.0000, 
sim time next is 7563000.0000, 
raw observation next is [27.66666666666667, 67.33333333333333, 1.0, 2.0, 0.5602810712208505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 651426.3207557809, 651426.3207557809, 151993.5622586679], 
processed observation next is [0.0, 0.5217391304347826, 0.580246913580247, 0.6733333333333333, 1.0, 1.0, 0.4765250847867267, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2326522574127789, 0.2326522574127789, 0.2922953120358998], 
reward next is 0.7077, 
noisyNet noise sample is [array([0.3677317], dtype=float32), 0.17542827]. 
=============================================
[2019-03-23 21:44:32,406] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[65.83611]
 [65.83611]
 [65.83611]
 [65.83611]
 [65.83611]], R is [[65.88545227]
 [65.93572235]
 [65.98693848]
 [66.03913879]
 [66.09223938]].
[2019-03-23 21:44:38,542] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.1638156e-17 1.0000000e+00 1.8665595e-28 2.0565334e-26 1.4184051e-30], sum to 1.0000
[2019-03-23 21:44:38,549] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8815
[2019-03-23 21:44:38,555] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.68333333333333, 68.33333333333333, 1.0, 2.0, 0.8787638743250153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260425699297, 1035804.373813701, 1035804.373813701, 214483.1178994341], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7650600.0000, 
sim time next is 7651200.0000, 
raw observation next is [26.76666666666667, 67.66666666666667, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 8.359725779497374, 6.9112, 121.9204877991856, 1945165.454340833, 1203424.581911568, 247744.5805506832], 
processed observation next is [1.0, 0.5652173913043478, 0.5469135802469137, 0.6766666666666667, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.14485257794973744, 0.0, 0.8094252506153359, 0.694701947978869, 0.4297944935398457, 0.47643188567439076], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.28174612], dtype=float32), 0.16922878]. 
=============================================
[2019-03-23 21:44:53,663] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:44:53,664] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:44:53,671] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run3
[2019-03-23 21:44:53,705] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:44:53,706] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:44:53,722] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run3
[2019-03-23 21:44:54,131] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:44:54,131] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:44:54,133] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run3
[2019-03-23 21:44:54,254] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:44:54,254] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:44:54,256] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run3
[2019-03-23 21:44:54,371] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:44:54,371] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:44:54,372] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run3
[2019-03-23 21:44:54,474] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:44:54,474] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:44:54,476] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run3
[2019-03-23 21:44:54,532] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:44:54,532] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:44:54,534] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run3
[2019-03-23 21:44:54,585] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:44:54,585] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:44:54,587] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run3
[2019-03-23 21:44:54,627] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:44:54,628] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:44:54,630] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run3
[2019-03-23 21:44:54,658] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:44:54,659] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:44:54,660] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run3
[2019-03-23 21:44:54,697] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:44:54,697] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:44:54,699] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run3
[2019-03-23 21:44:54,813] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:44:54,813] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:44:54,814] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run3
[2019-03-23 21:44:54,905] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:44:54,906] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:44:54,907] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run3
[2019-03-23 21:44:54,960] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:44:54,961] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:44:54,962] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run3
[2019-03-23 21:44:55,036] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:44:55,036] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:44:55,067] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 21:44:55,068] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:44:55,069] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run3
[2019-03-23 21:44:55,155] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run3
[2019-03-23 21:44:57,111] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.8985673e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:44:57,115] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8860
[2019-03-23 21:44:57,120] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 73.0, 1.0, 2.0, 0.2440387402022744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 314787.4004062574, 314787.4004062574, 97093.7427895964], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 21600.0000, 
sim time next is 22200.0000, 
raw observation next is [18.46666666666667, 70.33333333333334, 1.0, 2.0, 0.2441763321753581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 314964.9177663435, 314964.9177663439, 98123.91381810971], 
processed observation next is [1.0, 0.2608695652173913, 0.23950617283950623, 0.7033333333333335, 1.0, 1.0, 0.1002099192563787, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.11248747063083697, 0.11248747063083711, 0.18869983426559558], 
reward next is 0.8113, 
noisyNet noise sample is [array([0.0560515], dtype=float32), 0.93183076]. 
=============================================
[2019-03-23 21:44:58,093] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 21:44:58,094] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:44:58,095] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:44:58,097] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:44:58,098] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:44:58,099] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:44:58,101] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:44:58,100] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:44:58,102] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:44:58,102] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:44:58,103] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:44:58,117] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run18
[2019-03-23 21:44:58,140] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run18
[2019-03-23 21:44:58,165] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run18
[2019-03-23 21:44:58,165] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run18
[2019-03-23 21:44:58,213] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run18
[2019-03-23 21:45:43,804] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0987508]
[2019-03-23 21:45:43,806] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.52191794, 89.4781961, 1.0, 2.0, 0.8050766171034216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 917631.2885127498, 917631.2885127498, 196997.2271517232]
[2019-03-23 21:45:43,807] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:45:43,810] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.3480947e-23 1.0000000e+00 0.0000000e+00 2.5310627e-36 0.0000000e+00], sampled 0.5409962767210397
[2019-03-23 21:45:56,211] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0987508]
[2019-03-23 21:45:56,212] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.0, 89.0, 1.0, 2.0, 0.9493321988679494, 1.0, 2.0, 0.9493321988679494, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2165754.117574193, 2165754.117574193, 409326.3297606796]
[2019-03-23 21:45:56,213] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:45:56,217] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.3480947e-23 1.0000000e+00 0.0000000e+00 2.5310627e-36 0.0000000e+00], sampled 0.384062081424012
[2019-03-23 21:45:56,220] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2165754.117574193 W.
[2019-03-23 21:46:28,592] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0987508]
[2019-03-23 21:46:28,593] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [15.74058944666667, 77.93228827333333, 1.0, 2.0, 0.2015700082582353, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 259997.3796162893, 259997.3796162893, 81258.24466202379]
[2019-03-23 21:46:28,594] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:46:28,598] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.3480947e-23 1.0000000e+00 0.0000000e+00 2.5310627e-36 0.0000000e+00], sampled 0.21096471043037912
[2019-03-23 21:46:38,517] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 21:46:38,523] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 21:46:38,570] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 21:46:38,626] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 21:46:38,762] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 21:46:39,777] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 425000, evaluation results [425000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 21:46:40,090] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.1661614e-21 1.0000000e+00 1.2171534e-36 1.9872254e-33 1.6779009e-38], sum to 1.0000
[2019-03-23 21:46:40,102] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0960
[2019-03-23 21:46:40,109] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1398094.505241744 W.
[2019-03-23 21:46:40,113] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.65, 37.0, 1.0, 2.0, 0.5758947194291344, 1.0, 1.0, 0.5758947194291344, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9257438488603, 1398094.505241744, 1398094.505241744, 263390.9897256155], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 48600.0000, 
sim time next is 49200.0000, 
raw observation next is [29.83333333333334, 36.66666666666667, 1.0, 2.0, 0.3761223948696139, 1.0, 2.0, 0.3761223948696139, 1.0, 1.0, 0.6082547439914462, 6.911200000000001, 6.9112, 121.94756008, 1358081.830365164, 1358081.830365164, 286207.4438887074], 
processed observation next is [1.0, 0.5652173913043478, 0.6604938271604941, 0.3666666666666667, 1.0, 1.0, 0.25728856532096894, 1.0, 1.0, 0.25728856532096894, 1.0, 0.5, 0.5103184299893077, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.4850292251304157, 0.4850292251304157, 0.5503989305552065], 
reward next is 0.4496, 
noisyNet noise sample is [array([0.0224241], dtype=float32), 0.6642745]. 
=============================================
[2019-03-23 21:46:41,013] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2474093e-16 1.0000000e+00 2.7522910e-27 2.2006813e-26 6.8820526e-30], sum to 1.0000
[2019-03-23 21:46:41,019] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9679
[2019-03-23 21:46:41,024] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.75, 43.5, 1.0, 2.0, 0.4056531893471643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 499842.1861612421, 499842.1861612421, 129352.5503850565], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 66600.0000, 
sim time next is 67200.0000, 
raw observation next is [28.63333333333333, 44.0, 1.0, 2.0, 0.4045681410030465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 498484.3204522337, 498484.3204522337, 129198.3530895829], 
processed observation next is [1.0, 0.782608695652174, 0.6160493827160493, 0.44, 1.0, 1.0, 0.2911525488131506, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17803011444722633, 0.17803011444722633, 0.24845837132612097], 
reward next is 0.7515, 
noisyNet noise sample is [array([-0.55524445], dtype=float32), 0.6846784]. 
=============================================
[2019-03-23 21:46:42,841] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9353576e-24 1.0000000e+00 0.0000000e+00 5.6990472e-38 0.0000000e+00], sum to 1.0000
[2019-03-23 21:46:42,848] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0159
[2019-03-23 21:46:42,853] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.78333333333333, 76.83333333333334, 1.0, 2.0, 0.3931480904869594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 489778.3946960527, 489778.3946960527, 127714.0308809062], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 100200.0000, 
sim time next is 100800.0000, 
raw observation next is [21.7, 77.0, 1.0, 2.0, 0.3888381292063678, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 484782.9932560057, 484782.9932560062, 127120.435911182], 
processed observation next is [1.0, 0.17391304347826086, 0.3592592592592592, 0.77, 1.0, 1.0, 0.272426344293295, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17313678330571633, 0.1731367833057165, 0.24446237675227306], 
reward next is 0.7555, 
noisyNet noise sample is [array([-0.1940421], dtype=float32), 1.9294236]. 
=============================================
[2019-03-23 21:46:44,854] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0279670e-17 1.0000000e+00 3.5251097e-28 2.2091248e-27 4.6496312e-32], sum to 1.0000
[2019-03-23 21:46:44,865] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4243
[2019-03-23 21:46:44,879] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1432755.126343972 W.
[2019-03-23 21:46:44,887] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.66666666666666, 48.33333333333333, 1.0, 2.0, 0.6121745639632591, 1.0, 2.0, 0.6121745639632591, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1432755.126343972, 1432755.126343973, 273993.6815713964], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 124800.0000, 
sim time next is 125400.0000, 
raw observation next is [30.08333333333334, 47.16666666666667, 1.0, 2.0, 0.625382531900599, 1.0, 2.0, 0.625382531900599, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1460140.141665601, 1460140.141665601, 278508.4910787651], 
processed observation next is [1.0, 0.43478260869565216, 0.6697530864197533, 0.47166666666666673, 1.0, 1.0, 0.5540268236911893, 1.0, 1.0, 0.5540268236911893, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5214786220234289, 0.5214786220234289, 0.5355932520745482], 
reward next is 0.4644, 
noisyNet noise sample is [array([-0.17790323], dtype=float32), -0.695201]. 
=============================================
[2019-03-23 21:46:50,614] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2975659e-23 1.0000000e+00 0.0000000e+00 1.5870420e-38 0.0000000e+00], sum to 1.0000
[2019-03-23 21:46:50,624] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5060
[2019-03-23 21:46:50,636] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.7, 26.0, 1.0, 2.0, 0.3520306764829342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 449839.9795027294, 449839.979502729, 122247.3942451808], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 244800.0000, 
sim time next is 245400.0000, 
raw observation next is [29.36666666666667, 26.83333333333334, 1.0, 2.0, 0.3551145291915524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 453908.9614898563, 453908.9614898568, 122658.0715706648], 
processed observation next is [0.0, 0.8695652173913043, 0.64320987654321, 0.26833333333333337, 1.0, 1.0, 0.23227920141851477, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16211034338923438, 0.16211034338923458, 0.23588090686666308], 
reward next is 0.7641, 
noisyNet noise sample is [array([-0.14836486], dtype=float32), -0.08773086]. 
=============================================
[2019-03-23 21:46:50,662] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.0617565e-21 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:46:50,671] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2875
[2019-03-23 21:46:50,679] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.23333333333333, 21.33333333333334, 1.0, 2.0, 0.3670157485272285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 469375.2921667987, 469375.2921667991, 124258.6576345839], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 240600.0000, 
sim time next is 241200.0000, 
raw observation next is [31.0, 22.0, 1.0, 2.0, 0.3660964669047551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 468137.9320081049, 468137.9320081045, 124134.0944491829], 
processed observation next is [0.0, 0.8260869565217391, 0.7037037037037037, 0.22, 1.0, 1.0, 0.24535293679137515, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16719211857432317, 0.16719211857432303, 0.23871941240227482], 
reward next is 0.7613, 
noisyNet noise sample is [array([1.1565671], dtype=float32), -0.21437262]. 
=============================================
[2019-03-23 21:46:54,316] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.41215e-27 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00], sum to 1.0000
[2019-03-23 21:46:54,325] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3791
[2019-03-23 21:46:54,330] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.8, 30.33333333333334, 1.0, 2.0, 0.317767662704615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 409916.3066156639, 409916.3066156639, 116732.6948921115], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 303600.0000, 
sim time next is 304200.0000, 
raw observation next is [26.9, 30.5, 1.0, 2.0, 0.3176557778469826, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 409689.1743081359, 409689.1743081359, 117770.8497025641], 
processed observation next is [0.0, 0.5217391304347826, 0.5518518518518518, 0.305, 1.0, 1.0, 0.18768544981783647, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14631756225290568, 0.14631756225290568, 0.22648240327416172], 
reward next is 0.7735, 
noisyNet noise sample is [array([-0.67335516], dtype=float32), -0.47644123]. 
=============================================
[2019-03-23 21:46:57,636] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.1025318e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:46:57,642] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4615
[2019-03-23 21:46:57,647] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.85, 28.0, 1.0, 2.0, 0.8754478730596226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.026412249369047, 6.9112, 121.9254880384818, 1177117.852102967, 1118119.151227171, 216224.9829519614], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 387000.0000, 
sim time next is 387600.0000, 
raw observation next is [28.96666666666667, 27.66666666666667, 1.0, 2.0, 0.8877907078710092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.110765867910889, 6.9112, 121.9250643399934, 1235965.991276588, 1133771.24987916, 219030.5640567846], 
processed observation next is [1.0, 0.4782608695652174, 0.6283950617283951, 0.2766666666666667, 1.0, 1.0, 0.8664175093702491, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.01995658679108887, 0.0, 0.8094556340870327, 0.4414164254559243, 0.4049183035282714, 0.42121262318612424], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0841272], dtype=float32), -0.4089474]. 
=============================================
[2019-03-23 21:46:59,536] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0601209e-17 1.0000000e+00 1.3531935e-30 4.0605354e-28 4.4049182e-33], sum to 1.0000
[2019-03-23 21:46:59,546] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8348
[2019-03-23 21:46:59,546] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1420890.925939822 W.
[2019-03-23 21:46:59,552] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.7, 24.0, 1.0, 2.0, 0.9335375043899041, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.37584267547286, 6.9112, 121.924083711161, 1420890.925939822, 1182956.169607272, 229594.1365425388], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 396000.0000, 
sim time next is 396600.0000, 
raw observation next is [30.7, 24.16666666666666, 1.0, 2.0, 0.3385485486302018, 1.0, 1.0, 0.3385485486302018, 1.0, 1.0, 0.5645778249556426, 6.911200000000001, 6.9112, 121.94756008, 1264065.634853219, 1264065.634853218, 268783.8488816105], 
processed observation next is [1.0, 0.6086956521739131, 0.6925925925925925, 0.2416666666666666, 1.0, 1.0, 0.21255779598833546, 1.0, 0.5, 0.21255779598833546, 1.0, 0.5, 0.45572228119455316, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.4514520124475782, 0.4514520124475779, 0.5168920170800202], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6280835], dtype=float32), -0.6552418]. 
=============================================
[2019-03-23 21:47:18,251] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.0753624e-17 1.0000000e+00 2.1349178e-27 7.0816492e-25 2.6432488e-28], sum to 1.0000
[2019-03-23 21:47:18,256] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4163
[2019-03-23 21:47:18,264] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1375522.502781976 W.
[2019-03-23 21:47:18,270] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.7, 41.0, 1.0, 2.0, 0.3824429603306984, 1.0, 2.0, 0.3824429603306984, 1.0, 2.0, 0.6170893465849452, 6.9112, 6.9112, 121.94756008, 1375522.502781976, 1375522.502781976, 289036.9037536194], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 734400.0000, 
sim time next is 735000.0000, 
raw observation next is [28.98333333333333, 39.33333333333334, 1.0, 2.0, 0.4114837324452725, 1.0, 2.0, 0.4114837324452725, 1.0, 2.0, 0.6641059770871647, 6.911199999999999, 6.9112, 121.94756008, 1480716.507546347, 1480716.507546348, 301733.9883294708], 
processed observation next is [1.0, 0.5217391304347826, 0.6290123456790122, 0.3933333333333334, 1.0, 1.0, 0.2993853957681815, 1.0, 1.0, 0.2993853957681815, 1.0, 1.0, 0.5801324713589558, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5288273241236954, 0.5288273241236957, 0.5802576698643669], 
reward next is 0.4197, 
noisyNet noise sample is [array([-0.3716613], dtype=float32), -0.42612055]. 
=============================================
[2019-03-23 21:47:18,289] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[40.281704]
 [40.281704]
 [40.281704]
 [40.281704]
 [40.281704]], R is [[40.29863358]
 [40.33980942]
 [40.37867355]
 [39.97488785]
 [39.57513809]].
[2019-03-23 21:47:19,582] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.4975508e-16 1.0000000e+00 6.7638095e-31 2.8090155e-28 1.2641419e-31], sum to 1.0000
[2019-03-23 21:47:19,588] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0520
[2019-03-23 21:47:19,591] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.7, 39.0, 1.0, 2.0, 0.3157005385648864, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 401489.0730841113, 401489.0730841113, 117531.3769310648], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 774000.0000, 
sim time next is 774600.0000, 
raw observation next is [26.53333333333333, 39.5, 1.0, 2.0, 0.3137228885461306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 399090.184398965, 399090.184398965, 117282.517355739], 
processed observation next is [1.0, 1.0, 0.5382716049382715, 0.395, 1.0, 1.0, 0.1830034387453936, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14253220871391606, 0.14253220871391606, 0.22554330260719038], 
reward next is 0.7745, 
noisyNet noise sample is [array([0.12681034], dtype=float32), -1.4943881]. 
=============================================
[2019-03-23 21:47:20,736] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.6737081e-24 1.0000000e+00 0.0000000e+00 2.5306158e-38 0.0000000e+00], sum to 1.0000
[2019-03-23 21:47:20,752] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8871
[2019-03-23 21:47:20,759] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.36666666666667, 36.33333333333334, 1.0, 2.0, 0.324098728590889, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 412161.9183499651, 412161.9183499647, 118598.6787063004], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 771600.0000, 
sim time next is 772200.0000, 
raw observation next is [27.2, 37.0, 1.0, 2.0, 0.3221232098410585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 409638.5289375304, 409638.5289375304, 118346.4065690274], 
processed observation next is [1.0, 0.9565217391304348, 0.5629629629629629, 0.37, 1.0, 1.0, 0.1930038212393554, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14629947462054657, 0.14629947462054657, 0.22758924340197578], 
reward next is 0.7724, 
noisyNet noise sample is [array([1.1036665], dtype=float32), 0.5786296]. 
=============================================
[2019-03-23 21:47:29,522] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.934196e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:47:29,528] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3370
[2019-03-23 21:47:29,535] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.76666666666667, 54.66666666666667, 1.0, 2.0, 0.2680609405104349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 345536.5261901045, 345536.5261901045, 111709.0019912392], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 955200.0000, 
sim time next is 955800.0000, 
raw observation next is [21.65, 55.0, 1.0, 2.0, 0.2663127595304028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 343433.1712461169, 343433.1712461169, 111501.6984687165], 
processed observation next is [1.0, 0.043478260869565216, 0.35740740740740734, 0.55, 1.0, 1.0, 0.1265628089647652, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.12265470401647033, 0.12265470401647033, 0.21442634320907017], 
reward next is 0.7856, 
noisyNet noise sample is [array([-1.198908], dtype=float32), -0.023892619]. 
=============================================
[2019-03-23 21:47:30,607] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-23 21:47:30,611] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:47:30,611] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:47:30,613] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:47:30,616] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:47:30,617] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:47:30,617] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:47:30,618] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:47:30,618] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:47:30,617] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:47:30,625] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:47:30,631] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run19
[2019-03-23 21:47:30,653] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run19
[2019-03-23 21:47:30,653] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run19
[2019-03-23 21:47:30,673] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run19
[2019-03-23 21:47:30,695] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run19
[2019-03-23 21:47:50,294] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.06876687]
[2019-03-23 21:47:50,296] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.66666666666667, 30.5, 1.0, 2.0, 0.374220037300061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 464534.0172729128, 464534.0172729128, 125065.1810672974]
[2019-03-23 21:47:50,298] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:47:50,301] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0206126e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.1520472661848694
[2019-03-23 21:47:56,974] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.06876687]
[2019-03-23 21:47:56,975] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [32.33333333333334, 39.33333333333334, 1.0, 2.0, 0.4820681878432627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 574885.5524672343, 574885.5524672343, 140103.1152744837]
[2019-03-23 21:47:56,978] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:47:56,981] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0206126e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.6079955895141845
[2019-03-23 21:48:01,040] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.06876687]
[2019-03-23 21:48:01,043] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.81666666666667, 55.33333333333334, 1.0, 2.0, 0.6109819197772061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 698765.169937431, 698765.169937431, 160098.9570423715]
[2019-03-23 21:48:01,043] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:48:01,046] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0206126e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.05269845007035612
[2019-03-23 21:48:07,876] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.06876687]
[2019-03-23 21:48:07,877] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.01582663, 77.1100911, 1.0, 2.0, 0.5130838245960564, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 609027.9325725305, 609027.9325725305, 144855.4577327367]
[2019-03-23 21:48:07,879] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:48:07,882] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0206126e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.2655970086735633
[2019-03-23 21:48:18,501] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.06876687]
[2019-03-23 21:48:18,502] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [19.11640821333334, 81.81533884166667, 1.0, 2.0, 0.2941235912042982, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 376242.2838895841, 376242.2838895837, 114854.943636038]
[2019-03-23 21:48:18,504] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:48:18,508] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0206126e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.05784404137335275
[2019-03-23 21:48:24,853] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.06876687]
[2019-03-23 21:48:24,854] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.86904701333334, 102.9802328916667, 1.0, 2.0, 0.5201061095346894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 616769.2998565601, 616769.2998565601, 145953.858285473]
[2019-03-23 21:48:24,856] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:48:24,859] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0206126e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.7271829266107415
[2019-03-23 21:48:42,486] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.06876687]
[2019-03-23 21:48:42,487] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.33333333333334, 94.0, 1.0, 2.0, 0.5497375123873501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 667457.4028083998, 667457.4028083998, 151332.9313769092]
[2019-03-23 21:48:42,488] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:48:42,490] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0206126e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.593891439523359
[2019-03-23 21:49:04,414] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.06876687]
[2019-03-23 21:49:04,416] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.48578329, 68.50158030333333, 1.0, 2.0, 0.4679931542077257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 563113.092664423, 563113.092664423, 138130.9943514268]
[2019-03-23 21:49:04,418] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:49:04,422] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0206126e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.7037391144072253
[2019-03-23 21:49:05,684] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.06876687]
[2019-03-23 21:49:05,686] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.23333333333333, 63.66666666666667, 1.0, 2.0, 0.4334816590313633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 537019.39870416, 537019.39870416, 133433.9968100786]
[2019-03-23 21:49:05,688] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:49:05,691] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0206126e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.05113883860580026
[2019-03-23 21:49:09,907] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 21:49:10,557] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 21:49:10,633] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 21:49:10,655] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 21:49:10,962] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 21:49:11,978] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 450000, evaluation results [450000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 21:49:12,105] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.8828345e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:49:12,116] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6303
[2019-03-23 21:49:12,126] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.48333333333333, 58.16666666666666, 1.0, 2.0, 0.3612248139314164, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 460717.4273424086, 460717.4273424081, 123474.2938817726], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 978600.0000, 
sim time next is 979200.0000, 
raw observation next is [22.6, 58.0, 1.0, 2.0, 0.3504355139519673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 446601.6844684683, 446601.6844684683, 122032.3558596755], 
processed observation next is [1.0, 0.34782608695652173, 0.39259259259259266, 0.58, 1.0, 1.0, 0.22670894518091347, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15950060159588153, 0.15950060159588153, 0.2346776074224529], 
reward next is 0.7653, 
noisyNet noise sample is [array([3.0302665], dtype=float32), 0.013159228]. 
=============================================
[2019-03-23 21:49:17,657] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7809540e-21 1.0000000e+00 1.5165824e-35 9.4895262e-34 1.1554452e-37], sum to 1.0000
[2019-03-23 21:49:17,665] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2723
[2019-03-23 21:49:17,670] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.3, 42.0, 1.0, 2.0, 0.7159088842489795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 906994.3503135585, 906994.3503135585, 182351.1523373349], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1084800.0000, 
sim time next is 1085400.0000, 
raw observation next is [26.45, 41.5, 1.0, 2.0, 0.8007192784205767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1013692.551218674, 1013692.551218674, 199749.4575174295], 
processed observation next is [1.0, 0.5652173913043478, 0.5351851851851852, 0.415, 1.0, 1.0, 0.7627610457387818, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3620330540066693, 0.3620330540066693, 0.38413357214890287], 
reward next is 0.6159, 
noisyNet noise sample is [array([-0.59597945], dtype=float32), -0.34475204]. 
=============================================
[2019-03-23 21:49:19,819] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.4773658e-23 1.0000000e+00 0.0000000e+00 1.5135112e-38 0.0000000e+00], sum to 1.0000
[2019-03-23 21:49:19,830] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7013
[2019-03-23 21:49:19,841] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.96666666666667, 72.5, 1.0, 2.0, 0.2998277837555062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 383480.4590368231, 383480.4590368226, 115555.5952662113], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1116600.0000, 
sim time next is 1117200.0000, 
raw observation next is [19.83333333333334, 73.0, 1.0, 2.0, 0.2975199358647799, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 380755.8274587925, 380755.8274587925, 115270.9844030264], 
processed observation next is [1.0, 0.9565217391304348, 0.2901234567901237, 0.73, 1.0, 1.0, 0.16371420936283326, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1359842240924259, 0.1359842240924259, 0.22167497000582], 
reward next is 0.7783, 
noisyNet noise sample is [array([0.64368665], dtype=float32), -2.3975759]. 
=============================================
[2019-03-23 21:49:20,116] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.9277655e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:49:20,123] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6628
[2019-03-23 21:49:20,132] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.56666666666667, 74.0, 1.0, 2.0, 0.2953102950494908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 378375.5765610061, 378375.5765610057, 114998.9415741707], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1118400.0000, 
sim time next is 1119000.0000, 
raw observation next is [19.43333333333334, 74.5, 1.0, 2.0, 0.2927424722341038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 375307.6200615665, 375307.6200615665, 114683.9360794238], 
processed observation next is [1.0, 0.9565217391304348, 0.2753086419753089, 0.745, 1.0, 1.0, 0.1580267526596474, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13403843573627375, 0.13403843573627375, 0.22054603092196884], 
reward next is 0.7795, 
noisyNet noise sample is [array([-0.28114638], dtype=float32), 0.29984865]. 
=============================================
[2019-03-23 21:49:20,152] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[86.26553]
 [86.26553]
 [86.26553]
 [86.26553]
 [86.26553]], R is [[86.1823349 ]
 [86.0993576 ]
 [86.01699829]
 [85.93515778]
 [85.85358429]].
[2019-03-23 21:49:24,524] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.50082e-27 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00], sum to 1.0000
[2019-03-23 21:49:24,533] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5728
[2019-03-23 21:49:24,540] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 88.5, 1.0, 2.0, 0.3474264624288428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 437607.8744022136, 437607.8744022136, 121587.932382098], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1200600.0000, 
sim time next is 1201200.0000, 
raw observation next is [19.33333333333333, 89.0, 1.0, 2.0, 0.3479107520826252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 438253.9756310582, 438253.9756310578, 121652.3039130226], 
processed observation next is [1.0, 0.9130434782608695, 0.27160493827160476, 0.89, 1.0, 1.0, 0.2237032762888395, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15651927701109222, 0.15651927701109208, 0.23394673829427423], 
reward next is 0.7661, 
noisyNet noise sample is [array([0.29767036], dtype=float32), 0.5901987]. 
=============================================
[2019-03-23 21:49:24,782] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7013935e-24 1.0000000e+00 0.0000000e+00 2.1265839e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 21:49:24,789] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0243
[2019-03-23 21:49:24,792] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.2, 93.5, 1.0, 2.0, 0.3228235455560791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 409487.2211276553, 409487.2211276553, 118428.246514874], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1215000.0000, 
sim time next is 1215600.0000, 
raw observation next is [18.16666666666667, 93.33333333333334, 1.0, 2.0, 0.3219767765426765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 408646.4778648939, 408646.4778648934, 118322.1290933702], 
processed observation next is [1.0, 0.043478260869565216, 0.22839506172839524, 0.9333333333333335, 1.0, 1.0, 0.19282949588413867, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14594517066603355, 0.14594517066603335, 0.22754255594878883], 
reward next is 0.7725, 
noisyNet noise sample is [array([1.3339728], dtype=float32), 1.0092692]. 
=============================================
[2019-03-23 21:49:34,820] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.165674e-28 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:49:34,827] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9980
[2019-03-23 21:49:34,832] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.55, 57.0, 1.0, 2.0, 0.2642247580157452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 340395.1252834287, 340395.1252834282, 111260.3272914264], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1402200.0000, 
sim time next is 1402800.0000, 
raw observation next is [21.9, 56.0, 1.0, 2.0, 0.2682573177386653, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 345118.033579038, 345118.0335790375, 111738.0786351738], 
processed observation next is [0.0, 0.21739130434782608, 0.36666666666666664, 0.56, 1.0, 1.0, 0.12887775921269679, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12325644056394214, 0.12325644056394197, 0.21488092045225732], 
reward next is 0.7851, 
noisyNet noise sample is [array([-1.8857541], dtype=float32), 1.0450535]. 
=============================================
[2019-03-23 21:49:38,012] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.3664904e-23 1.0000000e+00 0.0000000e+00 3.0981770e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 21:49:38,024] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5392
[2019-03-23 21:49:38,028] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.25, 26.0, 1.0, 2.0, 0.3789287462809612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 474734.4962608797, 474734.4962608792, 125792.7743504222], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1449000.0000, 
sim time next is 1449600.0000, 
raw observation next is [32.1, 26.33333333333334, 1.0, 2.0, 0.377690445670152, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 473309.7977726224, 473309.7977726224, 125624.8642955121], 
processed observation next is [0.0, 0.782608695652174, 0.7444444444444445, 0.2633333333333334, 1.0, 1.0, 0.25915529246446667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16903921349022227, 0.16903921349022227, 0.24158627749136943], 
reward next is 0.7584, 
noisyNet noise sample is [array([-0.34823614], dtype=float32), 0.56127]. 
=============================================
[2019-03-23 21:49:40,057] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.6844154e-25 1.0000000e+00 0.0000000e+00 3.0657754e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 21:49:40,064] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2525
[2019-03-23 21:49:40,068] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.8, 48.33333333333334, 1.0, 2.0, 0.4177086671873648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 513735.989770624, 513735.989770624, 131049.668797681], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1498800.0000, 
sim time next is 1499400.0000, 
raw observation next is [28.15, 47.0, 1.0, 2.0, 0.4193276308372118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 515376.6558359965, 515376.6558359965, 131273.6447952676], 
processed observation next is [0.0, 0.34782608695652173, 0.5981481481481481, 0.47, 1.0, 1.0, 0.3087233700442997, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18406309136999874, 0.18406309136999874, 0.25244931691397615], 
reward next is 0.7476, 
noisyNet noise sample is [array([-0.47833574], dtype=float32), -0.37446004]. 
=============================================
[2019-03-23 21:49:44,560] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.005038e-23 1.000000e+00 0.000000e+00 8.398591e-36 0.000000e+00], sum to 1.0000
[2019-03-23 21:49:44,568] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2320
[2019-03-23 21:49:44,572] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.05, 85.0, 1.0, 2.0, 0.5093079375004854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 639345.0963212316, 639345.0963212316, 145241.2631753161], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1571400.0000, 
sim time next is 1572000.0000, 
raw observation next is [19.93333333333333, 85.66666666666667, 1.0, 2.0, 0.551187254699389, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 692192.5733327593, 692192.5733327593, 152130.4314236871], 
processed observation next is [1.0, 0.17391304347826086, 0.293827160493827, 0.8566666666666667, 1.0, 1.0, 0.46569911273736786, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24721163333312832, 0.24721163333312832, 0.2925585219686291], 
reward next is 0.7074, 
noisyNet noise sample is [array([-0.76137096], dtype=float32), 0.013479284]. 
=============================================
[2019-03-23 21:49:44,588] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[66.12559]
 [66.12559]
 [66.12559]
 [66.12559]
 [66.12559]], R is [[66.17177582]
 [66.23074341]
 [66.28689575]
 [66.29998016]
 [66.34423065]].
[2019-03-23 21:49:45,028] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7323977e-24 1.0000000e+00 0.0000000e+00 3.5547766e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 21:49:45,034] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0997
[2019-03-23 21:49:45,037] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.63333333333333, 64.0, 1.0, 2.0, 0.3881047563349218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 489495.7460383771, 489495.7460383771, 127108.6077645705], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1581600.0000, 
sim time next is 1582200.0000, 
raw observation next is [22.85, 62.5, 1.0, 2.0, 0.4054451365563462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 511511.4509548644, 511511.4509548644, 129550.2381680398], 
processed observation next is [1.0, 0.30434782608695654, 0.4018518518518519, 0.625, 1.0, 1.0, 0.2921965911385074, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1826826610553087, 0.1826826610553087, 0.24913507340007654], 
reward next is 0.7509, 
noisyNet noise sample is [array([-0.76166266], dtype=float32), -0.7094444]. 
=============================================
[2019-03-23 21:49:50,201] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.642018e-26 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:49:50,212] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8559
[2019-03-23 21:49:50,217] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.2, 81.0, 1.0, 2.0, 0.330535859007274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 421382.3717020401, 421382.3717020401, 119430.3595543057], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1656000.0000, 
sim time next is 1656600.0000, 
raw observation next is [18.98333333333333, 82.5, 1.0, 2.0, 0.3467417275070088, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 442165.939018779, 442165.939018779, 121544.8955610541], 
processed observation next is [1.0, 0.17391304347826086, 0.25864197530864186, 0.825, 1.0, 1.0, 0.2223115803654867, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15791640679242108, 0.15791640679242108, 0.23374018377125788], 
reward next is 0.7663, 
noisyNet noise sample is [array([0.46625268], dtype=float32), 0.09603818]. 
=============================================
[2019-03-23 21:49:52,308] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.7566389e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:49:52,315] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1348
[2019-03-23 21:49:52,321] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.7, 70.66666666666667, 1.0, 2.0, 0.4055108741071127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 498661.6125196404, 498661.61251964, 129306.8762056094], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1705200.0000, 
sim time next is 1705800.0000, 
raw observation next is [23.65, 71.33333333333333, 1.0, 2.0, 0.4095201677083572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 503216.7171282189, 503216.7171282189, 129866.4523323719], 
processed observation next is [1.0, 0.7391304347826086, 0.4314814814814814, 0.7133333333333333, 1.0, 1.0, 0.29704781870042524, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17972025611722103, 0.17972025611722103, 0.24974317756225367], 
reward next is 0.7503, 
noisyNet noise sample is [array([0.62391555], dtype=float32), -0.08432222]. 
=============================================
[2019-03-23 21:49:58,695] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3276465e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:49:58,707] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5434
[2019-03-23 21:49:58,712] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.65, 80.16666666666667, 1.0, 2.0, 0.3838874651325577, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 482412.4538137126, 482412.4538137131, 126499.386886798], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1840200.0000, 
sim time next is 1840800.0000, 
raw observation next is [20.8, 79.33333333333334, 1.0, 2.0, 0.3531898992385745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 443634.8591677093, 443634.8591677093, 122333.5204423927], 
processed observation next is [1.0, 0.30434782608695654, 0.32592592592592595, 0.7933333333333334, 1.0, 1.0, 0.2299879752840173, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15844102113132474, 0.15844102113132474, 0.23525677008152443], 
reward next is 0.7647, 
noisyNet noise sample is [array([0.08754176], dtype=float32), 1.2526761]. 
=============================================
[2019-03-23 21:49:59,868] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0645546e-24 1.0000000e+00 0.0000000e+00 8.0611398e-38 0.0000000e+00], sum to 1.0000
[2019-03-23 21:49:59,875] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6283
[2019-03-23 21:49:59,883] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.95, 89.16666666666667, 1.0, 2.0, 0.3538624312016554, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 447712.1934603626, 447712.1934603626, 122463.9970362605], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1833000.0000, 
sim time next is 1833600.0000, 
raw observation next is [19.1, 88.33333333333334, 1.0, 2.0, 0.3376491575326398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 426956.3076411831, 426956.3076411831, 120326.9729570052], 
processed observation next is [1.0, 0.21739130434782608, 0.262962962962963, 0.8833333333333334, 1.0, 1.0, 0.21148709230076168, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15248439558613683, 0.15248439558613683, 0.2313980249173177], 
reward next is 0.7686, 
noisyNet noise sample is [array([0.8192064], dtype=float32), -0.62415755]. 
=============================================
[2019-03-23 21:50:00,358] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.4589153e-23 1.0000000e+00 1.4273225e-38 3.6165101e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 21:50:00,371] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1967
[2019-03-23 21:50:00,377] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 87.0, 1.0, 2.0, 0.9384704841535779, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.163798152341809, 6.9112, 121.9249482406549, 1272962.748680047, 1143611.078750215, 229647.5393780759], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1872000.0000, 
sim time next is 1872600.0000, 
raw observation next is [21.58333333333334, 87.16666666666667, 1.0, 2.0, 0.8491093716844622, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9258804466724, 1039384.07623486, 1039384.07623486, 209449.7461416448], 
processed observation next is [1.0, 0.6956521739130435, 0.3549382716049385, 0.8716666666666667, 1.0, 1.0, 0.8203682996243598, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094610521866902, 0.37120859865530714, 0.37120859865530714, 0.40278797334931693], 
reward next is 0.5972, 
noisyNet noise sample is [array([0.8397081], dtype=float32), -0.758593]. 
=============================================
[2019-03-23 21:50:00,935] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.216788e-24 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:50:00,943] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7629
[2019-03-23 21:50:00,948] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.65, 86.5, 1.0, 2.0, 0.9326659768059486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.156626543208534, 6.9112, 121.9249615768642, 1267959.64820087, 1142280.436428168, 228477.5729955247], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1870200.0000, 
sim time next is 1870800.0000, 
raw observation next is [21.63333333333333, 86.66666666666667, 1.0, 2.0, 0.9515967732111069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.281133901943291, 6.9112, 121.9242768060582, 1354819.976214788, 1165383.497680776, 232952.77184672], 
processed observation next is [1.0, 0.6521739130434783, 0.35679012345678995, 0.8666666666666667, 1.0, 1.0, 0.9423771109656035, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.03699339019432912, 0.0, 0.8094504056806806, 0.4838642772195671, 0.4162083920288486, 0.44798609970523073], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.39338404], dtype=float32), -0.39776593]. 
=============================================
[2019-03-23 21:50:00,975] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.095374e-24 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 21:50:00,987] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2990
[2019-03-23 21:50:00,991] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666667, 90.16666666666667, 1.0, 2.0, 0.4251057005819989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 521371.1963222628, 521371.1963222628, 132079.7957441864], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1883400.0000, 
sim time next is 1884000.0000, 
raw observation next is [21.13333333333333, 90.33333333333334, 1.0, 2.0, 0.4237275688383195, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 519780.9215856869, 519780.9215856869, 131882.7723258742], 
processed observation next is [1.0, 0.8260869565217391, 0.33827160493827146, 0.9033333333333334, 1.0, 1.0, 0.3139613914741899, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1856360434234596, 0.1856360434234596, 0.25362071601129654], 
reward next is 0.7464, 
noisyNet noise sample is [array([-1.295768], dtype=float32), 0.2056939]. 
=============================================
[2019-03-23 21:50:01,010] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[68.59287]
 [68.59287]
 [68.59287]
 [68.59287]
 [68.59287]], R is [[68.65331268]
 [68.71278381]
 [68.77138519]
 [68.82935333]
 [68.88655853]].
[2019-03-23 21:50:02,116] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.6664106e-23 1.0000000e+00 0.0000000e+00 3.4115716e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 21:50:02,121] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3294
[2019-03-23 21:50:02,124] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.48333333333333, 92.0, 1.0, 2.0, 0.4054417108240293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 500514.634425865, 500514.634425865, 129345.4220924473], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1900200.0000, 
sim time next is 1900800.0000, 
raw observation next is [20.4, 92.0, 1.0, 2.0, 0.4028843700229011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 497956.1227372261, 497956.1227372256, 128997.8092753684], 
processed observation next is [1.0, 0.0, 0.31111111111111106, 0.92, 1.0, 1.0, 0.28914805955107276, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17784147240615217, 0.177841472406152, 0.24807271014493923], 
reward next is 0.7519, 
noisyNet noise sample is [array([-0.03796994], dtype=float32), -0.34695542]. 
=============================================
[2019-03-23 21:50:02,543] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.6412658e-23 1.0000000e+00 0.0000000e+00 1.7821356e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 21:50:02,550] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3189
[2019-03-23 21:50:02,557] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.6, 92.0, 1.0, 2.0, 0.3587553494082208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 448472.8084892026, 448472.8084892026, 123040.113694885], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1914000.0000, 
sim time next is 1914600.0000, 
raw observation next is [19.6, 92.0, 1.0, 2.0, 0.3588463774232714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 448586.9678779985, 448586.9678779985, 123052.2973340392], 
processed observation next is [1.0, 0.13043478260869565, 0.28148148148148155, 0.92, 1.0, 1.0, 0.23672187788484692, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16020963138499947, 0.16020963138499947, 0.23663903333469077], 
reward next is 0.7634, 
noisyNet noise sample is [array([-0.4188018], dtype=float32), -0.8819287]. 
=============================================
[2019-03-23 21:50:02,808] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 21:50:02,814] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:50:02,816] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:50:02,817] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:50:02,818] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:50:02,818] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:50:02,818] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:50:02,819] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:50:02,819] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:50:02,819] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:50:02,820] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:50:02,832] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run20
[2019-03-23 21:50:02,833] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run20
[2019-03-23 21:50:02,854] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run20
[2019-03-23 21:50:02,856] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run20
[2019-03-23 21:50:02,924] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run20
[2019-03-23 21:50:20,739] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.049559873]
[2019-03-23 21:50:20,740] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.40440680666667, 39.80728669666667, 1.0, 2.0, 0.3057101585708105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 389426.8601445119, 389426.8601445119, 116281.6816481191]
[2019-03-23 21:50:20,742] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:50:20,744] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.5564903e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.9777298292700451
[2019-03-23 21:50:23,199] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.049559873]
[2019-03-23 21:50:23,200] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.6, 63.66666666666666, 1.0, 2.0, 0.3639344093371301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 454550.0175162779, 454550.0175162779, 123728.0629784668]
[2019-03-23 21:50:23,200] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:50:23,202] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.5564903e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.5335405108706526
[2019-03-23 21:50:24,021] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.049559873]
[2019-03-23 21:50:24,022] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.67320974, 66.96244807, 1.0, 2.0, 0.6650232197034768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 787138.1212525698, 787138.1212525698, 170977.1590218641]
[2019-03-23 21:50:24,023] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:50:24,026] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.5564903e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.9806108983329759
[2019-03-23 21:50:45,365] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.049559873]
[2019-03-23 21:50:45,366] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.197703345, 87.896255615, 1.0, 2.0, 0.8306677422877048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 946818.2297150395, 946818.2297150395, 202371.9877638594]
[2019-03-23 21:50:45,367] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:50:45,369] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.5564903e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.9654232404022258
[2019-03-23 21:51:14,419] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.049559873]
[2019-03-23 21:51:14,421] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.81435734666667, 62.21909251500001, 1.0, 2.0, 0.4728167544097881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 568805.0520452334, 568805.052045233, 138862.8238827768]
[2019-03-23 21:51:14,422] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:51:14,425] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.5564903e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.552828415923418
[2019-03-23 21:51:20,633] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.049559873]
[2019-03-23 21:51:20,636] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [30.24158332333333, 61.287185575, 1.0, 2.0, 0.6617378520691957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 754172.4995873771, 754172.4995873771, 169025.8545939667]
[2019-03-23 21:51:20,636] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:51:20,640] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.5564903e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.9974656998146457
[2019-03-23 21:51:21,071] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.049559873]
[2019-03-23 21:51:21,072] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.0, 89.0, 1.0, 2.0, 0.490427064725672, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 584876.6332288545, 584876.6332288545, 141396.8839482289]
[2019-03-23 21:51:21,074] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:51:21,078] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.5564903e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.7105553453328716
[2019-03-23 21:51:38,792] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.049559873]
[2019-03-23 21:51:38,793] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [20.16666666666667, 51.0, 1.0, 2.0, 0.2278292388698863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 293874.6374156767, 293874.6374156767, 88054.28147714876]
[2019-03-23 21:51:38,794] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:51:38,797] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.5564903e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.6173889699936832
[2019-03-23 21:51:42,411] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 21:51:43,010] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 21:51:43,079] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 21:51:43,099] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 21:51:43,486] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 21:51:44,500] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 475000, evaluation results [475000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 21:51:55,247] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.1606244e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:51:55,259] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9832
[2019-03-23 21:51:55,266] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.5, 55.0, 1.0, 2.0, 0.5861896552986827, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 675850.2590118239, 675850.2590118239, 156098.2256104898], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2124000.0000, 
sim time next is 2124600.0000, 
raw observation next is [30.58333333333334, 54.33333333333334, 1.0, 2.0, 0.5845016717451701, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 674410.461759729, 674410.461759729, 155834.7122324032], 
processed observation next is [0.0, 0.6086956521739131, 0.6882716049382718, 0.5433333333333334, 1.0, 1.0, 0.5053591330299644, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2408608791999032, 0.2408608791999032, 0.2996821389084677], 
reward next is 0.7003, 
noisyNet noise sample is [array([-0.11216816], dtype=float32), 0.74825066]. 
=============================================
[2019-03-23 21:51:55,480] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.1516882e-23 1.0000000e+00 0.0000000e+00 2.4421162e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 21:51:55,488] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1213
[2019-03-23 21:51:55,494] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.75, 63.0, 1.0, 2.0, 0.5818130915801195, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 672335.3337058633, 672335.3337058633, 155426.1260833915], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2118600.0000, 
sim time next is 2119200.0000, 
raw observation next is [28.93333333333333, 62.0, 1.0, 2.0, 0.581713268831345, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 672315.6667395461, 672315.6667395461, 155413.6299187672], 
processed observation next is [0.0, 0.5217391304347826, 0.6271604938271603, 0.62, 1.0, 1.0, 0.5020396057516012, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24011273812126646, 0.24011273812126646, 0.29887236522839844], 
reward next is 0.7011, 
noisyNet noise sample is [array([-2.1323893], dtype=float32), 2.6016135]. 
=============================================
[2019-03-23 21:52:03,582] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.48733e-26 1.00000e+00 0.00000e+00 6.79075e-38 0.00000e+00], sum to 1.0000
[2019-03-23 21:52:03,590] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2008
[2019-03-23 21:52:03,594] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.3, 97.0, 1.0, 2.0, 0.4657562188611777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 562026.5994681667, 562026.5994681662, 137845.1633368017], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2260800.0000, 
sim time next is 2261400.0000, 
raw observation next is [21.15, 96.66666666666667, 1.0, 2.0, 0.5102586318534547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 617637.9175474164, 617637.9175474164, 144829.2389203243], 
processed observation next is [1.0, 0.17391304347826086, 0.33888888888888885, 0.9666666666666667, 1.0, 1.0, 0.4169745617303031, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22058497055264872, 0.22058497055264872, 0.2785177671544698], 
reward next is 0.7215, 
noisyNet noise sample is [array([0.7857129], dtype=float32), -1.3466401]. 
=============================================
[2019-03-23 21:52:11,565] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1611413e-21 1.0000000e+00 9.0946227e-38 1.4754951e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 21:52:11,576] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9093
[2019-03-23 21:52:11,588] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.7, 64.0, 1.0, 2.0, 0.3819037277588435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 476106.2811236502, 476106.2811236502, 126159.8711399642], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2415600.0000, 
sim time next is 2416200.0000, 
raw observation next is [23.55, 63.83333333333334, 1.0, 2.0, 0.3773304460927403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 471155.3520282395, 471155.3520282395, 125545.5317773603], 
processed observation next is [1.0, 1.0, 0.4277777777777778, 0.6383333333333334, 1.0, 1.0, 0.2587267215389766, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1682697685815141, 0.1682697685815141, 0.24143371495646213], 
reward next is 0.7586, 
noisyNet noise sample is [array([1.129118], dtype=float32), 0.4606922]. 
=============================================
[2019-03-23 21:52:22,794] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.8860674e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:52:22,805] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5609
[2019-03-23 21:52:22,809] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 85.0, 1.0, 2.0, 0.5120191441051525, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 610414.210572402, 610414.2105724015, 144785.6982514145], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2631600.0000, 
sim time next is 2632200.0000, 
raw observation next is [23.75, 84.66666666666667, 1.0, 2.0, 0.514944747888517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 612785.6027734432, 612785.6027734432, 145210.8687371991], 
processed observation next is [0.0, 0.4782608695652174, 0.4351851851851852, 0.8466666666666667, 1.0, 1.0, 0.4225532712958535, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21885200099051544, 0.21885200099051544, 0.27925167064845985], 
reward next is 0.7207, 
noisyNet noise sample is [array([-2.0392003], dtype=float32), -0.9726556]. 
=============================================
[2019-03-23 21:52:24,490] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3492301e-22 1.0000000e+00 4.9299322e-38 2.4769052e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 21:52:24,496] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4874
[2019-03-23 21:52:24,504] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.25, 81.33333333333334, 1.0, 2.0, 0.5739768062776426, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 668976.3965621237, 668976.3965621237, 154359.6808171359], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2663400.0000, 
sim time next is 2664000.0000, 
raw observation next is [25.1, 82.0, 1.0, 2.0, 0.5710459992730987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 666257.8613042466, 666257.8613042466, 153896.2905646093], 
processed observation next is [0.0, 0.8695652173913043, 0.4851851851851852, 0.82, 1.0, 1.0, 0.48934047532511754, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23794923618008806, 0.23794923618008806, 0.295954404931941], 
reward next is 0.7040, 
noisyNet noise sample is [array([0.31506923], dtype=float32), 2.069329]. 
=============================================
[2019-03-23 21:52:24,538] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[67.82133]
 [67.82133]
 [67.82133]
 [67.82133]
 [67.82133]], R is [[67.84715271]
 [67.8718338 ]
 [67.89537811]
 [67.91781616]
 [67.93924713]].
[2019-03-23 21:52:25,663] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.9758044e-24 1.0000000e+00 0.0000000e+00 5.1321099e-38 0.0000000e+00], sum to 1.0000
[2019-03-23 21:52:25,670] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0976
[2019-03-23 21:52:25,674] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 78.0, 1.0, 2.0, 0.537642247684299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 635339.1946563706, 635339.1946563706, 148705.3111686533], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2638800.0000, 
sim time next is 2639400.0000, 
raw observation next is [25.13333333333334, 77.66666666666667, 1.0, 2.0, 0.5379894755649495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 635436.9426462606, 635436.9426462606, 148749.7363424996], 
processed observation next is [0.0, 0.5652173913043478, 0.48641975308642, 0.7766666666666667, 1.0, 1.0, 0.4499874709106541, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22694176523080736, 0.22694176523080736, 0.2860571852740377], 
reward next is 0.7139, 
noisyNet noise sample is [array([0.5816682], dtype=float32), -0.077344075]. 
=============================================
[2019-03-23 21:52:29,457] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.7663817e-22 1.0000000e+00 0.0000000e+00 2.0436205e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 21:52:29,463] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9510
[2019-03-23 21:52:29,470] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.75, 53.5, 1.0, 2.0, 0.5436829860836103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 638682.5362806633, 638682.5362806633, 149539.6096824346], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2721000.0000, 
sim time next is 2721600.0000, 
raw observation next is [30.0, 52.0, 1.0, 2.0, 0.5398840121792959, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 635052.6554485353, 635052.6554485349, 148952.4215321093], 
processed observation next is [0.0, 0.5217391304347826, 0.6666666666666666, 0.52, 1.0, 1.0, 0.45224287164201893, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22680451980304833, 0.22680451980304817, 0.28644696448482554], 
reward next is 0.7136, 
noisyNet noise sample is [array([0.5449285], dtype=float32), -1.407513]. 
=============================================
[2019-03-23 21:52:32,734] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.3567651e-19 1.0000000e+00 3.2203648e-30 1.0881904e-27 1.4092996e-32], sum to 1.0000
[2019-03-23 21:52:32,743] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1048
[2019-03-23 21:52:32,759] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2317008.07577899 W.
[2019-03-23 21:52:32,765] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.13333333333333, 66.66666666666667, 1.0, 2.0, 0.7273331532020029, 1.0, 2.0, 0.6770312385774362, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2317008.07577899, 2317008.075778991, 436665.7133251742], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2803200.0000, 
sim time next is 2803800.0000, 
raw observation next is [30.41666666666666, 64.83333333333333, 1.0, 2.0, 0.7266814031312699, 1.0, 2.0, 0.6767053635420696, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2315891.385346588, 2315891.385346589, 436486.7716348901], 
processed observation next is [1.0, 0.43478260869565216, 0.6820987654320986, 0.6483333333333333, 1.0, 1.0, 0.6746207180134166, 1.0, 1.0, 0.615125432788178, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.82710406619521, 0.8271040661952104, 0.839397637759404], 
reward next is 0.1606, 
noisyNet noise sample is [array([0.55093116], dtype=float32), 2.5774992]. 
=============================================
[2019-03-23 21:52:34,237] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1465162e-12 1.0000000e+00 8.0182421e-21 2.3808287e-19 9.3866148e-22], sum to 1.0000
[2019-03-23 21:52:34,243] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2300
[2019-03-23 21:52:34,251] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.15, 58.33333333333334, 1.0, 2.0, 0.6660530607211025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 759092.9119825382, 759092.9119825382, 169816.9274113612], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2832600.0000, 
sim time next is 2833200.0000, 
raw observation next is [31.0, 59.0, 1.0, 2.0, 0.6690302060352583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 762487.6173935534, 762487.6173935529, 170363.6604325452], 
processed observation next is [1.0, 0.8260869565217391, 0.7037037037037037, 0.59, 1.0, 1.0, 0.6059883405181646, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27231700621198335, 0.2723170062119832, 0.3276224239087408], 
reward next is 0.6724, 
noisyNet noise sample is [array([0.33280376], dtype=float32), 0.23016134]. 
=============================================
[2019-03-23 21:52:35,225] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 21:52:35,226] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:52:35,227] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:52:35,227] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:52:35,228] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:52:35,228] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:52:35,229] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:52:35,228] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:52:35,230] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:52:35,230] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:52:35,230] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:52:35,236] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run21
[2019-03-23 21:52:35,236] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run21
[2019-03-23 21:52:35,259] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run21
[2019-03-23 21:52:35,260] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run21
[2019-03-23 21:52:35,280] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run21
[2019-03-23 21:52:37,475] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.11141864]
[2019-03-23 21:52:37,476] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.0, 50.0, 1.0, 2.0, 0.2332030245325241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 300807.5886173287, 300807.5886173287, 92043.38604279574]
[2019-03-23 21:52:37,478] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:52:37,480] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.1353332e-21 1.0000000e+00 5.4281494e-35 1.4237270e-32 2.3447008e-37], sampled 0.32307081805162163
[2019-03-23 21:53:08,427] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.11141864]
[2019-03-23 21:53:08,429] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.66666666666667, 49.0, 1.0, 2.0, 0.5471648991396615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 643657.5514977882, 643657.5514977882, 150148.3431432964]
[2019-03-23 21:53:08,431] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:53:08,433] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.1353332e-21 1.0000000e+00 5.4281494e-35 1.4237270e-32 2.3447008e-37], sampled 0.1593046347833592
[2019-03-23 21:53:25,519] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.11141864]
[2019-03-23 21:53:25,520] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.4, 81.33333333333334, 1.0, 2.0, 0.8817885577991502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1005125.37350786, 1005125.37350786, 213421.8479581599]
[2019-03-23 21:53:25,521] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:53:25,523] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.1353332e-21 1.0000000e+00 5.4281494e-35 1.4237270e-32 2.3447008e-37], sampled 0.47318816546288145
[2019-03-23 21:53:27,911] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.11141864]
[2019-03-23 21:53:27,912] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.99699468666667, 85.98095690666666, 1.0, 2.0, 0.8646765022654613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000003, 6.9112, 121.9260426156618, 985607.2902055315, 985607.2902055301, 209682.2355303221]
[2019-03-23 21:53:27,914] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:53:27,916] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.1353332e-21 1.0000000e+00 5.4281494e-35 1.4237270e-32 2.3447008e-37], sampled 0.3996810219140817
[2019-03-23 21:53:44,823] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.11141864]
[2019-03-23 21:53:44,824] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.0, 81.5, 1.0, 2.0, 0.5045519580644889, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 602046.2493062951, 602046.2493062951, 143621.7889409205]
[2019-03-23 21:53:44,824] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:53:44,826] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.1353332e-21 1.0000000e+00 5.4281494e-35 1.4237270e-32 2.3447008e-37], sampled 0.4702319424296991
[2019-03-23 21:53:45,520] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.11141864]
[2019-03-23 21:53:45,520] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.15, 96.0, 1.0, 2.0, 0.6213164524583843, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 710910.0353459646, 710910.0353459646, 161923.4633597896]
[2019-03-23 21:53:45,521] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:53:45,523] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.1353332e-21 1.0000000e+00 5.4281494e-35 1.4237270e-32 2.3447008e-37], sampled 0.9381005981946139
[2019-03-23 21:53:50,099] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.11141864]
[2019-03-23 21:53:50,102] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.66666666666667, 82.33333333333333, 1.0, 2.0, 0.476297128351842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 571062.4585940249, 571062.4585940249, 139327.8997178333]
[2019-03-23 21:53:50,104] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:53:50,108] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.1353332e-21 1.0000000e+00 5.4281494e-35 1.4237270e-32 2.3447008e-37], sampled 0.41063402802229687
[2019-03-23 21:53:55,998] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.11141864]
[2019-03-23 21:53:56,000] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.28708544666667, 95.85279835666667, 1.0, 2.0, 0.8128371838222012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 926482.1771543341, 926482.1771543341, 198605.0070345972]
[2019-03-23 21:53:56,001] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:53:56,003] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.1353332e-21 1.0000000e+00 5.4281494e-35 1.4237270e-32 2.3447008e-37], sampled 0.1413123439684949
[2019-03-23 21:54:00,486] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.11141864]
[2019-03-23 21:54:00,488] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.57804625, 73.50658598, 1.0, 2.0, 0.326346071973838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 413936.1054779331, 413936.1054779326, 118878.3101157708]
[2019-03-23 21:54:00,490] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:54:00,492] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.1353332e-21 1.0000000e+00 5.4281494e-35 1.4237270e-32 2.3447008e-37], sampled 0.07126660226327153
[2019-03-23 21:54:11,261] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.11141864]
[2019-03-23 21:54:11,264] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.22840281666667, 100.9337922233333, 1.0, 2.0, 0.4647467366168384, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 559612.8441850904, 559612.8441850904, 137653.0900018766]
[2019-03-23 21:54:11,265] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:54:11,267] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.1353332e-21 1.0000000e+00 5.4281494e-35 1.4237270e-32 2.3447008e-37], sampled 0.7298254137195769
[2019-03-23 21:54:11,307] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.11141864]
[2019-03-23 21:54:11,310] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.7, 65.66666666666667, 1.0, 2.0, 0.3497710067530034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 439782.8708872181, 439782.8708872176, 121886.9032505043]
[2019-03-23 21:54:11,311] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:54:11,314] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.1353332e-21 1.0000000e+00 5.4281494e-35 1.4237270e-32 2.3447008e-37], sampled 0.5421619779867975
[2019-03-23 21:54:17,002] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 21:54:17,024] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 21:54:17,160] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 21:54:17,213] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 21:54:17,218] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 21:54:18,232] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 500000, evaluation results [500000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 21:54:27,903] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.4284683e-22 1.0000000e+00 5.0576348e-38 6.5352428e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 21:54:27,910] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2545
[2019-03-23 21:54:27,914] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 93.16666666666666, 1.0, 2.0, 0.6310695122901797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 719917.3731354604, 719917.37313546, 163539.7570680994], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3030600.0000, 
sim time next is 3031200.0000, 
raw observation next is [24.8, 93.0, 1.0, 2.0, 0.6381245300490638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 727247.9918057821, 727247.9918057821, 164759.5367154349], 
processed observation next is [1.0, 0.08695652173913043, 0.4740740740740741, 0.93, 1.0, 1.0, 0.5691958691060283, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2597314256449222, 0.2597314256449222, 0.3168452629142979], 
reward next is 0.6832, 
noisyNet noise sample is [array([-0.174127], dtype=float32), 0.28263378]. 
=============================================
[2019-03-23 21:54:31,501] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.0917659e-15 1.0000000e+00 6.2490153e-23 8.9213457e-21 1.2293493e-24], sum to 1.0000
[2019-03-23 21:54:31,504] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7997
[2019-03-23 21:54:31,509] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.33333333333334, 71.66666666666667, 1.0, 2.0, 0.6746076505158625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 768847.3679039475, 768847.3679039475, 171390.8821504652], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3098400.0000, 
sim time next is 3099000.0000, 
raw observation next is [28.66666666666667, 68.83333333333333, 1.0, 2.0, 0.6630890846419796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 755713.2377947276, 755713.2377947271, 169272.0643440995], 
processed observation next is [1.0, 0.8695652173913043, 0.6172839506172841, 0.6883333333333332, 1.0, 1.0, 0.5989155769547376, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2698975849266884, 0.26989758492668825, 0.3255232006617298], 
reward next is 0.6745, 
noisyNet noise sample is [array([-0.97770596], dtype=float32), 0.27258825]. 
=============================================
[2019-03-23 21:54:31,547] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[34.476223]
 [34.476223]
 [34.476223]
 [34.476223]
 [34.476223]], R is [[34.80594254]
 [35.12828445]
 [35.44381332]
 [35.75370407]
 [36.05903244]].
[2019-03-23 21:54:39,852] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.0844728e-23 1.0000000e+00 0.0000000e+00 1.4448762e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 21:54:39,855] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5173
[2019-03-23 21:54:39,858] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.66666666666666, 43.33333333333333, 1.0, 2.0, 0.5256846980224305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 622402.9999361525, 622402.999936152, 146813.0117024865], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3249600.0000, 
sim time next is 3250200.0000, 
raw observation next is [31.83333333333333, 42.16666666666667, 1.0, 2.0, 0.5198461911531532, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 616804.7315707975, 616804.7315707975, 145925.7005345662], 
processed observation next is [0.0, 0.6086956521739131, 0.7345679012345677, 0.4216666666666667, 1.0, 1.0, 0.42838832280137285, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22028740413242767, 0.22028740413242767, 0.2806263471818581], 
reward next is 0.7194, 
noisyNet noise sample is [array([2.4402313], dtype=float32), -1.8272321]. 
=============================================
[2019-03-23 21:54:47,601] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.4779045e-22 1.0000000e+00 1.8747717e-37 4.3959016e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 21:54:47,613] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5974
[2019-03-23 21:54:47,620] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.7, 95.5, 1.0, 2.0, 0.6749444009392372, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 780949.8653227201, 780949.8653227201, 172030.8053114395], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3393000.0000, 
sim time next is 3393600.0000, 
raw observation next is [23.93333333333333, 94.0, 1.0, 2.0, 0.6572234887431746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 759739.1805682823, 759739.1805682823, 168728.9813807404], 
processed observation next is [1.0, 0.2608695652173913, 0.4419753086419752, 0.94, 1.0, 1.0, 0.5919327246942555, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2713354216315294, 0.2713354216315294, 0.3244788103475777], 
reward next is 0.6755, 
noisyNet noise sample is [array([-0.28281307], dtype=float32), -0.63836014]. 
=============================================
[2019-03-23 21:54:49,254] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.9881717e-15 1.0000000e+00 5.1542920e-26 9.0788803e-24 4.0493074e-27], sum to 1.0000
[2019-03-23 21:54:49,261] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8444
[2019-03-23 21:54:49,265] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.63333333333333, 78.66666666666667, 1.0, 2.0, 0.6908975036763843, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 787422.3779088878, 787422.3779088878, 174427.6941693872], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3439200.0000, 
sim time next is 3439800.0000, 
raw observation next is [27.45, 78.5, 1.0, 2.0, 0.6831419197516214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 778578.7767991655, 778578.7767991651, 172976.1664491504], 
processed observation next is [1.0, 0.8260869565217391, 0.5722222222222222, 0.785, 1.0, 1.0, 0.6227879997043112, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2780638488568448, 0.27806384885684465, 0.3326464739406738], 
reward next is 0.6674, 
noisyNet noise sample is [array([0.37002712], dtype=float32), 0.75810283]. 
=============================================
[2019-03-23 21:54:50,229] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.5415226e-14 1.0000000e+00 5.4467910e-22 4.4369201e-21 1.0299937e-22], sum to 1.0000
[2019-03-23 21:54:50,237] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7848
[2019-03-23 21:54:50,247] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.65, 67.5, 1.0, 2.0, 0.6311353898306392, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 719278.9785051141, 719278.9785051141, 163519.9867768716], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3432600.0000, 
sim time next is 3433200.0000, 
raw observation next is [29.76666666666667, 67.0, 1.0, 2.0, 0.64045416178664, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 729904.254863539, 729904.254863539, 165180.2988204489], 
processed observation next is [1.0, 0.7391304347826086, 0.6580246913580248, 0.67, 1.0, 1.0, 0.5719692402221905, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2606800910226925, 0.2606800910226925, 0.31765442080855555], 
reward next is 0.6823, 
noisyNet noise sample is [array([1.5585936], dtype=float32), -1.4533539]. 
=============================================
[2019-03-23 21:54:51,555] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.9453942e-25 1.0000000e+00 0.0000000e+00 7.8119406e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 21:54:51,563] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6961
[2019-03-23 21:54:51,566] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 100.0, 1.0, 2.0, 0.7888799241524445, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 899159.3681747539, 899159.3681747539, 193647.9038983358], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3466800.0000, 
sim time next is 3467400.0000, 
raw observation next is [24.0, 100.0, 1.0, 2.0, 0.8801784473669527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1003288.853514358, 1003288.853514358, 213057.0886311818], 
processed observation next is [1.0, 0.13043478260869565, 0.4444444444444444, 1.0, 1.0, 1.0, 0.8573552944844676, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.35831744768369933, 0.35831744768369933, 0.4097251704445804], 
reward next is 0.5903, 
noisyNet noise sample is [array([-1.114652], dtype=float32), -1.3153292]. 
=============================================
[2019-03-23 21:54:54,882] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.7618603e-13 1.0000000e+00 3.8691997e-20 1.6050782e-20 1.0689506e-22], sum to 1.0000
[2019-03-23 21:54:54,890] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5195
[2019-03-23 21:54:54,895] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1478850.832205692 W.
[2019-03-23 21:54:54,899] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.33333333333334, 71.33333333333333, 1.0, 2.0, 0.4323278711920215, 1.0, 1.0, 0.4323278711920215, 1.0, 2.0, 0.6882800508734915, 6.9112, 6.9112, 121.94756008, 1478850.832205692, 1478850.832205692, 311532.9489615816], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3516000.0000, 
sim time next is 3516600.0000, 
raw observation next is [27.41666666666667, 68.16666666666667, 1.0, 2.0, 0.6363670868521636, 1.0, 2.0, 0.6363670868521636, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1451175.107631898, 1451175.107631899, 280776.4210481264], 
processed observation next is [1.0, 0.6956521739130435, 0.5709876543209879, 0.6816666666666668, 1.0, 1.0, 0.5671036748240043, 1.0, 1.0, 0.5671036748240043, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5182768241542492, 0.5182768241542496, 0.5399546558617816], 
reward next is 0.4600, 
noisyNet noise sample is [array([-0.38226953], dtype=float32), -0.26104167]. 
=============================================
[2019-03-23 21:54:56,168] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.4163482e-23 1.0000000e+00 0.0000000e+00 1.2940527e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 21:54:56,177] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0031
[2019-03-23 21:54:56,184] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.06666666666667, 92.33333333333334, 1.0, 2.0, 0.7654241662398712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 920898.8483256161, 920898.8483256161, 191104.7202187589], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3572400.0000, 
sim time next is 3573000.0000, 
raw observation next is [22.15, 92.0, 1.0, 2.0, 0.8452729567606752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1015963.901130153, 1015963.901130153, 207945.2578644235], 
processed observation next is [1.0, 0.34782608695652173, 0.3759259259259259, 0.92, 1.0, 1.0, 0.8158011390008038, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.36284425040362606, 0.36284425040362606, 0.3998947266623529], 
reward next is 0.6001, 
noisyNet noise sample is [array([-1.7214218], dtype=float32), 0.72304446]. 
=============================================
[2019-03-23 21:54:56,200] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[67.08901]
 [67.08901]
 [67.08901]
 [67.08901]
 [67.08901]], R is [[67.01823425]
 [66.98054504]
 [67.00802612]
 [67.04516602]
 [67.10077667]].
[2019-03-23 21:54:59,689] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.6400301e-19 1.0000000e+00 7.7165942e-30 2.2593732e-28 7.0287127e-32], sum to 1.0000
[2019-03-23 21:54:59,695] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6805
[2019-03-23 21:54:59,702] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 83.0, 1.0, 2.0, 0.5588499259136239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 651639.6451902161, 651639.6451902166, 151838.6891073116], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3608400.0000, 
sim time next is 3609000.0000, 
raw observation next is [25.0, 83.0, 1.0, 2.0, 0.5592817075007116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 652140.6883017556, 652140.6883017556, 151910.3692518102], 
processed observation next is [1.0, 0.782608695652174, 0.48148148148148145, 0.83, 1.0, 1.0, 0.4753353660722757, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2329073886791984, 0.2329073886791984, 0.29213532548425036], 
reward next is 0.7079, 
noisyNet noise sample is [array([0.33933216], dtype=float32), 1.4698638]. 
=============================================
[2019-03-23 21:54:59,715] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[47.57657]
 [47.57657]
 [47.57657]
 [47.57657]
 [47.57657]], R is [[47.80866623]
 [48.03858566]
 [48.26600647]
 [48.4919281 ]
 [48.71759415]].
[2019-03-23 21:55:09,115] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 21:55:09,116] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:55:09,117] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:55:09,117] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:55:09,118] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:55:09,119] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:55:09,120] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:55:09,120] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:55:09,120] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:55:09,121] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:55:09,123] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:55:09,143] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run22
[2019-03-23 21:55:09,165] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run22
[2019-03-23 21:55:09,166] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run22
[2019-03-23 21:55:09,212] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run22
[2019-03-23 21:55:09,237] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run22
[2019-03-23 21:55:47,214] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.15374735]
[2019-03-23 21:55:47,217] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.26934217666667, 100.76352772, 1.0, 2.0, 0.4775324094407444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 574659.997814146, 574659.9978141455, 139590.6749906373]
[2019-03-23 21:55:47,217] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:55:47,219] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.6774036e-16 1.0000000e+00 1.1983808e-26 8.0868182e-25 2.0158699e-28], sampled 0.5694906947783155
[2019-03-23 21:56:11,945] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.15374735]
[2019-03-23 21:56:11,945] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.25, 83.5, 1.0, 2.0, 0.5188387983652951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 613541.7729132536, 613541.7729132532, 145683.7036629606]
[2019-03-23 21:56:11,948] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:56:11,951] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.6774036e-16 1.0000000e+00 1.1983808e-26 8.0868182e-25 2.0158699e-28], sampled 0.6571541816785165
[2019-03-23 21:56:20,966] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.15374735]
[2019-03-23 21:56:20,967] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.75180378166667, 68.915370645, 1.0, 2.0, 0.4160385623040774, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 512716.5356504686, 512716.5356504682, 130835.8338149284]
[2019-03-23 21:56:20,967] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:56:20,972] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.6774036e-16 1.0000000e+00 1.1983808e-26 8.0868182e-25 2.0158699e-28], sampled 0.40438755973670004
[2019-03-23 21:56:31,101] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.15374735]
[2019-03-23 21:56:31,102] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.07814275666667, 48.77953705833333, 1.0, 2.0, 0.2541513401045472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 327194.2849260888, 327194.2849260888, 110091.0257783821]
[2019-03-23 21:56:31,103] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:56:31,105] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.6774036e-16 1.0000000e+00 1.1983808e-26 8.0868182e-25 2.0158699e-28], sampled 0.5810752012789587
[2019-03-23 21:56:45,549] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.15374735]
[2019-03-23 21:56:45,552] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.058905155, 75.79825626499999, 1.0, 2.0, 0.542977131625279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 653548.202405605, 653548.202405605, 150021.5324767994]
[2019-03-23 21:56:45,552] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 21:56:45,556] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.6774036e-16 1.0000000e+00 1.1983808e-26 8.0868182e-25 2.0158699e-28], sampled 0.9487959513637624
[2019-03-23 21:56:49,403] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 21:56:49,492] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 21:56:49,589] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 21:56:49,607] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 21:56:49,812] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 21:56:50,830] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 525000, evaluation results [525000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 21:56:51,664] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.7461009e-21 1.0000000e+00 8.5564943e-37 1.4636776e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 21:56:51,670] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8449
[2019-03-23 21:56:51,676] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.2, 71.66666666666666, 1.0, 2.0, 0.5370800957428578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 633053.9766904257, 633053.9766904257, 148548.4300835542], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3822000.0000, 
sim time next is 3822600.0000, 
raw observation next is [26.1, 72.83333333333334, 1.0, 2.0, 0.5411766033706233, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 636827.3106506363, 636827.3106506363, 149174.4675696952], 
processed observation next is [0.0, 0.21739130434782608, 0.5222222222222223, 0.7283333333333334, 1.0, 1.0, 0.45378167067931346, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22743832523237012, 0.22743832523237012, 0.2868739760955677], 
reward next is 0.7131, 
noisyNet noise sample is [array([-0.10256059], dtype=float32), -0.8234944]. 
=============================================
[2019-03-23 21:56:52,223] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.0453954e-21 1.0000000e+00 2.1979708e-34 2.4938729e-31 1.8151927e-37], sum to 1.0000
[2019-03-23 21:56:52,232] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9221
[2019-03-23 21:56:52,236] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 75.66666666666667, 1.0, 2.0, 0.5620156479322861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 657144.5766457615, 657144.576645762, 152444.9045933379], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3813600.0000, 
sim time next is 3814200.0000, 
raw observation next is [26.0, 76.5, 1.0, 2.0, 0.5671530238866127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 661481.1542786269, 661481.1542786269, 153232.0317472231], 
processed observation next is [0.0, 0.13043478260869565, 0.5185185185185185, 0.765, 1.0, 1.0, 0.4847059808173961, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2362432693852239, 0.2362432693852239, 0.29467698412927523], 
reward next is 0.7053, 
noisyNet noise sample is [array([-0.03978106], dtype=float32), -0.4866068]. 
=============================================
[2019-03-23 21:56:54,471] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.6773402e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 21:56:54,478] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7687
[2019-03-23 21:56:54,481] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.25, 68.66666666666666, 1.0, 2.0, 0.7627450369550568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 869354.1264120702, 869354.1264120702, 188365.6222887504], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3873000.0000, 
sim time next is 3873600.0000, 
raw observation next is [29.9, 69.0, 1.0, 2.0, 0.7462053212910059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 850492.1903086734, 850492.190308673, 185077.3237900074], 
processed observation next is [0.0, 0.8695652173913043, 0.6629629629629629, 0.69, 1.0, 1.0, 0.697863477727388, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3037472108245262, 0.30374721082452605, 0.3559179303653988], 
reward next is 0.6441, 
noisyNet noise sample is [array([-1.0329067], dtype=float32), 2.3219638]. 
=============================================
[2019-03-23 21:57:00,720] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.8556925e-22 1.0000000e+00 0.0000000e+00 4.7430844e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 21:57:00,732] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4173
[2019-03-23 21:57:00,739] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.16666666666666, 88.16666666666667, 1.0, 2.0, 0.7627928732393635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000003, 6.9112, 121.9260426156618, 869408.6797122261, 869408.6797122248, 188375.6850779127], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3966600.0000, 
sim time next is 3967200.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.7603336365520863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 866604.130019347, 866604.130019347, 187883.6985297547], 
processed observation next is [0.0, 0.9565217391304348, 0.5555555555555556, 0.89, 1.0, 1.0, 0.7146829006572456, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3095014750069096, 0.3095014750069096, 0.3613148048649129], 
reward next is 0.6387, 
noisyNet noise sample is [array([-0.2137514], dtype=float32), -1.6208519]. 
=============================================
[2019-03-23 21:57:07,466] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.7582032e-23 1.0000000e+00 0.0000000e+00 1.8255554e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 21:57:07,476] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3771
[2019-03-23 21:57:07,479] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.5174551900558108, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 634575.6387531664, 634575.6387531664, 146227.6497901632], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4072800.0000, 
sim time next is 4073400.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.5118775112583323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 627776.0911963178, 627776.0911963178, 145331.2667844204], 
processed observation next is [1.0, 0.13043478260869565, 0.2962962962962963, 1.0, 1.0, 1.0, 0.41890179911706216, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22420574685582778, 0.22420574685582778, 0.27948320535465465], 
reward next is 0.7205, 
noisyNet noise sample is [array([-0.822388], dtype=float32), -1.7825965]. 
=============================================
[2019-03-23 21:57:08,156] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.6208333e-17 1.0000000e+00 5.2311802e-29 4.7992703e-27 2.3061311e-30], sum to 1.0000
[2019-03-23 21:57:08,162] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6122
[2019-03-23 21:57:08,166] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.6313478390641286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 762228.7486964829, 762228.7486964824, 165384.284548989], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4086000.0000, 
sim time next is 4086600.0000, 
raw observation next is [21.28333333333333, 97.33333333333334, 1.0, 2.0, 0.5796742187276378, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 699492.2599861135, 699492.2599861135, 156261.6901607243], 
processed observation next is [1.0, 0.30434782608695654, 0.3438271604938271, 0.9733333333333334, 1.0, 1.0, 0.4996121651519497, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24981866428075483, 0.24981866428075483, 0.3005032503090852], 
reward next is 0.6995, 
noisyNet noise sample is [array([0.867966], dtype=float32), -0.68959475]. 
=============================================
[2019-03-23 21:57:13,072] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.7656303e-16 1.0000000e+00 9.9041564e-28 2.0909932e-25 1.2843249e-29], sum to 1.0000
[2019-03-23 21:57:13,079] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3927
[2019-03-23 21:57:13,083] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.16666666666666, 30.66666666666666, 1.0, 2.0, 0.4289617591838268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 518773.3349089645, 518773.334908964, 132424.471646477], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4210800.0000, 
sim time next is 4211400.0000, 
raw observation next is [34.08333333333334, 32.33333333333334, 1.0, 2.0, 0.446964284820598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 537215.7981155039, 537215.7981155034, 134956.4453796302], 
processed observation next is [1.0, 0.7391304347826086, 0.8179012345679015, 0.3233333333333334, 1.0, 1.0, 0.34162414859595003, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19186278504125137, 0.1918627850412512, 0.25953162573005806], 
reward next is 0.7405, 
noisyNet noise sample is [array([-0.796516], dtype=float32), 0.13154662]. 
=============================================
[2019-03-23 21:57:14,175] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.2073571e-18 1.0000000e+00 2.8973100e-28 1.6914130e-26 1.4665485e-30], sum to 1.0000
[2019-03-23 21:57:14,186] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8317
[2019-03-23 21:57:14,190] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.66666666666667, 35.33333333333334, 1.0, 2.0, 0.4870778279536119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 580029.0256224555, 580029.0256224555, 140845.70556399], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4213200.0000, 
sim time next is 4213800.0000, 
raw observation next is [33.5, 36.0, 1.0, 2.0, 0.4871915122570974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 579819.3499331633, 579819.3499331633, 140850.3853144016], 
processed observation next is [1.0, 0.782608695652174, 0.7962962962962963, 0.36, 1.0, 1.0, 0.3895137050679731, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20707833926184402, 0.20707833926184402, 0.2708661256046184], 
reward next is 0.7291, 
noisyNet noise sample is [array([-1.3787509], dtype=float32), 0.6412879]. 
=============================================
[2019-03-23 21:57:22,801] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.6189305e-15 1.0000000e+00 2.0722066e-24 4.6091414e-23 1.4649866e-25], sum to 1.0000
[2019-03-23 21:57:22,809] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0410
[2019-03-23 21:57:22,817] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1700864.998148738 W.
[2019-03-23 21:57:22,823] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.4, 81.33333333333334, 1.0, 2.0, 0.497165096580135, 1.0, 2.0, 0.497165096580135, 1.0, 2.0, 0.7915030252923805, 6.9112, 6.9112, 121.94756008, 1700864.998148738, 1700864.998148738, 342199.8068897605], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4351200.0000, 
sim time next is 4351800.0000, 
raw observation next is [26.7, 80.16666666666667, 1.0, 2.0, 0.8601608475425419, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426155118, 1695608.7340447, 1695608.7340447, 348497.2563933891], 
processed observation next is [1.0, 0.34782608695652173, 0.5444444444444444, 0.8016666666666667, 1.0, 1.0, 0.833524818503026, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8094621288191401, 0.6055745478731072, 0.6055745478731072, 0.6701870315257482], 
reward next is 0.3298, 
noisyNet noise sample is [array([-0.18963744], dtype=float32), -0.8718155]. 
=============================================
[2019-03-23 21:57:25,343] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.9526446e-24 1.0000000e+00 0.0000000e+00 8.5225511e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 21:57:25,353] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6871
[2019-03-23 21:57:25,363] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.95, 85.0, 1.0, 2.0, 0.5733569386862045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 666572.7158675704, 666572.7158675704, 154180.7103372771], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4437000.0000, 
sim time next is 4437600.0000, 
raw observation next is [25.3, 84.66666666666667, 1.0, 2.0, 0.5885041455773894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 679901.0577988403, 679901.0577988403, 156557.9875347537], 
processed observation next is [0.0, 0.34782608695652173, 0.49259259259259264, 0.8466666666666667, 1.0, 1.0, 0.5101239828302254, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2428218063567287, 0.2428218063567287, 0.30107305295144937], 
reward next is 0.6989, 
noisyNet noise sample is [array([-0.40174457], dtype=float32), 0.5962978]. 
=============================================
[2019-03-23 21:57:26,643] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.3575742e-24 1.0000000e+00 9.7752866e-38 1.8591624e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 21:57:26,652] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1670
[2019-03-23 21:57:26,657] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 70.0, 1.0, 2.0, 0.7151768692912087, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 815108.5126218502, 815108.5126218498, 179040.7203238141], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4461600.0000, 
sim time next is 4462200.0000, 
raw observation next is [30.0, 70.0, 1.0, 2.0, 0.728133080311069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 829883.0889152735, 829883.0889152735, 181541.7028957919], 
processed observation next is [0.0, 0.6521739130434783, 0.6666666666666666, 0.7, 1.0, 1.0, 0.676348905132225, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29638681746974055, 0.29638681746974055, 0.34911865941498443], 
reward next is 0.6509, 
noisyNet noise sample is [array([-0.36456573], dtype=float32), -0.31387544]. 
=============================================
[2019-03-23 21:57:35,026] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0597572e-24 1.0000000e+00 0.0000000e+00 1.0006718e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 21:57:35,032] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2700
[2019-03-23 21:57:35,037] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333333, 99.16666666666666, 1.0, 2.0, 0.5284584684006411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 634803.5976163765, 634803.5976163765, 147599.8803790954], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4597800.0000, 
sim time next is 4598400.0000, 
raw observation next is [21.26666666666667, 99.33333333333334, 1.0, 2.0, 0.4944036306303334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 594381.4311792044, 594381.4311792044, 142186.1121619031], 
processed observation next is [1.0, 0.21739130434782608, 0.34320987654320995, 0.9933333333333334, 1.0, 1.0, 0.39809956027420645, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21227908256400158, 0.21227908256400158, 0.27343483108058286], 
reward next is 0.7266, 
noisyNet noise sample is [array([-1.6379073], dtype=float32), 2.2447956]. 
=============================================
[2019-03-23 21:57:38,335] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.6342752e-24 1.0000000e+00 0.0000000e+00 2.1080254e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 21:57:38,342] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8234
[2019-03-23 21:57:38,356] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 94.0, 1.0, 2.0, 0.7225834546487188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 823554.5551030238, 823554.5551030238, 180465.3629663561], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4657200.0000, 
sim time next is 4657800.0000, 
raw observation next is [26.0, 94.0, 1.0, 2.0, 0.7238144520453992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 824958.3225088773, 824958.3225088773, 180703.3165396995], 
processed observation next is [1.0, 0.9130434782608695, 0.5185185185185185, 0.94, 1.0, 1.0, 0.6712076810064276, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29462797232459903, 0.29462797232459903, 0.34750637796096057], 
reward next is 0.6525, 
noisyNet noise sample is [array([0.48551667], dtype=float32), -2.3560514]. 
=============================================
[2019-03-23 21:57:41,523] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 21:57:41,524] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 21:57:41,529] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:57:41,529] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 21:57:41,531] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:57:41,532] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 21:57:41,534] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 21:57:41,534] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:57:41,534] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:57:41,535] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 21:57:41,535] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 21:57:41,550] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run23
[2019-03-23 21:57:41,573] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run23
[2019-03-23 21:57:41,599] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run23
[2019-03-23 21:57:41,623] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run23
[2019-03-23 21:57:41,650] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run23
[2019-03-23 21:57:43,230] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.12234571]
[2019-03-23 21:57:43,231] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.9, 19.33333333333334, 1.0, 2.0, 0.5979894145672819, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 768936.9035615718, 768936.9035615728, 160313.8151640397]
[2019-03-23 21:57:43,232] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:57:43,234] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.5000398e-17 1.0000000e+00 2.1267407e-27 1.8053770e-25 3.6030225e-29], sampled 0.9346971335534299
[2019-03-23 21:57:43,318] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.12234571]
[2019-03-23 21:57:43,319] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.7, 25.0, 1.0, 2.0, 0.5282286053219576, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 672069.0866313069, 672069.0866313069, 148413.7870710025]
[2019-03-23 21:57:43,320] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:57:43,322] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.5000398e-17 1.0000000e+00 2.1267407e-27 1.8053770e-25 3.6030225e-29], sampled 0.6790733547823783
[2019-03-23 21:58:04,654] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.12234571]
[2019-03-23 21:58:04,655] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.865477255, 55.720465395, 1.0, 2.0, 0.3438108354579786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 435610.0407138292, 435610.0407138287, 121141.7089844155]
[2019-03-23 21:58:04,656] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:58:04,658] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.5000398e-17 1.0000000e+00 2.1267407e-27 1.8053770e-25 3.6030225e-29], sampled 0.7420416410313028
[2019-03-23 21:58:18,135] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.12234571]
[2019-03-23 21:58:18,136] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [33.25, 52.16666666666667, 1.0, 2.0, 0.7708637809710585, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1593685.982756787, 1593685.982756787, 330518.9188422666]
[2019-03-23 21:58:18,137] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:58:18,139] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [8.5000398e-17 1.0000000e+00 2.1267407e-27 1.8053770e-25 3.6030225e-29], sampled 0.6663666908557339
[2019-03-23 21:58:18,141] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1593685.982756787 W.
[2019-03-23 21:58:27,991] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.12234571]
[2019-03-23 21:58:27,992] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.211255405, 95.775712325, 1.0, 2.0, 0.7350975661475995, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1552861.872135612, 1552861.872135612, 323699.9034183805]
[2019-03-23 21:58:27,993] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 21:58:27,996] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.5000398e-17 1.0000000e+00 2.1267407e-27 1.8053770e-25 3.6030225e-29], sampled 0.07607743610930906
[2019-03-23 21:58:27,997] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1552861.872135612 W.
[2019-03-23 21:58:28,556] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.12234571]
[2019-03-23 21:58:28,557] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.46666666666667, 71.33333333333334, 1.0, 2.0, 0.7120331097528257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 811523.5788179103, 811523.5788179103, 178436.7077340274]
[2019-03-23 21:58:28,559] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 21:58:28,561] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.5000398e-17 1.0000000e+00 2.1267407e-27 1.8053770e-25 3.6030225e-29], sampled 0.20277648784256397
[2019-03-23 21:58:30,859] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.12234571]
[2019-03-23 21:58:30,861] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.75, 68.33333333333334, 1.0, 2.0, 0.7514444243210936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 856466.827224031, 856466.8272240305, 186117.145665417]
[2019-03-23 21:58:30,862] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 21:58:30,866] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [8.5000398e-17 1.0000000e+00 2.1267407e-27 1.8053770e-25 3.6030225e-29], sampled 0.1977598088049205
[2019-03-23 21:59:04,666] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.12234571]
[2019-03-23 21:59:04,668] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.0, 45.0, 1.0, 2.0, 0.3097216539408216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 399534.3522952537, 399534.3522952537, 111863.2006415843]
[2019-03-23 21:59:04,668] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 21:59:04,670] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.5000398e-17 1.0000000e+00 2.1267407e-27 1.8053770e-25 3.6030225e-29], sampled 0.5416068878544826
[2019-03-23 21:59:21,789] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 21:59:21,992] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 21:59:22,057] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 21:59:22,094] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 21:59:22,175] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 21:59:23,193] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 550000, evaluation results [550000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 21:59:24,750] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.0106931e-21 1.0000000e+00 1.3743357e-37 2.0679061e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 21:59:24,763] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4120
[2019-03-23 21:59:24,770] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1434537.782249511 W.
[2019-03-23 21:59:24,774] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.9, 93.66666666666667, 1.0, 2.0, 0.4193854953051989, 1.0, 1.0, 0.4193854953051989, 1.0, 2.0, 0.6676753669579141, 6.911200000000001, 6.9112, 121.94756008, 1434537.782249511, 1434537.78224951, 305678.1510021568], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4783200.0000, 
sim time next is 4783800.0000, 
raw observation next is [23.9, 93.83333333333334, 1.0, 2.0, 0.4179838585191663, 1.0, 2.0, 0.4179838585191663, 1.0, 2.0, 0.6654439155464268, 6.9112, 6.9112, 121.94756008, 1429738.909901299, 1429738.909901299, 305049.6502002039], 
processed observation next is [1.0, 0.34782608695652173, 0.4407407407407407, 0.9383333333333335, 1.0, 1.0, 0.30712364109424556, 1.0, 1.0, 0.30712364109424556, 1.0, 1.0, 0.5818048944330334, 0.0, 0.0, 0.8096049824067558, 0.510621039250464, 0.510621039250464, 0.5866339426926998], 
reward next is 0.4134, 
noisyNet noise sample is [array([-1.8108115], dtype=float32), 2.2797463]. 
=============================================
[2019-03-23 21:59:27,267] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.79427836e-14 1.00000000e+00 1.16762505e-23 1.08499843e-20
 3.65062246e-25], sum to 1.0000
[2019-03-23 21:59:27,274] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8466
[2019-03-23 21:59:27,280] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1921160.061779848 W.
[2019-03-23 21:59:27,284] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.33333333333334, 86.33333333333334, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.995244763317961, 6.9112, 121.9255759036366, 1921160.061779848, 1878121.795869093, 383833.8460466776], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4803600.0000, 
sim time next is 4804200.0000, 
raw observation next is [27.25, 87.0, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 7.319850386605834, 6.9112, 121.9243670016992, 2087559.254690031, 1878296.607899984, 382670.5678464904], 
processed observation next is [1.0, 0.6086956521739131, 0.5648148148148148, 0.87, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 0.04086503866058342, 0.0, 0.80945100448594, 0.7455568766750111, 0.6708202171071371, 0.7359049381663277], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.87401944], dtype=float32), 0.5564975]. 
=============================================
[2019-03-23 21:59:28,106] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.31895674e-17 1.00000000e+00 2.75166239e-26 1.28302625e-23
 1.38199136e-28], sum to 1.0000
[2019-03-23 21:59:28,114] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5680
[2019-03-23 21:59:28,119] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 93.83333333333334, 1.0, 2.0, 0.7226465308894803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 823626.4840073199, 823626.4840073199, 180477.4257197227], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4828200.0000, 
sim time next is 4828800.0000, 
raw observation next is [26.0, 93.66666666666667, 1.0, 2.0, 0.7196813860710795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 820245.1924964526, 820245.1924964526, 179905.1764628701], 
processed observation next is [1.0, 0.9130434782608695, 0.5185185185185185, 0.9366666666666668, 1.0, 1.0, 0.6662873643703326, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29294471160587593, 0.29294471160587593, 0.3459714931978271], 
reward next is 0.6540, 
noisyNet noise sample is [array([-1.954348], dtype=float32), 1.249635]. 
=============================================
[2019-03-23 21:59:33,922] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.9758379e-21 1.0000000e+00 4.7762020e-35 1.7030349e-33 2.5734414e-37], sum to 1.0000
[2019-03-23 21:59:33,930] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5345
[2019-03-23 21:59:33,934] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 88.0, 1.0, 2.0, 0.6388263957497304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 749880.6720505665, 749880.6720505665, 165910.7153873957], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4949400.0000, 
sim time next is 4950000.0000, 
raw observation next is [24.0, 89.0, 1.0, 2.0, 0.6380598466361044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 746987.950491324, 746987.950491324, 165685.649480028], 
processed observation next is [1.0, 0.30434782608695654, 0.4444444444444444, 0.89, 1.0, 1.0, 0.5691188650429814, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26678141088975854, 0.26678141088975854, 0.3186262490000538], 
reward next is 0.6814, 
noisyNet noise sample is [array([-1.5129632], dtype=float32), 0.41440615]. 
=============================================
[2019-03-23 21:59:33,952] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[60.733665]
 [60.733665]
 [60.733665]
 [60.733665]
 [60.733665]], R is [[60.80770111]
 [60.88056564]
 [60.95698547]
 [61.04635239]
 [61.14231491]].
[2019-03-23 21:59:37,149] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.8420918e-13 1.0000000e+00 2.9202085e-23 4.6110432e-22 8.3366811e-25], sum to 1.0000
[2019-03-23 21:59:37,157] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3752
[2019-03-23 21:59:37,162] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.9, 84.0, 1.0, 2.0, 0.6439533173285215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 733894.0347683355, 733894.0347683355, 165807.357780085], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4988400.0000, 
sim time next is 4989000.0000, 
raw observation next is [26.95, 84.0, 1.0, 2.0, 0.6515404660495343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 742545.0657771796, 742545.0657771796, 167175.0142325379], 
processed observation next is [1.0, 0.7391304347826086, 0.5537037037037037, 0.84, 1.0, 1.0, 0.5851672214875409, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2651946663489927, 0.2651946663489927, 0.3214904119856498], 
reward next is 0.6785, 
noisyNet noise sample is [array([0.5056267], dtype=float32), -0.7620242]. 
=============================================
[2019-03-23 21:59:37,190] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[36.701176]
 [36.701176]
 [36.701176]
 [36.701176]
 [36.701176]], R is [[37.01267242]
 [37.32368851]
 [37.63446808]
 [37.94021988]
 [38.12128448]].
[2019-03-23 21:59:43,380] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.4663965e-23 1.0000000e+00 0.0000000e+00 1.0502164e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 21:59:43,390] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5856
[2019-03-23 21:59:43,393] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.9, 66.0, 1.0, 2.0, 0.755402371367533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 860980.4735869243, 860980.4735869243, 186901.4406884585], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5061600.0000, 
sim time next is 5062200.0000, 
raw observation next is [31.08333333333333, 66.83333333333333, 1.0, 2.0, 0.7398160524504519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 843205.9752796657, 843205.9752796657, 183824.4608313432], 
processed observation next is [0.0, 0.6086956521739131, 0.7067901234567899, 0.6683333333333333, 1.0, 1.0, 0.690257205298157, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.30114499117130916, 0.30114499117130916, 0.35350857852181383], 
reward next is 0.6465, 
noisyNet noise sample is [array([-0.7348015], dtype=float32), 0.67250615]. 
=============================================
[2019-03-23 21:59:46,770] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.3956399e-22 1.0000000e+00 2.6356463e-36 1.0570514e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 21:59:46,778] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8789
[2019-03-23 21:59:46,785] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.76666666666667, 85.66666666666666, 1.0, 2.0, 0.714321854837514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 814133.5094769928, 814133.5094769928, 178873.0137151155], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5172000.0000, 
sim time next is 5172600.0000, 
raw observation next is [26.63333333333333, 85.83333333333334, 1.0, 2.0, 0.7092656194179138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 808367.7312074881, 808367.7312074881, 177905.1066345203], 
processed observation next is [0.0, 0.8695652173913043, 0.5419753086419752, 0.8583333333333334, 1.0, 1.0, 0.653887642164183, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28870276114553145, 0.28870276114553145, 0.3421252050663852], 
reward next is 0.6579, 
noisyNet noise sample is [array([-1.7125195], dtype=float32), -0.21064344]. 
=============================================
[2019-03-23 21:59:47,228] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.8850740e-22 1.0000000e+00 6.8165550e-36 4.7023535e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 21:59:47,236] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2931
[2019-03-23 21:59:47,241] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.91666666666666, 69.16666666666666, 1.0, 2.0, 0.7961589804291711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 907460.8934246823, 907460.8934246823, 195154.2813943087], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5158200.0000, 
sim time next is 5158800.0000, 
raw observation next is [30.9, 69.0, 1.0, 2.0, 0.7932423867391108, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 904134.6030605022, 904134.6030605022, 194554.1157416388], 
processed observation next is [0.0, 0.7391304347826086, 0.7, 0.69, 1.0, 1.0, 0.7538599842132272, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3229052153787508, 0.3229052153787508, 0.37414253027238226], 
reward next is 0.6259, 
noisyNet noise sample is [array([0.07180145], dtype=float32), 0.2693283]. 
=============================================
[2019-03-23 21:59:47,684] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.8283380e-23 1.0000000e+00 0.0000000e+00 1.7798624e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 21:59:47,692] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0381
[2019-03-23 21:59:47,697] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.9, 91.0, 1.0, 2.0, 0.6373573477747546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 728166.0717597627, 728166.0717597627, 164712.6451915106], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5182200.0000, 
sim time next is 5182800.0000, 
raw observation next is [24.93333333333333, 92.0, 1.0, 2.0, 0.6472790486336369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 737686.0934874393, 737686.0934874393, 166401.4549401015], 
processed observation next is [0.0, 1.0, 0.47901234567901224, 0.92, 1.0, 1.0, 0.5800941055162344, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2634593191026569, 0.2634593191026569, 0.3200027979617337], 
reward next is 0.6800, 
noisyNet noise sample is [array([-0.35581684], dtype=float32), 1.4543487]. 
=============================================
[2019-03-23 21:59:50,909] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.6788610e-15 1.0000000e+00 2.8743303e-24 5.3039733e-24 1.2233046e-25], sum to 1.0000
[2019-03-23 21:59:50,915] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8774
[2019-03-23 21:59:50,919] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 99.33333333333334, 1.0, 2.0, 0.7022094033671746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 814348.6404477098, 814348.6404477098, 177254.5165524523], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5205000.0000, 
sim time next is 5205600.0000, 
raw observation next is [23.0, 100.0, 1.0, 2.0, 0.6988979690306758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 810857.3818702619, 810857.3818702619, 176639.8922588337], 
processed observation next is [1.0, 0.2608695652173913, 0.4074074074074074, 1.0, 1.0, 1.0, 0.641545201226995, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28959192209652207, 0.28959192209652207, 0.3396921004977571], 
reward next is 0.6603, 
noisyNet noise sample is [array([-0.12315576], dtype=float32), 1.0110817]. 
=============================================
[2019-03-23 21:59:51,178] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.2619757e-13 1.0000000e+00 5.0717966e-23 1.7923223e-21 4.0886456e-24], sum to 1.0000
[2019-03-23 21:59:51,184] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4401
[2019-03-23 21:59:51,192] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2143752.655531982 W.
[2019-03-23 21:59:51,198] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.0, 70.0, 1.0, 2.0, 0.626466590515991, 1.0, 2.0, 0.626466590515991, 1.0, 1.0, 0.9973552146939315, 6.911200000000001, 6.9112, 121.94756008, 2143752.655531982, 2143752.655531981, 409984.412354416], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5230800.0000, 
sim time next is 5231400.0000, 
raw observation next is [29.91666666666666, 69.5, 1.0, 2.0, 0.6103073282510117, 1.0, 2.0, 0.6103073282510117, 1.0, 2.0, 0.9716291428976536, 6.911200000000001, 6.9112, 121.94756008, 2088391.41923427, 2088391.41923427, 401020.1542844138], 
processed observation next is [1.0, 0.5652173913043478, 0.66358024691358, 0.695, 1.0, 1.0, 0.5360801526797758, 1.0, 1.0, 0.5360801526797758, 1.0, 1.0, 0.964536428622067, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7458540782979536, 0.7458540782979536, 0.7711926043931034], 
reward next is 0.2288, 
noisyNet noise sample is [array([-0.75942373], dtype=float32), 1.1828167]. 
=============================================
[2019-03-23 21:59:58,468] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0564837e-24 1.0000000e+00 0.0000000e+00 3.7573435e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 21:59:58,469] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4951
[2019-03-23 21:59:58,475] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.56666666666667, 91.0, 1.0, 2.0, 0.7388875836743691, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 849554.5277904281, 849554.5277904281, 184012.1487745554], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5381400.0000, 
sim time next is 5382000.0000, 
raw observation next is [24.6, 91.0, 1.0, 2.0, 0.7179484108209931, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 824888.1739753722, 824888.1739753722, 179902.991792306], 
processed observation next is [1.0, 0.30434782608695654, 0.46666666666666673, 0.91, 1.0, 1.0, 0.6642242985964204, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2946029192769187, 0.2946029192769187, 0.3459672919082808], 
reward next is 0.6540, 
noisyNet noise sample is [array([-1.6839147], dtype=float32), -0.27174458]. 
=============================================
[2019-03-23 21:59:58,492] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[69.81214]
 [69.81214]
 [69.81214]
 [69.81214]
 [69.81214]], R is [[69.76804352]
 [69.71649933]
 [69.66368103]
 [69.61910248]
 [69.5991745 ]].
[2019-03-23 22:00:04,458] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.3106713e-18 1.0000000e+00 6.4852456e-30 1.3624724e-27 6.3236880e-31], sum to 1.0000
[2019-03-23 22:00:04,468] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7212
[2019-03-23 22:00:04,475] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2411728.13233735 W.
[2019-03-23 22:00:04,480] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.3, 69.0, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 7.076086371103493, 6.9112, 121.9255139620851, 2411728.13233735, 2327291.939060376, 443049.5418512911], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5497200.0000, 
sim time next is 5497800.0000, 
raw observation next is [30.93333333333334, 70.0, 1.0, 2.0, 0.9476119477045161, 1.0, 2.0, 0.9476119477045161, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9259433240673, 2161824.882545629, 2161824.882545629, 408526.8474204396], 
processed observation next is [1.0, 0.6521739130434783, 0.7012345679012348, 0.7, 1.0, 1.0, 0.9376332710768048, 1.0, 1.0, 0.9376332710768048, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094614696272044, 0.7720803151948675, 0.7720803151948675, 0.7856285527316146], 
reward next is 0.2144, 
noisyNet noise sample is [array([0.47563952], dtype=float32), 1.2320927]. 
=============================================
[2019-03-23 22:00:12,373] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4020577e-21 1.0000000e+00 1.3020361e-34 3.9461037e-33 1.3162217e-37], sum to 1.0000
[2019-03-23 22:00:12,381] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0180
[2019-03-23 22:00:12,386] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 97.0, 1.0, 2.0, 0.5863809489934163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 678574.4084234145, 678574.4084234145, 156247.5260961805], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5625000.0000, 
sim time next is 5625600.0000, 
raw observation next is [23.5, 97.0, 1.0, 2.0, 0.586036100306232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 678175.7592899546, 678175.7592899546, 156188.7379280287], 
processed observation next is [0.0, 0.08695652173913043, 0.42592592592592593, 0.97, 1.0, 1.0, 0.5071858336978952, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24220562831784093, 0.24220562831784093, 0.30036295755390136], 
reward next is 0.6996, 
noisyNet noise sample is [array([-0.64107853], dtype=float32), 0.92005473]. 
=============================================
[2019-03-23 22:00:14,157] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 22:00:14,159] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:00:14,160] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:00:14,160] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:00:14,161] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:00:14,163] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:00:14,164] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:00:14,164] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:00:14,165] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:00:14,165] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:00:14,166] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:00:14,180] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run24
[2019-03-23 22:00:14,181] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run24
[2019-03-23 22:00:14,202] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run24
[2019-03-23 22:00:14,225] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run24
[2019-03-23 22:00:14,268] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run24
[2019-03-23 22:00:27,631] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.09584473]
[2019-03-23 22:00:27,633] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.46666666666667, 45.66666666666667, 1.0, 2.0, 0.6900406171025352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 873795.9744029912, 873795.9744029912, 177292.632377884]
[2019-03-23 22:00:27,634] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:00:27,637] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.3922412e-22 1.0000000e+00 1.1735563e-36 4.2222113e-34 0.0000000e+00], sampled 0.7387494188103738
[2019-03-23 22:00:29,108] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.09584473]
[2019-03-23 22:00:29,109] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [18.23333333333333, 93.66666666666667, 1.0, 2.0, 0.3234056403512834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 409989.282904302, 409989.282904302, 118500.5547063777]
[2019-03-23 22:00:29,111] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:00:29,112] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.3922412e-22 1.0000000e+00 1.1735563e-36 4.2222113e-34 0.0000000e+00], sampled 0.7741540601614014
[2019-03-23 22:00:30,502] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.09584473]
[2019-03-23 22:00:30,504] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.2, 43.0, 1.0, 2.0, 0.7650375356558748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 958505.8289226338, 958505.8289226328, 192119.6428165595]
[2019-03-23 22:00:30,506] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:00:30,509] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.3922412e-22 1.0000000e+00 1.1735563e-36 4.2222113e-34 0.0000000e+00], sampled 0.7458008346559852
[2019-03-23 22:00:32,126] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.09584473]
[2019-03-23 22:00:32,128] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.63853933166667, 69.142509435, 1.0, 2.0, 0.3737727949805872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 466970.345983761, 466970.3459837605, 125063.7960978831]
[2019-03-23 22:00:32,128] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:00:32,132] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.3922412e-22 1.0000000e+00 1.1735563e-36 4.2222113e-34 0.0000000e+00], sampled 0.9731631151252538
[2019-03-23 22:00:35,609] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.09584473]
[2019-03-23 22:00:35,610] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.89954707, 74.46459480333334, 1.0, 2.0, 0.4100846178098418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 510119.7188578122, 510119.7188578122, 130091.0950550132]
[2019-03-23 22:00:35,611] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:00:35,614] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.3922412e-22 1.0000000e+00 1.1735563e-36 4.2222113e-34 0.0000000e+00], sampled 0.9901768354123044
[2019-03-23 22:01:16,419] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.09584473]
[2019-03-23 22:01:16,419] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.0, 58.0, 1.0, 2.0, 0.5061362389919869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 602756.6656391125, 602756.665639112, 143828.2822461827]
[2019-03-23 22:01:16,421] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:01:16,425] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.3922412e-22 1.0000000e+00 1.1735563e-36 4.2222113e-34 0.0000000e+00], sampled 0.7126507411603846
[2019-03-23 22:01:21,263] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.09584473]
[2019-03-23 22:01:21,264] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.43700653, 81.38597949333334, 1.0, 2.0, 0.8100386068874905, 1.0, 2.0, 0.8100386068874905, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1847648.661447801, 1847648.661447801, 347921.1106531928]
[2019-03-23 22:01:21,265] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:01:21,268] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.3922412e-22 1.0000000e+00 1.1735563e-36 4.2222113e-34 0.0000000e+00], sampled 0.5023576139413737
[2019-03-23 22:01:21,269] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1847648.661447801 W.
[2019-03-23 22:01:25,820] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.09584473]
[2019-03-23 22:01:25,820] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.8, 38.0, 1.0, 2.0, 0.7305640156727439, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 856904.8040686514, 856904.8040686509, 183185.9554998127]
[2019-03-23 22:01:25,821] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:01:25,826] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.3922412e-22 1.0000000e+00 1.1735563e-36 4.2222113e-34 0.0000000e+00], sampled 0.504857022409886
[2019-03-23 22:01:54,117] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.09584473]
[2019-03-23 22:01:54,118] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.30793170166667, 61.95456016166666, 1.0, 2.0, 0.5873391763539723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 669344.4492824761, 669344.4492824761, 155917.1449187815]
[2019-03-23 22:01:54,118] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:01:54,120] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.3922412e-22 1.0000000e+00 1.1735563e-36 4.2222113e-34 0.0000000e+00], sampled 0.08398506847294895
[2019-03-23 22:01:54,615] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:01:54,631] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:01:54,680] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:01:54,879] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:01:54,952] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:01:55,968] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 575000, evaluation results [575000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:01:57,897] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1288731e-22 1.0000000e+00 0.0000000e+00 1.7753019e-38 0.0000000e+00], sum to 1.0000
[2019-03-23 22:01:57,904] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9994
[2019-03-23 22:01:57,910] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.2, 96.66666666666667, 1.0, 2.0, 0.4723759474896193, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 571600.7001982458, 571600.7001982458, 138904.340761957], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5718000.0000, 
sim time next is 5718600.0000, 
raw observation next is [21.15, 96.5, 1.0, 2.0, 0.4689354422845984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 568106.7817178323, 568106.7817178323, 138400.6692168432], 
processed observation next is [0.0, 0.17391304347826086, 0.33888888888888885, 0.965, 1.0, 1.0, 0.36778028843404564, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2028952791849401, 0.2028952791849401, 0.2661551331093139], 
reward next is 0.7338, 
noisyNet noise sample is [array([0.9636726], dtype=float32), 0.4550089]. 
=============================================
[2019-03-23 22:02:00,092] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.319782e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:02:00,101] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0370
[2019-03-23 22:02:00,106] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.96666666666667, 62.0, 1.0, 2.0, 0.5384129084865275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 633363.1154420188, 633363.1154420188, 148714.0303334832], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5755200.0000, 
sim time next is 5755800.0000, 
raw observation next is [27.98333333333333, 62.0, 1.0, 2.0, 0.540726059850053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 635895.6502764587, 635895.6502764587, 149084.0841116886], 
processed observation next is [0.0, 0.6086956521739131, 0.5919753086419752, 0.62, 1.0, 1.0, 0.4532453093453011, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22710558938444952, 0.22710558938444952, 0.2867001617532473], 
reward next is 0.7133, 
noisyNet noise sample is [array([-0.10931346], dtype=float32), 0.38351274]. 
=============================================
[2019-03-23 22:02:00,124] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.3043606e-25 1.0000000e+00 0.0000000e+00 1.9137183e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 22:02:00,133] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4687
[2019-03-23 22:02:00,143] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.41666666666667, 69.16666666666667, 1.0, 2.0, 0.4805128412681891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 577656.5506808585, 577656.5506808581, 140028.4391723539], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5742600.0000, 
sim time next is 5743200.0000, 
raw observation next is [25.53333333333334, 68.33333333333334, 1.0, 2.0, 0.4799838980020159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 577196.9155806786, 577196.9155806786, 139953.0135261327], 
processed observation next is [0.0, 0.4782608695652174, 0.5012345679012348, 0.6833333333333335, 1.0, 1.0, 0.3809332119071618, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20614175556452807, 0.20614175556452807, 0.2691404106271783], 
reward next is 0.7309, 
noisyNet noise sample is [array([-0.7073793], dtype=float32), 0.8360788]. 
=============================================
[2019-03-23 22:02:01,082] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.3396068e-23 1.0000000e+00 0.0000000e+00 1.3198732e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 22:02:01,093] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6153
[2019-03-23 22:02:01,096] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 62.0, 1.0, 2.0, 0.492132634640125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 588625.3392841821, 588625.3392841821, 141724.8330963647], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5749200.0000, 
sim time next is 5749800.0000, 
raw observation next is [27.15, 62.0, 1.0, 2.0, 0.49747106012661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 593759.5009906864, 593759.5009906859, 142513.9831679177], 
processed observation next is [0.0, 0.5652173913043478, 0.561111111111111, 0.62, 1.0, 1.0, 0.4017512620554881, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21205696463953083, 0.21205696463953067, 0.2740653522459956], 
reward next is 0.7259, 
noisyNet noise sample is [array([-0.39356586], dtype=float32), 0.65857714]. 
=============================================
[2019-03-23 22:02:01,734] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.8580110e-23 1.0000000e+00 0.0000000e+00 1.2162676e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 22:02:01,741] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5518
[2019-03-23 22:02:01,744] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.46666666666667, 87.5, 1.0, 2.0, 0.4278328193513551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 524921.4351576674, 524921.4351576674, 132481.4344130966], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5730600.0000, 
sim time next is 5731200.0000, 
raw observation next is [21.5, 87.0, 1.0, 2.0, 0.4261064130373477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 523040.1732337791, 523040.1732337791, 132236.7576461], 
processed observation next is [0.0, 0.34782608695652173, 0.35185185185185186, 0.87, 1.0, 1.0, 0.3167933488539854, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1868000618692068, 0.1868000618692068, 0.2543014570117308], 
reward next is 0.7457, 
noisyNet noise sample is [array([2.0226822], dtype=float32), -1.830322]. 
=============================================
[2019-03-23 22:02:07,350] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.7561266e-22 1.0000000e+00 0.0000000e+00 1.6911657e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 22:02:07,361] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8857
[2019-03-23 22:02:07,365] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.4, 81.66666666666667, 1.0, 2.0, 0.3943092881691931, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 489404.2004775843, 489404.2004775843, 127838.8144660111], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5874600.0000, 
sim time next is 5875200.0000, 
raw observation next is [21.3, 82.0, 1.0, 2.0, 0.391480599439211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 486259.0534430764, 486259.0534430759, 127451.5856219057], 
processed observation next is [1.0, 0.0, 0.3444444444444445, 0.82, 1.0, 1.0, 0.2755721421895369, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17366394765824156, 0.1736639476582414, 0.24509920311904942], 
reward next is 0.7549, 
noisyNet noise sample is [array([0.3129523], dtype=float32), 0.97704405]. 
=============================================
[2019-03-23 22:02:20,828] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.6929896e-19 1.0000000e+00 9.8104959e-34 5.1756418e-29 5.3057072e-34], sum to 1.0000
[2019-03-23 22:02:20,839] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5674
[2019-03-23 22:02:20,846] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.5, 61.0, 1.0, 2.0, 0.5478254801975831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 640243.2767373045, 640243.2767373045, 150080.1297564231], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6115200.0000, 
sim time next is 6115800.0000, 
raw observation next is [28.35, 61.5, 1.0, 2.0, 0.5469287657850063, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 639820.8303352107, 639820.8303352103, 149959.658546186], 
processed observation next is [1.0, 0.782608695652174, 0.6055555555555556, 0.615, 1.0, 1.0, 0.4606294830773884, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2285074394054324, 0.22850743940543225, 0.28838395874266537], 
reward next is 0.7116, 
noisyNet noise sample is [array([-1.5241497], dtype=float32), 0.8560369]. 
=============================================
[2019-03-23 22:02:29,317] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.8168327e-24 1.0000000e+00 0.0000000e+00 1.0133296e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 22:02:29,325] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9015
[2019-03-23 22:02:29,333] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.45, 63.83333333333334, 1.0, 2.0, 0.6407718127519771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 730266.4435185647, 730266.4435185643, 165233.1489525024], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6271800.0000, 
sim time next is 6272400.0000, 
raw observation next is [29.5, 63.66666666666667, 1.0, 2.0, 0.6398139755217362, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 729174.3089090876, 729174.3089090876, 165061.8365288147], 
processed observation next is [0.0, 0.6086956521739131, 0.6481481481481481, 0.6366666666666667, 1.0, 1.0, 0.5712071137163527, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26041939603895986, 0.26041939603895986, 0.31742660870925904], 
reward next is 0.6826, 
noisyNet noise sample is [array([0.09870358], dtype=float32), -0.31413296]. 
=============================================
[2019-03-23 22:02:31,396] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.6724153e-22 1.0000000e+00 1.1471184e-37 5.1954864e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 22:02:31,401] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2058
[2019-03-23 22:02:31,407] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 87.0, 1.0, 2.0, 0.5695292020676505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 664742.6879426173, 664742.6879426173, 153652.3557334143], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6328800.0000, 
sim time next is 6329400.0000, 
raw observation next is [24.46666666666667, 87.0, 1.0, 2.0, 0.5729653181092249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 667934.2820802875, 667934.282080287, 154195.1838862641], 
processed observation next is [0.0, 0.2608695652173913, 0.46172839506172847, 0.87, 1.0, 1.0, 0.4916253787014582, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23854795788581695, 0.23854795788581679, 0.2965291997812771], 
reward next is 0.7035, 
noisyNet noise sample is [array([1.2704773], dtype=float32), -0.27045333]. 
=============================================
[2019-03-23 22:02:37,587] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.6623211e-21 1.0000000e+00 2.4584680e-33 1.9497214e-30 7.8231531e-36], sum to 1.0000
[2019-03-23 22:02:37,594] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2808
[2019-03-23 22:02:37,600] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2106453.089665837 W.
[2019-03-23 22:02:37,610] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.6, 77.5, 1.0, 2.0, 0.9233689339109229, 1.0, 2.0, 0.9233689339109229, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2106453.089665837, 2106453.089665837, 397370.1479161018], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6431400.0000, 
sim time next is 6432000.0000, 
raw observation next is [28.83333333333333, 76.66666666666667, 1.0, 2.0, 0.6097202639188175, 1.0, 2.0, 0.6097202639188175, 1.0, 1.0, 0.9706945173614498, 6.911199999999999, 6.9112, 121.94756008, 2086380.215828646, 2086380.215828647, 400697.1272513801], 
processed observation next is [1.0, 0.43478260869565216, 0.6234567901234566, 0.7666666666666667, 1.0, 1.0, 0.5353812665700208, 1.0, 1.0, 0.5353812665700208, 1.0, 0.5, 0.9633681467018124, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7451357913673735, 0.7451357913673738, 0.7705713985603464], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.22343004], dtype=float32), 0.7975601]. 
=============================================
[2019-03-23 22:02:37,641] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[53.557137]
 [53.557137]
 [53.557137]
 [53.557137]
 [53.557137]], R is [[53.02157211]
 [52.7271843 ]
 [52.44370651]
 [52.16262054]
 [51.83433533]].
[2019-03-23 22:02:38,855] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.0823215e-15 1.0000000e+00 4.7008912e-23 9.0481876e-22 1.0115130e-24], sum to 1.0000
[2019-03-23 22:02:38,864] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6386
[2019-03-23 22:02:38,869] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2249754.296952275 W.
[2019-03-23 22:02:38,873] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.25, 54.0, 1.0, 2.0, 0.986106332155345, 1.0, 2.0, 0.986106332155345, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2249754.296952275, 2249754.296952275, 426657.5577788834], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6445800.0000, 
sim time next is 6446400.0000, 
raw observation next is [32.2, 54.0, 1.0, 2.0, 0.6268234836277883, 1.0, 2.0, 0.6267764037903288, 1.0, 1.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2144814.10174355, 2144814.10174355, 410155.1336303377], 
processed observation next is [1.0, 0.6086956521739131, 0.7481481481481482, 0.54, 1.0, 1.0, 0.5557422424140337, 1.0, 1.0, 0.5556861949884867, 1.0, 0.5, 0.9972168686025908, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7660050363369821, 0.7660050363369821, 0.7887598723660341], 
reward next is 0.2112, 
noisyNet noise sample is [array([-0.06780096], dtype=float32), -0.37946942]. 
=============================================
[2019-03-23 22:02:46,553] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.2445352e-23 1.0000000e+00 0.0000000e+00 2.1377849e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 22:02:46,560] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4941
[2019-03-23 22:02:46,566] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.96666666666667, 43.66666666666667, 1.0, 2.0, 0.5777301983110922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 731495.7052364501, 731495.7052364501, 156734.0499765849], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6601200.0000, 
sim time next is 6601800.0000, 
raw observation next is [26.13333333333333, 42.83333333333333, 1.0, 2.0, 0.5558606954304491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 704049.6869426618, 704049.6869426613, 152995.0829216214], 
processed observation next is [1.0, 0.391304347826087, 0.5234567901234567, 0.4283333333333333, 1.0, 1.0, 0.47126273265529656, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2514463167652363, 0.25144631676523616, 0.29422131331081036], 
reward next is 0.7058, 
noisyNet noise sample is [array([-1.170709], dtype=float32), 1.4510603]. 
=============================================
[2019-03-23 22:02:46,698] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 22:02:46,699] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:02:46,700] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:02:46,700] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:02:46,701] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:02:46,701] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:02:46,702] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:02:46,705] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:02:46,701] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:02:46,705] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:02:46,706] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:02:46,722] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run25
[2019-03-23 22:02:46,744] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run25
[2019-03-23 22:02:46,745] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run25
[2019-03-23 22:02:46,745] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run25
[2019-03-23 22:02:46,790] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run25
[2019-03-23 22:02:59,262] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0568268]
[2019-03-23 22:02:59,263] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.27635076333333, 54.84316949666668, 1.0, 2.0, 0.3067881411810411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 390747.6219916703, 390747.6219916703, 116415.7909126153]
[2019-03-23 22:02:59,265] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:02:59,268] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.1079640e-22 1.0000000e+00 1.6497408e-37 4.7223586e-35 0.0000000e+00], sampled 0.007489710615646072
[2019-03-23 22:03:00,639] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0568268]
[2019-03-23 22:03:00,639] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [17.885317415, 84.21615744, 1.0, 2.0, 0.3715674651345366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 477270.8297055208, 477270.8297055208, 124873.5239408512]
[2019-03-23 22:03:00,640] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:03:00,643] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.1079640e-22 1.0000000e+00 1.6497408e-37 4.7223586e-35 0.0000000e+00], sampled 0.3969013835662434
[2019-03-23 22:03:27,993] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0568268]
[2019-03-23 22:03:27,994] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [32.5, 51.0, 1.0, 2.0, 0.9853620016132982, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.054473877357029, 6.9112, 121.9253437923988, 1196694.698010061, 1123326.087646513, 237209.5696655267]
[2019-03-23 22:03:27,995] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:03:27,997] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.1079640e-22 1.0000000e+00 1.6497408e-37 4.7223586e-35 0.0000000e+00], sampled 0.6833755841076969
[2019-03-23 22:03:59,825] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0568268]
[2019-03-23 22:03:59,826] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.774964665, 50.04233223666667, 1.0, 2.0, 0.6852216032390884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 825634.5229536315, 825634.5229536315, 175326.5193586881]
[2019-03-23 22:03:59,826] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:03:59,828] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.1079640e-22 1.0000000e+00 1.6497408e-37 4.7223586e-35 0.0000000e+00], sampled 0.3002237667472303
[2019-03-23 22:04:04,481] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0568268]
[2019-03-23 22:04:04,481] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.33333333333334, 88.16666666666666, 1.0, 2.0, 0.4986153920769438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 592565.1140994377, 592565.1140994377, 142597.7382458877]
[2019-03-23 22:04:04,483] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:04:04,486] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.1079640e-22 1.0000000e+00 1.6497408e-37 4.7223586e-35 0.0000000e+00], sampled 0.23313422056983213
[2019-03-23 22:04:04,789] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0568268]
[2019-03-23 22:04:04,789] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.07091348166666, 81.47682388333334, 1.0, 2.0, 0.5559255360498397, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 651163.9781759311, 651163.9781759311, 151480.6032055124]
[2019-03-23 22:04:04,791] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:04:04,792] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.1079640e-22 1.0000000e+00 1.6497408e-37 4.7223586e-35 0.0000000e+00], sampled 0.8185046771272355
[2019-03-23 22:04:27,054] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:04:27,266] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:04:27,342] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:04:27,409] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:04:27,480] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:04:28,496] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 600000, evaluation results [600000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:04:30,469] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.3018514e-22 1.0000000e+00 7.4207195e-38 1.9310792e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 22:04:30,477] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0743
[2019-03-23 22:04:30,481] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666666, 55.66666666666666, 1.0, 2.0, 0.3692351691578769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 462462.6327696199, 462462.6327696195, 124466.9355788565], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6640800.0000, 
sim time next is 6641400.0000, 
raw observation next is [24.68333333333333, 54.33333333333334, 1.0, 2.0, 0.3608073747049155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 453044.7675075154, 453044.7675075154, 123348.155428724], 
processed observation next is [1.0, 0.8695652173913043, 0.46975308641975294, 0.5433333333333334, 1.0, 1.0, 0.2390563984582327, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1618017026812555, 0.1618017026812555, 0.23720799120908462], 
reward next is 0.7628, 
noisyNet noise sample is [array([-0.31288332], dtype=float32), -0.21385111]. 
=============================================
[2019-03-23 22:04:32,545] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.744958e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:04:32,551] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6047
[2019-03-23 22:04:32,557] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.55, 29.33333333333333, 1.0, 2.0, 0.766699426263229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 971647.9364054189, 971647.9364054189, 192624.5773715616], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6702600.0000, 
sim time next is 6703200.0000, 
raw observation next is [29.7, 29.0, 1.0, 2.0, 0.7919562372413145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1003273.013985965, 1003273.013985965, 197899.0558266641], 
processed observation next is [1.0, 0.6086956521739131, 0.6555555555555556, 0.29, 1.0, 1.0, 0.7523288538587077, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3583117907092732, 0.3583117907092732, 0.3805751073589694], 
reward next is 0.6194, 
noisyNet noise sample is [array([-1.4324138], dtype=float32), 0.9766659]. 
=============================================
[2019-03-23 22:04:42,718] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.18791236e-26 1.00000000e+00 0.00000000e+00 0.00000000e+00
 0.00000000e+00], sum to 1.0000
[2019-03-23 22:04:42,727] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7060
[2019-03-23 22:04:42,733] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333334, 72.66666666666667, 1.0, 2.0, 0.4328652833197408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 528771.9409662813, 528771.9409662813, 133152.0510228084], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6855600.0000, 
sim time next is 6856200.0000, 
raw observation next is [24.1, 71.0, 1.0, 2.0, 0.4336203346968592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 529603.4715964013, 529603.4715964013, 133259.9465971191], 
processed observation next is [0.0, 0.34782608695652173, 0.4481481481481482, 0.71, 1.0, 1.0, 0.3257384936867372, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18914409699871476, 0.18914409699871476, 0.25626912807138286], 
reward next is 0.7437, 
noisyNet noise sample is [array([-0.1566101], dtype=float32), 0.59114677]. 
=============================================
[2019-03-23 22:04:45,461] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.4805335e-23 1.0000000e+00 1.0755610e-36 4.8076273e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 22:04:45,465] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9441
[2019-03-23 22:04:45,469] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 66.0, 1.0, 2.0, 0.4175792126310621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 514885.5701840253, 514885.5701840253, 131063.9805849733], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6906000.0000, 
sim time next is 6906600.0000, 
raw observation next is [24.05, 66.5, 1.0, 2.0, 0.4142427823374003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 511235.6260102162, 511235.6260102158, 130596.3367226934], 
processed observation next is [0.0, 0.9565217391304348, 0.4462962962962963, 0.665, 1.0, 1.0, 0.30266997897309555, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18258415214650578, 0.18258415214650564, 0.251146801389795], 
reward next is 0.7489, 
noisyNet noise sample is [array([-0.17517582], dtype=float32), 0.12195847]. 
=============================================
[2019-03-23 22:04:47,270] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.560692e-24 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:04:47,279] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7055
[2019-03-23 22:04:47,285] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 51.5, 1.0, 2.0, 0.5765040498830505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 668204.6193994812, 668204.6193994812, 154620.1215589724], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6965400.0000, 
sim time next is 6966000.0000, 
raw observation next is [31.0, 52.0, 1.0, 2.0, 0.5822471924000937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 673463.8641686036, 673463.864168604, 155528.9911550448], 
processed observation next is [0.0, 0.6521739130434783, 0.7037037037037037, 0.52, 1.0, 1.0, 0.5026752290477305, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24052280863164413, 0.2405228086316443, 0.2990942137597015], 
reward next is 0.7009, 
noisyNet noise sample is [array([-0.49255696], dtype=float32), -0.31938332]. 
=============================================
[2019-03-23 22:04:47,305] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[78.458374]
 [78.458374]
 [78.458374]
 [78.458374]
 [78.458374]], R is [[78.37469482]
 [78.29360199]
 [78.2149353 ]
 [78.13865662]
 [78.06403351]].
[2019-03-23 22:04:49,277] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.2386822e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:04:49,288] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8428
[2019-03-23 22:04:49,295] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.06666666666667, 47.33333333333334, 1.0, 2.0, 0.5462200641816373, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 642261.8790597726, 642261.8790597726, 149981.0541713128], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6970800.0000, 
sim time next is 6971400.0000, 
raw observation next is [31.1, 46.5, 1.0, 2.0, 0.5378125220888157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 634130.5586927871, 634130.5586927871, 148676.252651802], 
processed observation next is [0.0, 0.6956521739130435, 0.7074074074074075, 0.465, 1.0, 1.0, 0.44977681201049485, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22647519953313824, 0.22647519953313824, 0.2859158704842346], 
reward next is 0.7141, 
noisyNet noise sample is [array([0.04739364], dtype=float32), 0.9647798]. 
=============================================
[2019-03-23 22:04:55,863] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.2293703e-25 1.0000000e+00 0.0000000e+00 6.1194847e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 22:04:55,871] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0127
[2019-03-23 22:04:55,876] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.76666666666667, 78.66666666666667, 1.0, 2.0, 0.6555154906893286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 813799.1866184906, 813799.1866184906, 170456.1721635787], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7119600.0000, 
sim time next is 7120200.0000, 
raw observation next is [21.88333333333334, 78.33333333333333, 1.0, 2.0, 0.667170776235628, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 827468.4622224324, 827468.4622224324, 172621.85722846], 
processed observation next is [1.0, 0.391304347826087, 0.36604938271604964, 0.7833333333333333, 1.0, 1.0, 0.6037747336138429, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29552445079372586, 0.29552445079372586, 0.3319651100547308], 
reward next is 0.6680, 
noisyNet noise sample is [array([-0.8349777], dtype=float32), 1.1120933]. 
=============================================
[2019-03-23 22:05:03,933] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.8340446e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:05:03,945] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4406
[2019-03-23 22:05:03,954] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.06666666666667, 73.33333333333333, 1.0, 2.0, 0.4080885823153282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 503209.6180078526, 503209.6180078526, 129707.2970268482], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7238400.0000, 
sim time next is 7239000.0000, 
raw observation next is [22.98333333333333, 73.66666666666667, 1.0, 2.0, 0.4081346591852679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 503502.5664998583, 503502.5664998583, 129719.647880465], 
processed observation next is [1.0, 0.782608695652174, 0.40679012345679005, 0.7366666666666667, 1.0, 1.0, 0.2953984037919856, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1798223451785208, 0.1798223451785208, 0.24946086130858652], 
reward next is 0.7505, 
noisyNet noise sample is [array([1.1059521], dtype=float32), 1.5746785]. 
=============================================
[2019-03-23 22:05:03,965] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[79.2574]
 [79.2574]
 [79.2574]
 [79.2574]
 [79.2574]], R is [[79.21536255]
 [79.17377472]
 [79.1312561 ]
 [79.08792877]
 [79.04483032]].
[2019-03-23 22:05:19,243] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 22:05:19,244] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:05:19,244] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:05:19,245] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:05:19,246] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:05:19,248] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:05:19,252] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:05:19,254] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:05:19,253] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:05:19,254] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:05:19,255] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:05:19,274] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run26
[2019-03-23 22:05:19,274] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run26
[2019-03-23 22:05:19,318] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run26
[2019-03-23 22:05:19,319] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run26
[2019-03-23 22:05:19,384] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run26
[2019-03-23 22:05:25,828] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.11216533]
[2019-03-23 22:05:25,830] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [18.74113502833333, 53.12756084666667, 1.0, 2.0, 0.2167885766096285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 279630.80247059, 279630.8024705895, 82376.19826479795]
[2019-03-23 22:05:25,831] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:05:25,834] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.7290825e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.05986865749313386
[2019-03-23 22:05:37,146] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.11216533]
[2019-03-23 22:05:37,148] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.938287, 32.08465773333334, 1.0, 2.0, 0.3673133211428313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 459660.4143651213, 459660.4143651213, 124198.9105254375]
[2019-03-23 22:05:37,148] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:05:37,152] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.7290825e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.39554185370986084
[2019-03-23 22:05:39,685] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.11216533]
[2019-03-23 22:05:39,687] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.56666666666667, 69.0, 1.0, 2.0, 0.5139030220762204, 0.0, 2.0, 0.0, 1.0, 1.0, 0.839157756896127, 6.9112, 6.9112, 121.9258222925119, 1253912.769385173, 1253912.769385173, 259070.5038691175]
[2019-03-23 22:05:39,688] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:05:39,694] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.7290825e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.3856277728926274
[2019-03-23 22:06:40,453] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.11216533]
[2019-03-23 22:06:40,453] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.5, 86.33333333333334, 1.0, 2.0, 0.5933115118210366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 692476.6031804737, 692476.6031804737, 157699.5575361524]
[2019-03-23 22:06:40,454] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:06:40,456] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.7290825e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.03441765303701194
[2019-03-23 22:06:49,816] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.11216533]
[2019-03-23 22:06:49,818] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.2, 98.33333333333334, 1.0, 2.0, 0.8089483656947838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 922046.9861944303, 922046.9861944303, 197795.4094771515]
[2019-03-23 22:06:49,819] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:06:49,821] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.7290825e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.4589210406012342
[2019-03-23 22:06:59,512] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:06:59,550] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.11216533]
[2019-03-23 22:06:59,551] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.91451333, 58.59833082, 1.0, 2.0, 0.4181820526722055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 513985.4651777987, 513985.4651777987, 131109.7387048729]
[2019-03-23 22:06:59,552] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:06:59,555] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.7290825e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.06728790397234308
[2019-03-23 22:06:59,643] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:06:59,978] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:07:00,088] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:07:00,098] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:07:01,114] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 625000, evaluation results [625000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:07:05,165] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.7165332e-23 1.0000000e+00 0.0000000e+00 1.7350258e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 22:07:05,171] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9261
[2019-03-23 22:07:05,175] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.6, 87.5, 1.0, 2.0, 0.4172978945137409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 518377.9952963831, 518377.9952963831, 131111.7724139736], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7614600.0000, 
sim time next is 7615200.0000, 
raw observation next is [20.5, 88.0, 1.0, 2.0, 0.3943579915265815, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 490128.5602775866, 490128.5602775862, 127859.7785659683], 
processed observation next is [1.0, 0.13043478260869565, 0.3148148148148148, 0.88, 1.0, 1.0, 0.2789976089602161, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17504591438485237, 0.17504591438485223, 0.24588418954993904], 
reward next is 0.7541, 
noisyNet noise sample is [array([-0.7517867], dtype=float32), -0.07604611]. 
=============================================
[2019-03-23 22:07:07,753] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.8480079e-20 1.0000000e+00 7.4211874e-34 4.8791912e-31 1.2019365e-36], sum to 1.0000
[2019-03-23 22:07:07,762] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5384
[2019-03-23 22:07:07,765] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 67.0, 1.0, 2.0, 0.4012230378296466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260425649407, 495360.4175046472, 495360.4175046472, 128750.2087395505], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7665600.0000, 
sim time next is 7666200.0000, 
raw observation next is [23.65, 67.5, 1.0, 2.0, 0.3895484429167627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156464, 482167.27217786, 482167.27217786, 127144.9853288461], 
processed observation next is [1.0, 0.7391304347826086, 0.4314814814814814, 0.675, 1.0, 1.0, 0.27327195585328895, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288200337, 0.1722025972063786, 0.1722025972063786, 0.24450958717085788], 
reward next is 0.7555, 
noisyNet noise sample is [array([0.8208063], dtype=float32), -0.22694084]. 
=============================================
[2019-03-23 22:07:19,872] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2453455e-24 1.0000000e+00 0.0000000e+00 5.1764329e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 22:07:19,876] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4808
[2019-03-23 22:07:19,881] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.58333333333334, 72.0, 1.0, 2.0, 0.465282882799843, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 579163.7641333768, 579163.7641333763, 138252.3460264825], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7891800.0000, 
sim time next is 7892400.0000, 
raw observation next is [22.86666666666667, 71.0, 1.0, 2.0, 0.7319772434347748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 909209.7447827826, 909209.7447827822, 185237.3302396696], 
processed observation next is [1.0, 0.34782608695652173, 0.4024691358024693, 0.71, 1.0, 1.0, 0.6809252898033032, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.32471776599385094, 0.32471776599385077, 0.3562256350762877], 
reward next is 0.6438, 
noisyNet noise sample is [array([-0.4863975], dtype=float32), 1.2777901]. 
=============================================
[2019-03-23 22:07:19,952] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8631051e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:07:19,960] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9382
[2019-03-23 22:07:19,963] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.6, 86.0, 1.0, 2.0, 0.4009683936533078, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 499200.724612508, 499200.724612508, 128806.3900835369], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7876800.0000, 
sim time next is 7877400.0000, 
raw observation next is [20.46666666666667, 86.5, 1.0, 2.0, 0.4335263569412632, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 540251.0489424433, 540251.0489424429, 133507.5148013026], 
processed observation next is [1.0, 0.17391304347826086, 0.31358024691358033, 0.865, 1.0, 1.0, 0.32562661540626564, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19294680319372975, 0.1929468031937296, 0.2567452207717358], 
reward next is 0.7433, 
noisyNet noise sample is [array([0.7849121], dtype=float32), 1.1716956]. 
=============================================
[2019-03-23 22:07:22,981] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:07:22,981] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:07:23,002] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run4
[2019-03-23 22:07:23,098] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:07:23,098] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:07:23,105] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:07:23,106] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:07:23,115] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run4
[2019-03-23 22:07:23,153] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:07:23,154] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:07:23,158] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run4
[2019-03-23 22:07:23,187] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run4
[2019-03-23 22:07:23,397] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:07:23,398] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:07:23,401] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run4
[2019-03-23 22:07:23,464] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:07:23,464] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:07:23,468] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run4
[2019-03-23 22:07:23,781] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:07:23,781] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:07:23,782] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run4
[2019-03-23 22:07:23,859] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:07:23,859] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:07:23,860] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run4
[2019-03-23 22:07:23,931] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:07:23,931] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:07:23,932] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run4
[2019-03-23 22:07:24,037] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:07:24,037] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:07:24,038] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run4
[2019-03-23 22:07:24,096] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:07:24,096] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:07:24,098] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run4
[2019-03-23 22:07:24,292] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:07:24,292] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:07:24,293] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run4
[2019-03-23 22:07:24,326] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:07:24,327] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:07:24,329] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:07:24,329] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:07:24,330] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run4
[2019-03-23 22:07:24,333] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run4
[2019-03-23 22:07:24,601] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:07:24,601] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:07:24,602] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run4
[2019-03-23 22:07:24,681] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:07:24,681] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:07:24,682] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run4
[2019-03-23 22:07:41,983] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.0723652e-23 1.0000000e+00 0.0000000e+00 8.0589689e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 22:07:41,994] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6377
[2019-03-23 22:07:42,001] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.9, 30.5, 1.0, 2.0, 0.3176557778469826, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 409689.1743081359, 409689.1743081359, 117770.8497025641], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 304200.0000, 
sim time next is 304800.0000, 
raw observation next is [27.0, 30.66666666666666, 1.0, 2.0, 0.3184419884592032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 410411.1732270969, 410411.1732270969, 117873.4281333943], 
processed observation next is [0.0, 0.5217391304347826, 0.5555555555555556, 0.3066666666666666, 1.0, 1.0, 0.18862141483238476, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14657541900967747, 0.14657541900967747, 0.22667966948729673], 
reward next is 0.7733, 
noisyNet noise sample is [array([-0.88756704], dtype=float32), -0.7434937]. 
=============================================
[2019-03-23 22:07:45,183] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7051221e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:07:45,188] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2320
[2019-03-23 22:07:45,195] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.8, 33.5, 1.0, 2.0, 0.870702272697101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.014367677136711, 6.9112, 121.9254632867497, 1168715.346787564, 1115884.526096896, 215158.7570369703], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 379800.0000, 
sim time next is 380400.0000, 
raw observation next is [27.0, 33.0, 1.0, 2.0, 0.8785276766560056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.065579698004341, 6.9112, 121.9252469810476, 1204442.6346488, 1125386.946855037, 216928.3481791435], 
processed observation next is [1.0, 0.391304347826087, 0.5555555555555556, 0.33, 1.0, 1.0, 0.8553900912571495, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.015437969800434104, 0.0, 0.8094568466336993, 0.4301580838031428, 0.40192390959108465, 0.41716990034450674], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2743373], dtype=float32), -1.4382359]. 
=============================================
[2019-03-23 22:07:49,932] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.0056492e-24 1.0000000e+00 9.0171718e-38 1.5498267e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 22:07:49,938] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3946
[2019-03-23 22:07:49,946] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1373293.683159265 W.
[2019-03-23 22:07:49,950] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.05, 40.5, 1.0, 2.0, 0.936479655595171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.307614768804655, 6.9112, 121.9241946761607, 1373293.683159265, 1170296.967093441, 230015.262266746], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 469800.0000, 
sim time next is 470400.0000, 
raw observation next is [28.36666666666667, 39.66666666666667, 1.0, 2.0, 0.4886724717431688, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8069853109323929, 6.9112, 6.9112, 121.925803857235, 1206446.872335939, 1206446.872335939, 249377.3060860975], 
processed observation next is [1.0, 0.43478260869565216, 0.606172839506173, 0.3966666666666667, 1.0, 1.0, 0.391276752075201, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.758731638665491, 0.0, 0.0, 0.8094605437124732, 0.43087388297712104, 0.43087388297712104, 0.4795717424732644], 
reward next is 0.5204, 
noisyNet noise sample is [array([0.23973957], dtype=float32), 2.0066473]. 
=============================================
[2019-03-23 22:07:50,872] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.4980225e-18 1.0000000e+00 1.8668823e-33 1.5754669e-30 3.4283786e-35], sum to 1.0000
[2019-03-23 22:07:50,876] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8664
[2019-03-23 22:07:50,881] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.05, 31.0, 1.0, 2.0, 0.3539523856819124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 445513.3244456212, 445513.3244456212, 122448.1894670043], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 499800.0000, 
sim time next is 500400.0000, 
raw observation next is [29.8, 32.0, 1.0, 2.0, 0.3520439919384769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 442907.6813709488, 442907.6813709484, 122191.7861614575], 
processed observation next is [1.0, 0.8260869565217391, 0.6592592592592593, 0.32, 1.0, 1.0, 0.22862379992675821, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15818131477533887, 0.1581813147753387, 0.23498420415664903], 
reward next is 0.7650, 
noisyNet noise sample is [array([-1.0094341], dtype=float32), -0.7858157]. 
=============================================
[2019-03-23 22:07:51,277] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.1737671e-20 1.0000000e+00 9.6818693e-32 1.2516617e-30 2.7019626e-34], sum to 1.0000
[2019-03-23 22:07:51,281] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5790
[2019-03-23 22:07:51,286] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 24.0, 1.0, 2.0, 0.3647991124892566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 460557.7546229659, 460557.7546229659, 123919.3822614261], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 495000.0000, 
sim time next is 495600.0000, 
raw observation next is [31.76666666666667, 24.66666666666666, 1.0, 2.0, 0.3657552773080953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 461764.0699462777, 461764.0699462777, 124048.5705093207], 
processed observation next is [1.0, 0.7391304347826086, 0.7320987654320988, 0.24666666666666662, 1.0, 1.0, 0.24494675870011348, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16491573926652775, 0.16491573926652775, 0.2385549432871552], 
reward next is 0.7614, 
noisyNet noise sample is [array([1.442253], dtype=float32), 0.9845001]. 
=============================================
[2019-03-23 22:07:53,279] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 22:07:53,282] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:07:53,282] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:07:53,283] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:07:53,284] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:07:53,285] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:07:53,286] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:07:53,288] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:07:53,288] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:07:53,292] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:07:53,292] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:07:53,309] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run27
[2019-03-23 22:07:53,309] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run27
[2019-03-23 22:07:53,330] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run27
[2019-03-23 22:07:53,330] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run27
[2019-03-23 22:07:53,407] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run27
[2019-03-23 22:08:05,027] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.13963617]
[2019-03-23 22:08:05,028] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.9, 38.0, 1.0, 2.0, 0.264890271175504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 341689.9379613085, 341689.9379613085, 94815.7980799672]
[2019-03-23 22:08:05,029] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:08:05,031] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.8200973e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.20280871498709907
[2019-03-23 22:08:25,721] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.13963617]
[2019-03-23 22:08:25,722] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.5, 89.0, 1.0, 2.0, 0.6709528128667543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 777658.9079873323, 777658.9079873323, 171352.7756806935]
[2019-03-23 22:08:25,723] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:08:25,725] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.8200973e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.2684133988228148
[2019-03-23 22:08:43,391] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.13963617]
[2019-03-23 22:08:43,393] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.64863307, 70.39672468333333, 1.0, 2.0, 0.6120374596936664, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 700920.9715047798, 700920.9715047798, 160328.6452481374]
[2019-03-23 22:08:43,396] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:08:43,399] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.8200973e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.2759277899588546
[2019-03-23 22:09:09,206] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.13963617]
[2019-03-23 22:09:09,206] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.08654944166667, 47.19133437333333, 1.0, 2.0, 0.7502222902740623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 910115.2916369041, 910115.2916369037, 188285.6055610829]
[2019-03-23 22:09:09,207] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:09:09,210] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.8200973e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.7578502132929371
[2019-03-23 22:09:34,066] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:09:34,396] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.13963617]
[2019-03-23 22:09:34,397] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.85, 78.66666666666667, 1.0, 2.0, 0.3954170513646504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 490486.9171734521, 490486.9171734521, 127987.553174618]
[2019-03-23 22:09:34,399] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:09:34,401] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.8200973e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.8566401116138159
[2019-03-23 22:09:34,476] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:09:34,526] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:09:34,556] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:09:34,568] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:09:35,583] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 650000, evaluation results [650000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:09:40,263] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.6385124e-23 1.0000000e+00 0.0000000e+00 7.7033358e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 22:09:40,275] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5776
[2019-03-23 22:09:40,283] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.21666666666667, 66.0, 1.0, 2.0, 0.3245403616617109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 413914.1876815257, 413914.1876815252, 118660.7338989127], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 619800.0000, 
sim time next is 620400.0000, 
raw observation next is [21.03333333333333, 67.0, 1.0, 2.0, 0.3126174214169111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 398861.2292857512, 398861.2292857517, 117148.51212979], 
processed observation next is [1.0, 0.17391304347826086, 0.3345679012345678, 0.67, 1.0, 1.0, 0.1816874064487037, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14245043903062543, 0.1424504390306256, 0.22528560024959615], 
reward next is 0.7747, 
noisyNet noise sample is [array([0.03896254], dtype=float32), -1.1610518]. 
=============================================
[2019-03-23 22:09:43,718] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.0318780e-19 1.0000000e+00 1.1194892e-31 9.4915726e-30 7.0210713e-33], sum to 1.0000
[2019-03-23 22:09:43,725] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6007
[2019-03-23 22:09:43,729] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.11666666666667, 31.66666666666667, 1.0, 2.0, 0.3472202209935241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 439815.1522518914, 439815.1522518914, 121588.7619775265], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 684600.0000, 
sim time next is 685200.0000, 
raw observation next is [28.93333333333333, 32.33333333333334, 1.0, 2.0, 0.3448009377372244, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 436713.2941379446, 436713.2941379446, 121269.7656937525], 
processed observation next is [1.0, 0.9565217391304348, 0.6271604938271603, 0.3233333333333334, 1.0, 1.0, 0.2200011163538386, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1559690336206945, 0.1559690336206945, 0.23321108787260098], 
reward next is 0.7668, 
noisyNet noise sample is [array([0.802092], dtype=float32), -0.10824843]. 
=============================================
[2019-03-23 22:09:47,516] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.1896246e-18 1.0000000e+00 3.7069743e-28 3.1117207e-26 6.0354869e-31], sum to 1.0000
[2019-03-23 22:09:47,527] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3783
[2019-03-23 22:09:47,536] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1323828.47312716 W.
[2019-03-23 22:09:47,539] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.5, 48.33333333333334, 1.0, 2.0, 0.3687957583229002, 1.0, 1.0, 0.3687957583229002, 1.0, 2.0, 0.5944564285874738, 6.9112, 6.9112, 121.94756008, 1323828.47312716, 1323828.47312716, 283283.2740509476], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 732000.0000, 
sim time next is 732600.0000, 
raw observation next is [27.8, 46.5, 1.0, 2.0, 0.5454576545155624, 1.0, 2.0, 0.5454576545155624, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1315950.047918842, 1315950.047918842, 252854.7610538609], 
processed observation next is [1.0, 0.4782608695652174, 0.5851851851851853, 0.465, 1.0, 1.0, 0.45887816013757426, 1.0, 1.0, 0.45887816013757426, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.469982159971015, 0.469982159971015, 0.4862591558728094], 
reward next is 0.5137, 
noisyNet noise sample is [array([0.931882], dtype=float32), -0.81474304]. 
=============================================
[2019-03-23 22:09:48,359] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.7656474e-19 1.0000000e+00 2.2955812e-30 3.7869724e-28 1.5973844e-32], sum to 1.0000
[2019-03-23 22:09:48,366] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8872
[2019-03-23 22:09:48,374] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1375519.608629175 W.
[2019-03-23 22:09:48,378] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.7, 41.0, 1.0, 2.0, 0.5634978224507625, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9204139663046759, 6.911199999999999, 6.9112, 121.9260426156618, 1375519.608629175, 1375519.608629176, 276967.7713350554], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 734400.0000, 
sim time next is 735000.0000, 
raw observation next is [28.98333333333333, 39.33333333333334, 1.0, 2.0, 0.6092790282815231, 1.0, 1.0, 0.6092790282815231, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1480710.813211405, 1480710.813211406, 275075.6602160138], 
processed observation next is [1.0, 0.5217391304347826, 0.6290123456790122, 0.3933333333333334, 1.0, 1.0, 0.5348559860494323, 1.0, 0.5, 0.5348559860494323, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5288252904326446, 0.528825290432645, 0.528991654261565], 
reward next is 0.4710, 
noisyNet noise sample is [array([-0.44730073], dtype=float32), -0.37881044]. 
=============================================
[2019-03-23 22:09:48,398] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[49.38907]
 [49.38907]
 [49.38907]
 [49.38907]
 [49.38907]], R is [[49.36618423]
 [49.33989334]
 [49.31115341]
 [49.28445816]
 [48.79161453]].
[2019-03-23 22:09:50,148] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.7229547e-25 1.0000000e+00 0.0000000e+00 2.9279607e-38 0.0000000e+00], sum to 1.0000
[2019-03-23 22:09:50,155] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9215
[2019-03-23 22:09:50,160] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.93333333333333, 58.0, 1.0, 2.0, 0.3120308511521739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 396570.7243281645, 396570.7243281645, 117067.42074699], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 798600.0000, 
sim time next is 799200.0000, 
raw observation next is [23.0, 58.0, 1.0, 2.0, 0.3140743296346765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 398914.7459901513, 398914.7459901508, 117322.8927520336], 
processed observation next is [0.0, 0.2608695652173913, 0.4074074074074074, 0.58, 1.0, 1.0, 0.18342182099366253, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14246955213933976, 0.14246955213933957, 0.22562094760006463], 
reward next is 0.7744, 
noisyNet noise sample is [array([-1.0906982], dtype=float32), -0.4051662]. 
=============================================
[2019-03-23 22:09:50,220] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.7229547e-25 1.0000000e+00 0.0000000e+00 2.9279607e-38 0.0000000e+00], sum to 1.0000
[2019-03-23 22:09:50,227] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6852
[2019-03-23 22:09:50,233] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.13333333333333, 58.33333333333334, 1.0, 2.0, 0.3210496661510182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 407055.6977871213, 407055.6977871213, 118200.810843074], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 800400.0000, 
sim time next is 801000.0000, 
raw observation next is [23.2, 58.5, 1.0, 2.0, 0.3246328439728607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 411211.0444537684, 411211.0444537684, 118654.5233008022], 
processed observation next is [0.0, 0.2608695652173913, 0.4148148148148148, 0.585, 1.0, 1.0, 0.19599148092007224, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1468610873049173, 0.1468610873049173, 0.22818177557846578], 
reward next is 0.7718, 
noisyNet noise sample is [array([-1.0906982], dtype=float32), -0.4051662]. 
=============================================
[2019-03-23 22:09:50,248] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[76.00396]
 [76.00396]
 [76.00396]
 [76.00396]
 [76.00396]], R is [[76.01574707]
 [76.02828217]
 [76.04160309]
 [76.05556488]
 [76.06988525]].
[2019-03-23 22:09:52,996] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.6418735e-25 1.0000000e+00 0.0000000e+00 1.4390112e-38 0.0000000e+00], sum to 1.0000
[2019-03-23 22:09:53,006] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9816
[2019-03-23 22:09:53,011] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 52.0, 1.0, 2.0, 0.3975761901926947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 492968.5379115993, 492968.5379115993, 128286.2189179703], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 857400.0000, 
sim time next is 858000.0000, 
raw observation next is [26.16666666666667, 53.00000000000001, 1.0, 2.0, 0.3985863299672306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 494015.3705500816, 494015.3705500816, 128423.6358026004], 
processed observation next is [0.0, 0.9565217391304348, 0.5246913580246916, 0.53, 1.0, 1.0, 0.284031345199084, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17643406091074343, 0.17643406091074343, 0.24696853038961616], 
reward next is 0.7530, 
noisyNet noise sample is [array([2.291018], dtype=float32), -0.6126689]. 
=============================================
[2019-03-23 22:09:53,028] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[73.61634]
 [73.61634]
 [73.61634]
 [73.61634]
 [73.61634]], R is [[73.63319397]
 [73.65016174]
 [73.66720581]
 [73.68418884]
 [73.70098877]].
[2019-03-23 22:09:59,262] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.407504e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:09:59,268] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7552
[2019-03-23 22:09:59,272] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.41666666666666, 55.66666666666667, 1.0, 2.0, 0.2624660501956022, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 338561.8430529447, 338561.8430529447, 109491.6862541786], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 957000.0000, 
sim time next is 957600.0000, 
raw observation next is [21.3, 56.0, 1.0, 2.0, 0.2607860839245219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 336394.6542428664, 336394.6542428664, 108418.7880097483], 
processed observation next is [1.0, 0.08695652173913043, 0.3444444444444445, 0.56, 1.0, 1.0, 0.11998343324347846, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.12014094794388085, 0.12014094794388085, 0.20849766924951596], 
reward next is 0.7915, 
noisyNet noise sample is [array([0.19638565], dtype=float32), -0.6298682]. 
=============================================
[2019-03-23 22:10:04,056] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.346216e-27 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:10:04,064] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9309
[2019-03-23 22:10:04,068] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.4, 55.0, 1.0, 2.0, 0.2801200936320363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 359264.1537263692, 359264.1537263692, 113154.5201900645], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1037400.0000, 
sim time next is 1038000.0000, 
raw observation next is [22.3, 56.00000000000001, 1.0, 2.0, 0.2824649857660376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 362053.7714594791, 362053.7714594787, 113436.9872218997], 
processed observation next is [1.0, 0.0, 0.38148148148148153, 0.56, 1.0, 1.0, 0.14579164972147338, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1293049183783854, 0.12930491837838526, 0.21814805234980714], 
reward next is 0.7819, 
noisyNet noise sample is [array([0.87938905], dtype=float32), -0.19082329]. 
=============================================
[2019-03-23 22:10:04,084] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[81.54933]
 [81.54933]
 [81.54933]
 [81.54933]
 [81.54933]], R is [[81.51569366]
 [81.48293304]
 [81.45114136]
 [81.42046356]
 [81.39014435]].
[2019-03-23 22:10:06,840] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6055612e-21 1.0000000e+00 2.9595379e-38 1.4458246e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 22:10:06,848] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5939
[2019-03-23 22:10:06,851] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.73333333333333, 41.66666666666666, 1.0, 2.0, 0.8325582518276593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1050721.776336977, 1050721.776336977, 206572.7539178446], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1090200.0000, 
sim time next is 1090800.0000, 
raw observation next is [26.7, 42.0, 1.0, 2.0, 0.8590978293620841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1083739.319574894, 1083739.319574894, 212424.8035439431], 
processed observation next is [1.0, 0.6521739130434783, 0.5444444444444444, 0.42, 1.0, 1.0, 0.8322593206691478, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.38704975699103356, 0.38704975699103356, 0.40850923758450597], 
reward next is 0.5915, 
noisyNet noise sample is [array([-0.05221933], dtype=float32), 1.7954271]. 
=============================================
[2019-03-23 22:10:13,525] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.7435729e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:10:13,538] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2381
[2019-03-23 22:10:13,546] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.4, 94.0, 1.0, 2.0, 0.3350839064631392, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 423803.88257905, 423803.88257905, 119994.4335267545], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1212000.0000, 
sim time next is 1212600.0000, 
raw observation next is [18.35, 94.0, 1.0, 2.0, 0.3291826472769792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 416582.8078771461, 416582.8078771461, 119234.3682487801], 
processed observation next is [1.0, 0.0, 0.23518518518518525, 0.94, 1.0, 1.0, 0.20140791342497524, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1487795742418379, 0.1487795742418379, 0.22929686201688482], 
reward next is 0.7707, 
noisyNet noise sample is [array([0.99613994], dtype=float32), -0.6951539]. 
=============================================
[2019-03-23 22:10:20,240] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4836240e-18 1.0000000e+00 3.8200678e-28 1.6871277e-26 1.5055478e-30], sum to 1.0000
[2019-03-23 22:10:20,248] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9776
[2019-03-23 22:10:20,254] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1387210.144166223 W.
[2019-03-23 22:10:20,259] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.96666666666667, 28.66666666666666, 1.0, 2.0, 0.559638289019458, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9282913799736165, 6.911199999999999, 6.9112, 121.9257999286059, 1387210.144166223, 1387210.144166224, 274170.4827196393], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1356000.0000, 
sim time next is 1356600.0000, 
raw observation next is [30.98333333333333, 28.33333333333334, 1.0, 2.0, 0.3747900539728355, 1.0, 1.0, 0.3747900539728355, 1.0, 2.0, 0.6127756198582461, 6.911200000000001, 6.9112, 121.94756008, 1373886.001524498, 1373886.001524497, 284997.978832962], 
processed observation next is [1.0, 0.6956521739130435, 0.7030864197530863, 0.2833333333333334, 1.0, 1.0, 0.2557024452057565, 1.0, 0.5, 0.2557024452057565, 1.0, 1.0, 0.5159695248228077, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.490673571973035, 0.4906735719730347, 0.5480730362172346], 
reward next is 0.4519, 
noisyNet noise sample is [array([0.7246229], dtype=float32), -1.153556]. 
=============================================
[2019-03-23 22:10:21,028] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.0817200e-20 1.0000000e+00 2.1168617e-31 4.9923505e-29 1.1968095e-33], sum to 1.0000
[2019-03-23 22:10:21,035] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0754
[2019-03-23 22:10:21,042] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1377896.024586183 W.
[2019-03-23 22:10:21,048] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.95, 29.0, 1.0, 2.0, 0.9375959935667303, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.314212330728341, 6.9112, 121.9243297978865, 1377896.024586183, 1171520.589623967, 230274.5881069198], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1355400.0000, 
sim time next is 1356000.0000, 
raw observation next is [30.96666666666667, 28.66666666666666, 1.0, 2.0, 0.5625649756452024, 1.0, 1.0, 0.5625649756452024, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9257999286364, 1387210.138087916, 1387210.138087917, 259480.6007610477], 
processed observation next is [1.0, 0.6956521739130435, 0.7024691358024692, 0.2866666666666666, 1.0, 1.0, 0.4792440186252409, 1.0, 0.5, 0.4792440186252409, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.809460517630664, 0.4954321921742557, 0.49543219217425605, 0.4990011553097071], 
reward next is 0.5010, 
noisyNet noise sample is [array([-0.960592], dtype=float32), 0.6702338]. 
=============================================
[2019-03-23 22:10:21,078] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[50.588173]
 [50.588173]
 [50.588173]
 [50.588173]
 [50.588173]], R is [[50.58329773]
 [50.07746506]
 [49.57669067]
 [49.08092499]
 [48.59011459]].
[2019-03-23 22:10:24,620] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.102272e-25 1.000000e+00 0.000000e+00 4.748583e-37 0.000000e+00], sum to 1.0000
[2019-03-23 22:10:24,629] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5736
[2019-03-23 22:10:24,633] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.5, 37.0, 1.0, 2.0, 0.3442123777443397, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 432814.7228371794, 432814.7228371794, 121154.6272061633], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1463400.0000, 
sim time next is 1464000.0000, 
raw observation next is [28.33333333333333, 37.66666666666667, 1.0, 2.0, 0.3449630394561894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 433721.4470738083, 433721.4470738083, 121252.6879971098], 
processed observation next is [0.0, 0.9565217391304348, 0.6049382716049381, 0.3766666666666667, 1.0, 1.0, 0.22019409459070166, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1549005168120744, 0.1549005168120744, 0.23317824614828805], 
reward next is 0.7668, 
noisyNet noise sample is [array([1.0364856], dtype=float32), 1.2512372]. 
=============================================
[2019-03-23 22:10:24,648] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[75.35799]
 [75.35799]
 [75.35799]
 [75.35799]
 [75.35799]], R is [[75.37122345]
 [75.38452911]
 [75.39728546]
 [75.40932465]
 [75.4209137 ]].
[2019-03-23 22:10:26,252] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 22:10:26,253] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:10:26,254] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:10:26,255] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:10:26,256] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:10:26,257] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:10:26,258] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:10:26,258] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:10:26,259] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:10:26,261] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:10:26,263] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:10:26,266] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run28
[2019-03-23 22:10:26,301] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run28
[2019-03-23 22:10:26,335] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run28
[2019-03-23 22:10:26,365] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run28
[2019-03-23 22:10:26,388] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run28
[2019-03-23 22:10:40,096] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.07355752]
[2019-03-23 22:10:40,096] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.24163767333334, 59.63216275333334, 1.0, 2.0, 0.2524186796132144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 325574.1386725149, 325574.1386725149, 101956.4130302174]
[2019-03-23 22:10:40,097] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:10:40,101] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.441390e-25 1.000000e+00 0.000000e+00 8.446648e-38 0.000000e+00], sampled 0.6363524962672943
[2019-03-23 22:10:53,089] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.07355752]
[2019-03-23 22:10:53,090] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.21448672, 80.35970472, 1.0, 2.0, 0.4348227313265012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 533643.7528463829, 533643.7528463829, 133506.1242864151]
[2019-03-23 22:10:53,090] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:10:53,094] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.441390e-25 1.000000e+00 0.000000e+00 8.446648e-38 0.000000e+00], sampled 0.2796795105503638
[2019-03-23 22:10:53,219] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.07355752]
[2019-03-23 22:10:53,222] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.36666666666667, 54.33333333333334, 1.0, 2.0, 0.5344410144655343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 629520.383547298, 629520.3835472976, 148101.2044102183]
[2019-03-23 22:10:53,222] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:10:53,227] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.441390e-25 1.000000e+00 0.000000e+00 8.446648e-38 0.000000e+00], sampled 0.4854979929537272
[2019-03-23 22:11:15,791] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.07355752]
[2019-03-23 22:11:15,791] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.6, 84.5, 1.0, 2.0, 0.7314830534797008, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 833703.2670890157, 833703.2670890157, 182193.0233357769]
[2019-03-23 22:11:15,793] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:11:15,796] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [8.441390e-25 1.000000e+00 0.000000e+00 8.446648e-38 0.000000e+00], sampled 0.16528211391585268
[2019-03-23 22:11:23,004] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.07355752]
[2019-03-23 22:11:23,004] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.23522141, 75.53046935, 1.0, 2.0, 0.4936213805783872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 587350.3014562608, 587350.3014562608, 141845.3698601567]
[2019-03-23 22:11:23,006] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:11:23,008] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.441390e-25 1.000000e+00 0.000000e+00 8.446648e-38 0.000000e+00], sampled 0.15205549485728098
[2019-03-23 22:12:06,619] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:12:07,006] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:12:07,057] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:12:07,311] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:12:07,440] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:12:08,458] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 675000, evaluation results [675000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:12:12,174] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.3532516e-25 1.0000000e+00 0.0000000e+00 6.3291921e-38 0.0000000e+00], sum to 1.0000
[2019-03-23 22:12:12,179] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1947
[2019-03-23 22:12:12,184] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.56666666666666, 29.66666666666667, 1.0, 2.0, 0.4368195434975453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 532753.0990331101, 532753.0990331101, 133707.2815496497], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1509600.0000, 
sim time next is 1510200.0000, 
raw observation next is [33.7, 29.0, 1.0, 2.0, 0.4301339109524268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 525207.6928327834, 525207.6928327834, 132746.603740009], 
processed observation next is [0.0, 0.4782608695652174, 0.8037037037037038, 0.29, 1.0, 1.0, 0.3215879892290795, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18757417601170837, 0.18757417601170837, 0.2552819302692481], 
reward next is 0.7447, 
noisyNet noise sample is [array([-1.5062801], dtype=float32), -0.13630454]. 
=============================================
[2019-03-23 22:12:15,814] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.321733e-22 1.000000e+00 8.082649e-34 5.245294e-34 1.565135e-36], sum to 1.0000
[2019-03-23 22:12:15,820] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9364
[2019-03-23 22:12:15,826] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.9, 79.66666666666667, 1.0, 2.0, 0.6273648251013814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 785948.0605404095, 785948.0605404095, 165423.3201114347], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1566600.0000, 
sim time next is 1567200.0000, 
raw observation next is [20.8, 80.33333333333334, 1.0, 2.0, 0.538517306880428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 674723.6353682057, 674723.6353682057, 149989.0534675796], 
processed observation next is [1.0, 0.13043478260869565, 0.32592592592592595, 0.8033333333333335, 1.0, 1.0, 0.450615841524319, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24097272691721633, 0.24097272691721633, 0.28844048743765305], 
reward next is 0.7116, 
noisyNet noise sample is [array([0.24704656], dtype=float32), -0.96557057]. 
=============================================
[2019-03-23 22:12:21,602] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.0499952e-23 1.0000000e+00 1.2438411e-38 4.9738093e-32 0.0000000e+00], sum to 1.0000
[2019-03-23 22:12:21,611] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3748
[2019-03-23 22:12:21,623] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1385232.97793056 W.
[2019-03-23 22:12:21,626] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.85, 68.16666666666667, 1.0, 2.0, 0.952413140856449, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.324729012169817, 6.9112, 121.9241506078097, 1385232.97793056, 1173472.448976496, 233369.8103731855], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1702200.0000, 
sim time next is 1702800.0000, 
raw observation next is [23.9, 68.0, 1.0, 2.0, 0.3437033330211237, 1.0, 1.0, 0.3437033330211237, 1.0, 1.0, 0.5552413807750024, 6.911200000000001, 6.9112, 121.94756008, 1238705.620194422, 1238705.620194421, 272749.7294300747], 
processed observation next is [1.0, 0.7391304347826086, 0.4407407407407407, 0.68, 1.0, 1.0, 0.21869444407276634, 1.0, 0.5, 0.21869444407276634, 1.0, 0.5, 0.444051725968753, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.44239486435515074, 0.44239486435515035, 0.5245187104424514], 
reward next is 0.4755, 
noisyNet noise sample is [array([-0.04380093], dtype=float32), 0.9080829]. 
=============================================
[2019-03-23 22:12:21,876] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.6443501e-22 1.0000000e+00 0.0000000e+00 1.1790307e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 22:12:21,883] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8079
[2019-03-23 22:12:21,887] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.2, 76.33333333333334, 1.0, 2.0, 0.4325383191913202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 529192.7914925754, 529192.7914925754, 133127.3413568359], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1711200.0000, 
sim time next is 1711800.0000, 
raw observation next is [23.15, 77.0, 1.0, 2.0, 0.4346011644907259, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 531346.4804360439, 531346.4804360439, 133419.0847644829], 
processed observation next is [1.0, 0.8260869565217391, 0.4129629629629629, 0.77, 1.0, 1.0, 0.32690614820324515, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18976660015572996, 0.18976660015572996, 0.25657516300862093], 
reward next is 0.7434, 
noisyNet noise sample is [array([-0.39862975], dtype=float32), -0.515746]. 
=============================================
[2019-03-23 22:12:24,830] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.8267284e-23 1.0000000e+00 8.1430429e-38 3.1332284e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 22:12:24,836] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7550
[2019-03-23 22:12:24,840] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.2, 81.5, 1.0, 2.0, 0.3775878932256209, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 470176.5149414508, 470176.5149414508, 125555.9012396932], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1733400.0000, 
sim time next is 1734000.0000, 
raw observation next is [21.16666666666667, 81.66666666666667, 1.0, 2.0, 0.3770172609191569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 469536.1994119554, 469536.1994119554, 125479.141267147], 
processed observation next is [1.0, 0.043478260869565216, 0.33950617283950635, 0.8166666666666668, 1.0, 1.0, 0.25835388204661536, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16769149978998407, 0.16769149978998407, 0.2413060408983596], 
reward next is 0.7587, 
noisyNet noise sample is [array([-1.4770805], dtype=float32), 1.882353]. 
=============================================
[2019-03-23 22:12:24,852] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[66.06728]
 [66.06728]
 [66.06728]
 [66.06728]
 [66.06728]], R is [[66.16530609]
 [66.2621994 ]
 [66.35800171]
 [66.45275116]
 [66.54647827]].
[2019-03-23 22:12:25,175] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.6116809e-20 1.0000000e+00 9.7509488e-34 1.7736228e-31 3.8729612e-37], sum to 1.0000
[2019-03-23 22:12:25,184] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7451
[2019-03-23 22:12:25,188] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.75, 83.66666666666667, 1.0, 2.0, 0.3131546110102593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 399414.519066222, 399414.519066222, 117215.4724452395], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1799400.0000, 
sim time next is 1800000.0000, 
raw observation next is [18.3, 85.0, 1.0, 2.0, 0.3034962682577805, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 388187.6273831071, 388187.6273831076, 116009.7810975926], 
processed observation next is [1.0, 0.8695652173913043, 0.23333333333333336, 0.85, 1.0, 1.0, 0.170828890783072, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13863843835110967, 0.13863843835110987, 0.22309573287998577], 
reward next is 0.7769, 
noisyNet noise sample is [array([-0.42194882], dtype=float32), -0.28585914]. 
=============================================
[2019-03-23 22:12:25,216] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[58.367104]
 [58.367104]
 [58.367104]
 [58.367104]
 [58.367104]], R is [[58.56033325]
 [58.74931717]
 [58.93410873]
 [59.11480713]
 [59.29145432]].
[2019-03-23 22:12:50,437] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3870476e-18 1.0000000e+00 4.8669013e-32 3.8125996e-28 2.0599426e-32], sum to 1.0000
[2019-03-23 22:12:50,450] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8986
[2019-03-23 22:12:50,454] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.75, 98.0, 1.0, 2.0, 0.5516968049812161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 646986.1148935963, 646986.1148935963, 150812.8625797749], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2244600.0000, 
sim time next is 2245200.0000, 
raw observation next is [22.76666666666667, 98.0, 1.0, 2.0, 0.5523437059323749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 647526.7534626354, 647526.7534626354, 150910.6059646675], 
processed observation next is [1.0, 1.0, 0.3987654320987655, 0.98, 1.0, 1.0, 0.4670758403956844, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23125955480808408, 0.23125955480808408, 0.29021270377820674], 
reward next is 0.7098, 
noisyNet noise sample is [array([0.26709637], dtype=float32), -1.060456]. 
=============================================
[2019-03-23 22:12:56,109] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.5095778e-24 1.0000000e+00 8.0340017e-38 1.7456556e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 22:12:56,114] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3600
[2019-03-23 22:12:56,127] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 96.0, 1.0, 2.0, 0.477271231485558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 574555.7368010028, 574555.7368010032, 139557.1245956047], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2350800.0000, 
sim time next is 2351400.0000, 
raw observation next is [21.91666666666667, 92.5, 1.0, 2.0, 0.4944999073907056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 596162.9489348423, 596162.9489348418, 142257.6005006791], 
processed observation next is [1.0, 0.21739130434782608, 0.36728395061728414, 0.925, 1.0, 1.0, 0.39821417546512566, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21291533890530082, 0.21291533890530065, 0.27357230865515214], 
reward next is 0.7264, 
noisyNet noise sample is [array([1.8880843], dtype=float32), 1.0669556]. 
=============================================
[2019-03-23 22:12:58,503] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.5070804e-17 1.0000000e+00 2.6693716e-28 2.4989945e-25 5.9747815e-31], sum to 1.0000
[2019-03-23 22:12:58,510] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3726
[2019-03-23 22:12:58,515] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.36666666666667, 38.66666666666667, 1.0, 2.0, 0.4019072461492579, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 491725.3016031705, 491725.3016031701, 128729.6219310163], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2395200.0000, 
sim time next is 2395800.0000, 
raw observation next is [30.2, 39.0, 1.0, 2.0, 0.3933351744788309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 482959.9749340464, 482959.974934046, 127576.3392025005], 
processed observation next is [1.0, 0.7391304347826086, 0.674074074074074, 0.39, 1.0, 1.0, 0.27777996961765583, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.172485705333588, 0.17248570533358784, 0.2453391138509625], 
reward next is 0.7547, 
noisyNet noise sample is [array([0.04619118], dtype=float32), 1.8924443]. 
=============================================
[2019-03-23 22:12:59,133] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-23 22:12:59,136] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:12:59,137] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:12:59,137] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:12:59,138] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:12:59,139] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:12:59,139] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:12:59,143] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:12:59,146] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:12:59,148] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:12:59,148] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:12:59,165] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run29
[2019-03-23 22:12:59,188] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run29
[2019-03-23 22:12:59,208] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run29
[2019-03-23 22:12:59,209] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run29
[2019-03-23 22:12:59,210] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run29
[2019-03-23 22:13:24,634] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.08451949]
[2019-03-23 22:13:24,636] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.77573460333333, 84.60738865333333, 1.0, 2.0, 0.6509316825232164, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 741850.9140356001, 741850.9140356001, 167064.5063759857]
[2019-03-23 22:13:24,636] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:13:24,638] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.2014325e-21 1.0000000e+00 3.5485479e-34 1.1348740e-31 2.7849019e-36], sampled 0.25653540225326477
[2019-03-23 22:13:30,443] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.08451949]
[2019-03-23 22:13:30,444] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [31.554431505, 55.56873328, 1.0, 2.0, 0.6455308148835123, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 735692.7235471399, 735692.7235471399, 166088.7946075379]
[2019-03-23 22:13:30,445] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:13:30,447] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.2014325e-21 1.0000000e+00 3.5485479e-34 1.1348740e-31 2.7849019e-36], sampled 0.5984068037845824
[2019-03-23 22:13:39,821] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.08451949]
[2019-03-23 22:13:39,822] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.75, 52.66666666666667, 1.0, 2.0, 0.5214437421916723, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8301554198062339, 6.911200000000001, 6.9112, 121.9258648628055, 1188899.872902081, 1188899.872902081, 264545.5677773532]
[2019-03-23 22:13:39,823] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:13:39,829] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.2014325e-21 1.0000000e+00 3.5485479e-34 1.1348740e-31 2.7849019e-36], sampled 0.7784213914336401
[2019-03-23 22:13:42,825] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.08451949]
[2019-03-23 22:13:42,826] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.0, 83.0, 1.0, 2.0, 0.5666614277739542, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 660756.2959355294, 660756.2959355294, 153142.8020863241]
[2019-03-23 22:13:42,827] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:13:42,831] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.2014325e-21 1.0000000e+00 3.5485479e-34 1.1348740e-31 2.7849019e-36], sampled 0.1665676380986485
[2019-03-23 22:13:52,284] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.08451949]
[2019-03-23 22:13:52,285] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.0, 89.0, 1.0, 2.0, 0.5471487188594614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 640184.6278597388, 640184.6278597388, 150000.4337917878]
[2019-03-23 22:13:52,287] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:13:52,292] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.2014325e-21 1.0000000e+00 3.5485479e-34 1.1348740e-31 2.7849019e-36], sampled 0.32341430748945676
[2019-03-23 22:13:55,497] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.08451949]
[2019-03-23 22:13:55,498] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.62194089, 76.53561803666668, 1.0, 2.0, 0.6306586490658342, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.9254173209959, 1433660.954956457, 1433660.954956457, 305068.4572760428]
[2019-03-23 22:13:55,498] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:13:55,501] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.2014325e-21 1.0000000e+00 3.5485479e-34 1.1348740e-31 2.7849019e-36], sampled 0.8343772981284185
[2019-03-23 22:13:55,501] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1433660.954956457 W.
[2019-03-23 22:14:20,051] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.08451949]
[2019-03-23 22:14:20,052] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.5, 70.0, 1.0, 2.0, 0.7009362890255865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 798869.6382597246, 798869.6382597241, 176318.1169694027]
[2019-03-23 22:14:20,054] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:14:20,057] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.2014325e-21 1.0000000e+00 3.5485479e-34 1.1348740e-31 2.7849019e-36], sampled 0.9994947961710848
[2019-03-23 22:14:39,399] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:14:39,400] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:14:39,720] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:14:39,721] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:14:39,751] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.08451949]
[2019-03-23 22:14:39,752] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.5, 66.0, 1.0, 2.0, 0.4672829722590926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 565577.9867282883, 565577.9867282883, 138132.4637714047]
[2019-03-23 22:14:39,752] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:14:39,753] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.2014325e-21 1.0000000e+00 3.5485479e-34 1.1348740e-31 2.7849019e-36], sampled 0.33694000640704613
[2019-03-23 22:14:39,786] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:14:40,803] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 700000, evaluation results [700000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:14:48,369] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.6233526e-22 1.0000000e+00 2.2570379e-36 8.6549298e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 22:14:48,376] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0158
[2019-03-23 22:14:48,381] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1502463.466688456 W.
[2019-03-23 22:14:48,386] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.1, 30.0, 1.0, 2.0, 0.4196975358600146, 1.0, 2.0, 0.4196975358600146, 1.0, 2.0, 0.6755476057232185, 6.911200000000001, 6.9112, 121.94756008, 1502463.466688456, 1502463.466688456, 305557.8331965979], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2545800.0000, 
sim time next is 2546400.0000, 
raw observation next is [32.2, 30.0, 1.0, 2.0, 0.6510160333402818, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9580249541537579, 6.911199999999999, 6.9112, 121.9260426156618, 1503097.573392522, 1503097.573392522, 298028.1350468033], 
processed observation next is [1.0, 0.4782608695652174, 0.7481481481481482, 0.3, 1.0, 1.0, 0.5845428968336688, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9475311926921972, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5368205619259008, 0.5368205619259008, 0.5731310289361602], 
reward next is 0.4269, 
noisyNet noise sample is [array([1.9917754], dtype=float32), 0.009964117]. 
=============================================
[2019-03-23 22:14:49,215] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.1225856e-16 1.0000000e+00 2.3566312e-26 3.2098866e-25 4.4176346e-28], sum to 1.0000
[2019-03-23 22:14:49,224] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3993
[2019-03-23 22:14:49,224] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1766218.638962352 W.
[2019-03-23 22:14:49,231] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.23333333333333, 33.83333333333334, 1.0, 2.0, 0.7550794377735499, 1.0, 2.0, 0.7550794377735499, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 1766218.638962352, 1766218.638962351, 327734.3537427097], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2566200.0000, 
sim time next is 2566800.0000, 
raw observation next is [33.2, 34.0, 1.0, 2.0, 0.5099117844868144, 1.0, 2.0, 0.5099117844868144, 1.0, 1.0, 0.8125519004522347, 6.9112, 6.9112, 121.94756008, 1763897.143097048, 1763897.143097048, 348587.7800465574], 
processed observation next is [1.0, 0.7391304347826086, 0.7851851851851853, 0.34, 1.0, 1.0, 0.41656164819858854, 1.0, 1.0, 0.41656164819858854, 1.0, 0.5, 0.7656898755652932, 0.0, 0.0, 0.8096049824067558, 0.6299632653918028, 0.6299632653918028, 0.6703611154741489], 
reward next is 0.3296, 
noisyNet noise sample is [array([-0.8438909], dtype=float32), -0.9077975]. 
=============================================
[2019-03-23 22:14:51,387] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.3852591e-21 1.0000000e+00 3.2320714e-36 1.7614556e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 22:14:51,398] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7603
[2019-03-23 22:14:51,402] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.45, 86.83333333333334, 1.0, 2.0, 0.4723217977863119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 571340.7734158846, 571340.7734158846, 138889.8599736469], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2596200.0000, 
sim time next is 2596800.0000, 
raw observation next is [22.3, 87.66666666666667, 1.0, 2.0, 0.4705020211879469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 569528.2011578564, 569528.2011578564, 138624.4235737641], 
processed observation next is [0.0, 0.043478260869565216, 0.38148148148148153, 0.8766666666666667, 1.0, 1.0, 0.3696452633189844, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20340292898494872, 0.20340292898494872, 0.26658542994954637], 
reward next is 0.7334, 
noisyNet noise sample is [array([-0.7691565], dtype=float32), 0.75771546]. 
=============================================
[2019-03-23 22:15:01,175] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.5691687e-23 1.0000000e+00 2.8254978e-38 5.0103455e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 22:15:01,183] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9943
[2019-03-23 22:15:01,195] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.16666666666666, 89.0, 1.0, 2.0, 0.6799426287078839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 793487.2784934413, 793487.2784934408, 173276.9660388982], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2787000.0000, 
sim time next is 2787600.0000, 
raw observation next is [24.33333333333333, 89.0, 1.0, 2.0, 0.6886308617165291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 800852.667112868, 800852.667112868, 174784.3439656775], 
processed observation next is [1.0, 0.2608695652173913, 0.45679012345678993, 0.89, 1.0, 1.0, 0.6293224544244393, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2860188096831672, 0.2860188096831672, 0.3361237383955336], 
reward next is 0.6639, 
noisyNet noise sample is [array([-1.8030117], dtype=float32), -2.3417473]. 
=============================================
[2019-03-23 22:15:02,754] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.9539344e-18 1.0000000e+00 9.3855435e-29 9.6601330e-26 7.6841648e-30], sum to 1.0000
[2019-03-23 22:15:02,759] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4165
[2019-03-23 22:15:02,767] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2315891.401196377 W.
[2019-03-23 22:15:02,771] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.41666666666666, 64.83333333333333, 1.0, 2.0, 0.7266814123819153, 1.0, 2.0, 0.6767053681673922, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2315891.401196377, 2315891.401196377, 436486.7741740557], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2803800.0000, 
sim time next is 2804400.0000, 
raw observation next is [30.7, 63.0, 1.0, 2.0, 0.5859079881869731, 1.0, 2.0, 0.5859079881869731, 1.0, 2.0, 0.9327845988846742, 6.911199999999999, 6.9112, 121.94756008, 2004806.380645204, 2004806.380645205, 387751.0141955267], 
processed observation next is [1.0, 0.4782608695652174, 0.6925925925925925, 0.63, 1.0, 1.0, 0.507033319270206, 1.0, 1.0, 0.507033319270206, 1.0, 1.0, 0.9159807486058427, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7160022788018586, 0.716002278801859, 0.7456750272990899], 
reward next is 0.2543, 
noisyNet noise sample is [array([1.3729256], dtype=float32), 0.67144173]. 
=============================================
[2019-03-23 22:15:05,467] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.5282063e-21 1.0000000e+00 6.2652322e-35 7.8510327e-32 1.7025768e-37], sum to 1.0000
[2019-03-23 22:15:05,474] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4502
[2019-03-23 22:15:05,482] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.25, 95.5, 1.0, 2.0, 0.7602414428073719, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260425413601, 898563.5694924822, 898563.5694924822, 189398.9366521542], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2860200.0000, 
sim time next is 2860800.0000, 
raw observation next is [22.16666666666667, 97.0, 1.0, 2.0, 0.7234086632292602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156391, 859858.0739665616, 859858.073966562, 182268.4762558152], 
processed observation next is [1.0, 0.08695652173913043, 0.3765432098765434, 0.97, 1.0, 1.0, 0.6707245990824526, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288199852, 0.307092169273772, 0.30709216927377214, 0.3505163004919523], 
reward next is 0.6495, 
noisyNet noise sample is [array([-0.01724223], dtype=float32), -0.83012986]. 
=============================================
[2019-03-23 22:15:06,076] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.2704559e-24 1.0000000e+00 5.5461949e-37 6.0157525e-35 6.8300834e-38], sum to 1.0000
[2019-03-23 22:15:06,084] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1886
[2019-03-23 22:15:06,090] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1383779.663421749 W.
[2019-03-23 22:15:06,094] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.4045598079927842, 1.0, 2.0, 0.4045598079927842, 1.0, 1.0, 0.6440723899176227, 6.9112, 6.9112, 121.94756008, 1383779.663421749, 1383779.663421749, 299085.3439579012], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2886000.0000, 
sim time next is 2886600.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.6041716967146181, 1.0, 2.0, 0.6041716967146181, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1387843.134980055, 1387843.134980055, 269980.3658550221], 
processed observation next is [1.0, 0.391304347826087, 0.4074074074074074, 0.94, 1.0, 1.0, 0.5287758294221644, 1.0, 1.0, 0.5287758294221644, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.4956582624928768, 0.4956582624928768, 0.5191930112596579], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.16373529], dtype=float32), -1.5434985]. 
=============================================
[2019-03-23 22:15:08,310] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.7969428e-16 1.0000000e+00 3.5825662e-26 1.7991088e-23 4.5268336e-27], sum to 1.0000
[2019-03-23 22:15:08,319] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6050
[2019-03-23 22:15:08,326] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 85.66666666666667, 1.0, 2.0, 0.6881961344592514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 784342.0267900283, 784342.0267900283, 173921.7283386259], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2917200.0000, 
sim time next is 2917800.0000, 
raw observation next is [26.5, 86.5, 1.0, 2.0, 0.6759071409926769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 770329.1356786313, 770329.1356786313, 171633.6448746597], 
processed observation next is [1.0, 0.782608695652174, 0.5370370370370371, 0.865, 1.0, 1.0, 0.6141751678484249, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27511754845665404, 0.27511754845665404, 0.3300647016820379], 
reward next is 0.6699, 
noisyNet noise sample is [array([0.88542837], dtype=float32), 1.643394]. 
=============================================
[2019-03-23 22:15:12,478] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.8395883e-17 1.0000000e+00 6.1390161e-27 6.0046633e-25 1.8198117e-28], sum to 1.0000
[2019-03-23 22:15:12,488] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4083
[2019-03-23 22:15:12,495] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1738258.87770323 W.
[2019-03-23 22:15:12,500] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.33333333333334, 72.33333333333334, 1.0, 2.0, 0.7621270017515173, 1.0, 2.0, 0.7621270017515173, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1738258.87770323, 1738258.87770323, 328353.8437163043], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2988600.0000, 
sim time next is 2989200.0000, 
raw observation next is [28.46666666666667, 76.66666666666667, 1.0, 2.0, 0.7326615114146433, 1.0, 2.0, 0.7326615114146433, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1670991.147785999, 1670991.147785999, 316715.2221963477], 
processed observation next is [1.0, 0.6086956521739131, 0.6098765432098766, 0.7666666666666667, 1.0, 1.0, 0.6817398945412421, 1.0, 1.0, 0.6817398945412421, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.596782552780714, 0.596782552780714, 0.6090677349929764], 
reward next is 0.3909, 
noisyNet noise sample is [array([-1.6896547], dtype=float32), -0.12095534]. 
=============================================
[2019-03-23 22:15:13,835] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.5995552e-17 1.0000000e+00 6.3264518e-27 6.0793889e-24 4.0937699e-29], sum to 1.0000
[2019-03-23 22:15:13,842] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0546
[2019-03-23 22:15:13,845] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666666, 96.0, 1.0, 2.0, 0.7138984478972095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 813650.6840651305, 813650.6840651305, 178793.6075688477], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3004800.0000, 
sim time next is 3005400.0000, 
raw observation next is [25.83333333333334, 95.0, 1.0, 2.0, 0.7160086234289292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 816056.9923979521, 816056.9923979521, 179198.6939594481], 
processed observation next is [1.0, 0.782608695652174, 0.5123456790123458, 0.95, 1.0, 1.0, 0.6619150278915824, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29144892585641147, 0.29144892585641147, 0.34461287299893867], 
reward next is 0.6554, 
noisyNet noise sample is [array([-0.7411292], dtype=float32), -1.7213533]. 
=============================================
[2019-03-23 22:15:30,011] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.0282202e-23 1.0000000e+00 1.7786718e-37 1.6679671e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 22:15:30,019] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1878
[2019-03-23 22:15:30,022] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.95, 98.83333333333334, 1.0, 2.0, 0.5141515106191352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 611861.3777230855, 611861.3777230855, 145085.0516276063], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3304200.0000, 
sim time next is 3304800.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.5241470904250494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 621525.7125061658, 621525.7125061658, 146602.531968374], 
processed observation next is [0.0, 0.2608695652173913, 0.37037037037037035, 1.0, 1.0, 1.0, 0.4335084409822016, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22197346875220209, 0.22197346875220209, 0.28192794609302696], 
reward next is 0.7181, 
noisyNet noise sample is [array([0.36486444], dtype=float32), 0.23999612]. 
=============================================
[2019-03-23 22:15:31,573] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 22:15:31,574] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:15:31,576] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:15:31,576] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:15:31,577] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:15:31,579] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:15:31,581] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:15:31,584] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:15:31,588] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:15:31,589] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:15:31,582] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:15:31,600] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run30
[2019-03-23 22:15:31,621] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run30
[2019-03-23 22:15:31,622] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run30
[2019-03-23 22:15:31,624] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run30
[2019-03-23 22:15:31,701] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run30
[2019-03-23 22:15:36,227] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.111343466]
[2019-03-23 22:15:36,227] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [32.0, 21.0, 1.0, 2.0, 0.3551461821383333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 452064.606135958, 452064.606135958, 122656.0629888793]
[2019-03-23 22:15:36,228] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:15:36,230] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.0360419e-23 1.0000000e+00 8.7277864e-37 4.2576644e-34 0.0000000e+00], sampled 0.6538436451073653
[2019-03-23 22:15:45,079] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.111343466]
[2019-03-23 22:15:45,079] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.40269546, 54.65819058, 1.0, 2.0, 0.2713854386706968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 348403.3237447576, 348403.3237447576, 112111.9409822213]
[2019-03-23 22:15:45,080] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:15:45,082] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.0360419e-23 1.0000000e+00 8.7277864e-37 4.2576644e-34 0.0000000e+00], sampled 0.5669836912123248
[2019-03-23 22:15:55,946] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.111343466]
[2019-03-23 22:15:55,947] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.12746977666666, 81.92188530166666, 1.0, 2.0, 0.7318433297349874, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 834114.1131515212, 834114.1131515207, 182263.9384337762]
[2019-03-23 22:15:55,948] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:15:55,951] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.0360419e-23 1.0000000e+00 8.7277864e-37 4.2576644e-34 0.0000000e+00], sampled 0.7656036003241391
[2019-03-23 22:16:05,787] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.111343466]
[2019-03-23 22:16:05,788] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.87040768, 93.10913609, 1.0, 2.0, 0.7181615885192075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 818512.1029747182, 818512.1029747182, 179611.3785685225]
[2019-03-23 22:16:05,788] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:16:05,791] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.0360419e-23 1.0000000e+00 8.7277864e-37 4.2576644e-34 0.0000000e+00], sampled 0.9236801241273548
[2019-03-23 22:16:08,119] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.111343466]
[2019-03-23 22:16:08,121] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.0, 88.0, 1.0, 2.0, 0.4443873692484274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 540244.7520857545, 540244.7520857542, 134772.5864801427]
[2019-03-23 22:16:08,121] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:16:08,124] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.0360419e-23 1.0000000e+00 8.7277864e-37 4.2576644e-34 0.0000000e+00], sampled 0.5097628492569358
[2019-03-23 22:16:39,834] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.111343466]
[2019-03-23 22:16:39,835] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.81666666666667, 90.83333333333334, 1.0, 2.0, 0.6874179723781133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 783454.6966841902, 783454.6966841897, 173775.4831784839]
[2019-03-23 22:16:39,837] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:16:39,840] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.0360419e-23 1.0000000e+00 8.7277864e-37 4.2576644e-34 0.0000000e+00], sampled 0.32927826069670996
[2019-03-23 22:17:12,550] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:17:12,666] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:17:12,770] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:17:12,803] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:17:12,876] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:17:13,893] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 725000, evaluation results [725000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:17:16,445] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.9203006e-21 1.0000000e+00 4.3334800e-35 3.7928140e-35 1.4390771e-38], sum to 1.0000
[2019-03-23 22:17:16,451] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4588
[2019-03-23 22:17:16,454] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1735993.833694045 W.
[2019-03-23 22:17:16,457] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.6, 80.33333333333334, 1.0, 2.0, 0.5074233360243736, 1.0, 2.0, 0.5074233360243736, 1.0, 1.0, 0.8078344765751433, 6.911199999999999, 6.9112, 121.94756008, 1735993.833694045, 1735993.833694046, 347247.4489976518], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3400800.0000, 
sim time next is 3401400.0000, 
raw observation next is [26.8, 79.66666666666667, 1.0, 2.0, 0.7636931490343912, 1.0, 2.0, 0.7636931490343912, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426155362, 1741834.428245116, 1741834.428245116, 328979.6840946022], 
processed observation next is [1.0, 0.34782608695652173, 0.5481481481481482, 0.7966666666666667, 1.0, 1.0, 0.7186823202790371, 1.0, 1.0, 0.7186823202790371, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288193021, 0.6220837243732558, 0.6220837243732558, 0.6326532386434658], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.21129975], dtype=float32), 0.6317322]. 
=============================================
[2019-03-23 22:17:26,520] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.2311328e-24 1.0000000e+00 1.4401865e-38 2.3852613e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 22:17:26,528] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0466
[2019-03-23 22:17:26,532] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.06666666666667, 92.33333333333334, 1.0, 2.0, 0.7654241662398712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 920898.8483256161, 920898.8483256161, 191104.7202187589], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3572400.0000, 
sim time next is 3573000.0000, 
raw observation next is [22.15, 92.0, 1.0, 2.0, 0.8452729567606752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1015963.901130153, 1015963.901130153, 207945.2578644235], 
processed observation next is [1.0, 0.34782608695652173, 0.3759259259259259, 0.92, 1.0, 1.0, 0.8158011390008038, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.36284425040362606, 0.36284425040362606, 0.3998947266623529], 
reward next is 0.6001, 
noisyNet noise sample is [array([-0.7602788], dtype=float32), -0.6792]. 
=============================================
[2019-03-23 22:17:26,548] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[70.94753]
 [70.94753]
 [70.94753]
 [70.94753]
 [70.94753]], R is [[70.83816528]
 [70.7622757 ]
 [70.7519455 ]
 [70.75164795]
 [70.77018738]].
[2019-03-23 22:17:35,296] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.0732506e-22 1.0000000e+00 3.3433039e-36 1.2647967e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 22:17:35,305] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5100
[2019-03-23 22:17:35,309] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.26666666666667, 98.66666666666667, 1.0, 2.0, 0.7338425944663457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 836394.0066292302, 836394.0066292307, 182645.7274893498], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3734400.0000, 
sim time next is 3735000.0000, 
raw observation next is [24.2, 99.0, 1.0, 2.0, 0.7198645809294398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 820454.0976175911, 820454.0976175911, 179934.7794025377], 
processed observation next is [1.0, 0.21739130434782608, 0.45185185185185184, 0.99, 1.0, 1.0, 0.6665054534874284, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29301932057771113, 0.29301932057771113, 0.34602842192795713], 
reward next is 0.6540, 
noisyNet noise sample is [array([-0.01990313], dtype=float32), 0.7569644]. 
=============================================
[2019-03-23 22:17:35,324] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[63.329212]
 [63.329212]
 [63.329212]
 [63.329212]
 [63.329212]], R is [[63.34989548]
 [63.36515427]
 [63.35044479]
 [63.3938446 ]
 [63.4375267 ]].
[2019-03-23 22:17:36,030] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.7109311e-23 1.0000000e+00 1.7542478e-34 1.2152775e-31 3.3630392e-37], sum to 1.0000
[2019-03-23 22:17:36,038] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0023
[2019-03-23 22:17:36,043] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1369044.546651086 W.
[2019-03-23 22:17:36,046] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.5, 94.00000000000001, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.311699457928934, 6.9112, 122.5285924609954, 1369044.546651086, 1162939.480233105, 245672.9629941231], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3744600.0000, 
sim time next is 3745200.0000, 
raw observation next is [25.6, 94.0, 1.0, 2.0, 0.511224567944041, 1.0, 1.0, 0.511224567944041, 1.0, 1.0, 0.8138861615887346, 6.911200000000001, 6.9112, 121.94756008, 1749011.315850459, 1749011.315850459, 349132.3604090451], 
processed observation next is [1.0, 0.34782608695652173, 0.5037037037037038, 0.94, 1.0, 1.0, 0.41812448564766785, 1.0, 0.5, 0.41812448564766785, 1.0, 0.5, 0.7673577019859181, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6246468985180211, 0.6246468985180211, 0.6714083854020099], 
reward next is 0.3286, 
noisyNet noise sample is [array([0.04215012], dtype=float32), 0.042028174]. 
=============================================
[2019-03-23 22:17:37,807] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.4494717e-14 1.0000000e+00 1.2457174e-22 6.2187018e-21 4.2361716e-24], sum to 1.0000
[2019-03-23 22:17:37,815] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9798
[2019-03-23 22:17:37,823] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.25, 76.5, 1.0, 2.0, 0.7053369855838174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 803887.8210937608, 803887.8210937608, 177157.349553347], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3798600.0000, 
sim time next is 3799200.0000, 
raw observation next is [28.0, 76.0, 1.0, 2.0, 0.6944955698522607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 791525.2450898549, 791525.2450898549, 175103.8882816269], 
processed observation next is [1.0, 1.0, 0.5925925925925926, 0.76, 1.0, 1.0, 0.6363042498241198, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28268758753209106, 0.28268758753209106, 0.33673824669543634], 
reward next is 0.6633, 
noisyNet noise sample is [array([2.4341698], dtype=float32), 0.45094305]. 
=============================================
[2019-03-23 22:17:45,348] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0830921e-20 1.0000000e+00 1.5257756e-33 2.7269618e-32 1.4243216e-36], sum to 1.0000
[2019-03-23 22:17:45,355] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4351
[2019-03-23 22:17:45,361] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 0.8116539409242017, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 925132.6877727499, 925132.6877727499, 198367.39843174], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3934200.0000, 
sim time next is 3934800.0000, 
raw observation next is [31.0, 70.0, 1.0, 2.0, 0.8118968863671518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 925409.7670324073, 925409.7670324073, 198418.0877953622], 
processed observation next is [0.0, 0.5652173913043478, 0.7037037037037037, 0.7, 1.0, 1.0, 0.776067721865657, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3305034882258598, 0.3305034882258598, 0.38157324576031193], 
reward next is 0.6184, 
noisyNet noise sample is [array([-0.29172835], dtype=float32), -0.033672918]. 
=============================================
[2019-03-23 22:17:45,476] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.7176773e-20 1.0000000e+00 3.7395626e-32 8.0530317e-29 2.0343799e-35], sum to 1.0000
[2019-03-23 22:17:45,484] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0646
[2019-03-23 22:17:45,490] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.7538073365757941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 859161.4912816457, 859161.4912816457, 186583.8622495098], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3920400.0000, 
sim time next is 3921000.0000, 
raw observation next is [27.16666666666666, 87.33333333333334, 1.0, 2.0, 0.7508021557287434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 855734.3860518129, 855734.3860518129, 185987.3922403012], 
processed observation next is [0.0, 0.391304347826087, 0.5617283950617282, 0.8733333333333334, 1.0, 1.0, 0.7033358996770755, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.30561942358993316, 0.30561942358993316, 0.35766806200057927], 
reward next is 0.6423, 
noisyNet noise sample is [array([0.9224134], dtype=float32), -0.2779718]. 
=============================================
[2019-03-23 22:17:45,514] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[58.019512]
 [58.019512]
 [58.019512]
 [58.019512]
 [58.019512]], R is [[58.08164597]
 [58.14201736]
 [58.20186615]
 [58.26267624]
 [58.32878876]].
[2019-03-23 22:17:48,313] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.6801884e-22 1.0000000e+00 4.6735773e-35 7.1363964e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 22:17:48,326] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7419
[2019-03-23 22:17:48,334] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1314806.688927931 W.
[2019-03-23 22:17:48,338] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.95, 91.16666666666667, 1.0, 2.0, 1.01283967744716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.223778768800782, 6.9112, 121.9248676944203, 1314806.688927931, 1154739.963801426, 243832.6126568168], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3989400.0000, 
sim time next is 3990000.0000, 
raw observation next is [24.9, 91.33333333333334, 1.0, 2.0, 0.4656977094408901, 1.0, 1.0, 0.4656977094408901, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9258543862258, 1061709.981145011, 1061709.981145011, 224978.0124315015], 
processed observation next is [1.0, 0.17391304347826086, 0.47777777777777775, 0.9133333333333334, 1.0, 1.0, 0.3639258445724883, 1.0, 0.5, 0.3639258445724883, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094608791724257, 0.3791821361232182, 0.3791821361232182, 0.4326500239067336], 
reward next is 0.5673, 
noisyNet noise sample is [array([0.10023148], dtype=float32), 0.04765653]. 
=============================================
[2019-03-23 22:17:48,360] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[68.0745]
 [68.0745]
 [68.0745]
 [68.0745]
 [68.0745]], R is [[67.96109772]
 [67.28148651]
 [67.16952515]
 [66.49783325]
 [65.86019135]].
[2019-03-23 22:17:48,628] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.4205076e-24 1.0000000e+00 6.6601166e-38 4.0969619e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 22:17:48,637] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3275
[2019-03-23 22:17:48,646] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1623552.897239588 W.
[2019-03-23 22:17:48,650] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.35, 88.0, 1.0, 2.0, 0.7118806547420073, 1.0, 2.0, 0.7118806547420073, 0.0, 1.0, 0.0, 6.911199999999997, 6.9112, 121.9260421319614, 1623552.897239588, 1623552.897239589, 308686.7396076508], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3983400.0000, 
sim time next is 3984000.0000, 
raw observation next is [25.3, 88.33333333333333, 1.0, 2.0, 0.5836727906184214, 1.0, 2.0, 0.5836727906184214, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426155143, 1330906.32956019, 1330906.329560189, 262472.0286770174], 
processed observation next is [1.0, 0.08695652173913043, 0.49259259259259264, 0.8833333333333333, 1.0, 1.0, 0.5043723697838349, 1.0, 1.0, 0.5043723697838349, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288191567, 0.47532368912863926, 0.4753236891286389, 0.5047539013019566], 
reward next is 0.4952, 
noisyNet noise sample is [array([-2.4716377], dtype=float32), 2.0558798]. 
=============================================
[2019-03-23 22:17:48,674] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[63.558933]
 [63.558933]
 [63.558933]
 [63.558933]
 [63.558933]], R is [[63.41859436]
 [62.78440857]
 [62.40569305]
 [61.78163528]
 [61.84107971]].
[2019-03-23 22:17:51,704] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.0121493e-13 1.0000000e+00 9.1574694e-21 3.3011581e-18 1.3607580e-20], sum to 1.0000
[2019-03-23 22:17:51,710] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7310
[2019-03-23 22:17:51,717] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1749528.214950036 W.
[2019-03-23 22:17:51,727] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.66666666666667, 85.66666666666667, 1.0, 2.0, 0.767063127166535, 1.0, 2.0, 0.767063127166535, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1749528.214950036, 1749528.214950036, 330332.4431844843], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4030800.0000, 
sim time next is 4031400.0000, 
raw observation next is [26.83333333333333, 84.83333333333333, 1.0, 2.0, 0.7714285362134382, 1.0, 2.0, 0.7714285362134382, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1759494.706356718, 1759494.706356717, 332089.8149624981], 
processed observation next is [1.0, 0.6521739130434783, 0.5493827160493825, 0.8483333333333333, 1.0, 1.0, 0.7278911145398074, 1.0, 1.0, 0.7278911145398074, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6283909665559707, 0.6283909665559704, 0.6386342595432656], 
reward next is 0.3614, 
noisyNet noise sample is [array([-0.16661207], dtype=float32), 0.18087196]. 
=============================================
[2019-03-23 22:17:59,565] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.6886415e-23 1.0000000e+00 2.8471712e-37 4.0455566e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 22:17:59,571] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7900
[2019-03-23 22:17:59,576] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1447415.023762269 W.
[2019-03-23 22:17:59,580] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.26666666666667, 59.0, 1.0, 2.0, 0.6347197773335669, 1.0, 2.0, 0.6347197773335669, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1447415.023762269, 1447415.023762269, 280189.6799550681], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4184400.0000, 
sim time next is 4185000.0000, 
raw observation next is [29.4, 57.5, 1.0, 2.0, 0.6296233473006548, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9949562973181176, 6.911199999999999, 6.9112, 121.9260426156618, 1434628.409288811, 1434628.409288812, 304406.0056423448], 
processed observation next is [1.0, 0.43478260869565216, 0.6444444444444444, 0.575, 1.0, 1.0, 0.5590754134531605, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9936953716476471, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5123672890317182, 0.5123672890317186, 0.585396164696817], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.02355113], dtype=float32), 0.8125739]. 
=============================================
[2019-03-23 22:17:59,603] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[66.45609]
 [66.45609]
 [66.45609]
 [66.45609]
 [66.45609]], R is [[65.79152679]
 [65.5947876 ]
 [65.32746887]
 [65.00820923]
 [64.35813141]].
[2019-03-23 22:17:59,927] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.1675601e-21 1.0000000e+00 1.4090585e-31 3.3294416e-30 1.1942504e-34], sum to 1.0000
[2019-03-23 22:17:59,933] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0625
[2019-03-23 22:17:59,938] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.5, 41.0, 1.0, 2.0, 0.5422409011739694, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8646510837115599, 6.911200000000001, 6.9112, 121.9260426156618, 1255821.832071909, 1255821.832071909, 271742.3713752138], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4192200.0000, 
sim time next is 4192800.0000, 
raw observation next is [32.66666666666667, 39.33333333333334, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.582726065131361, 6.9112, 121.9233410816254, 1547973.873082642, 1204100.126848949, 247789.2536096412], 
processed observation next is [1.0, 0.5217391304347826, 0.7654320987654323, 0.3933333333333334, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.06715260651313608, 0.0, 0.8094441934435316, 0.5528478118152292, 0.4300357595889103, 0.47651779540315614], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5515534], dtype=float32), -0.7697269]. 
=============================================
[2019-03-23 22:18:01,530] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.6101101e-16 1.0000000e+00 4.3957664e-27 5.8760464e-25 3.1300394e-28], sum to 1.0000
[2019-03-23 22:18:01,537] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1937
[2019-03-23 22:18:01,540] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 66.0, 1.0, 2.0, 0.4709038746563878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 569624.140533233, 569624.140533233, 138672.9553489446], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4235400.0000, 
sim time next is 4236000.0000, 
raw observation next is [25.66666666666666, 63.33333333333333, 1.0, 2.0, 0.4596972703242607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 558505.5430934534, 558505.5430934534, 137050.1222168395], 
processed observation next is [1.0, 0.0, 0.5061728395061726, 0.6333333333333333, 1.0, 1.0, 0.356782464671739, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19946626539051907, 0.19946626539051907, 0.26355792734007594], 
reward next is 0.7364, 
noisyNet noise sample is [array([1.4943205], dtype=float32), -0.45102572]. 
=============================================
[2019-03-23 22:18:01,557] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[47.9798]
 [47.9798]
 [47.9798]
 [47.9798]
 [47.9798]], R is [[48.23644638]
 [48.48740387]
 [48.73312759]
 [48.97423553]
 [49.21224976]].
[2019-03-23 22:18:04,671] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 22:18:04,673] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:18:04,674] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:18:04,674] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:18:04,676] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:18:04,676] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:18:04,678] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:18:04,680] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:18:04,681] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:18:04,680] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:18:04,684] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:18:04,697] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run31
[2019-03-23 22:18:04,721] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run31
[2019-03-23 22:18:04,723] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run31
[2019-03-23 22:18:04,746] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run31
[2019-03-23 22:18:04,789] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run31
[2019-03-23 22:18:17,758] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.21464059]
[2019-03-23 22:18:17,759] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.73333333333333, 69.33333333333333, 1.0, 2.0, 0.2935980350189996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 374532.1605314292, 374532.1605314292, 114787.7968483155]
[2019-03-23 22:18:17,760] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:18:17,762] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.9851935e-18 1.0000000e+00 4.3971707e-29 7.8062863e-27 8.9774253e-31], sampled 0.8563493586636595
[2019-03-23 22:18:49,838] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.21464059]
[2019-03-23 22:18:49,839] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.66666666666667, 59.83333333333334, 1.0, 2.0, 0.7016835411101114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 799721.7391357525, 799721.7391357525, 176465.3596587337]
[2019-03-23 22:18:49,840] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:18:49,847] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.9851935e-18 1.0000000e+00 4.3971707e-29 7.8062863e-27 8.9774253e-31], sampled 0.5042660630235761
[2019-03-23 22:19:02,608] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.21464059]
[2019-03-23 22:19:02,608] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.32758842166667, 96.65751089166666, 1.0, 2.0, 0.8821046094734485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1005485.868067311, 1005485.868067311, 213492.3909947084]
[2019-03-23 22:19:02,609] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:19:02,611] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.9851935e-18 1.0000000e+00 4.3971707e-29 7.8062863e-27 8.9774253e-31], sampled 0.5316014119100357
[2019-03-23 22:19:10,839] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.21464059]
[2019-03-23 22:19:10,840] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.5, 84.0, 1.0, 2.0, 0.603065139793368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 693931.8918907859, 693931.8918907859, 158931.3693371745]
[2019-03-23 22:19:10,841] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:19:10,844] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.9851935e-18 1.0000000e+00 4.3971707e-29 7.8062863e-27 8.9774253e-31], sampled 0.8340908666889892
[2019-03-23 22:19:37,510] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.21464059]
[2019-03-23 22:19:37,510] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.95664028, 71.89392573, 1.0, 2.0, 0.3991524534548847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 499893.0524077345, 499893.0524077345, 128604.6302443959]
[2019-03-23 22:19:37,511] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:19:37,515] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.9851935e-18 1.0000000e+00 4.3971707e-29 7.8062863e-27 8.9774253e-31], sampled 0.7807575619611336
[2019-03-23 22:19:39,669] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.21464059]
[2019-03-23 22:19:39,671] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.630308845, 68.12952418500001, 1.0, 2.0, 0.4202324757845286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 513819.6602532045, 513819.6602532041, 131332.553584955]
[2019-03-23 22:19:39,674] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:19:39,677] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.9851935e-18 1.0000000e+00 4.3971707e-29 7.8062863e-27 8.9774253e-31], sampled 0.7539079712830781
[2019-03-23 22:19:43,319] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.21464059]
[2019-03-23 22:19:43,320] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.33333333333334, 35.33333333333334, 1.0, 2.0, 0.4368511500374609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 560554.1227332801, 560554.1227332801, 134156.6920596851]
[2019-03-23 22:19:43,322] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:19:43,324] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.9851935e-18 1.0000000e+00 4.3971707e-29 7.8062863e-27 8.9774253e-31], sampled 0.41222448432614955
[2019-03-23 22:19:45,980] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:19:46,157] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:19:46,198] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:19:46,225] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:19:46,239] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:19:47,253] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 750000, evaluation results [750000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:19:48,893] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.2128243e-19 1.0000000e+00 7.9174999e-32 6.4552110e-29 1.2341128e-33], sum to 1.0000
[2019-03-23 22:19:48,900] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5494
[2019-03-23 22:19:48,903] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.66666666666667, 53.0, 1.0, 2.0, 0.5731784497787086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 664224.2060385807, 664224.2060385807, 154053.3338010938], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4299600.0000, 
sim time next is 4300200.0000, 
raw observation next is [30.5, 53.5, 1.0, 2.0, 0.573368872336882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 665099.0963027631, 665099.0963027631, 154115.1713851916], 
processed observation next is [1.0, 0.782608695652174, 0.6851851851851852, 0.535, 1.0, 1.0, 0.49210580040105006, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2375353915367011, 0.2375353915367011, 0.29637532958690693], 
reward next is 0.7036, 
noisyNet noise sample is [array([-0.9251146], dtype=float32), -0.07469974]. 
=============================================
[2019-03-23 22:19:51,011] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.3684686e-23 1.0000000e+00 2.3312871e-37 1.4942616e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 22:19:51,019] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7595
[2019-03-23 22:19:51,023] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 74.0, 1.0, 2.0, 0.6131164073776061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 706066.4528876122, 706066.4528876122, 160707.257370925], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4311600.0000, 
sim time next is 4312200.0000, 
raw observation next is [27.0, 74.0, 1.0, 2.0, 0.6137890269806593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 706835.9890686683, 706835.9890686683, 160824.697162276], 
processed observation next is [1.0, 0.9130434782608695, 0.5555555555555556, 0.74, 1.0, 1.0, 0.5402250321198325, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25244142466738156, 0.25244142466738156, 0.3092782637736077], 
reward next is 0.6907, 
noisyNet noise sample is [array([0.7477025], dtype=float32), -0.22431296]. 
=============================================
[2019-03-23 22:19:54,956] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.1546642e-24 1.0000000e+00 5.9736434e-38 3.1488562e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 22:19:54,964] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1863
[2019-03-23 22:19:54,968] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.06666666666667, 52.33333333333334, 1.0, 2.0, 0.6168310598888093, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 702969.4487421144, 702969.4487421144, 160997.6572482288], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4382400.0000, 
sim time next is 4383000.0000, 
raw observation next is [31.8, 54.0, 1.0, 2.0, 0.6120392844085057, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 697506.0334496059, 697506.0334496059, 160162.1855100003], 
processed observation next is [1.0, 0.7391304347826086, 0.7333333333333334, 0.54, 1.0, 1.0, 0.5381420052482211, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24910929766057355, 0.24910929766057355, 0.3080042029038467], 
reward next is 0.6920, 
noisyNet noise sample is [array([0.9828163], dtype=float32), 0.8523681]. 
=============================================
[2019-03-23 22:19:54,982] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[67.35311]
 [67.35311]
 [67.35311]
 [67.35311]
 [67.35311]], R is [[67.3715744 ]
 [66.69786072]
 [66.03088379]
 [65.53050995]
 [65.04285431]].
[2019-03-23 22:20:00,996] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.9614105e-23 1.0000000e+00 4.2539081e-37 8.1499586e-34 1.3083167e-38], sum to 1.0000
[2019-03-23 22:20:01,006] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0414
[2019-03-23 22:20:01,009] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.45, 97.5, 1.0, 2.0, 0.5952280653484073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 688830.3720403318, 688830.3720403318, 157764.2088866963], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4552200.0000, 
sim time next is 4552800.0000, 
raw observation next is [23.6, 96.66666666666666, 1.0, 2.0, 0.6001114698717955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 693773.8605377077, 693773.8605377077, 158573.8352773736], 
processed observation next is [0.0, 0.6956521739130435, 0.4296296296296297, 0.9666666666666666, 1.0, 1.0, 0.5239422260378518, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24777637876346703, 0.24777637876346703, 0.30494968322571847], 
reward next is 0.6951, 
noisyNet noise sample is [array([0.6031125], dtype=float32), 2.2241287]. 
=============================================
[2019-03-23 22:20:01,039] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4017209e-21 1.0000000e+00 2.5767841e-35 2.2694057e-32 8.4760856e-38], sum to 1.0000
[2019-03-23 22:20:01,049] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7042
[2019-03-23 22:20:01,052] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 90.0, 1.0, 2.0, 0.5758414299129048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 672894.3147900609, 672894.3147900609, 154751.2391499531], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4500000.0000, 
sim time next is 4500600.0000, 
raw observation next is [23.91666666666667, 90.66666666666667, 1.0, 2.0, 0.5763573136752128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 672843.5762632648, 672843.5762632652, 154810.3470945639], 
processed observation next is [0.0, 0.08695652173913043, 0.4413580246913582, 0.9066666666666667, 1.0, 1.0, 0.4956634686609676, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24030127723688027, 0.24030127723688044, 0.29771220595108444], 
reward next is 0.7023, 
noisyNet noise sample is [array([-0.46891055], dtype=float32), -1.0685451]. 
=============================================
[2019-03-23 22:20:11,856] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1652843e-16 1.0000000e+00 1.1204283e-25 1.5641896e-24 9.0461584e-28], sum to 1.0000
[2019-03-23 22:20:11,862] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5548
[2019-03-23 22:20:11,868] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1680342.690288819 W.
[2019-03-23 22:20:11,873] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.5, 97.0, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.900516925036094, 6.9112, 121.9221790645021, 1680342.690288819, 1173740.054088488, 246188.947763924], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4699800.0000, 
sim time next is 4700400.0000, 
raw observation next is [23.66666666666667, 96.0, 1.0, 2.0, 0.6319066263858014, 1.0, 1.0, 0.6319066263858014, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9254468644799, 1440993.885440206, 1440993.885440207, 279189.8176600461], 
processed observation next is [1.0, 0.391304347826087, 0.43209876543209896, 0.96, 1.0, 1.0, 0.5617936028402397, 1.0, 0.5, 0.5617936028402397, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094581736518257, 0.5146406733715021, 0.5146406733715025, 0.5369034955000886], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.07839275], dtype=float32), 0.6948923]. 
=============================================
[2019-03-23 22:20:12,701] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.3645038e-21 1.0000000e+00 8.9442586e-33 5.7976069e-32 1.6115456e-34], sum to 1.0000
[2019-03-23 22:20:12,708] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1597
[2019-03-23 22:20:12,713] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.16666666666667, 92.33333333333333, 1.0, 2.0, 0.5938327677525224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 686058.1673202098, 686058.1673202098, 157470.3687214837], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4758600.0000, 
sim time next is 4759200.0000, 
raw observation next is [24.2, 92.0, 1.0, 2.0, 0.5934103091156503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 685721.1739788963, 685721.1739788959, 157404.8735761999], 
processed observation next is [1.0, 0.08695652173913043, 0.45185185185185184, 0.92, 1.0, 1.0, 0.5159646537091075, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24490041927817727, 0.2449004192781771, 0.3027016799542306], 
reward next is 0.6973, 
noisyNet noise sample is [array([0.50653815], dtype=float32), -0.45744938]. 
=============================================
[2019-03-23 22:20:15,946] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.6949374e-15 1.0000000e+00 1.5636049e-24 1.3922716e-22 8.3637807e-27], sum to 1.0000
[2019-03-23 22:20:15,954] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0296
[2019-03-23 22:20:15,958] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.06666666666667, 87.33333333333334, 1.0, 2.0, 0.7299654123717901, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 831972.6062606806, 831972.6062606806, 181902.6704305693], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4814400.0000, 
sim time next is 4815000.0000, 
raw observation next is [27.8, 89.0, 1.0, 2.0, 0.7232023769345395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 824260.3425712452, 824260.3425712452, 180591.2813770454], 
processed observation next is [1.0, 0.7391304347826086, 0.5851851851851853, 0.89, 1.0, 1.0, 0.670479020160166, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2943786937754447, 0.2943786937754447, 0.34729092572508735], 
reward next is 0.6527, 
noisyNet noise sample is [array([-0.33387882], dtype=float32), 0.58853084]. 
=============================================
[2019-03-23 22:20:15,976] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[39.574406]
 [39.574406]
 [39.574406]
 [39.574406]
 [39.574406]], R is [[39.83136749]
 [40.08324432]
 [40.18482208]
 [40.0725441 ]
 [39.67181778]].
[2019-03-23 22:20:19,250] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.1436134e-23 1.0000000e+00 9.2649553e-36 7.3965183e-33 1.8084254e-38], sum to 1.0000
[2019-03-23 22:20:19,257] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5876
[2019-03-23 22:20:19,262] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1440986.633656215 W.
[2019-03-23 22:20:19,271] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.86666666666667, 93.33333333333334, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.454057462420761, 6.9112, 121.924252405975, 1440986.633656215, 1162999.17452786, 245586.4915850116], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4868400.0000, 
sim time next is 4869000.0000, 
raw observation next is [25.9, 93.5, 1.0, 2.0, 0.4261464242504919, 1.0, 1.0, 0.4261464242504919, 1.0, 1.0, 0.6784389860269041, 6.9112, 6.9112, 121.94756008, 1457686.023775539, 1457686.023775539, 308725.0581002511], 
processed observation next is [1.0, 0.34782608695652173, 0.5148148148148147, 0.935, 1.0, 1.0, 0.3168409812505855, 1.0, 0.5, 0.3168409812505855, 1.0, 0.5, 0.5980487325336301, 0.0, 0.0, 0.8096049824067558, 0.5206021513484067, 0.5206021513484067, 0.5937020348081752], 
reward next is 0.4063, 
noisyNet noise sample is [array([1.60585], dtype=float32), 0.4158456]. 
=============================================
[2019-03-23 22:20:19,299] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[62.861298]
 [62.861298]
 [62.861298]
 [62.861298]
 [62.861298]], R is [[62.63899231]
 [62.01260376]
 [62.00471497]
 [62.02228546]
 [62.02229691]].
[2019-03-23 22:20:20,219] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.5410331e-17 1.0000000e+00 2.7582490e-28 2.0806878e-26 2.4546765e-30], sum to 1.0000
[2019-03-23 22:20:20,227] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6432
[2019-03-23 22:20:20,231] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2069382.014246638 W.
[2019-03-23 22:20:20,239] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.3, 86.5, 1.0, 2.0, 0.9071375441836851, 1.0, 2.0, 0.9071375441836851, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2069382.014246638, 2069382.014246639, 390015.7912333228], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4879800.0000, 
sim time next is 4880400.0000, 
raw observation next is [28.2, 87.33333333333333, 1.0, 2.0, 0.6355776120304651, 1.0, 2.0, 0.6311534679916673, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2159810.424914812, 2159810.424914812, 412377.3087970036], 
processed observation next is [1.0, 0.4782608695652174, 0.6, 0.8733333333333333, 1.0, 1.0, 0.5661638238457918, 1.0, 1.0, 0.5608969857043657, 1.0, 0.5, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7713608660410044, 0.7713608660410044, 0.7930332861480838], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.54508835], dtype=float32), 1.2270123]. 
=============================================
[2019-03-23 22:20:20,424] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.3704488e-16 1.0000000e+00 1.8582563e-26 5.2477023e-24 2.9741753e-28], sum to 1.0000
[2019-03-23 22:20:20,429] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5011
[2019-03-23 22:20:20,434] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2572643.421208617 W.
[2019-03-23 22:20:20,437] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.06666666666667, 73.66666666666667, 1.0, 2.0, 0.8765118284271612, 1.0, 2.0, 0.7516205761900154, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2572643.421208617, 2572643.421208618, 480039.6653430629], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4898400.0000, 
sim time next is 4899000.0000, 
raw observation next is [31.33333333333334, 69.83333333333333, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 8.071096797146874, 6.9112, 121.9214132364434, 2921904.72544097, 2327956.447231371, 443049.810605101], 
processed observation next is [1.0, 0.6956521739130435, 0.7160493827160496, 0.6983333333333333, 1.0, 1.0, 1.0238095238095237, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.25, 0.11598967971468736, 0.0, 0.8094313945563408, 1.0435374019432035, 0.8314130168683468, 0.8520188665482712], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.29736784], dtype=float32), 0.44991404]. 
=============================================
[2019-03-23 22:20:20,455] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[42.287937]
 [42.287937]
 [42.287937]
 [42.287937]
 [42.287937]], R is [[41.8650589 ]
 [41.52325439]
 [41.18080139]
 [40.76899338]
 [40.36130524]].
[2019-03-23 22:20:20,824] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.1872974e-17 1.0000000e+00 1.0228821e-24 7.3937913e-23 4.6412456e-26], sum to 1.0000
[2019-03-23 22:20:20,830] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3609
[2019-03-23 22:20:20,834] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 89.0, 1.0, 2.0, 0.8938659017340929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1018901.142621102, 1018901.142621102, 216110.8488387688], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4906800.0000, 
sim time next is 4907400.0000, 
raw observation next is [29.01666666666667, 88.5, 1.0, 2.0, 0.8937539785571856, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1018773.478659324, 1018773.478659324, 216085.5777361782], 
processed observation next is [1.0, 0.8260869565217391, 0.630246913580247, 0.885, 1.0, 1.0, 0.8735166411395067, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.36384767094975856, 0.36384767094975856, 0.4155491879541889], 
reward next is 0.5845, 
noisyNet noise sample is [array([-0.14463986], dtype=float32), 0.4022834]. 
=============================================
[2019-03-23 22:20:21,083] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2251321e-15 1.0000000e+00 2.1259988e-23 6.5281345e-23 3.5477639e-26], sum to 1.0000
[2019-03-23 22:20:21,093] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6082
[2019-03-23 22:20:21,099] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.03333333333333, 88.0, 1.0, 2.0, 0.8905574222817126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1015127.370278929, 1015127.370278929, 215373.7755569844], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4908000.0000, 
sim time next is 4908600.0000, 
raw observation next is [29.05, 87.5, 1.0, 2.0, 0.8860704450001174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1010009.390021018, 1010009.390021018, 214377.7434731473], 
processed observation next is [1.0, 0.8260869565217391, 0.6314814814814815, 0.875, 1.0, 1.0, 0.8643695773810922, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3607176392932207, 0.3607176392932207, 0.41226489129451405], 
reward next is 0.5877, 
noisyNet noise sample is [array([1.5156994], dtype=float32), -0.7470651]. 
=============================================
[2019-03-23 22:20:21,343] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.2975992e-14 1.0000000e+00 2.9285975e-23 1.7586213e-21 9.1591977e-25], sum to 1.0000
[2019-03-23 22:20:21,351] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2723
[2019-03-23 22:20:21,363] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2557775.372261975 W.
[2019-03-23 22:20:21,367] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.26666666666667, 85.16666666666667, 1.0, 2.0, 0.8678365931993507, 1.0, 2.0, 0.74728295857611, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2557775.372261975, 2557775.372261975, 477385.5684023242], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4896600.0000, 
sim time next is 4897200.0000, 
raw observation next is [30.53333333333334, 81.33333333333334, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 8.987433495225398, 6.9112, 121.9175235758794, 3391711.586598042, 2328568.752964716, 443050.9242083124], 
processed observation next is [1.0, 0.6956521739130435, 0.6864197530864199, 0.8133333333333335, 1.0, 1.0, 1.0238095238095237, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.25, 0.20762334952253977, 0.0, 0.8094055712551578, 1.2113255666421578, 0.8316316974873985, 0.8520210080929085], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3437344], dtype=float32), -0.81177974]. 
=============================================
[2019-03-23 22:20:21,921] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.9258630e-17 1.0000000e+00 4.6580200e-28 2.1907496e-24 7.0967208e-30], sum to 1.0000
[2019-03-23 22:20:21,930] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6349
[2019-03-23 22:20:21,936] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.08333333333333, 87.33333333333334, 1.0, 2.0, 0.6473794475941984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 758828.0958117256, 758828.0958117251, 167414.0158748402], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4939800.0000, 
sim time next is 4940400.0000, 
raw observation next is [24.16666666666666, 85.66666666666667, 1.0, 2.0, 0.5910730658089998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 694801.2615501422, 694801.2615501422, 157526.6407837899], 
processed observation next is [1.0, 0.17391304347826086, 0.45061728395061706, 0.8566666666666667, 1.0, 1.0, 0.5131822212011902, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24814330769647935, 0.24814330769647935, 0.3029358476611344], 
reward next is 0.6971, 
noisyNet noise sample is [array([0.74372655], dtype=float32), -0.7805235]. 
=============================================
[2019-03-23 22:20:26,152] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4613868e-17 1.0000000e+00 6.0332920e-26 1.7046351e-24 1.9656000e-28], sum to 1.0000
[2019-03-23 22:20:26,160] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7586
[2019-03-23 22:20:26,165] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 84.83333333333333, 1.0, 2.0, 0.6683032867126416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 761658.7424722443, 761658.7424722438, 170231.5408242876], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4990200.0000, 
sim time next is 4990800.0000, 
raw observation next is [26.66666666666667, 85.66666666666667, 1.0, 2.0, 0.6852771126488032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 781013.5019618964, 781013.5019618964, 173375.9017401253], 
processed observation next is [1.0, 0.782608695652174, 0.5432098765432101, 0.8566666666666667, 1.0, 1.0, 0.62532989601048, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27893339355782015, 0.27893339355782015, 0.3334151956540871], 
reward next is 0.6666, 
noisyNet noise sample is [array([0.18002042], dtype=float32), 1.6723084]. 
=============================================
[2019-03-23 22:20:31,503] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.9762672e-22 1.0000000e+00 3.3669595e-34 4.3426664e-34 1.6369649e-37], sum to 1.0000
[2019-03-23 22:20:31,512] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5123
[2019-03-23 22:20:31,517] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.53333333333333, 92.66666666666666, 1.0, 2.0, 0.7580870595524846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 864042.109532363, 864042.109532363, 187435.6901162915], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5092800.0000, 
sim time next is 5093400.0000, 
raw observation next is [26.41666666666667, 92.33333333333333, 1.0, 2.0, 0.7511236852671744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 856101.057283507, 856101.057283507, 186050.842514958], 
processed observation next is [0.0, 0.9565217391304348, 0.5339506172839508, 0.9233333333333333, 1.0, 1.0, 0.7037186729371124, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3057503776012525, 0.3057503776012525, 0.35779008175953464], 
reward next is 0.6422, 
noisyNet noise sample is [array([-0.832807], dtype=float32), 0.14398804]. 
=============================================
[2019-03-23 22:20:37,148] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.8228414e-20 1.0000000e+00 4.8288588e-33 9.1745254e-30 2.6903610e-34], sum to 1.0000
[2019-03-23 22:20:37,157] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4692
[2019-03-23 22:20:37,160] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.3, 75.66666666666667, 1.0, 2.0, 0.7473210342891746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 851764.5378037539, 851764.5378037539, 185300.6135372075], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5163600.0000, 
sim time next is 5164200.0000, 
raw observation next is [29.1, 76.5, 1.0, 2.0, 0.7587440689755248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 864791.3692334956, 864791.3692334956, 187567.414122205], 
processed observation next is [0.0, 0.782608695652174, 0.6333333333333334, 0.765, 1.0, 1.0, 0.7127905583041962, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.30885406044053415, 0.30885406044053415, 0.360706565619625], 
reward next is 0.6393, 
noisyNet noise sample is [array([-0.524227], dtype=float32), 1.0103512]. 
=============================================
[2019-03-23 22:20:37,301] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.2691425e-20 1.0000000e+00 2.9008179e-34 2.0736136e-32 1.3161270e-36], sum to 1.0000
[2019-03-23 22:20:37,311] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8515
[2019-03-23 22:20:37,318] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.93333333333333, 94.33333333333334, 1.0, 2.0, 0.7960757998021615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 918808.9241887822, 918808.9241887822, 195720.7210100229], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5199000.0000, 
sim time next is 5199600.0000, 
raw observation next is [23.86666666666667, 94.66666666666667, 1.0, 2.0, 0.743481735958343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 858616.2828746102, 858616.2828746102, 185105.8588264808], 
processed observation next is [1.0, 0.17391304347826086, 0.4395061728395063, 0.9466666666666668, 1.0, 1.0, 0.6946211142361226, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.30664867245521793, 0.30664867245521793, 0.35597280543554], 
reward next is 0.6440, 
noisyNet noise sample is [array([0.66009116], dtype=float32), 0.6101312]. 
=============================================
[2019-03-23 22:20:38,022] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 22:20:38,024] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:20:38,025] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:20:38,025] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:20:38,025] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:20:38,025] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:20:38,027] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:20:38,027] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:20:38,028] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:20:38,027] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:20:38,028] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:20:38,042] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run32
[2019-03-23 22:20:38,043] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run32
[2019-03-23 22:20:38,067] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run32
[2019-03-23 22:20:38,126] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run32
[2019-03-23 22:20:38,126] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run32
[2019-03-23 22:20:39,333] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.2152569]
[2019-03-23 22:20:39,333] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [20.5, 53.0, 1.0, 2.0, 0.2413484525471222, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 311316.4738993663, 311316.4738993663, 93396.34902223057]
[2019-03-23 22:20:39,334] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:20:39,336] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.3431672e-19 1.0000000e+00 2.6781697e-31 7.3086875e-29 4.3231152e-33], sampled 0.2564850362883958
[2019-03-23 22:20:51,349] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.2152569]
[2019-03-23 22:20:51,351] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.3, 64.33333333333333, 1.0, 2.0, 0.3372723778732112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 426681.3902147502, 426681.3902147507, 120279.9532595161]
[2019-03-23 22:20:51,351] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:20:51,353] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.3431672e-19 1.0000000e+00 2.6781697e-31 7.3086875e-29 4.3231152e-33], sampled 0.20896986361457948
[2019-03-23 22:20:55,825] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.2152569]
[2019-03-23 22:20:55,826] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.66666666666667, 45.66666666666667, 1.0, 2.0, 0.3497209899701348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 438572.0361077664, 438572.036107766, 121862.6369855273]
[2019-03-23 22:20:55,828] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:20:55,830] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.3431672e-19 1.0000000e+00 2.6781697e-31 7.3086875e-29 4.3231152e-33], sampled 0.633786399931511
[2019-03-23 22:20:58,580] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.2152569]
[2019-03-23 22:20:58,580] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.66666666666667, 28.66666666666667, 1.0, 2.0, 0.4241811962089002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 518932.2165107781, 518932.2165107781, 131910.0632163515]
[2019-03-23 22:20:58,582] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:20:58,584] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.3431672e-19 1.0000000e+00 2.6781697e-31 7.3086875e-29 4.3231152e-33], sampled 0.7709370390302622
[2019-03-23 22:21:06,741] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.2152569]
[2019-03-23 22:21:06,744] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.0, 74.0, 1.0, 2.0, 0.7454874307774219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 857758.8402809446, 857758.8402809446, 185344.7032168765]
[2019-03-23 22:21:06,745] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:21:06,748] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.3431672e-19 1.0000000e+00 2.6781697e-31 7.3086875e-29 4.3231152e-33], sampled 0.9734123391124817
[2019-03-23 22:22:00,799] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.2152569]
[2019-03-23 22:22:00,802] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.0, 74.0, 1.0, 2.0, 0.7062819834298246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 804965.4211426543, 804965.4211426543, 177338.9618875176]
[2019-03-23 22:22:00,803] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:22:00,805] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.3431672e-19 1.0000000e+00 2.6781697e-31 7.3086875e-29 4.3231152e-33], sampled 0.6050581720232543
[2019-03-23 22:22:12,859] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.2152569]
[2019-03-23 22:22:12,861] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.83333333333334, 21.66666666666666, 1.0, 2.0, 0.3404708493577979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 438523.4571682009, 438523.4571682009, 120712.9658073875]
[2019-03-23 22:22:12,862] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:22:12,865] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.3431672e-19 1.0000000e+00 2.6781697e-31 7.3086875e-29 4.3231152e-33], sampled 0.6344806295496145
[2019-03-23 22:22:19,518] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:22:19,570] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:22:19,769] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:22:19,808] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:22:19,869] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:22:20,884] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 775000, evaluation results [775000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:22:23,042] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.2507813e-15 1.0000000e+00 3.1692864e-24 9.1180103e-21 8.7915922e-26], sum to 1.0000
[2019-03-23 22:22:23,053] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3018
[2019-03-23 22:22:23,062] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.48333333333334, 85.33333333333334, 1.0, 2.0, 0.6459977723131314, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 755605.9060927734, 755605.9060927734, 167092.3842392854], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5285400.0000, 
sim time next is 5286000.0000, 
raw observation next is [24.36666666666667, 85.66666666666667, 1.0, 2.0, 0.5969400178968303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 699229.489376084, 699229.489376084, 158435.5283891289], 
processed observation next is [1.0, 0.17391304347826086, 0.4580246913580248, 0.8566666666666667, 1.0, 1.0, 0.5201666879724169, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2497248176343157, 0.2497248176343157, 0.3046837084406325], 
reward next is 0.6953, 
noisyNet noise sample is [array([0.28305537], dtype=float32), -0.3858316]. 
=============================================
[2019-03-23 22:22:23,085] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[38.312065]
 [38.312065]
 [38.312065]
 [38.312065]
 [38.312065]], R is [[38.62425613]
 [38.9166832 ]
 [39.19720459]
 [39.47208786]
 [39.73803711]].
[2019-03-23 22:22:24,191] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.5819413e-22 1.0000000e+00 7.0261250e-36 2.5330381e-32 1.7858182e-36], sum to 1.0000
[2019-03-23 22:22:24,197] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0683
[2019-03-23 22:22:24,204] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 87.0, 1.0, 2.0, 0.5583365039067092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 657704.8431916254, 657704.8431916254, 152036.4902211149], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5288400.0000, 
sim time next is 5289000.0000, 
raw observation next is [23.8, 87.33333333333333, 1.0, 2.0, 0.6303335009479755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 743322.3166025099, 743322.3166025095, 164527.3993608841], 
processed observation next is [1.0, 0.21739130434782608, 0.43703703703703706, 0.8733333333333333, 1.0, 1.0, 0.5599208344618756, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2654722559294678, 0.26547225592946766, 0.3163988449247771], 
reward next is 0.6836, 
noisyNet noise sample is [array([-0.06215482], dtype=float32), -0.16038941]. 
=============================================
[2019-03-23 22:22:24,218] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[63.03821]
 [63.03821]
 [63.03821]
 [63.03821]
 [63.03821]], R is [[63.09142685]
 [63.1681366 ]
 [63.24290848]
 [63.31411362]
 [63.3798027 ]].
[2019-03-23 22:22:35,307] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2998779e-18 1.0000000e+00 5.4935346e-29 1.6544074e-26 4.0596153e-31], sum to 1.0000
[2019-03-23 22:22:35,312] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0115
[2019-03-23 22:22:35,318] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3142098.573303244 W.
[2019-03-23 22:22:35,324] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.66666666666667, 67.0, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 9.377166493979333, 6.9112, 121.9161950716144, 3142098.573303244, 1879405.314399036, 375459.593308353], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5491200.0000, 
sim time next is 5491800.0000, 
raw observation next is [32.84999999999999, 66.0, 1.0, 2.0, 1.02, 1.0, 1.0, 0.8247331184476033, 1.0, 2.0, 0.9977734948820727, 6.917297603052059, 6.9112, 121.94756008, 2823288.510275591, 2820165.441454545, 526553.649772196], 
processed observation next is [1.0, 0.5652173913043478, 0.7722222222222217, 0.66, 1.0, 1.0, 1.0238095238095237, 1.0, 0.5, 0.7913489505328611, 1.0, 1.0, 0.9972168686025908, 0.0006097603052059419, 0.0, 0.8096049824067558, 1.0083173250984254, 1.0072019433766233, 1.0126031726388385], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.48574686], dtype=float32), -1.6673489]. 
=============================================
[2019-03-23 22:22:35,633] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.4704684e-16 1.0000000e+00 6.9766969e-26 1.6777977e-24 4.8048548e-28], sum to 1.0000
[2019-03-23 22:22:35,639] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4428
[2019-03-23 22:22:35,644] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.68333333333333, 81.0, 1.0, 2.0, 0.6450543857391037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 735149.4907193028, 735149.4907193028, 166002.0244800266], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5512200.0000, 
sim time next is 5512800.0000, 
raw observation next is [26.66666666666667, 81.0, 1.0, 2.0, 0.6484318111595867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 739000.4984548968, 739000.4984548968, 166610.0651199895], 
processed observation next is [1.0, 0.8260869565217391, 0.5432098765432101, 0.81, 1.0, 1.0, 0.5814664418566509, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26392874944817746, 0.26392874944817746, 0.3204039713845952], 
reward next is 0.6796, 
noisyNet noise sample is [array([-1.2391249], dtype=float32), -1.1880038]. 
=============================================
[2019-03-23 22:22:38,399] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.8760711e-22 1.0000000e+00 1.4031125e-35 1.3035595e-30 1.0308433e-36], sum to 1.0000
[2019-03-23 22:22:38,407] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9638
[2019-03-23 22:22:38,414] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.58333333333334, 92.16666666666667, 1.0, 2.0, 0.6826702856655315, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 778040.9812904111, 778040.9812904111, 172888.8807714418], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5533800.0000, 
sim time next is 5534400.0000, 
raw observation next is [25.56666666666667, 92.33333333333334, 1.0, 2.0, 0.6825650015436391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 777920.9278310253, 777920.9278310253, 172869.2976015942], 
processed observation next is [1.0, 0.043478260869565216, 0.5024691358024692, 0.9233333333333335, 1.0, 1.0, 0.6221011923138561, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2778289027967948, 0.2778289027967948, 0.3324409569261427], 
reward next is 0.6676, 
noisyNet noise sample is [array([2.4844866], dtype=float32), 1.0031149]. 
=============================================
[2019-03-23 22:22:44,249] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.1969931e-24 1.0000000e+00 0.0000000e+00 6.3406742e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 22:22:44,259] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6670
[2019-03-23 22:22:44,263] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 97.0, 1.0, 2.0, 0.5851781625409374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 677183.3846719526, 677183.3846719526, 156042.5433568091], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5632200.0000, 
sim time next is 5632800.0000, 
raw observation next is [23.5, 97.0, 1.0, 2.0, 0.5847347191477948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 676671.177473789, 676671.177473789, 155967.0633027043], 
processed observation next is [0.0, 0.17391304347826086, 0.42592592592592593, 0.97, 1.0, 1.0, 0.5056365704140414, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24166827766921034, 0.24166827766921034, 0.2999366601975083], 
reward next is 0.7001, 
noisyNet noise sample is [array([-0.7356839], dtype=float32), 1.8816969]. 
=============================================
[2019-03-23 22:22:47,713] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.9454775e-24 1.0000000e+00 1.7197498e-38 1.3952345e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 22:22:47,720] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5200
[2019-03-23 22:22:47,727] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.81666666666667, 70.33333333333333, 1.0, 2.0, 0.7178737749471283, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 818183.8974090284, 818183.8974090284, 179558.2774629252], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5669400.0000, 
sim time next is 5670000.0000, 
raw observation next is [29.9, 70.0, 1.0, 2.0, 0.7189754695985917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 819440.2055553322, 819440.2055553318, 179770.4475636678], 
processed observation next is [0.0, 0.6521739130434783, 0.6629629629629629, 0.7, 1.0, 1.0, 0.6654469876173711, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2926572162697615, 0.2926572162697613, 0.34571239916089963], 
reward next is 0.6543, 
noisyNet noise sample is [array([-0.5505438], dtype=float32), 1.374648]. 
=============================================
[2019-03-23 22:22:47,754] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[67.23731]
 [67.23731]
 [67.23731]
 [67.23731]
 [67.23731]], R is [[67.21923828]
 [67.20173645]
 [67.18478394]
 [67.16834259]
 [67.15242004]].
[2019-03-23 22:22:50,126] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.0488717e-22 1.0000000e+00 5.3568291e-36 1.6176818e-32 0.0000000e+00], sum to 1.0000
[2019-03-23 22:22:50,132] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3155
[2019-03-23 22:22:50,134] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.7, 72.66666666666666, 1.0, 2.0, 0.5745127976273015, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 668100.2815706743, 668100.2815706738, 154383.4699041044], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5769600.0000, 
sim time next is 5770200.0000, 
raw observation next is [26.55, 73.33333333333334, 1.0, 2.0, 0.5726167971785852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 666428.8495832073, 666428.8495832073, 154087.5604409867], 
processed observation next is [0.0, 0.782608695652174, 0.5388888888888889, 0.7333333333333334, 1.0, 1.0, 0.491210472831649, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23801030342257404, 0.23801030342257404, 0.2963222316172821], 
reward next is 0.7037, 
noisyNet noise sample is [array([0.26303256], dtype=float32), 0.82670647]. 
=============================================
[2019-03-23 22:22:53,701] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.35974853e-22 1.00000000e+00 0.00000000e+00 1.08675895e-35
 0.00000000e+00], sum to 1.0000
[2019-03-23 22:22:53,708] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7735
[2019-03-23 22:22:53,713] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.15, 86.5, 1.0, 2.0, 0.7380901568190914, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 122.0023338734303, 897684.3164881194, 897684.3164881194, 185933.2123159912], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5796600.0000, 
sim time next is 5797200.0000, 
raw observation next is [22.1, 87.0, 1.0, 2.0, 0.6382600076096098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 775884.5248766068, 775884.5248766068, 166814.1259252875], 
processed observation next is [1.0, 0.08695652173913043, 0.3740740740740741, 0.87, 1.0, 1.0, 0.5693571519162021, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27710161602735955, 0.27710161602735955, 0.32079639601016824], 
reward next is 0.6792, 
noisyNet noise sample is [array([-0.3188836], dtype=float32), -1.2254431]. 
=============================================
[2019-03-23 22:22:54,097] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.921812e-24 1.000000e+00 0.000000e+00 8.263239e-37 0.000000e+00], sum to 1.0000
[2019-03-23 22:22:54,106] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7675
[2019-03-23 22:22:54,113] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.58333333333334, 84.0, 1.0, 2.0, 0.4617530168423958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 560754.3700962414, 560754.3700962414, 137353.2290221266], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5813400.0000, 
sim time next is 5814000.0000, 
raw observation next is [22.7, 83.0, 1.0, 2.0, 0.494434776103294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 600588.0397331796, 600588.0397331796, 142392.2541816408], 
processed observation next is [1.0, 0.30434782608695654, 0.39629629629629626, 0.83, 1.0, 1.0, 0.3981366382182071, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21449572847613557, 0.21449572847613557, 0.27383125804161695], 
reward next is 0.7262, 
noisyNet noise sample is [array([-0.4007311], dtype=float32), -0.2480844]. 
=============================================
[2019-03-23 22:22:54,132] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[68.19014]
 [68.19014]
 [68.19014]
 [68.19014]
 [68.19014]], R is [[68.23440552]
 [68.28792572]
 [68.34081268]
 [68.39191437]
 [68.43987274]].
[2019-03-23 22:23:03,808] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.9515747e-22 1.0000000e+00 1.6543359e-36 7.2415847e-36 3.9092680e-37], sum to 1.0000
[2019-03-23 22:23:03,816] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4779
[2019-03-23 22:23:03,822] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1747443.445446793 W.
[2019-03-23 22:23:03,825] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.0, 55.5, 1.0, 2.0, 0.8937125314085386, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9859143778309677, 6.9112, 6.9112, 121.9260426156618, 1747443.445446793, 1747443.445446793, 353739.34580408], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6022200.0000, 
sim time next is 6022800.0000, 
raw observation next is [29.0, 55.0, 1.0, 2.0, 0.8772269361928452, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9832420192825365, 6.9112, 6.9112, 121.9260426156618, 1731658.697315611, 1731658.697315611, 349725.4233604786], 
processed observation next is [1.0, 0.7391304347826086, 0.6296296296296297, 0.55, 1.0, 1.0, 0.853841590705768, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9790525241031706, 0.0, 0.0, 0.8094621288201359, 0.6184495347555753, 0.6184495347555753, 0.6725488910778434], 
reward next is 0.3275, 
noisyNet noise sample is [array([0.9600938], dtype=float32), -0.44932032]. 
=============================================
[2019-03-23 22:23:05,253] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.10567245e-20 1.00000000e+00 1.13416420e-31 5.45375475e-30
 2.33720438e-33], sum to 1.0000
[2019-03-23 22:23:05,263] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3973
[2019-03-23 22:23:05,268] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.73333333333333, 56.33333333333334, 1.0, 2.0, 0.5030112118080212, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 590951.0436544542, 590951.0436544542, 143014.849754718], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6024000.0000, 
sim time next is 6024600.0000, 
raw observation next is [28.6, 57.0, 1.0, 2.0, 0.4935141165144537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 583809.7897692163, 583809.7897692163, 141696.4173844966], 
processed observation next is [1.0, 0.7391304347826086, 0.6148148148148148, 0.57, 1.0, 1.0, 0.3970406148981592, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20850349634614868, 0.20850349634614868, 0.27249311035480117], 
reward next is 0.7275, 
noisyNet noise sample is [array([-0.47144097], dtype=float32), 0.74005604]. 
=============================================
[2019-03-23 22:23:08,888] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.383596e-19 1.000000e+00 5.152318e-29 9.910213e-26 9.284159e-30], sum to 1.0000
[2019-03-23 22:23:08,898] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1864
[2019-03-23 22:23:08,901] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.23333333333333, 58.33333333333334, 1.0, 2.0, 0.5407416798844841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 629779.0875301999, 629779.0875301999, 148824.7013062343], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6112200.0000, 
sim time next is 6112800.0000, 
raw observation next is [29.1, 59.0, 1.0, 2.0, 0.546801509053385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 636819.9633317654, 636819.9633317654, 149814.8501126455], 
processed observation next is [1.0, 0.782608695652174, 0.6333333333333334, 0.59, 1.0, 1.0, 0.46047798696831543, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2274357011899162, 0.2274357011899162, 0.28810548098585675], 
reward next is 0.7119, 
noisyNet noise sample is [array([0.32137495], dtype=float32), 0.84633374]. 
=============================================
[2019-03-23 22:23:10,844] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.1031882e-26 1.0000000e+00 0.0000000e+00 2.4142619e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 22:23:10,850] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4491
[2019-03-23 22:23:10,854] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2210917.069539506 W.
[2019-03-23 22:23:10,856] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.53333333333333, 51.66666666666667, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9974262671616954, 7.559669454461427, 6.9112, 121.9235117723198, 2210917.069539506, 1878849.642246431, 381756.8821548807], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6099600.0000, 
sim time next is 6100200.0000, 
raw observation next is [30.5, 52.0, 1.0, 2.0, 0.607049339904556, 1.0, 1.0, 0.607049339904556, 1.0, 2.0, 0.9664423193448232, 6.9112, 6.9112, 121.94756008, 2077230.04673685, 2077230.04673685, 399229.8155744946], 
processed observation next is [1.0, 0.6086956521739131, 0.6851851851851852, 0.52, 1.0, 1.0, 0.5322015951244714, 1.0, 0.5, 0.5322015951244714, 1.0, 1.0, 0.9580528991810289, 0.0, 0.0, 0.8096049824067558, 0.7418678738345893, 0.7418678738345893, 0.7677496453355666], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.68579215], dtype=float32), -0.21506968]. 
=============================================
[2019-03-23 22:23:11,633] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 22:23:11,635] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:23:11,637] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:23:11,637] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:23:11,639] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:23:11,639] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:23:11,639] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:23:11,640] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:23:11,642] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:23:11,644] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:23:11,646] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:23:11,657] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run33
[2019-03-23 22:23:11,682] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run33
[2019-03-23 22:23:11,707] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run33
[2019-03-23 22:23:11,731] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run33
[2019-03-23 22:23:11,753] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run33
[2019-03-23 22:23:29,335] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.21259561]
[2019-03-23 22:23:29,336] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [32.2, 28.0, 1.0, 2.0, 0.3827186275622323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 476456.5017274228, 476456.5017274223, 126259.0244789302]
[2019-03-23 22:23:29,337] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:23:29,341] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.738993e-23 1.000000e+00 8.501704e-37 6.387222e-34 0.000000e+00], sampled 0.47879944649019657
[2019-03-23 22:23:47,926] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.21259561]
[2019-03-23 22:23:47,928] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.86666666666667, 54.66666666666666, 1.0, 2.0, 0.7312190424790237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 869284.599869317, 869284.599869317, 183812.4506216194]
[2019-03-23 22:23:47,929] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:23:47,932] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.738993e-23 1.000000e+00 8.501704e-37 6.387222e-34 0.000000e+00], sampled 0.6468108019307891
[2019-03-23 22:23:47,958] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.21259561]
[2019-03-23 22:23:47,960] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.6, 94.5, 1.0, 2.0, 0.5220497696496712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 618425.2814407742, 618425.2814407737, 146240.6419127463]
[2019-03-23 22:23:47,961] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:23:47,964] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.738993e-23 1.000000e+00 8.501704e-37 6.387222e-34 0.000000e+00], sampled 0.9164881453123986
[2019-03-23 22:24:07,371] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.21259561]
[2019-03-23 22:24:07,371] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.84807428333333, 80.10296665, 1.0, 2.0, 0.6152170885429096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 713993.0989939718, 713993.0989939718, 161333.8130485926]
[2019-03-23 22:24:07,372] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:24:07,377] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.738993e-23 1.000000e+00 8.501704e-37 6.387222e-34 0.000000e+00], sampled 0.7355803680206895
[2019-03-23 22:24:17,502] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.21259561]
[2019-03-23 22:24:17,504] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.36585819666667, 72.81973641666667, 1.0, 2.0, 0.5205830690440651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 619627.6553938014, 619627.6553938019, 146118.1871350487]
[2019-03-23 22:24:17,505] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:24:17,509] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.738993e-23 1.000000e+00 8.501704e-37 6.387222e-34 0.000000e+00], sampled 0.4697409924218079
[2019-03-23 22:24:37,190] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.21259561]
[2019-03-23 22:24:37,192] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.91666666666666, 84.66666666666667, 1.0, 2.0, 0.5933022242103118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 703100.3280404354, 703100.3280404354, 158144.0170964675]
[2019-03-23 22:24:37,193] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:24:37,195] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.738993e-23 1.000000e+00 8.501704e-37 6.387222e-34 0.000000e+00], sampled 0.6020384187893666
[2019-03-23 22:24:53,059] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:24:53,109] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:24:53,125] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:24:53,164] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:24:53,263] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:24:54,278] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 800000, evaluation results [800000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:24:59,944] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.872354e-24 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:24:59,953] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8305
[2019-03-23 22:24:59,959] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 62.0, 1.0, 2.0, 0.6564065692819193, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 748093.5532803336, 748093.5532803336, 168054.1020020975], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6278400.0000, 
sim time next is 6279000.0000, 
raw observation next is [30.05, 61.66666666666667, 1.0, 2.0, 0.6520641757221268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 743142.2144709263, 743142.2144709263, 167266.529138787], 
processed observation next is [0.0, 0.6956521739130435, 0.6685185185185185, 0.6166666666666667, 1.0, 1.0, 0.5857906853834843, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2654079337396165, 0.2654079337396165, 0.321666402189975], 
reward next is 0.6783, 
noisyNet noise sample is [array([0.7826499], dtype=float32), -0.99892664]. 
=============================================
[2019-03-23 22:24:59,980] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[75.64728]
 [75.64728]
 [75.64728]
 [75.64728]
 [75.64728]], R is [[75.5691452 ]
 [75.49027252]
 [75.41282654]
 [75.33670044]
 [75.26174927]].
[2019-03-23 22:25:02,358] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.9937128e-25 1.0000000e+00 0.0000000e+00 1.1424457e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 22:25:02,365] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0527
[2019-03-23 22:25:02,370] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 65.5, 1.0, 2.0, 0.6310399585035453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 719170.1683390286, 719170.1683390286, 163498.5566848642], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6269400.0000, 
sim time next is 6270000.0000, 
raw observation next is [29.13333333333333, 65.0, 1.0, 2.0, 0.6383574784904393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 727513.6008994087, 727513.6008994087, 164801.0142750754], 
processed observation next is [0.0, 0.5652173913043478, 0.6345679012345677, 0.65, 1.0, 1.0, 0.5694731886790945, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2598262860355031, 0.2598262860355031, 0.3169250274520681], 
reward next is 0.6831, 
noisyNet noise sample is [array([0.24754946], dtype=float32), 0.5094592]. 
=============================================
[2019-03-23 22:25:02,385] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[76.02452]
 [76.02452]
 [76.02452]
 [76.02452]
 [76.02452]], R is [[75.94734955]
 [75.87345123]
 [75.80090332]
 [75.72949982]
 [75.6582489 ]].
[2019-03-23 22:25:05,916] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.2696094e-21 1.0000000e+00 8.6910129e-36 1.7028085e-32 3.0400746e-36], sum to 1.0000
[2019-03-23 22:25:05,923] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5035
[2019-03-23 22:25:05,930] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.5, 62.5, 1.0, 2.0, 0.6934148345098675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 790292.882577947, 790292.882577947, 174900.8381789582], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6352200.0000, 
sim time next is 6352800.0000, 
raw observation next is [30.66666666666666, 61.33333333333333, 1.0, 2.0, 0.6908142164125136, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 787327.405879724, 787327.405879724, 174411.8493553651], 
processed observation next is [0.0, 0.5217391304347826, 0.6913580246913578, 0.6133333333333333, 1.0, 1.0, 0.6319216862053734, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28118835924275853, 0.28118835924275853, 0.33540740260647134], 
reward next is 0.6646, 
noisyNet noise sample is [array([-1.4967363], dtype=float32), -1.1717716]. 
=============================================
[2019-03-23 22:25:12,301] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.2147890e-19 1.0000000e+00 6.7140629e-32 3.0134945e-29 2.6164666e-33], sum to 1.0000
[2019-03-23 22:25:12,308] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4703
[2019-03-23 22:25:12,312] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.63333333333333, 76.0, 1.0, 2.0, 0.6644040016231963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 757212.5702492299, 757212.5702492299, 169513.5720693338], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6481200.0000, 
sim time next is 6481800.0000, 
raw observation next is [27.55, 76.5, 1.0, 2.0, 0.6653070274408106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 758242.2460146851, 758242.2460146851, 169678.9873844772], 
processed observation next is [1.0, 0.0, 0.575925925925926, 0.765, 1.0, 1.0, 0.601555985048584, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2708008021481018, 0.2708008021481018, 0.32630574497014847], 
reward next is 0.6737, 
noisyNet noise sample is [array([-1.1793131], dtype=float32), 0.8635862]. 
=============================================
[2019-03-23 22:25:20,675] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.6227102e-22 1.0000000e+00 2.6938617e-35 7.9810248e-33 4.1061713e-37], sum to 1.0000
[2019-03-23 22:25:20,681] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1519
[2019-03-23 22:25:20,687] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.15, 45.0, 1.0, 2.0, 0.3597305583793834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 449362.2901478652, 449362.2901478652, 123164.6250053176], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6633000.0000, 
sim time next is 6633600.0000, 
raw observation next is [26.86666666666667, 46.0, 1.0, 2.0, 0.3589380057718724, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 448650.6400469532, 448650.6400469532, 123063.5945996087], 
processed observation next is [1.0, 0.782608695652174, 0.5506172839506175, 0.46, 1.0, 1.0, 0.23683095925222905, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16023237144534044, 0.16023237144534044, 0.23666075884540133], 
reward next is 0.7633, 
noisyNet noise sample is [array([-0.49133372], dtype=float32), 0.24285293]. 
=============================================
[2019-03-23 22:25:23,408] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.022059e-24 1.000000e+00 0.000000e+00 6.893277e-36 0.000000e+00], sum to 1.0000
[2019-03-23 22:25:23,420] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3064
[2019-03-23 22:25:23,425] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.65, 49.5, 1.0, 2.0, 0.5153395514461533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 659140.0654743013, 659140.0654743013, 146323.5384411184], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6683400.0000, 
sim time next is 6684000.0000, 
raw observation next is [23.86666666666667, 48.66666666666667, 1.0, 2.0, 0.5830821874468506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 745291.6307558148, 745291.6307558148, 157706.2213339739], 
processed observation next is [1.0, 0.34782608695652173, 0.4395061728395063, 0.4866666666666667, 1.0, 1.0, 0.5036692707700602, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.266175582412791, 0.266175582412791, 0.30328119487302674], 
reward next is 0.6967, 
noisyNet noise sample is [array([-0.8142107], dtype=float32), -0.57209986]. 
=============================================
[2019-03-23 22:25:23,439] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[75.03899]
 [75.03899]
 [75.03899]
 [75.03899]
 [75.03899]], R is [[74.98531342]
 [74.95406342]
 [74.93672943]
 [74.9458313 ]
 [74.97306061]].
[2019-03-23 22:25:26,031] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.0708272e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:25:26,038] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6796
[2019-03-23 22:25:26,047] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.76666666666667, 56.33333333333334, 1.0, 2.0, 0.3381966808812994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 427442.6685877579, 427442.6685877574, 120396.0520851918], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6729600.0000, 
sim time next is 6730200.0000, 
raw observation next is [23.5, 58.0, 1.0, 2.0, 0.3386406212434675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 427872.992096235, 427872.992096235, 120452.4574831554], 
processed observation next is [1.0, 0.9130434782608695, 0.42592592592592593, 0.58, 1.0, 1.0, 0.21266740624222322, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15281178289151248, 0.15281178289151248, 0.2316393413137604], 
reward next is 0.7684, 
noisyNet noise sample is [array([-1.5210147], dtype=float32), -0.11559759]. 
=============================================
[2019-03-23 22:25:26,344] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.2703622e-23 1.0000000e+00 2.3587393e-38 1.2453426e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 22:25:26,351] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3721
[2019-03-23 22:25:26,359] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 36.0, 1.0, 2.0, 0.3307463195899598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 418583.0269753035, 418583.0269753035, 119436.1038861451], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6720000.0000, 
sim time next is 6720600.0000, 
raw observation next is [27.75, 37.0, 1.0, 2.0, 0.3293980115863752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 416837.1849485876, 416837.1849485871, 119261.9650607295], 
processed observation next is [1.0, 0.782608695652174, 0.5833333333333334, 0.37, 1.0, 1.0, 0.20166429950758955, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14887042319592414, 0.14887042319592397, 0.2293499328090952], 
reward next is 0.7707, 
noisyNet noise sample is [array([-0.3829711], dtype=float32), -1.725907]. 
=============================================
[2019-03-23 22:25:41,989] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.9894991e-25 1.0000000e+00 5.3108624e-37 8.3655014e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 22:25:41,990] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9774
[2019-03-23 22:25:41,993] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.9, 64.5, 1.0, 2.0, 0.9293716395018738, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.928897204776264, 6.9112, 121.925856299293, 1109087.888742106, 1100025.351987016, 226199.6333816813], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7043400.0000, 
sim time next is 7044000.0000, 
raw observation next is [27.06666666666667, 63.66666666666666, 1.0, 2.0, 0.9980525018019851, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.388061852322027, 6.9112, 121.9242173707863, 1429415.045213553, 1185222.811032498, 242728.8332193679], 
processed observation next is [1.0, 0.5217391304347826, 0.5580246913580248, 0.6366666666666666, 1.0, 1.0, 0.997681549764268, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.04768618523220267, 0.0, 0.8094500110922834, 0.5105053732905546, 0.423293861083035, 0.46678621772955364], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.27829185], dtype=float32), 1.037653]. 
=============================================
[2019-03-23 22:25:42,026] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[66.50836]
 [66.50836]
 [66.50836]
 [66.50836]
 [66.50836]], R is [[65.84327698]
 [65.66136169]
 [65.51728058]
 [65.27947235]
 [65.01480103]].
[2019-03-23 22:25:42,122] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.1695657e-22 1.0000000e+00 1.4424154e-35 4.6611034e-32 5.4899923e-37], sum to 1.0000
[2019-03-23 22:25:42,129] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6799
[2019-03-23 22:25:42,134] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 84.33333333333334, 1.0, 2.0, 0.5534337162727762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 682420.0236321852, 682420.0236321852, 152247.6667799015], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7010400.0000, 
sim time next is 7011000.0000, 
raw observation next is [21.4, 85.0, 1.0, 2.0, 0.5237679697484855, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 646038.6670032215, 646038.6670032215, 147347.3002302395], 
processed observation next is [1.0, 0.13043478260869565, 0.3481481481481481, 0.85, 1.0, 1.0, 0.43305710684343507, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2307280953582934, 0.2307280953582934, 0.28336019275046054], 
reward next is 0.7166, 
noisyNet noise sample is [array([1.6542332], dtype=float32), -0.97054726]. 
=============================================
[2019-03-23 22:25:42,152] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[64.94703]
 [64.94703]
 [64.94703]
 [64.94703]
 [64.94703]], R is [[65.01419067]
 [65.07126617]
 [65.10444641]
 [65.1523819 ]
 [65.20727539]].
[2019-03-23 22:25:45,131] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 22:25:45,132] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:25:45,133] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:25:45,133] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:25:45,134] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:25:45,135] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:25:45,135] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:25:45,137] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:25:45,139] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:25:45,140] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:25:45,140] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:25:45,147] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run34
[2019-03-23 22:25:45,148] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run34
[2019-03-23 22:25:45,202] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run34
[2019-03-23 22:25:45,203] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run34
[2019-03-23 22:25:45,232] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run34
[2019-03-23 22:26:13,403] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.18236281]
[2019-03-23 22:26:13,405] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.33333333333333, 54.16666666666666, 1.0, 2.0, 0.3543536917163542, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 447401.4695133361, 447401.4695133361, 122519.3128557499]
[2019-03-23 22:26:13,405] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:26:13,407] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.9362747e-24 1.0000000e+00 0.0000000e+00 3.5405396e-36 0.0000000e+00], sampled 0.4225685033812061
[2019-03-23 22:26:31,526] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.18236281]
[2019-03-23 22:26:31,527] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.92177907, 64.87418582, 1.0, 2.0, 0.7013667250514837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 799360.4697152664, 799360.4697152664, 176406.6635705081]
[2019-03-23 22:26:31,528] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:26:31,532] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.9362747e-24 1.0000000e+00 0.0000000e+00 3.5405396e-36 0.0000000e+00], sampled 0.24232641079565165
[2019-03-23 22:27:23,546] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.18236281]
[2019-03-23 22:27:23,549] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [20.33333333333334, 53.0, 1.0, 2.0, 0.2287848934617113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 295107.5637821522, 295107.5637821522, 90739.23134357198]
[2019-03-23 22:27:23,550] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:27:23,553] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.9362747e-24 1.0000000e+00 0.0000000e+00 3.5405396e-36 0.0000000e+00], sampled 0.6256028225545847
[2019-03-23 22:27:26,058] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:27:26,096] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:27:26,209] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:27:26,505] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:27:26,544] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:27:27,562] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 825000, evaluation results [825000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:27:41,943] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.5276522e-24 1.0000000e+00 2.4473841e-37 1.9868271e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 22:27:41,952] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8983
[2019-03-23 22:27:41,958] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.9, 92.0, 1.0, 2.0, 0.3860642692205717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 480713.7688052358, 480713.7688052353, 126723.4578125791], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7358400.0000, 
sim time next is 7359000.0000, 
raw observation next is [19.83333333333333, 92.66666666666667, 1.0, 2.0, 0.389325659880913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 484670.1151306499, 484670.1151306499, 127174.1003318763], 
processed observation next is [1.0, 0.17391304347826086, 0.2901234567901233, 0.9266666666666667, 1.0, 1.0, 0.27300673795346786, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1730964696895178, 0.1730964696895178, 0.24456557756130057], 
reward next is 0.7554, 
noisyNet noise sample is [array([-1.3361583], dtype=float32), -0.8401569]. 
=============================================
[2019-03-23 22:27:41,973] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[73.79494]
 [73.79494]
 [73.79494]
 [73.79494]
 [73.79494]], R is [[73.81242371]
 [73.83060455]
 [73.84745789]
 [73.86267853]
 [73.87293243]].
[2019-03-23 22:27:49,540] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9987000e-24 1.0000000e+00 1.2032433e-37 2.6258916e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 22:27:49,549] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4343
[2019-03-23 22:27:49,558] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.96666666666667, 93.33333333333334, 1.0, 2.0, 0.3790467052541288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 470591.9665960503, 470591.9665960503, 125726.9518179108], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7456800.0000, 
sim time next is 7457400.0000, 
raw observation next is [20.05, 93.0, 1.0, 2.0, 0.3807605642615335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 472427.6494417031, 472427.6494417036, 125956.0463352067], 
processed observation next is [0.0, 0.30434782608695654, 0.29814814814814816, 0.93, 1.0, 1.0, 0.2628101955494446, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16872416051489397, 0.16872416051489414, 0.24222316602924365], 
reward next is 0.7578, 
noisyNet noise sample is [array([-1.4274824], dtype=float32), -0.12427301]. 
=============================================
[2019-03-23 22:27:49,601] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.688013e-24 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:27:49,609] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6132
[2019-03-23 22:27:49,615] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.61666666666667, 85.33333333333334, 1.0, 2.0, 0.5053624576827138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 601213.4193547318, 601213.4193547318, 143682.6583547848], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7498200.0000, 
sim time next is 7498800.0000, 
raw observation next is [23.5, 86.0, 1.0, 2.0, 0.5039846648111316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 599858.3117616738, 599858.3117616738, 143475.924496233], 
processed observation next is [0.0, 0.8260869565217391, 0.42592592592592593, 0.86, 1.0, 1.0, 0.40950555334658517, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2142351113434549, 0.2142351113434549, 0.2759152394158327], 
reward next is 0.7241, 
noisyNet noise sample is [array([0.4874002], dtype=float32), -0.12517548]. 
=============================================
[2019-03-23 22:27:50,500] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.9860987e-23 1.0000000e+00 3.3581532e-38 1.8552960e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 22:27:50,506] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5670
[2019-03-23 22:27:50,511] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.1, 93.0, 1.0, 2.0, 0.4797784848120001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 576138.363140538, 576138.363140538, 139893.4372406062], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7509600.0000, 
sim time next is 7510200.0000, 
raw observation next is [22.05, 93.33333333333333, 1.0, 2.0, 0.4789473946605188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 575275.3882957068, 575275.3882957068, 139770.3168073402], 
processed observation next is [0.0, 0.9565217391304348, 0.37222222222222223, 0.9333333333333332, 1.0, 1.0, 0.3796992793577605, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2054554958198953, 0.2054554958198953, 0.2687890707833465], 
reward next is 0.7312, 
noisyNet noise sample is [array([0.7398235], dtype=float32), 0.7659612]. 
=============================================
[2019-03-23 22:27:52,004] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4986355e-25 1.0000000e+00 0.0000000e+00 6.5399244e-38 0.0000000e+00], sum to 1.0000
[2019-03-23 22:27:52,014] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8017
[2019-03-23 22:27:52,019] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 84.66666666666667, 1.0, 2.0, 0.4944272570502453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 589003.7397275171, 589003.7397275171, 141996.2653553995], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7554000.0000, 
sim time next is 7554600.0000, 
raw observation next is [23.85, 84.0, 1.0, 2.0, 0.4987379226910527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 593153.3766666291, 593153.3766666291, 142633.6857086556], 
processed observation next is [0.0, 0.43478260869565216, 0.43888888888888894, 0.84, 1.0, 1.0, 0.4032594317750628, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21184049166665325, 0.21184049166665325, 0.2742955494397223], 
reward next is 0.7257, 
noisyNet noise sample is [array([0.15973993], dtype=float32), -0.79584557]. 
=============================================
[2019-03-23 22:27:56,968] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.1315861e-23 1.0000000e+00 1.2479569e-38 3.9280174e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 22:27:56,975] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6103
[2019-03-23 22:27:56,978] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.6, 86.0, 1.0, 2.0, 0.5150312062905343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 611955.31023649, 611955.3102364895, 145188.9921875501], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7596000.0000, 
sim time next is 7596600.0000, 
raw observation next is [23.53333333333333, 86.33333333333334, 1.0, 2.0, 0.5131846528772571, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 609952.2743056498, 609952.2743056498, 144901.901314837], 
processed observation next is [0.0, 0.9565217391304348, 0.4271604938271604, 0.8633333333333334, 1.0, 1.0, 0.42045792009197275, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2178400979663035, 0.2178400979663035, 0.2786575025285327], 
reward next is 0.7213, 
noisyNet noise sample is [array([0.4490077], dtype=float32), 0.3402172]. 
=============================================
[2019-03-23 22:28:02,776] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.7555574e-20 1.0000000e+00 1.8118264e-34 7.5622146e-35 6.0244269e-37], sum to 1.0000
[2019-03-23 22:28:02,783] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4261
[2019-03-23 22:28:02,790] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 74.0, 1.0, 2.0, 0.3593850072072591, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 450932.9640814707, 450932.9640814702, 123152.5108845496], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7772400.0000, 
sim time next is 7773000.0000, 
raw observation next is [21.56666666666667, 74.0, 1.0, 2.0, 0.3571414395547314, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 448336.9595614985, 448336.9595614981, 122855.8789257629], 
processed observation next is [1.0, 1.0, 0.35432098765432113, 0.74, 1.0, 1.0, 0.2346921899461088, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16012034270053518, 0.16012034270053502, 0.2362613056264671], 
reward next is 0.7637, 
noisyNet noise sample is [array([-1.5575817], dtype=float32), -0.53864586]. 
=============================================
[2019-03-23 22:28:02,814] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[61.67541]
 [61.67541]
 [61.67541]
 [61.67541]
 [61.67541]], R is [[61.82239914]
 [61.96734238]
 [62.11018753]
 [62.2508812 ]
 [62.3894043 ]].
[2019-03-23 22:28:05,212] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.7957611e-23 1.0000000e+00 7.7963919e-38 3.4182076e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 22:28:05,218] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7559
[2019-03-23 22:28:05,222] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.9, 39.83333333333334, 1.0, 2.0, 0.8968735362193834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.996812825068583, 6.9112, 121.9252617956623, 1156469.264726601, 1112628.127066477, 220594.2181453687], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7816200.0000, 
sim time next is 7816800.0000, 
raw observation next is [29.0, 39.66666666666667, 1.0, 2.0, 0.8924153589572067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.964645472524498, 6.9112, 121.9256508928163, 1134027.397907147, 1106658.627002888, 219563.0662955604], 
processed observation next is [1.0, 0.4782608695652174, 0.6296296296296297, 0.3966666666666667, 1.0, 1.0, 0.871923046377627, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.005344547252449772, 0.0, 0.8094595281878049, 0.4050097849668382, 0.3952352239296028, 0.42223666595300074], 
reward next is 0.3105, 
noisyNet noise sample is [array([0.9363469], dtype=float32), 0.24240865]. 
=============================================
[2019-03-23 22:28:06,277] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.01681256e-25 1.00000000e+00 0.00000000e+00 2.26025070e-37
 0.00000000e+00], sum to 1.0000
[2019-03-23 22:28:06,284] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3586
[2019-03-23 22:28:06,290] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 45.0, 1.0, 2.0, 0.6994051783957708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 878810.0531719858, 878810.0531719858, 179015.9257511076], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7808400.0000, 
sim time next is 7809000.0000, 
raw observation next is [26.7, 44.66666666666666, 1.0, 2.0, 0.789921555677525, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 991383.7297552191, 991383.7297552191, 197336.0990504744], 
processed observation next is [1.0, 0.391304347826087, 0.5444444444444444, 0.44666666666666655, 1.0, 1.0, 0.7499066139018155, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3540656177697211, 0.3540656177697211, 0.3794924981739893], 
reward next is 0.6205, 
noisyNet noise sample is [array([-0.6476115], dtype=float32), 1.034359]. 
=============================================
[2019-03-23 22:28:06,301] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[74.41396]
 [74.41396]
 [74.41396]
 [74.41396]
 [74.41396]], R is [[74.29032898]
 [74.20316315]
 [74.10925293]
 [74.0222168 ]
 [73.94206238]].
[2019-03-23 22:28:09,499] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.4684283e-24 1.0000000e+00 0.0000000e+00 3.4967593e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 22:28:09,507] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4627
[2019-03-23 22:28:09,513] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.63333333333334, 70.33333333333334, 1.0, 2.0, 0.4166806008635534, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 513086.9481972565, 513086.9481972561, 130917.6006172168], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7860000.0000, 
sim time next is 7860600.0000, 
raw observation next is [23.55, 71.0, 1.0, 2.0, 0.4169201163570789, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 513243.0188625465, 513243.0188625469, 130948.4967771164], 
processed observation next is [1.0, 1.0, 0.4277777777777778, 0.71, 1.0, 1.0, 0.30585728137747487, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18330107816519517, 0.1833010781651953, 0.2518240322636854], 
reward next is 0.7482, 
noisyNet noise sample is [array([0.82924855], dtype=float32), 0.37675846]. 
=============================================
[2019-03-23 22:28:13,101] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:28:13,102] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:28:13,118] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run5
[2019-03-23 22:28:13,581] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:28:13,582] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:28:13,594] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run5
[2019-03-23 22:28:13,981] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:28:13,981] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:28:13,982] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run5
[2019-03-23 22:28:14,073] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:28:14,074] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:28:14,075] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run5
[2019-03-23 22:28:14,247] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:28:14,247] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:28:14,248] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run5
[2019-03-23 22:28:14,291] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:28:14,291] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:28:14,292] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run5
[2019-03-23 22:28:14,405] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:28:14,405] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:28:14,405] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:28:14,407] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:28:14,407] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run5
[2019-03-23 22:28:14,406] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run5
[2019-03-23 22:28:14,473] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:28:14,473] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:28:14,474] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run5
[2019-03-23 22:28:14,553] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:28:14,553] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:28:14,554] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run5
[2019-03-23 22:28:14,598] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:28:14,598] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:28:14,601] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run5
[2019-03-23 22:28:14,640] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:28:14,641] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:28:14,644] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run5
[2019-03-23 22:28:14,841] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:28:14,841] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:28:14,842] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run5
[2019-03-23 22:28:15,037] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:28:15,037] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:28:15,039] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run5
[2019-03-23 22:28:15,130] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:28:15,131] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:28:15,131] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:28:15,131] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:28:15,133] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run5
[2019-03-23 22:28:15,134] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run5
[2019-03-23 22:28:19,943] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 22:28:19,946] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:28:19,947] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:28:19,948] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:28:19,949] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:28:19,950] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:28:19,950] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:28:19,950] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:28:19,950] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:28:19,952] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:28:19,955] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:28:19,968] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run35
[2019-03-23 22:28:19,991] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run35
[2019-03-23 22:28:20,014] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run35
[2019-03-23 22:28:20,038] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run35
[2019-03-23 22:28:20,062] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run35
[2019-03-23 22:28:38,457] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.16620687]
[2019-03-23 22:28:38,458] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.68769216, 67.96929243000001, 1.0, 2.0, 0.4216414188336809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 520239.0799755419, 520239.0799755419, 131657.8556959247]
[2019-03-23 22:28:38,459] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:28:38,463] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.3830722e-21 1.0000000e+00 1.5725456e-34 7.8245418e-32 1.5361747e-36], sampled 0.07923470130321064
[2019-03-23 22:28:45,711] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.16620687]
[2019-03-23 22:28:45,712] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.4, 91.0, 1.0, 2.0, 0.5885209161140984, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9369444652417793, 6.911199999999999, 6.9112, 121.9260426156618, 1341970.839474673, 1341970.839474673, 289419.1698271949]
[2019-03-23 22:28:45,713] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:28:45,716] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.3830722e-21 1.0000000e+00 1.5725456e-34 7.8245418e-32 1.5361747e-36], sampled 0.4552747533095407
[2019-03-23 22:28:45,717] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1341970.839474673 W.
[2019-03-23 22:28:53,079] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.16620687]
[2019-03-23 22:28:53,081] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.0, 62.0, 1.0, 2.0, 0.6494028261770165, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 740107.6726990705, 740107.6726990701, 166785.5238975726]
[2019-03-23 22:28:53,083] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:28:53,085] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.3830722e-21 1.0000000e+00 1.5725456e-34 7.8245418e-32 1.5361747e-36], sampled 0.47526321695892504
[2019-03-23 22:29:18,504] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.16620687]
[2019-03-23 22:29:18,506] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.682330225, 108.6411544666667, 1.0, 2.0, 0.7214374955693649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 842666.5216108013, 842666.5216108009, 181238.9312523736]
[2019-03-23 22:29:18,507] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:29:18,509] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.3830722e-21 1.0000000e+00 1.5725456e-34 7.8245418e-32 1.5361747e-36], sampled 0.6774357736410184
[2019-03-23 22:29:36,360] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.16620687]
[2019-03-23 22:29:36,361] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.84437953, 78.04421606833334, 1.0, 2.0, 0.4544189553970416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 547902.551931041, 547902.551931041, 136123.1923588162]
[2019-03-23 22:29:36,362] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:29:36,367] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.3830722e-21 1.0000000e+00 1.5725456e-34 7.8245418e-32 1.5361747e-36], sampled 0.861512118640315
[2019-03-23 22:29:39,210] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.16620687]
[2019-03-23 22:29:39,211] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.10741128333333, 63.57279936333333, 1.0, 2.0, 0.6516496153271666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 742669.5208557775, 742669.5208557775, 167189.0513463866]
[2019-03-23 22:29:39,212] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:29:39,215] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.3830722e-21 1.0000000e+00 1.5725456e-34 7.8245418e-32 1.5361747e-36], sampled 0.22903474286381176
[2019-03-23 22:29:42,202] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.16620687]
[2019-03-23 22:29:42,203] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.46666666666667, 84.33333333333333, 1.0, 2.0, 0.9724708545281541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.975057375932082, 6.9112, 121.9257931018817, 1141290.562281011, 1108589.945216129, 234147.2466569286]
[2019-03-23 22:29:42,204] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:29:42,206] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.3830722e-21 1.0000000e+00 1.5725456e-34 7.8245418e-32 1.5361747e-36], sampled 0.34752987453519424
[2019-03-23 22:29:53,457] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.16620687]
[2019-03-23 22:29:53,458] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.85, 61.5, 1.0, 2.0, 0.7444976246274113, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9713699058418759, 6.911199999999999, 6.9112, 121.9260426156618, 1591750.073685785, 1591750.073685785, 320275.5162106222]
[2019-03-23 22:29:53,459] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:29:53,464] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.3830722e-21 1.0000000e+00 1.5725456e-34 7.8245418e-32 1.5361747e-36], sampled 0.8241207693982723
[2019-03-23 22:29:53,465] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1591750.073685785 W.
[2019-03-23 22:30:02,159] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:30:02,178] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:30:02,190] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:30:02,223] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:30:02,254] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:30:03,272] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 850000, evaluation results [850000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:30:03,562] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.1784562e-25 1.0000000e+00 0.0000000e+00 2.5725327e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 22:30:03,571] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0774
[2019-03-23 22:30:03,576] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 68.66666666666667, 1.0, 2.0, 0.4178592707776346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 513859.7290058789, 513859.7290058789, 131069.6960763919], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 87000.0000, 
sim time next is 87600.0000, 
raw observation next is [23.9, 69.33333333333334, 1.0, 2.0, 0.4187074376357676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 514863.4061783089, 514863.4061783089, 131190.7346649135], 
processed observation next is [1.0, 0.0, 0.4407407407407407, 0.6933333333333335, 1.0, 1.0, 0.3079850448044853, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1838797879208246, 0.1838797879208246, 0.2522898743556029], 
reward next is 0.7477, 
noisyNet noise sample is [array([0.25181952], dtype=float32), 0.6367682]. 
=============================================
[2019-03-23 22:30:05,033] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.6595717e-25 1.0000000e+00 0.0000000e+00 2.6733261e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 22:30:05,041] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9751
[2019-03-23 22:30:05,046] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.8, 75.66666666666667, 1.0, 2.0, 0.4734609056314353, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 591121.4249751779, 591121.4249751779, 139541.0516963475], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 108600.0000, 
sim time next is 109200.0000, 
raw observation next is [21.9, 75.33333333333334, 1.0, 2.0, 0.4419581945037776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 551364.3081173487, 551364.3081173487, 134765.1217413146], 
processed observation next is [1.0, 0.2608695652173913, 0.36666666666666664, 0.7533333333333334, 1.0, 1.0, 0.3356645172664019, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19691582432762453, 0.19691582432762453, 0.2591636956563742], 
reward next is 0.7408, 
noisyNet noise sample is [array([-1.2375141], dtype=float32), -0.56157905]. 
=============================================
[2019-03-23 22:30:06,199] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.8284484e-20 1.0000000e+00 7.2254846e-32 6.3976997e-29 3.6524584e-34], sum to 1.0000
[2019-03-23 22:30:06,205] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4315
[2019-03-23 22:30:06,211] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1452114.886288842 W.
[2019-03-23 22:30:06,216] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [35.48333333333333, 22.5, 1.0, 2.0, 0.9695843402276676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.420600071988284, 6.9112, 121.9238138492032, 1452114.886288842, 1191261.288170987, 237390.3782509715], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 133800.0000, 
sim time next is 134400.0000, 
raw observation next is [35.86666666666667, 21.0, 1.0, 2.0, 0.5739217973635947, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9345638603354856, 6.9112, 6.9112, 121.9257358211462, 1395625.954740006, 1395625.954740006, 281155.4867877257], 
processed observation next is [1.0, 0.5652173913043478, 0.8839506172839506, 0.21, 1.0, 1.0, 0.4927640444804699, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.918204825419357, 0.0, 0.0, 0.8094600920235961, 0.4984378409785736, 0.4984378409785736, 0.540683628437934], 
reward next is 0.4593, 
noisyNet noise sample is [array([1.6866974], dtype=float32), -0.8789555]. 
=============================================
[2019-03-23 22:30:15,687] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.5139948e-27 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:30:15,693] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7575
[2019-03-23 22:30:15,697] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.18333333333334, 31.33333333333334, 1.0, 2.0, 0.3019658243479986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 389526.9560194542, 389526.9560194537, 104171.1181702362], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 294600.0000, 
sim time next is 295200.0000, 
raw observation next is [25.3, 31.0, 1.0, 2.0, 0.3035775758634591, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 391606.5985065402, 391606.5985065402, 104585.8759045465], 
processed observation next is [0.0, 0.43478260869565216, 0.49259259259259264, 0.31, 1.0, 1.0, 0.17092568555173707, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1398594994666215, 0.1398594994666215, 0.2011266844318202], 
reward next is 0.7989, 
noisyNet noise sample is [array([-1.239922], dtype=float32), 0.887796]. 
=============================================
[2019-03-23 22:30:22,776] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.0766893e-28 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:30:22,785] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9876
[2019-03-23 22:30:22,789] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.61666666666667, 48.33333333333334, 1.0, 2.0, 0.2839230686992681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 364102.4156461105, 364102.4156461105, 113612.2763638125], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 432600.0000, 
sim time next is 433200.0000, 
raw observation next is [23.33333333333333, 49.66666666666667, 1.0, 2.0, 0.2812480034565267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 360744.083524652, 360744.083524652, 113289.824296186], 
processed observation next is [1.0, 0.0, 0.4197530864197529, 0.4966666666666667, 1.0, 1.0, 0.14434286125776985, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1288371726873757, 0.1288371726873757, 0.2178650467234346], 
reward next is 0.7821, 
noisyNet noise sample is [array([0.73509467], dtype=float32), 0.33954844]. 
=============================================
[2019-03-23 22:30:23,520] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.4165370e-26 1.0000000e+00 0.0000000e+00 1.2448486e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 22:30:23,527] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8090
[2019-03-23 22:30:23,531] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.3, 66.0, 1.0, 2.0, 0.3020816470514685, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 388455.2767675213, 388455.2767675213, 115828.9057334496], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 454800.0000, 
sim time next is 455400.0000, 
raw observation next is [20.6, 64.5, 1.0, 2.0, 0.3006372982534543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 386370.5165437894, 386370.5165437894, 115651.3918582249], 
processed observation next is [1.0, 0.2608695652173913, 0.3185185185185186, 0.645, 1.0, 1.0, 0.1674253550636361, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1379894701942105, 0.1379894701942105, 0.22240652280427867], 
reward next is 0.7776, 
noisyNet noise sample is [array([-0.05308731], dtype=float32), -0.6132864]. 
=============================================
[2019-03-23 22:30:41,598] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.1024118e-23 1.0000000e+00 7.9063430e-37 2.1189903e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 22:30:41,605] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8426
[2019-03-23 22:30:41,612] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 46.0, 1.0, 2.0, 0.2986784466325717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 380901.0263434874, 380901.0263434874, 115411.623355802], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 781200.0000, 
sim time next is 781800.0000, 
raw observation next is [24.63333333333333, 46.66666666666667, 1.0, 2.0, 0.2984204782003076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 380646.3701127513, 380646.3701127513, 115380.0484747366], 
processed observation next is [0.0, 0.043478260869565216, 0.46790123456790106, 0.46666666666666673, 1.0, 1.0, 0.16478628357179476, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13594513218312548, 0.13594513218312548, 0.2218847086052627], 
reward next is 0.7781, 
noisyNet noise sample is [array([-0.2788436], dtype=float32), -0.18003686]. 
=============================================
[2019-03-23 22:30:44,062] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3029413e-25 1.0000000e+00 0.0000000e+00 1.1828819e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 22:30:44,067] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5567
[2019-03-23 22:30:44,074] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.6, 36.0, 1.0, 2.0, 0.4375625764082148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 533357.961743245, 533357.9617432447, 133807.727560049], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 828000.0000, 
sim time next is 828600.0000, 
raw observation next is [31.63333333333334, 36.0, 1.0, 2.0, 0.4386806803826455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 534682.4530451639, 534682.4530451634, 133971.1909387408], 
processed observation next is [0.0, 0.6086956521739131, 0.7271604938271607, 0.36, 1.0, 1.0, 0.33176271474124464, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19095801894470138, 0.1909580189447012, 0.2576369056514246], 
reward next is 0.7424, 
noisyNet noise sample is [array([-0.55397403], dtype=float32), 0.42606428]. 
=============================================
[2019-03-23 22:30:44,091] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.8323055e-25 1.0000000e+00 0.0000000e+00 2.1071872e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 22:30:44,102] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5496
[2019-03-23 22:30:44,105] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 36.0, 1.0, 2.0, 0.4504749478692116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 546567.4251511313, 546567.4251511313, 135644.6369051602], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 835200.0000, 
sim time next is 835800.0000, 
raw observation next is [31.9, 36.16666666666666, 1.0, 2.0, 0.4537412715369987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 550720.5457848082, 550720.5457848082, 136138.4788622179], 
processed observation next is [0.0, 0.6956521739130435, 0.7370370370370369, 0.3616666666666666, 1.0, 1.0, 0.34969198992499845, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1966859092088601, 0.1966859092088601, 0.2618047670427267], 
reward next is 0.7382, 
noisyNet noise sample is [array([0.2962657], dtype=float32), 2.0392027]. 
=============================================
[2019-03-23 22:30:53,998] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 22:30:53,999] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:30:54,000] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:30:54,003] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:30:54,004] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:30:54,005] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:30:54,005] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:30:54,006] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:30:54,005] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:30:54,009] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:30:54,010] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:30:54,023] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run36
[2019-03-23 22:30:54,047] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run36
[2019-03-23 22:30:54,073] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run36
[2019-03-23 22:30:54,074] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run36
[2019-03-23 22:30:54,074] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run36
[2019-03-23 22:30:55,776] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.15941894]
[2019-03-23 22:30:55,777] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.9, 69.33333333333334, 1.0, 2.0, 0.4187074376357676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 514863.4061783089, 514863.4061783089, 131190.7346649135]
[2019-03-23 22:30:55,777] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:30:55,779] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.9926971e-20 1.0000000e+00 8.4368204e-32 2.7527293e-29 1.0705891e-33], sampled 0.7695945807213866
[2019-03-23 22:30:58,146] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.15941894]
[2019-03-23 22:30:58,146] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [18.7, 50.0, 1.0, 2.0, 0.2143575321179176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 276494.4866160102, 276494.4866160102, 80718.23629514602]
[2019-03-23 22:30:58,148] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:30:58,153] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.9926971e-20 1.0000000e+00 8.4368204e-32 2.7527293e-29 1.0705891e-33], sampled 0.5534089022434031
[2019-03-23 22:31:21,949] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.15941894]
[2019-03-23 22:31:21,950] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.91666666666666, 46.0, 1.0, 2.0, 0.3921545519535379, 0.0, 2.0, 0.0, 1.0, 1.0, 0.6243228182921589, 6.9112, 6.9112, 121.9256928614441, 893946.5448646215, 893946.5448646215, 221692.2445126094]
[2019-03-23 22:31:21,951] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:31:21,954] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.9926971e-20 1.0000000e+00 8.4368204e-32 2.7527293e-29 1.0705891e-33], sampled 0.23893555615669881
[2019-03-23 22:31:38,215] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.15941894]
[2019-03-23 22:31:38,218] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.021952925, 110.74922035, 1.0, 2.0, 0.6907438199249957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 787247.1331442468, 787247.1331442468, 174395.717252041]
[2019-03-23 22:31:38,219] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:31:38,224] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.9926971e-20 1.0000000e+00 8.4368204e-32 2.7527293e-29 1.0705891e-33], sampled 0.6435069850802669
[2019-03-23 22:31:48,977] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.15941894]
[2019-03-23 22:31:48,979] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.26666666666667, 86.0, 1.0, 2.0, 0.533890771557858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 626668.5594932464, 626668.5594932464, 147921.0232217129]
[2019-03-23 22:31:48,980] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:31:48,982] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.9926971e-20 1.0000000e+00 8.4368204e-32 2.7527293e-29 1.0705891e-33], sampled 0.9924772212745223
[2019-03-23 22:32:10,530] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.15941894]
[2019-03-23 22:32:10,532] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [30.56666666666667, 51.33333333333333, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9953227907816927, 7.210125914826163, 6.9112, 121.9248107784237, 2034336.810782927, 1881261.571254749, 382732.6464031473]
[2019-03-23 22:32:10,534] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:32:10,538] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.9926971e-20 1.0000000e+00 8.4368204e-32 2.7527293e-29 1.0705891e-33], sampled 0.8781012420555101
[2019-03-23 22:32:10,539] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2034336.810782927 W.
[2019-03-23 22:32:35,971] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:32:35,989] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.15941894]
[2019-03-23 22:32:35,990] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [30.1, 49.33333333333333, 1.0, 2.0, 0.8871717112043944, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9809220115683647, 6.911199999999999, 6.9112, 121.9260426156618, 1746193.339979459, 1746193.339979459, 351428.9236358193]
[2019-03-23 22:32:35,990] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:32:35,993] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.9926971e-20 1.0000000e+00 8.4368204e-32 2.7527293e-29 1.0705891e-33], sampled 0.6005881134054214
[2019-03-23 22:32:35,994] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1746193.339979459 W.
[2019-03-23 22:32:36,163] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:32:36,222] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:32:36,237] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:32:36,285] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:32:37,300] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 875000, evaluation results [875000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:32:37,813] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.2414397e-23 1.0000000e+00 2.2485743e-35 1.0744771e-31 1.0680824e-37], sum to 1.0000
[2019-03-23 22:32:37,818] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4566
[2019-03-23 22:32:37,822] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.86666666666667, 45.66666666666667, 1.0, 2.0, 0.283599328486754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 364448.2163075392, 364448.2163075387, 113570.1640885162], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1025400.0000, 
sim time next is 1026000.0000, 
raw observation next is [23.8, 46.0, 1.0, 2.0, 0.2813335952649243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 361536.5445528952, 361536.5445528952, 113297.2900388053], 
processed observation next is [1.0, 0.9130434782608695, 0.43703703703703706, 0.46, 1.0, 1.0, 0.144444756267767, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.12912019448317685, 0.12912019448317685, 0.21787940392077942], 
reward next is 0.7821, 
noisyNet noise sample is [array([2.4653513], dtype=float32), 0.9593343]. 
=============================================
[2019-03-23 22:32:37,839] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[63.430264]
 [63.430264]
 [63.430264]
 [63.430264]
 [63.430264]], R is [[63.57807922]
 [63.72389603]
 [63.86800385]
 [64.01088715]
 [64.15241241]].
[2019-03-23 22:32:38,096] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.218819e-25 1.000000e+00 0.000000e+00 7.354252e-35 0.000000e+00], sum to 1.0000
[2019-03-23 22:32:38,104] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7660
[2019-03-23 22:32:38,111] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.8, 60.83333333333333, 1.0, 2.0, 0.2914746753599091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 372597.1801059906, 372597.1801059901, 114529.8535325865], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1041000.0000, 
sim time next is 1041600.0000, 
raw observation next is [21.7, 61.66666666666667, 1.0, 2.0, 0.2931517914525069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 374625.1071875871, 374625.1071875871, 114734.6547046735], 
processed observation next is [1.0, 0.043478260869565216, 0.3592592592592592, 0.6166666666666667, 1.0, 1.0, 0.15851403744346063, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13379468113842397, 0.13379468113842397, 0.22064356673975674], 
reward next is 0.7794, 
noisyNet noise sample is [array([1.2654605], dtype=float32), -0.040668473]. 
=============================================
[2019-03-23 22:32:40,663] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.6793257e-23 1.0000000e+00 7.3019218e-35 6.7955319e-34 1.7055541e-37], sum to 1.0000
[2019-03-23 22:32:40,669] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0225
[2019-03-23 22:32:40,675] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.6, 49.66666666666667, 1.0, 2.0, 0.7309433882101711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 926247.6950631535, 926247.695063153, 185345.3833767014], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1077600.0000, 
sim time next is 1078200.0000, 
raw observation next is [24.75, 49.0, 1.0, 2.0, 0.6948153596145006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 880315.3116276244, 880315.3116276244, 178221.4463350992], 
processed observation next is [1.0, 0.4782608695652174, 0.4722222222222222, 0.49, 1.0, 1.0, 0.6366849519220245, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31439832558129444, 0.31439832558129444, 0.3427335506444215], 
reward next is 0.6573, 
noisyNet noise sample is [array([0.9820197], dtype=float32), -0.43899193]. 
=============================================
[2019-03-23 22:32:44,158] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.3464616e-25 1.0000000e+00 0.0000000e+00 5.9911763e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 22:32:44,166] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5432
[2019-03-23 22:32:44,177] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.7, 73.5, 1.0, 2.0, 0.2962103541894389, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 379304.7682267186, 379304.7682267186, 115109.7623481342], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1117800.0000, 
sim time next is 1118400.0000, 
raw observation next is [19.56666666666667, 74.0, 1.0, 2.0, 0.2953102950494908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 378375.5765610061, 378375.5765610057, 114998.9415741707], 
processed observation next is [1.0, 0.9565217391304348, 0.28024691358024706, 0.74, 1.0, 1.0, 0.16108368458272715, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1351341344860736, 0.13513413448607348, 0.22115181071955906], 
reward next is 0.7788, 
noisyNet noise sample is [array([-0.5572694], dtype=float32), 0.79179496]. 
=============================================
[2019-03-23 22:32:47,000] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.2358521e-23 1.0000000e+00 8.4030770e-36 9.1444485e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 22:32:47,010] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9201
[2019-03-23 22:32:47,022] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.73333333333333, 85.66666666666667, 1.0, 2.0, 0.3490734893922977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 439767.5672368614, 439767.5672368614, 121806.5436229757], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1197600.0000, 
sim time next is 1198200.0000, 
raw observation next is [19.66666666666667, 86.33333333333333, 1.0, 2.0, 0.3498409242758189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 440654.1275842112, 440654.1275842107, 121906.9728249534], 
processed observation next is [1.0, 0.8695652173913043, 0.28395061728395077, 0.8633333333333333, 1.0, 1.0, 0.22600110032835585, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15737647413721828, 0.15737647413721811, 0.23443648620183344], 
reward next is 0.7656, 
noisyNet noise sample is [array([0.33666462], dtype=float32), 0.5754853]. 
=============================================
[2019-03-23 22:32:52,059] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4904266e-24 1.0000000e+00 0.0000000e+00 2.3715637e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 22:32:52,066] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8636
[2019-03-23 22:32:52,069] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.36666666666667, 54.33333333333334, 1.0, 2.0, 0.8968631967564702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.949636644281515, 6.9112, 121.9259060754741, 1123556.081792774, 1103873.106534572, 220349.7553134629], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1268400.0000, 
sim time next is 1269000.0000, 
raw observation next is [26.4, 54.0, 1.0, 2.0, 0.8948967008835816, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.939268186590716, 6.9112, 121.9257588952599, 1116323.250805084, 1101949.864011359, 219914.8619855865], 
processed observation next is [1.0, 0.6956521739130435, 0.5333333333333333, 0.54, 1.0, 1.0, 0.8748770248614067, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0028068186590716414, 0.0, 0.8094602452117158, 0.39868687528752994, 0.3935535228611996, 0.4229131961261279], 
reward next is 0.4367, 
noisyNet noise sample is [array([-0.36037993], dtype=float32), -0.8740771]. 
=============================================
[2019-03-23 22:32:52,103] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[80.43656]
 [80.43656]
 [80.43656]
 [80.43656]
 [80.43656]], R is [[80.06894684]
 [79.65232086]
 [78.85579681]
 [78.06723785]
 [77.28656769]].
[2019-03-23 22:32:58,277] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.2984714e-24 1.0000000e+00 0.0000000e+00 3.2015163e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 22:32:58,286] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4762
[2019-03-23 22:32:58,289] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.7, 63.0, 1.0, 2.0, 0.2764673211313113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 355623.7935002372, 355623.7935002368, 112712.1638729917], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1396800.0000, 
sim time next is 1397400.0000, 
raw observation next is [20.66666666666667, 62.5, 1.0, 2.0, 0.2734326294460934, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 352006.4417327219, 352006.4417327219, 112348.6290890305], 
processed observation next is [0.0, 0.17391304347826086, 0.3209876543209878, 0.625, 1.0, 1.0, 0.13503884457868265, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.12571658633311497, 0.12571658633311497, 0.21605505594044325], 
reward next is 0.7839, 
noisyNet noise sample is [array([-0.56422067], dtype=float32), -1.0050746]. 
=============================================
[2019-03-23 22:33:03,092] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3630248e-25 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:33:03,102] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9478
[2019-03-23 22:33:03,108] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.15, 54.5, 1.0, 2.0, 0.4054184345289536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 500985.9900546509, 500985.9900546505, 129354.2485811834], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1495800.0000, 
sim time next is 1496400.0000, 
raw observation next is [26.46666666666667, 53.33333333333334, 1.0, 2.0, 0.4079832901260756, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 503606.2401907527, 503606.2401907523, 129705.2929200334], 
processed observation next is [0.0, 0.30434782608695654, 0.5358024691358025, 0.5333333333333334, 1.0, 1.0, 0.29521820253104236, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1798593714966974, 0.17985937149669726, 0.24943325561544885], 
reward next is 0.7506, 
noisyNet noise sample is [array([-0.42491096], dtype=float32), -0.24462533]. 
=============================================
[2019-03-23 22:33:08,687] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.6510014e-21 1.0000000e+00 6.2490690e-36 7.1812847e-36 2.6590120e-38], sum to 1.0000
[2019-03-23 22:33:08,696] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1513
[2019-03-23 22:33:08,701] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.28333333333333, 59.5, 1.0, 2.0, 0.4761600767704681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 600996.2996991322, 600996.2996991322, 140058.6553953462], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1583400.0000, 
sim time next is 1584000.0000, 
raw observation next is [23.5, 58.0, 1.0, 2.0, 0.4654693249692302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 587727.384973065, 587727.384973065, 138415.862803162], 
processed observation next is [1.0, 0.34782608695652173, 0.42592592592592593, 0.58, 1.0, 1.0, 0.3636539582967026, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20990263749038035, 0.20990263749038035, 0.2661843515445423], 
reward next is 0.7338, 
noisyNet noise sample is [array([0.8525077], dtype=float32), 0.58954126]. 
=============================================
[2019-03-23 22:33:08,732] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[69.492645]
 [69.492645]
 [69.492645]
 [69.492645]
 [69.492645]], R is [[69.53154755]
 [69.56689453]
 [69.60642242]
 [69.66122437]
 [69.7201767 ]].
[2019-03-23 22:33:16,113] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.7196909e-23 1.0000000e+00 6.3623349e-37 5.1724906e-34 2.4670768e-38], sum to 1.0000
[2019-03-23 22:33:16,114] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6384
[2019-03-23 22:33:16,120] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 79.0, 1.0, 2.0, 0.3890610876070346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 483903.291445818, 483903.2914458176, 127128.3079422943], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1724400.0000, 
sim time next is 1725000.0000, 
raw observation next is [21.56666666666667, 79.16666666666667, 1.0, 2.0, 0.3856533383508959, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 479862.4062007632, 479862.4062007628, 126659.6453676212], 
processed observation next is [1.0, 1.0, 0.35432098765432113, 0.7916666666666667, 1.0, 1.0, 0.26863492660820937, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17137943078598686, 0.17137943078598672, 0.24357624109157922], 
reward next is 0.7564, 
noisyNet noise sample is [array([3.1700082], dtype=float32), 1.6025468]. 
=============================================
[2019-03-23 22:33:16,157] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[69.63849]
 [69.63849]
 [69.63849]
 [69.63849]
 [69.63849]], R is [[69.69853973]
 [69.75708008]
 [69.81361389]
 [69.86846161]
 [69.92228699]].
[2019-03-23 22:33:20,154] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.1411762e-17 1.0000000e+00 4.0335317e-29 2.3354571e-26 1.3647643e-30], sum to 1.0000
[2019-03-23 22:33:20,160] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5776
[2019-03-23 22:33:20,167] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.4, 86.0, 1.0, 2.0, 0.299861862123284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 383114.305733515, 383114.305733515, 115559.4926075108], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1803600.0000, 
sim time next is 1804200.0000, 
raw observation next is [18.43333333333333, 86.16666666666667, 1.0, 2.0, 0.302173038042339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 385883.939775614, 385883.9397756135, 115845.1780904179], 
processed observation next is [1.0, 0.9130434782608695, 0.2382716049382715, 0.8616666666666667, 1.0, 1.0, 0.16925361671707026, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.137815692777005, 0.1378156927770048, 0.22277918863541904], 
reward next is 0.7772, 
noisyNet noise sample is [array([-0.7289569], dtype=float32), 0.4405697]. 
=============================================
[2019-03-23 22:33:20,690] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.01243273e-22 1.00000000e+00 1.84431247e-37 5.53358731e-34
 0.00000000e+00], sum to 1.0000
[2019-03-23 22:33:20,695] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0190
[2019-03-23 22:33:20,701] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.7, 88.0, 1.0, 2.0, 0.317639069271565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 403607.0220586109, 403607.0220586109, 117774.4513529494], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1810800.0000, 
sim time next is 1811400.0000, 
raw observation next is [18.66666666666667, 88.33333333333334, 1.0, 2.0, 0.3174617338754577, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 403319.8982350342, 403319.8982350342, 117751.539599392], 
processed observation next is [1.0, 1.0, 0.24691358024691376, 0.8833333333333334, 1.0, 1.0, 0.18745444508983056, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1440428207982265, 0.1440428207982265, 0.22644526846036922], 
reward next is 0.7736, 
noisyNet noise sample is [array([0.67945266], dtype=float32), -1.2720534]. 
=============================================
[2019-03-23 22:33:27,775] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.9970604e-20 1.0000000e+00 1.0097100e-29 5.0951122e-28 4.1688705e-33], sum to 1.0000
[2019-03-23 22:33:27,778] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7931
[2019-03-23 22:33:27,780] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1409269.198593641 W.
[2019-03-23 22:33:27,787] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.4, 59.66666666666666, 1.0, 2.0, 0.6149010253304947, 1.0, 2.0, 0.6149010253304947, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1409269.198593641, 1409269.198593642, 273557.176624041], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1959000.0000, 
sim time next is 1959600.0000, 
raw observation next is [28.5, 59.33333333333334, 1.0, 2.0, 0.6551748867374131, 0.0, 1.0, 0.0, 1.0, 1.0, 0.986311058050312, 6.911199999999999, 6.9112, 121.9260426156618, 1471206.247463127, 1471206.247463128, 307212.3409521072], 
processed observation next is [1.0, 0.6956521739130435, 0.6111111111111112, 0.5933333333333334, 1.0, 1.0, 0.5894939127826346, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9828888225628901, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5254308026654024, 0.5254308026654029, 0.590792963369437], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.55088043], dtype=float32), -1.2552886]. 
=============================================
[2019-03-23 22:33:28,025] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 22:33:28,027] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:33:28,027] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:33:28,030] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:33:28,034] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:33:28,035] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:33:28,032] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:33:28,037] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:33:28,038] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:33:28,039] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:33:28,039] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:33:28,059] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run37
[2019-03-23 22:33:28,059] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run37
[2019-03-23 22:33:28,104] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run37
[2019-03-23 22:33:28,105] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run37
[2019-03-23 22:33:28,105] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run37
[2019-03-23 22:33:29,667] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.14109151]
[2019-03-23 22:33:29,669] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.0, 23.0, 1.0, 2.0, 0.5095082791237546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 657365.3304645717, 657365.3304645717, 139757.2111391129]
[2019-03-23 22:33:29,670] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:33:29,673] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [7.8764370e-18 1.0000000e+00 2.3043747e-28 3.9877778e-26 3.8134101e-30], sampled 0.6386177467621409
[2019-03-23 22:33:39,102] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.14109151]
[2019-03-23 22:33:39,106] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [18.85, 35.0, 1.0, 2.0, 0.2266759017772872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 292386.675969332, 292386.6759693325, 78604.73581611825]
[2019-03-23 22:33:39,107] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:33:39,112] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [7.8764370e-18 1.0000000e+00 2.3043747e-28 3.9877778e-26 3.8134101e-30], sampled 0.16842720333689187
[2019-03-23 22:33:41,662] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.14109151]
[2019-03-23 22:33:41,664] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.1, 72.0, 1.0, 2.0, 0.3021420945391327, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 386194.8814941521, 386194.8814941525, 115841.7747434865]
[2019-03-23 22:33:41,665] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:33:41,668] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.8764370e-18 1.0000000e+00 2.3043747e-28 3.9877778e-26 3.8134101e-30], sampled 0.8976511243190199
[2019-03-23 22:33:51,805] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.14109151]
[2019-03-23 22:33:51,806] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.06666666666667, 80.66666666666666, 1.0, 2.0, 0.3592701588850266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 448851.4996296122, 448851.4996296122, 123104.2321775844]
[2019-03-23 22:33:51,806] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:33:51,810] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.8764370e-18 1.0000000e+00 2.3043747e-28 3.9877778e-26 3.8134101e-30], sampled 0.8301105712696331
[2019-03-23 22:34:14,937] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.14109151]
[2019-03-23 22:34:14,938] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [32.28414963333333, 69.88764599000001, 1.0, 2.0, 0.8766033659165984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 999211.0691010248, 999211.0691010248, 212289.7936683285]
[2019-03-23 22:34:14,940] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:34:14,941] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [7.8764370e-18 1.0000000e+00 2.3043747e-28 3.9877778e-26 3.8134101e-30], sampled 0.640501387206241
[2019-03-23 22:34:49,404] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.14109151]
[2019-03-23 22:34:49,406] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.45729629166667, 48.847083035, 1.0, 2.0, 0.9682899214078134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.241222863302205, 6.9112, 121.9246746490318, 1326976.456456224, 1157977.149469798, 235891.9122656365]
[2019-03-23 22:34:49,408] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:34:49,411] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [7.8764370e-18 1.0000000e+00 2.3043747e-28 3.9877778e-26 3.8134101e-30], sampled 0.7182541340982771
[2019-03-23 22:34:49,412] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1326976.456456224 W.
[2019-03-23 22:34:55,350] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.14109151]
[2019-03-23 22:34:55,351] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.00531829, 66.08963925, 1.0, 2.0, 0.5714172029339181, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 662946.6419726324, 662946.6419726324, 153792.0571951321]
[2019-03-23 22:34:55,352] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:34:55,355] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.8764370e-18 1.0000000e+00 2.3043747e-28 3.9877778e-26 3.8134101e-30], sampled 0.027965708078149354
[2019-03-23 22:34:55,488] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.14109151]
[2019-03-23 22:34:55,490] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.55, 49.5, 1.0, 2.0, 0.4890046624863106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 584910.2742605347, 584910.2742605347, 141239.1419209519]
[2019-03-23 22:34:55,491] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:34:55,496] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.8764370e-18 1.0000000e+00 2.3043747e-28 3.9877778e-26 3.8134101e-30], sampled 0.9980458767512214
[2019-03-23 22:34:55,934] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.14109151]
[2019-03-23 22:34:55,934] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.9230149, 85.37377241, 1.0, 2.0, 0.4142310380246775, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 512870.9964872541, 512870.9964872546, 130632.9493298291]
[2019-03-23 22:34:55,936] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:34:55,939] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.8764370e-18 1.0000000e+00 2.3043747e-28 3.9877778e-26 3.8134101e-30], sampled 0.47382631963303035
[2019-03-23 22:35:01,401] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.14109151]
[2019-03-23 22:35:01,402] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.0, 78.0, 1.0, 2.0, 0.727485923614692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 829145.0989641176, 829145.0989641171, 181408.0660393359]
[2019-03-23 22:35:01,404] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:35:01,409] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [7.8764370e-18 1.0000000e+00 2.3043747e-28 3.9877778e-26 3.8134101e-30], sampled 0.05833470803046814
[2019-03-23 22:35:09,974] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:35:09,975] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:35:10,019] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:35:10,150] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:35:10,183] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:35:11,200] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 900000, evaluation results [900000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:35:12,974] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.49330048e-24 1.00000000e+00 0.00000000e+00 1.04712465e-36
 0.00000000e+00], sum to 1.0000
[2019-03-23 22:35:12,981] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0248
[2019-03-23 22:35:12,983] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.95, 85.0, 1.0, 2.0, 0.4885861261821066, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 587764.7994742529, 587764.7994742529, 141291.2779019344], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1978200.0000, 
sim time next is 1978800.0000, 
raw observation next is [22.56666666666667, 85.66666666666667, 1.0, 2.0, 0.4744334557101959, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 573557.1371860849, 573557.1371860849, 139201.819581389], 
processed observation next is [1.0, 0.9130434782608695, 0.39135802469135816, 0.8566666666666667, 1.0, 1.0, 0.37432554251213795, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20484183470931602, 0.20484183470931602, 0.2676958068872865], 
reward next is 0.7323, 
noisyNet noise sample is [array([-0.53460735], dtype=float32), -0.7133304]. 
=============================================
[2019-03-23 22:35:16,746] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1536037e-23 1.0000000e+00 3.7836897e-38 2.7981091e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 22:35:16,753] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9112
[2019-03-23 22:35:16,758] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.95, 78.0, 1.0, 2.0, 0.5271996135212117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 623539.8240002115, 623539.8240002115, 147031.5250722856], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2067000.0000, 
sim time next is 2067600.0000, 
raw observation next is [24.8, 78.0, 1.0, 2.0, 0.5207823362725307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 617626.6837530661, 617626.6837530661, 146064.6595756334], 
processed observation next is [0.0, 0.9565217391304348, 0.4740740740740741, 0.78, 1.0, 1.0, 0.42950278127682223, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2205809584832379, 0.2205809584832379, 0.28089357610698734], 
reward next is 0.7191, 
noisyNet noise sample is [array([-1.7515353], dtype=float32), 0.06255945]. 
=============================================
[2019-03-23 22:35:21,494] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0534309e-21 1.0000000e+00 3.4793404e-35 3.3826431e-32 5.5749159e-37], sum to 1.0000
[2019-03-23 22:35:21,501] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7893
[2019-03-23 22:35:21,507] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.03333333333333, 72.0, 1.0, 2.0, 0.6498012638056216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 740561.9811512533, 740561.9811512533, 166856.8369321243], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2148000.0000, 
sim time next is 2148600.0000, 
raw observation next is [27.86666666666666, 72.5, 1.0, 2.0, 0.6464389445774006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 736728.1899442888, 736728.1899442893, 166250.2605322646], 
processed observation next is [0.0, 0.8695652173913043, 0.587654320987654, 0.725, 1.0, 1.0, 0.5790939816397626, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26311721069438887, 0.26311721069438904, 0.3197120394851242], 
reward next is 0.6803, 
noisyNet noise sample is [array([1.4030448], dtype=float32), 1.1286871]. 
=============================================
[2019-03-23 22:35:30,192] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.8526262e-17 1.0000000e+00 2.2623497e-27 2.8857298e-27 6.1002315e-30], sum to 1.0000
[2019-03-23 22:35:30,200] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7644
[2019-03-23 22:35:30,207] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1303193.287618273 W.
[2019-03-23 22:35:30,215] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.3, 79.0, 1.0, 2.0, 0.566300044250613, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9022065518087127, 6.9112, 6.9112, 121.9260426156618, 1303193.287618273, 1303193.287618273, 280804.6370864694], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2296800.0000, 
sim time next is 2297400.0000, 
raw observation next is [25.35, 78.16666666666667, 1.0, 2.0, 0.5611122409438332, 1.0, 1.0, 0.5611122409438332, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1289822.204502663, 1289822.204502663, 255436.348990307], 
processed observation next is [1.0, 0.6086956521739131, 0.4944444444444445, 0.7816666666666667, 1.0, 1.0, 0.4775145725521823, 1.0, 0.5, 0.4775145725521823, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4606507873223797, 0.4606507873223797, 0.49122374805828267], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1562647], dtype=float32), 0.029235624]. 
=============================================
[2019-03-23 22:35:33,082] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.4663485e-26 1.0000000e+00 0.0000000e+00 1.0653164e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 22:35:33,092] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8695
[2019-03-23 22:35:33,103] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.81666666666667, 54.5, 1.0, 2.0, 0.5208341443517752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 645774.6519207073, 645774.6519207073, 146950.1042005771], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2358600.0000, 
sim time next is 2359200.0000, 
raw observation next is [26.13333333333334, 52.00000000000001, 1.0, 2.0, 0.4326295783340272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 537490.3124129922, 537490.3124129922, 133342.1547014512], 
processed observation next is [1.0, 0.30434782608695654, 0.523456790123457, 0.52, 1.0, 1.0, 0.3245590218262229, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19196082586178295, 0.19196082586178295, 0.25642722057971384], 
reward next is 0.7436, 
noisyNet noise sample is [array([0.7012719], dtype=float32), -0.48151574]. 
=============================================
[2019-03-23 22:35:39,653] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1617500e-18 1.0000000e+00 3.5695872e-29 3.9728331e-28 7.1802891e-31], sum to 1.0000
[2019-03-23 22:35:39,659] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7834
[2019-03-23 22:35:39,663] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.25, 25.5, 1.0, 2.0, 0.3904629860424512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 485521.4215308487, 485521.4215308487, 127320.81888029], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2482200.0000, 
sim time next is 2482800.0000, 
raw observation next is [33.03333333333333, 26.0, 1.0, 2.0, 0.3883826409730211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 483186.3398078842, 483186.3398078842, 127036.673518894], 
processed observation next is [1.0, 0.7391304347826086, 0.7790123456790122, 0.26, 1.0, 1.0, 0.2718840963964537, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1725665499313872, 0.1725665499313872, 0.2443012952286423], 
reward next is 0.7557, 
noisyNet noise sample is [array([0.0785847], dtype=float32), -2.886454]. 
=============================================
[2019-03-23 22:35:48,594] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.7848911e-22 1.0000000e+00 1.2869496e-35 1.5793665e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 22:35:48,601] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6527
[2019-03-23 22:35:48,607] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.75, 84.66666666666667, 1.0, 2.0, 0.514944747888517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 612785.6027734432, 612785.6027734432, 145210.8687371991], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2632200.0000, 
sim time next is 2632800.0000, 
raw observation next is [24.0, 84.33333333333334, 1.0, 2.0, 0.5220619183526312, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 618993.0510476163, 618993.0510476163, 146264.7319298779], 
processed observation next is [0.0, 0.4782608695652174, 0.4444444444444444, 0.8433333333333334, 1.0, 1.0, 0.43102609327694186, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2210689468027201, 0.2210689468027201, 0.28127833063438057], 
reward next is 0.7187, 
noisyNet noise sample is [array([0.36366364], dtype=float32), 0.14325328]. 
=============================================
[2019-03-23 22:35:57,431] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.2062413e-18 1.0000000e+00 3.5582100e-28 3.6811358e-25 1.3266458e-30], sum to 1.0000
[2019-03-23 22:35:57,439] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2878
[2019-03-23 22:35:57,451] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2495767.725161079 W.
[2019-03-23 22:35:57,456] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.16666666666667, 78.16666666666667, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 8.116207374843796, 6.9112, 121.9202364146547, 2495767.725161079, 1878725.632267175, 379800.4867085262], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2797800.0000, 
sim time next is 2798400.0000, 
raw observation next is [28.33333333333334, 77.33333333333334, 1.0, 2.0, 0.6884944939925896, 1.0, 1.0, 0.6576119089727294, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2250465.435998199, 2250465.435998199, 426162.6581157467], 
processed observation next is [1.0, 0.391304347826087, 0.6049382716049385, 0.7733333333333334, 1.0, 1.0, 0.6291601118959399, 1.0, 0.5, 0.5923951297294398, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8096049824067558, 0.8037376557136425, 0.8037376557136425, 0.8195435732995129], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3857061], dtype=float32), -0.6597106]. 
=============================================
[2019-03-23 22:36:01,214] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.4361229e-22 1.0000000e+00 1.8094228e-34 8.8552429e-33 1.1001352e-36], sum to 1.0000
[2019-03-23 22:36:01,225] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9693
[2019-03-23 22:36:01,230] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1294870.851058462 W.
[2019-03-23 22:36:01,239] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.5645575828962377, 1.0, 2.0, 0.5645575828962377, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260425368154, 1294870.851058462, 1294870.851058462, 256441.5241270378], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2884800.0000, 
sim time next is 2885400.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.3906740639928825, 1.0, 2.0, 0.3906740639928825, 1.0, 1.0, 0.6223288129769483, 6.9112, 6.9112, 121.94756008, 1347044.7942779, 1347044.7942779, 293078.7717823474], 
processed observation next is [1.0, 0.391304347826087, 0.4074074074074074, 0.94, 1.0, 1.0, 0.27461198094390776, 1.0, 1.0, 0.27461198094390776, 1.0, 0.5, 0.5279110162211853, 0.0, 0.0, 0.8096049824067558, 0.4810874265278214, 0.4810874265278214, 0.5636130226583604], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.59818816], dtype=float32), -0.28621328]. 
=============================================
[2019-03-23 22:36:01,690] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 22:36:01,693] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:36:01,694] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:36:01,696] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:36:01,697] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:36:01,699] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:36:01,701] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:36:01,702] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:36:01,702] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:36:01,702] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:36:01,703] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:36:01,715] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run38
[2019-03-23 22:36:01,737] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run38
[2019-03-23 22:36:01,762] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run38
[2019-03-23 22:36:01,787] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run38
[2019-03-23 22:36:01,811] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run38
[2019-03-23 22:36:25,622] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.12854554]
[2019-03-23 22:36:25,623] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.73447294, 55.15752291, 1.0, 2.0, 0.4584891914895907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 553837.4037800186, 553837.4037800186, 136767.6064137725]
[2019-03-23 22:36:25,624] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:36:25,627] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.1490707e-19 1.0000000e+00 6.1930083e-31 1.6914694e-28 7.2358245e-33], sampled 0.4526701001386845
[2019-03-23 22:36:30,922] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.12854554]
[2019-03-23 22:36:30,923] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.5, 58.0, 1.0, 2.0, 0.4593287052801616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 573985.8166481628, 573985.8166481628, 137389.604019394]
[2019-03-23 22:36:30,923] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:36:30,925] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.1490707e-19 1.0000000e+00 6.1930083e-31 1.6914694e-28 7.2358245e-33], sampled 0.3064340835897327
[2019-03-23 22:36:33,153] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.12854554]
[2019-03-23 22:36:33,155] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.32227153, 64.96194388666666, 1.0, 2.0, 0.5001657521949864, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 597699.6044554795, 597699.6044554795, 142962.3686230781]
[2019-03-23 22:36:33,157] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:36:33,159] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.1490707e-19 1.0000000e+00 6.1930083e-31 1.6914694e-28 7.2358245e-33], sampled 0.11464361742769558
[2019-03-23 22:36:40,095] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.12854554]
[2019-03-23 22:36:40,095] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.73333333333333, 63.33333333333333, 1.0, 2.0, 0.7253173888740005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 826672.199426588, 826672.1994265876, 180998.0483578353]
[2019-03-23 22:36:40,096] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:36:40,100] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.1490707e-19 1.0000000e+00 6.1930083e-31 1.6914694e-28 7.2358245e-33], sampled 0.5666063521865132
[2019-03-23 22:37:07,814] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.12854554]
[2019-03-23 22:37:07,816] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.83333333333333, 84.83333333333333, 1.0, 2.0, 0.681191167564984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 776354.3730900537, 776354.3730900541, 172614.5963771735]
[2019-03-23 22:37:07,817] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:37:07,820] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.1490707e-19 1.0000000e+00 6.1930083e-31 1.6914694e-28 7.2358245e-33], sampled 0.7597560832300312
[2019-03-23 22:37:43,213] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:37:43,358] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:37:43,430] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:37:43,521] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:37:43,753] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:37:44,770] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 925000, evaluation results [925000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:37:45,335] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.2570378e-16 1.0000000e+00 3.3002634e-26 1.0635612e-22 1.0947940e-27], sum to 1.0000
[2019-03-23 22:37:45,349] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0709
[2019-03-23 22:37:45,353] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 89.0, 1.0, 2.0, 0.8470862760510547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 969919.0324943814, 969919.0324943814, 206091.4858697062], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2896800.0000, 
sim time next is 2897400.0000, 
raw observation next is [25.0, 89.0, 1.0, 2.0, 0.8334844141462243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 954487.7226076884, 954487.7226076884, 203189.3610041613], 
processed observation next is [1.0, 0.5217391304347826, 0.48148148148148145, 0.89, 1.0, 1.0, 0.801767159697886, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.34088847235988873, 0.34088847235988873, 0.39074877116184864], 
reward next is 0.6093, 
noisyNet noise sample is [array([0.17316255], dtype=float32), 1.0405937]. 
=============================================
[2019-03-23 22:37:50,674] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.0159591e-16 1.0000000e+00 8.2376745e-24 2.2651608e-23 3.3469834e-26], sum to 1.0000
[2019-03-23 22:37:50,683] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6631
[2019-03-23 22:37:50,690] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666667, 90.66666666666667, 1.0, 2.0, 0.7090194773584387, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 808087.0490750058, 808087.0490750053, 177859.1836290068], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3007200.0000, 
sim time next is 3007800.0000, 
raw observation next is [26.25, 89.0, 1.0, 2.0, 0.7029316328388014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 801144.9558198173, 801144.9558198177, 176699.8361702037], 
processed observation next is [1.0, 0.8260869565217391, 0.5277777777777778, 0.89, 1.0, 1.0, 0.6463471819509541, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.28612319850707757, 0.28612319850707774, 0.33980737725039173], 
reward next is 0.6602, 
noisyNet noise sample is [array([0.76728064], dtype=float32), -0.023629481]. 
=============================================
[2019-03-23 22:37:58,654] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.6308210e-22 1.0000000e+00 3.7448695e-34 2.7163094e-32 7.8647713e-37], sum to 1.0000
[2019-03-23 22:37:58,661] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7072
[2019-03-23 22:37:58,667] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1638968.704736955 W.
[2019-03-23 22:37:58,673] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [34.1, 34.33333333333334, 1.0, 2.0, 0.7930028799971427, 0.0, 2.0, 0.0, 1.0, 2.0, 0.978947552966206, 6.9112, 6.9112, 121.9260426156618, 1638968.704736955, 1638968.704736955, 331503.841234587], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3158400.0000, 
sim time next is 3159000.0000, 
raw observation next is [34.15, 33.5, 1.0, 2.0, 0.5052615993714257, 1.0, 1.0, 0.5052615993714257, 1.0, 2.0, 0.8044717811409339, 6.911199999999999, 6.9112, 121.94756008, 1732027.601361826, 1732027.601361827, 346204.5385442616], 
processed observation next is [1.0, 0.5652173913043478, 0.8203703703703703, 0.335, 1.0, 1.0, 0.4110257135374115, 1.0, 0.5, 0.4110257135374115, 1.0, 1.0, 0.7555897264261674, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6185812862006521, 0.6185812862006524, 0.6657779587389646], 
reward next is 0.3342, 
noisyNet noise sample is [array([0.6660284], dtype=float32), 0.7683897]. 
=============================================
[2019-03-23 22:37:58,698] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[63.452503]
 [63.452503]
 [63.452503]
 [63.452503]
 [63.452503]], R is [[63.15219879]
 [62.88316727]
 [62.70496368]
 [62.07791519]
 [61.9016571 ]].
[2019-03-23 22:38:01,504] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.64878840e-23 1.00000000e+00 1.02816934e-35 9.62395187e-31
 2.82726595e-38], sum to 1.0000
[2019-03-23 22:38:01,512] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5614
[2019-03-23 22:38:01,519] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.9, 60.0, 1.0, 2.0, 0.6444950809680569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 734520.3616293449, 734520.3616293444, 165899.9543810028], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3184200.0000, 
sim time next is 3184800.0000, 
raw observation next is [29.93333333333334, 57.33333333333333, 1.0, 2.0, 0.6164483129582277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 709633.416645388, 709633.4166453885, 161277.455454847], 
processed observation next is [1.0, 0.8695652173913043, 0.6641975308641977, 0.5733333333333333, 1.0, 1.0, 0.5433908487597948, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2534405059447814, 0.25344050594478157, 0.31014895279778265], 
reward next is 0.6899, 
noisyNet noise sample is [array([-0.10027131], dtype=float32), -0.93898916]. 
=============================================
[2019-03-23 22:38:02,020] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.8847811e-21 1.0000000e+00 1.7624982e-34 7.2593321e-31 3.0367232e-37], sum to 1.0000
[2019-03-23 22:38:02,025] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8399
[2019-03-23 22:38:02,030] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 76.0, 1.0, 2.0, 0.4744172613143072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 574237.7074800801, 574237.7074800801, 139222.089341862], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3214800.0000, 
sim time next is 3215400.0000, 
raw observation next is [23.75, 77.16666666666667, 1.0, 2.0, 0.4726120044331394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 572209.2135343803, 572209.2135343803, 138950.8654830824], 
processed observation next is [0.0, 0.21739130434782608, 0.4351851851851852, 0.7716666666666667, 1.0, 1.0, 0.3721571481346898, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20436043340513582, 0.20436043340513582, 0.26721320285208155], 
reward next is 0.7328, 
noisyNet noise sample is [array([0.5056399], dtype=float32), 0.7446828]. 
=============================================
[2019-03-23 22:38:03,720] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.0224421e-26 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-23 22:38:03,728] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2500
[2019-03-23 22:38:03,731] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.01666666666667, 53.5, 1.0, 2.0, 0.5450065601841901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 638482.2916295945, 638482.2916295945, 149683.3631815191], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3239400.0000, 
sim time next is 3240000.0000, 
raw observation next is [30.0, 55.0, 1.0, 2.0, 0.5593941937791599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 651780.4823276566, 651780.4823276566, 151907.816286848], 
processed observation next is [0.0, 0.5217391304347826, 0.6666666666666666, 0.55, 1.0, 1.0, 0.47546927830852365, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23277874368844878, 0.23277874368844878, 0.29213041593624617], 
reward next is 0.7079, 
noisyNet noise sample is [array([-0.8922191], dtype=float32), -1.1234285]. 
=============================================
[2019-03-23 22:38:03,745] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[76.81244]
 [76.81244]
 [76.81244]
 [76.81244]
 [76.81244]], R is [[76.75218964]
 [76.69681549]
 [76.64604187]
 [76.59950256]
 [76.55684662]].
[2019-03-23 22:38:04,847] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.1813266e-23 1.0000000e+00 1.8517993e-37 5.9748604e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 22:38:04,855] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8281
[2019-03-23 22:38:04,859] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 49.0, 1.0, 2.0, 0.5663411452420506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 662021.3457446035, 662021.3457446035, 153160.3021056365], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3261600.0000, 
sim time next is 3262200.0000, 
raw observation next is [30.56666666666667, 51.0, 1.0, 2.0, 0.5622422927515968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 657859.371571572, 657859.371571572, 152501.9857479914], 
processed observation next is [0.0, 0.782608695652174, 0.6876543209876544, 0.51, 1.0, 1.0, 0.47885987232332944, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23494977556127572, 0.23494977556127572, 0.29327304951536803], 
reward next is 0.7067, 
noisyNet noise sample is [array([-0.03980367], dtype=float32), 0.66817254]. 
=============================================
[2019-03-23 22:38:11,795] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.8805980e-24 1.0000000e+00 1.7047956e-34 1.5507509e-31 3.6018261e-37], sum to 1.0000
[2019-03-23 22:38:11,814] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7079
[2019-03-23 22:38:11,820] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 94.0, 1.0, 2.0, 0.7505275597444007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 866011.312407829, 866011.312407829, 186466.9267887911], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3384000.0000, 
sim time next is 3384600.0000, 
raw observation next is [23.81666666666667, 94.00000000000001, 1.0, 2.0, 0.7282028666344137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 842697.089597497, 842697.0895974966, 182188.3509094192], 
processed observation next is [1.0, 0.17391304347826086, 0.43765432098765444, 0.9400000000000002, 1.0, 1.0, 0.6764319840885877, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.30096324628482035, 0.3009632462848202, 0.3503622132873446], 
reward next is 0.6496, 
noisyNet noise sample is [array([0.6940073], dtype=float32), 0.036377892]. 
=============================================
[2019-03-23 22:38:12,342] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.2808422e-19 1.0000000e+00 9.1270322e-34 2.0390323e-29 1.7794338e-35], sum to 1.0000
[2019-03-23 22:38:12,350] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5596
[2019-03-23 22:38:12,360] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2236693.407523307 W.
[2019-03-23 22:38:12,370] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.85, 70.0, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 7.610780398435419, 6.9112, 121.9234582440348, 2236693.407523307, 1878453.309235966, 381621.9015821093], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3407400.0000, 
sim time next is 3408000.0000, 
raw observation next is [29.06666666666666, 69.0, 1.0, 2.0, 0.6359784408200772, 1.0, 1.0, 0.6313538823864732, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2160497.073610146, 2160497.073610146, 412479.4530877493], 
processed observation next is [1.0, 0.43478260869565216, 0.6320987654320985, 0.69, 1.0, 1.0, 0.5666410009762823, 1.0, 0.5, 0.5611355742696109, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8096049824067558, 0.7716060977179093, 0.7716060977179093, 0.793229717476441], 
reward next is 0.2068, 
noisyNet noise sample is [array([-0.21494983], dtype=float32), 0.9641777]. 
=============================================
[2019-03-23 22:38:12,390] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[65.395004]
 [65.395004]
 [65.395004]
 [65.395004]
 [65.395004]], R is [[64.9478302 ]
 [64.2983551 ]
 [63.65537262]
 [63.30471802]
 [62.67167282]].
[2019-03-23 22:38:14,599] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.8296145e-15 1.0000000e+00 1.0130889e-23 2.0921212e-22 8.7484687e-26], sum to 1.0000
[2019-03-23 22:38:14,608] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2755
[2019-03-23 22:38:14,618] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2050928.671836284 W.
[2019-03-23 22:38:14,622] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.95, 66.5, 1.0, 2.0, 0.5993718459277193, 1.0, 2.0, 0.5993718459277193, 1.0, 1.0, 0.9542194988951763, 6.911200000000001, 6.9112, 121.94756008, 2050928.671836284, 2050928.671836284, 395033.4500514751], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3429000.0000, 
sim time next is 3429600.0000, 
raw observation next is [29.73333333333333, 67.33333333333334, 1.0, 2.0, 0.8914224559758118, 1.0, 2.0, 0.8914224559758118, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2033491.59266201, 2033491.592662011, 382979.942321004], 
processed observation next is [1.0, 0.6956521739130435, 0.65679012345679, 0.6733333333333335, 1.0, 1.0, 0.8707410190188236, 1.0, 1.0, 0.8707410190188236, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7262469973792893, 0.7262469973792897, 0.7364998890788539], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.4221062], dtype=float32), -0.49323517]. 
=============================================
[2019-03-23 22:38:15,127] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.4475880e-17 1.0000000e+00 1.8220901e-28 1.7595294e-26 1.0699497e-30], sum to 1.0000
[2019-03-23 22:38:15,134] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0124
[2019-03-23 22:38:15,140] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.6916494596926195, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 788279.8299340133, 788279.8299340128, 174568.4107977146], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3448200.0000, 
sim time next is 3448800.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.6920659693853117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 788754.7744549422, 788754.7744549422, 174646.6609156837], 
processed observation next is [1.0, 0.9565217391304348, 0.5185185185185185, 0.89, 1.0, 1.0, 0.6334118683158473, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28169813373390795, 0.28169813373390795, 0.33585896329939174], 
reward next is 0.6641, 
noisyNet noise sample is [array([0.57712823], dtype=float32), 1.1457552]. 
=============================================
[2019-03-23 22:38:15,700] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.6125231e-21 1.0000000e+00 3.5235278e-33 6.0583433e-32 3.2933188e-35], sum to 1.0000
[2019-03-23 22:38:15,709] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2157
[2019-03-23 22:38:15,715] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2186891.908465421 W.
[2019-03-23 22:38:15,724] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.3, 61.5, 1.0, 2.0, 0.9585863613071209, 1.0, 2.0, 0.9585863613071209, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2186891.908465421, 2186891.908465421, 413642.82079593], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3425400.0000, 
sim time next is 3426000.0000, 
raw observation next is [31.06666666666667, 62.33333333333333, 1.0, 2.0, 0.6233021164055039, 1.0, 2.0, 0.6233021164055039, 1.0, 1.0, 0.9923172688503095, 6.911199999999999, 6.9112, 121.94756008, 2132910.974592423, 2132910.974592424, 408217.8848358174], 
processed observation next is [1.0, 0.6521739130434783, 0.7061728395061729, 0.6233333333333333, 1.0, 1.0, 0.5515501385779809, 1.0, 1.0, 0.5515501385779809, 1.0, 0.5, 0.9903965860628868, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.761753919497294, 0.7617539194972943, 0.7850343939150334], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.28088462], dtype=float32), 1.5123402]. 
=============================================
[2019-03-23 22:38:15,742] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[60.778828]
 [60.778828]
 [60.778828]
 [60.778828]
 [60.778828]], R is [[60.1710434 ]
 [59.77386475]
 [59.37171936]
 [59.00081635]
 [58.58717346]].
[2019-03-23 22:38:25,485] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.6028947e-19 1.0000000e+00 8.8378970e-33 7.4434153e-34 3.9788096e-35], sum to 1.0000
[2019-03-23 22:38:25,492] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3199
[2019-03-23 22:38:25,496] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.2, 97.00000000000001, 1.0, 2.0, 0.5757428209664037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 669902.4003198837, 669902.4003198837, 154607.6809899292], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3622200.0000, 
sim time next is 3622800.0000, 
raw observation next is [23.4, 94.0, 1.0, 2.0, 0.5670051653104117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 662067.7530786033, 662067.7530786033, 153240.0602193257], 
processed observation next is [1.0, 0.9565217391304348, 0.42222222222222217, 0.94, 1.0, 1.0, 0.484529958702871, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23645276895664405, 0.23645276895664405, 0.2946924234987033], 
reward next is 0.7053, 
noisyNet noise sample is [array([-0.6293599], dtype=float32), 0.8160119]. 
=============================================
[2019-03-23 22:38:30,375] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.1899628e-19 1.0000000e+00 4.0069790e-32 7.0982607e-31 1.0734916e-35], sum to 1.0000
[2019-03-23 22:38:30,382] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3287
[2019-03-23 22:38:30,386] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.46666666666667, 90.0, 1.0, 2.0, 0.7183972114683326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 818780.7935470932, 818780.7935470932, 179657.648713405], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3698400.0000, 
sim time next is 3699000.0000, 
raw observation next is [26.4, 90.0, 1.0, 2.0, 0.7150022055897997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 814909.3373405209, 814909.3373405209, 179004.8355992472], 
processed observation next is [1.0, 0.8260869565217391, 0.5333333333333333, 0.9, 1.0, 1.0, 0.6607169114164282, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29103904905018607, 0.29103904905018607, 0.34424006846009075], 
reward next is 0.6558, 
noisyNet noise sample is [array([0.19357406], dtype=float32), -0.9973218]. 
=============================================
[2019-03-23 22:38:30,405] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[63.996384]
 [63.996384]
 [63.996384]
 [63.996384]
 [63.996384]], R is [[64.01218414]
 [64.02656555]
 [64.03993988]
 [64.05266571]
 [64.06505585]].
[2019-03-23 22:38:32,712] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.1232334e-14 1.0000000e+00 3.0796874e-23 3.4797616e-22 2.9410087e-26], sum to 1.0000
[2019-03-23 22:38:32,716] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2434
[2019-03-23 22:38:32,723] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.2, 59.0, 1.0, 2.0, 0.7395386891432595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 842889.6763846456, 842889.6763846452, 183772.6652605286], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3778200.0000, 
sim time next is 3778800.0000, 
raw observation next is [33.46666666666667, 55.0, 1.0, 2.0, 0.725051603442711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 826369.1102173033, 826369.1102173033, 180946.2540778283], 
processed observation next is [1.0, 0.7391304347826086, 0.7950617283950618, 0.55, 1.0, 1.0, 0.6726804802889417, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2951318250776083, 0.2951318250776083, 0.34797356553428516], 
reward next is 0.6520, 
noisyNet noise sample is [array([-0.28240085], dtype=float32), 0.5094544]. 
=============================================
[2019-03-23 22:38:35,690] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 22:38:35,692] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:38:35,695] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:38:35,697] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:38:35,698] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:38:35,699] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:38:35,700] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:38:35,700] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:38:35,702] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:38:35,703] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:38:35,704] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:38:35,719] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run39
[2019-03-23 22:38:35,720] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run39
[2019-03-23 22:38:35,765] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run39
[2019-03-23 22:38:35,766] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run39
[2019-03-23 22:38:35,792] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run39
[2019-03-23 22:38:47,153] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.11282808]
[2019-03-23 22:38:47,154] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.80393771, 65.44304937, 1.0, 2.0, 0.4268680450734307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 522811.9102282305, 522811.91022823, 132316.154897563]
[2019-03-23 22:38:47,156] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:38:47,161] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.1152228e-23 1.0000000e+00 8.2843223e-37 7.5855344e-34 0.0000000e+00], sampled 0.29532209415412747
[2019-03-23 22:39:10,624] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.11282808]
[2019-03-23 22:39:10,625] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.4, 62.0, 1.0, 2.0, 0.8245529655262424, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426156618, 1654964.870644215, 1654964.870644215, 341165.671936103]
[2019-03-23 22:39:10,626] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:39:10,627] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.1152228e-23 1.0000000e+00 8.2843223e-37 7.5855344e-34 0.0000000e+00], sampled 0.9328504183881996
[2019-03-23 22:39:10,630] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1654964.870644215 W.
[2019-03-23 22:39:13,238] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.11282808]
[2019-03-23 22:39:13,239] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.39086706333334, 54.318422545, 1.0, 2.0, 0.4007502393649898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 498343.8765396151, 498343.8765396151, 128763.0749991511]
[2019-03-23 22:39:13,240] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:39:13,243] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [5.1152228e-23 1.0000000e+00 8.2843223e-37 7.5855344e-34 0.0000000e+00], sampled 0.071627346654206
[2019-03-23 22:39:15,948] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.11282808]
[2019-03-23 22:39:15,950] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.53333333333333, 68.0, 1.0, 2.0, 0.6377341335676603, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 726802.8597976145, 726802.8597976145, 164693.9360514708]
[2019-03-23 22:39:15,950] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:39:15,953] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.1152228e-23 1.0000000e+00 8.2843223e-37 7.5855344e-34 0.0000000e+00], sampled 0.39294695135047175
[2019-03-23 22:40:05,886] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.11282808]
[2019-03-23 22:40:05,887] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.69943745, 87.662049205, 1.0, 2.0, 0.4950129870732093, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 593801.3464948849, 593801.3464948854, 142235.3290144126]
[2019-03-23 22:40:05,888] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:40:05,893] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.1152228e-23 1.0000000e+00 8.2843223e-37 7.5855344e-34 0.0000000e+00], sampled 0.4983794213579231
[2019-03-23 22:40:11,860] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.11282808]
[2019-03-23 22:40:11,861] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.46682471, 104.398538, 1.0, 2.0, 0.440706074953457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 536283.7972650069, 536283.7972650069, 134243.8382227864]
[2019-03-23 22:40:11,863] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:40:11,867] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [5.1152228e-23 1.0000000e+00 8.2843223e-37 7.5855344e-34 0.0000000e+00], sampled 0.4655697496332575
[2019-03-23 22:40:17,502] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:40:17,529] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:40:17,585] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:40:17,586] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:40:17,798] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:40:18,813] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 950000, evaluation results [950000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:40:22,320] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.2470384e-20 1.0000000e+00 1.0549118e-34 3.6273736e-31 2.0307890e-36], sum to 1.0000
[2019-03-23 22:40:22,331] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1164
[2019-03-23 22:40:22,338] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 94.0, 1.0, 2.0, 0.7320073223076495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 834301.1244464569, 834301.1244464569, 182293.692103545], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3911400.0000, 
sim time next is 3912000.0000, 
raw observation next is [26.0, 94.0, 1.0, 2.0, 0.7339689892841694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 836538.1432070158, 836538.1432070158, 182676.2116095747], 
processed observation next is [0.0, 0.2608695652173913, 0.5185185185185185, 0.94, 1.0, 1.0, 0.6832964158144874, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29876362257393424, 0.29876362257393424, 0.35130040694148984], 
reward next is 0.6487, 
noisyNet noise sample is [array([0.09335873], dtype=float32), 0.902003]. 
=============================================
[2019-03-23 22:40:22,362] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[64.447266]
 [64.447266]
 [64.447266]
 [64.447266]
 [64.447266]], R is [[64.45149231]
 [64.45641327]
 [64.46178436]
 [64.467453  ]
 [64.47401428]].
[2019-03-23 22:40:22,670] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0901424e-21 1.0000000e+00 5.0731420e-34 2.6413512e-30 5.4043473e-35], sum to 1.0000
[2019-03-23 22:40:22,682] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8061
[2019-03-23 22:40:22,688] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 91.5, 1.0, 2.0, 0.7463267842370089, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 850630.7052861203, 850630.7052861198, 185102.1927471158], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3900600.0000, 
sim time next is 3901200.0000, 
raw observation next is [26.33333333333334, 92.33333333333334, 1.0, 2.0, 0.7436675126871853, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 847598.1076469445, 847598.1076469445, 184577.8121120502], 
processed observation next is [0.0, 0.13043478260869565, 0.5308641975308644, 0.9233333333333335, 1.0, 1.0, 0.6948422770085539, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3027136098739087, 0.3027136098739087, 0.3549573309847119], 
reward next is 0.6450, 
noisyNet noise sample is [array([-1.0188458], dtype=float32), 1.1107385]. 
=============================================
[2019-03-23 22:40:22,737] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.9528344e-20 1.0000000e+00 1.6227128e-32 3.4253971e-28 1.1700312e-33], sum to 1.0000
[2019-03-23 22:40:22,746] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8057
[2019-03-23 22:40:22,750] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 67.0, 1.0, 2.0, 0.8227967118119422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 937841.1202178778, 937841.1202178778, 200705.1056032994], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3870000.0000, 
sim time next is 3870600.0000, 
raw observation next is [31.65, 67.33333333333334, 1.0, 2.0, 0.7977284028689012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 909250.7800933508, 909250.7800933503, 195479.7296066917], 
processed observation next is [0.0, 0.8260869565217391, 0.7277777777777777, 0.6733333333333335, 1.0, 1.0, 0.7592004796058348, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.324732421461911, 0.32473242146191084, 0.37592255693594556], 
reward next is 0.6241, 
noisyNet noise sample is [array([-1.1189936], dtype=float32), -0.76999915]. 
=============================================
[2019-03-23 22:40:26,431] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.9445196e-20 1.0000000e+00 1.9184586e-33 3.1601020e-30 1.2915937e-33], sum to 1.0000
[2019-03-23 22:40:26,441] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0559
[2019-03-23 22:40:26,447] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.1, 77.0, 1.0, 2.0, 0.7564257513915291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 862147.5414096413, 862147.5414096413, 187105.9063872585], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3957600.0000, 
sim time next is 3958200.0000, 
raw observation next is [29.15, 76.0, 1.0, 2.0, 0.7691149365758765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 876618.5008408854, 876618.5008408854, 189645.1020437579], 
processed observation next is [0.0, 0.8260869565217391, 0.6351851851851852, 0.76, 1.0, 1.0, 0.7251368292569959, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31307803601460193, 0.31307803601460193, 0.3647021193149191], 
reward next is 0.6353, 
noisyNet noise sample is [array([0.688961], dtype=float32), 1.5754043]. 
=============================================
[2019-03-23 22:40:28,855] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8998602e-16 1.0000000e+00 2.2230746e-26 3.8197114e-24 1.4411610e-28], sum to 1.0000
[2019-03-23 22:40:28,862] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7548
[2019-03-23 22:40:28,866] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1694627.437353832 W.
[2019-03-23 22:40:28,873] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.7430152407698689, 1.0, 2.0, 0.7430152407698689, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1694627.437353832, 1694627.437353833, 320769.6738686492], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4010400.0000, 
sim time next is 4011000.0000, 
raw observation next is [25.2, 92.33333333333334, 1.0, 2.0, 0.9555085284133306, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1804450.432949123, 1804450.432949123, 369221.4911808494], 
processed observation next is [1.0, 0.43478260869565216, 0.4888888888888889, 0.9233333333333335, 1.0, 1.0, 0.9470339623968221, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, 0.0, 0.0, 0.8094621288201359, 0.6444465831961154, 0.6444465831961154, 0.7100413291939411], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6520275], dtype=float32), -1.1623006]. 
=============================================
[2019-03-23 22:40:28,892] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[44.90922]
 [44.90922]
 [44.90922]
 [44.90922]
 [44.90922]], R is [[44.46012878]
 [44.01552963]
 [43.5753746 ]
 [43.13962173]
 [43.06284714]].
[2019-03-23 22:40:32,589] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.2459479e-23 1.0000000e+00 9.2554884e-36 9.0779342e-34 1.2780346e-37], sum to 1.0000
[2019-03-23 22:40:32,603] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1694
[2019-03-23 22:40:32,610] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1406540.802240581 W.
[2019-03-23 22:40:32,613] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.13333333333333, 83.66666666666667, 1.0, 2.0, 0.9784070054464278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.355273408700319, 6.9112, 121.9244651632993, 1406540.802240581, 1179138.468274656, 238702.4461324576], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4090800.0000, 
sim time next is 4091400.0000, 
raw observation next is [23.35, 83.5, 1.0, 2.0, 0.5872042942402534, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9423001990474004, 6.9112, 6.9112, 121.9257752023137, 1391632.624881865, 1391632.624881865, 287737.2013135841], 
processed observation next is [1.0, 0.34782608695652173, 0.42037037037037045, 0.835, 1.0, 1.0, 0.5085765407622065, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.9278752488092503, 0.0, 0.0, 0.8094603534735948, 0.4970116517435232, 0.4970116517435232, 0.5533407717568926], 
reward next is 0.4467, 
noisyNet noise sample is [array([-0.73719066], dtype=float32), -1.5838162]. 
=============================================
[2019-03-23 22:40:35,004] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.7239005e-16 1.0000000e+00 2.1340896e-25 1.2496529e-23 1.2964890e-28], sum to 1.0000
[2019-03-23 22:40:35,014] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7096
[2019-03-23 22:40:35,021] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1910210.653201977 W.
[2019-03-23 22:40:35,023] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.86666666666667, 67.33333333333334, 1.0, 2.0, 0.5582917593576244, 1.0, 2.0, 0.5582917593576244, 1.0, 1.0, 0.8888186631905685, 6.911199999999999, 6.9112, 121.94756008, 1910210.653201977, 1910210.653201977, 373119.5601638836], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4112400.0000, 
sim time next is 4113000.0000, 
raw observation next is [28.9, 69.0, 1.0, 2.0, 0.5730120807702951, 1.0, 2.0, 0.5730120807702951, 1.0, 2.0, 0.9122538942869393, 6.911199999999999, 6.9112, 121.94756008, 1960631.914164939, 1960631.914164939, 380867.3799388677], 
processed observation next is [1.0, 0.6086956521739131, 0.6259259259259259, 0.69, 1.0, 1.0, 0.49168104853606553, 1.0, 1.0, 0.49168104853606553, 1.0, 1.0, 0.890317367858674, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7002256836303353, 0.7002256836303353, 0.7324372691132072], 
reward next is 0.2676, 
noisyNet noise sample is [array([0.5714503], dtype=float32), 1.1676186]. 
=============================================
[2019-03-23 22:40:35,035] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[45.543747]
 [45.543747]
 [45.543747]
 [45.543747]
 [45.543747]], R is [[45.35587692]
 [44.90231705]
 [44.45329285]
 [44.31934357]
 [44.17719269]].
[2019-03-23 22:40:42,353] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.3649962e-23 1.0000000e+00 2.3506038e-36 8.0705798e-32 0.0000000e+00], sum to 1.0000
[2019-03-23 22:40:42,358] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2936
[2019-03-23 22:40:42,363] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 81.5, 1.0, 2.0, 0.4970268220583736, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 617142.3220942385, 617142.3220942385, 143154.5279237729], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4255800.0000, 
sim time next is 4256400.0000, 
raw observation next is [22.0, 80.0, 1.0, 2.0, 0.4471466570523631, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 552954.4900603663, 552954.4900603663, 135434.4184100837], 
processed observation next is [1.0, 0.2608695652173913, 0.37037037037037035, 0.8, 1.0, 1.0, 0.34184125839567037, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19748374645013084, 0.19748374645013084, 0.2604508046347763], 
reward next is 0.7395, 
noisyNet noise sample is [array([1.0955197], dtype=float32), 1.2012888]. 
=============================================
[2019-03-23 22:40:45,277] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.1785446e-19 1.0000000e+00 3.0862858e-30 2.8977426e-27 2.2439005e-31], sum to 1.0000
[2019-03-23 22:40:45,283] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0433
[2019-03-23 22:40:45,289] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2057715.173970939 W.
[2019-03-23 22:40:45,293] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.83333333333334, 35.66666666666667, 1.0, 2.0, 0.601352879189052, 1.0, 2.0, 0.601352879189052, 1.0, 1.0, 0.9573733683649672, 6.9112, 6.9112, 121.94756008, 2057715.173970939, 2057715.173970939, 396113.2061112097], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4288200.0000, 
sim time next is 4288800.0000, 
raw observation next is [33.66666666666667, 37.33333333333334, 1.0, 2.0, 0.8886862260081061, 1.0, 2.0, 0.8886862260081061, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2027242.685323698, 2027242.685323698, 381761.7711148993], 
processed observation next is [1.0, 0.6521739130434783, 0.8024691358024693, 0.3733333333333334, 1.0, 1.0, 0.8674836023906025, 1.0, 1.0, 0.8674836023906025, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.7240152447584636, 0.7240152447584636, 0.7341572521440372], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8551113], dtype=float32), 0.80371535]. 
=============================================
[2019-03-23 22:40:50,373] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0603007e-21 1.0000000e+00 1.5418827e-34 1.5584552e-30 4.6142279e-37], sum to 1.0000
[2019-03-23 22:40:50,373] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0242
[2019-03-23 22:40:50,379] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 90.0, 1.0, 2.0, 0.4924661324954375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 591201.2975709827, 591201.2975709822, 141853.8545360049], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4413600.0000, 
sim time next is 4414200.0000, 
raw observation next is [22.41666666666667, 90.66666666666667, 1.0, 2.0, 0.4931349935493642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 591997.3140867925, 591997.3140867925, 141958.0591981], 
processed observation next is [0.0, 0.08695652173913043, 0.38580246913580263, 0.9066666666666667, 1.0, 1.0, 0.39658927803495736, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21142761217385447, 0.21142761217385447, 0.27299626768865387], 
reward next is 0.7270, 
noisyNet noise sample is [array([0.5493318], dtype=float32), 0.4149487]. 
=============================================
[2019-03-23 22:40:53,044] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2364651e-24 1.0000000e+00 2.6118368e-35 2.8747761e-34 2.5724096e-38], sum to 1.0000
[2019-03-23 22:40:53,051] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1431
[2019-03-23 22:40:53,056] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.8, 74.0, 1.0, 2.0, 0.6540173342101179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 745369.2655440919, 745369.2655440919, 167620.2128736424], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4452000.0000, 
sim time next is 4452600.0000, 
raw observation next is [27.9, 74.0, 1.0, 2.0, 0.6596584375406126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 751801.4605059865, 751801.4605059865, 168646.2441932726], 
processed observation next is [0.0, 0.5217391304347826, 0.5888888888888888, 0.74, 1.0, 1.0, 0.5948314732626341, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2685005216092809, 0.2685005216092809, 0.32431970037167807], 
reward next is 0.6757, 
noisyNet noise sample is [array([0.4895912], dtype=float32), -0.5904835]. 
=============================================
[2019-03-23 22:40:58,053] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.0108970e-23 1.0000000e+00 6.0885824e-38 9.1356230e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 22:40:58,066] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7449
[2019-03-23 22:40:58,075] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 94.00000000000001, 1.0, 2.0, 0.604374168649907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 697548.3397816239, 697548.3397816235, 159258.2555129105], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4558200.0000, 
sim time next is 4558800.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.6040836720169828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 697213.2288315519, 697213.2288315519, 159207.8623535547], 
processed observation next is [0.0, 0.782608695652174, 0.4444444444444444, 0.94, 1.0, 1.0, 0.5286710381154557, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2490047245826971, 0.2490047245826971, 0.30616896606452826], 
reward next is 0.6938, 
noisyNet noise sample is [array([0.34606886], dtype=float32), -0.7829991]. 
=============================================
[2019-03-23 22:41:04,248] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.7641937e-22 1.0000000e+00 4.7781178e-34 2.5951063e-32 1.7437711e-36], sum to 1.0000
[2019-03-23 22:41:04,257] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5954
[2019-03-23 22:41:04,257] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2065933.432545605 W.
[2019-03-23 22:41:04,260] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.86666666666667, 68.33333333333334, 1.0, 2.0, 0.6037518332458973, 1.0, 2.0, 0.6037518332458973, 1.0, 2.0, 0.9611925813519442, 6.9112, 6.9112, 121.94756008, 2065933.432545605, 2065933.432545605, 397423.576901095], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4638000.0000, 
sim time next is 4638600.0000, 
raw observation next is [29.8, 67.5, 1.0, 2.0, 0.5966250365404507, 1.0, 2.0, 0.5966250365404507, 1.0, 2.0, 0.9498464888933085, 6.9112, 6.9112, 121.94756008, 2041518.906178598, 2041518.906178598, 393539.8062856814], 
processed observation next is [1.0, 0.6956521739130435, 0.6592592592592593, 0.675, 1.0, 1.0, 0.5197917101672033, 1.0, 1.0, 0.5197917101672033, 1.0, 1.0, 0.9373081111166356, 0.0, 0.0, 0.8096049824067558, 0.729113895063785, 0.729113895063785, 0.7568073197801565], 
reward next is 0.2432, 
noisyNet noise sample is [array([-0.7316258], dtype=float32), -0.33151394]. 
=============================================
[2019-03-23 22:41:04,439] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.2040922e-23 1.0000000e+00 3.7405824e-36 4.4110389e-33 1.4297094e-38], sum to 1.0000
[2019-03-23 22:41:04,456] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0637
[2019-03-23 22:41:04,461] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.96666666666667, 94.16666666666667, 1.0, 2.0, 0.6664008042301973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 759489.4275498703, 759489.4275498699, 169879.4283484655], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4669800.0000, 
sim time next is 4670400.0000, 
raw observation next is [24.93333333333333, 94.33333333333334, 1.0, 2.0, 0.6657927838696434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 758796.1306651363, 758796.1306651363, 169767.8558957093], 
processed observation next is [1.0, 0.043478260869565216, 0.47901234567901224, 0.9433333333333335, 1.0, 1.0, 0.6021342665114802, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2709986180946915, 0.2709986180946915, 0.3264766459532871], 
reward next is 0.6735, 
noisyNet noise sample is [array([1.9729745], dtype=float32), -0.34096923]. 
=============================================
[2019-03-23 22:41:09,435] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 22:41:09,435] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:41:09,436] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:41:09,438] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:41:09,441] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:41:09,442] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:41:09,442] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:41:09,443] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:41:09,444] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:41:09,444] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:41:09,447] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:41:09,461] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run40
[2019-03-23 22:41:09,461] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run40
[2019-03-23 22:41:09,506] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run40
[2019-03-23 22:41:09,507] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run40
[2019-03-23 22:41:09,525] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run40
[2019-03-23 22:41:25,384] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.116657875]
[2019-03-23 22:41:25,385] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [19.16666666666667, 87.66666666666667, 1.0, 2.0, 0.337249545380386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 426416.4743057942, 426416.4743057942, 120274.517892583]
[2019-03-23 22:41:25,387] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:41:25,391] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.0502853e-21 1.0000000e+00 5.8483351e-34 2.6793551e-31 3.2718168e-36], sampled 0.8776534976612296
[2019-03-23 22:41:28,178] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.116657875]
[2019-03-23 22:41:28,179] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.0, 72.33333333333334, 1.0, 2.0, 0.6527326137545009, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9556726338243338, 6.9112, 6.9112, 121.9260426156114, 1517518.033272197, 1517518.033272197, 295212.077209167]
[2019-03-23 22:41:28,180] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:41:28,182] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.0502853e-21 1.0000000e+00 5.8483351e-34 2.6793551e-31 3.2718168e-36], sampled 0.6477474590638339
[2019-03-23 22:41:28,184] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1517518.033272197 W.
[2019-03-23 22:41:50,774] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.116657875]
[2019-03-23 22:41:50,775] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.54429061, 84.96742567, 1.0, 2.0, 0.4620415635471357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 559635.6502069279, 559635.6502069279, 137350.6712942633]
[2019-03-23 22:41:50,777] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:41:50,779] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.0502853e-21 1.0000000e+00 5.8483351e-34 2.6793551e-31 3.2718168e-36], sampled 0.49455059945077473
[2019-03-23 22:41:51,391] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.116657875]
[2019-03-23 22:41:51,392] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.0, 90.66666666666667, 1.0, 2.0, 0.56905775209379, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 676225.4736011276, 676225.4736011276, 154069.6146731727]
[2019-03-23 22:41:51,393] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:41:51,396] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.0502853e-21 1.0000000e+00 5.8483351e-34 2.6793551e-31 3.2718168e-36], sampled 0.9786002725547982
[2019-03-23 22:41:53,146] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.116657875]
[2019-03-23 22:41:53,148] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.5, 67.5, 1.0, 2.0, 0.9326766409211741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1063171.475243041, 1063171.475243041, 224895.5561481189]
[2019-03-23 22:41:53,149] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:41:53,151] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.0502853e-21 1.0000000e+00 5.8483351e-34 2.6793551e-31 3.2718168e-36], sampled 0.7865003174860072
[2019-03-23 22:41:53,525] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.116657875]
[2019-03-23 22:41:53,526] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.36666666666667, 65.33333333333333, 1.0, 2.0, 0.5095419279985148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 608653.232876935, 608653.2328769346, 144435.5332211322]
[2019-03-23 22:41:53,528] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:41:53,531] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.0502853e-21 1.0000000e+00 5.8483351e-34 2.6793551e-31 3.2718168e-36], sampled 0.7178635946035522
[2019-03-23 22:42:11,736] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.116657875]
[2019-03-23 22:42:11,738] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.88554645833333, 80.40369630166667, 1.0, 2.0, 0.7903373404101038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 900821.4964774873, 900821.4964774873, 193963.32269035]
[2019-03-23 22:42:11,739] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:42:11,744] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.0502853e-21 1.0000000e+00 5.8483351e-34 2.6793551e-31 3.2718168e-36], sampled 0.8618581253369043
[2019-03-23 22:42:25,815] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.116657875]
[2019-03-23 22:42:25,816] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.18333333333333, 88.33333333333334, 1.0, 2.0, 0.8262021945559289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 963964.924078366, 963964.924078366, 202547.5734643443]
[2019-03-23 22:42:25,818] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:42:25,821] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.0502853e-21 1.0000000e+00 5.8483351e-34 2.6793551e-31 3.2718168e-36], sampled 0.23219198340112002
[2019-03-23 22:42:41,207] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.116657875]
[2019-03-23 22:42:41,208] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.58333333333333, 94.83333333333333, 1.0, 2.0, 0.6282068249989857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 715939.8553470081, 715939.8553470076, 162997.2679107704]
[2019-03-23 22:42:41,209] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:42:41,211] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.0502853e-21 1.0000000e+00 5.8483351e-34 2.6793551e-31 3.2718168e-36], sampled 0.6170220513465693
[2019-03-23 22:42:45,538] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.116657875]
[2019-03-23 22:42:45,540] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [19.84880831, 96.59667392, 1.0, 2.0, 0.4115223634970462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 507950.9298587236, 507950.9298587231, 130208.5502786064]
[2019-03-23 22:42:45,542] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:42:45,545] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.0502853e-21 1.0000000e+00 5.8483351e-34 2.6793551e-31 3.2718168e-36], sampled 0.8659419895424963
[2019-03-23 22:42:51,597] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:42:51,645] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:42:51,658] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:42:51,677] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:42:51,725] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:42:52,740] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 975000, evaluation results [975000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:42:56,358] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.6870773e-20 1.0000000e+00 7.0806047e-30 2.3252328e-27 1.9286433e-33], sum to 1.0000
[2019-03-23 22:42:56,366] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0289
[2019-03-23 22:42:56,371] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1921708.736331576 W.
[2019-03-23 22:42:56,375] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.41666666666667, 85.66666666666667, 1.0, 2.0, 0.8424728303499587, 1.0, 2.0, 0.8424728303499587, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156443, 1921708.736331576, 1921708.736331576, 361618.2055532259], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4803000.0000, 
sim time next is 4803600.0000, 
raw observation next is [27.33333333333334, 86.33333333333334, 1.0, 2.0, 0.5489594522539141, 1.0, 2.0, 0.5489594522539141, 1.0, 1.0, 0.8739613263494378, 6.911199999999999, 6.9112, 121.94756008, 1878246.33801469, 1878246.338014691, 368268.2450591116], 
processed observation next is [1.0, 0.6086956521739131, 0.5679012345679014, 0.8633333333333334, 1.0, 1.0, 0.4630469669689453, 1.0, 1.0, 0.4630469669689453, 1.0, 0.5, 0.8424516579367971, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6708022635766749, 0.6708022635766753, 0.7082081635752147], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3295028], dtype=float32), -0.738512]. 
=============================================
[2019-03-23 22:43:00,163] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.9559518e-15 1.0000000e+00 4.7406282e-26 2.4969495e-22 1.1162602e-25], sum to 1.0000
[2019-03-23 22:43:00,171] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4765
[2019-03-23 22:43:00,181] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 94.0, 1.0, 2.0, 0.848784077106386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 967480.767738016, 967480.767738016, 206234.9912326126], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4915800.0000, 
sim time next is 4916400.0000, 
raw observation next is [27.33333333333334, 94.0, 1.0, 2.0, 0.8368100027931537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 953823.7063531845, 953823.7063531845, 203671.305290346], 
processed observation next is [1.0, 0.9130434782608695, 0.5679012345679014, 0.94, 1.0, 1.0, 0.8057261938013733, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3406513236975659, 0.3406513236975659, 0.39167558709681927], 
reward next is 0.6083, 
noisyNet noise sample is [array([1.1856862], dtype=float32), 0.3665703]. 
=============================================
[2019-03-23 22:43:10,073] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0333867e-21 1.0000000e+00 4.5389886e-35 3.5452079e-33 6.2010949e-38], sum to 1.0000
[2019-03-23 22:43:10,081] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0441
[2019-03-23 22:43:10,086] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 74.16666666666667, 1.0, 2.0, 0.8241448221306905, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 939378.6666979365, 939378.6666979361, 200990.9275147705], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5069400.0000, 
sim time next is 5070000.0000, 
raw observation next is [31.0, 73.33333333333334, 1.0, 2.0, 0.809659128287883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 922857.6078973552, 922857.6078973549, 197954.845623841], 
processed observation next is [0.0, 0.6956521739130435, 0.7037037037037037, 0.7333333333333334, 1.0, 1.0, 0.7734037241522417, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.329592002820484, 0.3295920028204839, 0.3806823954304635], 
reward next is 0.6193, 
noisyNet noise sample is [array([-0.656435], dtype=float32), 0.35726786]. 
=============================================
[2019-03-23 22:43:10,104] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[65.9263]
 [65.9263]
 [65.9263]
 [65.9263]
 [65.9263]], R is [[65.88636017]
 [65.84098053]
 [65.77386475]
 [65.70675659]
 [65.64048767]].
[2019-03-23 22:43:12,371] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.5863745e-21 1.0000000e+00 2.7989540e-33 1.7281879e-30 8.3951040e-35], sum to 1.0000
[2019-03-23 22:43:12,379] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1227
[2019-03-23 22:43:12,384] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.83333333333334, 76.66666666666667, 1.0, 2.0, 0.7789091941933932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 887788.2232061545, 887788.2232061541, 191628.933245421], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5138400.0000, 
sim time next is 5139000.0000, 
raw observation next is [29.95, 76.5, 1.0, 2.0, 0.8098522915335583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 923077.9099025417, 923077.9099025417, 197992.3703997283], 
processed observation next is [0.0, 0.4782608695652174, 0.6648148148148147, 0.765, 1.0, 1.0, 0.7736336803970932, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3296706821080506, 0.3296706821080506, 0.38075455846101597], 
reward next is 0.6192, 
noisyNet noise sample is [array([-0.33083478], dtype=float32), -1.4765896]. 
=============================================
[2019-03-23 22:43:12,407] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[60.018955]
 [60.018955]
 [60.018955]
 [60.018955]
 [60.018955]], R is [[60.03800583]
 [60.06910706]
 [60.10134506]
 [60.11751938]
 [60.12679672]].
[2019-03-23 22:43:17,162] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.8279630e-20 1.0000000e+00 5.2638035e-31 6.2831057e-29 5.9852430e-34], sum to 1.0000
[2019-03-23 22:43:17,169] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7387
[2019-03-23 22:43:17,173] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 100.0, 1.0, 2.0, 0.7652948363136911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 872261.965737222, 872261.965737222, 188868.6686742618], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5209200.0000, 
sim time next is 5209800.0000, 
raw observation next is [24.08333333333333, 98.50000000000001, 1.0, 2.0, 0.8381163813471396, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 955313.687958617, 955313.687958617, 203935.1868624691], 
processed observation next is [1.0, 0.30434782608695654, 0.4475308641975307, 0.9850000000000001, 1.0, 1.0, 0.8072814063656424, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.34118345998522037, 0.34118345998522037, 0.3921830516585944], 
reward next is 0.6078, 
noisyNet noise sample is [array([-0.66640896], dtype=float32), 0.42561913]. 
=============================================
[2019-03-23 22:43:20,286] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.8798515e-20 1.0000000e+00 3.1734489e-31 2.4883285e-27 2.7561698e-33], sum to 1.0000
[2019-03-23 22:43:20,296] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7053
[2019-03-23 22:43:20,299] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.1, 84.0, 1.0, 2.0, 0.8398566518545936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 973675.1560832167, 973675.1560832167, 205165.0504519404], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5281200.0000, 
sim time next is 5281800.0000, 
raw observation next is [25.01666666666667, 84.16666666666667, 1.0, 2.0, 0.8724111069942732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1012688.388587222, 1012688.388587221, 212316.1901549413], 
processed observation next is [1.0, 0.13043478260869565, 0.48209876543209884, 0.8416666666666667, 1.0, 1.0, 0.848108460707468, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3616744244954364, 0.3616744244954361, 0.4083003656825794], 
reward next is 0.5917, 
noisyNet noise sample is [array([-0.55198115], dtype=float32), 0.2724087]. 
=============================================
[2019-03-23 22:43:20,817] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.6316630e-23 1.0000000e+00 4.7223021e-36 7.5487911e-33 1.4116304e-38], sum to 1.0000
[2019-03-23 22:43:20,826] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5561
[2019-03-23 22:43:20,835] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.4, 88.66666666666667, 1.0, 2.0, 0.5555690286505225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 657943.4551882119, 657943.4551882119, 151716.8572907148], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5291400.0000, 
sim time next is 5292000.0000, 
raw observation next is [23.3, 89.0, 1.0, 2.0, 0.5494410286935945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 651378.1674455381, 651378.1674455381, 150726.937108558], 
processed observation next is [1.0, 0.2608695652173913, 0.41851851851851857, 0.89, 1.0, 1.0, 0.4636202722542791, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2326350598019779, 0.2326350598019779, 0.2898594944395346], 
reward next is 0.7101, 
noisyNet noise sample is [array([0.42020592], dtype=float32), 0.9878376]. 
=============================================
[2019-03-23 22:43:20,849] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[69.03467]
 [69.03467]
 [69.03467]
 [69.03467]
 [69.03467]], R is [[69.05446625]
 [69.07215881]
 [69.08699799]
 [69.09963226]
 [69.11483765]].
[2019-03-23 22:43:24,253] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.7409366e-17 1.0000000e+00 1.3377970e-28 5.7848969e-27 1.4975451e-31], sum to 1.0000
[2019-03-23 22:43:24,257] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5131
[2019-03-23 22:43:24,267] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.98333333333333, 75.66666666666667, 1.0, 2.0, 0.6217588524805664, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 711960.4444792755, 711960.4444792755, 162028.0624412308], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5349000.0000, 
sim time next is 5349600.0000, 
raw observation next is [26.9, 76.0, 1.0, 2.0, 0.6211976482652297, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 711770.4260914836, 711770.4260914836, 161951.5715912486], 
processed observation next is [1.0, 0.9565217391304348, 0.5518518518518518, 0.76, 1.0, 1.0, 0.5490448193633687, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25420372360410126, 0.25420372360410126, 0.31144532998317037], 
reward next is 0.6886, 
noisyNet noise sample is [array([-1.5141363], dtype=float32), -0.46217558]. 
=============================================
[2019-03-23 22:43:26,936] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.8433877e-18 1.0000000e+00 4.6871715e-32 4.6067895e-29 6.3247429e-33], sum to 1.0000
[2019-03-23 22:43:26,941] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1532
[2019-03-23 22:43:26,948] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1481873.347180068 W.
[2019-03-23 22:43:26,954] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.45, 83.5, 1.0, 2.0, 0.6498158199878584, 1.0, 2.0, 0.6498158199878584, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1481873.347180068, 1481873.347180068, 285603.5139275521], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5391000.0000, 
sim time next is 5391600.0000, 
raw observation next is [26.63333333333333, 82.66666666666667, 1.0, 2.0, 0.4217386520723676, 1.0, 2.0, 0.4217386520723676, 1.0, 1.0, 0.6714216691682121, 6.9112, 6.9112, 121.94756008, 1442594.50123415, 1442594.50123415, 306735.7635799671], 
processed observation next is [1.0, 0.391304347826087, 0.5419753086419752, 0.8266666666666667, 1.0, 1.0, 0.3115936334194852, 1.0, 1.0, 0.3115936334194852, 1.0, 0.5, 0.5892770864602651, 0.0, 0.0, 0.8096049824067558, 0.5152123218693393, 0.5152123218693393, 0.5898764684230137], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6705395], dtype=float32), 0.680782]. 
=============================================
[2019-03-23 22:43:27,028] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.3748242e-19 1.0000000e+00 5.5787810e-32 1.3407046e-27 1.0114383e-34], sum to 1.0000
[2019-03-23 22:43:27,035] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6496
[2019-03-23 22:43:27,035] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1371894.097499754 W.
[2019-03-23 22:43:27,042] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.6016320091757731, 1.0, 1.0, 0.6016320091757731, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9258507350435, 1371894.097499754, 1371894.097499755, 268603.6029293293], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5403600.0000, 
sim time next is 5404200.0000, 
raw observation next is [27.3, 82.66666666666667, 1.0, 2.0, 0.6495844015573287, 1.0, 2.0, 0.6495844015573287, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260425571521, 1481345.098290331, 1481345.098290331, 285520.5709729407], 
processed observation next is [1.0, 0.5652173913043478, 0.5666666666666667, 0.8266666666666667, 1.0, 1.0, 0.5828385732825341, 1.0, 1.0, 0.5828385732825341, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621284316924, 0.5290518208179753, 0.5290518208179753, 0.549078021101809], 
reward next is 0.4509, 
noisyNet noise sample is [array([0.72849953], dtype=float32), 1.4024404]. 
=============================================
[2019-03-23 22:43:28,804] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.3458611e-17 1.0000000e+00 5.7946400e-26 2.1051363e-24 1.5845947e-27], sum to 1.0000
[2019-03-23 22:43:28,812] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9756
[2019-03-23 22:43:28,820] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.26666666666667, 92.33333333333333, 1.0, 2.0, 0.8991796002242468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1024962.179835402, 1024962.179835402, 217290.3967491686], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5470800.0000, 
sim time next is 5471400.0000, 
raw observation next is [27.33333333333333, 92.16666666666667, 1.0, 2.0, 0.8877424738357537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1011916.552038062, 1011916.552038062, 214742.4420913097], 
processed observation next is [1.0, 0.30434782608695654, 0.5679012345679011, 0.9216666666666667, 1.0, 1.0, 0.8663600878997068, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3613987685850221, 0.3613987685850221, 0.4129662347909802], 
reward next is 0.5870, 
noisyNet noise sample is [array([-0.3125767], dtype=float32), -2.2989693]. 
=============================================
[2019-03-23 22:43:29,710] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.0922084e-20 1.0000000e+00 3.6612541e-30 4.4004114e-28 7.9156798e-34], sum to 1.0000
[2019-03-23 22:43:29,722] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8160
[2019-03-23 22:43:29,728] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.63333333333333, 92.16666666666667, 1.0, 2.0, 0.7427482784158461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 846549.8279931385, 846549.8279931385, 184398.5232059633], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5447400.0000, 
sim time next is 5448000.0000, 
raw observation next is [26.56666666666667, 92.33333333333334, 1.0, 2.0, 0.7403281385836932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 843789.9471642919, 843789.9471642914, 183922.7675615838], 
processed observation next is [1.0, 0.043478260869565216, 0.5395061728395063, 0.9233333333333335, 1.0, 1.0, 0.6908668316472538, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3013535525586757, 0.3013535525586755, 0.3536976299261227], 
reward next is 0.6463, 
noisyNet noise sample is [array([0.13712835], dtype=float32), 0.16732034]. 
=============================================
[2019-03-23 22:43:29,746] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[59.75899]
 [59.75899]
 [59.75899]
 [59.75899]
 [59.75899]], R is [[59.80771255]
 [59.85502243]
 [59.90110016]
 [59.9464798 ]
 [59.99106216]].
[2019-03-23 22:43:38,594] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.6609824e-23 1.0000000e+00 7.4348698e-35 1.9773515e-31 4.4456407e-38], sum to 1.0000
[2019-03-23 22:43:38,605] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8144
[2019-03-23 22:43:38,613] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 97.0, 1.0, 2.0, 0.5861804860625255, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 678343.7097675359, 678343.7097675359, 156213.3977180861], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5629800.0000, 
sim time next is 5630400.0000, 
raw observation next is [23.5, 97.0, 1.0, 2.0, 0.5874907624319071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 679858.8689172696, 679858.8689172692, 156436.9320617355], 
processed observation next is [0.0, 0.17391304347826086, 0.42592592592592593, 0.97, 1.0, 1.0, 0.5089175743236989, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24280673889902488, 0.2428067388990247, 0.30084025396487596], 
reward next is 0.6992, 
noisyNet noise sample is [array([1.4333051], dtype=float32), -0.3435673]. 
=============================================
[2019-03-23 22:43:43,286] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 22:43:43,287] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:43:43,288] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:43:43,288] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:43:43,289] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:43:43,290] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:43:43,292] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:43:43,295] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:43:43,295] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:43:43,297] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:43:43,299] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:43:43,311] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run41
[2019-03-23 22:43:43,311] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run41
[2019-03-23 22:43:43,311] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run41
[2019-03-23 22:43:43,312] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run41
[2019-03-23 22:43:43,415] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run41
[2019-03-23 22:44:00,469] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.124086425]
[2019-03-23 22:44:00,469] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.33333333333333, 46.0, 1.0, 2.0, 0.2782959715943287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 358783.9819833922, 358783.9819833922, 112923.9054502182]
[2019-03-23 22:44:00,470] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:44:00,472] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.2457270e-23 1.0000000e+00 1.4134855e-36 1.0463157e-33 0.0000000e+00], sampled 0.8701516853882948
[2019-03-23 22:44:11,847] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.124086425]
[2019-03-23 22:44:11,847] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.58618068, 86.01778098333334, 1.0, 2.0, 0.5534525101624036, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8811144208684334, 6.911199999999999, 6.9112, 121.9260426155854, 1261940.473522414, 1261940.473522415, 276189.5782479844]
[2019-03-23 22:44:11,848] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:44:11,850] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [8.2457270e-23 1.0000000e+00 1.4134855e-36 1.0463157e-33 0.0000000e+00], sampled 0.9615642141392856
[2019-03-23 22:44:12,448] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.124086425]
[2019-03-23 22:44:12,449] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.35, 75.0, 1.0, 2.0, 0.4102143401625796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 501991.337008155, 501991.337008155, 129909.3196596843]
[2019-03-23 22:44:12,450] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:44:12,454] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [8.2457270e-23 1.0000000e+00 1.4134855e-36 1.0463157e-33 0.0000000e+00], sampled 0.8504905097035365
[2019-03-23 22:44:16,970] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.124086425]
[2019-03-23 22:44:16,971] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.53333333333333, 60.66666666666667, 1.0, 2.0, 0.6029415015767806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 691887.3946311428, 691887.3946311428, 158818.2403227631]
[2019-03-23 22:44:16,971] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:44:16,973] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.2457270e-23 1.0000000e+00 1.4134855e-36 1.0463157e-33 0.0000000e+00], sampled 0.11653064910847377
[2019-03-23 22:44:32,046] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.124086425]
[2019-03-23 22:44:32,047] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.26947172, 66.73385869333333, 1.0, 2.0, 0.518913151216285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 618704.0929214143, 618704.0929214143, 145890.0002501726]
[2019-03-23 22:44:32,047] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:44:32,050] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.2457270e-23 1.0000000e+00 1.4134855e-36 1.0463157e-33 0.0000000e+00], sampled 0.17293968488745914
[2019-03-23 22:45:04,642] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.124086425]
[2019-03-23 22:45:04,644] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.3, 81.66666666666667, 1.0, 2.0, 0.4771701601030666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 575789.6235662407, 575789.6235662407, 139586.9456120505]
[2019-03-23 22:45:04,644] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:45:04,648] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.2457270e-23 1.0000000e+00 1.4134855e-36 1.0463157e-33 0.0000000e+00], sampled 0.5566820270210829
[2019-03-23 22:45:27,932] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.124086425]
[2019-03-23 22:45:27,933] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.54945314666667, 51.02136275, 1.0, 2.0, 0.6814343386321362, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 832584.8449863549, 832584.8449863549, 174986.8556143913]
[2019-03-23 22:45:27,933] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:45:27,936] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.2457270e-23 1.0000000e+00 1.4134855e-36 1.0463157e-33 0.0000000e+00], sampled 0.7613029979399883
[2019-03-23 22:45:28,307] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:45:28,319] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:45:28,434] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:45:28,458] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:45:28,469] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:45:29,483] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1000000, evaluation results [1000000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:45:37,456] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0867014e-19 1.0000000e+00 7.5882877e-33 3.5551709e-28 9.0254493e-34], sum to 1.0000
[2019-03-23 22:45:37,462] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8850
[2019-03-23 22:45:37,469] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.16666666666667, 85.0, 1.0, 2.0, 0.3597775741099044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 456349.1360405533, 456349.1360405533, 123264.8873106229], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5890800.0000, 
sim time next is 5891400.0000, 
raw observation next is [19.1, 85.0, 1.0, 2.0, 0.3556538837219034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 451459.2739255735, 451459.273925573, 122715.7748491669], 
processed observation next is [1.0, 0.17391304347826086, 0.262962962962963, 0.85, 1.0, 1.0, 0.23292129014512308, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16123545497341912, 0.16123545497341893, 0.23599187470993635], 
reward next is 0.7640, 
noisyNet noise sample is [array([-0.13843825], dtype=float32), 0.8866841]. 
=============================================
[2019-03-23 22:45:38,710] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.209609e-23 1.000000e+00 0.000000e+00 2.032935e-37 0.000000e+00], sum to 1.0000
[2019-03-23 22:45:38,720] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6510
[2019-03-23 22:45:38,728] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.7, 59.0, 1.0, 2.0, 0.4165053690451107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 511843.1638095722, 511843.1638095722, 130866.097369658], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5859000.0000, 
sim time next is 5859600.0000, 
raw observation next is [25.53333333333333, 60.33333333333334, 1.0, 2.0, 0.4211558406316808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 517025.6151074707, 517025.6151074707, 131521.7175244363], 
processed observation next is [1.0, 0.8260869565217391, 0.5012345679012346, 0.6033333333333334, 1.0, 1.0, 0.31089981027581054, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18465200539552526, 0.18465200539552526, 0.2529263798546852], 
reward next is 0.7471, 
noisyNet noise sample is [array([-1.871493], dtype=float32), -0.07154084]. 
=============================================
[2019-03-23 22:45:39,743] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.17121886e-26 1.00000000e+00 0.00000000e+00 2.05424131e-36
 0.00000000e+00], sum to 1.0000
[2019-03-23 22:45:39,752] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2321
[2019-03-23 22:45:39,755] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 81.0, 1.0, 2.0, 0.3311716937992474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 418852.2398602603, 418852.2398602603, 119488.3197189456], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5896800.0000, 
sim time next is 5897400.0000, 
raw observation next is [20.16666666666667, 80.33333333333333, 1.0, 2.0, 0.379699368957042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 479729.076022163, 479729.076022163, 125955.1935355466], 
processed observation next is [1.0, 0.2608695652173913, 0.3024691358024693, 0.8033333333333332, 1.0, 1.0, 0.2615468678060024, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1713318128650582, 0.1713318128650582, 0.2422215260298973], 
reward next is 0.7578, 
noisyNet noise sample is [array([-0.40256414], dtype=float32), 0.73636514]. 
=============================================
[2019-03-23 22:45:54,948] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0708617e-20 1.0000000e+00 1.4131203e-34 1.2525542e-31 1.5547384e-37], sum to 1.0000
[2019-03-23 22:45:54,957] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4258
[2019-03-23 22:45:54,962] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.4, 87.66666666666667, 1.0, 2.0, 0.5441968736230633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 646419.2601927896, 646419.2601927896, 149910.4511133642], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6158400.0000, 
sim time next is 6159000.0000, 
raw observation next is [23.5, 87.33333333333333, 1.0, 2.0, 0.5473216056633377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 649461.4744864468, 649461.4744864464, 150399.9651457797], 
processed observation next is [1.0, 0.2608695652173913, 0.42592592592592593, 0.8733333333333333, 1.0, 1.0, 0.46109714959921144, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23195052660230245, 0.23195052660230228, 0.28923070220342245], 
reward next is 0.7108, 
noisyNet noise sample is [array([-1.9736547], dtype=float32), 1.8025852]. 
=============================================
[2019-03-23 22:45:54,976] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[67.30081]
 [67.30081]
 [67.30081]
 [67.30081]
 [67.30081]], R is [[67.33857727]
 [67.37689972]
 [67.41544342]
 [67.45386505]
 [67.48744965]].
[2019-03-23 22:46:01,075] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0448966e-24 1.0000000e+00 2.8121670e-36 3.1076866e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 22:46:01,085] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9696
[2019-03-23 22:46:01,093] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.73333333333334, 67.66666666666667, 1.0, 2.0, 0.5923677373533767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 686441.7799248466, 686441.7799248466, 157315.0000815664], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6294000.0000, 
sim time next is 6294600.0000, 
raw observation next is [27.55, 68.5, 1.0, 2.0, 0.5913335510130668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 685737.0323792963, 685737.0323792959, 157160.1411153768], 
processed observation next is [0.0, 0.8695652173913043, 0.575925925925926, 0.685, 1.0, 1.0, 0.5134923226346033, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2449060829926058, 0.2449060829926057, 0.30223104060649386], 
reward next is 0.6978, 
noisyNet noise sample is [array([-0.04044217], dtype=float32), -0.18666762]. 
=============================================
[2019-03-23 22:46:01,295] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.046642e-20 1.000000e+00 1.081001e-32 4.173648e-31 3.117219e-35], sum to 1.0000
[2019-03-23 22:46:01,301] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3712
[2019-03-23 22:46:01,308] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.75, 62.83333333333333, 1.0, 2.0, 0.646868259363808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 737217.7031496238, 737217.7031496238, 166328.225769791], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6275400.0000, 
sim time next is 6276000.0000, 
raw observation next is [29.8, 62.66666666666667, 1.0, 2.0, 0.6495004107501783, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 740218.9410213553, 740218.9410213553, 166802.8882790058], 
processed observation next is [0.0, 0.6521739130434783, 0.6592592592592593, 0.6266666666666667, 1.0, 1.0, 0.5827385842264027, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2643639075076269, 0.2643639075076269, 0.32077478515193425], 
reward next is 0.6792, 
noisyNet noise sample is [array([0.6258692], dtype=float32), -1.4767944]. 
=============================================
[2019-03-23 22:46:01,327] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[62.86824]
 [62.86824]
 [62.86824]
 [62.86824]
 [62.86824]], R is [[62.9187851 ]
 [62.96973419]
 [63.01864624]
 [63.06729507]
 [63.11571121]].
[2019-03-23 22:46:02,143] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.9340627e-25 1.0000000e+00 0.0000000e+00 4.3298732e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 22:46:02,152] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6497
[2019-03-23 22:46:02,157] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.55, 68.5, 1.0, 2.0, 0.5913335510130668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 685737.0323792963, 685737.0323792959, 157160.1411153768], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6294600.0000, 
sim time next is 6295200.0000, 
raw observation next is [27.36666666666667, 69.33333333333333, 1.0, 2.0, 0.5904980118083325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 685284.7910440703, 685284.7910440703, 157040.4190752669], 
processed observation next is [0.0, 0.8695652173913043, 0.569135802469136, 0.6933333333333332, 1.0, 1.0, 0.5124976331051577, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2447445682300251, 0.2447445682300251, 0.3020008059139748], 
reward next is 0.6980, 
noisyNet noise sample is [array([-1.1176357], dtype=float32), 1.4107523]. 
=============================================
[2019-03-23 22:46:04,098] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.5754964e-23 1.0000000e+00 4.6182229e-38 3.1797574e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 22:46:04,105] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5152
[2019-03-23 22:46:04,113] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.2, 86.0, 1.0, 2.0, 0.6093821954507705, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 701535.791149677, 701535.7911496765, 160044.4078794924], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6336000.0000, 
sim time next is 6336600.0000, 
raw observation next is [25.43333333333333, 85.0, 1.0, 2.0, 0.6141530613575292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 705829.62746143, 705829.62746143, 160820.064527889], 
processed observation next is [0.0, 0.34782608695652173, 0.49753086419753073, 0.85, 1.0, 1.0, 0.540658406378011, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2520820098076536, 0.2520820098076536, 0.30926935486132495], 
reward next is 0.6907, 
noisyNet noise sample is [array([0.69706833], dtype=float32), 0.2480227]. 
=============================================
[2019-03-23 22:46:04,428] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.8239927e-22 1.0000000e+00 1.2219465e-34 1.1572258e-32 1.8072411e-36], sum to 1.0000
[2019-03-23 22:46:04,436] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5179
[2019-03-23 22:46:04,443] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.11666666666667, 69.33333333333333, 1.0, 2.0, 0.6872279386962109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 783238.0034145945, 783238.0034145945, 173739.6960905222], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6382200.0000, 
sim time next is 6382800.0000, 
raw observation next is [29.0, 70.0, 1.0, 2.0, 0.6874341284894193, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 783473.1193189819, 783473.1193189819, 173778.2799536838], 
processed observation next is [0.0, 0.9130434782608695, 0.6296296296296297, 0.7, 1.0, 1.0, 0.6278977720112134, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27981182832820783, 0.27981182832820783, 0.33418899991093043], 
reward next is 0.6658, 
noisyNet noise sample is [array([0.5873256], dtype=float32), -2.1364648]. 
=============================================
[2019-03-23 22:46:07,943] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6809722e-20 1.0000000e+00 8.6159557e-34 1.1936972e-30 6.6425435e-35], sum to 1.0000
[2019-03-23 22:46:07,954] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9564
[2019-03-23 22:46:07,959] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.13333333333333, 90.33333333333334, 1.0, 2.0, 0.5377894812320633, 1.0, 1.0, 0.5377894812320633, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9258376528571, 1226198.239969705, 1226198.239969705, 247316.6749515148], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6406800.0000, 
sim time next is 6407400.0000, 
raw observation next is [25.06666666666667, 90.66666666666667, 1.0, 2.0, 1.001072789577445, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.151271941722572, 6.9112, 121.9249898883891, 1264224.095171919, 1141286.865090474, 240979.7613055122], 
processed observation next is [1.0, 0.13043478260869565, 0.4839506172839507, 0.9066666666666667, 1.0, 1.0, 1.0012771304493393, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.02400719417225723, 0.0, 0.8094551398058044, 0.45150860541854254, 0.40760245181802646, 0.46342261789521577], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.86737525], dtype=float32), 0.9817521]. 
=============================================
[2019-03-23 22:46:08,099] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.0885494e-21 1.0000000e+00 2.8698141e-33 1.2684604e-31 7.8793995e-36], sum to 1.0000
[2019-03-23 22:46:08,104] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4510
[2019-03-23 22:46:08,107] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 85.0, 1.0, 2.0, 0.6685634448111113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 761955.3894890782, 761955.3894890782, 170275.991865834], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6398400.0000, 
sim time next is 6399000.0000, 
raw observation next is [26.0, 85.5, 1.0, 2.0, 0.6678621370252772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 761155.7188445323, 761155.7188445319, 170146.9755965882], 
processed observation next is [1.0, 0.043478260869565216, 0.5185185185185185, 0.855, 1.0, 1.0, 0.604597782172949, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2718413281587615, 0.2718413281587614, 0.32720572230113115], 
reward next is 0.6728, 
noisyNet noise sample is [array([-0.15098783], dtype=float32), 0.7624993]. 
=============================================
[2019-03-23 22:46:08,132] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[61.282032]
 [61.282032]
 [61.282032]
 [61.282032]
 [61.282032]], R is [[61.34200287]
 [61.40113068]
 [61.45896912]
 [61.51541901]
 [61.57021332]].
[2019-03-23 22:46:11,835] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.6000875e-19 1.0000000e+00 2.9094378e-28 1.5170218e-28 2.7119313e-31], sum to 1.0000
[2019-03-23 22:46:11,844] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0453
[2019-03-23 22:46:11,848] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.71666666666667, 75.5, 1.0, 2.0, 0.6638850341686595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 756620.8179035079, 756620.8179035079, 169418.5746398434], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6480600.0000, 
sim time next is 6481200.0000, 
raw observation next is [27.63333333333333, 76.0, 1.0, 2.0, 0.6644040016231963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 757212.5702492299, 757212.5702492299, 169513.5720693338], 
processed observation next is [1.0, 0.0, 0.5790123456790122, 0.76, 1.0, 1.0, 0.6004809543133289, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2704330608032964, 0.2704330608032964, 0.32598763859487273], 
reward next is 0.6740, 
noisyNet noise sample is [array([-0.22592047], dtype=float32), -0.62292206]. 
=============================================
[2019-03-23 22:46:20,213] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 22:46:20,214] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:46:20,215] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:46:20,216] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:46:20,218] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:46:20,219] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:46:20,217] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:46:20,222] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:46:20,219] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:46:20,225] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:46:20,228] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:46:20,244] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run42
[2019-03-23 22:46:20,269] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run42
[2019-03-23 22:46:20,269] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run42
[2019-03-23 22:46:20,270] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run42
[2019-03-23 22:46:20,292] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run42
[2019-03-23 22:46:27,012] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.10791302]
[2019-03-23 22:46:27,013] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [19.25, 67.83333333333333, 1.0, 2.0, 0.3296111418160382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 425198.4819439503, 425198.4819439508, 115136.2397765039]
[2019-03-23 22:46:27,014] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:46:27,016] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [7.1801780e-24 1.0000000e+00 3.1431853e-38 3.3054267e-35 0.0000000e+00], sampled 0.5137776355518577
[2019-03-23 22:46:34,780] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.10791302]
[2019-03-23 22:46:34,781] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.93333333333333, 76.0, 1.0, 2.0, 0.3470066936710507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 437419.5783877172, 437419.5783877167, 121537.041323895]
[2019-03-23 22:46:34,782] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:46:34,783] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.1801780e-24 1.0000000e+00 3.1431853e-38 3.3054267e-35 0.0000000e+00], sampled 0.7938674295168148
[2019-03-23 22:46:58,108] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.10791302]
[2019-03-23 22:46:58,110] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.0, 62.0, 1.0, 2.0, 0.4919522479364535, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 588867.9253580329, 588867.9253580329, 141713.3247121607]
[2019-03-23 22:46:58,112] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:46:58,114] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.1801780e-24 1.0000000e+00 3.1431853e-38 3.3054267e-35 0.0000000e+00], sampled 0.5363019666968979
[2019-03-23 22:46:58,142] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.10791302]
[2019-03-23 22:46:58,142] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.66666666666666, 59.33333333333333, 1.0, 2.0, 0.5021410459322817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 598987.7343990458, 598987.7343990454, 143234.8444367167]
[2019-03-23 22:46:58,144] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:46:58,145] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.1801780e-24 1.0000000e+00 3.1431853e-38 3.3054267e-35 0.0000000e+00], sampled 0.5675867541339396
[2019-03-23 22:47:06,215] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.10791302]
[2019-03-23 22:47:06,216] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.05, 78.83333333333334, 1.0, 2.0, 0.6416932067351415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 731317.0266788701, 731317.0266788701, 165398.9675619698]
[2019-03-23 22:47:06,217] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:47:06,218] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.1801780e-24 1.0000000e+00 3.1431853e-38 3.3054267e-35 0.0000000e+00], sampled 0.8079493612773928
[2019-03-23 22:47:28,303] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.10791302]
[2019-03-23 22:47:28,304] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.16666666666667, 98.16666666666667, 1.0, 2.0, 0.7578424955079337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 863763.2065918719, 863763.2065918719, 187389.0506412325]
[2019-03-23 22:47:28,305] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:47:28,310] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.1801780e-24 1.0000000e+00 3.1431853e-38 3.3054267e-35 0.0000000e+00], sampled 0.48074772623622697
[2019-03-23 22:47:46,371] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.10791302]
[2019-03-23 22:47:46,374] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.23333333333333, 59.66666666666667, 1.0, 2.0, 0.338019435648477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 426989.953848539, 426989.953848539, 120370.3993869427]
[2019-03-23 22:47:46,375] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:47:46,379] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.1801780e-24 1.0000000e+00 3.1431853e-38 3.3054267e-35 0.0000000e+00], sampled 0.47487254083870656
[2019-03-23 22:47:56,796] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.10791302]
[2019-03-23 22:47:56,796] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.11666666666667, 76.66666666666667, 1.0, 2.0, 0.5170606986063365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 612496.0869474573, 612496.0869474573, 145440.9281436513]
[2019-03-23 22:47:56,797] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:47:56,800] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.1801780e-24 1.0000000e+00 3.1431853e-38 3.3054267e-35 0.0000000e+00], sampled 0.5172135747724861
[2019-03-23 22:48:02,773] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:48:02,941] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:48:02,991] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:48:03,017] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:48:03,021] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:48:04,033] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1025000, evaluation results [1025000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:48:04,316] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.785144e-25 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-23 22:48:04,333] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9676
[2019-03-23 22:48:04,344] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.45, 54.5, 1.0, 2.0, 0.3710558548276143, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 462399.5867539573, 462399.5867539573, 124671.8390541817], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6636600.0000, 
sim time next is 6637200.0000, 
raw observation next is [25.16666666666666, 56.66666666666666, 1.0, 2.0, 0.3772884279658109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 469456.1042201903, 469456.1042201903, 125507.9751864623], 
processed observation next is [1.0, 0.8260869565217391, 0.4876543209876541, 0.5666666666666665, 1.0, 1.0, 0.2586766999592987, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1676628943643537, 0.1676628943643537, 0.2413614907431967], 
reward next is 0.7586, 
noisyNet noise sample is [array([-0.4207526], dtype=float32), -0.15802525]. 
=============================================
[2019-03-23 22:48:04,576] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4354646e-22 1.0000000e+00 4.2296362e-37 2.3884506e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 22:48:04,586] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2599
[2019-03-23 22:48:04,590] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 45.33333333333334, 1.0, 2.0, 0.3256986452492784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 420149.9774547277, 420149.9774547277, 114872.973945257], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6666000.0000, 
sim time next is 6666600.0000, 
raw observation next is [23.0, 45.16666666666666, 1.0, 2.0, 0.3162372290512755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 407941.54125799, 407941.54125799, 113136.3318773561], 
processed observation next is [1.0, 0.13043478260869565, 0.4074074074074074, 0.45166666666666655, 1.0, 1.0, 0.18599670125151846, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14569340759213928, 0.14569340759213928, 0.2175698689949156], 
reward next is 0.7824, 
noisyNet noise sample is [array([0.24529858], dtype=float32), 1.617101]. 
=============================================
[2019-03-23 22:48:05,793] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.2058802e-23 1.0000000e+00 5.3611805e-37 5.2665695e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 22:48:05,799] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7996
[2019-03-23 22:48:05,804] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.2, 46.5, 1.0, 2.0, 0.2729572919236708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 352058.5514979695, 352058.5514979691, 112286.0093687453], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6659400.0000, 
sim time next is 6660000.0000, 
raw observation next is [23.1, 47.0, 1.0, 2.0, 0.2720225000028505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 350858.7498424751, 350858.7498424751, 112175.0490302398], 
processed observation next is [1.0, 0.08695652173913043, 0.41111111111111115, 0.47, 1.0, 1.0, 0.1333601190510125, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.12530669637231254, 0.12530669637231254, 0.21572124813507654], 
reward next is 0.7843, 
noisyNet noise sample is [array([-0.3053366], dtype=float32), -1.3406142]. 
=============================================
[2019-03-23 22:48:05,815] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[77.41326]
 [77.41326]
 [77.41326]
 [77.41326]
 [77.41326]], R is [[77.42340088]
 [77.43323517]
 [77.44274139]
 [77.45185852]
 [77.46052551]].
[2019-03-23 22:48:05,865] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.8760592e-25 1.0000000e+00 0.0000000e+00 2.1564731e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 22:48:05,871] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0417
[2019-03-23 22:48:05,879] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.46666666666667, 42.83333333333333, 1.0, 2.0, 0.7104597202767108, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 904816.3088122417, 904816.3088122412, 181314.7870911955], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6688200.0000, 
sim time next is 6688800.0000, 
raw observation next is [25.7, 42.0, 1.0, 2.0, 0.6709361621627937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000003, 6.9112, 121.9260426156618, 854086.1992112758, 854086.1992112744, 173674.2845380165], 
processed observation next is [1.0, 0.43478260869565216, 0.5074074074074074, 0.42, 1.0, 1.0, 0.6082573359080877, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 2.6645352591003756e-16, 0.0, 0.8094621288201359, 0.3050307854325985, 0.305030785432598, 0.3339890087269548], 
reward next is 0.6660, 
noisyNet noise sample is [array([-0.4859465], dtype=float32), -1.6179459]. 
=============================================
[2019-03-23 22:48:06,917] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.7791080e-20 1.0000000e+00 4.6773024e-36 9.2391082e-31 0.0000000e+00], sum to 1.0000
[2019-03-23 22:48:06,923] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1218
[2019-03-23 22:48:06,929] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 45.83333333333334, 1.0, 2.0, 0.3643249584942124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 469993.0400836995, 469993.0400836995, 121112.3599290975], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6664200.0000, 
sim time next is 6664800.0000, 
raw observation next is [23.0, 45.66666666666667, 1.0, 2.0, 0.3454598072372529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 445649.2062959917, 445649.2062959917, 118346.2693432619], 
processed observation next is [1.0, 0.13043478260869565, 0.4074074074074074, 0.4566666666666667, 1.0, 1.0, 0.22078548480625346, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15916043081999703, 0.15916043081999703, 0.22758897950627288], 
reward next is 0.7724, 
noisyNet noise sample is [array([0.4327833], dtype=float32), 0.9275072]. 
=============================================
[2019-03-23 22:48:08,069] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.8330381e-24 1.0000000e+00 0.0000000e+00 1.5786522e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 22:48:08,081] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8761
[2019-03-23 22:48:08,089] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.71666666666667, 45.5, 1.0, 2.0, 0.3293298713191384, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 416937.2491633601, 416937.2491633601, 119255.0599798773], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6725400.0000, 
sim time next is 6726000.0000, 
raw observation next is [25.43333333333334, 47.0, 1.0, 2.0, 0.330255976534747, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 417965.4919039343, 417965.4919039347, 119372.9297596885], 
processed observation next is [1.0, 0.8695652173913043, 0.4975308641975311, 0.47, 1.0, 1.0, 0.20268568635088927, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1492733899656908, 0.14927338996569095, 0.22956332646093944], 
reward next is 0.7704, 
noisyNet noise sample is [array([0.8762285], dtype=float32), 0.10594384]. 
=============================================
[2019-03-23 22:48:08,112] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[72.62724]
 [72.62724]
 [72.62724]
 [72.62724]
 [72.62724]], R is [[72.67140961]
 [72.71535492]
 [72.76021576]
 [72.80605316]
 [72.85103607]].
[2019-03-23 22:48:10,714] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.8774663e-25 1.0000000e+00 0.0000000e+00 3.0749847e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 22:48:10,724] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6990
[2019-03-23 22:48:10,730] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1407056.82643419 W.
[2019-03-23 22:48:10,735] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.03333333333333, 54.66666666666667, 1.0, 2.0, 0.4032319651944294, 1.0, 1.0, 0.4032319651944294, 1.0, 2.0, 0.6435089973802703, 6.9112, 6.9112, 121.94756008, 1407056.82643419, 1407056.82643419, 298572.844587368], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6798000.0000, 
sim time next is 6798600.0000, 
raw observation next is [28.05, 55.0, 1.0, 2.0, 0.6029569671197835, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9653481610483541, 6.911199999999999, 6.9112, 121.9260426156618, 1419875.21710411, 1419875.217104111, 294098.2917433315], 
processed observation next is [1.0, 0.6956521739130435, 0.5944444444444444, 0.55, 1.0, 1.0, 0.527329722761647, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9566852013104427, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5070982918228965, 0.5070982918228968, 0.5655736379679451], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7265403], dtype=float32), -0.11801545]. 
=============================================
[2019-03-23 22:48:13,355] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.5220331e-24 1.0000000e+00 0.0000000e+00 7.3258280e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 22:48:13,361] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4357
[2019-03-23 22:48:13,364] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.93333333333333, 78.33333333333334, 1.0, 2.0, 0.4374223446472367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 534613.8740519426, 534613.8740519426, 133828.0884666478], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6828000.0000, 
sim time next is 6828600.0000, 
raw observation next is [22.86666666666667, 78.16666666666666, 1.0, 2.0, 0.4332177326816992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 530189.3394483243, 530189.3394483243, 133231.1694607488], 
processed observation next is [0.0, 0.0, 0.4024691358024693, 0.7816666666666666, 1.0, 1.0, 0.3252592055734515, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18935333551725866, 0.18935333551725866, 0.2562137874245169], 
reward next is 0.7438, 
noisyNet noise sample is [array([1.1022803], dtype=float32), 1.8775622]. 
=============================================
[2019-03-23 22:48:15,186] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.3557428e-25 1.0000000e+00 0.0000000e+00 1.4698884e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 22:48:15,195] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5689
[2019-03-23 22:48:15,197] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.05, 76.0, 1.0, 2.0, 0.4170536794387336, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 511755.8165295028, 511755.8165295028, 130924.8463437082], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6852600.0000, 
sim time next is 6853200.0000, 
raw observation next is [23.13333333333333, 76.0, 1.0, 2.0, 0.4204704285994022, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 515324.5426450467, 515324.5426450462, 131399.8317686173], 
processed observation next is [0.0, 0.30434782608695654, 0.41234567901234553, 0.76, 1.0, 1.0, 0.3100838435707169, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18404447951608813, 0.18404447951608793, 0.2526919841704179], 
reward next is 0.7473, 
noisyNet noise sample is [array([0.5448763], dtype=float32), 0.788823]. 
=============================================
[2019-03-23 22:48:16,106] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.0417621e-23 1.0000000e+00 1.5512854e-36 8.4245623e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 22:48:16,111] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4849
[2019-03-23 22:48:16,114] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 48.0, 1.0, 2.0, 0.5340531269653118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 627828.1449778436, 627828.1449778432, 147987.744737002], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6876000.0000, 
sim time next is 6876600.0000, 
raw observation next is [30.86666666666667, 48.16666666666666, 1.0, 2.0, 0.5360477928716073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 630519.6555378602, 630519.6555378602, 148326.0220086918], 
processed observation next is [0.0, 0.6086956521739131, 0.6987654320987656, 0.4816666666666666, 1.0, 1.0, 0.4476759438947706, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2251855912635215, 0.2251855912635215, 0.285242350016715], 
reward next is 0.7148, 
noisyNet noise sample is [array([0.86341506], dtype=float32), 2.4099228]. 
=============================================
[2019-03-23 22:48:23,987] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2391909e-22 1.0000000e+00 1.2689406e-37 4.7569488e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 22:48:23,997] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2701
[2019-03-23 22:48:24,001] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.95, 81.0, 1.0, 2.0, 0.6150164738385212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 758144.7574072037, 758144.7574072032, 162923.9996031015], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7007400.0000, 
sim time next is 7008000.0000, 
raw observation next is [21.86666666666667, 81.66666666666666, 1.0, 2.0, 0.5805383816919932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 715712.1493171392, 715712.1493171392, 156862.8206078107], 
processed observation next is [1.0, 0.08695652173913043, 0.36543209876543226, 0.8166666666666665, 1.0, 1.0, 0.5006409305857062, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25561148189897825, 0.25561148189897825, 0.3016592703996359], 
reward next is 0.6983, 
noisyNet noise sample is [array([0.5310088], dtype=float32), 0.046988927]. 
=============================================
[2019-03-23 22:48:24,011] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[70.16179]
 [70.16179]
 [70.16179]
 [70.16179]
 [70.16179]], R is [[70.1585083 ]
 [70.14360809]
 [70.09159088]
 [70.01000977]
 [70.05831146]].
[2019-03-23 22:48:24,714] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.6101430e-25 1.0000000e+00 4.9012796e-38 1.1383067e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 22:48:24,720] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8687
[2019-03-23 22:48:24,724] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.68333333333333, 90.66666666666667, 1.0, 2.0, 0.5715613862406655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 705282.2293120772, 705282.2293120772, 155334.9857008482], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7017000.0000, 
sim time next is 7017600.0000, 
raw observation next is [20.76666666666667, 90.33333333333334, 1.0, 2.0, 0.5015671567414179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 618506.8168709342, 618506.8168709342, 143774.6848595672], 
processed observation next is [1.0, 0.21739130434782608, 0.32469135802469146, 0.9033333333333334, 1.0, 1.0, 0.40662756754930707, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22089529173961936, 0.22089529173961936, 0.2764897785760908], 
reward next is 0.7235, 
noisyNet noise sample is [array([-0.80209064], dtype=float32), -0.3112742]. 
=============================================
[2019-03-23 22:48:27,285] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.5694927e-19 1.0000000e+00 1.7101532e-30 3.9685959e-26 2.9119302e-32], sum to 1.0000
[2019-03-23 22:48:27,292] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3255
[2019-03-23 22:48:27,298] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.76666666666667, 78.66666666666667, 1.0, 2.0, 0.4662041375749074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 562202.7936416463, 562202.7936416463, 137901.243614875], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7062000.0000, 
sim time next is 7062600.0000, 
raw observation next is [23.73333333333333, 78.83333333333334, 1.0, 2.0, 0.4732737554143487, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 570814.6962833119, 570814.6962833119, 138980.6807610372], 
processed observation next is [1.0, 0.7391304347826086, 0.4345679012345678, 0.7883333333333334, 1.0, 1.0, 0.37294494692184366, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20386239152975427, 0.20386239152975427, 0.2672705399250715], 
reward next is 0.7327, 
noisyNet noise sample is [array([-1.3270625], dtype=float32), -1.3104558]. 
=============================================
[2019-03-23 22:48:29,752] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.9014199e-21 1.0000000e+00 6.4367987e-35 4.3511236e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 22:48:29,760] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7933
[2019-03-23 22:48:29,766] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.78333333333333, 83.66666666666667, 1.0, 2.0, 0.5210556492509063, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 649645.1876440003, 649645.1876440003, 147062.0403847131], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7110600.0000, 
sim time next is 7111200.0000, 
raw observation next is [20.76666666666667, 83.33333333333334, 1.0, 2.0, 0.4524526975669524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 564469.878713842, 564469.878713842, 136333.768858459], 
processed observation next is [1.0, 0.30434782608695654, 0.32469135802469146, 0.8333333333333335, 1.0, 1.0, 0.3481579732939909, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20159638525494358, 0.20159638525494358, 0.2621803247278058], 
reward next is 0.7378, 
noisyNet noise sample is [array([0.36541274], dtype=float32), -1.5915053]. 
=============================================
[2019-03-23 22:48:33,788] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.1955562e-23 1.0000000e+00 8.5464756e-38 1.2308164e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 22:48:33,795] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0706
[2019-03-23 22:48:33,799] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.76666666666667, 91.0, 1.0, 2.0, 0.3649659441075695, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 455962.9837958093, 455962.9837958093, 123869.3658487184], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7190400.0000, 
sim time next is 7191000.0000, 
raw observation next is [19.85, 90.5, 1.0, 2.0, 0.365462890879375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 456447.7302453273, 456447.7302453273, 123933.9096728304], 
processed observation next is [1.0, 0.21739130434782608, 0.2907407407407408, 0.905, 1.0, 1.0, 0.2445986796183036, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1630170465161883, 0.1630170465161883, 0.23833444167852], 
reward next is 0.7617, 
noisyNet noise sample is [array([1.0967575], dtype=float32), -0.90608305]. 
=============================================
[2019-03-23 22:48:33,819] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[75.92528]
 [75.92528]
 [75.92528]
 [75.92528]
 [75.92528]], R is [[75.92768097]
 [75.93019104]
 [75.9308548 ]
 [75.93178558]
 [75.93186951]].
[2019-03-23 22:48:39,217] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2587047e-23 1.0000000e+00 2.4120054e-38 1.0158352e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 22:48:39,226] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1819
[2019-03-23 22:48:39,230] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.23333333333333, 79.66666666666667, 1.0, 2.0, 0.3722794679193347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 464771.047527387, 464771.047527387, 124854.271799847], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7251600.0000, 
sim time next is 7252200.0000, 
raw observation next is [21.15, 80.0, 1.0, 2.0, 0.3708236512007216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 463179.6834949369, 463179.6834949369, 124660.4459647746], 
processed observation next is [1.0, 0.9565217391304348, 0.33888888888888885, 0.8, 1.0, 1.0, 0.25098053714371615, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16542131553390604, 0.16542131553390604, 0.23973162685533575], 
reward next is 0.7603, 
noisyNet noise sample is [array([-1.2674367], dtype=float32), 1.099976]. 
=============================================
[2019-03-23 22:48:49,450] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.8808992e-22 1.0000000e+00 3.6757532e-37 2.6412336e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 22:48:49,456] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5095
[2019-03-23 22:48:49,464] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.81666666666666, 76.5, 1.0, 2.0, 0.4961732542908073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 591187.7101398545, 591187.7101398545, 142272.8472399243], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7477800.0000, 
sim time next is 7478400.0000, 
raw observation next is [24.93333333333333, 76.0, 1.0, 2.0, 0.4986429131842278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 593700.0873311298, 593700.0873311298, 142643.5461764296], 
processed observation next is [0.0, 0.5652173913043478, 0.47901234567901224, 0.76, 1.0, 1.0, 0.4031463252193188, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21203574547540352, 0.21203574547540352, 0.27431451187774925], 
reward next is 0.7257, 
noisyNet noise sample is [array([-2.1703408], dtype=float32), -0.1955836]. 
=============================================
[2019-03-23 22:48:51,838] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.0253862e-25 1.0000000e+00 0.0000000e+00 3.8595147e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 22:48:51,848] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8717
[2019-03-23 22:48:51,853] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.85, 84.0, 1.0, 2.0, 0.4987379226910527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 593153.3766666291, 593153.3766666291, 142633.6857086556], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7554600.0000, 
sim time next is 7555200.0000, 
raw observation next is [24.03333333333333, 83.33333333333334, 1.0, 2.0, 0.5031196860423087, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 597374.8280936889, 597374.8280936889, 143284.5424074955], 
processed observation next is [0.0, 0.43478260869565216, 0.4456790123456789, 0.8333333333333335, 1.0, 1.0, 0.40847581671703415, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2133481528906032, 0.2133481528906032, 0.27554719693749136], 
reward next is 0.7245, 
noisyNet noise sample is [array([-1.0664884], dtype=float32), -0.06794626]. 
=============================================
[2019-03-23 22:48:52,532] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.7580412e-25 1.0000000e+00 0.0000000e+00 1.3963207e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 22:48:52,541] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7589
[2019-03-23 22:48:52,544] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.16666666666666, 66.0, 1.0, 2.0, 0.5280204718548624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 622480.4378144743, 622480.4378144743, 147083.055248501], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7567800.0000, 
sim time next is 7568400.0000, 
raw observation next is [27.33333333333334, 66.0, 1.0, 2.0, 0.5333616316381012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 626950.3815509257, 626950.3815509257, 147872.8975962746], 
processed observation next is [0.0, 0.6086956521739131, 0.5679012345679014, 0.66, 1.0, 1.0, 0.44447813290250143, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22391085055390203, 0.22391085055390203, 0.2843709569159127], 
reward next is 0.7156, 
noisyNet noise sample is [array([-1.4213641], dtype=float32), 0.013745773]. 
=============================================
[2019-03-23 22:48:53,418] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.6976010e-21 1.0000000e+00 1.4414095e-34 1.7585721e-31 1.8510931e-37], sum to 1.0000
[2019-03-23 22:48:53,425] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4198
[2019-03-23 22:48:53,428] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 86.83333333333333, 1.0, 2.0, 0.4817097468288104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 576662.2134818739, 576662.2134818734, 140127.9247231103], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7552200.0000, 
sim time next is 7552800.0000, 
raw observation next is [23.3, 86.0, 1.0, 2.0, 0.4859719934882878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 580847.5959282393, 580847.5959282388, 140753.2304730742], 
processed observation next is [0.0, 0.43478260869565216, 0.41851851851851857, 0.86, 1.0, 1.0, 0.3880618970098664, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20744556997437116, 0.207445569974371, 0.27067928937129654], 
reward next is 0.7293, 
noisyNet noise sample is [array([1.8166001], dtype=float32), 1.7317303]. 
=============================================
[2019-03-23 22:48:54,152] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.3521599e-25 1.0000000e+00 1.0872435e-36 2.9325244e-36 0.0000000e+00], sum to 1.0000
[2019-03-23 22:48:54,161] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6962
[2019-03-23 22:48:54,170] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 86.16666666666667, 1.0, 2.0, 0.4438736098574696, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 541403.6652583255, 541403.6652583255, 134749.2888338913], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7606200.0000, 
sim time next is 7606800.0000, 
raw observation next is [21.9, 86.0, 1.0, 2.0, 0.4378049776591019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 535011.5452941825, 535011.5452941825, 133882.3619487996], 
processed observation next is [1.0, 0.043478260869565216, 0.36666666666666664, 0.86, 1.0, 1.0, 0.3307202114989309, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19107555189077946, 0.19107555189077946, 0.2574660806707685], 
reward next is 0.7425, 
noisyNet noise sample is [array([0.3212226], dtype=float32), -0.8985516]. 
=============================================
[2019-03-23 22:48:54,431] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 22:48:54,431] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:48:54,432] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:48:54,433] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:48:54,434] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:48:54,435] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:48:54,434] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:48:54,437] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:48:54,437] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:48:54,439] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:48:54,441] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:48:54,459] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run43
[2019-03-23 22:48:54,460] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run43
[2019-03-23 22:48:54,502] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run43
[2019-03-23 22:48:54,526] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run43
[2019-03-23 22:48:54,528] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run43
[2019-03-23 22:49:07,635] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.07180932]
[2019-03-23 22:49:07,636] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.78048077666667, 49.08742776333334, 1.0, 2.0, 0.5731988707717737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 704113.0439025646, 704113.0439025646, 155532.9120460583]
[2019-03-23 22:49:07,637] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:49:07,639] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.8932731e-22 1.0000000e+00 5.8315569e-35 3.2834014e-32 2.7566899e-37], sampled 0.4424880114730323
[2019-03-23 22:49:22,684] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.07180932]
[2019-03-23 22:49:22,686] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.86666666666667, 39.66666666666667, 1.0, 2.0, 0.3970104835347504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 488410.3007714829, 488410.3007714829, 128114.4053998634]
[2019-03-23 22:49:22,686] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:49:22,688] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.8932731e-22 1.0000000e+00 5.8315569e-35 3.2834014e-32 2.7566899e-37], sampled 0.6476962737097123
[2019-03-23 22:49:40,580] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.07180932]
[2019-03-23 22:49:40,582] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [33.248475185, 55.65523782, 1.0, 2.0, 0.7139312095534757, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 813688.0432911552, 813688.0432911557, 178803.486105315]
[2019-03-23 22:49:40,582] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:49:40,585] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.8932731e-22 1.0000000e+00 5.8315569e-35 3.2834014e-32 2.7566899e-37], sampled 0.3658187343279483
[2019-03-23 22:50:06,077] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.07180932]
[2019-03-23 22:50:06,078] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.55, 81.0, 1.0, 2.0, 0.5737953208902427, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 666136.4823813213, 666136.4823813213, 154211.8284251538]
[2019-03-23 22:50:06,079] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:50:06,082] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.8932731e-22 1.0000000e+00 5.8315569e-35 3.2834014e-32 2.7566899e-37], sampled 0.8678560291689322
[2019-03-23 22:50:21,849] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.07180932]
[2019-03-23 22:50:21,850] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.08333333333333, 64.0, 1.0, 2.0, 0.5581614240772671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 651392.4038026304, 651392.4038026304, 151748.8173189793]
[2019-03-23 22:50:21,852] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:50:21,854] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.8932731e-22 1.0000000e+00 5.8315569e-35 3.2834014e-32 2.7566899e-37], sampled 0.44537304146822354
[2019-03-23 22:50:36,590] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:50:36,703] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:50:36,751] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:50:37,001] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:50:37,036] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:50:38,049] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1050000, evaluation results [1050000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:50:40,802] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.2233807e-26 1.0000000e+00 6.8197283e-36 5.1393807e-37 0.0000000e+00], sum to 1.0000
[2019-03-23 22:50:40,810] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9684
[2019-03-23 22:50:40,823] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1402243.685657859 W.
[2019-03-23 22:50:40,826] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.01666666666667, 73.83333333333333, 1.0, 2.0, 0.6116012019649701, 1.0, 2.0, 0.6116012019649701, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1402243.685657859, 1402243.685657859, 272431.8093156698], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7645800.0000, 
sim time next is 7646400.0000, 
raw observation next is [26.1, 73.0, 1.0, 2.0, 0.4161630627936022, 1.0, 2.0, 0.4161630627936022, 1.0, 1.0, 0.6625451494521518, 6.911199999999999, 6.9112, 121.94756008, 1423504.981525841, 1423504.981525841, 304234.8206476247], 
processed observation next is [1.0, 0.5217391304347826, 0.5222222222222223, 0.73, 1.0, 1.0, 0.3049560271352408, 1.0, 1.0, 0.3049560271352408, 1.0, 0.5, 0.5781814368151897, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5083946362592289, 0.5083946362592289, 0.5850669627838937], 
reward next is 0.4149, 
noisyNet noise sample is [array([-1.5805334], dtype=float32), -1.0109702]. 
=============================================
[2019-03-23 22:50:44,428] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.5008066e-23 1.0000000e+00 0.0000000e+00 3.6655071e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 22:50:44,441] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9781
[2019-03-23 22:50:44,444] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.61666666666667, 61.83333333333333, 1.0, 2.0, 0.2845657975707656, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 367076.0658637811, 367076.0658637811, 103239.6801006882], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7697400.0000, 
sim time next is 7698000.0000, 
raw observation next is [19.53333333333333, 63.66666666666667, 1.0, 2.0, 0.2569356552715931, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 331426.8222788958, 331426.8222788958, 101403.3617017033], 
processed observation next is [1.0, 0.08695652173913043, 0.2790123456790123, 0.6366666666666667, 1.0, 1.0, 0.11539958960903943, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1183667222424628, 0.1183667222424628, 0.19500646481096787], 
reward next is 0.8050, 
noisyNet noise sample is [array([-0.49866828], dtype=float32), 1.8382415]. 
=============================================
[2019-03-23 22:50:44,458] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[78.72108]
 [78.72108]
 [78.72108]
 [78.72108]
 [78.72108]], R is [[78.73886108]
 [78.75292969]
 [78.78376007]
 [78.80888367]
 [78.82787323]].
[2019-03-23 22:50:51,507] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.4979591e-20 1.0000000e+00 2.4772587e-33 1.3541656e-28 9.0648838e-35], sum to 1.0000
[2019-03-23 22:50:51,514] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3289
[2019-03-23 22:50:51,520] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.93333333333333, 41.33333333333334, 1.0, 2.0, 0.4091549342123597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 500118.7458453889, 500118.7458453889, 129742.6758834808], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7839600.0000, 
sim time next is 7840200.0000, 
raw observation next is [29.61666666666667, 42.66666666666667, 1.0, 2.0, 0.41457339355329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 506587.7141664608, 506587.7141664608, 130510.8004369662], 
processed observation next is [1.0, 0.7391304347826086, 0.6524691358024692, 0.4266666666666667, 1.0, 1.0, 0.3030635637539167, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18092418363087887, 0.18092418363087887, 0.2509823085326273], 
reward next is 0.7490, 
noisyNet noise sample is [array([-0.09724103], dtype=float32), -1.5856769]. 
=============================================
[2019-03-23 22:50:57,567] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:50:57,568] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:50:57,612] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run6
[2019-03-23 22:50:57,875] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:50:57,876] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:50:57,924] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run6
[2019-03-23 22:50:58,081] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.2125968e-22 1.0000000e+00 2.8443175e-36 4.6969084e-32 1.2284686e-38], sum to 1.0000
[2019-03-23 22:50:58,082] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3488
[2019-03-23 22:50:58,083] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1587429.619721137 W.
[2019-03-23 22:50:58,086] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.1, 47.16666666666667, 1.0, 2.0, 0.7443700628304449, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9745881039212041, 6.9112, 6.9112, 121.9260426156618, 1587429.619721137, 1587429.619721137, 321042.5800107241], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7917000.0000, 
sim time next is 7917600.0000, 
raw observation next is [30.1, 47.33333333333334, 1.0, 2.0, 0.7046535067252471, 1.0, 1.0, 0.7046535067252471, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1640350.349700083, 1640350.349700084, 307577.6999554654], 
processed observation next is [1.0, 0.6521739130434783, 0.6703703703703704, 0.47333333333333344, 1.0, 1.0, 0.6483970318157704, 1.0, 0.5, 0.6483970318157704, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5858394106071725, 0.5858394106071728, 0.5914955768374335], 
reward next is 0.4085, 
noisyNet noise sample is [array([-0.14264451], dtype=float32), 0.4533611]. 
=============================================
[2019-03-23 22:50:58,329] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:50:58,330] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:50:58,332] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run6
[2019-03-23 22:50:58,357] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:50:58,357] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:50:58,362] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run6
[2019-03-23 22:50:58,450] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:50:58,451] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:50:58,454] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run6
[2019-03-23 22:50:58,562] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:50:58,562] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:50:58,566] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run6
[2019-03-23 22:50:58,601] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:50:58,601] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:50:58,604] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run6
[2019-03-23 22:50:58,845] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:50:58,845] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:50:58,849] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run6
[2019-03-23 22:50:58,882] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:50:58,883] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:50:58,887] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run6
[2019-03-23 22:50:59,004] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:50:59,005] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:50:59,007] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run6
[2019-03-23 22:50:59,059] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:50:59,059] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:50:59,064] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run6
[2019-03-23 22:50:59,097] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:50:59,097] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:50:59,117] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:50:59,117] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:50:59,125] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run6
[2019-03-23 22:50:59,127] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run6
[2019-03-23 22:50:59,159] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:50:59,202] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:50:59,205] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run6
[2019-03-23 22:50:59,313] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:50:59,313] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:50:59,317] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run6
[2019-03-23 22:50:59,351] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 22:50:59,351] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:50:59,354] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run6
[2019-03-23 22:51:05,801] A3C_AGENT_WORKER-Thread-21 INFO:Local step 66500, global step 1062727: loss 0.0036
[2019-03-23 22:51:05,804] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 66500, global step 1062727: learning rate 0.0005
[2019-03-23 22:51:06,928] A3C_AGENT_WORKER-Thread-22 INFO:Local step 66500, global step 1063273: loss 0.0263
[2019-03-23 22:51:06,931] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 66500, global step 1063274: learning rate 0.0005
[2019-03-23 22:51:08,125] A3C_AGENT_WORKER-Thread-16 INFO:Local step 66500, global step 1063856: loss 1.2216
[2019-03-23 22:51:08,134] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 66500, global step 1063856: learning rate 0.0005
[2019-03-23 22:51:08,178] A3C_AGENT_WORKER-Thread-11 INFO:Local step 66500, global step 1063879: loss 1.2040
[2019-03-23 22:51:08,179] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 66500, global step 1063879: learning rate 0.0005
[2019-03-23 22:51:08,234] A3C_AGENT_WORKER-Thread-19 INFO:Local step 66500, global step 1063907: loss 1.0999
[2019-03-23 22:51:08,239] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 66500, global step 1063910: learning rate 0.0005
[2019-03-23 22:51:08,315] A3C_AGENT_WORKER-Thread-15 INFO:Local step 66500, global step 1063949: loss 1.0891
[2019-03-23 22:51:08,316] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 66500, global step 1063949: learning rate 0.0005
[2019-03-23 22:51:08,317] A3C_AGENT_WORKER-Thread-18 INFO:Local step 66500, global step 1063949: loss 1.1249
[2019-03-23 22:51:08,322] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 66500, global step 1063950: learning rate 0.0005
[2019-03-23 22:51:08,393] A3C_AGENT_WORKER-Thread-9 INFO:Local step 66500, global step 1063982: loss 1.1133
[2019-03-23 22:51:08,394] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 66500, global step 1063982: learning rate 0.0005
[2019-03-23 22:51:08,673] A3C_AGENT_WORKER-Thread-13 INFO:Local step 66500, global step 1064120: loss 1.0208
[2019-03-23 22:51:08,674] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 66500, global step 1064120: learning rate 0.0005
[2019-03-23 22:51:08,804] A3C_AGENT_WORKER-Thread-12 INFO:Local step 66500, global step 1064185: loss 0.9269
[2019-03-23 22:51:08,810] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 66500, global step 1064185: learning rate 0.0005
[2019-03-23 22:51:09,002] A3C_AGENT_WORKER-Thread-3 INFO:Local step 66500, global step 1064282: loss 0.6461
[2019-03-23 22:51:09,007] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 66500, global step 1064283: learning rate 0.0005
[2019-03-23 22:51:09,138] A3C_AGENT_WORKER-Thread-17 INFO:Local step 66500, global step 1064346: loss 0.5124
[2019-03-23 22:51:09,141] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 66500, global step 1064347: learning rate 0.0005
[2019-03-23 22:51:09,191] A3C_AGENT_WORKER-Thread-14 INFO:Local step 66500, global step 1064370: loss 0.3758
[2019-03-23 22:51:09,194] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 66500, global step 1064372: learning rate 0.0005
[2019-03-23 22:51:09,213] A3C_AGENT_WORKER-Thread-10 INFO:Local step 66500, global step 1064379: loss 0.3152
[2019-03-23 22:51:09,217] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 66500, global step 1064380: learning rate 0.0005
[2019-03-23 22:51:09,337] A3C_AGENT_WORKER-Thread-20 INFO:Local step 66500, global step 1064439: loss 0.1982
[2019-03-23 22:51:09,338] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 66500, global step 1064440: learning rate 0.0005
[2019-03-23 22:51:09,344] A3C_AGENT_WORKER-Thread-2 INFO:Local step 66500, global step 1064443: loss 0.2250
[2019-03-23 22:51:09,349] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 66500, global step 1064446: learning rate 0.0005
[2019-03-23 22:51:14,110] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1042744e-25 1.0000000e+00 0.0000000e+00 4.4332106e-38 0.0000000e+00], sum to 1.0000
[2019-03-23 22:51:14,119] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0100
[2019-03-23 22:51:14,123] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 48.66666666666666, 1.0, 2.0, 0.2692073379857393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 347259.9131761965, 347259.9131761965, 99379.99393105078], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 264000.0000, 
sim time next is 264600.0000, 
raw observation next is [21.35, 49.0, 1.0, 2.0, 0.266665825717702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 343980.7928600144, 343980.7928600144, 98411.41365386936], 
processed observation next is [0.0, 0.043478260869565216, 0.3462962962962963, 0.49, 1.0, 1.0, 0.1269831258544071, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.12285028316429086, 0.12285028316429086, 0.18925271856513337], 
reward next is 0.8107, 
noisyNet noise sample is [array([-0.9478623], dtype=float32), 0.3266771]. 
=============================================
[2019-03-23 22:51:21,617] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67000, global step 1070627: loss 0.5321
[2019-03-23 22:51:21,624] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67000, global step 1070628: learning rate 0.0005
[2019-03-23 22:51:22,678] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67000, global step 1071173: loss 0.5348
[2019-03-23 22:51:22,681] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67000, global step 1071173: learning rate 0.0005
[2019-03-23 22:51:23,870] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67000, global step 1071792: loss 0.0003
[2019-03-23 22:51:23,872] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67000, global step 1071792: learning rate 0.0005
[2019-03-23 22:51:23,944] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67000, global step 1071828: loss 0.0057
[2019-03-23 22:51:23,947] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67000, global step 1071829: learning rate 0.0005
[2019-03-23 22:51:23,983] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67000, global step 1071847: loss 0.0214
[2019-03-23 22:51:23,987] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67000, global step 1071848: learning rate 0.0005
[2019-03-23 22:51:24,047] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67000, global step 1071883: loss 0.0540
[2019-03-23 22:51:24,050] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67000, global step 1071884: learning rate 0.0005
[2019-03-23 22:51:24,168] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67000, global step 1071946: loss 0.0032
[2019-03-23 22:51:24,170] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67000, global step 1071947: learning rate 0.0005
[2019-03-23 22:51:24,303] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67000, global step 1072013: loss 0.0311
[2019-03-23 22:51:24,306] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67000, global step 1072013: learning rate 0.0005
[2019-03-23 22:51:24,442] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67000, global step 1072084: loss 0.0201
[2019-03-23 22:51:24,446] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67000, global step 1072084: learning rate 0.0005
[2019-03-23 22:51:24,540] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67000, global step 1072135: loss 0.0017
[2019-03-23 22:51:24,541] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67000, global step 1072135: learning rate 0.0005
[2019-03-23 22:51:24,821] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67000, global step 1072281: loss 0.0214
[2019-03-23 22:51:24,829] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67000, global step 1072282: learning rate 0.0005
[2019-03-23 22:51:24,979] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67000, global step 1072360: loss 0.0288
[2019-03-23 22:51:24,980] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67000, global step 1072360: learning rate 0.0005
[2019-03-23 22:51:25,015] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67000, global step 1072374: loss 0.0324
[2019-03-23 22:51:25,020] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67000, global step 1072375: learning rate 0.0005
[2019-03-23 22:51:25,130] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67000, global step 1072435: loss 0.0478
[2019-03-23 22:51:25,132] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67000, global step 1072436: loss 0.0418
[2019-03-23 22:51:25,136] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67000, global step 1072436: learning rate 0.0005
[2019-03-23 22:51:25,139] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67000, global step 1072436: learning rate 0.0005
[2019-03-23 22:51:25,188] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67000, global step 1072460: loss 0.0399
[2019-03-23 22:51:25,193] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67000, global step 1072462: learning rate 0.0005
[2019-03-23 22:51:30,123] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 22:51:30,124] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:51:30,125] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:51:30,126] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:51:30,128] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:51:30,128] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:51:30,129] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:51:30,129] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:51:30,129] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:51:30,130] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:51:30,132] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:51:30,145] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run44
[2019-03-23 22:51:30,168] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run44
[2019-03-23 22:51:30,169] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run44
[2019-03-23 22:51:30,169] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run44
[2019-03-23 22:51:30,256] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run44
[2019-03-23 22:51:38,355] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.053669468]
[2019-03-23 22:51:38,356] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.33333333333334, 26.0, 1.0, 2.0, 0.5482821548906723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 692076.1992494599, 692076.1992494594, 151692.4151974068]
[2019-03-23 22:51:38,356] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:51:38,359] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.8042761e-21 1.0000000e+00 5.5549723e-33 2.3423401e-30 4.3685009e-35], sampled 0.6909395084814078
[2019-03-23 22:51:47,672] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.053669468]
[2019-03-23 22:51:47,674] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.23333333333333, 50.33333333333334, 1.0, 2.0, 0.3451944968685329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 434856.3126221152, 434856.3126221152, 121294.7866948106]
[2019-03-23 22:51:47,674] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:51:47,677] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.8042761e-21 1.0000000e+00 5.5549723e-33 2.3423401e-30 4.3685009e-35], sampled 0.5637271728984162
[2019-03-23 22:51:58,577] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.053669468]
[2019-03-23 22:51:58,577] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.66666666666667, 63.0, 1.0, 2.0, 0.3411975040969739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 430964.1874114221, 430964.1874114226, 120784.6509170909]
[2019-03-23 22:51:58,578] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:51:58,582] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.8042761e-21 1.0000000e+00 5.5549723e-33 2.3423401e-30 4.3685009e-35], sampled 0.6451966691434071
[2019-03-23 22:52:02,859] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.053669468]
[2019-03-23 22:52:02,861] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.83333333333334, 70.66666666666667, 1.0, 2.0, 0.6277403243026699, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 718826.1133617305, 718826.11336173, 163084.957076322]
[2019-03-23 22:52:02,861] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:52:02,864] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.8042761e-21 1.0000000e+00 5.5549723e-33 2.3423401e-30 4.3685009e-35], sampled 0.1850037552163838
[2019-03-23 22:52:09,576] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.053669468]
[2019-03-23 22:52:09,578] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.81024102, 77.577119445, 1.0, 2.0, 0.4298852063093441, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 526865.1302967892, 526865.1302967892, 132764.7441186911]
[2019-03-23 22:52:09,578] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:52:09,580] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.8042761e-21 1.0000000e+00 5.5549723e-33 2.3423401e-30 4.3685009e-35], sampled 0.6443254727050794
[2019-03-23 22:52:10,317] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.053669468]
[2019-03-23 22:52:10,318] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.1949126, 82.87132084166667, 1.0, 2.0, 0.5230863743579598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 619516.4647557592, 619516.4647557592, 146402.1344210217]
[2019-03-23 22:52:10,321] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:52:10,323] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.8042761e-21 1.0000000e+00 5.5549723e-33 2.3423401e-30 4.3685009e-35], sampled 0.23069723066860415
[2019-03-23 22:52:15,116] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.053669468]
[2019-03-23 22:52:15,118] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.16666666666666, 88.0, 1.0, 2.0, 0.8776379507213177, 0.0, 1.0, 0.0, 1.0, 1.0, 0.993992385797098, 6.911200000000001, 6.9112, 121.9260425360147, 1719600.337918774, 1719600.337918774, 351606.475286391]
[2019-03-23 22:52:15,120] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:52:15,123] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.8042761e-21 1.0000000e+00 5.5549723e-33 2.3423401e-30 4.3685009e-35], sampled 0.05175093503341499
[2019-03-23 22:52:15,123] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1719600.337918774 W.
[2019-03-23 22:52:45,700] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.053669468]
[2019-03-23 22:52:45,702] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.438067845, 44.99302510333334, 1.0, 2.0, 0.5799535613363843, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 712642.3604954517, 712642.3604954517, 156699.8151609341]
[2019-03-23 22:52:45,704] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:52:45,708] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.8042761e-21 1.0000000e+00 5.5549723e-33 2.3423401e-30 4.3685009e-35], sampled 0.46503955840317757
[2019-03-23 22:52:49,156] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.053669468]
[2019-03-23 22:52:49,158] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.08333333333334, 88.00000000000001, 1.0, 2.0, 0.6237305947974412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 712852.9808948376, 712852.9808948376, 162307.1000196905]
[2019-03-23 22:52:49,159] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:52:49,164] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.8042761e-21 1.0000000e+00 5.5549723e-33 2.3423401e-30 4.3685009e-35], sampled 0.7011172952079379
[2019-03-23 22:52:51,505] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.053669468]
[2019-03-23 22:52:51,506] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.4, 87.0, 1.0, 2.0, 0.5695292020676505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 664742.6879426173, 664742.6879426173, 153652.3557334143]
[2019-03-23 22:52:51,507] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:52:51,510] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.8042761e-21 1.0000000e+00 5.5549723e-33 2.3423401e-30 4.3685009e-35], sampled 0.38227440932020185
[2019-03-23 22:53:13,059] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:53:13,096] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:53:13,124] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:53:13,334] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:53:13,406] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:53:14,422] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1075000, evaluation results [1075000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:53:16,522] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.6783516e-20 1.0000000e+00 8.7118090e-32 1.8221498e-31 2.2530489e-34], sum to 1.0000
[2019-03-23 22:53:16,529] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5032
[2019-03-23 22:53:16,533] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 53.5, 1.0, 2.0, 0.3304259988119207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 418723.6066734471, 418723.6066734471, 119399.9257189983], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 610200.0000, 
sim time next is 610800.0000, 
raw observation next is [23.86666666666667, 54.0, 1.0, 2.0, 0.3280047833264226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 415817.6351890377, 415817.6351890381, 119089.6952246346], 
processed observation next is [1.0, 0.043478260869565216, 0.4395061728395063, 0.54, 1.0, 1.0, 0.20000569443621735, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14850629828179918, 0.14850629828179931, 0.22901864466275884], 
reward next is 0.7710, 
noisyNet noise sample is [array([0.3532641], dtype=float32), -0.3000843]. 
=============================================
[2019-03-23 22:53:19,551] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.2460170e-18 1.0000000e+00 1.2905523e-29 3.2828228e-26 2.9785519e-32], sum to 1.0000
[2019-03-23 22:53:19,564] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8902
[2019-03-23 22:53:19,572] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1354807.707113029 W.
[2019-03-23 22:53:19,580] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [35.61666666666667, 18.16666666666666, 1.0, 2.0, 0.3719781897795011, 1.0, 1.0, 0.3719781897795011, 1.0, 2.0, 0.605054355664628, 6.911199999999999, 6.9112, 121.94756008, 1354807.707113029, 1354807.70711303, 284110.5452574202], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 661800.0000, 
sim time next is 662400.0000, 
raw observation next is [35.6, 18.0, 1.0, 2.0, 0.3725283270045916, 1.0, 2.0, 0.3725283270045916, 1.0, 2.0, 0.6048696388285932, 6.911200000000001, 6.9112, 121.94756008, 1353453.499984055, 1353453.499984054, 284448.28860014], 
processed observation next is [1.0, 0.6956521739130435, 0.8740740740740741, 0.18, 1.0, 1.0, 0.2530099131007043, 1.0, 1.0, 0.2530099131007043, 1.0, 1.0, 0.5060870485357415, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.4833762499943054, 0.48337624999430495, 0.5470159396156539], 
reward next is 0.4530, 
noisyNet noise sample is [array([1.2356026], dtype=float32), -0.46703488]. 
=============================================
[2019-03-23 22:53:20,072] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0285083e-17 1.0000000e+00 1.2447113e-28 4.8789221e-27 6.1812543e-31], sum to 1.0000
[2019-03-23 22:53:20,079] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7335
[2019-03-23 22:53:20,083] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 45.5, 1.0, 2.0, 0.3773096164285074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 483691.9585195927, 483691.9585195927, 125662.5505653739], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 703800.0000, 
sim time next is 704400.0000, 
raw observation next is [24.03333333333333, 46.33333333333334, 1.0, 2.0, 0.3654856507320787, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 468543.7023870467, 468543.7023870467, 124050.8028955775], 
processed observation next is [1.0, 0.13043478260869565, 0.4456790123456789, 0.46333333333333343, 1.0, 1.0, 0.2446257746810461, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1673370365668024, 0.1673370365668024, 0.23855923633764903], 
reward next is 0.7614, 
noisyNet noise sample is [array([0.3153679], dtype=float32), 0.47462112]. 
=============================================
[2019-03-23 22:53:20,352] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.9824844e-19 1.0000000e+00 2.4887221e-31 3.5353446e-28 5.7167881e-32], sum to 1.0000
[2019-03-23 22:53:20,360] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6247
[2019-03-23 22:53:20,367] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.86666666666667, 52.16666666666667, 1.0, 2.0, 0.2866849861191986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 367758.8412047666, 367758.8412047666, 113945.9953901521], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 708600.0000, 
sim time next is 709200.0000, 
raw observation next is [22.7, 53.0, 1.0, 2.0, 0.2850453088350675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 365702.6459596349, 365702.6459596349, 113747.368744327], 
processed observation next is [1.0, 0.21739130434782608, 0.39629629629629626, 0.53, 1.0, 1.0, 0.1488634628988899, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13060808784272676, 0.13060808784272676, 0.21874493989293656], 
reward next is 0.7813, 
noisyNet noise sample is [array([1.6132072], dtype=float32), -0.34029326]. 
=============================================
[2019-03-23 22:53:21,969] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67500, global step 1078681: loss 0.0108
[2019-03-23 22:53:21,973] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67500, global step 1078683: learning rate 0.0005
[2019-03-23 22:53:23,032] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67500, global step 1079199: loss 0.0658
[2019-03-23 22:53:23,040] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67500, global step 1079201: learning rate 0.0005
[2019-03-23 22:53:23,519] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.6529788e-22 1.0000000e+00 1.5496360e-35 1.8850305e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 22:53:23,528] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8327
[2019-03-23 22:53:23,531] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.73333333333333, 50.5, 1.0, 2.0, 0.2967150461636717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 378966.7859959558, 378966.7859959562, 115171.3815422247], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 785400.0000, 
sim time next is 786000.0000, 
raw observation next is [23.66666666666667, 51.0, 1.0, 2.0, 0.2975972077020465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 380004.8513250869, 380004.8513250869, 115279.7610683204], 
processed observation next is [0.0, 0.08695652173913043, 0.43209876543209896, 0.51, 1.0, 1.0, 0.16380619964529347, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13571601833038818, 0.13571601833038818, 0.22169184820830845], 
reward next is 0.7783, 
noisyNet noise sample is [array([-1.6061424], dtype=float32), -0.013645244]. 
=============================================
[2019-03-23 22:53:23,547] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[71.97037]
 [71.97037]
 [71.97037]
 [71.97037]
 [71.97037]], R is [[72.02896881]
 [72.08719635]
 [72.14490509]
 [72.20172119]
 [72.25765991]].
[2019-03-23 22:53:24,342] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67500, global step 1079836: loss 0.4779
[2019-03-23 22:53:24,344] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67500, global step 1079836: learning rate 0.0005
[2019-03-23 22:53:24,372] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67500, global step 1079851: loss 0.5339
[2019-03-23 22:53:24,377] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67500, global step 1079852: learning rate 0.0005
[2019-03-23 22:53:24,394] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67500, global step 1079862: loss 0.4942
[2019-03-23 22:53:24,396] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67500, global step 1079862: learning rate 0.0005
[2019-03-23 22:53:24,459] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67500, global step 1079892: loss 0.6822
[2019-03-23 22:53:24,463] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67500, global step 1079893: learning rate 0.0005
[2019-03-23 22:53:24,581] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67500, global step 1079954: loss 0.7711
[2019-03-23 22:53:24,583] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67500, global step 1079954: learning rate 0.0005
[2019-03-23 22:53:24,727] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67500, global step 1080025: loss 0.7328
[2019-03-23 22:53:24,730] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67500, global step 1080025: learning rate 0.0005
[2019-03-23 22:53:24,808] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67500, global step 1080065: loss 0.7402
[2019-03-23 22:53:24,812] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67500, global step 1080066: loss 0.8191
[2019-03-23 22:53:24,813] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67500, global step 1080066: learning rate 0.0005
[2019-03-23 22:53:24,815] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67500, global step 1080066: learning rate 0.0005
[2019-03-23 22:53:25,202] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67500, global step 1080257: loss 0.5595
[2019-03-23 22:53:25,204] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67500, global step 1080257: learning rate 0.0005
[2019-03-23 22:53:25,403] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67500, global step 1080351: loss 0.4134
[2019-03-23 22:53:25,405] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67500, global step 1080352: learning rate 0.0005
[2019-03-23 22:53:25,560] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67500, global step 1080427: loss 0.3350
[2019-03-23 22:53:25,564] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67500, global step 1080428: learning rate 0.0005
[2019-03-23 22:53:25,746] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67500, global step 1080516: loss 0.1431
[2019-03-23 22:53:25,749] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67500, global step 1080517: learning rate 0.0005
[2019-03-23 22:53:25,808] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67500, global step 1080548: loss 0.1238
[2019-03-23 22:53:25,810] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67500, global step 1080549: learning rate 0.0005
[2019-03-23 22:53:25,832] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67500, global step 1080560: loss 0.1303
[2019-03-23 22:53:25,836] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67500, global step 1080561: learning rate 0.0005
[2019-03-23 22:53:35,877] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1084803e-21 1.0000000e+00 6.6426381e-37 7.0584527e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 22:53:35,890] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2257
[2019-03-23 22:53:35,894] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.13333333333334, 47.0, 1.0, 2.0, 0.3402604840070876, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260425628981, 426337.6811702439, 426337.6811702434, 120612.890955268], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1012800.0000, 
sim time next is 1013400.0000, 
raw observation next is [25.65, 48.5, 1.0, 2.0, 0.3272374715955764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156457, 411709.9655721567, 411709.9655721567, 118955.0227109941], 
processed observation next is [1.0, 0.7391304347826086, 0.5055555555555555, 0.485, 1.0, 1.0, 0.19909222808997193, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.809462128820029, 0.1470392734186274, 0.1470392734186274, 0.22875965905960405], 
reward next is 0.7712, 
noisyNet noise sample is [array([0.7097426], dtype=float32), -0.31474784]. 
=============================================
[2019-03-23 22:53:36,079] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.00920375e-25 1.00000000e+00 0.00000000e+00 1.12773475e-33
 0.00000000e+00], sum to 1.0000
[2019-03-23 22:53:36,087] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6827
[2019-03-23 22:53:36,096] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.23333333333333, 57.0, 1.0, 2.0, 0.3206763031563408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 406749.4542227581, 406749.4542227577, 118154.5174914301], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1016400.0000, 
sim time next is 1017000.0000, 
raw observation next is [22.75, 59.0, 1.0, 2.0, 0.3172024555224556, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 402867.1502698177, 402867.1502698177, 117717.7161577506], 
processed observation next is [1.0, 0.782608695652174, 0.39814814814814814, 0.59, 1.0, 1.0, 0.1871457803838757, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14388112509636344, 0.14388112509636344, 0.22638022338028962], 
reward next is 0.7736, 
noisyNet noise sample is [array([-0.2120342], dtype=float32), -0.62488925]. 
=============================================
[2019-03-23 22:53:36,120] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[77.62374]
 [77.62374]
 [77.62374]
 [77.62374]
 [77.62374]], R is [[77.62113953]
 [77.61771393]
 [77.61351013]
 [77.60837555]
 [77.60308075]].
[2019-03-23 22:53:37,165] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.0433730e-23 1.0000000e+00 9.5457919e-36 2.3716904e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 22:53:37,174] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5051
[2019-03-23 22:53:37,182] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 52.33333333333334, 1.0, 2.0, 0.2736502022058544, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 351433.6545951898, 351433.6545951894, 112379.9601605554], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1035600.0000, 
sim time next is 1036200.0000, 
raw observation next is [22.6, 53.16666666666666, 1.0, 2.0, 0.2738454241726343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 351545.9629580886, 351545.9629580881, 112403.7678030433], 
processed observation next is [1.0, 1.0, 0.39259259259259266, 0.5316666666666666, 1.0, 1.0, 0.1355302668721837, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12555212962788878, 0.12555212962788861, 0.21616109192892943], 
reward next is 0.7838, 
noisyNet noise sample is [array([-0.13234067], dtype=float32), -0.79554844]. 
=============================================
[2019-03-23 22:53:38,313] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68000, global step 1086627: loss 0.1382
[2019-03-23 22:53:38,316] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68000, global step 1086627: learning rate 0.0005
[2019-03-23 22:53:39,268] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68000, global step 1087095: loss 0.5736
[2019-03-23 22:53:39,275] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68000, global step 1087096: learning rate 0.0005
[2019-03-23 22:53:40,681] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68000, global step 1087782: loss 0.0070
[2019-03-23 22:53:40,683] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68000, global step 1087783: learning rate 0.0005
[2019-03-23 22:53:40,755] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68000, global step 1087825: loss 0.0511
[2019-03-23 22:53:40,755] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68000, global step 1087825: learning rate 0.0005
[2019-03-23 22:53:40,937] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68000, global step 1087909: loss 0.0002
[2019-03-23 22:53:40,940] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68000, global step 1087911: learning rate 0.0005
[2019-03-23 22:53:40,983] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68000, global step 1087930: loss 0.0060
[2019-03-23 22:53:40,986] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68000, global step 1087930: learning rate 0.0005
[2019-03-23 22:53:41,097] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68000, global step 1087985: loss 0.0417
[2019-03-23 22:53:41,100] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68000, global step 1087986: learning rate 0.0005
[2019-03-23 22:53:41,104] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68000, global step 1087987: loss 0.0092
[2019-03-23 22:53:41,107] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68000, global step 1087988: learning rate 0.0005
[2019-03-23 22:53:41,207] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68000, global step 1088038: loss 0.0012
[2019-03-23 22:53:41,211] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68000, global step 1088040: learning rate 0.0005
[2019-03-23 22:53:41,323] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68000, global step 1088095: loss 0.0241
[2019-03-23 22:53:41,326] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68000, global step 1088097: learning rate 0.0005
[2019-03-23 22:53:41,610] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68000, global step 1088235: loss 0.0042
[2019-03-23 22:53:41,615] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68000, global step 1088237: learning rate 0.0005
[2019-03-23 22:53:41,832] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68000, global step 1088346: loss 0.0106
[2019-03-23 22:53:41,833] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68000, global step 1088346: learning rate 0.0005
[2019-03-23 22:53:41,877] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68000, global step 1088368: loss 0.0194
[2019-03-23 22:53:41,879] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68000, global step 1088368: learning rate 0.0005
[2019-03-23 22:53:42,171] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68000, global step 1088512: loss 0.0345
[2019-03-23 22:53:42,172] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68000, global step 1088513: learning rate 0.0005
[2019-03-23 22:53:42,228] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68000, global step 1088538: loss 0.0352
[2019-03-23 22:53:42,235] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68000, global step 1088538: learning rate 0.0005
[2019-03-23 22:53:42,238] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68000, global step 1088541: loss 0.0289
[2019-03-23 22:53:42,244] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68000, global step 1088544: learning rate 0.0005
[2019-03-23 22:53:42,617] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.9886242e-22 1.0000000e+00 1.7729775e-34 7.4346506e-33 1.4119751e-38], sum to 1.0000
[2019-03-23 22:53:42,622] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3190
[2019-03-23 22:53:42,627] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 63.0, 1.0, 2.0, 0.3041775117387617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 387227.5387517387, 387227.5387517387, 116089.5753965659], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1062000.0000, 
sim time next is 1062600.0000, 
raw observation next is [22.03333333333333, 62.33333333333333, 1.0, 2.0, 0.3575793493588882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 455066.6229714067, 455066.6229714071, 122980.7598943481], 
processed observation next is [1.0, 0.30434782608695654, 0.37160493827160485, 0.6233333333333333, 1.0, 1.0, 0.23521351114153355, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16252379391835953, 0.16252379391835967, 0.2365014613352848], 
reward next is 0.7635, 
noisyNet noise sample is [array([-0.41689107], dtype=float32), 1.1075836]. 
=============================================
[2019-03-23 22:53:48,590] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.04689194e-23 1.00000000e+00 1.25102658e-38 8.34420278e-37
 0.00000000e+00], sum to 1.0000
[2019-03-23 22:53:48,597] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6239
[2019-03-23 22:53:48,600] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 65.0, 1.0, 2.0, 0.4041300512039451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 513742.3753450239, 513742.3753450234, 129400.0382295133], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1168800.0000, 
sim time next is 1169400.0000, 
raw observation next is [21.75, 65.0, 1.0, 2.0, 0.3976572259977031, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 505322.3740186592, 505322.3740186592, 128482.6408956487], 
processed observation next is [1.0, 0.5217391304347826, 0.3611111111111111, 0.65, 1.0, 1.0, 0.28292526904488463, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18047227643523542, 0.18047227643523542, 0.24708200172240136], 
reward next is 0.7529, 
noisyNet noise sample is [array([-0.36692652], dtype=float32), -0.8539873]. 
=============================================
[2019-03-23 22:53:49,174] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.57123368e-22 1.00000000e+00 1.02837676e-36 1.06482074e-35
 0.00000000e+00], sum to 1.0000
[2019-03-23 22:53:49,179] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1935
[2019-03-23 22:53:49,180] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.1613534e-24 1.0000000e+00 0.0000000e+00 2.9044498e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 22:53:49,188] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.13333333333333, 90.66666666666667, 1.0, 2.0, 0.3495238078883664, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 440330.1255956798, 440330.1255956793, 121866.0178029454], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1203000.0000, 
sim time next is 1203600.0000, 
raw observation next is [19.06666666666667, 91.33333333333334, 1.0, 2.0, 0.3508413887758287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 441932.1160951412, 441932.1160951412, 122039.6724717666], 
processed observation next is [1.0, 0.9565217391304348, 0.2617283950617285, 0.9133333333333334, 1.0, 1.0, 0.22719212949503417, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15783289860540758, 0.15783289860540758, 0.23469167783032038], 
reward next is 0.7653, 
noisyNet noise sample is [array([0.39067608], dtype=float32), 0.8982693]. 
=============================================
[2019-03-23 22:53:49,191] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1656
[2019-03-23 22:53:49,194] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.93333333333333, 92.66666666666667, 1.0, 2.0, 0.3500173704665095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 440785.6547891969, 440785.6547891964, 121929.1031344427], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1204800.0000, 
sim time next is 1205400.0000, 
raw observation next is [18.86666666666667, 93.33333333333334, 1.0, 2.0, 0.3491113679655188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 439595.796725734, 439595.796725734, 121808.6121606411], 
processed observation next is [1.0, 0.9565217391304348, 0.25432098765432115, 0.9333333333333335, 1.0, 1.0, 0.2251325809113319, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15699849883061928, 0.15699849883061928, 0.23424733107815596], 
reward next is 0.7658, 
noisyNet noise sample is [array([0.00702358], dtype=float32), 0.6420756]. 
=============================================
[2019-03-23 22:53:54,089] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.6352217e-26 1.0000000e+00 0.0000000e+00 1.8950213e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 22:53:54,100] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0352
[2019-03-23 22:53:54,107] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.8, 32.0, 1.0, 2.0, 0.9117745270917059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.117109306708771, 6.9112, 121.9252142198068, 1240390.937590327, 1134947.685002988, 224124.283273119], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1350000.0000, 
sim time next is 1350600.0000, 
raw observation next is [30.81666666666667, 31.66666666666667, 1.0, 2.0, 0.9711255823374196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.52026348315719, 6.9112, 121.923475423717, 1521642.166395336, 1209753.7925905, 238227.8324867827], 
processed observation next is [1.0, 0.6521739130434783, 0.6969135802469137, 0.3166666666666667, 1.0, 1.0, 0.9656256932588329, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.06090634831571897, 0.0, 0.8094450853353139, 0.5434436308554771, 0.4320549259251786, 0.4581304470899667], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.02771194], dtype=float32), 1.6167102]. 
=============================================
[2019-03-23 22:53:54,407] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68500, global step 1094650: loss -83.1262
[2019-03-23 22:53:54,409] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68500, global step 1094651: learning rate 0.0005
[2019-03-23 22:53:55,269] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68500, global step 1095093: loss -105.9871
[2019-03-23 22:53:55,271] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68500, global step 1095093: learning rate 0.0005
[2019-03-23 22:53:56,122] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1493824e-23 1.0000000e+00 1.7662251e-36 7.2769976e-30 0.0000000e+00], sum to 1.0000
[2019-03-23 22:53:56,131] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4476
[2019-03-23 22:53:56,150] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.1, 56.33333333333333, 1.0, 2.0, 0.7774159576737215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156612, 967187.5557101337, 967187.5557101337, 194543.3181604198], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1330800.0000, 
sim time next is 1331400.0000, 
raw observation next is [25.35, 54.66666666666667, 1.0, 2.0, 0.7725168751173922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 961780.0680929265, 961780.0680929265, 193541.3635619066], 
processed observation next is [1.0, 0.391304347826087, 0.4944444444444445, 0.5466666666666667, 1.0, 1.0, 0.7291867560921336, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3434928814617595, 0.3434928814617595, 0.37219492992674347], 
reward next is 0.6278, 
noisyNet noise sample is [array([-2.2042506], dtype=float32), -0.6147004]. 
=============================================
[2019-03-23 22:53:56,469] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68500, global step 1095719: loss -71.4186
[2019-03-23 22:53:56,470] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68500, global step 1095719: learning rate 0.0005
[2019-03-23 22:53:56,637] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68500, global step 1095802: loss -66.4693
[2019-03-23 22:53:56,640] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68500, global step 1095803: learning rate 0.0005
[2019-03-23 22:53:56,802] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68500, global step 1095884: loss -87.9757
[2019-03-23 22:53:56,803] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68500, global step 1095884: learning rate 0.0005
[2019-03-23 22:53:56,877] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68500, global step 1095923: loss -70.1640
[2019-03-23 22:53:56,880] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68500, global step 1095924: learning rate 0.0005
[2019-03-23 22:53:56,972] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68500, global step 1095970: loss -60.5915
[2019-03-23 22:53:56,976] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68500, global step 1095970: learning rate 0.0005
[2019-03-23 22:53:56,988] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68500, global step 1095980: loss -66.0082
[2019-03-23 22:53:56,989] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68500, global step 1095980: learning rate 0.0005
[2019-03-23 22:53:57,052] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68500, global step 1096015: loss -67.0509
[2019-03-23 22:53:57,053] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68500, global step 1096015: learning rate 0.0005
[2019-03-23 22:53:57,325] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68500, global step 1096157: loss -55.4641
[2019-03-23 22:53:57,328] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68500, global step 1096157: learning rate 0.0005
[2019-03-23 22:53:57,577] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68500, global step 1096278: loss -57.3348
[2019-03-23 22:53:57,580] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68500, global step 1096279: learning rate 0.0005
[2019-03-23 22:53:57,782] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68500, global step 1096391: loss -58.3911
[2019-03-23 22:53:57,784] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68500, global step 1096391: learning rate 0.0005
[2019-03-23 22:53:57,838] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68500, global step 1096424: loss -83.2937
[2019-03-23 22:53:57,842] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68500, global step 1096424: learning rate 0.0005
[2019-03-23 22:53:57,944] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68500, global step 1096476: loss -78.5325
[2019-03-23 22:53:57,949] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68500, global step 1096478: learning rate 0.0005
[2019-03-23 22:53:58,145] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68500, global step 1096582: loss -75.1622
[2019-03-23 22:53:58,147] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68500, global step 1096582: learning rate 0.0005
[2019-03-23 22:53:58,180] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68500, global step 1096593: loss -66.8317
[2019-03-23 22:53:58,181] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68500, global step 1096593: learning rate 0.0005
[2019-03-23 22:54:00,774] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.5969956e-23 1.0000000e+00 4.4736962e-37 1.3334476e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 22:54:00,787] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4650
[2019-03-23 22:54:00,795] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.6, 54.0, 1.0, 2.0, 0.2791633794573393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 358146.8650023618, 358146.8650023618, 113039.5256906351], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1404000.0000, 
sim time next is 1404600.0000, 
raw observation next is [22.96666666666667, 53.0, 1.0, 2.0, 0.2841614840145712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 364014.9683480729, 364014.9683480729, 113642.040993745], 
processed observation next is [0.0, 0.2608695652173913, 0.4061728395061729, 0.53, 1.0, 1.0, 0.14781129049353714, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13000534583859746, 0.13000534583859746, 0.2185423865264327], 
reward next is 0.7815, 
noisyNet noise sample is [array([-1.4459513], dtype=float32), -0.62298304]. 
=============================================
[2019-03-23 22:54:04,932] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-23 22:54:04,933] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:54:04,933] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:54:04,935] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:54:04,935] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:54:04,937] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:54:04,938] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:54:04,936] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:54:04,938] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:54:04,945] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:54:04,940] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:54:04,960] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run45
[2019-03-23 22:54:04,960] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run45
[2019-03-23 22:54:04,982] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run45
[2019-03-23 22:54:05,008] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run45
[2019-03-23 22:54:05,064] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run45
[2019-03-23 22:54:12,971] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.02171435]
[2019-03-23 22:54:12,973] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [16.0, 74.5, 1.0, 2.0, 0.189130474473982, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 243949.5533833348, 243949.5533833348, 78842.73893375768]
[2019-03-23 22:54:12,974] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:54:12,976] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.230780e-23 1.000000e+00 9.517463e-37 8.369496e-34 0.000000e+00], sampled 0.9185483362996981
[2019-03-23 22:54:45,812] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.02171435]
[2019-03-23 22:54:45,813] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.90881010666667, 86.06630716333333, 1.0, 2.0, 0.5291814620345031, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 624465.365919077, 624465.365919077, 147295.1171553589]
[2019-03-23 22:54:45,814] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:54:45,819] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.230780e-23 1.000000e+00 9.517463e-37 8.369496e-34 0.000000e+00], sampled 0.47650239692264484
[2019-03-23 22:54:51,486] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.02171435]
[2019-03-23 22:54:51,488] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.0, 84.0, 1.0, 2.0, 0.6216246565385918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 708434.9794289925, 708434.9794289925, 161836.6961296304]
[2019-03-23 22:54:51,491] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:54:51,496] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.230780e-23 1.000000e+00 9.517463e-37 8.369496e-34 0.000000e+00], sampled 0.6244114133017827
[2019-03-23 22:55:06,245] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.02171435]
[2019-03-23 22:55:06,246] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.83333333333333, 60.83333333333334, 1.0, 2.0, 0.655477905193426, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156249, 1461986.622236221, 1461986.622236221, 309324.1827505722]
[2019-03-23 22:55:06,247] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:55:06,251] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.230780e-23 1.000000e+00 9.517463e-37 8.369496e-34 0.000000e+00], sampled 0.13620144412348378
[2019-03-23 22:55:06,252] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1461986.622236221 W.
[2019-03-23 22:55:18,130] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.02171435]
[2019-03-23 22:55:18,130] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.1, 65.0, 1.0, 2.0, 0.5716492121456216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 664339.838057829, 664339.838057829, 153881.7229378405]
[2019-03-23 22:55:18,130] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:55:18,134] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.230780e-23 1.000000e+00 9.517463e-37 8.369496e-34 0.000000e+00], sampled 0.7990100735851632
[2019-03-23 22:55:25,358] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.02171435]
[2019-03-23 22:55:25,361] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.66666666666667, 86.33333333333333, 1.0, 2.0, 0.505005281710137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 598764.8656408702, 598764.8656408702, 143548.8752159893]
[2019-03-23 22:55:25,363] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:55:25,367] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.230780e-23 1.000000e+00 9.517463e-37 8.369496e-34 0.000000e+00], sampled 0.527814684738167
[2019-03-23 22:55:48,358] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:55:48,449] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:55:48,453] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:55:48,584] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:55:48,590] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:55:49,606] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1100000, evaluation results [1100000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:55:55,285] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69000, global step 1102770: loss 0.2544
[2019-03-23 22:55:55,290] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69000, global step 1102770: learning rate 0.0005
[2019-03-23 22:55:55,852] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69000, global step 1103045: loss 0.6267
[2019-03-23 22:55:55,854] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69000, global step 1103045: learning rate 0.0005
[2019-03-23 22:55:56,379] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3816499e-19 1.0000000e+00 5.0758187e-32 1.5898442e-27 1.4405094e-32], sum to 1.0000
[2019-03-23 22:55:56,387] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3765
[2019-03-23 22:55:56,392] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 43.0, 1.0, 2.0, 0.3511578882927372, 1.0, 2.0, 0.3511578882927372, 1.0, 1.0, 0.5711689966555495, 6.911199999999999, 6.9112, 121.94756008, 1278854.778090442, 1278854.778090442, 275412.939288385], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1609200.0000, 
sim time next is 1609800.0000, 
raw observation next is [27.55, 42.83333333333334, 1.0, 2.0, 0.9025466371414187, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.032146742717988, 6.9112, 121.9254242976506, 1181118.549046478, 1119183.320768578, 221882.9453058881], 
processed observation next is [1.0, 0.6521739130434783, 0.575925925925926, 0.42833333333333345, 1.0, 1.0, 0.8839840918350222, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.012094674271798755, 0.0, 0.809458023831547, 0.421828053230885, 0.3997083288459207, 0.4266979717420925], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.17084587], dtype=float32), -1.5763718]. 
=============================================
[2019-03-23 22:55:56,853] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.4999448e-20 1.0000000e+00 1.4934637e-34 5.3672308e-32 2.5689714e-35], sum to 1.0000
[2019-03-23 22:55:56,862] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5848
[2019-03-23 22:55:56,873] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.36666666666667, 46.5, 1.0, 2.0, 0.3543844027505741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 444846.6856187614, 444846.6856187614, 122487.8898019308], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1624200.0000, 
sim time next is 1624800.0000, 
raw observation next is [26.23333333333333, 47.0, 1.0, 2.0, 0.3551704909779502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 445948.3592934466, 445948.3592934461, 122594.3186701373], 
processed observation next is [1.0, 0.8260869565217391, 0.5271604938271603, 0.47, 1.0, 1.0, 0.2323458225927979, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15926727117623093, 0.15926727117623077, 0.23575830513487944], 
reward next is 0.7642, 
noisyNet noise sample is [array([-0.9494283], dtype=float32), 0.38540408]. 
=============================================
[2019-03-23 22:55:56,975] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69000, global step 1103590: loss 0.1071
[2019-03-23 22:55:56,979] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69000, global step 1103590: learning rate 0.0005
[2019-03-23 22:55:57,146] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69000, global step 1103671: loss 0.0206
[2019-03-23 22:55:57,150] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69000, global step 1103673: learning rate 0.0005
[2019-03-23 22:55:57,421] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69000, global step 1103805: loss 0.0263
[2019-03-23 22:55:57,425] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69000, global step 1103806: learning rate 0.0005
[2019-03-23 22:55:57,698] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69000, global step 1103937: loss 0.0427
[2019-03-23 22:55:57,699] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69000, global step 1103937: learning rate 0.0005
[2019-03-23 22:55:57,723] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69000, global step 1103950: loss 0.0242
[2019-03-23 22:55:57,726] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69000, global step 1103951: learning rate 0.0005
[2019-03-23 22:55:57,777] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69000, global step 1103979: loss 0.0313
[2019-03-23 22:55:57,781] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69000, global step 1103980: learning rate 0.0005
[2019-03-23 22:55:57,814] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69000, global step 1103996: loss 0.0023
[2019-03-23 22:55:57,815] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69000, global step 1103996: learning rate 0.0005
[2019-03-23 22:55:58,290] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69000, global step 1104229: loss 0.0261
[2019-03-23 22:55:58,294] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69000, global step 1104230: learning rate 0.0005
[2019-03-23 22:55:58,522] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.898243e-25 1.000000e+00 0.000000e+00 6.772958e-36 0.000000e+00], sum to 1.0000
[2019-03-23 22:55:58,532] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4427
[2019-03-23 22:55:58,534] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69000, global step 1104345: loss 0.0072
[2019-03-23 22:55:58,542] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69000, global step 1104347: learning rate 0.0005
[2019-03-23 22:55:58,542] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.83333333333333, 80.33333333333334, 1.0, 2.0, 0.6155114232430022, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 779621.7673896962, 779621.7673896962, 163401.5418044946], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1680600.0000, 
sim time next is 1681200.0000, 
raw observation next is [19.9, 80.0, 1.0, 2.0, 0.6340060320216163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 802864.5977711327, 802864.5977711322, 166754.9955444291], 
processed observation next is [1.0, 0.4782608695652174, 0.2925925925925925, 0.8, 1.0, 1.0, 0.564292895263829, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2867373563468331, 0.28673735634683295, 0.32068268373928677], 
reward next is 0.6793, 
noisyNet noise sample is [array([-0.46253493], dtype=float32), 0.17224343]. 
=============================================
[2019-03-23 22:55:58,764] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69000, global step 1104456: loss 0.0063
[2019-03-23 22:55:58,766] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69000, global step 1104457: learning rate 0.0005
[2019-03-23 22:55:58,776] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.2376000e-24 1.0000000e+00 2.0780259e-38 1.3961608e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 22:55:58,783] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1563
[2019-03-23 22:55:58,788] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.6, 78.33333333333334, 1.0, 2.0, 0.3438177929621198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 438030.4692188016, 438030.4692188016, 121158.3677777015], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1654800.0000, 
sim time next is 1655400.0000, 
raw observation next is [19.4, 79.66666666666666, 1.0, 2.0, 0.3349398415591048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 426857.3712672701, 426857.3712672701, 119999.675882788], 
processed observation next is [1.0, 0.13043478260869565, 0.274074074074074, 0.7966666666666665, 1.0, 1.0, 0.2082617161417914, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1524490611668822, 0.1524490611668822, 0.2307686074669], 
reward next is 0.7692, 
noisyNet noise sample is [array([-1.1405935], dtype=float32), 1.0221651]. 
=============================================
[2019-03-23 22:55:58,831] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69000, global step 1104487: loss 0.0009
[2019-03-23 22:55:58,837] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69000, global step 1104489: learning rate 0.0005
[2019-03-23 22:55:58,843] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69000, global step 1104492: loss 0.0060
[2019-03-23 22:55:58,848] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69000, global step 1104493: learning rate 0.0005
[2019-03-23 22:55:58,905] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69000, global step 1104522: loss 0.0111
[2019-03-23 22:55:58,907] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69000, global step 1104522: learning rate 0.0005
[2019-03-23 22:55:58,933] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69000, global step 1104536: loss 0.0260
[2019-03-23 22:55:58,934] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69000, global step 1104536: learning rate 0.0005
[2019-03-23 22:56:03,580] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.5172733e-24 1.0000000e+00 2.5518179e-37 6.0654656e-32 8.0506295e-38], sum to 1.0000
[2019-03-23 22:56:03,597] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1909
[2019-03-23 22:56:03,604] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.96666666666667, 88.16666666666667, 1.0, 2.0, 0.3899656431317965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 488138.3618033805, 488138.3618033801, 127313.0346826939], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1746600.0000, 
sim time next is 1747200.0000, 
raw observation next is [20.13333333333333, 87.33333333333334, 1.0, 2.0, 0.3710533933073112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 464082.0078806899, 464082.0078806899, 124702.8367845206], 
processed observation next is [1.0, 0.21739130434782608, 0.30123456790123443, 0.8733333333333334, 1.0, 1.0, 0.25125403965156096, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16574357424310354, 0.16574357424310354, 0.2398131476625396], 
reward next is 0.7602, 
noisyNet noise sample is [array([-0.6964086], dtype=float32), -0.35198683]. 
=============================================
[2019-03-23 22:56:11,750] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69500, global step 1110781: loss -123.4216
[2019-03-23 22:56:11,755] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69500, global step 1110782: learning rate 0.0005
[2019-03-23 22:56:12,425] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.8374217e-24 1.0000000e+00 4.6625118e-38 4.8775812e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 22:56:12,439] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9694
[2019-03-23 22:56:12,443] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.63333333333333, 92.0, 1.0, 2.0, 0.3723823722329081, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 465267.1523914562, 465267.1523914557, 124875.0936175426], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1916400.0000, 
sim time next is 1917000.0000, 
raw observation next is [19.65, 92.0, 1.0, 2.0, 0.3750541643051963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 468540.4214503498, 468540.4214503498, 125238.3866093338], 
processed observation next is [1.0, 0.17391304347826086, 0.28333333333333327, 0.92, 1.0, 1.0, 0.25601686226809084, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16733586480369636, 0.16733586480369636, 0.24084305117179577], 
reward next is 0.7592, 
noisyNet noise sample is [array([-0.11866985], dtype=float32), -2.3469195]. 
=============================================
[2019-03-23 22:56:12,456] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[79.01887]
 [79.01887]
 [79.01887]
 [79.01887]
 [79.01887]], R is [[78.98783875]
 [78.95781708]
 [78.91110229]
 [78.88490295]
 [78.85941315]].
[2019-03-23 22:56:12,499] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69500, global step 1111149: loss -184.1416
[2019-03-23 22:56:12,502] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69500, global step 1111149: learning rate 0.0005
[2019-03-23 22:56:13,598] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69500, global step 1111682: loss -155.0005
[2019-03-23 22:56:13,601] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69500, global step 1111682: learning rate 0.0005
[2019-03-23 22:56:13,663] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69500, global step 1111717: loss -124.6796
[2019-03-23 22:56:13,665] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69500, global step 1111717: learning rate 0.0005
[2019-03-23 22:56:13,764] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69500, global step 1111761: loss -104.6841
[2019-03-23 22:56:13,766] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69500, global step 1111761: learning rate 0.0005
[2019-03-23 22:56:14,089] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69500, global step 1111918: loss -157.3618
[2019-03-23 22:56:14,093] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69500, global step 1111918: learning rate 0.0005
[2019-03-23 22:56:14,107] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69500, global step 1111926: loss -115.3848
[2019-03-23 22:56:14,108] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69500, global step 1111926: learning rate 0.0005
[2019-03-23 22:56:14,200] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69500, global step 1111971: loss -86.0401
[2019-03-23 22:56:14,201] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69500, global step 1111971: learning rate 0.0005
[2019-03-23 22:56:14,280] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69500, global step 1112011: loss -56.3895
[2019-03-23 22:56:14,284] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69500, global step 1112011: learning rate 0.0005
[2019-03-23 22:56:14,617] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69500, global step 1112170: loss -102.4560
[2019-03-23 22:56:14,617] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69500, global step 1112170: learning rate 0.0005
[2019-03-23 22:56:14,966] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69500, global step 1112341: loss -86.9682
[2019-03-23 22:56:14,968] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69500, global step 1112341: learning rate 0.0005
[2019-03-23 22:56:15,229] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69500, global step 1112469: loss -73.5741
[2019-03-23 22:56:15,231] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69500, global step 1112470: learning rate 0.0005
[2019-03-23 22:56:15,259] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69500, global step 1112481: loss -141.9356
[2019-03-23 22:56:15,264] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69500, global step 1112482: learning rate 0.0005
[2019-03-23 22:56:15,279] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69500, global step 1112489: loss -125.1185
[2019-03-23 22:56:15,281] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69500, global step 1112490: learning rate 0.0005
[2019-03-23 22:56:15,349] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69500, global step 1112527: loss -142.6155
[2019-03-23 22:56:15,354] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69500, global step 1112529: learning rate 0.0005
[2019-03-23 22:56:15,384] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69500, global step 1112544: loss -99.2261
[2019-03-23 22:56:15,385] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69500, global step 1112544: learning rate 0.0005
[2019-03-23 22:56:16,725] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.7136915e-24 1.0000000e+00 3.2866171e-35 7.7486714e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 22:56:16,742] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4910
[2019-03-23 22:56:16,752] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.3, 93.5, 1.0, 2.0, 0.3639462411847413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 455719.4831342913, 455719.4831342913, 123750.0927304869], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2003400.0000, 
sim time next is 2004000.0000, 
raw observation next is [19.3, 93.66666666666667, 1.0, 2.0, 0.3637807994185449, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 455400.4990456486, 455400.4990456486, 123725.9013506426], 
processed observation next is [0.0, 0.17391304347826086, 0.27037037037037037, 0.9366666666666668, 1.0, 1.0, 0.24259618978398204, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16264303537344593, 0.16264303537344593, 0.2379344256743127], 
reward next is 0.7621, 
noisyNet noise sample is [array([-1.3026819], dtype=float32), 0.19100407]. 
=============================================
[2019-03-23 22:56:16,769] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[75.50614]
 [75.50614]
 [75.50614]
 [75.50614]
 [75.50614]], R is [[75.51315308]
 [75.52003479]
 [75.52700806]
 [75.53435516]
 [75.54192352]].
[2019-03-23 22:56:19,073] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.8223990e-23 1.0000000e+00 3.7645007e-37 3.4344968e-32 4.4578678e-38], sum to 1.0000
[2019-03-23 22:56:19,086] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1157
[2019-03-23 22:56:19,095] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.9, 63.00000000000001, 1.0, 2.0, 0.5892900582167635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 679165.3317589647, 679165.3317589647, 156614.8343573437], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2046000.0000, 
sim time next is 2046600.0000, 
raw observation next is [28.95, 63.0, 1.0, 2.0, 0.5917862219065766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 681376.336493872, 681376.336493872, 157010.1964329811], 
processed observation next is [0.0, 0.6956521739130435, 0.6277777777777778, 0.63, 1.0, 1.0, 0.5140312165554483, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2433486916049543, 0.2433486916049543, 0.30194268544804054], 
reward next is 0.6981, 
noisyNet noise sample is [array([0.13459045], dtype=float32), 0.3143497]. 
=============================================
[2019-03-23 22:56:20,504] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.8531201e-23 1.0000000e+00 5.2795304e-38 5.2842334e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 22:56:20,515] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5309
[2019-03-23 22:56:20,521] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.63333333333333, 65.66666666666667, 1.0, 2.0, 0.6013776537253146, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 689753.4332320658, 689753.4332320653, 158531.7395171375], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2050800.0000, 
sim time next is 2051400.0000, 
raw observation next is [28.51666666666667, 66.33333333333333, 1.0, 2.0, 0.6024017764336798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 690848.7297404585, 690848.7297404585, 158704.7328579664], 
processed observation next is [0.0, 0.7391304347826086, 0.6117283950617285, 0.6633333333333333, 1.0, 1.0, 0.5266687814686664, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2467316891930209, 0.2467316891930209, 0.30520140934224305], 
reward next is 0.6948, 
noisyNet noise sample is [array([0.12244121], dtype=float32), 0.8358394]. 
=============================================
[2019-03-23 22:56:24,470] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.2782323e-20 1.0000000e+00 2.7268695e-31 6.5751722e-30 7.0393313e-34], sum to 1.0000
[2019-03-23 22:56:24,478] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6118
[2019-03-23 22:56:24,483] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.88333333333333, 68.5, 1.0, 2.0, 0.6517366285393951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 742768.7357840101, 742768.7357840101, 167207.7320622075], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2145000.0000, 
sim time next is 2145600.0000, 
raw observation next is [28.7, 70.0, 1.0, 2.0, 0.6563333015962293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 748010.0108094546, 748010.0108094546, 168041.5673702869], 
processed observation next is [0.0, 0.8695652173913043, 0.6185185185185185, 0.7, 1.0, 1.0, 0.5908729780907491, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2671464324319481, 0.2671464324319481, 0.3231568603274748], 
reward next is 0.6768, 
noisyNet noise sample is [array([0.84818923], dtype=float32), 0.9336157]. 
=============================================
[2019-03-23 22:56:27,913] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70000, global step 1118745: loss 0.0443
[2019-03-23 22:56:27,915] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70000, global step 1118746: learning rate 0.0005
[2019-03-23 22:56:28,474] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70000, global step 1119034: loss 0.3102
[2019-03-23 22:56:28,476] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70000, global step 1119034: learning rate 0.0005
[2019-03-23 22:56:29,633] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70000, global step 1119631: loss 0.2027
[2019-03-23 22:56:29,634] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70000, global step 1119631: learning rate 0.0005
[2019-03-23 22:56:29,646] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70000, global step 1119635: loss 0.2274
[2019-03-23 22:56:29,652] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70000, global step 1119637: learning rate 0.0005
[2019-03-23 22:56:29,667] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70000, global step 1119645: loss 0.1699
[2019-03-23 22:56:29,671] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70000, global step 1119645: learning rate 0.0005
[2019-03-23 22:56:29,735] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.6140062e-19 1.0000000e+00 3.8981838e-32 8.1653206e-29 9.2313087e-34], sum to 1.0000
[2019-03-23 22:56:29,743] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2884
[2019-03-23 22:56:29,748] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.05, 95.0, 1.0, 2.0, 0.5546677974718646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 651119.6854323146, 651119.6854323146, 151332.0312197954], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2226600.0000, 
sim time next is 2227200.0000, 
raw observation next is [23.0, 95.0, 1.0, 2.0, 0.5501280782284574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 646437.2883428335, 646437.2883428335, 150607.8662391921], 
processed observation next is [1.0, 0.782608695652174, 0.4074074074074074, 0.95, 1.0, 1.0, 0.46443818836721124, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23087046012244053, 0.23087046012244053, 0.28963051199844636], 
reward next is 0.7104, 
noisyNet noise sample is [array([-0.93452215], dtype=float32), 0.55702037]. 
=============================================
[2019-03-23 22:56:30,266] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70000, global step 1119954: loss 0.0050
[2019-03-23 22:56:30,268] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70000, global step 1119954: learning rate 0.0005
[2019-03-23 22:56:30,280] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70000, global step 1119961: loss 0.0148
[2019-03-23 22:56:30,281] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70000, global step 1119961: learning rate 0.0005
[2019-03-23 22:56:30,378] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70000, global step 1120003: loss 0.0454
[2019-03-23 22:56:30,381] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70000, global step 1120003: learning rate 0.0005
[2019-03-23 22:56:30,405] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70000, global step 1120021: loss 0.0621
[2019-03-23 22:56:30,409] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70000, global step 1120022: learning rate 0.0005
[2019-03-23 22:56:30,635] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70000, global step 1120133: loss 0.0054
[2019-03-23 22:56:30,640] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70000, global step 1120135: learning rate 0.0005
[2019-03-23 22:56:31,144] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70000, global step 1120393: loss 0.0021
[2019-03-23 22:56:31,146] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70000, global step 1120394: learning rate 0.0005
[2019-03-23 22:56:31,210] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70000, global step 1120428: loss 0.0012
[2019-03-23 22:56:31,214] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70000, global step 1120429: learning rate 0.0005
[2019-03-23 22:56:31,272] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70000, global step 1120455: loss 0.0012
[2019-03-23 22:56:31,272] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70000, global step 1120455: learning rate 0.0005
[2019-03-23 22:56:31,348] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70000, global step 1120498: loss 0.0015
[2019-03-23 22:56:31,351] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70000, global step 1120499: learning rate 0.0005
[2019-03-23 22:56:31,510] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70000, global step 1120585: loss 0.0048
[2019-03-23 22:56:31,511] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70000, global step 1120585: learning rate 0.0005
[2019-03-23 22:56:31,692] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70000, global step 1120677: loss 0.0100
[2019-03-23 22:56:31,696] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70000, global step 1120679: learning rate 0.0005
[2019-03-23 22:56:32,999] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.4209294e-20 1.0000000e+00 1.0122465e-31 1.0517832e-31 8.1648598e-35], sum to 1.0000
[2019-03-23 22:56:33,006] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7301
[2019-03-23 22:56:33,014] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.8, 96.0, 1.0, 2.0, 0.5065523062367027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 607564.5329286212, 607564.5329286212, 144050.8402990295], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2345400.0000, 
sim time next is 2346000.0000, 
raw observation next is [21.76666666666667, 96.0, 1.0, 2.0, 0.5060598375615136, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 607339.7255249544, 607339.7255249544, 143985.6398106715], 
processed observation next is [1.0, 0.13043478260869565, 0.3617283950617285, 0.96, 1.0, 1.0, 0.41197599709704, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21690704483034084, 0.21690704483034084, 0.2768954611743683], 
reward next is 0.7231, 
noisyNet noise sample is [array([-0.614593], dtype=float32), 0.3132709]. 
=============================================
[2019-03-23 22:56:33,032] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[64.28887]
 [64.28887]
 [64.28887]
 [64.28887]
 [64.28887]], R is [[64.36908722]
 [64.44837189]
 [64.52567291]
 [64.59501648]
 [64.66847229]].
[2019-03-23 22:56:35,415] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.8045272e-22 1.0000000e+00 2.5800101e-35 5.1770586e-31 7.0482376e-38], sum to 1.0000
[2019-03-23 22:56:35,420] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6461
[2019-03-23 22:56:35,427] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.4829733628801072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 579985.4650784361, 579985.4650784356, 140386.3762359109], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2338200.0000, 
sim time next is 2338800.0000, 
raw observation next is [22.0, 94.33333333333333, 1.0, 2.0, 0.484766413594218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 581716.8443082741, 581716.8443082741, 140648.8810244325], 
processed observation next is [1.0, 0.043478260869565216, 0.37037037037037035, 0.9433333333333332, 1.0, 1.0, 0.38662668285025953, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2077560158243836, 0.2077560158243836, 0.27047861735467793], 
reward next is 0.7295, 
noisyNet noise sample is [array([-2.5728436], dtype=float32), -0.75071055]. 
=============================================
[2019-03-23 22:56:37,710] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.467010e-19 1.000000e+00 5.996402e-32 8.782097e-28 9.289494e-33], sum to 1.0000
[2019-03-23 22:56:37,720] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4276
[2019-03-23 22:56:37,724] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.26666666666667, 79.83333333333333, 1.0, 2.0, 0.2802549245557218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 360894.6053994664, 360894.6053994664, 113162.5838981161], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2436600.0000, 
sim time next is 2437200.0000, 
raw observation next is [18.1, 81.0, 1.0, 2.0, 0.3030257629627616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 390277.3472577312, 390277.3472577312, 115941.5235943103], 
processed observation next is [1.0, 0.21739130434782608, 0.22592592592592597, 0.81, 1.0, 1.0, 0.1702687654318591, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13938476687776113, 0.13938476687776113, 0.22296446845059673], 
reward next is 0.7770, 
noisyNet noise sample is [array([-0.07859114], dtype=float32), -0.8281018]. 
=============================================
[2019-03-23 22:56:39,998] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 22:56:39,999] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:56:39,999] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:56:39,999] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:56:40,002] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:56:40,000] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:56:40,004] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:56:40,003] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:56:40,007] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:56:40,008] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:56:40,011] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:56:40,028] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run46
[2019-03-23 22:56:40,053] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run46
[2019-03-23 22:56:40,080] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run46
[2019-03-23 22:56:40,080] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run46
[2019-03-23 22:56:40,126] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run46
[2019-03-23 22:56:41,517] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.03449397]
[2019-03-23 22:56:41,518] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [16.60162398666667, 80.78258608333334, 1.0, 2.0, 0.2278246041338884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 293868.6489042864, 293868.6489042864, 91298.09010922513]
[2019-03-23 22:56:41,519] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 22:56:41,521] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.6257757e-22 1.0000000e+00 1.0294409e-35 7.4256375e-33 5.7239718e-38], sampled 0.11056441252598215
[2019-03-23 22:56:58,733] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.03449397]
[2019-03-23 22:56:58,734] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.26666666666667, 55.33333333333334, 1.0, 2.0, 0.9353186848739066, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.273085148879311, 6.9112, 121.9244482236833, 1349204.680141592, 1163889.56233228, 229626.4278149557]
[2019-03-23 22:56:58,735] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:56:58,737] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.6257757e-22 1.0000000e+00 1.0294409e-35 7.4256375e-33 5.7239718e-38], sampled 0.7027337575293162
[2019-03-23 22:56:58,739] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1349204.680141592 W.
[2019-03-23 22:57:06,801] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.03449397]
[2019-03-23 22:57:06,801] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.0, 65.0, 1.0, 2.0, 0.4719565443884032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 568884.7046098668, 568884.7046098668, 138768.2246134022]
[2019-03-23 22:57:06,801] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 22:57:06,813] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.6257757e-22 1.0000000e+00 1.0294409e-35 7.4256375e-33 5.7239718e-38], sampled 0.09052510024869742
[2019-03-23 22:57:08,496] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.03449397]
[2019-03-23 22:57:08,497] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.09115156166667, 66.85595793166667, 1.0, 2.0, 0.9101874368157421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.16189556223863, 6.9112, 124.8669009407919, 1265056.364736, 1133581.337403342, 224241.470240604]
[2019-03-23 22:57:08,498] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 22:57:08,500] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.6257757e-22 1.0000000e+00 1.0294409e-35 7.4256375e-33 5.7239718e-38], sampled 0.8733821569441633
[2019-03-23 22:57:16,430] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.03449397]
[2019-03-23 22:57:16,432] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.1, 89.0, 1.0, 2.0, 0.4552866179851961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 551304.931785778, 551304.9317857776, 136329.5476211433]
[2019-03-23 22:57:16,433] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:57:16,436] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.6257757e-22 1.0000000e+00 1.0294409e-35 7.4256375e-33 5.7239718e-38], sampled 0.10219784098813212
[2019-03-23 22:58:10,896] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.03449397]
[2019-03-23 22:58:10,897] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.13333333333333, 84.0, 1.0, 2.0, 0.7249833718041881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 826291.3020841447, 826291.3020841447, 180927.9533742489]
[2019-03-23 22:58:10,898] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 22:58:10,901] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.6257757e-22 1.0000000e+00 1.0294409e-35 7.4256375e-33 5.7239718e-38], sampled 0.862730939258194
[2019-03-23 22:58:21,606] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.03449397]
[2019-03-23 22:58:21,609] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.4, 63.33333333333333, 1.0, 2.0, 0.44058879456484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 537730.7017162739, 537730.7017162739, 134273.3194007553]
[2019-03-23 22:58:21,610] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:58:21,612] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.6257757e-22 1.0000000e+00 1.0294409e-35 7.4256375e-33 5.7239718e-38], sampled 0.7913719298351439
[2019-03-23 22:58:22,363] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 22:58:22,803] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 22:58:22,839] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 22:58:22,977] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 22:58:23,045] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 22:58:24,064] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1125000, evaluation results [1125000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 22:58:27,088] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.8867573e-21 1.0000000e+00 6.0498642e-33 2.2925706e-30 8.6101357e-35], sum to 1.0000
[2019-03-23 22:58:27,100] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3362
[2019-03-23 22:58:27,107] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1448906.275864196 W.
[2019-03-23 22:58:27,111] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [34.6, 23.0, 1.0, 2.0, 0.4027712970104252, 1.0, 1.0, 0.4027712970104252, 1.0, 2.0, 0.6499390874396064, 6.9112, 6.9112, 121.94756008, 1448906.275864196, 1448906.275864196, 297880.3011078355], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2473200.0000, 
sim time next is 2473800.0000, 
raw observation next is [34.55, 23.16666666666667, 1.0, 2.0, 0.4179037754173662, 1.0, 2.0, 0.4179037754173662, 1.0, 2.0, 0.6730098825550195, 6.9112, 6.9112, 121.94756008, 1497629.147959733, 1497629.147959733, 304723.8244371683], 
processed observation next is [1.0, 0.6521739130434783, 0.835185185185185, 0.23166666666666672, 1.0, 1.0, 0.3070283040682931, 1.0, 1.0, 0.3070283040682931, 1.0, 1.0, 0.5912623531937743, 0.0, 0.0, 0.8096049824067558, 0.5348675528427618, 0.5348675528427618, 0.5860073546868622], 
reward next is 0.4140, 
noisyNet noise sample is [array([0.49610108], dtype=float32), 0.2906903]. 
=============================================
[2019-03-23 22:58:27,996] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70500, global step 1126922: loss -188.4468
[2019-03-23 22:58:27,997] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70500, global step 1126922: learning rate 0.0005
[2019-03-23 22:58:28,217] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70500, global step 1127022: loss -152.0076
[2019-03-23 22:58:28,218] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70500, global step 1127022: learning rate 0.0005
[2019-03-23 22:58:29,030] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.4778126e-21 1.0000000e+00 3.9203361e-36 2.6303911e-30 3.2192846e-37], sum to 1.0000
[2019-03-23 22:58:29,036] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8634
[2019-03-23 22:58:29,043] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.98333333333333, 43.16666666666667, 1.0, 2.0, 0.7023929538189873, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 863249.8164328455, 863249.8164328451, 179162.8733011923], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2535000.0000, 
sim time next is 2535600.0000, 
raw observation next is [29.16666666666667, 42.33333333333334, 1.0, 2.0, 0.9531561111735141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.313769355286299, 6.9112, 121.924612594192, 1377586.490080958, 1171437.416801541, 233457.10539172], 
processed observation next is [1.0, 0.34782608695652173, 0.6358024691358026, 0.42333333333333345, 1.0, 1.0, 0.9442334656827548, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.04025693552862988, 0.0, 0.809452634964694, 0.49199517502891355, 0.4183705060005504, 0.4489559719071538], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.218786], dtype=float32), -1.4926304]. 
=============================================
[2019-03-23 22:58:29,463] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70500, global step 1127624: loss -92.3627
[2019-03-23 22:58:29,466] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70500, global step 1127624: learning rate 0.0005
[2019-03-23 22:58:29,479] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70500, global step 1127633: loss -157.4911
[2019-03-23 22:58:29,481] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70500, global step 1127633: learning rate 0.0005
[2019-03-23 22:58:29,582] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70500, global step 1127677: loss -135.0200
[2019-03-23 22:58:29,584] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70500, global step 1127677: learning rate 0.0005
[2019-03-23 22:58:30,161] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70500, global step 1127937: loss -147.8338
[2019-03-23 22:58:30,162] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70500, global step 1127937: learning rate 0.0005
[2019-03-23 22:58:30,274] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70500, global step 1127990: loss -128.9056
[2019-03-23 22:58:30,275] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70500, global step 1127990: loss -148.9395
[2019-03-23 22:58:30,277] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70500, global step 1127990: learning rate 0.0005
[2019-03-23 22:58:30,278] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70500, global step 1127992: learning rate 0.0005
[2019-03-23 22:58:30,467] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70500, global step 1128086: loss -119.5490
[2019-03-23 22:58:30,468] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70500, global step 1128086: learning rate 0.0005
[2019-03-23 22:58:30,491] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70500, global step 1128095: loss -84.6396
[2019-03-23 22:58:30,495] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70500, global step 1128096: learning rate 0.0005
[2019-03-23 22:58:30,897] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70500, global step 1128291: loss -117.5667
[2019-03-23 22:58:30,902] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70500, global step 1128294: learning rate 0.0005
[2019-03-23 22:58:31,069] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.4510655e-18 1.0000000e+00 1.9390554e-30 9.5666417e-29 4.8899028e-32], sum to 1.0000
[2019-03-23 22:58:31,077] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4755
[2019-03-23 22:58:31,080] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1763897.143093484 W.
[2019-03-23 22:58:31,087] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.2, 34.0, 1.0, 2.0, 0.5091760971417835, 1.0, 1.0, 0.5091760971417835, 1.0, 2.0, 0.811536759129809, 6.9112, 6.9112, 121.94756008, 1763897.143093484, 1763897.143093484, 348229.8273335473], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2566800.0000, 
sim time next is 2567400.0000, 
raw observation next is [33.01666666666667, 34.83333333333334, 1.0, 2.0, 0.3370463768117488, 1.0, 2.0, 0.3370463768117488, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 792269.1053771103, 792269.1053771103, 190688.8718582451], 
processed observation next is [1.0, 0.7391304347826086, 0.7783950617283953, 0.34833333333333344, 1.0, 1.0, 0.2107694962044629, 1.0, 1.0, 0.2107694962044629, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28295325192039655, 0.28295325192039655, 0.3667093689581637], 
reward next is 0.6333, 
noisyNet noise sample is [array([1.0865222], dtype=float32), -1.0062034]. 
=============================================
[2019-03-23 22:58:31,113] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70500, global step 1128399: loss -110.2865
[2019-03-23 22:58:31,114] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70500, global step 1128400: learning rate 0.0005
[2019-03-23 22:58:31,171] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70500, global step 1128422: loss -124.4562
[2019-03-23 22:58:31,173] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70500, global step 1128424: learning rate 0.0005
[2019-03-23 22:58:31,443] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70500, global step 1128553: loss -66.4336
[2019-03-23 22:58:31,445] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70500, global step 1128554: learning rate 0.0005
[2019-03-23 22:58:31,649] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70500, global step 1128655: loss -131.1576
[2019-03-23 22:58:31,653] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70500, global step 1128655: learning rate 0.0005
[2019-03-23 22:58:31,761] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70500, global step 1128709: loss -88.6386
[2019-03-23 22:58:31,762] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70500, global step 1128709: learning rate 0.0005
[2019-03-23 22:58:31,770] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.7953589e-22 1.0000000e+00 1.1788122e-33 4.0915447e-33 1.2899718e-36], sum to 1.0000
[2019-03-23 22:58:31,776] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0315
[2019-03-23 22:58:31,782] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 93.16666666666667, 1.0, 2.0, 0.4965127426744084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 594288.045010053, 594288.0450100525, 142424.6494005621], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2625000.0000, 
sim time next is 2625600.0000, 
raw observation next is [22.66666666666667, 92.33333333333334, 1.0, 2.0, 0.5067001782422813, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 603963.2692221897, 603963.2692221897, 143937.8200011167], 
processed observation next is [0.0, 0.391304347826087, 0.39506172839506193, 0.9233333333333335, 1.0, 1.0, 0.41273830743128725, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21570116757935345, 0.21570116757935345, 0.2768035000021475], 
reward next is 0.7232, 
noisyNet noise sample is [array([0.34234622], dtype=float32), 0.6340319]. 
=============================================
[2019-03-23 22:58:32,942] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4066527e-23 1.0000000e+00 1.6607093e-36 5.8133945e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 22:58:32,951] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4004
[2019-03-23 22:58:32,955] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.1, 72.0, 1.0, 2.0, 0.4921893271139574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 590327.3042822233, 590327.3042822233, 141791.6635390538], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2588400.0000, 
sim time next is 2589000.0000, 
raw observation next is [24.86666666666667, 73.33333333333333, 1.0, 2.0, 0.4910403685640933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 589214.7691414302, 589214.7691414302, 141621.8626499233], 
processed observation next is [1.0, 1.0, 0.47654320987654336, 0.7333333333333333, 1.0, 1.0, 0.3940956768620158, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21043384612193933, 0.21043384612193933, 0.27234973586523714], 
reward next is 0.7277, 
noisyNet noise sample is [array([-0.47270548], dtype=float32), -1.5388846]. 
=============================================
[2019-03-23 22:58:32,972] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[78.10692]
 [78.10692]
 [78.10692]
 [78.10692]
 [78.10692]], R is [[78.05350494]
 [78.00029755]
 [77.94720459]
 [77.89421844]
 [77.84130096]].
[2019-03-23 22:58:35,400] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.3818446e-24 1.0000000e+00 1.5142635e-36 2.6933595e-34 2.7435437e-38], sum to 1.0000
[2019-03-23 22:58:35,409] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0881
[2019-03-23 22:58:35,420] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 74.0, 1.0, 2.0, 0.6077294814416737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 699693.7046705369, 699693.7046705369, 159759.5279240899], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2649000.0000, 
sim time next is 2649600.0000, 
raw observation next is [27.0, 74.0, 1.0, 2.0, 0.6074667606701533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 699390.9522016334, 699390.9522016334, 159713.8206546671], 
processed observation next is [0.0, 0.6956521739130435, 0.5555555555555556, 0.74, 1.0, 1.0, 0.5326985246073253, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24978248292915478, 0.24978248292915478, 0.3071419627974367], 
reward next is 0.6929, 
noisyNet noise sample is [array([1.018397], dtype=float32), 1.3940787]. 
=============================================
[2019-03-23 22:58:44,544] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71000, global step 1134922: loss 0.2720
[2019-03-23 22:58:44,547] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71000, global step 1134924: learning rate 0.0005
[2019-03-23 22:58:44,652] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71000, global step 1134977: loss 0.3488
[2019-03-23 22:58:44,653] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71000, global step 1134977: learning rate 0.0005
[2019-03-23 22:58:45,829] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71000, global step 1135532: loss 0.5575
[2019-03-23 22:58:45,833] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71000, global step 1135532: learning rate 0.0005
[2019-03-23 22:58:46,183] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71000, global step 1135701: loss 0.4075
[2019-03-23 22:58:46,188] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71000, global step 1135701: learning rate 0.0005
[2019-03-23 22:58:46,234] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71000, global step 1135724: loss 0.3512
[2019-03-23 22:58:46,236] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71000, global step 1135724: learning rate 0.0005
[2019-03-23 22:58:46,648] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71000, global step 1135924: loss 0.2205
[2019-03-23 22:58:46,651] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71000, global step 1135924: learning rate 0.0005
[2019-03-23 22:58:46,776] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71000, global step 1135991: loss 0.1509
[2019-03-23 22:58:46,779] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71000, global step 1135992: learning rate 0.0005
[2019-03-23 22:58:46,787] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71000, global step 1135994: loss 0.1817
[2019-03-23 22:58:46,789] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71000, global step 1135995: learning rate 0.0005
[2019-03-23 22:58:46,794] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71000, global step 1135998: loss 0.1304
[2019-03-23 22:58:46,795] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71000, global step 1135998: learning rate 0.0005
[2019-03-23 22:58:46,839] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71000, global step 1136015: loss 0.0926
[2019-03-23 22:58:46,843] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71000, global step 1136016: learning rate 0.0005
[2019-03-23 22:58:47,268] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71000, global step 1136228: loss 0.0403
[2019-03-23 22:58:47,272] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71000, global step 1136230: learning rate 0.0005
[2019-03-23 22:58:47,535] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71000, global step 1136358: loss 0.0265
[2019-03-23 22:58:47,538] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71000, global step 1136359: learning rate 0.0005
[2019-03-23 22:58:47,554] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71000, global step 1136370: loss 0.0010
[2019-03-23 22:58:47,559] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71000, global step 1136370: learning rate 0.0005
[2019-03-23 22:58:47,732] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71000, global step 1136455: loss 0.0033
[2019-03-23 22:58:47,734] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71000, global step 1136456: learning rate 0.0005
[2019-03-23 22:58:48,228] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71000, global step 1136697: loss 0.0457
[2019-03-23 22:58:48,232] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71000, global step 1136699: learning rate 0.0005
[2019-03-23 22:58:48,465] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71000, global step 1136811: loss 0.0218
[2019-03-23 22:58:48,469] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71000, global step 1136812: learning rate 0.0005
[2019-03-23 22:58:55,590] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.9800199e-18 1.0000000e+00 5.5925780e-28 7.6846161e-27 2.1846008e-30], sum to 1.0000
[2019-03-23 22:58:55,600] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0748
[2019-03-23 22:58:55,608] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1685722.831397573 W.
[2019-03-23 22:58:55,613] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.33333333333334, 89.0, 1.0, 2.0, 0.8515000076099418, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1685722.831397573, 1685722.831397573, 346698.3525982953], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3057600.0000, 
sim time next is 3058200.0000, 
raw observation next is [27.5, 89.0, 1.0, 2.0, 0.9001651429385049, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1741272.99630988, 1741272.99630988, 357006.5214630931], 
processed observation next is [1.0, 0.391304347826087, 0.5740740740740741, 0.89, 1.0, 1.0, 0.8811489796886963, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8094621288201359, 0.6218832129678142, 0.6218832129678142, 0.6865510028136406], 
reward next is 0.3134, 
noisyNet noise sample is [array([-1.1376208], dtype=float32), 0.53588396]. 
=============================================
[2019-03-23 22:58:57,411] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.4644370e-22 1.0000000e+00 6.8590044e-33 3.9796852e-30 5.9235911e-36], sum to 1.0000
[2019-03-23 22:58:57,419] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5386
[2019-03-23 22:58:57,423] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.53333333333333, 93.33333333333334, 1.0, 2.0, 0.6226979551145905, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 712164.5384646951, 712164.5384646951, 162150.5494010056], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3030000.0000, 
sim time next is 3030600.0000, 
raw observation next is [24.66666666666667, 93.16666666666666, 1.0, 2.0, 0.6310695122901797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 719917.3731354604, 719917.37313546, 163539.7570680994], 
processed observation next is [1.0, 0.043478260869565216, 0.469135802469136, 0.9316666666666665, 1.0, 1.0, 0.5607970384406901, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2571133475483787, 0.25711334754837856, 0.3144995328232681], 
reward next is 0.6855, 
noisyNet noise sample is [array([-1.4367855], dtype=float32), 0.091825]. 
=============================================
[2019-03-23 22:58:59,364] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.4175689e-16 1.0000000e+00 3.5653875e-26 1.6276985e-23 2.2055463e-27], sum to 1.0000
[2019-03-23 22:58:59,369] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8058
[2019-03-23 22:58:59,380] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 58.5, 1.0, 2.0, 0.7222731072721863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 865844.4228313398, 865844.4228313398, 182334.1132085401], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3123000.0000, 
sim time next is 3123600.0000, 
raw observation next is [27.33333333333334, 59.66666666666666, 1.0, 2.0, 0.7017534219718824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 840483.618160428, 840483.6181604277, 178309.7348553585], 
processed observation next is [1.0, 0.13043478260869565, 0.5679012345679014, 0.5966666666666666, 1.0, 1.0, 0.6449445499665266, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3001727207715814, 0.3001727207715813, 0.3429033362603048], 
reward next is 0.6571, 
noisyNet noise sample is [array([0.31363738], dtype=float32), 0.012981292]. 
=============================================
[2019-03-23 22:58:59,823] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.3373953e-19 1.0000000e+00 4.6248396e-28 1.4964361e-25 3.8690786e-29], sum to 1.0000
[2019-03-23 22:58:59,829] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9213
[2019-03-23 22:58:59,834] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 58.0, 1.0, 2.0, 0.509812359784565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 607377.6794736056, 607377.6794736056, 144419.8956623308], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3111000.0000, 
sim time next is 3111600.0000, 
raw observation next is [28.0, 58.0, 1.0, 2.0, 0.5082033126191244, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 605491.9333228176, 605491.9333228171, 144165.8066066599], 
processed observation next is [1.0, 0.0, 0.5925925925925926, 0.58, 1.0, 1.0, 0.41452775311800527, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2162471190438634, 0.21624711904386323, 0.27724193578203826], 
reward next is 0.7228, 
noisyNet noise sample is [array([-0.18112475], dtype=float32), -1.2149116]. 
=============================================
[2019-03-23 22:59:01,072] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71500, global step 1142997: loss -70.6530
[2019-03-23 22:59:01,072] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71500, global step 1142997: learning rate 0.0005
[2019-03-23 22:59:01,151] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71500, global step 1143038: loss -111.0605
[2019-03-23 22:59:01,153] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71500, global step 1143038: learning rate 0.0005
[2019-03-23 22:59:02,206] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71500, global step 1143579: loss -90.3017
[2019-03-23 22:59:02,209] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71500, global step 1143579: learning rate 0.0005
[2019-03-23 22:59:02,552] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71500, global step 1143756: loss -72.1683
[2019-03-23 22:59:02,553] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71500, global step 1143756: learning rate 0.0005
[2019-03-23 22:59:02,594] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71500, global step 1143777: loss -163.0788
[2019-03-23 22:59:02,596] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71500, global step 1143777: learning rate 0.0005
[2019-03-23 22:59:02,835] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71500, global step 1143904: loss -153.4784
[2019-03-23 22:59:02,838] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71500, global step 1143904: learning rate 0.0005
[2019-03-23 22:59:02,893] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71500, global step 1143929: loss -110.9428
[2019-03-23 22:59:02,895] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71500, global step 1143930: learning rate 0.0005
[2019-03-23 22:59:03,003] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71500, global step 1143987: loss -66.5809
[2019-03-23 22:59:03,006] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71500, global step 1143989: learning rate 0.0005
[2019-03-23 22:59:03,024] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71500, global step 1143998: loss -60.0659
[2019-03-23 22:59:03,025] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71500, global step 1143998: learning rate 0.0005
[2019-03-23 22:59:03,133] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71500, global step 1144054: loss -146.2555
[2019-03-23 22:59:03,134] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71500, global step 1144054: learning rate 0.0005
[2019-03-23 22:59:03,480] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71500, global step 1144235: loss -94.2578
[2019-03-23 22:59:03,483] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71500, global step 1144236: learning rate 0.0005
[2019-03-23 22:59:03,716] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71500, global step 1144349: loss -145.4590
[2019-03-23 22:59:03,718] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71500, global step 1144349: learning rate 0.0005
[2019-03-23 22:59:03,744] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71500, global step 1144365: loss -85.3067
[2019-03-23 22:59:03,747] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71500, global step 1144365: learning rate 0.0005
[2019-03-23 22:59:03,780] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71500, global step 1144387: loss -36.5739
[2019-03-23 22:59:03,784] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71500, global step 1144388: learning rate 0.0005
[2019-03-23 22:59:04,364] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71500, global step 1144695: loss -77.2348
[2019-03-23 22:59:04,365] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71500, global step 1144695: learning rate 0.0005
[2019-03-23 22:59:04,851] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71500, global step 1144940: loss -60.4725
[2019-03-23 22:59:04,854] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71500, global step 1144942: learning rate 0.0005
[2019-03-23 22:59:08,520] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.9096605e-20 1.0000000e+00 6.0021688e-32 3.3055155e-27 1.3584040e-34], sum to 1.0000
[2019-03-23 22:59:08,530] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5083
[2019-03-23 22:59:08,534] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 49.0, 1.0, 2.0, 0.5663411452420506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 662021.3457446035, 662021.3457446035, 153160.3021056365], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3261600.0000, 
sim time next is 3262200.0000, 
raw observation next is [30.56666666666667, 51.0, 1.0, 2.0, 0.5622422927515968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 657859.371571572, 657859.371571572, 152501.9857479914], 
processed observation next is [0.0, 0.782608695652174, 0.6876543209876544, 0.51, 1.0, 1.0, 0.47885987232332944, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23494977556127572, 0.23494977556127572, 0.29327304951536803], 
reward next is 0.7067, 
noisyNet noise sample is [array([-1.3180017], dtype=float32), 1.0562414]. 
=============================================
[2019-03-23 22:59:14,647] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-23 22:59:14,649] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 22:59:14,650] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:59:14,650] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 22:59:14,652] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 22:59:14,653] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:59:14,653] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 22:59:14,653] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 22:59:14,653] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:59:14,654] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:59:14,655] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 22:59:14,668] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run47
[2019-03-23 22:59:14,668] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run47
[2019-03-23 22:59:14,668] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run47
[2019-03-23 22:59:14,735] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run47
[2019-03-23 22:59:14,770] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run47
[2019-03-23 22:59:37,899] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.041875843]
[2019-03-23 22:59:37,900] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.05, 72.33333333333334, 1.0, 2.0, 0.5793241548251757, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 670326.4210376343, 670326.4210376343, 155044.5699259658]
[2019-03-23 22:59:37,903] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 22:59:37,905] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.6875322e-21 1.0000000e+00 7.0548998e-33 2.7912279e-30 4.7079332e-35], sampled 0.05163170633550096
[2019-03-23 23:00:01,020] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.041875843]
[2019-03-23 23:00:01,022] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.26947172, 66.73385869333333, 1.0, 2.0, 0.5164473549545888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 615767.51986154, 615767.51986154, 145495.0870805426]
[2019-03-23 23:00:01,024] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:00:01,028] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [8.6875322e-21 1.0000000e+00 7.0548998e-33 2.7912279e-30 4.7079332e-35], sampled 0.7081197849252815
[2019-03-23 23:00:07,803] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.041875843]
[2019-03-23 23:00:07,805] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.27670277666667, 70.88734497, 1.0, 2.0, 0.4276233029474058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 524263.5336537522, 524263.5336537522, 132441.9340257754]
[2019-03-23 23:00:07,806] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:00:07,812] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [8.6875322e-21 1.0000000e+00 7.0548998e-33 2.7912279e-30 4.7079332e-35], sampled 0.20122443208665253
[2019-03-23 23:00:26,073] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.041875843]
[2019-03-23 23:00:26,075] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.5, 86.0, 1.0, 2.0, 0.6799648556207635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 774956.0374071939, 774956.0374071939, 172385.824227336]
[2019-03-23 23:00:26,076] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:00:26,079] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.6875322e-21 1.0000000e+00 7.0548998e-33 2.7912279e-30 4.7079332e-35], sampled 0.024893072102185942
[2019-03-23 23:00:36,544] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.041875843]
[2019-03-23 23:00:36,545] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.5, 90.5, 1.0, 2.0, 0.516411045291966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 607877.948498982, 607877.948498982, 145183.1864845558]
[2019-03-23 23:00:36,548] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:00:36,551] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.6875322e-21 1.0000000e+00 7.0548998e-33 2.7912279e-30 4.7079332e-35], sampled 0.5686770754844378
[2019-03-23 23:00:38,013] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.041875843]
[2019-03-23 23:00:38,014] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.16666666666667, 72.66666666666667, 1.0, 2.0, 0.7118360933580445, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 811298.9150134085, 811298.9150134085, 178393.8823717253]
[2019-03-23 23:00:38,015] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:00:38,019] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.6875322e-21 1.0000000e+00 7.0548998e-33 2.7912279e-30 4.7079332e-35], sampled 0.5002665351235488
[2019-03-23 23:00:57,635] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:00:57,687] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:00:57,738] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:00:57,812] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:00:57,821] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:00:58,838] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1150000, evaluation results [1150000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:00:58,909] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.7410611e-19 1.0000000e+00 1.7617069e-32 4.5770263e-30 1.8282533e-34], sum to 1.0000
[2019-03-23 23:00:58,916] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4605
[2019-03-23 23:00:58,923] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 100.0, 1.0, 2.0, 0.6298061278446234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 731469.1706142032, 731469.1706142027, 163941.0100291949], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3391200.0000, 
sim time next is 3391800.0000, 
raw observation next is [23.23333333333333, 98.50000000000001, 1.0, 2.0, 0.6896862700068765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 799706.8882846346, 799706.8882846346, 174872.2165600625], 
processed observation next is [1.0, 0.2608695652173913, 0.4160493827160493, 0.9850000000000001, 1.0, 1.0, 0.6305788928653292, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28560960295879806, 0.28560960295879806, 0.3362927241539663], 
reward next is 0.6637, 
noisyNet noise sample is [array([1.50468], dtype=float32), 0.93434954]. 
=============================================
[2019-03-23 23:01:00,737] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72000, global step 1150919: loss 0.0745
[2019-03-23 23:01:00,739] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72000, global step 1150920: learning rate 0.0005
[2019-03-23 23:01:00,811] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72000, global step 1150957: loss 0.1412
[2019-03-23 23:01:00,817] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72000, global step 1150957: learning rate 0.0005
[2019-03-23 23:01:02,018] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72000, global step 1151542: loss 0.3939
[2019-03-23 23:01:02,021] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72000, global step 1151543: learning rate 0.0005
[2019-03-23 23:01:02,517] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72000, global step 1151784: loss 0.1870
[2019-03-23 23:01:02,518] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72000, global step 1151784: loss 0.1968
[2019-03-23 23:01:02,519] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72000, global step 1151784: learning rate 0.0005
[2019-03-23 23:01:02,523] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72000, global step 1151784: learning rate 0.0005
[2019-03-23 23:01:02,567] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72000, global step 1151804: loss 0.1806
[2019-03-23 23:01:02,574] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72000, global step 1151806: learning rate 0.0005
[2019-03-23 23:01:02,600] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72000, global step 1151822: loss 0.1463
[2019-03-23 23:01:02,604] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72000, global step 1151822: learning rate 0.0005
[2019-03-23 23:01:02,890] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72000, global step 1151957: loss 0.1010
[2019-03-23 23:01:02,892] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72000, global step 1151957: learning rate 0.0005
[2019-03-23 23:01:02,901] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72000, global step 1151960: loss 0.1064
[2019-03-23 23:01:02,903] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72000, global step 1151961: learning rate 0.0005
[2019-03-23 23:01:02,977] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72000, global step 1152003: loss 0.0754
[2019-03-23 23:01:02,986] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72000, global step 1152005: learning rate 0.0005
[2019-03-23 23:01:03,598] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72000, global step 1152295: loss 0.0220
[2019-03-23 23:01:03,599] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72000, global step 1152295: learning rate 0.0005
[2019-03-23 23:01:03,663] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72000, global step 1152329: loss 0.0144
[2019-03-23 23:01:03,667] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72000, global step 1152329: learning rate 0.0005
[2019-03-23 23:01:03,842] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72000, global step 1152413: loss 0.0504
[2019-03-23 23:01:03,845] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72000, global step 1152413: learning rate 0.0005
[2019-03-23 23:01:03,952] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72000, global step 1152468: loss 0.0159
[2019-03-23 23:01:03,958] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72000, global step 1152468: learning rate 0.0005
[2019-03-23 23:01:04,488] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72000, global step 1152732: loss 0.0578
[2019-03-23 23:01:04,491] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72000, global step 1152733: learning rate 0.0005
[2019-03-23 23:01:04,988] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72000, global step 1152973: loss 0.0902
[2019-03-23 23:01:04,990] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72000, global step 1152975: learning rate 0.0005
[2019-03-23 23:01:11,332] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.134850e-22 1.000000e+00 5.566894e-33 6.552359e-31 9.447875e-35], sum to 1.0000
[2019-03-23 23:01:11,339] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1413
[2019-03-23 23:01:11,345] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 83.0, 1.0, 2.0, 0.5588499258243174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 651639.6451902161, 651639.6451902166, 151838.689097058], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3608400.0000, 
sim time next is 3609000.0000, 
raw observation next is [25.0, 83.0, 1.0, 2.0, 0.5592817074830246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 652140.6883017556, 652140.6883017556, 151910.369249778], 
processed observation next is [1.0, 0.782608695652174, 0.48148148148148145, 0.83, 1.0, 1.0, 0.4753353660512198, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2329073886791984, 0.2329073886791984, 0.2921353254803423], 
reward next is 0.7079, 
noisyNet noise sample is [array([-0.45062056], dtype=float32), -0.97621095]. 
=============================================
[2019-03-23 23:01:11,366] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[62.585968]
 [62.585968]
 [62.585968]
 [62.585968]
 [62.585968]], R is [[62.66796875]
 [62.74929428]
 [62.82960892]
 [62.90989304]
 [62.9913826 ]].
[2019-03-23 23:01:13,164] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.9784179e-21 1.0000000e+00 1.4210560e-34 1.0066783e-31 4.5121068e-36], sum to 1.0000
[2019-03-23 23:01:13,170] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3555
[2019-03-23 23:01:13,173] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 99.33333333333334, 1.0, 2.0, 0.5387961935160287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 636823.4039952325, 636823.4039952325, 148898.6757580896], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3649800.0000, 
sim time next is 3650400.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.5217238401339737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 617713.6727703778, 617713.6727703774, 146175.697653815], 
processed observation next is [1.0, 0.2608695652173913, 0.37037037037037035, 1.0, 1.0, 1.0, 0.43062361920711145, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22061202598942065, 0.22061202598942048, 0.28110711087272117], 
reward next is 0.7189, 
noisyNet noise sample is [array([-0.6951197], dtype=float32), -1.5924791]. 
=============================================
[2019-03-23 23:01:14,273] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.6227108e-19 1.0000000e+00 1.6010431e-34 8.3535914e-31 1.4974799e-34], sum to 1.0000
[2019-03-23 23:01:14,283] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1512
[2019-03-23 23:01:14,286] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.66666666666667, 1.0, 2.0, 0.5701406899286054, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 670785.1487239931, 670785.1487239926, 153982.6056231993], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3644400.0000, 
sim time next is 3645000.0000, 
raw observation next is [23.0, 95.0, 1.0, 2.0, 0.5717427412042697, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 672129.1391251883, 672129.1391251883, 154230.554886271], 
processed observation next is [1.0, 0.17391304347826086, 0.4074074074074074, 0.95, 1.0, 1.0, 0.49016993000508297, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24004612111613868, 0.24004612111613868, 0.2965972209351366], 
reward next is 0.7034, 
noisyNet noise sample is [array([-0.9443217], dtype=float32), -0.5889406]. 
=============================================
[2019-03-23 23:01:14,305] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[66.81183]
 [66.81183]
 [66.81183]
 [66.81183]
 [66.81183]], R is [[66.8470993 ]
 [66.88250732]
 [66.91015625]
 [66.95394135]
 [66.99557495]].
[2019-03-23 23:01:14,951] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.2079419e-22 1.0000000e+00 3.1112482e-32 1.6076760e-28 8.3116440e-36], sum to 1.0000
[2019-03-23 23:01:14,958] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7318
[2019-03-23 23:01:14,962] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1608731.893584816 W.
[2019-03-23 23:01:14,967] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.0, 100.0, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.69430430096614, 6.9112, 121.923362638675, 1608731.893584816, 1207721.312968293, 247962.2984140332], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3661800.0000, 
sim time next is 3662400.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.3803962107694602, 1.0, 1.0, 0.3803962107694602, 1.0, 1.0, 0.6056031561846695, 6.9112, 6.9112, 121.94756008, 1301058.919218612, 1301058.919218612, 288601.1143352606], 
processed observation next is [1.0, 0.391304347826087, 0.37037037037037035, 1.0, 1.0, 1.0, 0.2623764413922145, 1.0, 0.5, 0.2623764413922145, 1.0, 0.5, 0.5070039452308369, 0.0, 0.0, 0.8096049824067558, 0.4646638997209328, 0.4646638997209328, 0.5550021429524242], 
reward next is 0.4450, 
noisyNet noise sample is [array([0.7286468], dtype=float32), 0.48986638]. 
=============================================
[2019-03-23 23:01:15,073] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.4306164e-20 1.0000000e+00 2.6441106e-32 9.7824461e-31 1.3667830e-34], sum to 1.0000
[2019-03-23 23:01:15,078] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1749
[2019-03-23 23:01:15,084] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.08333333333334, 94.00000000000001, 1.0, 2.0, 0.6696799924360773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 763228.5417115594, 763228.5417115594, 170482.4166058683], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3712200.0000, 
sim time next is 3712800.0000, 
raw observation next is [25.06666666666667, 94.0, 1.0, 2.0, 0.6681501539406507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 761484.1318554935, 761484.1318554935, 170201.0041468944], 
processed observation next is [1.0, 1.0, 0.4839506172839507, 0.94, 1.0, 1.0, 0.6049406594531556, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2719586185198191, 0.2719586185198191, 0.3273096233594123], 
reward next is 0.6727, 
noisyNet noise sample is [array([-0.30591902], dtype=float32), 1.3289707]. 
=============================================
[2019-03-23 23:01:17,279] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72500, global step 1158935: loss -109.7020
[2019-03-23 23:01:17,281] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72500, global step 1158935: learning rate 0.0005
[2019-03-23 23:01:17,512] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72500, global step 1159044: loss -109.1390
[2019-03-23 23:01:17,514] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72500, global step 1159046: learning rate 0.0005
[2019-03-23 23:01:18,462] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72500, global step 1159500: loss -108.3356
[2019-03-23 23:01:18,465] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72500, global step 1159500: learning rate 0.0005
[2019-03-23 23:01:18,966] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72500, global step 1159745: loss -106.6449
[2019-03-23 23:01:18,967] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72500, global step 1159746: learning rate 0.0005
[2019-03-23 23:01:18,979] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72500, global step 1159751: loss -121.2988
[2019-03-23 23:01:18,983] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72500, global step 1159752: learning rate 0.0005
[2019-03-23 23:01:19,043] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72500, global step 1159780: loss -107.7034
[2019-03-23 23:01:19,047] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72500, global step 1159782: learning rate 0.0005
[2019-03-23 23:01:19,070] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72500, global step 1159791: loss -140.1900
[2019-03-23 23:01:19,071] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72500, global step 1159791: learning rate 0.0005
[2019-03-23 23:01:19,375] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72500, global step 1159941: loss -96.9530
[2019-03-23 23:01:19,380] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72500, global step 1159941: learning rate 0.0005
[2019-03-23 23:01:19,479] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72500, global step 1159990: loss -118.2755
[2019-03-23 23:01:19,482] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72500, global step 1159990: learning rate 0.0005
[2019-03-23 23:01:19,612] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72500, global step 1160051: loss -117.5142
[2019-03-23 23:01:19,613] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72500, global step 1160053: learning rate 0.0005
[2019-03-23 23:01:20,066] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72500, global step 1160278: loss -149.5654
[2019-03-23 23:01:20,071] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72500, global step 1160278: learning rate 0.0005
[2019-03-23 23:01:20,346] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72500, global step 1160410: loss -107.0370
[2019-03-23 23:01:20,353] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72500, global step 1160410: learning rate 0.0005
[2019-03-23 23:01:20,416] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72500, global step 1160443: loss -105.8768
[2019-03-23 23:01:20,423] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72500, global step 1160443: learning rate 0.0005
[2019-03-23 23:01:20,469] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72500, global step 1160469: loss -98.7687
[2019-03-23 23:01:20,473] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72500, global step 1160470: learning rate 0.0005
[2019-03-23 23:01:20,874] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72500, global step 1160667: loss -86.7900
[2019-03-23 23:01:20,877] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72500, global step 1160667: learning rate 0.0005
[2019-03-23 23:01:21,425] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72500, global step 1160935: loss -129.1504
[2019-03-23 23:01:21,426] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72500, global step 1160935: learning rate 0.0005
[2019-03-23 23:01:21,610] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.8549535e-21 1.0000000e+00 1.5994696e-32 6.3854320e-30 5.2294484e-35], sum to 1.0000
[2019-03-23 23:01:21,618] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8018
[2019-03-23 23:01:21,626] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.16666666666666, 59.0, 1.0, 2.0, 0.6425717629525376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 732815.988911174, 732815.988911174, 165579.8690615533], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3793800.0000, 
sim time next is 3794400.0000, 
raw observation next is [30.0, 59.0, 1.0, 2.0, 0.6314531342314018, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 722533.7688282294, 722533.7688282294, 163716.3560948353], 
processed observation next is [1.0, 0.9565217391304348, 0.6666666666666666, 0.59, 1.0, 1.0, 0.5612537312278593, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2580477745815105, 0.2580477745815105, 0.31483914633622173], 
reward next is 0.6852, 
noisyNet noise sample is [array([0.8773102], dtype=float32), 0.2410815]. 
=============================================
[2019-03-23 23:01:24,385] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.4584188e-20 1.0000000e+00 4.4720331e-33 2.0639337e-29 1.9561008e-35], sum to 1.0000
[2019-03-23 23:01:24,393] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4537
[2019-03-23 23:01:24,398] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.11666666666667, 93.16666666666667, 1.0, 2.0, 0.739287966639277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 842603.7581764528, 842603.7581764538, 183716.7778123635], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3887400.0000, 
sim time next is 3888000.0000, 
raw observation next is [26.0, 94.0, 1.0, 2.0, 0.7385263505095606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 841735.2292184276, 841735.2292184276, 183567.4584407163], 
processed observation next is [0.0, 0.0, 0.5185185185185185, 0.94, 1.0, 1.0, 0.688721845844715, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.300619724720867, 0.300619724720867, 0.3530143431552236], 
reward next is 0.6470, 
noisyNet noise sample is [array([2.3378644], dtype=float32), -1.0137376]. 
=============================================
[2019-03-23 23:01:24,419] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[62.63574]
 [62.63574]
 [62.63574]
 [62.63574]
 [62.63574]], R is [[62.65636444]
 [62.67649841]
 [62.69729614]
 [62.72068405]
 [62.7406044 ]].
[2019-03-23 23:01:25,845] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.3329915e-22 1.0000000e+00 7.6775192e-36 3.7310172e-30 2.5073645e-36], sum to 1.0000
[2019-03-23 23:01:25,846] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7342
[2019-03-23 23:01:25,853] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.93333333333333, 47.33333333333333, 1.0, 2.0, 0.6863534549253073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 782240.8401981449, 782240.8401981449, 173576.5132534534], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3861600.0000, 
sim time next is 3862200.0000, 
raw observation next is [33.91666666666666, 46.66666666666667, 1.0, 2.0, 0.6828083467289628, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 778198.4096943679, 778198.4096943679, 172914.1847535137], 
processed observation next is [0.0, 0.6956521739130435, 0.811728395061728, 0.46666666666666673, 1.0, 1.0, 0.622390888963051, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27792800346227425, 0.27792800346227425, 0.3325272783721417], 
reward next is 0.6675, 
noisyNet noise sample is [array([-0.87578815], dtype=float32), 0.04503508]. 
=============================================
[2019-03-23 23:01:25,951] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.6300962e-20 1.0000000e+00 2.1048938e-33 2.9727758e-31 3.1002743e-34], sum to 1.0000
[2019-03-23 23:01:25,963] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6894
[2019-03-23 23:01:25,968] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.25, 68.66666666666666, 1.0, 2.0, 0.7627450369550568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 869354.1264120702, 869354.1264120702, 188365.6222887504], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3873000.0000, 
sim time next is 3873600.0000, 
raw observation next is [29.9, 69.0, 1.0, 2.0, 0.7462053212910059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 850492.1903086734, 850492.190308673, 185077.3237900074], 
processed observation next is [0.0, 0.8695652173913043, 0.6629629629629629, 0.69, 1.0, 1.0, 0.697863477727388, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3037472108245262, 0.30374721082452605, 0.3559179303653988], 
reward next is 0.6441, 
noisyNet noise sample is [array([-0.4293414], dtype=float32), -0.10079224]. 
=============================================
[2019-03-23 23:01:33,097] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.4563587e-18 1.0000000e+00 7.0282137e-29 1.9928282e-25 1.0323339e-30], sum to 1.0000
[2019-03-23 23:01:33,105] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5151
[2019-03-23 23:01:33,117] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1330934.101604077 W.
[2019-03-23 23:01:33,123] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.3, 88.33333333333333, 1.0, 2.0, 0.3891233659715267, 1.0, 2.0, 0.3891233659715267, 1.0, 1.0, 0.6194970714899615, 6.9112, 6.9112, 121.94756008, 1330934.101604077, 1330934.101604077, 292350.3514165011], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3984000.0000, 
sim time next is 3984600.0000, 
raw observation next is [25.25, 88.66666666666667, 1.0, 2.0, 0.5347816938394797, 1.0, 2.0, 0.5347816938394797, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1219334.811370145, 1219334.811370145, 246348.5763615649], 
processed observation next is [1.0, 0.08695652173913043, 0.49074074074074076, 0.8866666666666667, 1.0, 1.0, 0.44616868314223773, 1.0, 1.0, 0.44616868314223773, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.4354767183464804, 0.4354767183464804, 0.4737472622337786], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9510086], dtype=float32), 0.1942588]. 
=============================================
[2019-03-23 23:01:33,737] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73000, global step 1166931: loss 0.6533
[2019-03-23 23:01:33,738] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73000, global step 1166931: learning rate 0.0005
[2019-03-23 23:01:34,160] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73000, global step 1167148: loss 0.8668
[2019-03-23 23:01:34,162] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73000, global step 1167149: learning rate 0.0005
[2019-03-23 23:01:34,947] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73000, global step 1167552: loss 1.1408
[2019-03-23 23:01:34,950] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73000, global step 1167552: learning rate 0.0005
[2019-03-23 23:01:35,174] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73000, global step 1167665: loss 0.8762
[2019-03-23 23:01:35,176] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73000, global step 1167666: learning rate 0.0005
[2019-03-23 23:01:35,290] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73000, global step 1167722: loss 0.8462
[2019-03-23 23:01:35,296] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73000, global step 1167723: learning rate 0.0005
[2019-03-23 23:01:35,396] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73000, global step 1167779: loss 0.8678
[2019-03-23 23:01:35,399] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73000, global step 1167779: learning rate 0.0005
[2019-03-23 23:01:35,413] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73000, global step 1167784: loss 0.8755
[2019-03-23 23:01:35,415] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73000, global step 1167784: learning rate 0.0005
[2019-03-23 23:01:35,552] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73000, global step 1167858: loss 0.6726
[2019-03-23 23:01:35,556] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73000, global step 1167858: learning rate 0.0005
[2019-03-23 23:01:35,726] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73000, global step 1167945: loss 0.6900
[2019-03-23 23:01:35,729] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73000, global step 1167947: learning rate 0.0005
[2019-03-23 23:01:35,756] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73000, global step 1167961: loss 0.6342
[2019-03-23 23:01:35,761] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73000, global step 1167961: learning rate 0.0005
[2019-03-23 23:01:36,545] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73000, global step 1168364: loss 0.1221
[2019-03-23 23:01:36,548] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73000, global step 1168365: learning rate 0.0005
[2019-03-23 23:01:36,597] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73000, global step 1168395: loss 0.0576
[2019-03-23 23:01:36,600] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73000, global step 1168395: learning rate 0.0005
[2019-03-23 23:01:36,759] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73000, global step 1168480: loss 0.0120
[2019-03-23 23:01:36,760] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73000, global step 1168480: learning rate 0.0005
[2019-03-23 23:01:36,793] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73000, global step 1168492: loss 0.0129
[2019-03-23 23:01:36,797] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73000, global step 1168493: learning rate 0.0005
[2019-03-23 23:01:37,306] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73000, global step 1168755: loss 0.0123
[2019-03-23 23:01:37,307] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73000, global step 1168756: learning rate 0.0005
[2019-03-23 23:01:37,887] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73000, global step 1169054: loss 0.0062
[2019-03-23 23:01:37,889] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73000, global step 1169055: learning rate 0.0005
[2019-03-23 23:01:47,898] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.0408777e-19 1.0000000e+00 2.2050297e-30 1.9628061e-27 6.1841053e-32], sum to 1.0000
[2019-03-23 23:01:47,906] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2529
[2019-03-23 23:01:47,912] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2172731.219539227 W.
[2019-03-23 23:01:47,917] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.16666666666666, 42.33333333333334, 1.0, 2.0, 0.9523868107378626, 1.0, 2.0, 0.9523868107378626, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2172731.219539227, 2172731.219539227, 410745.1038668235], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4290600.0000, 
sim time next is 4291200.0000, 
raw observation next is [33.0, 44.0, 1.0, 2.0, 0.9479933532811442, 1.0, 2.0, 0.9479933532811442, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2162696.04994476, 2162696.04994476, 408701.1771068761], 
processed observation next is [1.0, 0.6956521739130435, 0.7777777777777778, 0.44, 1.0, 1.0, 0.9380873253346955, 1.0, 1.0, 0.9380873253346955, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.7723914464088428, 0.7723914464088428, 0.7859638021286078], 
reward next is 0.2140, 
noisyNet noise sample is [array([-0.32904172], dtype=float32), 2.0440118]. 
=============================================
[2019-03-23 23:01:49,162] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73500, global step 1174842: loss -111.0503
[2019-03-23 23:01:49,169] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73500, global step 1174842: learning rate 0.0005
[2019-03-23 23:01:49,469] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 23:01:49,473] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:01:49,474] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:01:49,474] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:01:49,474] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:01:49,474] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:01:49,476] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:01:49,475] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:01:49,477] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:01:49,478] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:01:49,477] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:01:49,501] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run48
[2019-03-23 23:01:49,525] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run48
[2019-03-23 23:01:49,526] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run48
[2019-03-23 23:01:49,570] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run48
[2019-03-23 23:01:49,570] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run48
[2019-03-23 23:01:51,330] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.04795365]
[2019-03-23 23:01:51,331] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.88947856, 47.14260598666667, 1.0, 2.0, 0.3427375436556037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 432153.4784527359, 432153.4784527354, 120977.5808983927]
[2019-03-23 23:01:51,332] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:01:51,334] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.9173124e-21 1.0000000e+00 3.9251453e-33 1.6662352e-30 2.4646819e-35], sampled 0.47078641447827296
[2019-03-23 23:01:59,170] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.04795365]
[2019-03-23 23:01:59,171] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.09117276, 30.82073806333333, 1.0, 2.0, 0.3374463079532261, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 428339.0775928025, 428339.0775928025, 120315.4363037951]
[2019-03-23 23:01:59,172] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:01:59,174] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.9173124e-21 1.0000000e+00 3.9251453e-33 1.6662352e-30 2.4646819e-35], sampled 0.17513346322522427
[2019-03-23 23:02:09,523] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.04795365]
[2019-03-23 23:02:09,524] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.26666666666667, 78.66666666666667, 1.0, 2.0, 0.6967296914801593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 880580.877161484, 880580.877161484, 178568.9790654641]
[2019-03-23 23:02:09,526] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:02:09,527] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.9173124e-21 1.0000000e+00 3.9251453e-33 1.6662352e-30 2.4646819e-35], sampled 0.21592961037975122
[2019-03-23 23:02:11,392] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.04795365]
[2019-03-23 23:02:11,393] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.83333333333334, 88.33333333333334, 1.0, 2.0, 0.4866500785585974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 601792.5751157071, 601792.5751157067, 141466.6181085007]
[2019-03-23 23:02:11,394] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:02:11,396] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.9173124e-21 1.0000000e+00 3.9251453e-33 1.6662352e-30 2.4646819e-35], sampled 0.6328964723330668
[2019-03-23 23:02:11,423] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.04795365]
[2019-03-23 23:02:11,424] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.0, 90.0, 1.0, 2.0, 0.4398756102253016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 541262.2919415171, 541262.2919415171, 134287.8630670249]
[2019-03-23 23:02:11,424] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:02:11,426] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.9173124e-21 1.0000000e+00 3.9251453e-33 1.6662352e-30 2.4646819e-35], sampled 0.22959373706468778
[2019-03-23 23:02:42,883] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.04795365]
[2019-03-23 23:02:42,884] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.13333333333333, 88.0, 1.0, 2.0, 0.5780799645221347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260425980766, 661554.3273454955, 661554.3273454955, 154485.8356532589]
[2019-03-23 23:02:42,885] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:02:42,888] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.9173124e-21 1.0000000e+00 3.9251453e-33 1.6662352e-30 2.4646819e-35], sampled 0.03165158434105131
[2019-03-23 23:02:47,879] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.04795365]
[2019-03-23 23:02:47,880] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.0, 59.5, 1.0, 2.0, 0.6984236657247149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 797430.6740928398, 797430.6740928394, 175914.4756253989]
[2019-03-23 23:02:47,881] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:02:47,884] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.9173124e-21 1.0000000e+00 3.9251453e-33 1.6662352e-30 2.4646819e-35], sampled 0.25948296855912456
[2019-03-23 23:02:54,900] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.04795365]
[2019-03-23 23:02:54,901] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.75, 74.66666666666667, 1.0, 2.0, 0.7378076832529087, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 852441.8536327363, 852441.8536327353, 184005.2979494723]
[2019-03-23 23:02:54,903] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:02:54,906] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.9173124e-21 1.0000000e+00 3.9251453e-33 1.6662352e-30 2.4646819e-35], sampled 0.46669590787731985
[2019-03-23 23:02:57,002] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.04795365]
[2019-03-23 23:02:57,007] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.0, 94.0, 1.0, 2.0, 0.5990305068893342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 690676.392665214, 690676.3926652136, 158300.0520655443]
[2019-03-23 23:02:57,009] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:02:57,010] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.9173124e-21 1.0000000e+00 3.9251453e-33 1.6662352e-30 2.4646819e-35], sampled 0.7400181304303255
[2019-03-23 23:02:57,834] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.04795365]
[2019-03-23 23:02:57,837] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.16666666666667, 95.0, 1.0, 2.0, 0.6898156764370509, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 786188.7769111303, 786188.7769111303, 174224.1336729662]
[2019-03-23 23:02:57,839] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:02:57,842] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.9173124e-21 1.0000000e+00 3.9251453e-33 1.6662352e-30 2.4646819e-35], sampled 0.23806955301877342
[2019-03-23 23:03:08,001] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.04795365]
[2019-03-23 23:03:08,002] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.47259754, 81.21734352333334, 1.0, 2.0, 0.4426255217322879, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 541950.6390463243, 541950.6390463243, 134623.3558648224]
[2019-03-23 23:03:08,003] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:03:08,005] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.9173124e-21 1.0000000e+00 3.9251453e-33 1.6662352e-30 2.4646819e-35], sampled 0.6857264379461442
[2019-03-23 23:03:13,229] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.04795365]
[2019-03-23 23:03:13,232] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.0, 74.0, 1.0, 2.0, 0.7054313055947565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 803995.3760310678, 803995.3760310675, 177177.0833776878]
[2019-03-23 23:03:13,233] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:03:13,236] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.9173124e-21 1.0000000e+00 3.9251453e-33 1.6662352e-30 2.4646819e-35], sampled 0.8336623183160815
[2019-03-23 23:03:25,843] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.04795365]
[2019-03-23 23:03:25,845] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.83333333333334, 42.0, 1.0, 2.0, 0.2872222770010135, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 368518.749436699, 368518.749436699, 114010.8869700963]
[2019-03-23 23:03:25,846] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:03:25,848] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.9173124e-21 1.0000000e+00 3.9251453e-33 1.6662352e-30 2.4646819e-35], sampled 0.7523995842320557
[2019-03-23 23:03:32,498] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:03:32,502] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:03:32,558] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:03:32,622] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:03:32,647] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:03:33,663] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1175000, evaluation results [1175000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:03:33,896] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.6369390e-22 1.0000000e+00 3.3043962e-33 2.9503938e-32 1.4280382e-35], sum to 1.0000
[2019-03-23 23:03:33,902] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9156
[2019-03-23 23:03:33,910] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.53333333333333, 65.33333333333334, 1.0, 2.0, 0.6011218325624693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 691968.054997047, 691968.054997047, 158608.328133989], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4306800.0000, 
sim time next is 4307400.0000, 
raw observation next is [28.15, 67.5, 1.0, 2.0, 0.602608823238433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 693483.112633403, 693483.112633403, 158856.0512359448], 
processed observation next is [1.0, 0.8695652173913043, 0.5981481481481481, 0.675, 1.0, 1.0, 0.5269152657600393, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24767254022621538, 0.24767254022621538, 0.30549240622297075], 
reward next is 0.6945, 
noisyNet noise sample is [array([-0.6034047], dtype=float32), -1.5761232]. 
=============================================
[2019-03-23 23:03:34,002] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73500, global step 1175162: loss -127.3352
[2019-03-23 23:03:34,008] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73500, global step 1175164: learning rate 0.0005
[2019-03-23 23:03:34,812] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73500, global step 1175553: loss -157.6478
[2019-03-23 23:03:34,815] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73500, global step 1175553: learning rate 0.0005
[2019-03-23 23:03:34,962] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73500, global step 1175624: loss -104.5547
[2019-03-23 23:03:34,965] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73500, global step 1175625: learning rate 0.0005
[2019-03-23 23:03:35,137] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73500, global step 1175712: loss -158.3499
[2019-03-23 23:03:35,140] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73500, global step 1175712: learning rate 0.0005
[2019-03-23 23:03:35,179] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73500, global step 1175733: loss -105.1989
[2019-03-23 23:03:35,181] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73500, global step 1175733: learning rate 0.0005
[2019-03-23 23:03:35,384] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73500, global step 1175828: loss -84.7302
[2019-03-23 23:03:35,386] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73500, global step 1175828: learning rate 0.0005
[2019-03-23 23:03:35,405] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73500, global step 1175838: loss -127.9712
[2019-03-23 23:03:35,407] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73500, global step 1175838: learning rate 0.0005
[2019-03-23 23:03:35,456] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73500, global step 1175867: loss -119.7695
[2019-03-23 23:03:35,461] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73500, global step 1175867: learning rate 0.0005
[2019-03-23 23:03:35,614] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73500, global step 1175942: loss -72.1448
[2019-03-23 23:03:35,618] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73500, global step 1175942: learning rate 0.0005
[2019-03-23 23:03:36,519] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73500, global step 1176382: loss -80.0779
[2019-03-23 23:03:36,525] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73500, global step 1176385: learning rate 0.0005
[2019-03-23 23:03:36,535] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73500, global step 1176388: loss -102.2096
[2019-03-23 23:03:36,537] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73500, global step 1176388: learning rate 0.0005
[2019-03-23 23:03:36,596] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73500, global step 1176417: loss -66.0306
[2019-03-23 23:03:36,599] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73500, global step 1176418: learning rate 0.0005
[2019-03-23 23:03:36,679] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73500, global step 1176459: loss -101.8707
[2019-03-23 23:03:36,681] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73500, global step 1176459: learning rate 0.0005
[2019-03-23 23:03:37,209] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73500, global step 1176722: loss -115.4830
[2019-03-23 23:03:37,210] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73500, global step 1176722: learning rate 0.0005
[2019-03-23 23:03:37,648] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73500, global step 1176936: loss -109.5902
[2019-03-23 23:03:37,649] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73500, global step 1176936: learning rate 0.0005
[2019-03-23 23:03:40,975] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.3079018e-19 1.0000000e+00 4.4662753e-31 2.6158931e-29 9.9426951e-35], sum to 1.0000
[2019-03-23 23:03:40,980] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1455
[2019-03-23 23:03:40,985] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.16666666666667, 65.83333333333334, 1.0, 2.0, 0.6411472037833245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 730694.4681672167, 730694.4681672167, 165300.7113850907], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4457400.0000, 
sim time next is 4458000.0000, 
raw observation next is [29.33333333333334, 66.66666666666667, 1.0, 2.0, 0.6595266188202692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 751651.1553026398, 751651.1553026394, 168622.8774887465], 
processed observation next is [0.0, 0.6086956521739131, 0.6419753086419755, 0.6666666666666667, 1.0, 1.0, 0.5946745462146061, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26844684117951423, 0.26844684117951406, 0.3242747644014356], 
reward next is 0.6757, 
noisyNet noise sample is [array([0.57856673], dtype=float32), 1.5142809]. 
=============================================
[2019-03-23 23:03:41,006] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[65.931656]
 [65.931656]
 [65.931656]
 [65.931656]
 [65.931656]], R is [[65.94807434]
 [65.97071075]
 [65.99312592]
 [66.01316833]
 [66.03105164]].
[2019-03-23 23:03:49,761] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74000, global step 1182882: loss 0.0027
[2019-03-23 23:03:49,763] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74000, global step 1182883: learning rate 0.0005
[2019-03-23 23:03:50,512] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74000, global step 1183249: loss 0.0039
[2019-03-23 23:03:50,514] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74000, global step 1183249: learning rate 0.0005
[2019-03-23 23:03:50,823] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.6356396e-20 1.0000000e+00 5.9086947e-29 8.2419281e-29 1.6105815e-33], sum to 1.0000
[2019-03-23 23:03:50,829] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7190
[2019-03-23 23:03:50,833] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.66666666666667, 80.66666666666667, 1.0, 2.0, 0.68276906198865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 778153.6140491075, 778153.6140491075, 172909.3257577292], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4645200.0000, 
sim time next is 4645800.0000, 
raw observation next is [27.5, 81.5, 1.0, 2.0, 0.6804694075869498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 775531.3662562115, 775531.3662562115, 172481.1585393459], 
processed observation next is [1.0, 0.782608695652174, 0.5740740740740741, 0.815, 1.0, 1.0, 0.6196064376035118, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27697548794864696, 0.27697548794864696, 0.3316945356525883], 
reward next is 0.6683, 
noisyNet noise sample is [array([-1.0652801], dtype=float32), 0.6885701]. 
=============================================
[2019-03-23 23:03:51,350] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74000, global step 1183665: loss 0.0644
[2019-03-23 23:03:51,352] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74000, global step 1183666: learning rate 0.0005
[2019-03-23 23:03:51,392] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74000, global step 1183683: loss 0.0575
[2019-03-23 23:03:51,395] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74000, global step 1183684: learning rate 0.0005
[2019-03-23 23:03:51,441] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74000, global step 1183710: loss 0.0534
[2019-03-23 23:03:51,447] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74000, global step 1183710: learning rate 0.0005
[2019-03-23 23:03:51,645] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74000, global step 1183808: loss 0.0168
[2019-03-23 23:03:51,647] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74000, global step 1183808: learning rate 0.0005
[2019-03-23 23:03:51,664] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74000, global step 1183814: loss 0.0206
[2019-03-23 23:03:51,666] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74000, global step 1183817: learning rate 0.0005
[2019-03-23 23:03:51,710] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74000, global step 1183841: loss 0.0035
[2019-03-23 23:03:51,711] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74000, global step 1183841: learning rate 0.0005
[2019-03-23 23:03:51,926] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74000, global step 1183941: loss 0.0002
[2019-03-23 23:03:51,930] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74000, global step 1183941: learning rate 0.0005
[2019-03-23 23:03:52,019] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74000, global step 1183985: loss 0.0001
[2019-03-23 23:03:52,021] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74000, global step 1183985: learning rate 0.0005
[2019-03-23 23:03:52,645] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6402152e-22 1.0000000e+00 2.9968528e-34 4.3395578e-32 4.7028150e-36], sum to 1.0000
[2019-03-23 23:03:52,651] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0242
[2019-03-23 23:03:52,656] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 94.66666666666667, 1.0, 2.0, 0.8931513664360335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.925881215065, 1021878.542009406, 1021878.542009406, 216140.8153070965], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4674000.0000, 
sim time next is 4674600.0000, 
raw observation next is [23.9, 94.5, 1.0, 2.0, 0.7307740568547058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260425664464, 842156.4405466687, 842156.4405466687, 182518.2293335609], 
processed observation next is [1.0, 0.08695652173913043, 0.4407407407407407, 0.945, 1.0, 1.0, 0.6794929248270306, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621284933968, 0.300770157338096, 0.300770157338096, 0.3509965948722325], 
reward next is 0.6490, 
noisyNet noise sample is [array([-0.395146], dtype=float32), 0.7961327]. 
=============================================
[2019-03-23 23:03:52,753] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74000, global step 1184339: loss 0.0017
[2019-03-23 23:03:52,758] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74000, global step 1184339: learning rate 0.0005
[2019-03-23 23:03:52,858] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74000, global step 1184389: loss 0.0010
[2019-03-23 23:03:52,860] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74000, global step 1184389: learning rate 0.0005
[2019-03-23 23:03:52,999] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74000, global step 1184457: loss 0.0002
[2019-03-23 23:03:53,002] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74000, global step 1184460: learning rate 0.0005
[2019-03-23 23:03:53,068] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74000, global step 1184491: loss 0.0000
[2019-03-23 23:03:53,071] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74000, global step 1184492: learning rate 0.0005
[2019-03-23 23:03:53,769] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74000, global step 1184817: loss 0.0002
[2019-03-23 23:03:53,771] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74000, global step 1184817: learning rate 0.0005
[2019-03-23 23:03:54,111] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74000, global step 1184982: loss 0.0129
[2019-03-23 23:03:54,115] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74000, global step 1184982: learning rate 0.0005
[2019-03-23 23:04:06,259] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74500, global step 1190850: loss 0.2253
[2019-03-23 23:04:06,261] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74500, global step 1190850: learning rate 0.0005
[2019-03-23 23:04:06,872] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74500, global step 1191144: loss 0.4455
[2019-03-23 23:04:06,876] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74500, global step 1191144: learning rate 0.0005
[2019-03-23 23:04:07,674] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74500, global step 1191561: loss 0.4045
[2019-03-23 23:04:07,675] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74500, global step 1191561: learning rate 0.0005
[2019-03-23 23:04:07,870] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74500, global step 1191657: loss 0.6122
[2019-03-23 23:04:07,875] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74500, global step 1191658: learning rate 0.0005
[2019-03-23 23:04:07,911] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74500, global step 1191681: loss 0.5665
[2019-03-23 23:04:07,916] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74500, global step 1191681: learning rate 0.0005
[2019-03-23 23:04:07,959] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74500, global step 1191704: loss 0.5807
[2019-03-23 23:04:07,959] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74500, global step 1191704: loss 0.7008
[2019-03-23 23:04:07,960] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74500, global step 1191704: learning rate 0.0005
[2019-03-23 23:04:07,961] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74500, global step 1191704: learning rate 0.0005
[2019-03-23 23:04:08,321] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74500, global step 1191891: loss 0.5639
[2019-03-23 23:04:08,325] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74500, global step 1191893: learning rate 0.0005
[2019-03-23 23:04:08,342] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74500, global step 1191904: loss 0.5510
[2019-03-23 23:04:08,345] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74500, global step 1191905: learning rate 0.0005
[2019-03-23 23:04:08,428] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74500, global step 1191948: loss 0.4527
[2019-03-23 23:04:08,430] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74500, global step 1191948: learning rate 0.0005
[2019-03-23 23:04:08,950] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9382584e-20 1.0000000e+00 1.8976231e-30 3.6987273e-27 1.9605337e-32], sum to 1.0000
[2019-03-23 23:04:08,954] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0837
[2019-03-23 23:04:08,959] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.4, 90.0, 1.0, 2.0, 0.6601980798499059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 752416.783483857, 752416.7834838566, 168744.2097567154], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4995000.0000, 
sim time next is 4995600.0000, 
raw observation next is [25.2, 90.33333333333334, 1.0, 2.0, 0.6511921855568673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 742147.9466914413, 742147.9466914413, 167107.9418780368], 
processed observation next is [1.0, 0.8260869565217391, 0.4888888888888889, 0.9033333333333334, 1.0, 1.0, 0.5847526018534135, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2650528381040862, 0.2650528381040862, 0.3213614266885323], 
reward next is 0.6786, 
noisyNet noise sample is [array([0.49959195], dtype=float32), 1.0495286]. 
=============================================
[2019-03-23 23:04:09,222] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74500, global step 1192353: loss 0.3807
[2019-03-23 23:04:09,226] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74500, global step 1192354: learning rate 0.0005
[2019-03-23 23:04:09,314] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74500, global step 1192402: loss 0.2940
[2019-03-23 23:04:09,318] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74500, global step 1192403: learning rate 0.0005
[2019-03-23 23:04:09,386] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74500, global step 1192437: loss 0.3282
[2019-03-23 23:04:09,388] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74500, global step 1192437: learning rate 0.0005
[2019-03-23 23:04:09,413] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74500, global step 1192448: loss 0.2599
[2019-03-23 23:04:09,414] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74500, global step 1192448: learning rate 0.0005
[2019-03-23 23:04:09,817] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.4353267e-16 1.0000000e+00 4.1280407e-26 1.0797195e-24 3.1833215e-29], sum to 1.0000
[2019-03-23 23:04:09,821] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1333
[2019-03-23 23:04:09,825] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 89.0, 1.0, 2.0, 0.6380598466361044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 746987.950491324, 746987.950491324, 165685.649480028], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4950000.0000, 
sim time next is 4950600.0000, 
raw observation next is [24.08333333333333, 87.16666666666667, 1.0, 2.0, 0.6438021526785517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 754947.4631619395, 754947.463161939, 166777.6126385206], 
processed observation next is [1.0, 0.30434782608695654, 0.4475308641975307, 0.8716666666666667, 1.0, 1.0, 0.5759549436649425, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26962409398640697, 0.2696240939864068, 0.32072617815100113], 
reward next is 0.6793, 
noisyNet noise sample is [array([-0.37778598], dtype=float32), 0.06026133]. 
=============================================
[2019-03-23 23:04:10,099] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74500, global step 1192802: loss 0.1869
[2019-03-23 23:04:10,101] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74500, global step 1192802: learning rate 0.0005
[2019-03-23 23:04:10,157] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74500, global step 1192833: loss 0.2022
[2019-03-23 23:04:10,160] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74500, global step 1192833: learning rate 0.0005
[2019-03-23 23:04:13,467] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7165326e-22 1.0000000e+00 1.8266099e-32 5.1449112e-30 5.6697605e-35], sum to 1.0000
[2019-03-23 23:04:13,476] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8576
[2019-03-23 23:04:13,479] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.95, 94.66666666666667, 1.0, 2.0, 0.5391437081108215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 634725.2353751698, 634725.2353751693, 148853.9292760345], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5032200.0000, 
sim time next is 5032800.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.5371888271469287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 632838.4490636433, 632838.4490636433, 148551.9812808732], 
processed observation next is [0.0, 0.2608695652173913, 0.4074074074074074, 0.94, 1.0, 1.0, 0.449034318032058, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22601373180844406, 0.22601373180844406, 0.28567688707860234], 
reward next is 0.7143, 
noisyNet noise sample is [array([-0.29221848], dtype=float32), 0.8106845]. 
=============================================
[2019-03-23 23:04:14,613] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0159776e-20 1.0000000e+00 4.1632942e-32 9.4993245e-30 1.4931512e-33], sum to 1.0000
[2019-03-23 23:04:14,622] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1369
[2019-03-23 23:04:14,625] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.3, 98.0, 1.0, 2.0, 0.715636867085667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 815633.0648478653, 815633.0648478644, 179126.4862646998], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5107200.0000, 
sim time next is 5107800.0000, 
raw observation next is [25.15, 99.0, 1.0, 2.0, 0.7149585121468389, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 814859.5121489662, 814859.5121489662, 178996.1560354635], 
processed observation next is [0.0, 0.08695652173913043, 0.487037037037037, 0.99, 1.0, 1.0, 0.6606648954129035, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2910212543389165, 0.2910212543389165, 0.344223376991276], 
reward next is 0.6558, 
noisyNet noise sample is [array([0.54831904], dtype=float32), 2.1452007]. 
=============================================
[2019-03-23 23:04:18,311] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.3195436e-21 1.0000000e+00 1.8368517e-34 6.3967446e-30 2.1052700e-34], sum to 1.0000
[2019-03-23 23:04:18,320] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9281
[2019-03-23 23:04:18,324] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.41666666666666, 94.16666666666666, 1.0, 2.0, 0.7470121768882841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 851412.3198257467, 851412.3198257467, 185239.0775706492], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5125800.0000, 
sim time next is 5126400.0000, 
raw observation next is [26.7, 93.0, 1.0, 2.0, 0.7577602066122907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 863669.3636501353, 863669.3636501353, 187371.7529637729], 
processed observation next is [0.0, 0.34782608695652173, 0.5444444444444444, 0.93, 1.0, 1.0, 0.7116192935860604, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.30845334416076264, 0.30845334416076264, 0.3603302941611017], 
reward next is 0.6397, 
noisyNet noise sample is [array([-0.04065447], dtype=float32), -1.0744592]. 
=============================================
[2019-03-23 23:04:21,890] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.8187882e-20 1.0000000e+00 2.7170170e-30 2.0717113e-29 2.6492395e-32], sum to 1.0000
[2019-03-23 23:04:21,895] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5037
[2019-03-23 23:04:21,899] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.13333333333333, 93.33333333333334, 1.0, 2.0, 0.9787741055421479, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.024894000749812, 6.9112, 121.9256385594236, 1176058.258064423, 1117836.960768878, 235753.9965531426], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5193600.0000, 
sim time next is 5194200.0000, 
raw observation next is [24.06666666666667, 93.66666666666667, 1.0, 2.0, 0.95852967794929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.954492644930458, 6.9112, 121.9256311094295, 1126944.602078897, 1104774.973245619, 231540.752999743], 
processed observation next is [1.0, 0.08695652173913043, 0.4469135802469137, 0.9366666666666668, 1.0, 1.0, 0.95063056898725, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.004329264493045759, 0.0, 0.8094593968466898, 0.4024802150281775, 0.39456249044486397, 0.44527067884565963], 
reward next is 0.3383, 
noisyNet noise sample is [array([0.4869221], dtype=float32), -0.54583246]. 
=============================================
[2019-03-23 23:04:21,911] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75000, global step 1198877: loss 0.0166
[2019-03-23 23:04:21,913] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75000, global step 1198877: learning rate 0.0005
[2019-03-23 23:04:21,979] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.9863915e-18 1.0000000e+00 5.3178988e-29 1.2592682e-28 1.3515620e-32], sum to 1.0000
[2019-03-23 23:04:21,988] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8006
[2019-03-23 23:04:21,993] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.9, 91.0, 1.0, 2.0, 0.6373573477747546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 728166.0717597627, 728166.0717597627, 164712.6451915106], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5182200.0000, 
sim time next is 5182800.0000, 
raw observation next is [24.93333333333333, 92.0, 1.0, 2.0, 0.6472790486336369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 737686.0934874393, 737686.0934874393, 166401.4549401015], 
processed observation next is [0.0, 1.0, 0.47901234567901224, 0.92, 1.0, 1.0, 0.5800941055162344, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2634593191026569, 0.2634593191026569, 0.3200027979617337], 
reward next is 0.6800, 
noisyNet noise sample is [array([0.9797031], dtype=float32), 0.009635191]. 
=============================================
[2019-03-23 23:04:22,350] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75000, global step 1199103: loss 0.0940
[2019-03-23 23:04:22,351] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75000, global step 1199103: learning rate 0.0005
[2019-03-23 23:04:23,416] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75000, global step 1199650: loss 0.3198
[2019-03-23 23:04:23,418] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75000, global step 1199650: learning rate 0.0005
[2019-03-23 23:04:23,445] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75000, global step 1199660: loss 0.3236
[2019-03-23 23:04:23,450] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75000, global step 1199661: learning rate 0.0005
[2019-03-23 23:04:23,572] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75000, global step 1199727: loss 0.2918
[2019-03-23 23:04:23,574] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75000, global step 1199728: learning rate 0.0005
[2019-03-23 23:04:23,636] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75000, global step 1199754: loss 0.2479
[2019-03-23 23:04:23,637] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75000, global step 1199754: learning rate 0.0005
[2019-03-23 23:04:23,686] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75000, global step 1199785: loss 0.2439
[2019-03-23 23:04:23,689] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75000, global step 1199786: learning rate 0.0005
[2019-03-23 23:04:23,721] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75000, global step 1199802: loss 0.2550
[2019-03-23 23:04:23,723] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75000, global step 1199803: learning rate 0.0005
[2019-03-23 23:04:24,063] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75000, global step 1199948: loss 0.2140
[2019-03-23 23:04:24,065] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75000, global step 1199948: learning rate 0.0005
[2019-03-23 23:04:24,162] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-23 23:04:24,163] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:04:24,163] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:04:24,164] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:04:24,164] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:04:24,165] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:04:24,166] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:04:24,166] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:04:24,168] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:04:24,165] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:04:24,169] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:04:24,185] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run49
[2019-03-23 23:04:24,185] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run49
[2019-03-23 23:04:24,208] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run49
[2019-03-23 23:04:24,262] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run49
[2019-03-23 23:04:24,297] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run49
[2019-03-23 23:04:28,292] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.040785417]
[2019-03-23 23:04:28,293] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [18.6545054, 47.55443576, 1.0, 2.0, 0.2369229005702727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 305606.7968316366, 305606.7968316366, 83183.11771772699]
[2019-03-23 23:04:28,293] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:04:28,294] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.4660324e-17 1.0000000e+00 1.0668498e-27 1.5603984e-25 1.3604143e-29], sampled 0.27493125572704624
[2019-03-23 23:04:34,490] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.040785417]
[2019-03-23 23:04:34,492] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.3, 18.33333333333334, 1.0, 2.0, 0.2978654663197849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 384236.2907340638, 384236.2907340638, 94298.9473438812]
[2019-03-23 23:04:34,493] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:04:34,498] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.4660324e-17 1.0000000e+00 1.0668498e-27 1.5603984e-25 1.3604143e-29], sampled 0.35580523238911765
[2019-03-23 23:04:49,078] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.040785417]
[2019-03-23 23:04:49,080] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.0, 54.0, 1.0, 2.0, 0.4151787980895122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 507992.6003544285, 507992.6003544285, 130616.0759935518]
[2019-03-23 23:04:49,081] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:04:49,084] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.4660324e-17 1.0000000e+00 1.0668498e-27 1.5603984e-25 1.3604143e-29], sampled 0.3222928096459272
[2019-03-23 23:04:55,433] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.040785417]
[2019-03-23 23:04:55,434] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.53333333333333, 76.66666666666667, 1.0, 2.0, 0.5459974442210977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 641960.2780370902, 641960.2780370902, 149943.0742992861]
[2019-03-23 23:04:55,434] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:04:55,438] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.4660324e-17 1.0000000e+00 1.0668498e-27 1.5603984e-25 1.3604143e-29], sampled 0.9071819186274455
[2019-03-23 23:04:56,418] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.040785417]
[2019-03-23 23:04:56,418] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [30.85, 55.0, 1.0, 2.0, 0.6044936363699682, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 692800.4162241672, 692800.4162241672, 159044.906823813]
[2019-03-23 23:04:56,419] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:04:56,423] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.4660324e-17 1.0000000e+00 1.0668498e-27 1.5603984e-25 1.3604143e-29], sampled 0.16970072927801827
[2019-03-23 23:04:56,689] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.040785417]
[2019-03-23 23:04:56,691] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.25, 87.16666666666667, 1.0, 2.0, 0.7203582667218146, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 825223.666924122, 825223.6669241225, 180245.4472460913]
[2019-03-23 23:04:56,691] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:04:56,694] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.4660324e-17 1.0000000e+00 1.0668498e-27 1.5603984e-25 1.3604143e-29], sampled 0.07266364019878813
[2019-03-23 23:04:58,731] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.040785417]
[2019-03-23 23:04:58,732] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.73333333333333, 78.66666666666667, 1.0, 2.0, 0.8036073263708998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 915955.5810788585, 915955.5810788585, 196684.8241658541]
[2019-03-23 23:04:58,733] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:04:58,735] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.4660324e-17 1.0000000e+00 1.0668498e-27 1.5603984e-25 1.3604143e-29], sampled 0.8423257402617607
[2019-03-23 23:05:09,644] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.040785417]
[2019-03-23 23:05:09,645] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.837486985, 78.19788705333333, 1.0, 2.0, 1.014994531261912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.237054425586105, 6.9112, 121.9246871392248, 1324068.442850532, 1157203.707501958, 244378.6709286596]
[2019-03-23 23:05:09,645] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:05:09,649] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.4660324e-17 1.0000000e+00 1.0668498e-27 1.5603984e-25 1.3604143e-29], sampled 0.6309822953459143
[2019-03-23 23:05:09,651] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1324068.442850532 W.
[2019-03-23 23:05:36,637] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.040785417]
[2019-03-23 23:05:36,638] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.4, 75.0, 1.0, 2.0, 0.6170687510648039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 703466.806559694, 703466.806559694, 161049.5034026424]
[2019-03-23 23:05:36,638] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:05:36,641] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.4660324e-17 1.0000000e+00 1.0668498e-27 1.5603984e-25 1.3604143e-29], sampled 0.43467861979584355
[2019-03-23 23:06:06,746] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:06:07,040] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:06:07,244] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:06:07,317] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:06:07,386] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:06:08,402] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1200000, evaluation results [1200000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:06:08,437] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75000, global step 1200020: loss 0.2090
[2019-03-23 23:06:08,440] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75000, global step 1200021: learning rate 0.0005
[2019-03-23 23:06:09,197] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75000, global step 1200386: loss 0.1084
[2019-03-23 23:06:09,200] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75000, global step 1200387: learning rate 0.0005
[2019-03-23 23:06:09,453] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75000, global step 1200510: loss 0.0581
[2019-03-23 23:06:09,454] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75000, global step 1200510: learning rate 0.0005
[2019-03-23 23:06:09,474] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75000, global step 1200515: loss 0.0638
[2019-03-23 23:06:09,476] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75000, global step 1200516: learning rate 0.0005
[2019-03-23 23:06:09,589] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75000, global step 1200579: loss 0.0330
[2019-03-23 23:06:09,592] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75000, global step 1200579: learning rate 0.0005
[2019-03-23 23:06:10,049] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75000, global step 1200805: loss 0.0137
[2019-03-23 23:06:10,053] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75000, global step 1200806: learning rate 0.0005
[2019-03-23 23:06:10,417] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75000, global step 1200981: loss 0.0021
[2019-03-23 23:06:10,419] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75000, global step 1200982: learning rate 0.0005
[2019-03-23 23:06:10,426] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.50150764e-21 1.00000000e+00 3.77752868e-32 1.02253226e-29
 9.40346478e-36], sum to 1.0000
[2019-03-23 23:06:10,430] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7198
[2019-03-23 23:06:10,439] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.61666666666667, 87.33333333333333, 1.0, 2.0, 0.6548021054484232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 746264.0875455833, 746264.0875455833, 167761.848516209], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5273400.0000, 
sim time next is 5274000.0000, 
raw observation next is [25.6, 87.0, 1.0, 2.0, 0.6492839682388071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 739972.1479863283, 739972.1479863283, 166762.9130553889], 
processed observation next is [1.0, 0.043478260869565216, 0.5037037037037038, 0.87, 1.0, 1.0, 0.5824809145700084, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2642757671379744, 0.2642757671379744, 0.3206979097219017], 
reward next is 0.6793, 
noisyNet noise sample is [array([-1.2325972], dtype=float32), 1.5513948]. 
=============================================
[2019-03-23 23:06:10,458] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[67.02252]
 [67.02252]
 [67.02252]
 [67.02252]
 [67.02252]], R is [[67.03160095]
 [67.03866577]
 [67.04438019]
 [67.04951477]
 [67.0537796 ]].
[2019-03-23 23:06:15,310] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.4443433e-21 1.0000000e+00 2.2646126e-34 2.0274359e-30 1.6988935e-35], sum to 1.0000
[2019-03-23 23:06:15,317] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1838
[2019-03-23 23:06:15,324] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.4, 76.5, 1.0, 2.0, 0.7325519680636349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 834922.2194152767, 834922.2194152767, 182404.212151205], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5423400.0000, 
sim time next is 5424000.0000, 
raw observation next is [29.33333333333334, 77.0, 1.0, 2.0, 0.7361741334743771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 839052.8229532002, 839052.8229532002, 183111.4784960658], 
processed observation next is [1.0, 0.782608695652174, 0.6419753086419755, 0.77, 1.0, 1.0, 0.6859215874694965, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29966172248328576, 0.29966172248328576, 0.3521374586462804], 
reward next is 0.6479, 
noisyNet noise sample is [array([0.23967195], dtype=float32), -0.08396695]. 
=============================================
[2019-03-23 23:06:15,343] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[66.28811]
 [66.28811]
 [66.28811]
 [66.28811]
 [66.28811]], R is [[66.27310181]
 [66.25959778]
 [66.24588776]
 [66.22993469]
 [66.22048187]].
[2019-03-23 23:06:17,453] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.8133495e-17 1.0000000e+00 2.6124939e-28 8.3191684e-27 2.2723437e-31], sum to 1.0000
[2019-03-23 23:06:17,468] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5080
[2019-03-23 23:06:17,474] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 94.0, 1.0, 2.0, 0.9704258377360393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.962458630201536, 6.9112, 121.925817214755, 1132501.293058925, 1106252.341477074, 233671.3685442741], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5464800.0000, 
sim time next is 5465400.0000, 
raw observation next is [26.58333333333334, 93.83333333333334, 1.0, 2.0, 0.9764443252319353, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.999533460686187, 6.9112, 121.925538372501, 1158366.429580003, 1113131.989628031, 235096.0261276777], 
processed observation next is [1.0, 0.2608695652173913, 0.5401234567901236, 0.9383333333333335, 1.0, 1.0, 0.9719575300380181, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.008833346068618741, 0.0, 0.8094587811699241, 0.4137022962785725, 0.3975471391528682, 0.45210774255322633], 
reward next is 0.1062, 
noisyNet noise sample is [array([-0.12707105], dtype=float32), -0.85301167]. 
=============================================
[2019-03-23 23:06:19,588] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.2116633e-19 1.0000000e+00 4.1449165e-30 2.1154210e-27 1.9651096e-31], sum to 1.0000
[2019-03-23 23:06:19,597] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4636
[2019-03-23 23:06:19,601] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 94.0, 1.0, 2.0, 0.9704258377360393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.962458630201536, 6.9112, 121.925817214755, 1132501.293058925, 1106252.341477074, 233671.3685442741], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5464800.0000, 
sim time next is 5465400.0000, 
raw observation next is [26.58333333333334, 93.83333333333334, 1.0, 2.0, 0.9764443252319353, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.999533460686187, 6.9112, 121.925538372501, 1158366.429580003, 1113131.989628031, 235096.0261276777], 
processed observation next is [1.0, 0.2608695652173913, 0.5401234567901236, 0.9383333333333335, 1.0, 1.0, 0.9719575300380181, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.008833346068618741, 0.0, 0.8094587811699241, 0.4137022962785725, 0.3975471391528682, 0.45210774255322633], 
reward next is 0.1062, 
noisyNet noise sample is [array([2.3396852], dtype=float32), -0.26799682]. 
=============================================
[2019-03-23 23:06:19,882] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.9432183e-21 1.0000000e+00 2.0290276e-32 7.0695930e-30 5.7507975e-33], sum to 1.0000
[2019-03-23 23:06:19,892] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2424
[2019-03-23 23:06:19,898] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.2, 92.5, 1.0, 2.0, 0.9329145825257404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1063442.896513911, 1063442.89651391, 224938.3415403327], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5470200.0000, 
sim time next is 5470800.0000, 
raw observation next is [27.26666666666667, 92.33333333333333, 1.0, 2.0, 0.8991796002242468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1024962.179835402, 1024962.179835402, 217290.3967491686], 
processed observation next is [1.0, 0.30434782608695654, 0.5654320987654322, 0.9233333333333333, 1.0, 1.0, 0.8799757145526748, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.36605792136978643, 0.36605792136978643, 0.41786614759455504], 
reward next is 0.5821, 
noisyNet noise sample is [array([0.47831753], dtype=float32), 1.1221818]. 
=============================================
[2019-03-23 23:06:22,405] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75500, global step 1206801: loss 0.4243
[2019-03-23 23:06:22,408] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75500, global step 1206804: learning rate 0.0005
[2019-03-23 23:06:22,947] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75500, global step 1207065: loss 0.2452
[2019-03-23 23:06:22,949] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75500, global step 1207067: learning rate 0.0005
[2019-03-23 23:06:24,006] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75500, global step 1207585: loss 0.0455
[2019-03-23 23:06:24,009] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75500, global step 1207587: learning rate 0.0005
[2019-03-23 23:06:24,101] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75500, global step 1207630: loss 0.0345
[2019-03-23 23:06:24,104] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75500, global step 1207631: learning rate 0.0005
[2019-03-23 23:06:24,247] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75500, global step 1207706: loss 0.0042
[2019-03-23 23:06:24,249] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75500, global step 1207706: learning rate 0.0005
[2019-03-23 23:06:24,262] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75500, global step 1207713: loss 0.0011
[2019-03-23 23:06:24,264] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75500, global step 1207714: learning rate 0.0005
[2019-03-23 23:06:24,343] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75500, global step 1207753: loss 0.0117
[2019-03-23 23:06:24,347] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75500, global step 1207754: learning rate 0.0005
[2019-03-23 23:06:24,424] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2054044e-19 1.0000000e+00 1.3747850e-32 7.1527709e-28 1.6490559e-36], sum to 1.0000
[2019-03-23 23:06:24,432] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2514
[2019-03-23 23:06:24,436] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.9, 90.0, 1.0, 2.0, 0.6882485410618115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 784401.7855293098, 784401.7855293098, 173930.7908329035], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5526000.0000, 
sim time next is 5526600.0000, 
raw observation next is [25.88333333333333, 90.16666666666667, 1.0, 2.0, 0.6887497913108003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 784973.3565493103, 784973.3565493098, 174024.7013023535], 
processed observation next is [1.0, 1.0, 0.5141975308641974, 0.9016666666666667, 1.0, 1.0, 0.6294640372747622, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2803476273390394, 0.28034762733903923, 0.33466288711991055], 
reward next is 0.6653, 
noisyNet noise sample is [array([-0.10298361], dtype=float32), -2.6379051]. 
=============================================
[2019-03-23 23:06:24,470] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75500, global step 1207808: loss 0.0101
[2019-03-23 23:06:24,473] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75500, global step 1207809: learning rate 0.0005
[2019-03-23 23:06:24,608] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75500, global step 1207875: loss 0.0007
[2019-03-23 23:06:24,609] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75500, global step 1207875: learning rate 0.0005
[2019-03-23 23:06:24,685] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75500, global step 1207914: loss 0.0080
[2019-03-23 23:06:24,687] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75500, global step 1207915: learning rate 0.0005
[2019-03-23 23:06:24,996] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.4463791e-19 1.0000000e+00 7.1436014e-30 2.3592812e-29 3.9879178e-32], sum to 1.0000
[2019-03-23 23:06:25,004] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1299
[2019-03-23 23:06:25,011] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.75, 92.83333333333333, 1.0, 2.0, 0.694559091137551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 791597.6784731805, 791597.67847318, 175117.0105955385], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5601000.0000, 
sim time next is 5601600.0000, 
raw observation next is [25.8, 93.0, 1.0, 2.0, 0.6988888184228149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 796534.8868371941, 796534.8868371941, 175934.4455884027], 
processed observation next is [1.0, 0.8695652173913043, 0.5111111111111112, 0.93, 1.0, 1.0, 0.6415343076462082, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2844767452989979, 0.2844767452989979, 0.33833547228538985], 
reward next is 0.6617, 
noisyNet noise sample is [array([-0.02542162], dtype=float32), 0.49144682]. 
=============================================
[2019-03-23 23:06:25,684] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75500, global step 1208403: loss 0.0968
[2019-03-23 23:06:25,686] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75500, global step 1208403: learning rate 0.0005
[2019-03-23 23:06:25,779] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75500, global step 1208446: loss 0.0976
[2019-03-23 23:06:25,784] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75500, global step 1208446: learning rate 0.0005
[2019-03-23 23:06:25,794] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75500, global step 1208447: loss 0.0631
[2019-03-23 23:06:25,797] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75500, global step 1208449: learning rate 0.0005
[2019-03-23 23:06:25,935] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75500, global step 1208521: loss 0.0977
[2019-03-23 23:06:25,938] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75500, global step 1208522: learning rate 0.0005
[2019-03-23 23:06:26,494] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75500, global step 1208789: loss 0.2472
[2019-03-23 23:06:26,496] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75500, global step 1208789: learning rate 0.0005
[2019-03-23 23:06:26,715] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75500, global step 1208894: loss 0.1905
[2019-03-23 23:06:26,718] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75500, global step 1208895: learning rate 0.0005
[2019-03-23 23:06:27,237] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.5832775e-19 1.0000000e+00 4.0816963e-31 3.7025064e-29 2.7400678e-33], sum to 1.0000
[2019-03-23 23:06:27,246] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8603
[2019-03-23 23:06:27,250] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.63333333333333, 95.33333333333334, 1.0, 2.0, 0.6577981013765478, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 749680.2303406324, 749680.2303406324, 168306.6930477245], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5607600.0000, 
sim time next is 5608200.0000, 
raw observation next is [24.51666666666667, 95.66666666666666, 1.0, 2.0, 0.6545430137022182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 745968.6624914559, 745968.6624914559, 167714.920192067], 
processed observation next is [1.0, 0.9130434782608695, 0.46358024691358035, 0.9566666666666666, 1.0, 1.0, 0.5887416829788312, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2664173794612342, 0.2664173794612342, 0.3225286926770519], 
reward next is 0.6775, 
noisyNet noise sample is [array([-0.03785938], dtype=float32), -1.5646919]. 
=============================================
[2019-03-23 23:06:28,672] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.08487435e-20 1.00000000e+00 2.63465782e-31 2.49844617e-29
 7.38301140e-34], sum to 1.0000
[2019-03-23 23:06:28,683] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4916
[2019-03-23 23:06:28,685] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.75, 92.83333333333333, 1.0, 2.0, 0.694559091137551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 791597.6784731805, 791597.67847318, 175117.0105955385], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5601000.0000, 
sim time next is 5601600.0000, 
raw observation next is [25.8, 93.0, 1.0, 2.0, 0.6988888184228149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 796534.8868371941, 796534.8868371941, 175934.4455884027], 
processed observation next is [1.0, 0.8695652173913043, 0.5111111111111112, 0.93, 1.0, 1.0, 0.6415343076462082, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2844767452989979, 0.2844767452989979, 0.33833547228538985], 
reward next is 0.6617, 
noisyNet noise sample is [array([0.35157087], dtype=float32), -1.2072773]. 
=============================================
[2019-03-23 23:06:35,777] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.5518899e-20 1.0000000e+00 3.4836734e-33 4.3164339e-29 1.4004235e-34], sum to 1.0000
[2019-03-23 23:06:35,784] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0233
[2019-03-23 23:06:35,789] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.8, 68.5, 1.0, 2.0, 0.5953871079098836, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 686856.5603912566, 686856.5603912566, 157690.6950133212], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5765400.0000, 
sim time next is 5766000.0000, 
raw observation next is [27.63333333333333, 69.0, 1.0, 2.0, 0.5917000262327827, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 683681.1761705457, 683681.1761705457, 157108.4311178991], 
processed observation next is [0.0, 0.7391304347826086, 0.5790123456790122, 0.69, 1.0, 1.0, 0.5139286026580746, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24417184863233776, 0.24417184863233776, 0.3021315983036521], 
reward next is 0.6979, 
noisyNet noise sample is [array([0.7155867], dtype=float32), 0.93531364]. 
=============================================
[2019-03-23 23:06:35,810] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[68.6209]
 [68.6209]
 [68.6209]
 [68.6209]
 [68.6209]], R is [[68.63256073]
 [68.64298248]
 [68.65219116]
 [68.66035461]
 [68.66810608]].
[2019-03-23 23:06:36,394] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.2073665e-22 1.0000000e+00 2.8275429e-33 2.4484107e-30 1.7745667e-35], sum to 1.0000
[2019-03-23 23:06:36,404] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4744
[2019-03-23 23:06:36,416] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 80.0, 1.0, 2.0, 0.5356245784624534, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 631996.4142400594, 631996.4142400594, 148337.8431348591], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5778000.0000, 
sim time next is 5778600.0000, 
raw observation next is [24.7, 80.33333333333334, 1.0, 2.0, 0.532885361868483, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 629364.2588961768, 629364.2588961768, 147916.6385414228], 
processed observation next is [0.0, 0.9130434782608695, 0.4703703703703703, 0.8033333333333335, 1.0, 1.0, 0.44391114508152735, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22477294960577743, 0.22477294960577743, 0.2844550741181208], 
reward next is 0.7155, 
noisyNet noise sample is [array([-0.38650042], dtype=float32), 0.33091682]. 
=============================================
[2019-03-23 23:06:38,886] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76000, global step 1214806: loss 0.0227
[2019-03-23 23:06:38,887] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76000, global step 1214806: learning rate 0.0005
[2019-03-23 23:06:39,424] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76000, global step 1215071: loss 0.1109
[2019-03-23 23:06:39,428] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76000, global step 1215073: learning rate 0.0005
[2019-03-23 23:06:39,681] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.2705367e-21 1.0000000e+00 1.6899237e-33 8.0927501e-31 1.1193418e-35], sum to 1.0000
[2019-03-23 23:06:39,689] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0310
[2019-03-23 23:06:39,694] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.96666666666667, 85.33333333333334, 1.0, 2.0, 0.4812300093898966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 578951.0772841612, 578951.0772841608, 140153.7042824521], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5790000.0000, 
sim time next is 5790600.0000, 
raw observation next is [22.9, 85.5, 1.0, 2.0, 0.4788270590936547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 576497.2911361257, 576497.2911361257, 139798.4967784627], 
processed observation next is [1.0, 0.0, 0.4037037037037037, 0.855, 1.0, 1.0, 0.37955602273054134, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20589188969147346, 0.20589188969147346, 0.26884326303550515], 
reward next is 0.7312, 
noisyNet noise sample is [array([1.215163], dtype=float32), 0.9620821]. 
=============================================
[2019-03-23 23:06:40,683] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76000, global step 1215654: loss 0.1338
[2019-03-23 23:06:40,690] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76000, global step 1215654: learning rate 0.0005
[2019-03-23 23:06:40,741] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76000, global step 1215680: loss 0.0775
[2019-03-23 23:06:40,742] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76000, global step 1215680: loss 0.0954
[2019-03-23 23:06:40,743] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76000, global step 1215680: learning rate 0.0005
[2019-03-23 23:06:40,744] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76000, global step 1215680: learning rate 0.0005
[2019-03-23 23:06:40,749] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76000, global step 1215681: loss 0.0959
[2019-03-23 23:06:40,751] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76000, global step 1215683: learning rate 0.0005
[2019-03-23 23:06:40,819] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76000, global step 1215710: loss 0.1250
[2019-03-23 23:06:40,823] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76000, global step 1215711: learning rate 0.0005
[2019-03-23 23:06:41,031] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76000, global step 1215799: loss 0.0788
[2019-03-23 23:06:41,034] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76000, global step 1215799: learning rate 0.0005
[2019-03-23 23:06:41,358] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76000, global step 1215955: loss 0.0338
[2019-03-23 23:06:41,359] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76000, global step 1215955: loss 0.0165
[2019-03-23 23:06:41,360] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76000, global step 1215955: learning rate 0.0005
[2019-03-23 23:06:41,362] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76000, global step 1215956: learning rate 0.0005
[2019-03-23 23:06:42,255] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76000, global step 1216420: loss 0.0226
[2019-03-23 23:06:42,257] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76000, global step 1216420: learning rate 0.0005
[2019-03-23 23:06:42,456] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76000, global step 1216524: loss 0.0069
[2019-03-23 23:06:42,460] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76000, global step 1216524: learning rate 0.0005
[2019-03-23 23:06:42,465] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76000, global step 1216526: loss 0.0141
[2019-03-23 23:06:42,467] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76000, global step 1216527: learning rate 0.0005
[2019-03-23 23:06:42,857] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76000, global step 1216730: loss 0.0037
[2019-03-23 23:06:42,859] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76000, global step 1216731: learning rate 0.0005
[2019-03-23 23:06:43,237] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76000, global step 1216930: loss 0.0014
[2019-03-23 23:06:43,238] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76000, global step 1216930: learning rate 0.0005
[2019-03-23 23:06:43,290] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76000, global step 1216956: loss 0.0055
[2019-03-23 23:06:43,292] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76000, global step 1216956: learning rate 0.0005
[2019-03-23 23:06:44,249] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.4143370e-21 1.0000000e+00 7.7583729e-34 1.6650025e-30 1.1347022e-36], sum to 1.0000
[2019-03-23 23:06:44,255] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5550
[2019-03-23 23:06:44,257] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.6, 60.33333333333334, 1.0, 2.0, 0.868123954736386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260244055368, 1063418.395902724, 1063418.395902724, 213691.3779162502], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5912400.0000, 
sim time next is 5913000.0000, 
raw observation next is [25.85, 59.5, 1.0, 2.0, 0.8760378476145037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426101091, 1071813.649852, 1071813.649852, 215424.4264131816], 
processed observation next is [1.0, 0.43478260869565216, 0.5129629629629631, 0.595, 1.0, 1.0, 0.8524260090648853, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621287832718, 0.38279058923285714, 0.38279058923285714, 0.4142777431022723], 
reward next is 0.5857, 
noisyNet noise sample is [array([-1.4563316], dtype=float32), -0.04548508]. 
=============================================
[2019-03-23 23:06:44,279] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[71.30372]
 [71.30372]
 [71.30372]
 [71.30372]
 [71.30372]], R is [[71.17640686]
 [71.05370331]
 [70.34317017]
 [70.14037323]
 [69.43897247]].
[2019-03-23 23:06:45,042] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.3227755e-23 1.0000000e+00 2.3749238e-34 1.7445598e-32 5.3567882e-36], sum to 1.0000
[2019-03-23 23:06:45,052] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8387
[2019-03-23 23:06:45,062] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.03333333333333, 85.0, 1.0, 2.0, 0.3429333226997203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 435633.8569697447, 435633.8569697447, 121034.9484804274], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5892000.0000, 
sim time next is 5892600.0000, 
raw observation next is [18.96666666666667, 85.0, 1.0, 2.0, 0.3357987230548986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 426882.915325749, 426882.915325749, 120105.5737033603], 
processed observation next is [1.0, 0.17391304347826086, 0.25802469135802475, 0.85, 1.0, 1.0, 0.20928419411297453, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15245818404491038, 0.15245818404491038, 0.23097225712184674], 
reward next is 0.7690, 
noisyNet noise sample is [array([-1.0558873], dtype=float32), 0.79302436]. 
=============================================
[2019-03-23 23:06:45,455] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.9167879e-21 1.0000000e+00 8.8196046e-34 6.5793590e-31 1.7645896e-35], sum to 1.0000
[2019-03-23 23:06:45,462] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3771
[2019-03-23 23:06:45,466] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 77.0, 1.0, 2.0, 0.3517448257975024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 442437.5985458789, 442437.5985458789, 122150.8068210318], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5900400.0000, 
sim time next is 5901000.0000, 
raw observation next is [21.18333333333333, 76.33333333333334, 1.0, 2.0, 0.3781930230954506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 475205.6884088357, 475205.6884088357, 125713.7844129822], 
processed observation next is [1.0, 0.30434782608695654, 0.34012345679012335, 0.7633333333333334, 1.0, 1.0, 0.25975359892315547, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16971631728886988, 0.16971631728886988, 0.24175727771727348], 
reward next is 0.7582, 
noisyNet noise sample is [array([2.0166733], dtype=float32), 1.1490772]. 
=============================================
[2019-03-23 23:06:45,485] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[69.531]
 [69.531]
 [69.531]
 [69.531]
 [69.531]], R is [[69.59393311]
 [69.66308594]
 [69.73069   ]
 [69.7987442 ]
 [69.86755371]].
[2019-03-23 23:06:46,796] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.2154969e-22 1.0000000e+00 1.7499970e-34 6.4170237e-32 3.5837231e-36], sum to 1.0000
[2019-03-23 23:06:46,804] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5119
[2019-03-23 23:06:46,805] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1601246.789967016 W.
[2019-03-23 23:06:46,809] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.75, 70.5, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.684674099767758, 6.9112, 121.9229364043839, 1601246.789967016, 1205169.009366041, 247838.3642873524], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5999400.0000, 
sim time next is 6000000.0000, 
raw observation next is [25.93333333333333, 70.33333333333333, 1.0, 2.0, 0.6581079151608752, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9756199847285155, 6.9112, 6.9112, 121.9255768421569, 1485066.039956424, 1485066.039956424, 305440.0191945422], 
processed observation next is [1.0, 0.43478260869565216, 0.5160493827160493, 0.7033333333333333, 1.0, 1.0, 0.5929856132867561, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.9695249809106443, 0.0, 0.0, 0.8094590365684338, 0.5303807285558657, 0.5303807285558657, 0.5873846522971965], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.47077543], dtype=float32), 1.3766689]. 
=============================================
[2019-03-23 23:06:46,829] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[70.52413]
 [70.52413]
 [70.52413]
 [70.52413]
 [70.52413]], R is [[69.81889343]
 [69.12070465]
 [68.88259888]
 [68.69165039]
 [68.00473785]].
[2019-03-23 23:06:48,221] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.03059434e-19 1.00000000e+00 1.16075395e-32 7.78148281e-29
 1.39072381e-34], sum to 1.0000
[2019-03-23 23:06:48,231] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9787
[2019-03-23 23:06:48,231] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1618700.404850269 W.
[2019-03-23 23:06:48,237] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.43333333333333, 67.33333333333334, 1.0, 2.0, 0.7097549039254576, 1.0, 2.0, 0.7097549039254576, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1618700.404850269, 1618700.404850269, 307873.2044243688], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6003600.0000, 
sim time next is 6004200.0000, 
raw observation next is [27.71666666666667, 66.66666666666666, 1.0, 2.0, 0.8074868481949966, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9974222942703511, 6.911199999999999, 6.9112, 121.9260426156618, 1635825.010888154, 1635825.010888155, 337666.6505247724], 
processed observation next is [1.0, 0.4782608695652174, 0.5820987654320988, 0.6666666666666665, 1.0, 1.0, 0.770817676422615, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9967778678379388, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5842232181743406, 0.5842232181743411, 0.64935894331687], 
reward next is 0.3506, 
noisyNet noise sample is [array([0.24345258], dtype=float32), -0.7250478]. 
=============================================
[2019-03-23 23:06:51,810] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.0736231e-23 1.0000000e+00 5.6057150e-35 2.3209985e-33 4.9840720e-37], sum to 1.0000
[2019-03-23 23:06:51,821] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4734
[2019-03-23 23:06:51,829] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.53333333333333, 85.33333333333334, 1.0, 2.0, 0.55763976655275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 664379.4488298498, 664379.4488298498, 152216.2231024129], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6067200.0000, 
sim time next is 6067800.0000, 
raw observation next is [23.6, 85.0, 1.0, 2.0, 0.5525358302656825, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 658075.9839865417, 658075.9839865417, 151356.7276820784], 
processed observation next is [1.0, 0.21739130434782608, 0.4296296296296297, 0.85, 1.0, 1.0, 0.4673045598400982, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23502713713805062, 0.23502713713805062, 0.29107063015784307], 
reward next is 0.7089, 
noisyNet noise sample is [array([0.37018293], dtype=float32), -1.1131328]. 
=============================================
[2019-03-23 23:06:52,514] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.2151846e-21 1.0000000e+00 4.2466853e-33 4.3825641e-31 9.1555180e-35], sum to 1.0000
[2019-03-23 23:06:52,524] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5981
[2019-03-23 23:06:52,533] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.8, 60.0, 1.0, 2.0, 0.5528097390032127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 644834.3812655631, 644834.3812655631, 150848.2229191653], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6114000.0000, 
sim time next is 6114600.0000, 
raw observation next is [28.65, 60.5, 1.0, 2.0, 0.5498362459036629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 641973.1717908048, 641973.1717908048, 150384.2588391664], 
processed observation next is [1.0, 0.782608695652174, 0.6166666666666666, 0.605, 1.0, 1.0, 0.46409076893293194, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2292761327824303, 0.2292761327824303, 0.2892004977676277], 
reward next is 0.7108, 
noisyNet noise sample is [array([0.63842624], dtype=float32), -0.8375202]. 
=============================================
[2019-03-23 23:06:54,553] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76500, global step 1222739: loss 0.0860
[2019-03-23 23:06:54,554] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76500, global step 1222740: learning rate 0.0005
[2019-03-23 23:06:55,075] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76500, global step 1223000: loss 0.0275
[2019-03-23 23:06:55,076] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76500, global step 1223000: learning rate 0.0005
[2019-03-23 23:06:55,925] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76500, global step 1223437: loss 0.0199
[2019-03-23 23:06:55,927] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76500, global step 1223437: learning rate 0.0005
[2019-03-23 23:06:56,321] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76500, global step 1223646: loss 0.0134
[2019-03-23 23:06:56,322] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76500, global step 1223646: learning rate 0.0005
[2019-03-23 23:06:56,369] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76500, global step 1223668: loss 0.0036
[2019-03-23 23:06:56,370] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76500, global step 1223668: learning rate 0.0005
[2019-03-23 23:06:56,406] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76500, global step 1223683: loss 0.0104
[2019-03-23 23:06:56,407] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76500, global step 1223683: learning rate 0.0005
[2019-03-23 23:06:56,603] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76500, global step 1223788: loss 0.0224
[2019-03-23 23:06:56,605] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76500, global step 1223789: learning rate 0.0005
[2019-03-23 23:06:56,653] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76500, global step 1223816: loss 0.0083
[2019-03-23 23:06:56,657] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76500, global step 1223817: learning rate 0.0005
[2019-03-23 23:06:56,851] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76500, global step 1223912: loss 0.0031
[2019-03-23 23:06:56,852] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76500, global step 1223912: learning rate 0.0005
[2019-03-23 23:06:56,979] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76500, global step 1223978: loss 0.0278
[2019-03-23 23:06:56,982] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76500, global step 1223978: learning rate 0.0005
[2019-03-23 23:06:57,405] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.4515903e-21 1.0000000e+00 1.0287128e-31 4.8096754e-29 1.2905440e-34], sum to 1.0000
[2019-03-23 23:06:57,417] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4604
[2019-03-23 23:06:57,417] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1813292.671608742 W.
[2019-03-23 23:06:57,423] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.53333333333333, 66.33333333333334, 1.0, 2.0, 0.7949916671570705, 1.0, 2.0, 0.7949916671570705, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1813292.671608742, 1813292.671608743, 341687.6105426861], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6174600.0000, 
sim time next is 6175200.0000, 
raw observation next is [27.66666666666667, 65.66666666666667, 1.0, 2.0, 0.5383505861514802, 1.0, 2.0, 0.5383505861514802, 1.0, 1.0, 0.8570716660077152, 6.911200000000001, 6.9112, 121.94756008, 1841911.038192313, 1841911.038192313, 362810.4886624927], 
processed observation next is [1.0, 0.4782608695652174, 0.580246913580247, 0.6566666666666667, 1.0, 1.0, 0.45041736446604785, 1.0, 1.0, 0.45041736446604785, 1.0, 0.5, 0.8213395825096439, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6578253707829689, 0.6578253707829689, 0.6977124781971014], 
reward next is 0.3023, 
noisyNet noise sample is [array([-1.8613138], dtype=float32), 0.5493555]. 
=============================================
[2019-03-23 23:06:57,513] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76500, global step 1224253: loss 0.0138
[2019-03-23 23:06:57,514] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76500, global step 1224253: learning rate 0.0005
[2019-03-23 23:06:57,860] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76500, global step 1224430: loss 0.0618
[2019-03-23 23:06:57,862] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76500, global step 1224430: learning rate 0.0005
[2019-03-23 23:06:58,099] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76500, global step 1224553: loss 0.0886
[2019-03-23 23:06:58,101] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76500, global step 1224554: learning rate 0.0005
[2019-03-23 23:06:58,226] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.6497165e-21 1.0000000e+00 1.0912346e-32 5.7091039e-29 7.9630394e-36], sum to 1.0000
[2019-03-23 23:06:58,232] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9689
[2019-03-23 23:06:58,237] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.2, 70.0, 1.0, 2.0, 0.5335783232066694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 631375.388271421, 631375.388271421, 148076.7358797647], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6213600.0000, 
sim time next is 6214200.0000, 
raw observation next is [26.05, 70.33333333333334, 1.0, 2.0, 0.5300326316264592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 628094.5516078484, 628094.5516078484, 147537.1792820794], 
processed observation next is [1.0, 0.9565217391304348, 0.5203703703703704, 0.7033333333333335, 1.0, 1.0, 0.4405150376505466, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2243194827170887, 0.2243194827170887, 0.2837253447732296], 
reward next is 0.7163, 
noisyNet noise sample is [array([-1.0603591], dtype=float32), -0.74604326]. 
=============================================
[2019-03-23 23:06:58,378] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76500, global step 1224696: loss 0.0722
[2019-03-23 23:06:58,382] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76500, global step 1224697: learning rate 0.0005
[2019-03-23 23:06:58,484] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76500, global step 1224751: loss 0.1135
[2019-03-23 23:06:58,485] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76500, global step 1224751: learning rate 0.0005
[2019-03-23 23:06:58,875] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76500, global step 1224954: loss 0.1638
[2019-03-23 23:06:58,880] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76500, global step 1224955: learning rate 0.0005
[2019-03-23 23:06:58,970] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 23:06:58,972] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:06:58,973] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:06:58,973] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:06:58,976] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:06:58,978] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:06:58,977] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:06:58,984] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:06:58,983] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:06:58,987] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:06:58,989] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:06:58,998] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run50
[2019-03-23 23:06:59,019] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run50
[2019-03-23 23:06:59,043] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run50
[2019-03-23 23:06:59,066] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run50
[2019-03-23 23:06:59,067] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run50
[2019-03-23 23:07:32,280] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.06524029]
[2019-03-23 23:07:32,281] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.36666666666667, 87.0, 1.0, 2.0, 0.8439601210094724, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1004149.815807815, 1004149.815807815, 207242.5529594806]
[2019-03-23 23:07:32,282] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:07:32,284] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.3171428e-19 1.0000000e+00 6.1226324e-31 1.6921406e-28 5.0570494e-33], sampled 0.9556130485448899
[2019-03-23 23:07:34,214] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.06524029]
[2019-03-23 23:07:34,216] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.0, 74.83333333333334, 1.0, 2.0, 0.5458579464505539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 639744.9577680741, 639744.9577680741, 149834.1661897687]
[2019-03-23 23:07:34,218] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:07:34,220] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.3171428e-19 1.0000000e+00 6.1226324e-31 1.6921406e-28 5.0570494e-33], sampled 0.23535178837744253
[2019-03-23 23:07:50,276] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.06524029]
[2019-03-23 23:07:50,277] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.8, 53.0, 1.0, 2.0, 0.6354821426813558, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9855437607170686, 6.9112, 6.9112, 121.9260426156618, 1449113.146535606, 1449113.146535606, 303656.6564694942]
[2019-03-23 23:07:50,278] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:07:50,280] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.3171428e-19 1.0000000e+00 6.1226324e-31 1.6921406e-28 5.0570494e-33], sampled 0.3840492404019914
[2019-03-23 23:07:50,282] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1449113.146535606 W.
[2019-03-23 23:07:51,775] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.06524029]
[2019-03-23 23:07:51,777] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.81078344, 83.61017288, 1.0, 2.0, 0.7212846573076649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 885856.8387660673, 885856.8387660668, 182847.4560468]
[2019-03-23 23:07:51,779] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:07:51,781] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.3171428e-19 1.0000000e+00 6.1226324e-31 1.6921406e-28 5.0570494e-33], sampled 0.4080668662645158
[2019-03-23 23:08:00,915] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.06524029]
[2019-03-23 23:08:00,916] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.852410035, 93.21658070000001, 1.0, 2.0, 0.914261219810649, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260425490398, 1042165.196791411, 1042165.196791411, 220689.3193704088]
[2019-03-23 23:08:00,917] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:08:00,920] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.3171428e-19 1.0000000e+00 6.1226324e-31 1.6921406e-28 5.0570494e-33], sampled 0.405666530491422
[2019-03-23 23:08:01,535] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.06524029]
[2019-03-23 23:08:01,536] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.85, 61.0, 1.0, 2.0, 0.5349246706396878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 632148.6662855827, 632148.6662855832, 148263.1539478299]
[2019-03-23 23:08:01,537] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:08:01,540] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.3171428e-19 1.0000000e+00 6.1226324e-31 1.6921406e-28 5.0570494e-33], sampled 0.32708607429746817
[2019-03-23 23:08:10,470] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.06524029]
[2019-03-23 23:08:10,471] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.75, 63.66666666666667, 1.0, 2.0, 0.6441419678681486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 734109.1370086966, 734109.1370086966, 165838.5764618786]
[2019-03-23 23:08:10,472] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:08:10,476] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.3171428e-19 1.0000000e+00 6.1226324e-31 1.6921406e-28 5.0570494e-33], sampled 0.06640603428957936
[2019-03-23 23:08:11,808] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.06524029]
[2019-03-23 23:08:11,809] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.17276662333333, 47.73918877, 1.0, 2.0, 0.3700906561322549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 463378.9218828194, 463378.921882819, 124580.1883627019]
[2019-03-23 23:08:11,812] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:08:11,815] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.3171428e-19 1.0000000e+00 6.1226324e-31 1.6921406e-28 5.0570494e-33], sampled 0.4483931898798197
[2019-03-23 23:08:41,920] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:08:41,940] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:08:42,013] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:08:42,049] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:08:42,195] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:08:43,210] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1225000, evaluation results [1225000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:08:43,421] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.5492772e-20 1.0000000e+00 7.6495289e-32 7.9561415e-30 3.3592730e-35], sum to 1.0000
[2019-03-23 23:08:43,429] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6259
[2019-03-23 23:08:43,437] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1860489.701960569 W.
[2019-03-23 23:08:43,443] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.0, 51.0, 1.0, 2.0, 0.5437750773792704, 1.0, 2.0, 0.5437750773792704, 1.0, 1.0, 0.865707632705703, 6.911199999999999, 6.9112, 121.94756008, 1860489.701960569, 1860489.701960569, 365593.5290392677], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6195600.0000, 
sim time next is 6196200.0000, 
raw observation next is [29.88333333333333, 51.83333333333333, 1.0, 2.0, 0.3718119420063728, 1.0, 2.0, 0.3718119420063728, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 855782.5526396761, 855782.5526396766, 198980.7400432968], 
processed observation next is [1.0, 0.7391304347826086, 0.6623456790123455, 0.5183333333333333, 1.0, 1.0, 0.2521570738171105, 1.0, 1.0, 0.2521570738171105, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3056366259427415, 0.30563662594274166, 0.3826552693140323], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.84047204], dtype=float32), 1.3087721]. 
=============================================
[2019-03-23 23:08:55,054] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77000, global step 1230770: loss -127.8711
[2019-03-23 23:08:55,055] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77000, global step 1230770: learning rate 0.0005
[2019-03-23 23:08:55,384] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.4402891e-19 1.0000000e+00 7.0547453e-31 1.9603349e-29 1.0915594e-32], sum to 1.0000
[2019-03-23 23:08:55,391] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9268
[2019-03-23 23:08:55,399] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.96666666666667, 92.0, 1.0, 2.0, 0.7673903160367753, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 874651.6986322526, 874651.6986322526, 189289.1432052994], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6417600.0000, 
sim time next is 6418200.0000, 
raw observation next is [24.98333333333333, 92.0, 1.0, 2.0, 0.7519068241625629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 856994.1470467596, 856994.1470467596, 186198.4594168281], 
processed observation next is [1.0, 0.2608695652173913, 0.4808641975308641, 0.92, 1.0, 1.0, 0.7046509811459083, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3060693382309856, 0.3060693382309856, 0.3580739604169771], 
reward next is 0.6419, 
noisyNet noise sample is [array([-0.19894394], dtype=float32), 0.08046291]. 
=============================================
[2019-03-23 23:08:55,784] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77000, global step 1231118: loss -53.7766
[2019-03-23 23:08:55,788] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77000, global step 1231120: learning rate 0.0005
[2019-03-23 23:08:56,441] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77000, global step 1231428: loss -127.8249
[2019-03-23 23:08:56,443] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77000, global step 1231428: learning rate 0.0005
[2019-03-23 23:08:56,884] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77000, global step 1231643: loss -19.7187
[2019-03-23 23:08:56,886] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77000, global step 1231644: learning rate 0.0005
[2019-03-23 23:08:57,002] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77000, global step 1231696: loss -112.0563
[2019-03-23 23:08:57,004] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77000, global step 1231696: learning rate 0.0005
[2019-03-23 23:08:57,215] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77000, global step 1231802: loss -49.0522
[2019-03-23 23:08:57,216] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77000, global step 1231802: learning rate 0.0005
[2019-03-23 23:08:57,477] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77000, global step 1231926: loss -1.3079
[2019-03-23 23:08:57,477] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77000, global step 1231926: learning rate 0.0005
[2019-03-23 23:08:57,622] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77000, global step 1232000: loss -7.0175
[2019-03-23 23:08:57,623] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77000, global step 1232000: learning rate 0.0005
[2019-03-23 23:08:57,625] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77000, global step 1232000: loss -8.8242
[2019-03-23 23:08:57,628] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77000, global step 1232000: learning rate 0.0005
[2019-03-23 23:08:57,646] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77000, global step 1232009: loss -1.2740
[2019-03-23 23:08:57,647] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77000, global step 1232009: learning rate 0.0005
[2019-03-23 23:08:58,184] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77000, global step 1232266: loss -16.4479
[2019-03-23 23:08:58,186] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77000, global step 1232267: learning rate 0.0005
[2019-03-23 23:08:58,667] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77000, global step 1232503: loss -18.1118
[2019-03-23 23:08:58,670] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77000, global step 1232504: learning rate 0.0005
[2019-03-23 23:08:58,940] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77000, global step 1232635: loss -9.6423
[2019-03-23 23:08:58,943] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77000, global step 1232635: learning rate 0.0005
[2019-03-23 23:08:59,315] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77000, global step 1232815: loss -21.1065
[2019-03-23 23:08:59,319] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77000, global step 1232815: learning rate 0.0005
[2019-03-23 23:08:59,361] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77000, global step 1232838: loss -18.3721
[2019-03-23 23:08:59,362] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77000, global step 1232838: learning rate 0.0005
[2019-03-23 23:08:59,471] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.3476717e-15 1.0000000e+00 1.0995959e-25 2.5499288e-23 9.6539338e-28], sum to 1.0000
[2019-03-23 23:08:59,481] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1770
[2019-03-23 23:08:59,485] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666666, 83.16666666666667, 1.0, 2.0, 0.9739884014571341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.984405909112009, 6.9112, 121.9257347976941, 1147812.503590368, 1110324.629698305, 234506.4678684995], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6491400.0000, 
sim time next is 6492000.0000, 
raw observation next is [26.63333333333333, 83.33333333333334, 1.0, 2.0, 0.9235599935692981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9259985322894, 1052772.139143684, 1052772.139143683, 222787.6358696897], 
processed observation next is [1.0, 0.13043478260869565, 0.5419753086419752, 0.8333333333333335, 1.0, 1.0, 0.9089999923444024, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094618361523866, 0.3759900496941728, 0.3759900496941725, 0.4284377612878648], 
reward next is 0.5716, 
noisyNet noise sample is [array([1.4422275], dtype=float32), 0.010283441]. 
=============================================
[2019-03-23 23:08:59,508] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[49.304443]
 [49.304443]
 [49.304443]
 [49.304443]
 [49.304443]], R is [[49.38295746]
 [49.07212448]
 [49.15733337]
 [49.2308197 ]
 [49.24340057]].
[2019-03-23 23:08:59,798] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77000, global step 1233048: loss -59.6791
[2019-03-23 23:08:59,801] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77000, global step 1233049: learning rate 0.0005
[2019-03-23 23:09:00,932] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.6389375e-15 1.0000000e+00 4.5760626e-24 3.3942015e-23 5.2867375e-26], sum to 1.0000
[2019-03-23 23:09:00,941] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4909
[2019-03-23 23:09:00,946] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1772109.365325985 W.
[2019-03-23 23:09:00,952] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.56666666666667, 79.16666666666667, 1.0, 2.0, 0.5179692876453726, 1.0, 2.0, 0.5179692876453726, 1.0, 1.0, 0.82462397501344, 6.911200000000001, 6.9112, 121.94756008, 1772109.365325985, 1772109.365325985, 352496.1267679709], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6537000.0000, 
sim time next is 6537600.0000, 
raw observation next is [27.6, 79.0, 1.0, 2.0, 0.9507197568210164, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1798983.617271424, 1798983.617271424, 368144.5170192251], 
processed observation next is [1.0, 0.6956521739130435, 0.5777777777777778, 0.79, 1.0, 1.0, 0.9413330438345433, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6424941490255086, 0.6424941490255086, 0.7079702250369714], 
reward next is 0.2920, 
noisyNet noise sample is [array([0.14604682], dtype=float32), 0.6494015]. 
=============================================
[2019-03-23 23:09:07,911] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.5377701e-24 1.0000000e+00 5.9203381e-36 5.9937686e-33 1.3320868e-38], sum to 1.0000
[2019-03-23 23:09:07,919] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9046
[2019-03-23 23:09:07,923] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.96666666666667, 40.66666666666667, 1.0, 2.0, 0.2945039095279153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 378151.605491173, 378151.6054911735, 114897.5278575214], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6648000.0000, 
sim time next is 6648600.0000, 
raw observation next is [24.98333333333333, 39.33333333333334, 1.0, 2.0, 0.2929240571645119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 376875.9549859988, 376875.9549859988, 114699.8914020964], 
processed observation next is [1.0, 0.9565217391304348, 0.4808641975308641, 0.3933333333333334, 1.0, 1.0, 0.1582429251958475, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13459855535214243, 0.13459855535214243, 0.22057671423480077], 
reward next is 0.7794, 
noisyNet noise sample is [array([-0.02717761], dtype=float32), 0.029918704]. 
=============================================
[2019-03-23 23:09:11,330] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.0379005e-22 1.0000000e+00 1.3335830e-36 9.6305846e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 23:09:11,339] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4206
[2019-03-23 23:09:11,346] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.15, 48.5, 1.0, 2.0, 0.3303662240398308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 417991.9391431009, 417991.9391431009, 119385.9950891192], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6726600.0000, 
sim time next is 6727200.0000, 
raw observation next is [24.86666666666667, 50.0, 1.0, 2.0, 0.3311351454490649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 418882.9389094019, 418882.9389094014, 119484.322363319], 
processed observation next is [1.0, 0.8695652173913043, 0.47654320987654336, 0.5, 1.0, 1.0, 0.20373231601079156, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14960104961050066, 0.1496010496105005, 0.2297775430063827], 
reward next is 0.7702, 
noisyNet noise sample is [array([0.11204758], dtype=float32), -0.07245139]. 
=============================================
[2019-03-23 23:09:11,362] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77500, global step 1238668: loss 0.0226
[2019-03-23 23:09:11,364] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77500, global step 1238669: learning rate 0.0005
[2019-03-23 23:09:11,908] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77500, global step 1238931: loss 0.0038
[2019-03-23 23:09:11,910] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77500, global step 1238932: learning rate 0.0005
[2019-03-23 23:09:12,409] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.1969716e-24 1.0000000e+00 2.6979018e-36 1.4470525e-32 1.4152645e-38], sum to 1.0000
[2019-03-23 23:09:12,424] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3762
[2019-03-23 23:09:12,428] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.95, 30.66666666666667, 1.0, 2.0, 0.5519914371912241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 700956.751567791, 700956.751567791, 152357.8970843423], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6700200.0000, 
sim time next is 6700800.0000, 
raw observation next is [29.1, 30.33333333333334, 1.0, 2.0, 0.7182078652995748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 911614.2323371973, 911614.2323371973, 182822.4206928058], 
processed observation next is [1.0, 0.5652173913043478, 0.6333333333333334, 0.3033333333333334, 1.0, 1.0, 0.6645331729756843, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.325576511548999, 0.325576511548999, 0.35158157825539577], 
reward next is 0.6484, 
noisyNet noise sample is [array([0.1741195], dtype=float32), -0.07687314]. 
=============================================
[2019-03-23 23:09:12,604] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.8458046e-22 1.0000000e+00 1.9707058e-35 2.8095900e-31 5.0488834e-38], sum to 1.0000
[2019-03-23 23:09:12,610] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7119
[2019-03-23 23:09:12,615] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.25, 30.0, 1.0, 2.0, 0.799248928766363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1013766.533953812, 1013766.533953812, 199457.2715527619], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6701400.0000, 
sim time next is 6702000.0000, 
raw observation next is [29.4, 29.66666666666666, 1.0, 2.0, 0.7659171741592848, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 970971.5326083654, 970971.5326083654, 192466.1139447954], 
processed observation next is [1.0, 0.5652173913043478, 0.6444444444444444, 0.29666666666666663, 1.0, 1.0, 0.7213299692372438, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3467755473601305, 0.3467755473601305, 0.3701271422015296], 
reward next is 0.6299, 
noisyNet noise sample is [array([1.3330575], dtype=float32), -0.79726344]. 
=============================================
[2019-03-23 23:09:12,628] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[75.49893]
 [75.49893]
 [75.49893]
 [75.49893]
 [75.49893]], R is [[75.37382507]
 [75.23651123]
 [75.13256836]
 [75.08824158]
 [75.01311493]].
[2019-03-23 23:09:12,949] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77500, global step 1239438: loss 0.0184
[2019-03-23 23:09:12,956] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77500, global step 1239439: learning rate 0.0005
[2019-03-23 23:09:13,302] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77500, global step 1239609: loss 0.0003
[2019-03-23 23:09:13,307] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77500, global step 1239610: learning rate 0.0005
[2019-03-23 23:09:13,540] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77500, global step 1239729: loss 0.0050
[2019-03-23 23:09:13,549] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77500, global step 1239729: learning rate 0.0005
[2019-03-23 23:09:13,649] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77500, global step 1239782: loss 0.0006
[2019-03-23 23:09:13,652] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77500, global step 1239783: learning rate 0.0005
[2019-03-23 23:09:13,716] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77500, global step 1239811: loss 0.0001
[2019-03-23 23:09:13,720] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77500, global step 1239811: learning rate 0.0005
[2019-03-23 23:09:13,726] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77500, global step 1239816: loss 0.0003
[2019-03-23 23:09:13,727] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77500, global step 1239817: learning rate 0.0005
[2019-03-23 23:09:13,869] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77500, global step 1239885: loss 0.0020
[2019-03-23 23:09:13,872] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77500, global step 1239885: learning rate 0.0005
[2019-03-23 23:09:14,071] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77500, global step 1239988: loss 0.0320
[2019-03-23 23:09:14,072] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77500, global step 1239988: learning rate 0.0005
[2019-03-23 23:09:14,446] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77500, global step 1240164: loss 0.0033
[2019-03-23 23:09:14,451] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77500, global step 1240166: learning rate 0.0005
[2019-03-23 23:09:14,799] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.72602016e-21 1.00000000e+00 7.80218029e-34 4.28710284e-32
 1.16549526e-35], sum to 1.0000
[2019-03-23 23:09:14,809] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0625
[2019-03-23 23:09:14,813] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.43333333333334, 47.0, 1.0, 2.0, 0.330255976534747, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 417965.4919039343, 417965.4919039347, 119372.9297596885], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6726000.0000, 
sim time next is 6726600.0000, 
raw observation next is [25.15, 48.5, 1.0, 2.0, 0.3303662240398308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 417991.9391431009, 417991.9391431009, 119385.9950891192], 
processed observation next is [1.0, 0.8695652173913043, 0.487037037037037, 0.485, 1.0, 1.0, 0.20281693338075094, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14928283540825033, 0.14928283540825033, 0.22958845209446], 
reward next is 0.7704, 
noisyNet noise sample is [array([1.6896267], dtype=float32), -1.1993592]. 
=============================================
[2019-03-23 23:09:15,338] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77500, global step 1240577: loss 0.0028
[2019-03-23 23:09:15,342] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77500, global step 1240577: learning rate 0.0005
[2019-03-23 23:09:15,504] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77500, global step 1240645: loss 0.0309
[2019-03-23 23:09:15,509] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77500, global step 1240645: learning rate 0.0005
[2019-03-23 23:09:15,611] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77500, global step 1240692: loss 0.0489
[2019-03-23 23:09:15,613] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77500, global step 1240693: learning rate 0.0005
[2019-03-23 23:09:15,952] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77500, global step 1240833: loss 0.0454
[2019-03-23 23:09:15,958] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77500, global step 1240833: learning rate 0.0005
[2019-03-23 23:09:16,176] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.1804376e-24 1.0000000e+00 2.9839821e-36 1.7511055e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 23:09:16,183] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4833
[2019-03-23 23:09:16,191] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1425886.864168249 W.
[2019-03-23 23:09:16,195] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.0, 54.0, 1.0, 2.0, 0.6014101286614584, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9652467126315065, 6.911200000000001, 6.9112, 121.9260425035009, 1425886.864168249, 1425886.864168249, 293193.6685812515], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6796800.0000, 
sim time next is 6797400.0000, 
raw observation next is [28.01666666666667, 54.33333333333333, 1.0, 2.0, 0.6025112909501215, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9665543682261483, 6.911199999999999, 6.9112, 121.9260426156276, 1426776.827445705, 1426776.827445706, 293678.6226111821], 
processed observation next is [1.0, 0.6956521739130435, 0.59320987654321, 0.5433333333333333, 1.0, 1.0, 0.5267991558930017, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9581929602826852, -8.881784197001253e-17, 0.0, 0.8094621288199089, 0.5095631526591804, 0.5095631526591807, 0.564766581944581], 
reward next is 0.4352, 
noisyNet noise sample is [array([-0.8200569], dtype=float32), 1.0823817]. 
=============================================
[2019-03-23 23:09:16,241] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.4591707e-21 1.0000000e+00 6.4896655e-33 3.0820639e-29 1.3392577e-35], sum to 1.0000
[2019-03-23 23:09:16,248] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2762
[2019-03-23 23:09:16,251] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.91666666666667, 70.5, 1.0, 2.0, 0.4736603800482272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 571994.1332378, 571994.1332378, 139063.3306343231], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6811800.0000, 
sim time next is 6812400.0000, 
raw observation next is [24.83333333333334, 71.0, 1.0, 2.0, 0.4709304248750881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 568734.9801102615, 568734.9801102615, 138647.4482764785], 
processed observation next is [1.0, 0.8695652173913043, 0.47530864197530887, 0.71, 1.0, 1.0, 0.37015526770843826, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20311963575366482, 0.20311963575366482, 0.2666297082239971], 
reward next is 0.7334, 
noisyNet noise sample is [array([0.53646296], dtype=float32), -1.1805521]. 
=============================================
[2019-03-23 23:09:16,491] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77500, global step 1241104: loss 0.0180
[2019-03-23 23:09:16,494] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77500, global step 1241105: learning rate 0.0005
[2019-03-23 23:09:22,622] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.8487121e-21 1.0000000e+00 3.2553867e-34 8.0463028e-30 1.4375141e-37], sum to 1.0000
[2019-03-23 23:09:22,627] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8164
[2019-03-23 23:09:22,631] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 76.66666666666667, 1.0, 2.0, 0.4179585507320256, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 514544.3807063419, 514544.3807063419, 131098.3750461982], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6919800.0000, 
sim time next is 6920400.0000, 
raw observation next is [22.6, 77.33333333333334, 1.0, 2.0, 0.4180130650898232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 514643.9057697994, 514643.9057697994, 131107.0393003242], 
processed observation next is [0.0, 0.08695652173913043, 0.39259259259259266, 0.7733333333333334, 1.0, 1.0, 0.30715841082121814, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18380139491778552, 0.18380139491778552, 0.2521289217313927], 
reward next is 0.7479, 
noisyNet noise sample is [array([0.27102384], dtype=float32), 1.203118]. 
=============================================
[2019-03-23 23:09:23,356] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.9847752e-21 1.0000000e+00 8.0747591e-34 3.0132874e-29 2.0087074e-36], sum to 1.0000
[2019-03-23 23:09:23,364] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4759
[2019-03-23 23:09:23,369] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.1, 46.5, 1.0, 2.0, 0.5378125220888157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 634130.5586927871, 634130.5586927871, 148676.252651802], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6971400.0000, 
sim time next is 6972000.0000, 
raw observation next is [31.13333333333333, 45.66666666666667, 1.0, 2.0, 0.5304304024066674, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 627150.8974876625, 627150.8974876625, 147545.7707461921], 
processed observation next is [0.0, 0.6956521739130435, 0.7086419753086418, 0.4566666666666667, 1.0, 1.0, 0.4409885742936516, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2239824633884509, 0.2239824633884509, 0.28374186681960023], 
reward next is 0.7163, 
noisyNet noise sample is [array([-1.0903174], dtype=float32), -1.4723493]. 
=============================================
[2019-03-23 23:09:23,396] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[69.03362]
 [69.03362]
 [69.03362]
 [69.03362]
 [69.03362]], R is [[69.05953979]
 [69.08302307]
 [69.10377502]
 [69.11927795]
 [69.13618469]].
[2019-03-23 23:09:26,174] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.55570191e-21 1.00000000e+00 5.97816938e-34 5.32126168e-31
 1.31652865e-36], sum to 1.0000
[2019-03-23 23:09:26,182] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0034
[2019-03-23 23:09:26,186] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.66666666666666, 50.0, 1.0, 2.0, 0.5470125664690597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 641367.9207773753, 641367.9207773753, 150035.2416244709], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6961200.0000, 
sim time next is 6961800.0000, 
raw observation next is [30.83333333333334, 49.5, 1.0, 2.0, 0.5517018943095723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 646316.7451461897, 646316.7451461897, 150785.0973729597], 
processed observation next is [0.0, 0.5652173913043478, 0.6975308641975311, 0.495, 1.0, 1.0, 0.466311778939967, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23082740898078202, 0.23082740898078202, 0.2899713411018456], 
reward next is 0.7100, 
noisyNet noise sample is [array([0.86634505], dtype=float32), -0.5525615]. 
=============================================
[2019-03-23 23:09:27,345] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78000, global step 1246692: loss -159.4007
[2019-03-23 23:09:27,346] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78000, global step 1246693: learning rate 0.0005
[2019-03-23 23:09:27,838] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78000, global step 1246944: loss -106.7119
[2019-03-23 23:09:27,841] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78000, global step 1246946: learning rate 0.0005
[2019-03-23 23:09:29,049] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78000, global step 1247559: loss -149.9406
[2019-03-23 23:09:29,050] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78000, global step 1247559: learning rate 0.0005
[2019-03-23 23:09:29,136] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78000, global step 1247608: loss -137.3460
[2019-03-23 23:09:29,140] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78000, global step 1247609: learning rate 0.0005
[2019-03-23 23:09:29,424] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78000, global step 1247759: loss -82.5955
[2019-03-23 23:09:29,425] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78000, global step 1247759: learning rate 0.0005
[2019-03-23 23:09:29,469] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78000, global step 1247777: loss -87.7826
[2019-03-23 23:09:29,471] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78000, global step 1247778: learning rate 0.0005
[2019-03-23 23:09:29,643] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78000, global step 1247871: loss -113.4710
[2019-03-23 23:09:29,646] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78000, global step 1247873: learning rate 0.0005
[2019-03-23 23:09:29,646] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78000, global step 1247873: loss -137.7456
[2019-03-23 23:09:29,650] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78000, global step 1247874: learning rate 0.0005
[2019-03-23 23:09:29,892] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78000, global step 1248000: loss -106.6160
[2019-03-23 23:09:29,894] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78000, global step 1248000: learning rate 0.0005
[2019-03-23 23:09:30,167] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78000, global step 1248147: loss -90.6503
[2019-03-23 23:09:30,168] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78000, global step 1248147: learning rate 0.0005
[2019-03-23 23:09:30,305] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78000, global step 1248220: loss -157.8698
[2019-03-23 23:09:30,306] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78000, global step 1248220: learning rate 0.0005
[2019-03-23 23:09:31,015] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78000, global step 1248585: loss -125.1159
[2019-03-23 23:09:31,016] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78000, global step 1248585: learning rate 0.0005
[2019-03-23 23:09:31,028] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78000, global step 1248592: loss -93.5309
[2019-03-23 23:09:31,030] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78000, global step 1248593: learning rate 0.0005
[2019-03-23 23:09:31,164] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78000, global step 1248659: loss -143.8334
[2019-03-23 23:09:31,167] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78000, global step 1248659: learning rate 0.0005
[2019-03-23 23:09:31,549] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78000, global step 1248854: loss -117.0497
[2019-03-23 23:09:31,552] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78000, global step 1248856: learning rate 0.0005
[2019-03-23 23:09:32,107] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78000, global step 1249140: loss -151.2979
[2019-03-23 23:09:32,110] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78000, global step 1249141: learning rate 0.0005
[2019-03-23 23:09:33,096] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.8619508e-21 1.0000000e+00 1.1026945e-35 3.2597535e-31 1.6008076e-38], sum to 1.0000
[2019-03-23 23:09:33,106] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4128
[2019-03-23 23:09:33,109] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.8, 90.0, 1.0, 2.0, 0.3633496137070789, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 454476.0702652417, 454476.0702652417, 123661.1886045712], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7169400.0000, 
sim time next is 7170000.0000, 
raw observation next is [19.8, 90.33333333333334, 1.0, 2.0, 0.3645360983655273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 455727.6475576625, 455727.6475576625, 123816.8826646867], 
processed observation next is [1.0, 1.0, 0.2888888888888889, 0.9033333333333334, 1.0, 1.0, 0.2434953551970563, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1627598741277366, 0.1627598741277366, 0.2381093897397821], 
reward next is 0.7619, 
noisyNet noise sample is [array([0.3508714], dtype=float32), -0.24622506]. 
=============================================
[2019-03-23 23:09:33,120] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[74.380135]
 [74.380135]
 [74.380135]
 [74.380135]
 [74.380135]], R is [[74.39823914]
 [74.4164505 ]
 [74.4347229 ]
 [74.45301056]
 [74.47123718]].
[2019-03-23 23:09:33,761] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 23:09:33,762] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:09:33,763] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:09:33,765] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:09:33,766] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:09:33,769] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:09:33,768] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:09:33,772] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:09:33,772] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:09:33,773] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:09:33,775] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:09:33,790] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run51
[2019-03-23 23:09:33,815] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run51
[2019-03-23 23:09:33,852] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run51
[2019-03-23 23:09:33,852] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run51
[2019-03-23 23:09:33,853] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run51
[2019-03-23 23:10:24,559] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.09347491]
[2019-03-23 23:10:24,560] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.06666666666667, 91.33333333333334, 1.0, 2.0, 0.5631843827115156, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8966078789115817, 6.9112, 6.9112, 121.9260426156618, 1284148.951633551, 1284148.951633551, 279813.0356583261]
[2019-03-23 23:10:24,560] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:10:24,562] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.2436626e-22 1.0000000e+00 1.7880286e-34 9.4194243e-32 8.9480624e-37], sampled 0.4097032934587854
[2019-03-23 23:10:27,547] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.09347491]
[2019-03-23 23:10:27,547] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.94260048, 63.73256008, 1.0, 2.0, 0.7077141631451067, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1521606.144146202, 1521606.144146202, 318639.0556865502]
[2019-03-23 23:10:27,548] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:10:27,550] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.2436626e-22 1.0000000e+00 1.7880286e-34 9.4194243e-32 8.9480624e-37], sampled 0.8524232508079859
[2019-03-23 23:10:27,550] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1521606.144146202 W.
[2019-03-23 23:10:51,818] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.09347491]
[2019-03-23 23:10:51,819] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.49098133, 74.38992064333334, 1.0, 2.0, 0.6627792689109083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 755359.9712191154, 755359.971219115, 169219.0608175097]
[2019-03-23 23:10:51,820] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:10:51,823] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.2436626e-22 1.0000000e+00 1.7880286e-34 9.4194243e-32 8.9480624e-37], sampled 0.10441591750016066
[2019-03-23 23:11:16,131] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.09347491]
[2019-03-23 23:11:16,132] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.0, 51.0, 1.0, 2.0, 0.9023156385351196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.912398585623446, 6.9112, 121.926005605655, 1097577.556149952, 1096963.773368691, 221156.6583018902]
[2019-03-23 23:11:16,132] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:11:16,134] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.2436626e-22 1.0000000e+00 1.7880286e-34 9.4194243e-32 8.9480624e-37], sampled 0.8539352403186533
[2019-03-23 23:11:16,547] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:11:16,854] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:11:16,895] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:11:16,899] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:11:17,082] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:11:18,100] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1250000, evaluation results [1250000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:11:20,697] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.8452424e-24 1.0000000e+00 3.7941871e-36 1.1100307e-33 5.2491665e-38], sum to 1.0000
[2019-03-23 23:11:20,705] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0515
[2019-03-23 23:11:20,708] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 70.0, 1.0, 2.0, 0.9104025113345059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.013970848005199, 6.9112, 121.9254960668614, 1168438.414953316, 1115810.791131484, 223317.8306560465], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7228800.0000, 
sim time next is 7229400.0000, 
raw observation next is [23.88333333333333, 70.0, 1.0, 2.0, 0.8164621854851783, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9259807183608, 1001232.559248538, 1001232.559248538, 202413.8065288546], 
processed observation next is [1.0, 0.6956521739130435, 0.4401234567901233, 0.7, 1.0, 1.0, 0.7815026017680694, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.809461717886426, 0.35758305687447783, 0.35758305687447783, 0.3892573202477973], 
reward next is 0.6107, 
noisyNet noise sample is [array([0.18569396], dtype=float32), -0.15994117]. 
=============================================
[2019-03-23 23:11:22,368] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.6261092e-21 1.0000000e+00 8.4633086e-34 1.9172836e-30 2.1193692e-36], sum to 1.0000
[2019-03-23 23:11:22,377] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0805
[2019-03-23 23:11:22,382] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666667, 83.0, 1.0, 2.0, 0.4375654498752282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 543725.5530917026, 543725.5530917031, 134071.0801074638], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7200600.0000, 
sim time next is 7201200.0000, 
raw observation next is [21.33333333333334, 82.0, 1.0, 2.0, 0.5786841511053914, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 718550.3409718336, 718550.3409718331, 156665.0843381659], 
processed observation next is [1.0, 0.34782608695652173, 0.3456790123456792, 0.82, 1.0, 1.0, 0.498433513220704, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.25662512177565483, 0.25662512177565466, 0.3012790083426267], 
reward next is 0.6987, 
noisyNet noise sample is [array([1.0656456], dtype=float32), 0.18132353]. 
=============================================
[2019-03-23 23:11:27,620] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78500, global step 1254637: loss 0.0379
[2019-03-23 23:11:27,622] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78500, global step 1254637: learning rate 0.0005
[2019-03-23 23:11:28,160] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78500, global step 1254902: loss 0.0419
[2019-03-23 23:11:28,167] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78500, global step 1254902: learning rate 0.0005
[2019-03-23 23:11:29,377] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78500, global step 1255502: loss 0.0102
[2019-03-23 23:11:29,379] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78500, global step 1255502: learning rate 0.0005
[2019-03-23 23:11:29,603] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78500, global step 1255601: loss 0.0091
[2019-03-23 23:11:29,606] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78500, global step 1255603: learning rate 0.0005
[2019-03-23 23:11:29,858] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78500, global step 1255736: loss 0.0018
[2019-03-23 23:11:29,860] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78500, global step 1255736: learning rate 0.0005
[2019-03-23 23:11:29,905] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78500, global step 1255753: loss 0.0003
[2019-03-23 23:11:29,909] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78500, global step 1255753: learning rate 0.0005
[2019-03-23 23:11:30,188] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78500, global step 1255883: loss 0.0010
[2019-03-23 23:11:30,192] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78500, global step 1255883: learning rate 0.0005
[2019-03-23 23:11:30,261] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78500, global step 1255912: loss 0.0004
[2019-03-23 23:11:30,263] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78500, global step 1255912: learning rate 0.0005
[2019-03-23 23:11:30,388] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78500, global step 1255969: loss 0.0121
[2019-03-23 23:11:30,389] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78500, global step 1255969: learning rate 0.0005
[2019-03-23 23:11:30,653] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.9031468e-22 1.0000000e+00 3.9159717e-36 7.3481780e-32 1.4602742e-37], sum to 1.0000
[2019-03-23 23:11:30,668] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8159
[2019-03-23 23:11:30,677] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 96.0, 1.0, 2.0, 0.3824758139311042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 475811.9773171494, 475811.977317149, 126218.6865010711], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7362000.0000, 
sim time next is 7362600.0000, 
raw observation next is [19.46666666666667, 96.0, 1.0, 2.0, 0.3998339668052119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 497543.354459396, 497543.3544593956, 128641.4528955546], 
processed observation next is [1.0, 0.21739130434782608, 0.2765432098765433, 0.96, 1.0, 1.0, 0.2855166271490618, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17769405516407, 0.17769405516406986, 0.24738740941452808], 
reward next is 0.7526, 
noisyNet noise sample is [array([-0.1622709], dtype=float32), -1.5265502]. 
=============================================
[2019-03-23 23:11:30,680] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78500, global step 1256110: loss 0.0039
[2019-03-23 23:11:30,681] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78500, global step 1256110: learning rate 0.0005
[2019-03-23 23:11:30,720] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78500, global step 1256132: loss 0.0118
[2019-03-23 23:11:30,722] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78500, global step 1256133: learning rate 0.0005
[2019-03-23 23:11:31,466] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78500, global step 1256492: loss 0.0021
[2019-03-23 23:11:31,468] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78500, global step 1256492: learning rate 0.0005
[2019-03-23 23:11:31,736] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78500, global step 1256619: loss 0.0407
[2019-03-23 23:11:31,737] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78500, global step 1256620: learning rate 0.0005
[2019-03-23 23:11:31,775] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78500, global step 1256637: loss 0.0526
[2019-03-23 23:11:31,777] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78500, global step 1256637: learning rate 0.0005
[2019-03-23 23:11:32,208] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78500, global step 1256848: loss 0.0446
[2019-03-23 23:11:32,212] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78500, global step 1256850: learning rate 0.0005
[2019-03-23 23:11:32,785] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78500, global step 1257127: loss 0.0564
[2019-03-23 23:11:32,787] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78500, global step 1257127: learning rate 0.0005
[2019-03-23 23:11:40,114] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6766980e-23 1.0000000e+00 6.1773761e-35 6.1822385e-33 3.2762849e-38], sum to 1.0000
[2019-03-23 23:11:40,115] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4114
[2019-03-23 23:11:40,119] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 95.66666666666666, 1.0, 2.0, 0.4392070269614659, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 534451.9082490135, 534451.9082490135, 134022.8302729552], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7543200.0000, 
sim time next is 7543800.0000, 
raw observation next is [21.0, 95.5, 1.0, 2.0, 0.4382676199756531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 533478.9480150999, 533478.9480150999, 133889.6634121576], 
processed observation next is [0.0, 0.30434782608695654, 0.3333333333333333, 0.955, 1.0, 1.0, 0.33127097616149176, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19052819571967852, 0.19052819571967852, 0.2574801219464569], 
reward next is 0.7425, 
noisyNet noise sample is [array([0.87573224], dtype=float32), 0.56890434]. 
=============================================
[2019-03-23 23:11:41,491] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.2794830e-23 1.0000000e+00 1.2246985e-36 2.9011625e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 23:11:41,503] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8745
[2019-03-23 23:11:41,506] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.21666666666667, 82.66666666666667, 1.0, 2.0, 0.5075473193232066, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 601638.3601569422, 601638.3601569422, 143945.0093491195], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7555800.0000, 
sim time next is 7556400.0000, 
raw observation next is [24.4, 82.0, 1.0, 2.0, 0.5119955442291906, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 605914.2625093966, 605914.2625093966, 144611.1797825487], 
processed observation next is [0.0, 0.4782608695652174, 0.4592592592592592, 0.82, 1.0, 1.0, 0.41904231455856017, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21639795089621308, 0.21639795089621308, 0.27809842265874746], 
reward next is 0.7219, 
noisyNet noise sample is [array([-0.43240258], dtype=float32), -0.7814983]. 
=============================================
[2019-03-23 23:11:44,239] A3C_AGENT_WORKER-Thread-22 INFO:Local step 79000, global step 1262687: loss -111.1947
[2019-03-23 23:11:44,245] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 79000, global step 1262687: learning rate 0.0005
[2019-03-23 23:11:44,516] A3C_AGENT_WORKER-Thread-21 INFO:Local step 79000, global step 1262825: loss -112.9835
[2019-03-23 23:11:44,523] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 79000, global step 1262826: learning rate 0.0005
[2019-03-23 23:11:45,708] A3C_AGENT_WORKER-Thread-18 INFO:Local step 79000, global step 1263404: loss -111.5336
[2019-03-23 23:11:45,709] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 79000, global step 1263405: learning rate 0.0005
[2019-03-23 23:11:46,344] A3C_AGENT_WORKER-Thread-15 INFO:Local step 79000, global step 1263704: loss -132.7689
[2019-03-23 23:11:46,347] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 79000, global step 1263705: learning rate 0.0005
[2019-03-23 23:11:46,426] A3C_AGENT_WORKER-Thread-12 INFO:Local step 79000, global step 1263746: loss -91.1175
[2019-03-23 23:11:46,428] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 79000, global step 1263746: learning rate 0.0005
[2019-03-23 23:11:46,509] A3C_AGENT_WORKER-Thread-16 INFO:Local step 79000, global step 1263784: loss -106.3834
[2019-03-23 23:11:46,511] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 79000, global step 1263785: learning rate 0.0005
[2019-03-23 23:11:46,598] A3C_AGENT_WORKER-Thread-13 INFO:Local step 79000, global step 1263833: loss -125.1633
[2019-03-23 23:11:46,600] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 79000, global step 1263833: learning rate 0.0005
[2019-03-23 23:11:46,801] A3C_AGENT_WORKER-Thread-11 INFO:Local step 79000, global step 1263925: loss -106.5162
[2019-03-23 23:11:46,803] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 79000, global step 1263925: learning rate 0.0005
[2019-03-23 23:11:47,002] A3C_AGENT_WORKER-Thread-19 INFO:Local step 79000, global step 1264021: loss -124.0766
[2019-03-23 23:11:47,006] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 79000, global step 1264022: learning rate 0.0005
[2019-03-23 23:11:47,113] A3C_AGENT_WORKER-Thread-9 INFO:Local step 79000, global step 1264076: loss -87.8058
[2019-03-23 23:11:47,116] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 79000, global step 1264076: learning rate 0.0005
[2019-03-23 23:11:47,189] A3C_AGENT_WORKER-Thread-10 INFO:Local step 79000, global step 1264112: loss -105.6977
[2019-03-23 23:11:47,191] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 79000, global step 1264112: learning rate 0.0005
[2019-03-23 23:11:47,950] A3C_AGENT_WORKER-Thread-17 INFO:Local step 79000, global step 1264484: loss -132.3478
[2019-03-23 23:11:47,955] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 79000, global step 1264485: learning rate 0.0005
[2019-03-23 23:11:48,239] A3C_AGENT_WORKER-Thread-3 INFO:Local step 79000, global step 1264625: loss -121.1895
[2019-03-23 23:11:48,242] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 79000, global step 1264626: learning rate 0.0005
[2019-03-23 23:11:48,504] A3C_AGENT_WORKER-Thread-14 INFO:Local step 79000, global step 1264752: loss -117.8516
[2019-03-23 23:11:48,509] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 79000, global step 1264754: learning rate 0.0005
[2019-03-23 23:11:48,868] A3C_AGENT_WORKER-Thread-2 INFO:Local step 79000, global step 1264927: loss -129.3730
[2019-03-23 23:11:48,872] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 79000, global step 1264927: learning rate 0.0005
[2019-03-23 23:11:49,319] A3C_AGENT_WORKER-Thread-20 INFO:Local step 79000, global step 1265148: loss -145.9688
[2019-03-23 23:11:49,323] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 79000, global step 1265149: learning rate 0.0005
[2019-03-23 23:11:52,409] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.7782019e-22 1.0000000e+00 2.2040927e-33 5.1492648e-32 1.5489370e-37], sum to 1.0000
[2019-03-23 23:11:52,415] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9890
[2019-03-23 23:11:52,422] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1421823.572350931 W.
[2019-03-23 23:11:52,428] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.0, 48.0, 1.0, 2.0, 0.599182684679054, 1.0, 1.0, 0.599182684679054, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9257548675734, 1421823.572350931, 1421823.572350932, 270274.0055427748], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7738200.0000, 
sim time next is 7738800.0000, 
raw observation next is [29.2, 47.0, 1.0, 2.0, 0.5857028220898514, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9416812898113619, 6.911200000000001, 6.9112, 121.926042527919, 1394329.496003489, 1394329.496003489, 286942.3985811189], 
processed observation next is [1.0, 0.5652173913043478, 0.637037037037037, 0.47, 1.0, 1.0, 0.5067890739164898, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9271016122642023, 8.881784197001253e-17, 0.0, 0.809462128237615, 0.4979748200012461, 0.4979748200012461, 0.5518123049636902], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.7205918], dtype=float32), -0.5957934]. 
=============================================
[2019-03-23 23:11:56,244] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.3631325e-20 1.0000000e+00 3.2009718e-33 1.6279622e-27 4.9542782e-35], sum to 1.0000
[2019-03-23 23:11:56,249] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6820
[2019-03-23 23:11:56,256] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1390658.994441687 W.
[2019-03-23 23:11:56,260] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.13333333333333, 35.0, 1.0, 2.0, 0.3888880991610264, 1.0, 1.0, 0.3888880991610264, 1.0, 2.0, 0.6256554490192826, 6.9112, 6.9112, 121.94756008, 1390658.994441687, 1390658.994441687, 291974.0471608927], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7836000.0000, 
sim time next is 7836600.0000, 
raw observation next is [31.16666666666666, 35.5, 1.0, 2.0, 0.5840462176852884, 1.0, 2.0, 0.5840462176852884, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1398549.428943044, 1398549.428943045, 265524.7591745359], 
processed observation next is [1.0, 0.6956521739130435, 0.7098765432098764, 0.355, 1.0, 1.0, 0.5048169258158195, 1.0, 1.0, 0.5048169258158195, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.49948193890823, 0.49948193890823034, 0.5106245368741076], 
reward next is 0.4894, 
noisyNet noise sample is [array([-0.19119278], dtype=float32), 0.4020235]. 
=============================================
[2019-03-23 23:11:56,266] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.8289494e-22 1.0000000e+00 1.1579892e-33 9.5133128e-32 1.6292168e-35], sum to 1.0000
[2019-03-23 23:11:56,271] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8596
[2019-03-23 23:11:56,281] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1462208.48136466 W.
[2019-03-23 23:11:56,286] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.4, 36.33333333333333, 1.0, 2.0, 0.6168449860899786, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9578220307604821, 6.9112, 6.9112, 121.9260424312685, 1462208.48136466, 1462208.48136466, 291936.2012782842], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7825200.0000, 
sim time next is 7825800.0000, 
raw observation next is [30.5, 36.66666666666667, 1.0, 2.0, 0.6144776717023135, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9580252462758589, 6.911199999999999, 6.9112, 121.9260426156056, 1458801.415238944, 1458801.415238945, 291673.0737197958], 
processed observation next is [1.0, 0.5652173913043478, 0.6851851851851852, 0.3666666666666667, 1.0, 1.0, 0.5410448472646588, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9475315578448237, -8.881784197001253e-17, 0.0, 0.8094621288197628, 0.52100050544248, 0.5210005054424803, 0.5609097571534535], 
reward next is 0.4391, 
noisyNet noise sample is [array([-0.8688741], dtype=float32), -0.21323012]. 
=============================================
[2019-03-23 23:11:57,122] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.7358411e-23 1.0000000e+00 1.4482755e-36 2.3686392e-31 9.1972650e-38], sum to 1.0000
[2019-03-23 23:11:57,130] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2502
[2019-03-23 23:11:57,134] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.71666666666667, 69.66666666666667, 1.0, 2.0, 0.4161286818004857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 512544.1714841527, 512544.1714841527, 130841.7862760398], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7859400.0000, 
sim time next is 7860000.0000, 
raw observation next is [23.63333333333334, 70.33333333333334, 1.0, 2.0, 0.4166806008635534, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 513086.9481972565, 513086.9481972561, 130917.6006172168], 
processed observation next is [1.0, 1.0, 0.43086419753086447, 0.7033333333333335, 1.0, 1.0, 0.3055721438851826, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1832453386418773, 0.18324533864187717, 0.2517646165715708], 
reward next is 0.7482, 
noisyNet noise sample is [array([0.07471281], dtype=float32), -0.4445877]. 
=============================================
[2019-03-23 23:11:57,151] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[72.39908]
 [72.39908]
 [72.39908]
 [72.39908]
 [72.39908]], R is [[72.42332458]
 [72.44747162]
 [72.47109222]
 [72.49340057]
 [72.51465607]].
[2019-03-23 23:11:58,090] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.0789252e-22 1.0000000e+00 1.1326843e-33 2.3907138e-33 8.4932112e-37], sum to 1.0000
[2019-03-23 23:11:58,097] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9038
[2019-03-23 23:11:58,101] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 76.0, 1.0, 2.0, 0.4153880631689108, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 511336.2905224634, 511336.2905224634, 130728.0005699351], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7866000.0000, 
sim time next is 7866600.0000, 
raw observation next is [22.71666666666667, 76.66666666666667, 1.0, 2.0, 0.4167307781239784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 512945.9155069785, 512945.9155069781, 130919.6584637046], 
processed observation next is [1.0, 0.043478260869565216, 0.39691358024691364, 0.7666666666666667, 1.0, 1.0, 0.30563187871902187, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1831949698239209, 0.18319496982392075, 0.2517685739686627], 
reward next is 0.7482, 
noisyNet noise sample is [array([-0.33709073], dtype=float32), -0.59490573]. 
=============================================
[2019-03-23 23:12:00,742] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:12:00,742] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:12:00,774] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run7
[2019-03-23 23:12:01,488] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:12:01,490] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:12:01,525] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run7
[2019-03-23 23:12:01,689] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.417777e-23 1.000000e+00 5.145372e-34 5.996173e-32 6.629857e-36], sum to 1.0000
[2019-03-23 23:12:01,694] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1659
[2019-03-23 23:12:01,698] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1731714.960537851 W.
[2019-03-23 23:12:01,702] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.1, 49.66666666666667, 1.0, 2.0, 0.7522025669166155, 1.0, 2.0, 0.7522025669166155, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1731714.960537851, 1731714.960537851, 325232.9566600532], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7923000.0000, 
sim time next is 7923600.0000, 
raw observation next is [30.1, 50.0, 1.0, 2.0, 0.8738858274399673, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9837702972266746, 6.9112, 6.9112, 121.9260426156618, 1727124.863583137, 1727124.863583137, 349108.6324229252], 
processed observation next is [1.0, 0.7391304347826086, 0.6703703703703704, 0.5, 1.0, 1.0, 0.8498640802856754, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9797128715333433, 0.0, 0.0, 0.8094621288201359, 0.6168303084225489, 0.6168303084225489, 0.6713627546594716], 
reward next is 0.3286, 
noisyNet noise sample is [array([-1.0237955], dtype=float32), 0.36853707]. 
=============================================
[2019-03-23 23:12:01,936] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:12:01,936] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:12:01,957] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run7
[2019-03-23 23:12:02,596] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:12:02,597] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:12:02,601] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run7
[2019-03-23 23:12:02,656] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:12:02,656] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:12:02,661] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run7
[2019-03-23 23:12:02,738] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:12:02,738] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:12:02,742] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run7
[2019-03-23 23:12:02,825] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:12:02,825] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:12:02,830] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run7
[2019-03-23 23:12:02,957] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:12:02,957] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:12:02,960] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run7
[2019-03-23 23:12:03,045] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:12:03,045] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:12:03,049] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run7
[2019-03-23 23:12:03,101] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:12:03,102] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:12:03,106] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run7
[2019-03-23 23:12:03,142] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:12:03,142] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:12:03,149] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run7
[2019-03-23 23:12:03,301] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:12:03,302] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:12:03,305] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run7
[2019-03-23 23:12:03,432] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:12:03,432] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:12:03,436] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run7
[2019-03-23 23:12:03,509] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:12:03,510] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:12:03,513] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run7
[2019-03-23 23:12:03,544] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:12:03,545] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:12:03,548] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run7
[2019-03-23 23:12:03,609] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:12:03,610] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:12:03,612] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run7
[2019-03-23 23:12:06,230] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.2297424e-22 1.0000000e+00 3.2947403e-34 2.8550513e-33 3.1398195e-37], sum to 1.0000
[2019-03-23 23:12:06,239] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6397
[2019-03-23 23:12:06,243] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 43.0, 1.0, 2.0, 0.7296137977052874, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 929037.9418627211, 929037.9418627211, 185115.7140266729], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 36000.0000, 
sim time next is 36600.0000, 
raw observation next is [25.73333333333333, 42.66666666666667, 1.0, 2.0, 0.7346850497808546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 934249.3013005974, 934249.3013005974, 186125.0279047625], 
processed observation next is [1.0, 0.43478260869565216, 0.5086419753086419, 0.4266666666666667, 1.0, 1.0, 0.6841488687867316, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3336604647502133, 0.3336604647502133, 0.35793274597069713], 
reward next is 0.6421, 
noisyNet noise sample is [array([-1.3492696], dtype=float32), -1.30492]. 
=============================================
[2019-03-23 23:12:10,144] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 23:12:10,145] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:12:10,145] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:12:10,145] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:12:10,147] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:12:10,149] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:12:10,150] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:12:10,150] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:12:10,148] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:12:10,152] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:12:10,155] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:12:10,171] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run52
[2019-03-23 23:12:10,197] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run52
[2019-03-23 23:12:10,219] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run52
[2019-03-23 23:12:10,243] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run52
[2019-03-23 23:12:10,264] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run52
[2019-03-23 23:12:54,528] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.11647002]
[2019-03-23 23:12:54,529] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.65686334166667, 92.98521902499999, 1.0, 2.0, 0.429773958488088, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 526750.5405272825, 526750.5405272825, 132748.4923980475]
[2019-03-23 23:12:54,531] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:12:54,535] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.1846796e-22 1.0000000e+00 8.7128927e-35 4.9339736e-32 4.1841248e-37], sampled 0.6011612903941703
[2019-03-23 23:13:24,045] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.11647002]
[2019-03-23 23:13:24,045] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [34.66666666666667, 32.66666666666667, 1.0, 2.0, 0.5001116454866852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 593987.7023237791, 593987.7023237791, 142818.6382774364]
[2019-03-23 23:13:24,046] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:13:24,048] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.1846796e-22 1.0000000e+00 8.7128927e-35 4.9339736e-32 4.1841248e-37], sampled 0.09428164042910747
[2019-03-23 23:13:31,319] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.11647002]
[2019-03-23 23:13:31,319] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.01116756666666, 51.23831201, 1.0, 2.0, 0.6127324752270995, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 707625.2212589693, 707625.2212589693, 160734.109075215]
[2019-03-23 23:13:31,321] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:13:31,326] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.1846796e-22 1.0000000e+00 8.7128927e-35 4.9339736e-32 4.1841248e-37], sampled 0.8774527881566537
[2019-03-23 23:13:40,852] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.11647002]
[2019-03-23 23:13:40,854] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.00568512666667, 75.44377256333334, 1.0, 2.0, 0.5231676631404002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 622192.5080296583, 622192.5080296583, 146514.6121666709]
[2019-03-23 23:13:40,855] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:13:40,859] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.1846796e-22 1.0000000e+00 8.7128927e-35 4.9339736e-32 4.1841248e-37], sampled 0.7605934214803147
[2019-03-23 23:13:52,779] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:13:52,886] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:13:53,027] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:13:53,253] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:13:53,498] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:13:54,514] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1275000, evaluation results [1275000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:14:13,564] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.495671e-22 1.000000e+00 5.813344e-35 3.711760e-34 1.228225e-38], sum to 1.0000
[2019-03-23 23:14:13,571] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2064
[2019-03-23 23:14:13,581] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1493792.215174528 W.
[2019-03-23 23:14:13,584] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.5, 36.5, 1.0, 2.0, 0.9695880534212987, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.480342219711843, 6.9112, 121.9236722287714, 1493792.215174528, 1202346.195494179, 237714.4505956924], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 473400.0000, 
sim time next is 474000.0000, 
raw observation next is [29.66666666666667, 36.0, 1.0, 2.0, 0.3269397771821476, 1.0, 1.0, 0.3269397771821476, 1.0, 1.0, 0.5316311977873902, 6.911200000000001, 6.9112, 121.94756008, 1190143.460988496, 1190143.460988495, 265615.6929641197], 
processed observation next is [1.0, 0.4782608695652174, 0.6543209876543211, 0.36, 1.0, 1.0, 0.19873782997874717, 1.0, 0.5, 0.19873782997874717, 1.0, 0.5, 0.4145389972342377, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.42505123606732, 0.42505123606731965, 0.510799409546384], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.702016], dtype=float32), 0.47716603]. 
=============================================
[2019-03-23 23:14:13,605] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[75.90954]
 [75.90954]
 [75.90954]
 [75.90954]
 [75.90954]], R is [[75.1504364 ]
 [74.39893341]
 [74.1545639 ]
 [73.90488434]
 [73.16583252]].
[2019-03-23 23:14:21,406] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.1559931e-20 1.0000000e+00 1.6693000e-32 2.1167992e-29 1.5718927e-33], sum to 1.0000
[2019-03-23 23:14:21,412] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7360
[2019-03-23 23:14:21,415] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.83333333333334, 47.0, 1.0, 2.0, 0.3441363848035106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 433816.990072306, 433816.990072306, 121159.579580239], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 602400.0000, 
sim time next is 603000.0000, 
raw observation next is [25.7, 47.5, 1.0, 2.0, 0.3434800554580031, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 433108.3270807973, 433108.3270807973, 121074.9399081314], 
processed observation next is [1.0, 1.0, 0.5074074074074074, 0.475, 1.0, 1.0, 0.21842863745000368, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15468154538599904, 0.15468154538599904, 0.2328364229002527], 
reward next is 0.7672, 
noisyNet noise sample is [array([-2.1726165], dtype=float32), -1.061907]. 
=============================================
[2019-03-23 23:14:21,429] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[67.38198]
 [67.38198]
 [67.38198]
 [67.38198]
 [67.38198]], R is [[67.47533417]
 [67.56758118]
 [67.65856171]
 [67.74815369]
 [67.83609772]].
[2019-03-23 23:14:21,505] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.6016630e-21 1.0000000e+00 4.4836681e-32 1.1018053e-31 2.5075091e-35], sum to 1.0000
[2019-03-23 23:14:21,512] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6874
[2019-03-23 23:14:21,514] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.76666666666667, 39.0, 1.0, 2.0, 0.3734649133279522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 465675.0894467799, 465675.0894467795, 125004.860758211], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 592800.0000, 
sim time next is 593400.0000, 
raw observation next is [28.58333333333333, 39.5, 1.0, 2.0, 0.3718707479841937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 463953.7039064373, 463953.7039064369, 124792.8613908357], 
processed observation next is [1.0, 0.8695652173913043, 0.6141975308641974, 0.395, 1.0, 1.0, 0.2522270809335639, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1656977513951562, 0.16569775139515605, 0.23998627190545327], 
reward next is 0.7600, 
noisyNet noise sample is [array([0.26337782], dtype=float32), 0.73699]. 
=============================================
[2019-03-23 23:14:22,407] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.3629414e-22 1.0000000e+00 1.2940922e-36 5.7390948e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 23:14:22,414] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9991
[2019-03-23 23:14:22,419] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.43333333333333, 67.0, 1.0, 2.0, 0.3235004227071513, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 411387.6961089171, 411387.6961089171, 118522.2574463436], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 625200.0000, 
sim time next is 625800.0000, 
raw observation next is [21.71666666666667, 66.0, 1.0, 2.0, 0.3259983066991414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 414029.3941627031, 414029.3941627031, 118838.3386751046], 
processed observation next is [1.0, 0.21739130434782608, 0.3598765432098766, 0.66, 1.0, 1.0, 0.19761703178469217, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14786764077239395, 0.14786764077239395, 0.22853526668289348], 
reward next is 0.7715, 
noisyNet noise sample is [array([1.7911503], dtype=float32), -1.457866]. 
=============================================
[2019-03-23 23:14:22,601] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.5625311e-22 1.0000000e+00 1.4605207e-35 9.1143077e-32 4.0320827e-38], sum to 1.0000
[2019-03-23 23:14:22,608] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8542
[2019-03-23 23:14:22,612] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.86666666666667, 69.0, 1.0, 2.0, 0.3230788798158899, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 411906.1307011053, 411906.1307011053, 118473.597007768], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 624000.0000, 
sim time next is 624600.0000, 
raw observation next is [21.15, 68.0, 1.0, 2.0, 0.3229368530072219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 411200.3109799944, 411200.310979994, 118453.2016037369], 
processed observation next is [1.0, 0.21739130434782608, 0.33888888888888885, 0.68, 1.0, 1.0, 0.19397244405621655, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14685725392142657, 0.14685725392142643, 0.2277946184687248], 
reward next is 0.7722, 
noisyNet noise sample is [array([1.5194709], dtype=float32), 0.4610279]. 
=============================================
[2019-03-23 23:14:23,648] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.9621490e-19 1.0000000e+00 3.5541601e-32 9.8717506e-29 2.3778428e-34], sum to 1.0000
[2019-03-23 23:14:23,655] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7025
[2019-03-23 23:14:23,663] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1658842.366801877 W.
[2019-03-23 23:14:23,666] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [35.7, 19.16666666666667, 1.0, 2.0, 0.6860388184158692, 1.0, 2.0, 0.6860388184158692, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1658842.366801877, 1658842.366801877, 303041.927855383], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 658200.0000, 
sim time next is 658800.0000, 
raw observation next is [35.7, 19.0, 1.0, 2.0, 0.4574426254836713, 1.0, 2.0, 0.4574426254836713, 1.0, 1.0, 0.7380383505572092, 6.911200000000001, 6.9112, 121.94756008, 1645279.567152138, 1645279.567152137, 322807.0088804248], 
processed observation next is [1.0, 0.6521739130434783, 0.8777777777777779, 0.19, 1.0, 1.0, 0.35409836367103725, 1.0, 1.0, 0.35409836367103725, 1.0, 0.5, 0.6725479381965116, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5875998454114779, 0.5875998454114775, 0.6207827093854322], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.6798487], dtype=float32), 0.40705323]. 
=============================================
[2019-03-23 23:14:28,107] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.9467905e-21 1.0000000e+00 4.9672270e-33 5.3869221e-32 9.8691500e-37], sum to 1.0000
[2019-03-23 23:14:28,114] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5655
[2019-03-23 23:14:28,119] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.7, 54.0, 1.0, 2.0, 0.43192076825734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 548479.1884169166, 548479.1884169162, 133414.3542207107], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 715200.0000, 
sim time next is 715800.0000, 
raw observation next is [23.8, 54.0, 1.0, 2.0, 0.4550250399341155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 577216.9097882496, 577216.9097882496, 136854.980187842], 
processed observation next is [1.0, 0.2608695652173913, 0.43703703703703706, 0.54, 1.0, 1.0, 0.35122028563585184, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2061488963529463, 0.2061488963529463, 0.26318265420738846], 
reward next is 0.7368, 
noisyNet noise sample is [array([0.72783864], dtype=float32), 0.33858564]. 
=============================================
[2019-03-23 23:14:29,050] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.5723337e-17 1.0000000e+00 2.7652626e-30 2.8347458e-26 5.3444123e-31], sum to 1.0000
[2019-03-23 23:14:29,059] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8378
[2019-03-23 23:14:29,063] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1365499.60998305 W.
[2019-03-23 23:14:29,069] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.2, 50.16666666666667, 1.0, 2.0, 0.3813199014283781, 1.0, 2.0, 0.3813199014283781, 1.0, 1.0, 0.6138934007674269, 6.911200000000001, 6.9112, 121.94756008, 1365499.60998305, 1365499.609983049, 288676.7270469032], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 731400.0000, 
sim time next is 732000.0000, 
raw observation next is [27.5, 48.33333333333334, 1.0, 2.0, 0.5495962999432458, 1.0, 2.0, 0.5495962999432458, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1323767.654205601, 1323767.654205601, 254154.0302966673], 
processed observation next is [1.0, 0.4782608695652174, 0.5740740740740741, 0.48333333333333345, 1.0, 1.0, 0.46380511898005444, 1.0, 1.0, 0.46380511898005444, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.47277416221628604, 0.47277416221628604, 0.48875775057051407], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5256772], dtype=float32), -0.4683038]. 
=============================================
[2019-03-23 23:14:29,093] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[61.553978]
 [61.553978]
 [61.553978]
 [61.553978]
 [61.553978]], R is [[60.93843079]
 [60.77389908]
 [60.6713028 ]
 [60.06459045]
 [59.46394348]].
[2019-03-23 23:14:29,791] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.5180475e-17 1.0000000e+00 1.6774102e-28 1.3722846e-26 9.1278171e-30], sum to 1.0000
[2019-03-23 23:14:29,797] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3774
[2019-03-23 23:14:29,803] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.1, 23.0, 1.0, 2.0, 0.5043255867802604, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8400432068028577, 6.9112, 6.9112, 121.9260425109708, 1254215.560625536, 1254215.560625536, 254057.8495833714], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 745200.0000, 
sim time next is 745800.0000, 
raw observation next is [32.08333333333334, 23.16666666666667, 1.0, 2.0, 0.9328169208306989, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.330472650226648, 6.9112, 121.9242712550002, 1389239.638153104, 1174537.68634175, 229318.5538134655], 
processed observation next is [1.0, 0.6521739130434783, 0.7438271604938275, 0.23166666666666672, 1.0, 1.0, 0.9200201438460701, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.04192726502266479, 0.0, 0.8094503688274283, 0.4961570136261086, 0.41947774512205355, 0.440997218872049], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3787923], dtype=float32), 0.5193995]. 
=============================================
[2019-03-23 23:14:30,233] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.6397495e-17 1.0000000e+00 3.8378603e-27 2.5545996e-25 9.8979521e-30], sum to 1.0000
[2019-03-23 23:14:30,241] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8344
[2019-03-23 23:14:30,247] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.53333333333333, 32.5, 1.0, 2.0, 0.3343207218575251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 424660.6036284645, 424660.6036284645, 119911.4883518105], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 767400.0000, 
sim time next is 768000.0000, 
raw observation next is [28.36666666666667, 33.0, 1.0, 2.0, 0.3334822983980203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 423683.0843232846, 423683.0843232846, 119803.4527201305], 
processed observation next is [1.0, 0.9130434782608695, 0.606172839506173, 0.33, 1.0, 1.0, 0.20652654571192894, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15131538725831595, 0.15131538725831595, 0.2303912552310202], 
reward next is 0.7696, 
noisyNet noise sample is [array([1.3396895], dtype=float32), -0.33562538]. 
=============================================
[2019-03-23 23:14:30,273] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[57.818443]
 [57.818443]
 [57.818443]
 [57.818443]
 [57.818443]], R is [[58.00986481]
 [58.19916916]
 [58.38638306]
 [58.57141113]
 [58.7542572 ]].
[2019-03-23 23:14:31,290] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.1875528e-20 1.0000000e+00 9.7135268e-34 9.3787551e-34 5.7850663e-37], sum to 1.0000
[2019-03-23 23:14:31,298] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6291
[2019-03-23 23:14:31,305] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.53333333333333, 52.0, 1.0, 2.0, 0.2994788753415976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 382225.6084055145, 382225.6084055145, 115511.3413328044], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 787200.0000, 
sim time next is 787800.0000, 
raw observation next is [23.46666666666667, 52.5, 1.0, 2.0, 0.3001080056689364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 382939.9539687388, 382939.9539687383, 115588.8108777952], 
processed observation next is [0.0, 0.08695652173913043, 0.42469135802469143, 0.525, 1.0, 1.0, 0.16679524484397193, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13676426927454957, 0.1367642692745494, 0.22228617476499077], 
reward next is 0.7777, 
noisyNet noise sample is [array([-1.6768695], dtype=float32), -0.99466574]. 
=============================================
[2019-03-23 23:14:37,147] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.12350845e-20 1.00000000e+00 1.05879120e-32 1.55760454e-31
 3.04699414e-36], sum to 1.0000
[2019-03-23 23:14:37,153] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9106
[2019-03-23 23:14:37,159] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.4, 45.66666666666667, 1.0, 2.0, 0.4235025828481778, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 520428.8997449654, 520428.8997449654, 131874.4930354854], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 918600.0000, 
sim time next is 919200.0000, 
raw observation next is [28.4, 45.33333333333334, 1.0, 2.0, 0.4204080620220236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 517123.7906500443, 517123.7906500443, 131440.1415985631], 
processed observation next is [0.0, 0.6521739130434783, 0.6074074074074074, 0.4533333333333334, 1.0, 1.0, 0.3100095976452662, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18468706808930152, 0.18468706808930152, 0.2527695030741598], 
reward next is 0.7472, 
noisyNet noise sample is [array([0.16603175], dtype=float32), -0.19694407]. 
=============================================
[2019-03-23 23:14:38,837] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2970068e-23 1.0000000e+00 9.5883140e-35 1.9927603e-32 1.7166242e-37], sum to 1.0000
[2019-03-23 23:14:38,844] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9836
[2019-03-23 23:14:38,851] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 60.0, 1.0, 2.0, 0.2897142613062078, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 370488.8197661703, 370488.8197661703, 114315.4104267125], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1040400.0000, 
sim time next is 1041000.0000, 
raw observation next is [21.8, 60.83333333333333, 1.0, 2.0, 0.2914746753599091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 372597.1801059906, 372597.1801059901, 114529.8535325865], 
processed observation next is [1.0, 0.043478260869565216, 0.362962962962963, 0.6083333333333333, 1.0, 1.0, 0.15651747066655847, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13307042146642523, 0.13307042146642503, 0.2202497183318971], 
reward next is 0.7798, 
noisyNet noise sample is [array([0.8492039], dtype=float32), -0.04341182]. 
=============================================
[2019-03-23 23:14:38,869] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[74.96669]
 [74.96669]
 [74.96669]
 [74.96669]
 [74.96669]], R is [[74.99676514]
 [75.02695465]
 [75.05730438]
 [75.08776093]
 [75.11830139]].
[2019-03-23 23:14:44,864] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-23 23:14:44,866] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:14:44,867] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:14:44,867] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:14:44,868] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:14:44,868] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:14:44,869] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:14:44,871] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:14:44,870] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:14:44,869] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:14:44,874] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:14:44,897] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run53
[2019-03-23 23:14:44,898] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run53
[2019-03-23 23:14:44,944] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run53
[2019-03-23 23:14:44,970] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run53
[2019-03-23 23:14:44,996] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run53
[2019-03-23 23:15:05,273] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.1367507]
[2019-03-23 23:15:05,273] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [19.224287755, 78.25210237499999, 1.0, 2.0, 0.3167678804146524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 404130.0848710776, 404130.0848710776, 117671.3786762812]
[2019-03-23 23:15:05,278] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:15:05,279] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.94107808e-23 1.00000000e+00 1.46569389e-36 1.14812765e-33
 0.00000000e+00], sampled 0.17727438901529702
[2019-03-23 23:15:06,454] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.1367507]
[2019-03-23 23:15:06,456] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.6, 88.0, 1.0, 2.0, 0.3909019711394483, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 485215.8248940483, 485215.8248940478, 127364.0136003482]
[2019-03-23 23:15:06,456] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:15:06,458] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.94107808e-23 1.00000000e+00 1.46569389e-36 1.14812765e-33
 0.00000000e+00], sampled 0.9214305034890707
[2019-03-23 23:15:07,070] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.1367507]
[2019-03-23 23:15:07,071] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.538175625, 74.88298642500001, 1.0, 2.0, 0.3644270760463942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 452551.3266504777, 452551.3266504781, 123742.945665357]
[2019-03-23 23:15:07,072] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:15:07,074] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [5.94107808e-23 1.00000000e+00 1.46569389e-36 1.14812765e-33
 0.00000000e+00], sampled 0.7856258119008868
[2019-03-23 23:15:28,049] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.1367507]
[2019-03-23 23:15:28,051] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.83333333333334, 82.0, 1.0, 2.0, 0.7187503118564883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 823292.2579717473, 823292.2579717473, 179929.7705555739]
[2019-03-23 23:15:28,052] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:15:28,054] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.94107808e-23 1.00000000e+00 1.46569389e-36 1.14812765e-33
 0.00000000e+00], sampled 0.37170637840432597
[2019-03-23 23:15:49,919] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.1367507]
[2019-03-23 23:15:49,920] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.75, 95.0, 1.0, 2.0, 0.7200127191547645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 820623.0261661949, 820623.0261661945, 179968.615112035]
[2019-03-23 23:15:49,921] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:15:49,927] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.94107808e-23 1.00000000e+00 1.46569389e-36 1.14812765e-33
 0.00000000e+00], sampled 0.32684097713639193
[2019-03-23 23:16:00,076] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.1367507]
[2019-03-23 23:16:00,077] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.63333333333333, 47.0, 1.0, 2.0, 0.9691670069252366, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.425876803151809, 6.9112, 121.9238874021394, 1455795.924130303, 1192240.058427211, 237335.5556463644]
[2019-03-23 23:16:00,078] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:16:00,082] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.94107808e-23 1.00000000e+00 1.46569389e-36 1.14812765e-33
 0.00000000e+00], sampled 0.20486127540478216
[2019-03-23 23:16:00,083] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1455795.924130303 W.
[2019-03-23 23:16:10,989] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.1367507]
[2019-03-23 23:16:10,990] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.33333333333334, 86.0, 1.0, 2.0, 0.4904385373372158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 585398.5788951815, 585398.5788951815, 141417.2871920604]
[2019-03-23 23:16:10,992] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:16:10,996] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.94107808e-23 1.00000000e+00 1.46569389e-36 1.14812765e-33
 0.00000000e+00], sampled 0.1724889916523853
[2019-03-23 23:16:17,317] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.1367507]
[2019-03-23 23:16:17,318] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.82161701, 76.66348969166665, 1.0, 2.0, 0.5120101794276113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 620959.9069593402, 620959.9069593402, 145148.0985410719]
[2019-03-23 23:16:17,318] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:16:17,323] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.94107808e-23 1.00000000e+00 1.46569389e-36 1.14812765e-33
 0.00000000e+00], sampled 0.42767615779182033
[2019-03-23 23:16:26,546] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.1367507]
[2019-03-23 23:16:26,548] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.23333333333333, 49.66666666666667, 1.0, 2.0, 0.658762660937712, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9703881725874391, 6.9112, 6.9112, 121.9260426156618, 1491838.101750292, 1491838.101750292, 304217.6426748443]
[2019-03-23 23:16:26,549] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:16:26,552] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.94107808e-23 1.00000000e+00 1.46569389e-36 1.14812765e-33
 0.00000000e+00], sampled 0.14712876004435693
[2019-03-23 23:16:26,553] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1491838.101750292 W.
[2019-03-23 23:16:28,315] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:16:28,417] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:16:28,468] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:16:28,695] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:16:28,729] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:16:29,743] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1300000, evaluation results [1300000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:16:32,677] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.3439162e-21 1.0000000e+00 2.2096996e-33 3.4658998e-32 1.1356907e-34], sum to 1.0000
[2019-03-23 23:16:32,684] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9148
[2019-03-23 23:16:32,687] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 40.66666666666667, 1.0, 2.0, 0.776791959183473, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 981438.7932269779, 981438.7932269779, 194685.3053615224], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1088400.0000, 
sim time next is 1089000.0000, 
raw observation next is [26.8, 41.0, 1.0, 2.0, 0.7779900771839103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 982751.892983771, 982751.892983771, 194932.6615835956], 
processed observation next is [1.0, 0.6086956521739131, 0.5481481481481482, 0.41, 1.0, 1.0, 0.7357024728379885, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3509828189227754, 0.3509828189227754, 0.3748705030453761], 
reward next is 0.6251, 
noisyNet noise sample is [array([0.23656693], dtype=float32), -0.37769574]. 
=============================================
[2019-03-23 23:16:32,713] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[69.8704]
 [69.8704]
 [69.8704]
 [69.8704]
 [69.8704]], R is [[69.79682922]
 [69.72446442]
 [69.61521912]
 [69.53074646]
 [69.47699738]].
[2019-03-23 23:16:45,627] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.0018602e-22 1.0000000e+00 1.6163231e-34 1.0183870e-28 4.5482939e-36], sum to 1.0000
[2019-03-23 23:16:45,639] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3435
[2019-03-23 23:16:45,645] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.85, 24.66666666666667, 1.0, 2.0, 0.3846243649464708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 481414.0848991207, 481414.0848991207, 126570.5389104861], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1446600.0000, 
sim time next is 1447200.0000, 
raw observation next is [32.7, 25.0, 1.0, 2.0, 0.3829381785031569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 479411.8104910203, 479411.8104910203, 126339.2833141712], 
processed observation next is [0.0, 0.782608695652174, 0.7666666666666667, 0.25, 1.0, 1.0, 0.2654025934561392, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17121850374679298, 0.17121850374679298, 0.24296016021956002], 
reward next is 0.7570, 
noisyNet noise sample is [array([-1.8527937], dtype=float32), -0.5152209]. 
=============================================
[2019-03-23 23:16:48,028] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.2273261e-22 1.0000000e+00 3.3942697e-36 9.6264071e-32 1.0259943e-36], sum to 1.0000
[2019-03-23 23:16:48,039] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5751
[2019-03-23 23:16:48,044] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.73333333333333, 67.0, 1.0, 2.0, 0.3296840149117203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 417788.4807674947, 417788.4807674947, 119304.3253765155], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1384800.0000, 
sim time next is 1385400.0000, 
raw observation next is [21.66666666666667, 67.0, 1.0, 2.0, 0.3260826101125187, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 413508.0652494192, 413508.0652494187, 118844.0694901745], 
processed observation next is [0.0, 0.0, 0.3580246913580249, 0.67, 1.0, 1.0, 0.1977173929910937, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14768145187479256, 0.1476814518747924, 0.2285462874811048], 
reward next is 0.7715, 
noisyNet noise sample is [array([0.8264678], dtype=float32), 0.8831745]. 
=============================================
[2019-03-23 23:16:48,491] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.9291912e-22 1.0000000e+00 5.1793562e-36 1.5315421e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 23:16:48,500] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6518
[2019-03-23 23:16:48,521] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.73333333333333, 67.0, 1.0, 2.0, 0.3296840149117203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 417788.4807674947, 417788.4807674947, 119304.3253765155], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1384800.0000, 
sim time next is 1385400.0000, 
raw observation next is [21.66666666666667, 67.0, 1.0, 2.0, 0.3260826101125187, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 413508.0652494192, 413508.0652494187, 118844.0694901745], 
processed observation next is [0.0, 0.0, 0.3580246913580249, 0.67, 1.0, 1.0, 0.1977173929910937, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14768145187479256, 0.1476814518747924, 0.2285462874811048], 
reward next is 0.7715, 
noisyNet noise sample is [array([-1.5009022], dtype=float32), -0.42804563]. 
=============================================
[2019-03-23 23:16:51,095] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.0182353e-24 1.0000000e+00 8.6135436e-37 4.3891704e-32 1.5563695e-38], sum to 1.0000
[2019-03-23 23:16:51,104] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8714
[2019-03-23 23:16:51,107] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.5, 25.0, 1.0, 2.0, 0.3762299067940211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 471851.5421017581, 471851.5421017576, 125430.7811247628], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1427400.0000, 
sim time next is 1428000.0000, 
raw observation next is [32.66666666666667, 24.66666666666667, 1.0, 2.0, 0.3778646729726103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 473729.4915889805, 473729.4915889805, 125652.1092241788], 
processed observation next is [0.0, 0.5217391304347826, 0.7654320987654323, 0.2466666666666667, 1.0, 1.0, 0.2593627059197742, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1691891041389216, 0.1691891041389216, 0.24163867158495922], 
reward next is 0.7584, 
noisyNet noise sample is [array([1.5889478], dtype=float32), 0.009759898]. 
=============================================
[2019-03-23 23:16:51,118] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[81.365906]
 [81.365906]
 [81.365906]
 [81.365906]
 [81.365906]], R is [[81.31060791]
 [81.25629425]
 [81.20246887]
 [81.14661407]
 [81.09542847]].
[2019-03-23 23:16:51,475] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.5150558e-19 1.0000000e+00 3.3827576e-33 8.5174421e-31 6.1515089e-35], sum to 1.0000
[2019-03-23 23:16:51,483] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0840
[2019-03-23 23:16:51,487] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.40000000000001, 26.66666666666667, 1.0, 2.0, 0.3629684655944183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 457226.832503281, 457226.832503281, 123659.856803491], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1423200.0000, 
sim time next is 1423800.0000, 
raw observation next is [31.55, 26.5, 1.0, 2.0, 0.364471563955482, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 458767.6832045785, 458767.6832045785, 123857.7040088144], 
processed observation next is [0.0, 0.4782608695652174, 0.7240740740740741, 0.265, 1.0, 1.0, 0.243418528518431, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16384560114449234, 0.16384560114449234, 0.23818789232464307], 
reward next is 0.7618, 
noisyNet noise sample is [array([-1.2017734], dtype=float32), 0.81710994]. 
=============================================
[2019-03-23 23:16:53,506] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.2878111e-21 1.0000000e+00 3.5715140e-33 6.6687078e-31 6.1298179e-35], sum to 1.0000
[2019-03-23 23:16:53,517] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2352
[2019-03-23 23:16:53,527] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.1, 65.5, 1.0, 2.0, 0.3382838226446179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 428217.2636750843, 428217.2636750843, 120414.2985573978], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1481400.0000, 
sim time next is 1482000.0000, 
raw observation next is [22.0, 66.33333333333333, 1.0, 2.0, 0.3388910567155046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 428853.0606733214, 428853.0606733214, 120492.1508044539], 
processed observation next is [0.0, 0.13043478260869565, 0.37037037037037035, 0.6633333333333333, 1.0, 1.0, 0.21296554370893409, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15316180738332907, 0.15316180738332907, 0.2317156746239498], 
reward next is 0.7683, 
noisyNet noise sample is [array([1.4074459], dtype=float32), -1.5014954]. 
=============================================
[2019-03-23 23:16:53,546] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[73.40165]
 [73.40165]
 [73.40165]
 [73.40165]
 [73.40165]], R is [[73.43592072]
 [73.46999359]
 [73.5040741 ]
 [73.53838348]
 [73.57283783]].
[2019-03-23 23:17:00,901] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.1817555e-18 1.0000000e+00 2.9952176e-27 8.9425845e-26 2.0473409e-29], sum to 1.0000
[2019-03-23 23:17:00,910] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4813
[2019-03-23 23:17:00,916] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.85, 45.0, 1.0, 2.0, 0.3609595304438744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 452356.4055650234, 452356.405565023, 123354.7628683854], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1621800.0000, 
sim time next is 1622400.0000, 
raw observation next is [26.73333333333333, 45.33333333333333, 1.0, 2.0, 0.3562276016437708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 446624.3826787751, 446624.3826787751, 122724.9420431741], 
processed observation next is [1.0, 0.782608695652174, 0.545679012345679, 0.4533333333333333, 1.0, 1.0, 0.23360428767115574, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15950870809956255, 0.15950870809956255, 0.23600950392918096], 
reward next is 0.7640, 
noisyNet noise sample is [array([-0.14331985], dtype=float32), 1.5026666]. 
=============================================
[2019-03-23 23:17:03,099] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.9547644e-22 1.0000000e+00 1.3101773e-34 3.4991798e-31 3.7960817e-37], sum to 1.0000
[2019-03-23 23:17:03,106] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1809
[2019-03-23 23:17:03,113] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.96666666666667, 89.66666666666667, 1.0, 2.0, 0.316088738511665, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 403808.666172352, 403808.666172352, 117587.5856517569], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1660800.0000, 
sim time next is 1661400.0000, 
raw observation next is [18.0, 89.5, 1.0, 2.0, 0.3182815786813011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 406560.8769969786, 406560.8769969786, 117865.1850955496], 
processed observation next is [1.0, 0.21739130434782608, 0.2222222222222222, 0.895, 1.0, 1.0, 0.1884304508110727, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14520031321320664, 0.14520031321320664, 0.22666381749144154], 
reward next is 0.7733, 
noisyNet noise sample is [array([1.040569], dtype=float32), 0.15320283]. 
=============================================
[2019-03-23 23:17:17,725] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.7821696e-18 1.0000000e+00 7.7614934e-31 1.4809193e-28 1.1961444e-31], sum to 1.0000
[2019-03-23 23:17:17,731] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3895
[2019-03-23 23:17:17,743] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1392842.484051021 W.
[2019-03-23 23:17:17,748] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.6, 80.0, 1.0, 2.0, 0.9794049090939514, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.335637064001537, 6.9112, 121.9242406215906, 1392842.484051021, 1175495.983826833, 238744.4964863521], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1942800.0000, 
sim time next is 1943400.0000, 
raw observation next is [23.85, 78.5, 1.0, 2.0, 0.3623647374850215, 1.0, 1.0, 0.3623647374850215, 1.0, 1.0, 0.5791577587544446, 6.911199999999999, 6.9112, 121.94756008, 1272422.985870766, 1272422.985870766, 280987.3633214768], 
processed observation next is [1.0, 0.4782608695652174, 0.43888888888888894, 0.785, 1.0, 1.0, 0.24091040176788275, 1.0, 0.5, 0.24091040176788275, 1.0, 0.5, 0.4739471984430558, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.4544367806681307, 0.4544367806681307, 0.540360314079763], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.14193135], dtype=float32), -0.2933373]. 
=============================================
[2019-03-23 23:17:19,557] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.39959567e-19 1.00000000e+00 1.19355935e-32 1.43907818e-29
 2.91153679e-35], sum to 1.0000
[2019-03-23 23:17:19,561] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3444
[2019-03-23 23:17:19,566] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.43333333333333, 87.5, 1.0, 2.0, 0.4363546164499478, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 535014.3736467432, 535014.3736467432, 133717.9234384684], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1980600.0000, 
sim time next is 1981200.0000, 
raw observation next is [21.06666666666667, 88.0, 1.0, 2.0, 0.4247721818055077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 523159.397839162, 523159.397839162, 132088.2990976248], 
processed observation next is [1.0, 0.9565217391304348, 0.3358024691358026, 0.88, 1.0, 1.0, 0.3152049783398901, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18684264208541498, 0.18684264208541498, 0.25401595980312464], 
reward next is 0.7460, 
noisyNet noise sample is [array([0.02649611], dtype=float32), 0.90182436]. 
=============================================
[2019-03-23 23:17:20,125] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 23:17:20,130] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:17:20,131] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:17:20,132] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:17:20,138] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:17:20,135] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:17:20,135] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:17:20,137] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:17:20,140] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:17:20,133] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:17:20,141] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:17:20,162] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run54
[2019-03-23 23:17:20,187] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run54
[2019-03-23 23:17:20,188] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run54
[2019-03-23 23:17:20,189] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run54
[2019-03-23 23:17:20,189] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run54
[2019-03-23 23:17:56,412] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.06870718]
[2019-03-23 23:17:56,412] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.0, 100.0, 1.0, 2.0, 0.5974332000464073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 693282.3425054055, 693282.3425054055, 158231.3977343019]
[2019-03-23 23:17:56,415] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:17:56,419] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.4729075e-21 1.0000000e+00 2.5589672e-34 1.3153121e-31 9.7001440e-37], sampled 0.6981335097292962
[2019-03-23 23:17:59,374] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.06870718]
[2019-03-23 23:17:59,375] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.1, 83.0, 1.0, 2.0, 0.736966153591111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 839956.0207557884, 839956.0207557884, 183264.8712698683]
[2019-03-23 23:17:59,379] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:17:59,383] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.4729075e-21 1.0000000e+00 2.5589672e-34 1.3153121e-31 9.7001440e-37], sampled 0.3348260203140452
[2019-03-23 23:18:05,148] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.06870718]
[2019-03-23 23:18:05,150] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.0, 89.0, 1.0, 2.0, 0.7994509703757866, 1.0, 1.0, 0.7994509703757866, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.925781416599, 1823474.261062113, 1823474.261062113, 343525.8992353008]
[2019-03-23 23:18:05,152] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:18:05,155] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.4729075e-21 1.0000000e+00 2.5589672e-34 1.3153121e-31 9.7001440e-37], sampled 0.6828786636987217
[2019-03-23 23:18:05,155] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1823474.261062113 W.
[2019-03-23 23:18:41,794] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.06870718]
[2019-03-23 23:18:41,795] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.81115971333333, 78.79258125666667, 1.0, 2.0, 0.6744149590215234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 768627.6481484275, 768627.6481484275, 171358.3271583857]
[2019-03-23 23:18:41,797] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:18:41,799] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.4729075e-21 1.0000000e+00 2.5589672e-34 1.3153121e-31 9.7001440e-37], sampled 0.35621542141879226
[2019-03-23 23:18:53,110] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.06870718]
[2019-03-23 23:18:53,111] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.0, 45.33333333333334, 1.0, 2.0, 0.5400425335811171, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8597653014185779, 6.911199999999999, 6.9112, 121.9260426156618, 1231339.486472869, 1231339.486472869, 271256.6050502568]
[2019-03-23 23:18:53,112] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:18:53,118] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.4729075e-21 1.0000000e+00 2.5589672e-34 1.3153121e-31 9.7001440e-37], sampled 0.27124832867546766
[2019-03-23 23:18:58,906] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.06870718]
[2019-03-23 23:18:58,909] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [17.25, 97.5, 1.0, 2.0, 0.2863144856107203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 365280.9668499348, 365280.9668499348, 113900.9852115485]
[2019-03-23 23:18:58,910] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:18:58,917] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.4729075e-21 1.0000000e+00 2.5589672e-34 1.3153121e-31 9.7001440e-37], sampled 0.43370694760006656
[2019-03-23 23:19:03,006] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:19:03,134] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:19:03,365] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:19:03,532] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:19:03,597] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:19:04,613] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1325000, evaluation results [1325000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:19:08,604] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.6580098e-21 1.0000000e+00 2.4813092e-31 1.8853650e-29 8.5851155e-34], sum to 1.0000
[2019-03-23 23:19:08,616] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7699
[2019-03-23 23:19:08,621] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.75, 65.0, 1.0, 2.0, 0.6005102148633794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 688854.058490721, 688854.058490721, 158386.7279439515], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2050200.0000, 
sim time next is 2050800.0000, 
raw observation next is [28.63333333333333, 65.66666666666667, 1.0, 2.0, 0.6013776537253146, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 689753.4332320658, 689753.4332320653, 158531.7395171375], 
processed observation next is [0.0, 0.7391304347826086, 0.6160493827160493, 0.6566666666666667, 1.0, 1.0, 0.5254495877682317, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2463405118685949, 0.24634051186859474, 0.30486872984064906], 
reward next is 0.6951, 
noisyNet noise sample is [array([-0.6257157], dtype=float32), -1.1949387]. 
=============================================
[2019-03-23 23:19:11,376] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.3518672e-22 1.0000000e+00 2.6380832e-34 5.8981432e-33 1.2168285e-36], sum to 1.0000
[2019-03-23 23:19:11,382] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0018
[2019-03-23 23:19:11,389] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.33333333333334, 49.0, 1.0, 2.0, 0.561674513807213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 653718.6226257801, 653718.6226257801, 152255.2257892265], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2130000.0000, 
sim time next is 2130600.0000, 
raw observation next is [31.41666666666666, 48.5, 1.0, 2.0, 0.5596366888288822, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 651761.4318267031, 651761.4318267031, 151934.4379746965], 
processed observation next is [0.0, 0.6521739130434783, 0.7191358024691356, 0.485, 1.0, 1.0, 0.4757579628915264, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23277193993810827, 0.23277193993810827, 0.292181611489801], 
reward next is 0.7078, 
noisyNet noise sample is [array([1.9159548], dtype=float32), -0.23406294]. 
=============================================
[2019-03-23 23:19:21,785] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.9587684e-18 1.0000000e+00 1.7238777e-27 1.5111552e-26 1.0231253e-29], sum to 1.0000
[2019-03-23 23:19:21,790] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5302
[2019-03-23 23:19:21,794] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.6, 70.0, 1.0, 2.0, 0.4982982300322874, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 596105.1368709797, 596105.1368709797, 142692.8257064288], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2311200.0000, 
sim time next is 2311800.0000, 
raw observation next is [25.5, 70.5, 1.0, 2.0, 0.4947689860688292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 592101.8856008622, 592101.8856008617, 142147.8584499753], 
processed observation next is [1.0, 0.782608695652174, 0.5, 0.705, 1.0, 1.0, 0.3985345072247967, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21146495914316507, 0.2114649591431649, 0.2733612662499525], 
reward next is 0.7266, 
noisyNet noise sample is [array([0.79969263], dtype=float32), 0.5679455]. 
=============================================
[2019-03-23 23:19:24,783] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.9266927e-23 1.0000000e+00 3.9579754e-37 7.6884965e-32 4.2697895e-38], sum to 1.0000
[2019-03-23 23:19:24,791] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1968
[2019-03-23 23:19:24,798] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.93333333333333, 92.33333333333334, 1.0, 2.0, 0.4710726088331779, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 568371.08323437, 568371.0832343696, 138651.5816289485], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2334000.0000, 
sim time next is 2334600.0000, 
raw observation next is [21.95, 92.5, 1.0, 2.0, 0.4726371217633156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 569893.5320236493, 569893.5320236493, 138878.3338675227], 
processed observation next is [1.0, 0.0, 0.36851851851851847, 0.925, 1.0, 1.0, 0.37218704971823285, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20353340429416047, 0.20353340429416047, 0.26707371897600524], 
reward next is 0.7329, 
noisyNet noise sample is [array([-0.4210887], dtype=float32), -0.85313433]. 
=============================================
[2019-03-23 23:19:25,326] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.8206094e-20 1.0000000e+00 2.1820499e-32 1.4388963e-30 4.4677170e-34], sum to 1.0000
[2019-03-23 23:19:25,335] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8607
[2019-03-23 23:19:25,340] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 75.0, 1.0, 2.0, 0.4493073575288818, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 548405.7892223023, 548405.7892223023, 135567.7050223666], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2354400.0000, 
sim time next is 2355000.0000, 
raw observation next is [23.83333333333334, 72.0, 1.0, 2.0, 0.4379235201548969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 535642.7369949273, 535642.7369949273, 133913.477242679], 
processed observation next is [1.0, 0.2608695652173913, 0.43827160493827183, 0.72, 1.0, 1.0, 0.33086133351773434, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1913009774981883, 0.1913009774981883, 0.25752591777438266], 
reward next is 0.7425, 
noisyNet noise sample is [array([-0.75572073], dtype=float32), 0.51374865]. 
=============================================
[2019-03-23 23:19:25,357] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[68.90059]
 [68.90059]
 [68.90059]
 [68.90059]
 [68.90059]], R is [[68.95406342]
 [69.00382233]
 [69.04883575]
 [69.09145355]
 [69.13262939]].
[2019-03-23 23:19:27,728] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3070599e-15 1.0000000e+00 3.0254506e-29 5.8548964e-27 4.9279213e-30], sum to 1.0000
[2019-03-23 23:19:27,734] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4337
[2019-03-23 23:19:27,743] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1540009.260457298 W.
[2019-03-23 23:19:27,747] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.86666666666667, 37.0, 1.0, 2.0, 0.4334954853064492, 1.0, 2.0, 0.4334954853064492, 1.0, 1.0, 0.6954328911163563, 6.911200000000001, 6.9112, 121.94756008, 1540009.260457298, 1540009.260457298, 311986.4018387323], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2389200.0000, 
sim time next is 2389800.0000, 
raw observation next is [30.83333333333333, 37.0, 1.0, 2.0, 0.4476194567583159, 1.0, 2.0, 0.4476194567583159, 1.0, 2.0, 0.7170477302083857, 6.911199999999999, 6.9112, 121.94756008, 1583916.345648385, 1583916.345648386, 318569.8777209824], 
processed observation next is [1.0, 0.6521739130434783, 0.6975308641975307, 0.37, 1.0, 1.0, 0.3424041151884713, 1.0, 1.0, 0.3424041151884713, 1.0, 1.0, 0.6463096627604822, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5656844091601375, 0.5656844091601378, 0.6126343802326585], 
reward next is 0.3874, 
noisyNet noise sample is [array([-0.83957994], dtype=float32), 0.52587044]. 
=============================================
[2019-03-23 23:19:29,197] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.4245910e-21 1.0000000e+00 8.7730303e-34 7.0792001e-30 3.6173736e-36], sum to 1.0000
[2019-03-23 23:19:29,206] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1228
[2019-03-23 23:19:29,212] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.36666666666667, 70.33333333333333, 1.0, 2.0, 0.2884685505210189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 368995.9036151796, 368995.9036151801, 114164.0668034857], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2439600.0000, 
sim time next is 2440200.0000, 
raw observation next is [20.93333333333333, 67.66666666666667, 1.0, 2.0, 0.2925352927801934, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 373568.5678165551, 373568.5678165551, 114658.9439767929], 
processed observation next is [1.0, 0.21739130434782608, 0.3308641975308641, 0.6766666666666667, 1.0, 1.0, 0.1577801104526112, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13341734564876967, 0.13341734564876967, 0.2204979691861402], 
reward next is 0.7795, 
noisyNet noise sample is [array([0.55442566], dtype=float32), 0.7330694]. 
=============================================
[2019-03-23 23:19:30,347] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.3236032e-20 1.0000000e+00 2.3160457e-33 1.7261924e-29 2.0176861e-35], sum to 1.0000
[2019-03-23 23:19:30,355] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2888
[2019-03-23 23:19:30,362] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.25, 24.0, 1.0, 2.0, 0.3407086709304328, 1.0, 1.0, 0.3407086709304328, 1.0, 1.0, 0.555739865546793, 6.9112, 6.9112, 121.94756008, 1245314.537341633, 1245314.537341633, 270972.6026324455], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2460600.0000, 
sim time next is 2461200.0000, 
raw observation next is [33.36666666666667, 24.0, 1.0, 2.0, 0.961933500739779, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.422671320215846, 6.9112, 121.9239177339492, 1453559.68036495, 1191645.214254011, 235833.2246808814], 
processed observation next is [1.0, 0.4782608695652174, 0.7913580246913581, 0.24, 1.0, 1.0, 0.9546827389759274, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.05114713202158461, 0.0, 0.8094480218152855, 0.5191284572731965, 0.42558757651928963, 0.45352543207861806], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1735895], dtype=float32), -0.6629109]. 
=============================================
[2019-03-23 23:19:37,221] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.5864943e-20 1.0000000e+00 1.4852160e-32 9.9325233e-30 3.6850951e-34], sum to 1.0000
[2019-03-23 23:19:37,229] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1381
[2019-03-23 23:19:37,237] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.88333333333333, 100.0, 1.0, 2.0, 0.4676693364123399, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 565766.5096172723, 565766.5096172723, 138182.4981439878], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2616600.0000, 
sim time next is 2617200.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4726837860898848, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 570680.1405569023, 570680.1405569023, 138909.7107633163], 
processed observation next is [0.0, 0.30434782608695654, 0.3333333333333333, 1.0, 1.0, 1.0, 0.3722426024879581, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20381433591317938, 0.20381433591317938, 0.26713405916022365], 
reward next is 0.7329, 
noisyNet noise sample is [array([0.79781467], dtype=float32), -0.2218885]. 
=============================================
[2019-03-23 23:19:55,125] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-23 23:19:55,129] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:19:55,133] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:19:55,140] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:19:55,140] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:19:55,152] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run55
[2019-03-23 23:19:55,232] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:19:55,239] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:19:55,250] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run55
[2019-03-23 23:19:55,281] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:19:55,281] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:19:55,293] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:19:55,293] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:19:55,301] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run55
[2019-03-23 23:19:55,342] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run55
[2019-03-23 23:19:55,378] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run55
[2019-03-23 23:20:02,110] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.093694724]
[2019-03-23 23:20:02,111] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [16.0, 93.0, 1.0, 2.0, 0.2395422789706317, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 308986.2130361335, 308986.2130361335, 99754.06212007225]
[2019-03-23 23:20:02,113] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:20:02,116] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.1083943e-16 1.0000000e+00 1.2425540e-26 1.4803350e-24 2.4272011e-28], sampled 0.2995212214483216
[2019-03-23 23:20:04,821] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.093694724]
[2019-03-23 23:20:04,822] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.96666666666667, 53.0, 1.0, 2.0, 0.9297252183566321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.219795232731558, 6.9112, 121.9246808703137, 1312028.088089427, 1154001.511960067, 228235.1665186417]
[2019-03-23 23:20:04,825] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:20:04,828] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.1083943e-16 1.0000000e+00 1.2425540e-26 1.4803350e-24 2.4272011e-28], sampled 0.4428920908952324
[2019-03-23 23:20:04,829] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1312028.088089427 W.
[2019-03-23 23:20:11,901] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.093694724]
[2019-03-23 23:20:11,901] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.66666666666667, 31.83333333333333, 1.0, 2.0, 0.3490006889741903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 439824.0558827563, 439824.0558827563, 121798.8312144327]
[2019-03-23 23:20:11,902] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:20:11,904] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.1083943e-16 1.0000000e+00 1.2425540e-26 1.4803350e-24 2.4272011e-28], sampled 0.23873133368189248
[2019-03-23 23:20:12,011] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.093694724]
[2019-03-23 23:20:12,013] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [31.80187973333334, 38.28114245, 1.0, 2.0, 0.8434540239948951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1019012.588070859, 1019012.588070859, 207747.3429637688]
[2019-03-23 23:20:12,014] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:20:12,019] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.1083943e-16 1.0000000e+00 1.2425540e-26 1.4803350e-24 2.4272011e-28], sampled 0.20576259771130745
[2019-03-23 23:20:16,232] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.093694724]
[2019-03-23 23:20:16,236] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.14799798, 81.96622636666666, 1.0, 2.0, 0.6945716100269986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 851437.6946575685, 851437.6946575685, 177585.7216664285]
[2019-03-23 23:20:16,237] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:20:16,241] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.1083943e-16 1.0000000e+00 1.2425540e-26 1.4803350e-24 2.4272011e-28], sampled 0.6647895636447702
[2019-03-23 23:20:20,336] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.093694724]
[2019-03-23 23:20:20,337] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.61666666666667, 94.5, 1.0, 2.0, 0.4207809699237333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 516439.5341104118, 516439.5341104113, 131464.2659939436]
[2019-03-23 23:20:20,337] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:20:20,339] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.1083943e-16 1.0000000e+00 1.2425540e-26 1.4803350e-24 2.4272011e-28], sampled 0.3408488809021474
[2019-03-23 23:20:42,813] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.093694724]
[2019-03-23 23:20:42,814] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [33.08333333333334, 51.83333333333333, 1.0, 2.0, 0.7032244419857809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 801478.8506220308, 801478.8506220308, 176755.7958413642]
[2019-03-23 23:20:42,817] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:20:42,822] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.1083943e-16 1.0000000e+00 1.2425540e-26 1.4803350e-24 2.4272011e-28], sampled 0.8532814190913012
[2019-03-23 23:21:11,500] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.093694724]
[2019-03-23 23:21:11,501] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.04932041, 67.73959071833333, 1.0, 2.0, 0.519473534052982, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 610147.5583178462, 610147.5583178462, 145617.0345334501]
[2019-03-23 23:21:11,502] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:21:11,505] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.1083943e-16 1.0000000e+00 1.2425540e-26 1.4803350e-24 2.4272011e-28], sampled 0.5341089583442583
[2019-03-23 23:21:29,467] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.093694724]
[2019-03-23 23:21:29,468] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.0, 70.66666666666667, 1.0, 2.0, 0.9281891345575042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.120293292930361, 6.9112, 121.9250653782745, 1242612.529567567, 1135538.933242656, 227386.9185372533]
[2019-03-23 23:21:29,469] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:21:29,471] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.1083943e-16 1.0000000e+00 1.2425540e-26 1.4803350e-24 2.4272011e-28], sampled 0.4026018004645884
[2019-03-23 23:21:38,144] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:21:38,765] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:21:38,822] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:21:38,916] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:21:38,961] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:21:39,976] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1350000, evaluation results [1350000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:21:46,183] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.5398716e-20 1.0000000e+00 2.1856177e-30 2.5362620e-29 3.6195070e-32], sum to 1.0000
[2019-03-23 23:21:46,192] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0151
[2019-03-23 23:21:46,196] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.8, 98.16666666666667, 1.0, 2.0, 0.5101875044030053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 607290.5358897154, 607290.5358897154, 144458.6980109983], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3045000.0000, 
sim time next is 3045600.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4846311793082476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 583048.2446076545, 583048.2446076545, 140678.6613099667], 
processed observation next is [1.0, 0.2608695652173913, 0.3333333333333333, 1.0, 1.0, 1.0, 0.3864656896526757, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20823151593130518, 0.20823151593130518, 0.27053588713455134], 
reward next is 0.7295, 
noisyNet noise sample is [array([0.5238868], dtype=float32), 2.405341]. 
=============================================
[2019-03-23 23:21:49,465] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.7543769e-15 1.0000000e+00 4.9943632e-24 9.3909132e-22 2.5044329e-26], sum to 1.0000
[2019-03-23 23:21:49,472] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6641
[2019-03-23 23:21:49,477] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 79.0, 1.0, 2.0, 0.7802245056365771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 889288.2639093208, 889288.2639093208, 191893.5421107759], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3092400.0000, 
sim time next is 3093000.0000, 
raw observation next is [28.66666666666667, 79.66666666666667, 1.0, 2.0, 0.7725724500337684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 880561.5544982904, 880561.55449829, 190342.6209424391], 
processed observation next is [1.0, 0.8260869565217391, 0.6172839506172841, 0.7966666666666667, 1.0, 1.0, 0.7292529167068671, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.31448626946367514, 0.314486269463675, 0.3660435018123829], 
reward next is 0.6340, 
noisyNet noise sample is [array([0.08191954], dtype=float32), 0.71045977]. 
=============================================
[2019-03-23 23:21:49,496] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[47.439068]
 [47.439068]
 [47.439068]
 [47.439068]
 [47.439068]], R is [[47.59862137]
 [47.7536087 ]
 [47.90734482]
 [48.06048203]
 [48.21458817]].
[2019-03-23 23:21:49,536] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.4694253e-16 1.0000000e+00 6.4059148e-26 2.2439768e-24 1.0794420e-27], sum to 1.0000
[2019-03-23 23:21:49,545] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6720
[2019-03-23 23:21:49,552] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.26666666666667, 48.33333333333334, 1.0, 2.0, 0.7402019181240996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 905087.4077804441, 905087.4077804441, 186499.1439454055], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3118800.0000, 
sim time next is 3119400.0000, 
raw observation next is [28.2, 50.0, 1.0, 2.0, 0.6825814220604697, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 831437.8798252352, 831437.8798252352, 175127.1667974986], 
processed observation next is [1.0, 0.08695652173913043, 0.6, 0.5, 1.0, 1.0, 0.6221207405481781, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.296942099937584, 0.296942099937584, 0.33678301307211267], 
reward next is 0.6632, 
noisyNet noise sample is [array([-0.15072921], dtype=float32), 0.270169]. 
=============================================
[2019-03-23 23:21:53,786] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.5033336e-16 1.0000000e+00 1.0567124e-26 7.6899283e-26 8.5090435e-28], sum to 1.0000
[2019-03-23 23:21:53,793] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0630
[2019-03-23 23:21:53,797] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.86666666666667, 62.66666666666667, 1.0, 2.0, 0.6608059537121388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 753109.9075548879, 753109.9075548876, 168855.2114822615], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3183600.0000, 
sim time next is 3184200.0000, 
raw observation next is [29.9, 60.0, 1.0, 2.0, 0.6444950809680569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 734520.3616293449, 734520.3616293444, 165899.9543810028], 
processed observation next is [1.0, 0.8695652173913043, 0.6629629629629629, 0.6, 1.0, 1.0, 0.5767798582953058, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2623287005819089, 0.2623287005819087, 0.3190383738096208], 
reward next is 0.6810, 
noisyNet noise sample is [array([-0.48104766], dtype=float32), 0.10129071]. 
=============================================
[2019-03-23 23:21:54,141] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.9006203e-18 1.0000000e+00 4.1441145e-28 2.9367039e-26 4.9213089e-30], sum to 1.0000
[2019-03-23 23:21:54,149] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7480
[2019-03-23 23:21:54,156] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1510147.459658487 W.
[2019-03-23 23:21:54,160] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [33.66666666666666, 36.66666666666667, 1.0, 2.0, 0.4414681295353187, 1.0, 2.0, 0.4414681295353187, 1.0, 2.0, 0.702831639833453, 6.911200000000001, 6.9112, 121.94756008, 1510147.459658487, 1510147.459658487, 315723.5963046983], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3156000.0000, 
sim time next is 3156600.0000, 
raw observation next is [33.83333333333334, 36.33333333333333, 1.0, 2.0, 0.6879241625680211, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9850903584342768, 6.9112, 6.9112, 121.9260426156618, 1510219.564161832, 1510219.564161832, 312787.2942828942], 
processed observation next is [1.0, 0.5217391304347826, 0.8086419753086423, 0.3633333333333333, 1.0, 1.0, 0.6284811459143108, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.981362948042846, 0.0, 0.0, 0.8094621288201359, 0.5393641300577972, 0.5393641300577972, 0.6015140274671041], 
reward next is 0.3985, 
noisyNet noise sample is [array([-0.9393163], dtype=float32), 1.0149485]. 
=============================================
[2019-03-23 23:21:54,464] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.4944954e-19 1.0000000e+00 4.1361480e-31 3.7324057e-26 3.2369254e-33], sum to 1.0000
[2019-03-23 23:21:54,473] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2669
[2019-03-23 23:21:54,483] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.96666666666667, 93.33333333333334, 1.0, 2.0, 0.4891122279647957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 588524.9659068594, 588524.9659068594, 141377.901132087], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3292800.0000, 
sim time next is 3293400.0000, 
raw observation next is [21.98333333333333, 93.66666666666667, 1.0, 2.0, 0.4919006371129744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 591284.2450223926, 591284.2450223926, 141792.0664620933], 
processed observation next is [0.0, 0.08695652173913043, 0.36975308641975296, 0.9366666666666668, 1.0, 1.0, 0.39511980608687425, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2111729446508545, 0.2111729446508545, 0.27267705088864097], 
reward next is 0.7273, 
noisyNet noise sample is [array([-1.1839619], dtype=float32), -0.12330578]. 
=============================================
[2019-03-23 23:22:03,747] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4311209e-18 1.0000000e+00 3.5888471e-32 4.6980240e-30 2.6696573e-35], sum to 1.0000
[2019-03-23 23:22:03,756] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2280
[2019-03-23 23:22:03,761] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.03333333333333, 92.33333333333334, 1.0, 2.0, 0.6555784458812256, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 747149.2974928991, 747149.2974928991, 167903.2377241526], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3369000.0000, 
sim time next is 3369600.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.6644290147809884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 757241.0914997566, 757241.0914997566, 169518.0692989845], 
processed observation next is [1.0, 0.0, 0.48148148148148145, 0.94, 1.0, 1.0, 0.600510731882129, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27044324696419875, 0.27044324696419875, 0.32599628711343176], 
reward next is 0.6740, 
noisyNet noise sample is [array([1.4133195], dtype=float32), 0.4346916]. 
=============================================
[2019-03-23 23:22:04,336] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.0431755e-19 1.0000000e+00 1.4886760e-32 1.1071066e-29 2.6892206e-35], sum to 1.0000
[2019-03-23 23:22:04,341] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7577
[2019-03-23 23:22:04,344] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 91.0, 1.0, 2.0, 0.6528926096285191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 753492.5181797235, 753492.5181797231, 167879.703057833], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3394800.0000, 
sim time next is 3395400.0000, 
raw observation next is [24.63333333333333, 89.66666666666667, 1.0, 2.0, 0.7248771806136974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 835642.9057788991, 835642.9057788991, 181383.4263988528], 
processed observation next is [1.0, 0.30434782608695654, 0.46790123456790106, 0.8966666666666667, 1.0, 1.0, 0.6724728340639256, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2984438949210354, 0.2984438949210354, 0.34881428153625543], 
reward next is 0.6512, 
noisyNet noise sample is [array([1.8070663], dtype=float32), 0.49169058]. 
=============================================
[2019-03-23 23:22:08,161] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.05074692e-16 1.00000000e+00 4.57983454e-24 3.74231787e-24
 1.07865635e-26], sum to 1.0000
[2019-03-23 23:22:08,169] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4601
[2019-03-23 23:22:08,177] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.45, 78.5, 1.0, 2.0, 0.6831419197516214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 778578.7767991655, 778578.7767991651, 172976.1664491504], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3439800.0000, 
sim time next is 3440400.0000, 
raw observation next is [27.26666666666667, 78.33333333333334, 1.0, 2.0, 0.6732252807810368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 767271.0986843529, 767271.0986843529, 171135.6340443362], 
processed observation next is [1.0, 0.8260869565217391, 0.5654320987654322, 0.7833333333333334, 1.0, 1.0, 0.610982477120282, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2740253923872689, 0.2740253923872689, 0.3291069885468004], 
reward next is 0.6709, 
noisyNet noise sample is [array([2.3784473], dtype=float32), -0.24397022]. 
=============================================
[2019-03-23 23:22:09,114] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.6517661e-18 1.0000000e+00 1.3382347e-30 6.8527187e-28 5.6522124e-32], sum to 1.0000
[2019-03-23 23:22:09,122] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0601
[2019-03-23 23:22:09,128] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 90.83333333333334, 1.0, 2.0, 0.5483378336525642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 652795.9965051311, 652795.9965051311, 150649.5007423383], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3556200.0000, 
sim time next is 3556800.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.5424368335690626, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 646585.4165895064, 646585.4165895064, 149706.4739480808], 
processed observation next is [1.0, 0.17391304347826086, 0.4074074074074074, 0.89, 1.0, 1.0, 0.4552819447250745, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23092336306768088, 0.23092336306768088, 0.28789706528477077], 
reward next is 0.7121, 
noisyNet noise sample is [array([0.7894544], dtype=float32), 0.73674315]. 
=============================================
[2019-03-23 23:22:09,357] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.2287196e-20 1.0000000e+00 1.0934396e-31 1.0076509e-30 4.8939659e-34], sum to 1.0000
[2019-03-23 23:22:09,365] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7490
[2019-03-23 23:22:09,372] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 100.0, 1.0, 2.0, 0.7164636182076453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 816575.8401431678, 816575.8401431678, 179279.9595190936], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3469800.0000, 
sim time next is 3470400.0000, 
raw observation next is [24.0, 100.0, 1.0, 2.0, 0.7207777460464513, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 821495.4206475157, 821495.4206475157, 180110.4614391863], 
processed observation next is [1.0, 0.17391304347826086, 0.4444444444444444, 1.0, 1.0, 1.0, 0.6675925548172039, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.293391221659827, 0.293391221659827, 0.34636627199843517], 
reward next is 0.6536, 
noisyNet noise sample is [array([1.8055495], dtype=float32), 0.40546876]. 
=============================================
[2019-03-23 23:22:17,337] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.6548765e-18 1.0000000e+00 1.1002116e-27 1.0143481e-26 6.2686665e-30], sum to 1.0000
[2019-03-23 23:22:17,342] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3198
[2019-03-23 23:22:17,350] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1456215.596546905 W.
[2019-03-23 23:22:17,355] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.1, 81.66666666666667, 1.0, 2.0, 0.4257169612468621, 1.0, 2.0, 0.4257169612468621, 1.0, 2.0, 0.6777552669384919, 6.911200000000001, 6.9112, 121.94756008, 1456215.596546905, 1456215.596546904, 308530.7621616452], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3601200.0000, 
sim time next is 3601800.0000, 
raw observation next is [25.15, 81.0, 1.0, 2.0, 0.4344405452791809, 1.0, 2.0, 0.4344405452791809, 1.0, 2.0, 0.6916434968252407, 6.911199999999999, 6.9112, 121.94756008, 1486084.603148558, 1486084.603148559, 312497.4672868799], 
processed observation next is [1.0, 0.6956521739130435, 0.487037037037037, 0.81, 1.0, 1.0, 0.3267149348561678, 1.0, 1.0, 0.3267149348561678, 1.0, 1.0, 0.6145543710315509, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.530744501124485, 0.5307445011244853, 0.6009566678593844], 
reward next is 0.3990, 
noisyNet noise sample is [array([0.3376504], dtype=float32), -1.5772187]. 
=============================================
[2019-03-23 23:22:17,585] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0074720e-19 1.0000000e+00 1.6564952e-29 3.6546996e-28 1.3561435e-31], sum to 1.0000
[2019-03-23 23:22:17,591] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9155
[2019-03-23 23:22:17,599] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.75, 78.83333333333333, 1.0, 2.0, 0.5260464171464401, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 622910.5811059331, 622910.5811059331, 146874.3977636507], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3613800.0000, 
sim time next is 3614400.0000, 
raw observation next is [24.7, 78.0, 1.0, 2.0, 0.5207922045684427, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 618619.3433118764, 618619.343311876, 146104.0431855974], 
processed observation next is [1.0, 0.8695652173913043, 0.4703703703703703, 0.78, 1.0, 1.0, 0.429514529248146, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22093547975424158, 0.2209354797542414, 0.2809693138184565], 
reward next is 0.7190, 
noisyNet noise sample is [array([0.43583328], dtype=float32), -0.090303674]. 
=============================================
[2019-03-23 23:22:21,175] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8950748e-17 1.0000000e+00 5.4174144e-27 7.9259172e-28 3.0128276e-29], sum to 1.0000
[2019-03-23 23:22:21,178] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.2096509e-17 1.0000000e+00 6.6728147e-28 9.5035485e-26 2.3841535e-28], sum to 1.0000
[2019-03-23 23:22:21,181] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5731
[2019-03-23 23:22:21,186] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.73333333333333, 89.66666666666667, 1.0, 2.0, 0.7217989426768721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 822659.9385202851, 822659.9385202846, 180314.6247122932], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3696000.0000, 
sim time next is 3696600.0000, 
raw observation next is [26.66666666666667, 89.83333333333333, 1.0, 2.0, 0.7226846454459286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 823669.9478925539, 823669.9478925539, 180485.4404705235], 
processed observation next is [1.0, 0.782608695652174, 0.5432098765432101, 0.8983333333333333, 1.0, 1.0, 0.669862673149915, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29416783853305495, 0.29416783853305495, 0.3470873855202375], 
reward next is 0.6529, 
noisyNet noise sample is [array([0.1572768], dtype=float32), -0.43013847]. 
=============================================
[2019-03-23 23:22:21,191] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2184
[2019-03-23 23:22:21,195] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.8, 91.33333333333334, 1.0, 2.0, 0.6968489582287243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 794208.8207127714, 794208.8207127709, 175547.9829762611], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3702000.0000, 
sim time next is 3702600.0000, 
raw observation next is [25.6, 92.0, 1.0, 2.0, 0.6922598227231861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 788975.8248268866, 788975.8248268862, 174683.1402571915], 
processed observation next is [1.0, 0.8695652173913043, 0.5037037037037038, 0.92, 1.0, 1.0, 0.6336426460990311, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2817770802953167, 0.2817770802953165, 0.3359291158792144], 
reward next is 0.6641, 
noisyNet noise sample is [array([-0.99181974], dtype=float32), -1.0940999]. 
=============================================
[2019-03-23 23:22:27,198] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.9029826e-20 1.0000000e+00 1.9257027e-33 2.9341447e-30 4.2646683e-35], sum to 1.0000
[2019-03-23 23:22:27,204] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8175
[2019-03-23 23:22:27,215] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666667, 82.33333333333333, 1.0, 2.0, 0.6371217921849336, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 726818.5871893178, 726818.5871893173, 164616.2822000471], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3804600.0000, 
sim time next is 3805200.0000, 
raw observation next is [26.0, 84.0, 1.0, 2.0, 0.6436731303408879, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 733574.5613766143, 733574.5613766143, 165752.751530244], 
processed observation next is [0.0, 0.043478260869565216, 0.5185185185185185, 0.84, 1.0, 1.0, 0.5758013456439142, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26199091477736225, 0.26199091477736225, 0.31875529140431536], 
reward next is 0.6812, 
noisyNet noise sample is [array([-2.3521674], dtype=float32), -0.94237435]. 
=============================================
[2019-03-23 23:22:30,091] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.2114068e-18 1.0000000e+00 6.9302562e-32 7.3764953e-30 3.3764371e-35], sum to 1.0000
[2019-03-23 23:22:30,097] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2415
[2019-03-23 23:22:30,102] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.0, 56.0, 1.0, 2.0, 0.7428159873016954, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 846627.0420447317, 846627.0420447312, 184411.9963826062], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3848400.0000, 
sim time next is 3849000.0000, 
raw observation next is [33.01666666666667, 55.16666666666667, 1.0, 2.0, 0.7216768438271586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 822520.7034468419, 822520.7034468414, 180291.7771446201], 
processed observation next is [0.0, 0.5652173913043478, 0.7783950617283953, 0.5516666666666667, 1.0, 1.0, 0.668662909318046, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2937573940881578, 0.29375739408815765, 0.34671495604734637], 
reward next is 0.6533, 
noisyNet noise sample is [array([-0.16685534], dtype=float32), -0.12690985]. 
=============================================
[2019-03-23 23:22:30,140] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[66.69842]
 [66.69842]
 [66.69842]
 [66.69842]
 [66.69842]], R is [[66.68470764]
 [66.66322327]
 [66.64051819]
 [66.61798859]
 [66.6000824 ]].
[2019-03-23 23:22:30,372] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-23 23:22:30,373] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:22:30,374] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:22:30,375] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:22:30,376] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:22:30,376] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:22:30,377] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:22:30,378] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:22:30,379] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:22:30,381] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:22:30,379] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:22:30,399] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run56
[2019-03-23 23:22:30,423] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run56
[2019-03-23 23:22:30,460] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run56
[2019-03-23 23:22:30,461] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run56
[2019-03-23 23:22:30,461] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run56
[2019-03-23 23:22:45,863] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.1709836]
[2019-03-23 23:22:45,865] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.8, 23.33333333333333, 1.0, 2.0, 0.3844989490887034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 479269.4139383422, 479269.4139383422, 126516.7560625764]
[2019-03-23 23:22:45,866] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:22:45,868] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.4189662e-19 1.0000000e+00 2.0069213e-30 4.8783054e-28 2.6445546e-32], sampled 0.2905267370937584
[2019-03-23 23:22:46,706] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.1709836]
[2019-03-23 23:22:46,707] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [37.85, 17.5, 1.0, 2.0, 0.5947911003794369, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9585026054159275, 6.911199999999999, 6.9112, 121.9260426156618, 1433794.950721097, 1433794.950721098, 288658.5409410999]
[2019-03-23 23:22:46,708] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:22:46,713] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.4189662e-19 1.0000000e+00 2.0069213e-30 4.8783054e-28 2.6445546e-32], sampled 0.8765348449671773
[2019-03-23 23:22:46,713] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1433794.950721097 W.
[2019-03-23 23:22:54,355] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.1709836]
[2019-03-23 23:22:54,355] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.45, 70.5, 1.0, 2.0, 0.3574826483836655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 446505.544312603, 446505.544312603, 122862.9805804126]
[2019-03-23 23:22:54,357] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:22:54,359] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.4189662e-19 1.0000000e+00 2.0069213e-30 4.8783054e-28 2.6445546e-32], sampled 0.8395059267427254
[2019-03-23 23:23:03,310] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.1709836]
[2019-03-23 23:23:03,312] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.39901804, 78.20179676, 1.0, 2.0, 0.6270053436009119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156505, 714569.9413214248, 714569.9413214243, 162787.0636228908]
[2019-03-23 23:23:03,313] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:23:03,317] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.4189662e-19 1.0000000e+00 2.0069213e-30 4.8783054e-28 2.6445546e-32], sampled 0.4790228585647065
[2019-03-23 23:23:04,388] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.1709836]
[2019-03-23 23:23:04,390] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.85, 78.5, 1.0, 2.0, 0.6753594308879628, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 769704.598868757, 769704.598868757, 171528.2708815585]
[2019-03-23 23:23:04,392] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:23:04,395] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.4189662e-19 1.0000000e+00 2.0069213e-30 4.8783054e-28 2.6445546e-32], sampled 0.49363515743666475
[2019-03-23 23:23:32,202] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.1709836]
[2019-03-23 23:23:32,205] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.08004955333333, 93.44367327333333, 1.0, 2.0, 0.939277906578605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1070701.610228521, 1070701.610228521, 226414.7132017254]
[2019-03-23 23:23:32,208] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:23:32,211] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.4189662e-19 1.0000000e+00 2.0069213e-30 4.8783054e-28 2.6445546e-32], sampled 0.5976170299689655
[2019-03-23 23:23:50,437] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.1709836]
[2019-03-23 23:23:50,439] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.94218356333333, 80.10710119333334, 1.0, 2.0, 0.4780716049004114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 573680.0066865202, 573680.0066865202, 139617.2634153004]
[2019-03-23 23:23:50,439] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:23:50,441] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [5.4189662e-19 1.0000000e+00 2.0069213e-30 4.8783054e-28 2.6445546e-32], sampled 0.7689623071716829
[2019-03-23 23:24:03,952] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.1709836]
[2019-03-23 23:24:03,952] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [33.0, 44.0, 1.0, 2.0, 0.8649453501046527, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1701070.044172464, 1701070.044172464, 349497.7142803853]
[2019-03-23 23:24:03,953] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:24:03,958] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.4189662e-19 1.0000000e+00 2.0069213e-30 4.8783054e-28 2.6445546e-32], sampled 0.012285617107708258
[2019-03-23 23:24:03,959] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1701070.044172464 W.
[2019-03-23 23:24:08,315] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.1709836]
[2019-03-23 23:24:08,317] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.50660595, 67.20690117666668, 1.0, 2.0, 0.3901640443213891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 484100.5005590981, 484100.5005590977, 127256.8103373528]
[2019-03-23 23:24:08,318] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:24:08,323] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.4189662e-19 1.0000000e+00 2.0069213e-30 4.8783054e-28 2.6445546e-32], sampled 0.6864378130775491
[2019-03-23 23:24:13,689] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:24:13,775] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:24:13,994] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:24:14,114] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:24:14,126] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:24:15,140] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1375000, evaluation results [1375000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:24:18,095] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.7865628e-19 1.0000000e+00 5.5904790e-31 1.0701830e-29 5.4645963e-33], sum to 1.0000
[2019-03-23 23:24:18,103] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3522
[2019-03-23 23:24:18,110] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 94.0, 1.0, 2.0, 0.7385263505095606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 841735.2292184276, 841735.2292184276, 183567.4584407163], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3888000.0000, 
sim time next is 3888600.0000, 
raw observation next is [26.0, 94.00000000000001, 1.0, 2.0, 0.727174067774228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 828789.4720911101, 828789.4720911101, 181354.0673766652], 
processed observation next is [0.0, 0.0, 0.5185185185185185, 0.9400000000000002, 1.0, 1.0, 0.6752072235407476, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2959962400325393, 0.2959962400325393, 0.3487578218782023], 
reward next is 0.6512, 
noisyNet noise sample is [array([-0.15878148], dtype=float32), 0.20018838]. 
=============================================
[2019-03-23 23:24:19,162] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.6793506e-20 1.0000000e+00 6.3194585e-34 9.2500003e-32 6.9795964e-34], sum to 1.0000
[2019-03-23 23:24:19,172] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9061
[2019-03-23 23:24:19,181] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.25, 71.5, 1.0, 2.0, 0.720498145504254, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 821176.5794920988, 821176.5794920988, 180061.8088833509], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3927000.0000, 
sim time next is 3927600.0000, 
raw observation next is [29.5, 70.0, 1.0, 2.0, 0.7209102613745723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 821646.5339212943, 821646.5339212943, 180141.2085391717], 
processed observation next is [0.0, 0.4782608695652174, 0.6481481481481481, 0.7, 1.0, 1.0, 0.6677503111602051, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2934451906861765, 0.2934451906861765, 0.34642540103686864], 
reward next is 0.6536, 
noisyNet noise sample is [array([0.06782932], dtype=float32), 1.0217655]. 
=============================================
[2019-03-23 23:24:19,890] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.0843894e-19 1.0000000e+00 1.1607362e-32 8.6280198e-28 4.4854086e-34], sum to 1.0000
[2019-03-23 23:24:19,898] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2041
[2019-03-23 23:24:19,908] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.75, 70.0, 1.0, 2.0, 0.7166831249538088, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 816826.1521088869, 816826.1521088869, 179328.6432743666], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3928200.0000, 
sim time next is 3928800.0000, 
raw observation next is [30.0, 70.0, 1.0, 2.0, 0.7224511196562801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 823403.6470985591, 823403.6470985591, 180441.2997306091], 
processed observation next is [0.0, 0.4782608695652174, 0.6666666666666666, 0.7, 1.0, 1.0, 0.6695846662574763, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29407273110662824, 0.29407273110662824, 0.3470024994819406], 
reward next is 0.6530, 
noisyNet noise sample is [array([0.15300012], dtype=float32), 0.041705787]. 
=============================================
[2019-03-23 23:24:22,064] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.8114099e-18 1.0000000e+00 1.8300231e-29 1.0767036e-26 2.8189824e-32], sum to 1.0000
[2019-03-23 23:24:22,073] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6661
[2019-03-23 23:24:22,080] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.3, 94.0, 1.0, 2.0, 0.8110699747695412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 929583.0077484575, 929583.007748457, 198504.3711269733], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4003200.0000, 
sim time next is 4003800.0000, 
raw observation next is [24.35, 94.00000000000001, 1.0, 2.0, 0.774259906716116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 886807.544539354, 886807.544539354, 190900.6015343669], 
processed observation next is [1.0, 0.34782608695652173, 0.4574074074074075, 0.9400000000000002, 1.0, 1.0, 0.7312617937096619, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31671698019262645, 0.31671698019262645, 0.36711654141224404], 
reward next is 0.6329, 
noisyNet noise sample is [array([1.1679683], dtype=float32), 2.2826622]. 
=============================================
[2019-03-23 23:24:28,261] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0302738e-20 1.0000000e+00 4.2664017e-31 3.0467740e-28 1.5635985e-32], sum to 1.0000
[2019-03-23 23:24:28,267] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0167
[2019-03-23 23:24:28,273] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1510257.66993367 W.
[2019-03-23 23:24:28,276] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 70.0, 1.0, 2.0, 0.6977713940011223, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1510257.66993367, 1510257.669933671, 316826.0816253016], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4107600.0000, 
sim time next is 4108200.0000, 
raw observation next is [28.96666666666667, 69.0, 1.0, 2.0, 0.7325124793667852, 1.0, 1.0, 0.7325124793667852, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1670650.930532224, 1670650.930532225, 316656.4076861733], 
processed observation next is [1.0, 0.5652173913043478, 0.6283950617283951, 0.69, 1.0, 1.0, 0.681562475436649, 1.0, 0.5, 0.681562475436649, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5966610466186514, 0.5966610466186517, 0.6089546301657178], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5674401], dtype=float32), 0.5267597]. 
=============================================
[2019-03-23 23:24:39,883] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4357093e-17 1.0000000e+00 2.7590305e-26 2.1347316e-26 1.0987173e-29], sum to 1.0000
[2019-03-23 23:24:39,893] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2403
[2019-03-23 23:24:39,898] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.73333333333333, 82.66666666666667, 1.0, 2.0, 0.5610886953357335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 657836.8227726655, 657836.8227726655, 152365.9015100994], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4324800.0000, 
sim time next is 4325400.0000, 
raw observation next is [24.6, 82.5, 1.0, 2.0, 0.5525332935206312, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 649775.0505550455, 649775.0505550455, 151026.7161812988], 
processed observation next is [1.0, 0.043478260869565216, 0.46666666666666673, 0.825, 1.0, 1.0, 0.4673015399055133, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2320625180553734, 0.2320625180553734, 0.29043599265634384], 
reward next is 0.7096, 
noisyNet noise sample is [array([1.8658262], dtype=float32), 0.91082144]. 
=============================================
[2019-03-23 23:24:49,348] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.7559274e-20 1.0000000e+00 6.7037903e-35 3.2058003e-32 9.9118266e-36], sum to 1.0000
[2019-03-23 23:24:49,363] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0002
[2019-03-23 23:24:49,365] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.6955472635266586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 792724.4932899722, 792724.4932899722, 175303.2181584823], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4482600.0000, 
sim time next is 4483200.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.7034178820199884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 801699.4333667646, 801699.4333667646, 176792.2746753431], 
processed observation next is [0.0, 0.9130434782608695, 0.5555555555555556, 0.84, 1.0, 1.0, 0.6469260500237958, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2863212262024159, 0.2863212262024159, 0.339985143606429], 
reward next is 0.6600, 
noisyNet noise sample is [array([0.03536328], dtype=float32), 0.15413694]. 
=============================================
[2019-03-23 23:24:52,797] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.3439193e-21 1.0000000e+00 1.8507923e-34 6.7950720e-32 6.6149015e-36], sum to 1.0000
[2019-03-23 23:24:52,803] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2624
[2019-03-23 23:24:52,808] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.45, 97.5, 1.0, 2.0, 0.5952280653484073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 688830.3720403318, 688830.3720403318, 157764.2088866963], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4552200.0000, 
sim time next is 4552800.0000, 
raw observation next is [23.6, 96.66666666666666, 1.0, 2.0, 0.6001114698717955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 693773.8605377077, 693773.8605377077, 158573.8352773736], 
processed observation next is [0.0, 0.6956521739130435, 0.4296296296296297, 0.9666666666666666, 1.0, 1.0, 0.5239422260378518, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24777637876346703, 0.24777637876346703, 0.30494968322571847], 
reward next is 0.6951, 
noisyNet noise sample is [array([0.19178729], dtype=float32), 1.3535482]. 
=============================================
[2019-03-23 23:24:53,254] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9157352e-21 1.0000000e+00 1.8351526e-31 3.5741929e-29 1.2742540e-34], sum to 1.0000
[2019-03-23 23:24:53,261] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9093
[2019-03-23 23:24:53,266] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 94.0, 1.0, 2.0, 0.6004602859199565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 693034.7523098465, 693034.7523098469, 158580.6028200891], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4560600.0000, 
sim time next is 4561200.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.6000171064649585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 692524.2615863256, 692524.2615863256, 158504.0664181812], 
processed observation next is [0.0, 0.8260869565217391, 0.4444444444444444, 0.94, 1.0, 1.0, 0.5238298886487601, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24733009342368772, 0.24733009342368772, 0.30481551234265614], 
reward next is 0.6952, 
noisyNet noise sample is [array([-0.91029954], dtype=float32), -0.4422926]. 
=============================================
[2019-03-23 23:24:53,707] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.5023654e-21 1.0000000e+00 2.0033309e-33 1.0152707e-31 1.9622207e-36], sum to 1.0000
[2019-03-23 23:24:53,719] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1708
[2019-03-23 23:24:53,724] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.58333333333333, 96.66666666666666, 1.0, 2.0, 0.5408313292213308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 637540.6649169078, 637540.6649169078, 149163.4318578739], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4576200.0000, 
sim time next is 4576800.0000, 
raw observation next is [22.26666666666667, 97.33333333333333, 1.0, 2.0, 0.530294678487372, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 627963.8071123932, 627963.8071123932, 147562.1497107835], 
processed observation next is [0.0, 1.0, 0.38024691358024704, 0.9733333333333333, 1.0, 1.0, 0.44082699819925236, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22427278825442615, 0.22427278825442615, 0.2837733648284298], 
reward next is 0.7162, 
noisyNet noise sample is [array([-0.17108318], dtype=float32), 1.15017]. 
=============================================
[2019-03-23 23:24:53,741] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.5379104e-21 1.0000000e+00 4.0495883e-33 4.1211859e-31 5.8807420e-37], sum to 1.0000
[2019-03-23 23:24:53,750] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0843
[2019-03-23 23:24:53,754] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4823133106592503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 581951.0599757279, 581951.0599757279, 140377.897710097], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4593600.0000, 
sim time next is 4594200.0000, 
raw observation next is [21.06666666666667, 99.83333333333334, 1.0, 2.0, 0.5260045931331206, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 634262.6524537991, 634262.6524537991, 147284.278668725], 
processed observation next is [1.0, 0.17391304347826086, 0.3358024691358026, 0.9983333333333334, 1.0, 1.0, 0.4357197537299055, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22652237587635685, 0.22652237587635685, 0.28323899743985576], 
reward next is 0.7168, 
noisyNet noise sample is [array([0.05878543], dtype=float32), -0.3159508]. 
=============================================
[2019-03-23 23:24:56,502] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.9391790e-17 1.0000000e+00 4.0956152e-28 2.9301912e-26 2.3362721e-30], sum to 1.0000
[2019-03-23 23:24:56,510] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7466
[2019-03-23 23:24:56,516] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2033609.891530956 W.
[2019-03-23 23:24:56,522] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.58333333333334, 64.33333333333334, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 7.214606599045194, 6.9112, 121.9250003748246, 2033609.891530956, 1878239.922781256, 383044.1625672169], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4630200.0000, 
sim time next is 4630800.0000, 
raw observation next is [29.66666666666667, 64.66666666666667, 1.0, 2.0, 0.5870713182653946, 1.0, 1.0, 0.5870713182653946, 1.0, 2.0, 0.9346366582565369, 6.9112, 6.9112, 121.94756008, 2008791.433370555, 2008791.433370555, 388376.3904223841], 
processed observation next is [1.0, 0.6086956521739131, 0.6543209876543211, 0.6466666666666667, 1.0, 1.0, 0.5084182360302316, 1.0, 0.5, 0.5084182360302316, 1.0, 1.0, 0.9182958228206711, 0.0, 0.0, 0.8096049824067558, 0.7174255119180554, 0.7174255119180554, 0.7468776738892001], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.57305473], dtype=float32), 0.52527934]. 
=============================================
[2019-03-23 23:25:00,414] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0625536e-18 1.0000000e+00 8.4661953e-31 6.3812716e-29 1.0878930e-32], sum to 1.0000
[2019-03-23 23:25:00,420] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7683
[2019-03-23 23:25:00,426] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.6667898871059881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 759933.0806957921, 759933.0806957921, 169950.8790615674], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4669200.0000, 
sim time next is 4669800.0000, 
raw observation next is [24.96666666666667, 94.16666666666667, 1.0, 2.0, 0.6664008042301973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 759489.4275498703, 759489.4275498699, 169879.4283484655], 
processed observation next is [1.0, 0.043478260869565216, 0.48024691358024696, 0.9416666666666668, 1.0, 1.0, 0.6028581002740444, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2712462241249537, 0.2712462241249535, 0.32669120836243365], 
reward next is 0.6733, 
noisyNet noise sample is [array([0.9025306], dtype=float32), 0.5564759]. 
=============================================
[2019-03-23 23:25:03,101] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.1395458e-20 1.0000000e+00 8.7220881e-31 5.3446853e-28 8.3867900e-33], sum to 1.0000
[2019-03-23 23:25:03,110] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4112
[2019-03-23 23:25:03,116] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.1, 92.33333333333334, 1.0, 2.0, 0.6517325000101698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 742764.028317804, 742764.028317804, 167206.4870051115], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4750800.0000, 
sim time next is 4751400.0000, 
raw observation next is [25.05, 93.16666666666667, 1.0, 2.0, 0.65494717910632, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 746429.5054207097, 746429.5054207097, 167789.2738715453], 
processed observation next is [1.0, 1.0, 0.48333333333333334, 0.9316666666666668, 1.0, 1.0, 0.5892228322694286, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26658196622168207, 0.26658196622168207, 0.3226716805222025], 
reward next is 0.6773, 
noisyNet noise sample is [array([1.1642668], dtype=float32), 0.7926574]. 
=============================================
[2019-03-23 23:25:05,639] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 23:25:05,642] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:25:05,644] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:25:05,644] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:25:05,645] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:25:05,645] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:25:05,649] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:25:05,650] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:25:05,649] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:25:05,650] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:25:05,651] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:25:05,672] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run57
[2019-03-23 23:25:05,694] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run57
[2019-03-23 23:25:05,720] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run57
[2019-03-23 23:25:05,743] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run57
[2019-03-23 23:25:05,767] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run57
[2019-03-23 23:25:08,007] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.19997552]
[2019-03-23 23:25:08,008] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.83333333333334, 38.66666666666667, 1.0, 2.0, 0.3228019596746945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 416412.2498678816, 416412.2498678816, 100269.4072605166]
[2019-03-23 23:25:08,008] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:25:08,010] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.5573631e-16 1.0000000e+00 9.8545706e-26 9.6649345e-24 1.9520612e-27], sampled 0.24820245828444487
[2019-03-23 23:25:12,852] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.19997552]
[2019-03-23 23:25:12,856] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [15.75, 88.16666666666666, 1.0, 2.0, 0.2192714685319849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 282834.0204839522, 282834.0204839522, 89807.27296255711]
[2019-03-23 23:25:12,857] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:25:12,860] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.5573631e-16 1.0000000e+00 9.8545706e-26 9.6649345e-24 1.9520612e-27], sampled 0.41759677031462206
[2019-03-23 23:25:18,669] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.19997552]
[2019-03-23 23:25:18,670] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.16666666666667, 48.33333333333333, 1.0, 2.0, 0.2351143654256874, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 303273.5065320207, 303273.5065320212, 91830.35551171692]
[2019-03-23 23:25:18,671] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:25:18,672] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.5573631e-16 1.0000000e+00 9.8545706e-26 9.6649345e-24 1.9520612e-27], sampled 0.7029071675484961
[2019-03-23 23:25:29,816] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.19997552]
[2019-03-23 23:25:29,818] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.45, 55.0, 1.0, 2.0, 0.3989904333530154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 490568.261960488, 490568.261960488, 128385.1872709431]
[2019-03-23 23:25:29,820] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:25:29,822] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.5573631e-16 1.0000000e+00 9.8545706e-26 9.6649345e-24 1.9520612e-27], sampled 0.15709566999187619
[2019-03-23 23:25:35,027] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.19997552]
[2019-03-23 23:25:35,028] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [31.18333333333333, 30.33333333333333, 1.0, 2.0, 0.3774510501010006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 471109.4373869399, 471109.4373869399, 125558.4746794772]
[2019-03-23 23:25:35,029] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:25:35,030] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.5573631e-16 1.0000000e+00 9.8545706e-26 9.6649345e-24 1.9520612e-27], sampled 0.10927335446881681
[2019-03-23 23:25:45,527] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.19997552]
[2019-03-23 23:25:45,528] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.384781885, 106.50459794, 1.0, 2.0, 0.5889084536454507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 691372.7628205147, 691372.7628205143, 157116.5934416898]
[2019-03-23 23:25:45,530] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:25:45,533] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.5573631e-16 1.0000000e+00 9.8545706e-26 9.6649345e-24 1.9520612e-27], sampled 0.4517799090460818
[2019-03-23 23:25:45,926] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.19997552]
[2019-03-23 23:25:45,927] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.19154861, 87.67635066, 1.0, 2.0, 0.4386686109437321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 533605.1614612213, 533605.1614612213, 133938.654177581]
[2019-03-23 23:25:45,928] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:25:45,931] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.5573631e-16 1.0000000e+00 9.8545706e-26 9.6649345e-24 1.9520612e-27], sampled 0.917560999616456
[2019-03-23 23:25:56,278] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.19997552]
[2019-03-23 23:25:56,279] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [19.96078436333334, 100.4559088916667, 1.0, 2.0, 0.4149978515736346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 508843.9548047087, 508843.9548047087, 130619.1089073534]
[2019-03-23 23:25:56,280] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:25:56,284] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.5573631e-16 1.0000000e+00 9.8545706e-26 9.6649345e-24 1.9520612e-27], sampled 0.9853282100327106
[2019-03-23 23:26:16,611] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.19997552]
[2019-03-23 23:26:16,612] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.35, 93.0, 1.0, 2.0, 0.7548191582407742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 860315.3751440179, 860315.3751440179, 186779.0651612997]
[2019-03-23 23:26:16,612] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:26:16,616] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.5573631e-16 1.0000000e+00 9.8545706e-26 9.6649345e-24 1.9520612e-27], sampled 0.5053965856744588
[2019-03-23 23:26:48,612] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.19997552]
[2019-03-23 23:26:48,616] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [20.0, 92.0, 1.0, 2.0, 0.3723698784874565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 462772.827943525, 462772.8279435245, 124824.6272001575]
[2019-03-23 23:26:48,617] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:26:48,620] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.5573631e-16 1.0000000e+00 9.8545706e-26 9.6649345e-24 1.9520612e-27], sampled 0.4274999719470628
[2019-03-23 23:26:49,280] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:26:49,372] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:26:49,501] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:26:49,560] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:26:49,563] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:26:50,579] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1400000, evaluation results [1400000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:26:50,690] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2412574e-16 1.0000000e+00 6.9664313e-26 1.1751544e-23 3.0181783e-28], sum to 1.0000
[2019-03-23 23:26:50,700] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1128
[2019-03-23 23:26:50,710] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1981518.006624732 W.
[2019-03-23 23:26:50,723] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.08333333333333, 88.33333333333334, 1.0, 2.0, 0.5791094634309899, 1.0, 1.0, 0.5791094634309899, 1.0, 2.0, 0.9219611260606553, 6.9112, 6.9112, 121.94756008, 1981518.006624732, 1981518.006624732, 384110.891460572], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4805400.0000, 
sim time next is 4806000.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.4849925626751367, 1.0, 2.0, 0.4849925626751367, 1.0, 2.0, 0.7721239548838702, 6.9112, 6.9112, 121.94756008, 1659182.547260883, 1659182.547260883, 336284.2842984606], 
processed observation next is [1.0, 0.6521739130434783, 0.5555555555555556, 0.89, 1.0, 1.0, 0.3868959079465913, 1.0, 1.0, 0.3868959079465913, 1.0, 1.0, 0.7151549436048377, 0.0, 0.0, 0.8096049824067558, 0.5925651954503154, 0.5925651954503154, 0.6467005467278089], 
reward next is 0.3533, 
noisyNet noise sample is [array([0.03524542], dtype=float32), 0.9295738]. 
=============================================
[2019-03-23 23:26:50,736] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[48.46168]
 [48.46168]
 [48.46168]
 [48.46168]
 [48.46168]], R is [[48.33036423]
 [47.84706116]
 [47.36859131]
 [46.89490509]
 [46.42595673]].
[2019-03-23 23:26:54,036] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.4028166e-19 1.0000000e+00 3.0079097e-31 4.1026853e-27 3.0453271e-32], sum to 1.0000
[2019-03-23 23:26:54,043] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7151
[2019-03-23 23:26:54,046] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.2, 94.5, 1.0, 2.0, 0.3518582231725539, 1.0, 2.0, 0.3518582231725539, 1.0, 1.0, 0.5601697505130245, 6.911199999999999, 6.9112, 121.94756008, 1203374.554596175, 1203374.554596175, 276636.1404410593], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4847400.0000, 
sim time next is 4848000.0000, 
raw observation next is [25.13333333333333, 94.33333333333334, 1.0, 2.0, 0.9240035410004117, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426155264, 1053278.089038158, 1053278.089038158, 222888.9331126021], 
processed observation next is [1.0, 0.08695652173913043, 0.4864197530864196, 0.9433333333333335, 1.0, 1.0, 0.9095280250004901, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288192371, 0.37617074608505646, 0.37617074608505646, 0.42863256367808095], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5961503], dtype=float32), -0.60281587]. 
=============================================
[2019-03-23 23:26:54,062] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[61.267864]
 [61.267864]
 [61.267864]
 [61.267864]
 [61.267864]], R is [[60.6551857 ]
 [60.51663971]
 [60.32922745]
 [59.72593689]
 [59.7911644 ]].
[2019-03-23 23:27:02,255] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.7773917e-20 1.0000000e+00 1.0505105e-34 6.0549300e-30 2.7475800e-35], sum to 1.0000
[2019-03-23 23:27:02,262] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0987
[2019-03-23 23:27:02,266] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.83333333333334, 87.66666666666666, 1.0, 2.0, 0.6465379184255213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 736841.0418545154, 736841.0418545154, 166269.4810476991], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5042400.0000, 
sim time next is 5043000.0000, 
raw observation next is [25.91666666666667, 88.33333333333334, 1.0, 2.0, 0.6571452572451786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 748935.8325791277, 748935.8325791277, 168189.6008865433], 
processed observation next is [0.0, 0.34782608695652173, 0.5154320987654323, 0.8833333333333334, 1.0, 1.0, 0.591839591958546, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2674770830639742, 0.2674770830639742, 0.32344154016642945], 
reward next is 0.6766, 
noisyNet noise sample is [array([-0.3050277], dtype=float32), 1.27104]. 
=============================================
[2019-03-23 23:27:02,281] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[69.58224]
 [69.58224]
 [69.58224]
 [69.58224]
 [69.58224]], R is [[69.56297302]
 [69.54759979]
 [69.5357666 ]
 [69.52715302]
 [69.52191162]].
[2019-03-23 23:27:02,707] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.2848351e-21 1.0000000e+00 7.1611412e-31 5.0993069e-30 4.4928064e-34], sum to 1.0000
[2019-03-23 23:27:02,717] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5719
[2019-03-23 23:27:02,721] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 96.0, 1.0, 2.0, 0.625401718517555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 717204.918378797, 717204.918378797, 162723.0667738807], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5002800.0000, 
sim time next is 5003400.0000, 
raw observation next is [24.0, 95.0, 1.0, 2.0, 0.6165560002350581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 709056.9207743221, 709056.9207743217, 161263.1311855725], 
processed observation next is [1.0, 0.9130434782608695, 0.4444444444444444, 0.95, 1.0, 1.0, 0.5435190478988786, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2532346145622579, 0.2532346145622577, 0.31012140612610095], 
reward next is 0.6899, 
noisyNet noise sample is [array([0.18133533], dtype=float32), -0.69430697]. 
=============================================
[2019-03-23 23:27:06,009] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.4411494e-19 1.0000000e+00 7.9369749e-32 5.9640653e-28 1.1078273e-32], sum to 1.0000
[2019-03-23 23:27:06,010] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8872
[2019-03-23 23:27:06,014] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.26666666666667, 86.66666666666666, 1.0, 2.0, 0.8169789448738634, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 931205.8773486805, 931205.8773486805, 199480.9765238214], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5085600.0000, 
sim time next is 5086200.0000, 
raw observation next is [28.13333333333333, 87.83333333333334, 1.0, 2.0, 0.8205826589891018, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 935315.9558796998, 935315.9558796994, 200237.4822320375], 
processed observation next is [0.0, 0.8695652173913043, 0.5975308641975308, 0.8783333333333334, 1.0, 1.0, 0.7864079273679783, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3340414128141785, 0.3340414128141784, 0.3850720812154567], 
reward next is 0.6149, 
noisyNet noise sample is [array([0.2346002], dtype=float32), 0.20214705]. 
=============================================
[2019-03-23 23:27:06,174] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.5386029e-20 1.0000000e+00 1.8829913e-31 3.5983424e-27 1.7486375e-32], sum to 1.0000
[2019-03-23 23:27:06,180] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7337
[2019-03-23 23:27:06,190] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.66666666666667, 80.66666666666667, 1.0, 2.0, 0.6999827028641323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 797782.2534369333, 797782.2534369333, 176141.8424371745], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5046600.0000, 
sim time next is 5047200.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.7036257484046079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 801936.4667788643, 801936.4667788643, 176832.9369591526], 
processed observation next is [0.0, 0.43478260869565216, 0.5925925925925926, 0.79, 1.0, 1.0, 0.6471735100054856, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2864058809924515, 0.2864058809924515, 0.3400633403060627], 
reward next is 0.6599, 
noisyNet noise sample is [array([0.06738379], dtype=float32), -1.566077]. 
=============================================
[2019-03-23 23:27:09,359] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3751514e-18 1.0000000e+00 1.6507225e-30 6.3219436e-26 4.3940957e-32], sum to 1.0000
[2019-03-23 23:27:09,368] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3217
[2019-03-23 23:27:09,371] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.3, 85.0, 1.0, 2.0, 0.7360319343837549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 838890.6631617954, 838890.6631617954, 183079.3868782075], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5169600.0000, 
sim time next is 5170200.0000, 
raw observation next is [27.16666666666666, 85.16666666666667, 1.0, 2.0, 0.7153918935807239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 815353.7126000167, 815353.7126000167, 179080.0529955167], 
processed observation next is [0.0, 0.8695652173913043, 0.5617283950617282, 0.8516666666666667, 1.0, 1.0, 0.661180825691338, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29119775450000596, 0.29119775450000596, 0.34438471729907055], 
reward next is 0.6556, 
noisyNet noise sample is [array([0.50960016], dtype=float32), -1.0326513]. 
=============================================
[2019-03-23 23:27:10,281] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.8980721e-21 1.0000000e+00 7.7148285e-30 7.7440184e-30 3.4369196e-33], sum to 1.0000
[2019-03-23 23:27:10,286] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6893
[2019-03-23 23:27:10,293] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.5, 74.83333333333334, 1.0, 2.0, 0.7533649400986693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 858656.9818200419, 858656.9818200424, 186497.6497993096], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5163000.0000, 
sim time next is 5163600.0000, 
raw observation next is [29.3, 75.66666666666667, 1.0, 2.0, 0.7473210342891746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 851764.5378037539, 851764.5378037539, 185300.6135372075], 
processed observation next is [0.0, 0.782608695652174, 0.6407407407407407, 0.7566666666666667, 1.0, 1.0, 0.6991917074871127, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3042016206441978, 0.3042016206441978, 0.35634733372539906], 
reward next is 0.6437, 
noisyNet noise sample is [array([-0.64374524], dtype=float32), 0.23696937]. 
=============================================
[2019-03-23 23:27:10,638] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1038566e-19 1.0000000e+00 2.4345895e-30 2.5265223e-26 1.9691683e-32], sum to 1.0000
[2019-03-23 23:27:10,646] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6523
[2019-03-23 23:27:10,650] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.9, 82.0, 1.0, 2.0, 0.7406873351681603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 844199.5673995045, 844199.5673995045, 183992.3200284565], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5167800.0000, 
sim time next is 5168400.0000, 
raw observation next is [27.7, 83.0, 1.0, 2.0, 0.7421702227304905, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 845890.6235252187, 845890.6235252187, 184283.3897647566], 
processed observation next is [0.0, 0.8260869565217391, 0.5814814814814815, 0.83, 1.0, 1.0, 0.6930597889648696, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3021037941161495, 0.3021037941161495, 0.35439113416299345], 
reward next is 0.6456, 
noisyNet noise sample is [array([-0.53047276], dtype=float32), 0.67939997]. 
=============================================
[2019-03-23 23:27:18,699] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.3879775e-17 1.0000000e+00 2.3517715e-27 1.0406447e-23 4.7315491e-30], sum to 1.0000
[2019-03-23 23:27:18,708] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4104
[2019-03-23 23:27:18,716] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1381561.302256268 W.
[2019-03-23 23:27:18,722] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.1, 79.66666666666667, 1.0, 2.0, 0.4039118354707949, 1.0, 1.0, 0.4039118354707949, 1.0, 2.0, 0.643040796559624, 6.911199999999999, 6.9112, 121.94756008, 1381561.302256268, 1381561.302256268, 298799.9751018617], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5311200.0000, 
sim time next is 5311800.0000, 
raw observation next is [25.3, 78.5, 1.0, 2.0, 0.6203558045449179, 1.0, 2.0, 0.6203558045449179, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1419698.495418853, 1419698.495418854, 275366.8437556863], 
processed observation next is [1.0, 0.4782608695652174, 0.49259259259259264, 0.785, 1.0, 1.0, 0.5480426244582356, 1.0, 1.0, 0.5480426244582356, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5070351769353046, 0.507035176935305, 0.5295516226070891], 
reward next is 0.4704, 
noisyNet noise sample is [array([1.099919], dtype=float32), -0.055589475]. 
=============================================
[2019-03-23 23:27:18,920] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.3539612e-19 1.0000000e+00 2.2406180e-29 3.1542156e-28 2.0766396e-30], sum to 1.0000
[2019-03-23 23:27:18,928] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7958
[2019-03-23 23:27:18,934] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1378850.65643068 W.
[2019-03-23 23:27:18,941] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.26666666666667, 73.0, 1.0, 2.0, 0.4031200664432871, 1.0, 2.0, 0.4031200664432871, 1.0, 2.0, 0.6417802744817146, 6.9112, 6.9112, 121.94756008, 1378850.65643068, 1378850.65643068, 298451.5936778312], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5314800.0000, 
sim time next is 5315400.0000, 
raw observation next is [26.45, 72.0, 1.0, 2.0, 0.3727073731351929, 1.0, 2.0, 0.3727073731351929, 1.0, 2.0, 0.5933622762629561, 6.9112, 6.9112, 121.94756008, 1274739.116608306, 1274739.116608306, 285332.9571351861], 
processed observation next is [1.0, 0.5217391304347826, 0.5351851851851852, 0.72, 1.0, 1.0, 0.25322306325618205, 1.0, 1.0, 0.25322306325618205, 1.0, 1.0, 0.4917028453286951, 0.0, 0.0, 0.8096049824067558, 0.4552639702172522, 0.4552639702172522, 0.5487172252599734], 
reward next is 0.4513, 
noisyNet noise sample is [array([0.4660539], dtype=float32), 0.26069075]. 
=============================================
[2019-03-23 23:27:38,197] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.4966298e-19 1.0000000e+00 1.2503243e-32 1.1036105e-30 1.9161766e-33], sum to 1.0000
[2019-03-23 23:27:38,208] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5883
[2019-03-23 23:27:38,210] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.41666666666667, 96.16666666666666, 1.0, 2.0, 0.5318552572104641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 630281.672019112, 630281.672019112, 147833.9577955492], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5706600.0000, 
sim time next is 5707200.0000, 
raw observation next is [22.33333333333334, 96.33333333333333, 1.0, 2.0, 0.5284320880873269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 626979.9318578771, 626979.9318578771, 147308.4711238231], 
processed observation next is [0.0, 0.043478260869565216, 0.38271604938271625, 0.9633333333333333, 1.0, 1.0, 0.4386096286753891, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2239214042349561, 0.2239214042349561, 0.2832855213919675], 
reward next is 0.7167, 
noisyNet noise sample is [array([0.49892622], dtype=float32), 0.57901156]. 
=============================================
[2019-03-23 23:27:41,049] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 23:27:41,050] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:27:41,051] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:27:41,052] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:27:41,055] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:27:41,057] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:27:41,058] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:27:41,059] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:27:41,060] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:27:41,061] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:27:41,063] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:27:41,078] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run58
[2019-03-23 23:27:41,105] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run58
[2019-03-23 23:27:41,127] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run58
[2019-03-23 23:27:41,152] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run58
[2019-03-23 23:27:41,154] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run58
[2019-03-23 23:27:48,013] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.15906186]
[2019-03-23 23:27:48,014] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.66528033, 55.93016329, 1.0, 2.0, 0.4118549346328187, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 504991.2491856424, 504991.2491856424, 130171.1168030001]
[2019-03-23 23:27:48,015] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:27:48,016] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.5647498e-21 1.0000000e+00 3.2620747e-34 1.5842470e-31 2.4385417e-36], sampled 0.8302926394698191
[2019-03-23 23:28:24,489] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.15906186]
[2019-03-23 23:28:24,491] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.82254309, 67.2703481, 1.0, 2.0, 0.5297004404116217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 625016.3695854554, 625016.3695854549, 147376.714583407]
[2019-03-23 23:28:24,494] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:28:24,496] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.5647498e-21 1.0000000e+00 3.2620747e-34 1.5842470e-31 2.4385417e-36], sampled 0.06764136096488493
[2019-03-23 23:28:33,153] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.15906186]
[2019-03-23 23:28:33,155] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.47239238833333, 82.21817177, 1.0, 2.0, 0.5790970808324241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 696902.632137454, 696902.632137454, 156098.0740018478]
[2019-03-23 23:28:33,155] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:28:33,159] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.5647498e-21 1.0000000e+00 3.2620747e-34 1.5842470e-31 2.4385417e-36], sampled 0.2458435671678646
[2019-03-23 23:28:46,284] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.15906186]
[2019-03-23 23:28:46,285] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.15091438333334, 103.3030324533333, 1.0, 2.0, 0.9148048470821598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1042785.298490491, 1042785.298490491, 220813.6948741601]
[2019-03-23 23:28:46,287] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:28:46,290] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.5647498e-21 1.0000000e+00 3.2620747e-34 1.5842470e-31 2.4385417e-36], sampled 0.37872085836006086
[2019-03-23 23:28:47,595] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.15906186]
[2019-03-23 23:28:47,595] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.83333333333334, 56.66666666666666, 1.0, 2.0, 0.818864229994969, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1648471.755157947, 1648471.755157948, 340012.2025259889]
[2019-03-23 23:28:47,597] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:28:47,602] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.5647498e-21 1.0000000e+00 3.2620747e-34 1.5842470e-31 2.4385417e-36], sampled 0.7613020898582451
[2019-03-23 23:28:47,604] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1648471.755157947 W.
[2019-03-23 23:29:03,073] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.15906186]
[2019-03-23 23:29:03,075] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.589353765, 86.22350985, 1.0, 2.0, 0.5829043989878477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 678015.0809395931, 678015.0809395931, 155812.7732084907]
[2019-03-23 23:29:03,075] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:29:03,078] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.5647498e-21 1.0000000e+00 3.2620747e-34 1.5842470e-31 2.4385417e-36], sampled 0.568803394209356
[2019-03-23 23:29:04,115] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.15906186]
[2019-03-23 23:29:04,118] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.0, 92.0, 1.0, 2.0, 0.7808219614997508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 889969.6305873106, 889969.6305873102, 192004.1189110276]
[2019-03-23 23:29:04,119] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:29:04,121] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.5647498e-21 1.0000000e+00 3.2620747e-34 1.5842470e-31 2.4385417e-36], sampled 0.31010797563826764
[2019-03-23 23:29:07,945] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.15906186]
[2019-03-23 23:29:07,946] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.777166535, 59.43698244666666, 1.0, 2.0, 0.2831693114360068, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 359368.8964579886, 359368.8964579886, 113510.3745322779]
[2019-03-23 23:29:07,946] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:29:07,949] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.5647498e-21 1.0000000e+00 3.2620747e-34 1.5842470e-31 2.4385417e-36], sampled 0.8491320859413112
[2019-03-23 23:29:24,537] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:29:24,964] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:29:25,006] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:29:25,122] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:29:25,137] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:29:26,153] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1425000, evaluation results [1425000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:29:28,058] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.8459007e-22 1.0000000e+00 7.3164450e-36 2.2325329e-34 2.4671626e-37], sum to 1.0000
[2019-03-23 23:29:28,063] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9395
[2019-03-23 23:29:28,070] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.03333333333333, 63.0, 1.0, 2.0, 0.5549360526752227, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 650144.0236307953, 650144.0236307953, 151322.1389998047], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5757600.0000, 
sim time next is 5758200.0000, 
raw observation next is [28.05, 63.5, 1.0, 2.0, 0.5589771227381986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 653572.87844092, 653572.87844092, 151937.6305653238], 
processed observation next is [0.0, 0.6521739130434783, 0.5944444444444444, 0.635, 1.0, 1.0, 0.4749727651645221, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23341888515747145, 0.23341888515747145, 0.29218775108716116], 
reward next is 0.7078, 
noisyNet noise sample is [array([1.8105817], dtype=float32), 0.31511104]. 
=============================================
[2019-03-23 23:29:28,433] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.5204709e-22 1.0000000e+00 2.9636789e-34 1.5224036e-33 1.4889244e-34], sum to 1.0000
[2019-03-23 23:29:28,440] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2687
[2019-03-23 23:29:28,445] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.96666666666667, 68.0, 1.0, 2.0, 0.5990189728309644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 689963.6086002332, 689963.6086002332, 158265.0439026471], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5764800.0000, 
sim time next is 5765400.0000, 
raw observation next is [27.8, 68.5, 1.0, 2.0, 0.5953871079098836, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 686856.5603912566, 686856.5603912566, 157690.6950133212], 
processed observation next is [0.0, 0.7391304347826086, 0.5851851851851853, 0.685, 1.0, 1.0, 0.5183179856070043, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24530591442544877, 0.24530591442544877, 0.30325133656407927], 
reward next is 0.6967, 
noisyNet noise sample is [array([2.072822], dtype=float32), 1.7718256]. 
=============================================
[2019-03-23 23:29:38,782] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.0196883e-20 1.0000000e+00 1.3153165e-32 6.4015015e-31 4.4217640e-36], sum to 1.0000
[2019-03-23 23:29:38,790] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9279
[2019-03-23 23:29:38,795] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.91666666666667, 80.5, 1.0, 2.0, 0.472976958507797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 584141.5067039237, 584141.5067039242, 139329.4189319175], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5973000.0000, 
sim time next is 5973600.0000, 
raw observation next is [21.83333333333334, 81.0, 1.0, 2.0, 0.4343272330427351, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 536555.9515231199, 536555.9515231199, 133523.1124676533], 
processed observation next is [1.0, 0.13043478260869565, 0.36419753086419776, 0.81, 1.0, 1.0, 0.3265800393365894, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1916271255439714, 0.1916271255439714, 0.2567752162839486], 
reward next is 0.7432, 
noisyNet noise sample is [array([0.28619385], dtype=float32), -0.8583414]. 
=============================================
[2019-03-23 23:29:39,739] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.7226060e-22 1.0000000e+00 1.8938072e-35 2.1645737e-32 5.1731904e-38], sum to 1.0000
[2019-03-23 23:29:39,749] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5970
[2019-03-23 23:29:39,754] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333334, 72.33333333333334, 1.0, 2.0, 0.9270772228811115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.104873322029591, 6.9112, 121.9251434954682, 1231855.019848199, 1132677.700013451, 227077.0317138919], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5992800.0000, 
sim time next is 5993400.0000, 
raw observation next is [24.01666666666667, 72.16666666666666, 1.0, 2.0, 0.9461865347100998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.216303478557458, 6.9112, 121.924583177494, 1309592.378238528, 1153353.997552218, 231484.2281856643], 
processed observation next is [1.0, 0.34782608695652173, 0.4450617283950618, 0.7216666666666666, 1.0, 1.0, 0.935936350845357, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.030510347855745756, 0.0, 0.8094524396684105, 0.46771156365661715, 0.41191214198293497, 0.4451619772801237], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.52162766], dtype=float32), -1.523329]. 
=============================================
[2019-03-23 23:29:41,344] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.9438735e-21 1.0000000e+00 1.1857408e-31 1.4796884e-28 4.1549129e-34], sum to 1.0000
[2019-03-23 23:29:41,351] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8649
[2019-03-23 23:29:41,356] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1719470.766469032 W.
[2019-03-23 23:29:41,361] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.0, 58.0, 1.0, 2.0, 0.7538974109946318, 1.0, 1.0, 0.7538974109946318, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1719470.766469032, 1719470.766469032, 325070.6734735682], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6019200.0000, 
sim time next is 6019800.0000, 
raw observation next is [29.0, 57.5, 1.0, 2.0, 0.5168429583340339, 1.0, 2.0, 0.5168429583340339, 1.0, 1.0, 0.822830822067804, 6.911199999999999, 6.9112, 121.94756008, 1768252.082673153, 1768252.082673153, 351932.6830119248], 
processed observation next is [1.0, 0.6956521739130435, 0.6296296296296297, 0.575, 1.0, 1.0, 0.42481304563575467, 1.0, 1.0, 0.42481304563575467, 1.0, 0.5, 0.7785385275847551, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6315186009546975, 0.6315186009546975, 0.6767936211767784], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.82618695], dtype=float32), -0.23707719]. 
=============================================
[2019-03-23 23:29:41,436] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2056390e-19 1.0000000e+00 2.3514696e-32 2.9324215e-30 5.8718073e-34], sum to 1.0000
[2019-03-23 23:29:41,454] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8002
[2019-03-23 23:29:41,465] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.53333333333333, 65.33333333333333, 1.0, 2.0, 0.5529586601478681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 648267.3397922567, 648267.3397922567, 151013.1439005953], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6119400.0000, 
sim time next is 6120000.0000, 
raw observation next is [27.4, 66.0, 1.0, 2.0, 0.5536011058846677, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 649183.6720128149, 649183.6720128149, 151126.4120770686], 
processed observation next is [1.0, 0.8695652173913043, 0.5703703703703703, 0.66, 1.0, 1.0, 0.4685727451007949, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2318513114331482, 0.2318513114331482, 0.29062771553282424], 
reward next is 0.7094, 
noisyNet noise sample is [array([-1.5586462], dtype=float32), 1.0124927]. 
=============================================
[2019-03-23 23:29:41,479] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[64.90646]
 [64.90646]
 [64.90646]
 [64.90646]
 [64.90646]], R is [[64.96676636]
 [65.02668762]
 [65.08657837]
 [65.14662933]
 [65.20659637]].
[2019-03-23 23:29:42,207] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2131167e-20 1.0000000e+00 3.7330027e-34 1.1420123e-33 3.3670991e-35], sum to 1.0000
[2019-03-23 23:29:42,216] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2573
[2019-03-23 23:29:42,221] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.8, 72.0, 1.0, 2.0, 0.5220135290974621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 618613.8887175892, 618613.8887175892, 146244.1373602733], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6038400.0000, 
sim time next is 6039000.0000, 
raw observation next is [25.7, 72.5, 1.0, 2.0, 0.5234370492894204, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 620516.0628820707, 620516.0628820707, 146481.4123678921], 
processed observation next is [1.0, 0.9130434782608695, 0.5074074074074074, 0.725, 1.0, 1.0, 0.4326631539159766, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22161287960073953, 0.22161287960073953, 0.2816950237844079], 
reward next is 0.7183, 
noisyNet noise sample is [array([0.553092], dtype=float32), -1.3993721]. 
=============================================
[2019-03-23 23:29:42,240] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[65.20268]
 [65.20268]
 [65.20268]
 [65.20268]
 [65.20268]], R is [[65.26896667]
 [65.33503723]
 [65.39987183]
 [65.46346283]
 [65.52585602]].
[2019-03-23 23:29:43,140] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.8978580e-23 1.0000000e+00 1.5736430e-35 3.9870619e-34 2.8788528e-38], sum to 1.0000
[2019-03-23 23:29:43,147] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8332
[2019-03-23 23:29:43,153] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.35, 69.5, 1.0, 2.0, 0.5302533657670122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 626787.686622951, 626787.686622951, 147511.1128162339], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6035400.0000, 
sim time next is 6036000.0000, 
raw observation next is [26.23333333333333, 70.0, 1.0, 2.0, 0.5293400796480651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 626073.4126661824, 626073.4126661824, 147377.7736004535], 
processed observation next is [1.0, 0.8695652173913043, 0.5271604938271603, 0.7, 1.0, 1.0, 0.43969057100960124, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22359764738077942, 0.22359764738077942, 0.28341879538548753], 
reward next is 0.7166, 
noisyNet noise sample is [array([-2.512039], dtype=float32), 0.034379143]. 
=============================================
[2019-03-23 23:29:43,174] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[72.54419]
 [72.54419]
 [72.54419]
 [72.54419]
 [72.54419]], R is [[72.53533173]
 [72.52630615]
 [72.51718903]
 [72.50801849]
 [72.49891663]].
[2019-03-23 23:29:48,077] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.45580363e-19 1.00000000e+00 7.54643816e-31 1.09002564e-29
 1.49122727e-33], sum to 1.0000
[2019-03-23 23:29:48,087] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6666
[2019-03-23 23:29:48,094] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.43333333333333, 88.33333333333334, 1.0, 2.0, 0.475554827198425, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 573824.6437426492, 573824.6437426488, 139338.6136655599], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6240000.0000, 
sim time next is 6240600.0000, 
raw observation next is [22.55, 88.0, 1.0, 2.0, 0.4777898343648187, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 575805.1345575597, 575805.1345575597, 139657.9259194042], 
processed observation next is [0.0, 0.21739130434782608, 0.3907407407407408, 0.88, 1.0, 1.0, 0.3783212313866889, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2056446909134142, 0.2056446909134142, 0.2685729344603927], 
reward next is 0.7314, 
noisyNet noise sample is [array([1.9066782], dtype=float32), -1.0988373]. 
=============================================
[2019-03-23 23:29:48,768] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0371469e-20 1.0000000e+00 4.3050130e-33 8.5281339e-32 6.8347298e-36], sum to 1.0000
[2019-03-23 23:29:48,773] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2630
[2019-03-23 23:29:48,781] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333333, 79.5, 1.0, 2.0, 0.5550750221022817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 649638.8875368255, 649638.8875368255, 151316.6023081745], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6253800.0000, 
sim time next is 6254400.0000, 
raw observation next is [25.46666666666667, 79.0, 1.0, 2.0, 0.5586581791003731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 653079.0110695895, 653079.0110695895, 151879.2896208795], 
processed observation next is [0.0, 0.391304347826087, 0.4987654320987655, 0.79, 1.0, 1.0, 0.47459307035758697, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23324250395342483, 0.23324250395342483, 0.29207555696322984], 
reward next is 0.7079, 
noisyNet noise sample is [array([0.16849795], dtype=float32), 1.0728892]. 
=============================================
[2019-03-23 23:29:49,237] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0402172e-21 1.0000000e+00 2.4098056e-32 3.0658816e-29 5.1402881e-35], sum to 1.0000
[2019-03-23 23:29:49,245] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9472
[2019-03-23 23:29:49,248] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.26666666666667, 89.83333333333333, 1.0, 2.0, 0.6817705807931385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 806847.8748639856, 806847.8748639851, 174107.2535097459], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6144600.0000, 
sim time next is 6145200.0000, 
raw observation next is [23.2, 90.0, 1.0, 2.0, 0.6960458077926773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 824485.5618943683, 824485.5618943683, 176848.8111045697], 
processed observation next is [1.0, 0.13043478260869565, 0.4148148148148148, 0.9, 1.0, 1.0, 0.6381497711817588, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29445912924798867, 0.29445912924798867, 0.3400938675087879], 
reward next is 0.6599, 
noisyNet noise sample is [array([0.80444294], dtype=float32), -0.82576025]. 
=============================================
[2019-03-23 23:29:55,281] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.3041523e-21 1.0000000e+00 6.3321511e-34 7.3373664e-32 2.5260191e-35], sum to 1.0000
[2019-03-23 23:29:55,288] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3221
[2019-03-23 23:29:55,292] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.5, 62.0, 1.0, 2.0, 0.6831113597142169, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 778543.9297498517, 778543.9297498526, 172971.080577509], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6375600.0000, 
sim time next is 6376200.0000, 
raw observation next is [30.36666666666667, 62.66666666666667, 1.0, 2.0, 0.6719545361535174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 765822.114639712, 765822.1146397116, 170902.7256122067], 
processed observation next is [0.0, 0.8260869565217391, 0.680246913580247, 0.6266666666666667, 1.0, 1.0, 0.6094696858970445, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27350789808561143, 0.27350789808561127, 0.3286590877157821], 
reward next is 0.6713, 
noisyNet noise sample is [array([-0.73113], dtype=float32), -0.28424677]. 
=============================================
[2019-03-23 23:29:57,909] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.1238468e-19 1.0000000e+00 2.5288865e-32 3.9855319e-31 1.6950815e-34], sum to 1.0000
[2019-03-23 23:29:57,921] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2117
[2019-03-23 23:29:57,930] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.16666666666666, 91.16666666666667, 1.0, 2.0, 0.8032794224526082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 915581.611321528, 915581.611321528, 196613.3504069104], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6421800.0000, 
sim time next is 6422400.0000, 
raw observation next is [25.2, 91.0, 1.0, 2.0, 0.818769208892621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 933247.6918610901, 933247.6918610901, 199843.2961964347], 
processed observation next is [1.0, 0.34782608695652173, 0.4888888888888889, 0.91, 1.0, 1.0, 0.7842490582055012, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3333027470932465, 0.3333027470932465, 0.3843140311469898], 
reward next is 0.6157, 
noisyNet noise sample is [array([0.12710589], dtype=float32), -1.6741775]. 
=============================================
[2019-03-23 23:29:58,070] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.6697010e-22 1.0000000e+00 1.2877858e-33 5.3928025e-32 2.2977819e-36], sum to 1.0000
[2019-03-23 23:29:58,077] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0096
[2019-03-23 23:29:58,085] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.08333333333333, 82.0, 1.0, 2.0, 0.57437858895987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 670359.4135574527, 670359.4135574527, 154467.795563397], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6303000.0000, 
sim time next is 6303600.0000, 
raw observation next is [24.9, 83.0, 1.0, 2.0, 0.5724344258834972, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 668607.05726827, 668607.05726827, 154162.1612150317], 
processed observation next is [0.0, 1.0, 0.47777777777777775, 0.83, 1.0, 1.0, 0.4909933641470205, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23878823473866784, 0.23878823473866784, 0.29646569464429173], 
reward next is 0.7035, 
noisyNet noise sample is [array([-0.0152412], dtype=float32), -0.56096125]. 
=============================================
[2019-03-23 23:30:09,169] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.2955971e-14 1.0000000e+00 4.0324979e-23 1.4985814e-21 9.7268453e-25], sum to 1.0000
[2019-03-23 23:30:09,176] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1608
[2019-03-23 23:30:09,179] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.23333333333333, 81.33333333333333, 1.0, 2.0, 0.6347137959352817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 724554.7749492117, 724554.7749492117, 164211.2268466518], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6562200.0000, 
sim time next is 6562800.0000, 
raw observation next is [26.2, 81.0, 1.0, 2.0, 0.6281916688901237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 718412.3070287661, 718412.3070287661, 163118.6191217076], 
processed observation next is [1.0, 1.0, 0.5259259259259259, 0.81, 1.0, 1.0, 0.5573710343930044, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25657582393884504, 0.25657582393884504, 0.31368965215713], 
reward next is 0.6863, 
noisyNet noise sample is [array([1.1474432], dtype=float32), 1.6661594]. 
=============================================
[2019-03-23 23:30:12,549] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.5560262e-20 1.0000000e+00 1.2710512e-32 2.4571123e-30 1.8869935e-34], sum to 1.0000
[2019-03-23 23:30:12,555] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3757
[2019-03-23 23:30:12,565] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.46666666666667, 46.16666666666667, 1.0, 2.0, 0.716426016812558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 906621.9537029372, 906621.9537029372, 182442.2316892932], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6599400.0000, 
sim time next is 6600000.0000, 
raw observation next is [25.63333333333334, 45.33333333333334, 1.0, 2.0, 0.676832836626076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 856595.6659612665, 856595.6659612665, 174753.2421855305], 
processed observation next is [1.0, 0.391304347826087, 0.5049382716049385, 0.4533333333333334, 1.0, 1.0, 0.6152771864596143, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.30592702355759516, 0.30592702355759516, 0.33606392727986634], 
reward next is 0.6639, 
noisyNet noise sample is [array([-1.8723955], dtype=float32), 0.30129755]. 
=============================================
[2019-03-23 23:30:12,598] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[68.56022]
 [68.56022]
 [68.56022]
 [68.56022]
 [68.56022]], R is [[68.53855133]
 [68.50231171]
 [68.47537231]
 [68.46114349]
 [68.44857788]].
[2019-03-23 23:30:14,952] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.7482328e-24 1.0000000e+00 4.1903042e-38 6.4921353e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 23:30:14,961] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8915
[2019-03-23 23:30:14,966] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.86666666666667, 48.66666666666667, 1.0, 2.0, 0.5830821874468506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 745291.6307558148, 745291.6307558148, 157706.2213339739], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6684000.0000, 
sim time next is 6684600.0000, 
raw observation next is [24.08333333333333, 47.83333333333334, 1.0, 2.0, 0.6066644298701489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 774970.2248256946, 774970.2248256941, 161860.0369295597], 
processed observation next is [1.0, 0.34782608695652173, 0.4475308641975307, 0.47833333333333344, 1.0, 1.0, 0.5317433688930344, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2767750802948909, 0.27677508029489073, 0.3112693017876148], 
reward next is 0.6887, 
noisyNet noise sample is [array([-0.02834492], dtype=float32), 0.38497224]. 
=============================================
[2019-03-23 23:30:15,537] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.8094122e-23 1.0000000e+00 1.0884221e-36 8.0571247e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 23:30:15,544] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1239
[2019-03-23 23:30:15,548] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.01666666666667, 50.16666666666666, 1.0, 2.0, 0.3600641518146885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 450192.4326572239, 450192.4326572234, 123216.9558788946], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6635400.0000, 
sim time next is 6636000.0000, 
raw observation next is [25.73333333333333, 52.33333333333333, 1.0, 2.0, 0.3651356704357238, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 455760.4741943211, 455760.4741943211, 123884.6923480905], 
processed observation next is [1.0, 0.8260869565217391, 0.5086419753086419, 0.5233333333333333, 1.0, 1.0, 0.2442091314710998, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16277159792654325, 0.16277159792654325, 0.2382397929770971], 
reward next is 0.7618, 
noisyNet noise sample is [array([-0.9479264], dtype=float32), 0.2705481]. 
=============================================
[2019-03-23 23:30:15,560] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[76.529686]
 [76.529686]
 [76.529686]
 [76.529686]
 [76.529686]], R is [[76.52615356]
 [76.52394104]
 [76.52265167]
 [76.52104187]
 [76.51916504]].
[2019-03-23 23:30:16,591] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-23 23:30:16,591] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:30:16,592] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:30:16,597] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:30:16,598] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:30:16,598] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:30:16,600] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:30:16,600] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:30:16,605] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:30:16,606] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:30:16,606] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:30:16,624] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run59
[2019-03-23 23:30:16,649] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run59
[2019-03-23 23:30:16,672] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run59
[2019-03-23 23:30:16,672] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run59
[2019-03-23 23:30:16,713] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run59
[2019-03-23 23:30:19,324] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.1289809]
[2019-03-23 23:30:19,325] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.41666666666667, 40.0, 1.0, 2.0, 0.4565563153739746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 589020.69633397, 589020.69633397, 121748.4048560516]
[2019-03-23 23:30:19,326] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:30:19,329] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.9605372e-21 1.0000000e+00 2.1164305e-34 1.0969070e-31 1.5176408e-36], sampled 0.21568654024213918
[2019-03-23 23:30:23,197] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.1289809]
[2019-03-23 23:30:23,198] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [17.85, 76.0, 1.0, 2.0, 0.2901050854207037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 374223.221659857, 374223.221659857, 106111.4888694486]
[2019-03-23 23:30:23,200] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:30:23,202] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.9605372e-21 1.0000000e+00 2.1164305e-34 1.0969070e-31 1.5176408e-36], sampled 0.09457367376805004
[2019-03-23 23:30:31,160] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.1289809]
[2019-03-23 23:30:31,164] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.75, 65.0, 1.0, 2.0, 0.3976572259977031, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 505322.3740186592, 505322.3740186592, 128482.6408956487]
[2019-03-23 23:30:31,166] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:30:31,168] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.9605372e-21 1.0000000e+00 2.1164305e-34 1.0969070e-31 1.5176408e-36], sampled 0.5492860393063667
[2019-03-23 23:30:50,119] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.1289809]
[2019-03-23 23:30:50,119] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.598994185, 82.00291870000001, 1.0, 2.0, 0.6104367146284757, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 704146.9520447906, 704146.9520447901, 160294.3150488565]
[2019-03-23 23:30:50,120] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:30:50,125] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.9605372e-21 1.0000000e+00 2.1164305e-34 1.0969070e-31 1.5176408e-36], sampled 0.8909155963049817
[2019-03-23 23:31:15,775] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.1289809]
[2019-03-23 23:31:15,776] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.83650112, 91.03129736, 1.0, 2.0, 0.4779293295357098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 570603.9793119262, 570603.9793119266, 139492.0699808557]
[2019-03-23 23:31:15,777] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:31:15,781] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.9605372e-21 1.0000000e+00 2.1164305e-34 1.0969070e-31 1.5176408e-36], sampled 0.8333531011916598
[2019-03-23 23:31:20,100] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.1289809]
[2019-03-23 23:31:20,102] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.55059731, 89.73684002333334, 1.0, 2.0, 0.4870678784885731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 584409.4970259875, 584409.4970259875, 141002.8864619354]
[2019-03-23 23:31:20,103] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:31:20,107] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.9605372e-21 1.0000000e+00 2.1164305e-34 1.0969070e-31 1.5176408e-36], sampled 0.1397563759543603
[2019-03-23 23:31:31,932] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.1289809]
[2019-03-23 23:31:31,933] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.28333333333333, 57.5, 1.0, 2.0, 0.8067429628664086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 919531.7391422294, 919531.7391422294, 197333.918063461]
[2019-03-23 23:31:31,935] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:31:31,938] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.9605372e-21 1.0000000e+00 2.1164305e-34 1.0969070e-31 1.5176408e-36], sampled 0.7669117939938308
[2019-03-23 23:31:55,847] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.1289809]
[2019-03-23 23:31:55,849] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [17.0, 94.0, 1.0, 2.0, 0.2656095379040365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 340901.5858191466, 340901.5858191466, 111430.770622106]
[2019-03-23 23:31:55,850] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:31:55,852] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.9605372e-21 1.0000000e+00 2.1164305e-34 1.0969070e-31 1.5176408e-36], sampled 0.8072632462719158
[2019-03-23 23:32:00,099] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:32:00,238] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:32:00,445] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:32:00,571] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:32:00,694] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:32:01,710] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1450000, evaluation results [1450000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:32:04,091] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2191422e-21 1.0000000e+00 1.5880383e-34 1.5285502e-31 3.1062478e-37], sum to 1.0000
[2019-03-23 23:32:04,101] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5755
[2019-03-23 23:32:04,107] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.75, 41.0, 1.0, 2.0, 0.3229142997061002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 408677.2588036184, 408677.2588036184, 118431.4545479875], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6723000.0000, 
sim time next is 6723600.0000, 
raw observation next is [26.5, 42.0, 1.0, 2.0, 0.3196574655663208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 404617.4127628648, 404617.4127628648, 118017.4986277596], 
processed observation next is [1.0, 0.8260869565217391, 0.5370370370370371, 0.42, 1.0, 1.0, 0.19006841138847713, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1445062188438803, 0.1445062188438803, 0.22695672813030693], 
reward next is 0.7730, 
noisyNet noise sample is [array([-1.2076105], dtype=float32), 0.62383515]. 
=============================================
[2019-03-23 23:32:07,477] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.870680e-19 1.000000e+00 2.842470e-31 3.484478e-29 6.343881e-33], sum to 1.0000
[2019-03-23 23:32:07,486] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6990
[2019-03-23 23:32:07,492] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.2, 49.0, 1.0, 2.0, 0.7291216822592888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 900330.7852725418, 900330.7852725418, 184534.9577121405], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6786000.0000, 
sim time next is 6786600.0000, 
raw observation next is [27.31666666666667, 48.83333333333334, 1.0, 2.0, 0.7942375288902727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 979964.474292484, 979964.474292484, 197864.2032669234], 
processed observation next is [1.0, 0.5652173913043478, 0.5672839506172841, 0.48833333333333345, 1.0, 1.0, 0.7550446772503245, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3499873122473157, 0.3499873122473157, 0.3805080832056219], 
reward next is 0.6195, 
noisyNet noise sample is [array([0.31529], dtype=float32), 0.59413517]. 
=============================================
[2019-03-23 23:32:12,804] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.0207575e-20 1.0000000e+00 6.4655980e-33 7.3931970e-31 1.3555215e-33], sum to 1.0000
[2019-03-23 23:32:12,811] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7816
[2019-03-23 23:32:12,816] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 65.0, 1.0, 2.0, 0.4219579989451635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 519351.7907946567, 519351.7907946563, 131672.2314362967], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6904800.0000, 
sim time next is 6905400.0000, 
raw observation next is [24.35, 65.5, 1.0, 2.0, 0.4200415444443932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 517455.4085878731, 517455.4085878731, 131407.1553783335], 
processed observation next is [0.0, 0.9565217391304348, 0.4574074074074075, 0.655, 1.0, 1.0, 0.3095732671957062, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18480550306709753, 0.18480550306709753, 0.25270606803525675], 
reward next is 0.7473, 
noisyNet noise sample is [array([-0.09082451], dtype=float32), -0.13356858]. 
=============================================
[2019-03-23 23:32:14,375] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3848341e-23 1.0000000e+00 5.7953209e-35 3.3464462e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 23:32:14,388] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7128
[2019-03-23 23:32:14,393] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.86666666666667, 67.33333333333333, 1.0, 2.0, 0.4867279917725896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 583972.640654034, 583972.6406540335, 140949.3080188289], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6946800.0000, 
sim time next is 6947400.0000, 
raw observation next is [26.13333333333333, 66.16666666666667, 1.0, 2.0, 0.4889754430994624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 586012.8494496302, 586012.8494496302, 141275.134411497], 
processed observation next is [0.0, 0.391304347826087, 0.5234567901234567, 0.6616666666666667, 1.0, 1.0, 0.39163743226126474, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20929030337486795, 0.20929030337486795, 0.2716829507913404], 
reward next is 0.7283, 
noisyNet noise sample is [array([0.21687485], dtype=float32), 0.23246604]. 
=============================================
[2019-03-23 23:32:17,976] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.8087444e-22 1.0000000e+00 4.2082678e-35 1.6207278e-31 3.9714359e-37], sum to 1.0000
[2019-03-23 23:32:17,985] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1300
[2019-03-23 23:32:17,988] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.13333333333333, 45.66666666666667, 1.0, 2.0, 0.5304304024066674, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 627150.8974876625, 627150.8974876625, 147545.7707461921], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6972000.0000, 
sim time next is 6972600.0000, 
raw observation next is [31.16666666666666, 44.83333333333334, 1.0, 2.0, 0.5224699979843507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 619433.0178980189, 619433.0178980189, 146328.1682468381], 
processed observation next is [0.0, 0.6956521739130435, 0.7098765432098764, 0.4483333333333334, 1.0, 1.0, 0.43151190236232223, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22122607782072104, 0.22122607782072104, 0.2814003235516117], 
reward next is 0.7186, 
noisyNet noise sample is [array([-1.0311875], dtype=float32), -0.55460256]. 
=============================================
[2019-03-23 23:32:35,607] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.5220246e-20 1.0000000e+00 9.0749266e-33 2.7568816e-28 3.3231013e-35], sum to 1.0000
[2019-03-23 23:32:35,615] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4259
[2019-03-23 23:32:35,617] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.4, 76.16666666666667, 1.0, 2.0, 0.7713333635002403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 940537.447827064, 940537.447827064, 192751.9676062395], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7297800.0000, 
sim time next is 7298400.0000, 
raw observation next is [23.6, 75.33333333333334, 1.0, 2.0, 0.8331981462974973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1014719.888952674, 1014719.888952674, 205801.5264782893], 
processed observation next is [1.0, 0.4782608695652174, 0.4296296296296297, 0.7533333333333334, 1.0, 1.0, 0.8014263646398778, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3623999603402407, 0.3623999603402407, 0.39577216630440254], 
reward next is 0.6042, 
noisyNet noise sample is [array([0.09912761], dtype=float32), 0.87344575]. 
=============================================
[2019-03-23 23:32:39,419] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.1487150e-22 1.0000000e+00 2.1795093e-35 1.0051194e-33 7.6648700e-38], sum to 1.0000
[2019-03-23 23:32:39,426] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0583
[2019-03-23 23:32:39,432] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.4, 74.0, 1.0, 2.0, 0.5079149310519315, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 603060.9020229867, 603060.9020229867, 144041.1699412817], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7480800.0000, 
sim time next is 7481400.0000, 
raw observation next is [25.36666666666667, 74.16666666666667, 1.0, 2.0, 0.5090661693607053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 604370.9376977647, 604370.9376977647, 144221.2705981578], 
processed observation next is [0.0, 0.6086956521739131, 0.49506172839506185, 0.7416666666666667, 1.0, 1.0, 0.4155549635246491, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2158467634634874, 0.2158467634634874, 0.2773485973041496], 
reward next is 0.7227, 
noisyNet noise sample is [array([0.6023552], dtype=float32), -1.4744802]. 
=============================================
[2019-03-23 23:32:44,873] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5763956e-19 1.0000000e+00 3.1251789e-31 5.1321700e-30 5.1397219e-34], sum to 1.0000
[2019-03-23 23:32:44,882] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3271
[2019-03-23 23:32:44,887] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 79.0, 1.0, 2.0, 0.4702041824265449, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 565518.8106887608, 565518.8106887604, 138458.6000358745], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7473600.0000, 
sim time next is 7474200.0000, 
raw observation next is [24.03333333333333, 78.66666666666667, 1.0, 2.0, 0.4742799967110004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 569714.0022569881, 569714.0022569876, 139056.3782969684], 
processed observation next is [0.0, 0.5217391304347826, 0.4456790123456789, 0.7866666666666667, 1.0, 1.0, 0.3741428532273814, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2034692865203529, 0.20346928652035273, 0.2674161121095546], 
reward next is 0.7326, 
noisyNet noise sample is [array([0.39987788], dtype=float32), -0.2268838]. 
=============================================
[2019-03-23 23:32:45,341] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.9036669e-21 1.0000000e+00 3.5856961e-34 5.6256308e-30 1.3828401e-36], sum to 1.0000
[2019-03-23 23:32:45,353] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6098
[2019-03-23 23:32:45,364] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.93333333333333, 76.0, 1.0, 2.0, 0.4986429131842278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 593700.0873311298, 593700.0873311298, 142643.5461764296], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7478400.0000, 
sim time next is 7479000.0000, 
raw observation next is [25.05, 75.5, 1.0, 2.0, 0.5009502607539799, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 596024.7641865816, 596024.7641865811, 142989.9042389468], 
processed observation next is [0.0, 0.5652173913043478, 0.48333333333333334, 0.755, 1.0, 1.0, 0.4058931675642617, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21286598720949343, 0.21286598720949326, 0.2749805850748977], 
reward next is 0.7250, 
noisyNet noise sample is [array([1.3565258], dtype=float32), 0.021442696]. 
=============================================
[2019-03-23 23:32:45,380] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[72.373856]
 [72.373856]
 [72.373856]
 [72.373856]
 [72.373856]], R is [[72.37513733]
 [72.3770752 ]
 [72.37969971]
 [72.38302612]
 [72.38721466]].
[2019-03-23 23:32:49,814] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.4407868e-21 1.0000000e+00 1.6287942e-35 2.6716277e-32 9.0848139e-37], sum to 1.0000
[2019-03-23 23:32:49,823] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7009
[2019-03-23 23:32:49,829] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 86.83333333333333, 1.0, 2.0, 0.4817097468288104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 576662.2134818739, 576662.2134818734, 140127.9247231103], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7552200.0000, 
sim time next is 7552800.0000, 
raw observation next is [23.3, 86.0, 1.0, 2.0, 0.4859719934882878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 580847.5959282393, 580847.5959282388, 140753.2304730742], 
processed observation next is [0.0, 0.43478260869565216, 0.41851851851851857, 0.86, 1.0, 1.0, 0.3880618970098664, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20744556997437116, 0.207445569974371, 0.27067928937129654], 
reward next is 0.7293, 
noisyNet noise sample is [array([-1.8906829], dtype=float32), 0.12757514]. 
=============================================
[2019-03-23 23:32:52,088] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 23:32:52,090] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:32:52,090] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:32:52,090] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:32:52,091] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:32:52,093] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:32:52,094] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:32:52,095] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:32:52,096] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:32:52,093] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:32:52,097] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:32:52,117] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run60
[2019-03-23 23:32:52,142] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run60
[2019-03-23 23:32:52,165] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run60
[2019-03-23 23:32:52,190] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run60
[2019-03-23 23:32:52,212] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run60
[2019-03-23 23:33:00,305] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.09576237]
[2019-03-23 23:33:00,306] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.14903594666666, 56.58958977666667, 1.0, 2.0, 0.433835551996154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 540713.8163173919, 540713.8163173919, 133555.0301789533]
[2019-03-23 23:33:00,308] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:33:00,314] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.7742515e-21 1.0000000e+00 6.5047564e-34 3.0677737e-31 4.7335204e-36], sampled 0.4602794014640257
[2019-03-23 23:33:24,615] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.09576237]
[2019-03-23 23:33:24,616] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.27385818, 66.03815365666667, 1.0, 2.0, 0.7449726169545073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 849086.4295646114, 849086.4295646114, 184838.5956666217]
[2019-03-23 23:33:24,617] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:33:24,620] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.7742515e-21 1.0000000e+00 6.5047564e-34 3.0677737e-31 4.7335204e-36], sampled 0.25600945998804503
[2019-03-23 23:34:03,470] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.09576237]
[2019-03-23 23:34:03,472] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [35.08333333333333, 33.5, 1.0, 2.0, 0.3535151866672803, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5637794035184254, 6.911199999999999, 6.9112, 121.9260426156618, 819085.2491833379, 819085.2491833384, 209927.1833675445]
[2019-03-23 23:34:03,473] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:34:03,476] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.7742515e-21 1.0000000e+00 6.5047564e-34 3.0677737e-31 4.7335204e-36], sampled 0.7077816242250858
[2019-03-23 23:34:34,691] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.09576237]
[2019-03-23 23:34:34,692] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.03333333333333, 77.83333333333333, 1.0, 2.0, 0.3940818363557475, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 488483.7506131884, 488483.7506131879, 127793.0342199231]
[2019-03-23 23:34:34,693] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:34:34,697] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.7742515e-21 1.0000000e+00 6.5047564e-34 3.0677737e-31 4.7335204e-36], sampled 0.38580907352829996
[2019-03-23 23:34:35,861] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:34:35,867] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:34:36,039] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:34:36,120] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:34:36,184] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:34:37,199] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1475000, evaluation results [1475000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:34:43,182] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.2953178e-23 1.0000000e+00 2.9601732e-36 2.4461254e-36 3.5622391e-38], sum to 1.0000
[2019-03-23 23:34:43,189] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4922
[2019-03-23 23:34:43,193] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 92.83333333333333, 1.0, 2.0, 0.352173983134784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 444888.3057832611, 444888.3057832611, 122232.1484560356], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7711800.0000, 
sim time next is 7712400.0000, 
raw observation next is [18.73333333333333, 92.66666666666667, 1.0, 2.0, 0.3360453597767015, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 424267.6619005947, 424267.6619005951, 120111.0106271922], 
processed observation next is [1.0, 0.2608695652173913, 0.2493827160493826, 0.9266666666666667, 1.0, 1.0, 0.209577809257978, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1515241649644981, 0.15152416496449825, 0.2309827127446004], 
reward next is 0.7690, 
noisyNet noise sample is [array([0.08826587], dtype=float32), 0.6006255]. 
=============================================
[2019-03-23 23:34:46,129] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.663712e-20 1.000000e+00 1.463151e-30 4.814191e-29 2.070197e-34], sum to 1.0000
[2019-03-23 23:34:46,137] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2925
[2019-03-23 23:34:46,144] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.73333333333333, 73.5, 1.0, 2.0, 0.3619363718991192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 453802.5307229271, 453802.5307229271, 123489.5477503866], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7771800.0000, 
sim time next is 7772400.0000, 
raw observation next is [21.6, 74.0, 1.0, 2.0, 0.3593850072072591, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 450932.9640814707, 450932.9640814702, 123152.5108845496], 
processed observation next is [1.0, 1.0, 0.3555555555555556, 0.74, 1.0, 1.0, 0.23736310381816558, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1610474871719538, 0.16104748717195363, 0.23683175170105691], 
reward next is 0.7632, 
noisyNet noise sample is [array([0.07379913], dtype=float32), -0.6029691]. 
=============================================
[2019-03-23 23:34:46,278] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.3890692e-21 1.0000000e+00 1.9122189e-33 3.0723909e-29 1.7244683e-36], sum to 1.0000
[2019-03-23 23:34:46,287] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8825
[2019-03-23 23:34:46,296] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 73.0, 1.0, 2.0, 0.3316657855138477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 419229.2225528349, 419229.2225528349, 119549.3300173369], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7781400.0000, 
sim time next is 7782000.0000, 
raw observation next is [21.06666666666667, 73.0, 1.0, 2.0, 0.3308150876052203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 418304.4996521823, 418304.4996521823, 119441.1669981053], 
processed observation next is [1.0, 0.043478260869565216, 0.3358024691358026, 0.73, 1.0, 1.0, 0.20335129476811944, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14939446416149366, 0.14939446416149366, 0.22969455191943328], 
reward next is 0.7703, 
noisyNet noise sample is [array([-0.5408368], dtype=float32), 0.6765523]. 
=============================================
[2019-03-23 23:34:46,324] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[73.463776]
 [73.463776]
 [73.463776]
 [73.463776]
 [73.463776]], R is [[73.49944305]
 [73.5345459 ]
 [73.56903839]
 [73.60279083]
 [73.63576508]].
[2019-03-23 23:34:49,620] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.7374114e-18 1.0000000e+00 9.3115812e-29 3.3996518e-26 7.3057256e-31], sum to 1.0000
[2019-03-23 23:34:49,624] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8657
[2019-03-23 23:34:49,630] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.93333333333333, 41.33333333333334, 1.0, 2.0, 0.4091549251431876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 500118.7458453889, 500118.7458453889, 129742.674912124], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7839600.0000, 
sim time next is 7840200.0000, 
raw observation next is [29.61666666666667, 42.66666666666667, 1.0, 2.0, 0.4145733930649294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 506587.7141664608, 506587.7141664608, 130510.800385288], 
processed observation next is [1.0, 0.7391304347826086, 0.6524691358024692, 0.4266666666666667, 1.0, 1.0, 0.303063563172535, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18092418363087887, 0.18092418363087887, 0.25098230843324615], 
reward next is 0.7490, 
noisyNet noise sample is [array([0.3931901], dtype=float32), 0.82377714]. 
=============================================
[2019-03-23 23:34:50,824] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:34:50,825] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:34:50,895] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run8
[2019-03-23 23:34:52,027] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.2105697e-19 1.0000000e+00 1.4469704e-31 4.6221235e-28 2.6256854e-33], sum to 1.0000
[2019-03-23 23:34:52,032] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4078
[2019-03-23 23:34:52,036] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.05, 80.5, 1.0, 2.0, 0.3772391890156974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 471486.9247574077, 471486.9247574077, 125541.3497245326], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7885800.0000, 
sim time next is 7886400.0000, 
raw observation next is [21.2, 79.66666666666667, 1.0, 2.0, 0.3769649346937184, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 470918.9867755907, 470918.9867755907, 125499.6869397929], 
processed observation next is [1.0, 0.2608695652173913, 0.34074074074074073, 0.7966666666666667, 1.0, 1.0, 0.25829158892109333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16818535241985383, 0.16818535241985383, 0.24134555180729403], 
reward next is 0.7587, 
noisyNet noise sample is [array([0.30757162], dtype=float32), 0.6883286]. 
=============================================
[2019-03-23 23:34:54,197] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:34:54,198] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:34:54,266] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run8
[2019-03-23 23:34:55,057] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:34:55,058] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:34:55,078] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run8
[2019-03-23 23:34:55,186] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:34:55,187] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:34:55,198] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run8
[2019-03-23 23:34:55,606] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:34:55,606] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:34:55,614] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run8
[2019-03-23 23:34:55,901] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:34:55,901] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:34:55,909] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run8
[2019-03-23 23:34:55,929] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:34:55,930] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:34:55,938] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run8
[2019-03-23 23:34:55,991] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:34:55,992] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:34:55,996] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run8
[2019-03-23 23:34:56,027] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:34:56,028] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:34:56,034] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run8
[2019-03-23 23:34:56,063] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:34:56,064] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:34:56,063] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:34:56,065] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:34:56,073] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run8
[2019-03-23 23:34:56,101] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run8
[2019-03-23 23:34:56,102] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:34:56,129] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:34:56,139] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run8
[2019-03-23 23:34:56,305] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:34:56,305] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:34:56,308] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run8
[2019-03-23 23:34:56,337] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:34:56,338] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:34:56,357] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run8
[2019-03-23 23:34:56,390] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:34:56,391] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:34:56,395] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run8
[2019-03-23 23:34:56,569] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:34:56,569] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:34:56,572] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run8
[2019-03-23 23:34:58,483] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.4027511e-24 1.0000000e+00 3.3844399e-38 3.6535294e-35 0.0000000e+00], sum to 1.0000
[2019-03-23 23:34:58,488] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7123
[2019-03-23 23:34:58,492] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.73333333333333, 62.66666666666667, 1.0, 2.0, 0.3736403854946415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 466690.7862741298, 466690.7862741298, 125043.771241754], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 202800.0000, 
sim time next is 203400.0000, 
raw observation next is [24.1, 60.0, 1.0, 2.0, 0.3733642525189765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 466794.668473474, 466794.668473474, 125014.2210369136], 
processed observation next is [0.0, 0.34782608695652173, 0.4481481481481482, 0.6, 1.0, 1.0, 0.25400506252259103, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16671238159766927, 0.16671238159766927, 0.24041196353252617], 
reward next is 0.7596, 
noisyNet noise sample is [array([0.18105094], dtype=float32), 0.1377893]. 
=============================================
[2019-03-23 23:35:04,813] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.5941275e-16 1.0000000e+00 9.9960155e-27 4.1620706e-25 3.3829727e-28], sum to 1.0000
[2019-03-23 23:35:04,817] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8964
[2019-03-23 23:35:04,826] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1714681.710117094 W.
[2019-03-23 23:35:04,830] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [37.4, 14.5, 1.0, 2.0, 0.4734794804422202, 1.0, 1.0, 0.4734794804422202, 1.0, 2.0, 0.7670049271559057, 6.9112, 6.9112, 121.94756008, 1714681.710117094, 1714681.710117094, 330155.1879690009], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 137400.0000, 
sim time next is 138000.0000, 
raw observation next is [37.4, 14.0, 1.0, 2.0, 0.4347376933357084, 1.0, 2.0, 0.4347376933357084, 1.0, 2.0, 0.7037655781999286, 6.911199999999999, 6.9112, 121.94756008, 1572563.900982334, 1572563.900982335, 312081.7646766208], 
processed observation next is [1.0, 0.6086956521739131, 0.9407407407407407, 0.14, 1.0, 1.0, 0.32706868254251004, 1.0, 1.0, 0.32706868254251004, 1.0, 1.0, 0.6297069727499107, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5616299646365479, 0.5616299646365482, 0.6001572397627323], 
reward next is 0.3998, 
noisyNet noise sample is [array([0.9554441], dtype=float32), -0.18247189]. 
=============================================
[2019-03-23 23:35:04,856] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[53.871174]
 [53.871174]
 [53.871174]
 [53.871174]
 [53.871174]], R is [[53.73230362]
 [53.19498062]
 [52.66303253]
 [52.60079956]
 [52.51187134]].
[2019-03-23 23:35:04,886] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.1684586e-16 1.0000000e+00 8.6514707e-24 3.8086661e-25 1.0047775e-27], sum to 1.0000
[2019-03-23 23:35:04,900] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6615
[2019-03-23 23:35:04,904] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1395665.887000779 W.
[2019-03-23 23:35:04,907] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [35.86666666666667, 21.0, 1.0, 2.0, 0.3883766046693281, 1.0, 1.0, 0.3883766046693281, 1.0, 1.0, 0.6263691695090262, 6.9112, 6.9112, 121.94756008, 1395665.887000779, 1395665.887000779, 291621.3284518757], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 134400.0000, 
sim time next is 135000.0000, 
raw observation next is [36.25, 19.5, 1.0, 2.0, 0.5849718506015598, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9505766602691309, 6.9112, 6.9112, 121.9260425222375, 1418534.220414412, 1418534.220414412, 285537.4983345655], 
processed observation next is [1.0, 0.5652173913043478, 0.8981481481481481, 0.195, 1.0, 1.0, 0.5059188697637617, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9382208253364135, 0.0, 0.0, 0.8094621281998957, 0.5066193644337186, 0.5066193644337186, 0.5491105737203182], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.4353837], dtype=float32), 1.0125815]. 
=============================================
[2019-03-23 23:35:04,918] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[52.687855]
 [52.687855]
 [52.687855]
 [52.687855]
 [52.687855]], R is [[52.16098022]
 [52.07855988]
 [51.55777359]
 [51.04219818]
 [51.0306015 ]].
[2019-03-23 23:35:07,779] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.8220200e-22 1.0000000e+00 4.0621918e-36 3.8817087e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 23:35:07,786] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6189
[2019-03-23 23:35:07,792] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.2, 35.0, 1.0, 2.0, 0.7052131157444003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 905575.2641721091, 905575.2641721091, 180295.3343873203], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 378000.0000, 
sim time next is 378600.0000, 
raw observation next is [26.4, 34.5, 1.0, 2.0, 0.8563181533836159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.922452020368901, 6.9112, 121.926002644575, 1104591.097022721, 1098829.058788648, 211932.8331543257], 
processed observation next is [1.0, 0.391304347826087, 0.5333333333333333, 0.345, 1.0, 1.0, 0.8289501825995428, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.001125202036890105, 0.0, 0.8094618634536865, 0.3944968203652575, 0.39243894956737435, 0.40756314068139554], 
reward next is 0.5362, 
noisyNet noise sample is [array([0.3817604], dtype=float32), 0.5800808]. 
=============================================
[2019-03-23 23:35:07,924] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.4895703e-21 1.0000000e+00 1.4008663e-35 7.1549866e-34 0.0000000e+00], sum to 1.0000
[2019-03-23 23:35:07,930] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5337
[2019-03-23 23:35:07,936] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.53333333333333, 62.66666666666667, 1.0, 2.0, 0.2758124172645286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 352818.342948971, 352818.3429489706, 112640.5830024893], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 196800.0000, 
sim time next is 197400.0000, 
raw observation next is [21.71666666666667, 63.33333333333334, 1.0, 2.0, 0.2890031201017073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 368726.3042126098, 368726.3042126098, 114227.5748342838], 
processed observation next is [0.0, 0.2608695652173913, 0.3598765432098766, 0.6333333333333334, 1.0, 1.0, 0.153575142978223, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13168796579021777, 0.13168796579021777, 0.21966841314285346], 
reward next is 0.7803, 
noisyNet noise sample is [array([1.8567653], dtype=float32), -0.104999594]. 
=============================================
[2019-03-23 23:35:09,899] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1197202e-23 1.0000000e+00 9.8497100e-36 6.1804731e-32 1.3867068e-36], sum to 1.0000
[2019-03-23 23:35:09,910] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2335
[2019-03-23 23:35:09,916] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.7, 30.0, 1.0, 2.0, 0.3491575094536404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 441810.1954580632, 441810.1954580627, 121840.1301233473], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 212400.0000, 
sim time next is 213000.0000, 
raw observation next is [29.9, 29.0, 1.0, 2.0, 0.3511401849507769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 444736.4876184459, 444736.4876184454, 122106.7823266648], 
processed observation next is [0.0, 0.4782608695652174, 0.6629629629629629, 0.29, 1.0, 1.0, 0.22754783922711538, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15883445986373068, 0.15883445986373051, 0.23482073524358615], 
reward next is 0.7652, 
noisyNet noise sample is [array([1.8849696], dtype=float32), 0.7669928]. 
=============================================
[2019-03-23 23:35:09,935] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[75.08576]
 [75.08576]
 [75.08576]
 [75.08576]
 [75.08576]], R is [[75.10009766]
 [75.11479187]
 [75.13014221]
 [75.14616394]
 [75.16251373]].
[2019-03-23 23:35:15,969] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.7456405e-22 1.0000000e+00 2.0382551e-36 1.4120918e-33 1.3274402e-38], sum to 1.0000
[2019-03-23 23:35:15,977] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1021
[2019-03-23 23:35:15,983] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.2, 53.0, 1.0, 2.0, 0.2615382937437919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 337365.170336205, 337365.170336205, 101830.890899253], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 351600.0000, 
sim time next is 352200.0000, 
raw observation next is [21.05, 53.5, 1.0, 2.0, 0.2599338504763279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 335295.104080551, 335295.1040805514, 101023.4111809151], 
processed observation next is [1.0, 0.043478260869565216, 0.3351851851851852, 0.535, 1.0, 1.0, 0.11896886961467605, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.11974825145733965, 0.11974825145733979, 0.19427579073252904], 
reward next is 0.8057, 
noisyNet noise sample is [array([0.02593047], dtype=float32), 1.2334367]. 
=============================================
[2019-03-23 23:35:16,695] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.4449164e-21 1.0000000e+00 2.9181987e-34 2.5602109e-31 1.6766246e-34], sum to 1.0000
[2019-03-23 23:35:16,702] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9911
[2019-03-23 23:35:16,706] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.26666666666667, 42.5, 1.0, 2.0, 0.2948447231550033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 379576.7782969117, 379576.7782969113, 114933.6176163639], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 339000.0000, 
sim time next is 339600.0000, 
raw observation next is [24.13333333333334, 43.0, 1.0, 2.0, 0.2932592385387378, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 377608.8539673844, 377608.853967384, 114738.8258633974], 
processed observation next is [0.0, 0.9565217391304348, 0.44938271604938296, 0.43, 1.0, 1.0, 0.15864195064135453, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13486030498835155, 0.13486030498835144, 0.22065158819884115], 
reward next is 0.7793, 
noisyNet noise sample is [array([0.31983438], dtype=float32), 1.529574]. 
=============================================
[2019-03-23 23:35:17,814] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.0834424e-20 1.0000000e+00 2.4388919e-31 4.2539532e-31 7.7593537e-33], sum to 1.0000
[2019-03-23 23:35:17,818] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5650
[2019-03-23 23:35:17,821] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 33.0, 1.0, 2.0, 0.8785276766560056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.065579698004341, 6.9112, 121.9252469810476, 1204442.6346488, 1125386.946855037, 216928.3481791435], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 380400.0000, 
sim time next is 381000.0000, 
raw observation next is [27.2, 32.5, 1.0, 2.0, 0.8850200766303133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.107572117701318, 6.9112, 121.9250273248542, 1233738.055122334, 1133178.816692729, 218404.487276441], 
processed observation next is [1.0, 0.391304347826087, 0.5629629629629629, 0.325, 1.0, 1.0, 0.8631191388456111, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.019637211770131825, 0.0, 0.8094553883450015, 0.44062073397226215, 0.40470672024740323, 0.42000862937777117], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0085473], dtype=float32), -0.967569]. 
=============================================
[2019-03-23 23:35:17,835] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[68.16902]
 [68.16902]
 [68.16902]
 [68.16902]
 [68.16902]], R is [[67.48733521]
 [66.81246185]
 [66.21473694]
 [65.75644684]
 [65.63506317]].
[2019-03-23 23:35:24,081] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.8541920e-16 1.0000000e+00 5.8879103e-27 1.0898147e-27 1.0855866e-27], sum to 1.0000
[2019-03-23 23:35:24,088] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5350
[2019-03-23 23:35:24,093] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.43333333333334, 60.0, 1.0, 2.0, 0.3160305094084779, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 402109.2255081561, 402109.2255081561, 117574.2411973744], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 519000.0000, 
sim time next is 519600.0000, 
raw observation next is [22.26666666666667, 61.0, 1.0, 2.0, 0.3147786804676075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 400522.5666754185, 400522.5666754185, 117416.1749293681], 
processed observation next is [1.0, 0.0, 0.38024691358024704, 0.61, 1.0, 1.0, 0.18426033389000893, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14304377381264946, 0.14304377381264946, 0.22580033640263097], 
reward next is 0.7742, 
noisyNet noise sample is [array([-1.0956981], dtype=float32), 0.59126335]. 
=============================================
[2019-03-23 23:35:28,593] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 23:35:28,594] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:35:28,596] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:35:28,596] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:35:28,597] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:35:28,597] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:35:28,599] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:35:28,599] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:35:28,600] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:35:28,601] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:35:28,601] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:35:28,623] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run61
[2019-03-23 23:35:28,646] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run61
[2019-03-23 23:35:28,672] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run61
[2019-03-23 23:35:28,673] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run61
[2019-03-23 23:35:28,699] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run61
[2019-03-23 23:35:33,039] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.12254217]
[2019-03-23 23:35:33,040] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.7, 25.0, 1.0, 2.0, 0.737083903729455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 937177.8583676567, 937177.8583676567, 186607.1592083515]
[2019-03-23 23:35:33,041] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:35:33,043] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0167745e-16 1.0000000e+00 1.1904255e-26 1.3380499e-24 1.8763614e-28], sampled 0.12219440097361012
[2019-03-23 23:35:56,187] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.12254217]
[2019-03-23 23:35:56,188] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.611063805, 87.40978258, 1.0, 2.0, 0.5359200404656922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 632496.2500775654, 632496.250077565, 148391.3993094037]
[2019-03-23 23:35:56,189] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:35:56,191] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0167745e-16 1.0000000e+00 1.1904255e-26 1.3380499e-24 1.8763614e-28], sampled 0.8077081064100496
[2019-03-23 23:36:14,721] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.12254217]
[2019-03-23 23:36:14,725] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.65483531333333, 88.97198906333334, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.646996211902877, 6.9112, 121.9233903352824, 1539859.420876483, 1163074.192122045, 245582.5154586127]
[2019-03-23 23:36:14,725] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:36:14,728] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0167745e-16 1.0000000e+00 1.1904255e-26 1.3380499e-24 1.8763614e-28], sampled 0.26005231163859965
[2019-03-23 23:36:14,729] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1539859.420876483 W.
[2019-03-23 23:36:35,602] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.12254217]
[2019-03-23 23:36:35,603] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.0, 94.0, 1.0, 2.0, 0.4501904084376673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 549080.8044080362, 549080.8044080362, 135687.814599654]
[2019-03-23 23:36:35,606] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:36:35,608] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0167745e-16 1.0000000e+00 1.1904255e-26 1.3380499e-24 1.8763614e-28], sampled 0.1285372515796167
[2019-03-23 23:37:05,916] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.12254217]
[2019-03-23 23:37:05,917] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.75678834, 108.1553746, 1.0, 2.0, 0.4662245942911978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 565717.3745025662, 565717.3745025662, 138016.8892798269]
[2019-03-23 23:37:05,918] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:37:05,922] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0167745e-16 1.0000000e+00 1.1904255e-26 1.3380499e-24 1.8763614e-28], sampled 0.17655450381383375
[2019-03-23 23:37:15,600] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:37:16,016] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:37:16,050] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:37:16,097] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:37:16,178] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:37:17,196] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1500000, evaluation results [1500000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:37:18,376] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.1304061e-20 1.0000000e+00 3.6251963e-34 1.5587236e-29 1.2659013e-34], sum to 1.0000
[2019-03-23 23:37:18,381] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2891
[2019-03-23 23:37:18,387] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.86666666666667, 69.0, 1.0, 2.0, 0.3230788798158899, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 411906.1307011053, 411906.1307011053, 118473.597007768], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 624000.0000, 
sim time next is 624600.0000, 
raw observation next is [21.15, 68.0, 1.0, 2.0, 0.3229368530072219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 411200.3109799944, 411200.310979994, 118453.2016037369], 
processed observation next is [1.0, 0.21739130434782608, 0.33888888888888885, 0.68, 1.0, 1.0, 0.19397244405621655, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14685725392142657, 0.14685725392142643, 0.2277946184687248], 
reward next is 0.7722, 
noisyNet noise sample is [array([-1.0327083], dtype=float32), 1.5337583]. 
=============================================
[2019-03-23 23:37:27,251] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.7218925e-23 1.0000000e+00 2.3746935e-37 1.3536701e-35 1.6618611e-38], sum to 1.0000
[2019-03-23 23:37:27,260] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6769
[2019-03-23 23:37:27,264] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1344991.444706192 W.
[2019-03-23 23:37:27,272] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.11666666666667, 23.0, 1.0, 2.0, 0.5387585317003505, 0.0, 2.0, 0.0, 1.0, 1.0, 0.901968420634172, 6.911200000000001, 6.9112, 121.9256987871629, 1344991.444706192, 1344991.444706192, 265808.3787260835], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 744600.0000, 
sim time next is 745200.0000, 
raw observation next is [32.1, 23.0, 1.0, 2.0, 0.3392018790147442, 1.0, 1.0, 0.3392018790147442, 1.0, 2.0, 0.5592406511286143, 6.911200000000001, 6.9112, 121.94756008, 1254274.250855399, 1254274.250855399, 269725.6194357884], 
processed observation next is [1.0, 0.6521739130434783, 0.7444444444444445, 0.23, 1.0, 1.0, 0.21333557025564784, 1.0, 0.5, 0.21333557025564784, 1.0, 1.0, 0.44905081391076784, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.44795508959121394, 0.44795508959121394, 0.5187031142995931], 
reward next is 0.4813, 
noisyNet noise sample is [array([-0.73372954], dtype=float32), -0.005924583]. 
=============================================
[2019-03-23 23:37:31,414] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2001640e-20 1.0000000e+00 5.2847625e-33 4.3013774e-29 1.1262768e-34], sum to 1.0000
[2019-03-23 23:37:31,423] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8097
[2019-03-23 23:37:31,427] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.1, 47.66666666666667, 1.0, 2.0, 0.3954460906278995, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 491146.1886505549, 491146.1886505549, 128005.1723881358], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 854400.0000, 
sim time next is 855000.0000, 
raw observation next is [26.95, 48.5, 1.0, 2.0, 0.396357532697983, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 492099.3568467219, 492099.3568467214, 128129.1466800857], 
processed observation next is [0.0, 0.9130434782608695, 0.5537037037037037, 0.485, 1.0, 1.0, 0.28137801511664645, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1757497703024007, 0.1757497703024005, 0.24640220515401096], 
reward next is 0.7536, 
noisyNet noise sample is [array([2.1157184], dtype=float32), -0.7463286]. 
=============================================
[2019-03-23 23:37:31,440] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[69.58281]
 [69.58281]
 [69.58281]
 [69.58281]
 [69.58281]], R is [[69.64058685]
 [69.69802094]
 [69.7555542 ]
 [69.8130188 ]
 [69.87001038]].
[2019-03-23 23:37:32,981] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.9024749e-22 1.0000000e+00 9.9455681e-37 2.3980493e-32 1.8265485e-38], sum to 1.0000
[2019-03-23 23:37:32,991] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3267
[2019-03-23 23:37:32,995] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 66.66666666666666, 1.0, 2.0, 0.3777076126603642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 472213.9591076591, 472213.9591076591, 125608.0280243821], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 870000.0000, 
sim time next is 870600.0000, 
raw observation next is [22.85, 67.33333333333334, 1.0, 2.0, 0.3760173133404075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 470351.7461778418, 470351.7461778413, 125380.9151805746], 
processed observation next is [0.0, 0.043478260869565216, 0.4018518518518519, 0.6733333333333335, 1.0, 1.0, 0.2571634682623899, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16798276649208635, 0.16798276649208618, 0.24111714457802808], 
reward next is 0.7589, 
noisyNet noise sample is [array([-0.85647196], dtype=float32), 0.749904]. 
=============================================
[2019-03-23 23:37:33,089] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.3059401e-22 1.0000000e+00 5.7428558e-35 1.7438679e-32 1.0585745e-37], sum to 1.0000
[2019-03-23 23:37:33,095] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3283
[2019-03-23 23:37:33,104] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.06666666666667, 65.16666666666667, 1.0, 2.0, 0.305672672079111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 390975.8709444478, 390975.8709444478, 116280.8449591544], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 882600.0000, 
sim time next is 883200.0000, 
raw observation next is [21.13333333333333, 65.33333333333334, 1.0, 2.0, 0.3077348920318592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 393305.6928160409, 393305.6928160409, 116537.8975447615], 
processed observation next is [0.0, 0.21739130434782608, 0.33827160493827146, 0.6533333333333334, 1.0, 1.0, 0.17587487146649908, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14046631886287175, 0.14046631886287175, 0.22411134143223363], 
reward next is 0.7759, 
noisyNet noise sample is [array([0.35327578], dtype=float32), 1.7591527]. 
=============================================
[2019-03-23 23:37:33,666] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.8754422e-21 1.0000000e+00 1.5315639e-36 1.4310124e-32 8.4667137e-38], sum to 1.0000
[2019-03-23 23:37:33,676] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2843
[2019-03-23 23:37:33,681] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 57.0, 1.0, 2.0, 0.4192729844643435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 515774.1423784401, 515774.1423784406, 131277.8143019638], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 907200.0000, 
sim time next is 907800.0000, 
raw observation next is [26.2, 56.16666666666666, 1.0, 2.0, 0.4216157862236242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 518280.1528528815, 518280.152852881, 131606.123372143], 
processed observation next is [0.0, 0.5217391304347826, 0.5259259259259259, 0.5616666666666665, 1.0, 1.0, 0.3114473645519336, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18510005459031484, 0.18510005459031464, 0.25308869879258267], 
reward next is 0.7469, 
noisyNet noise sample is [array([1.7251643], dtype=float32), -0.5458799]. 
=============================================
[2019-03-23 23:37:38,208] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3295289e-22 1.0000000e+00 1.1170140e-33 6.4549798e-32 5.4975189e-36], sum to 1.0000
[2019-03-23 23:37:38,215] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4140
[2019-03-23 23:37:38,218] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 56.0, 1.0, 2.0, 0.8958566374520227, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.017244180546533, 6.9112, 121.9251769928308, 1170722.885198941, 1116419.172173719, 220484.2654805399], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 990000.0000, 
sim time next is 990600.0000, 
raw observation next is [25.03333333333333, 55.83333333333334, 1.0, 2.0, 0.7928269468090167, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9259787067103, 987695.0187516782, 987695.0187516777, 197801.9509295397], 
processed observation next is [1.0, 0.4782608695652174, 0.482716049382716, 0.5583333333333335, 1.0, 1.0, 0.753365412867877, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094617045311586, 0.3527482209827422, 0.35274822098274206, 0.3803883671721917], 
reward next is 0.6196, 
noisyNet noise sample is [array([1.4502261], dtype=float32), 1.4538925]. 
=============================================
[2019-03-23 23:37:52,089] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.0147829e-21 1.0000000e+00 3.7966106e-33 1.9111581e-29 1.7780903e-35], sum to 1.0000
[2019-03-23 23:37:52,098] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7023
[2019-03-23 23:37:52,103] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.91666666666667, 27.66666666666666, 1.0, 2.0, 0.3576033788033732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 450874.6708758818, 450874.6708758818, 122945.1460309329], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1421400.0000, 
sim time next is 1422000.0000, 
raw observation next is [31.1, 27.0, 1.0, 2.0, 0.359358068999974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 453230.9300340283, 453230.9300340283, 123181.8489391798], 
processed observation next is [0.0, 0.4782608695652174, 0.7074074074074075, 0.27, 1.0, 1.0, 0.2373310345237786, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16186818929786725, 0.16186818929786725, 0.23688817103688425], 
reward next is 0.7631, 
noisyNet noise sample is [array([0.55517113], dtype=float32), -0.5507075]. 
=============================================
[2019-03-23 23:37:52,121] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[71.70168]
 [71.70168]
 [71.70168]
 [71.70168]
 [71.70168]], R is [[71.74777985]
 [71.79386902]
 [71.83988953]
 [71.88577271]
 [71.93147278]].
[2019-03-23 23:37:58,443] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2515124e-17 1.0000000e+00 1.6030279e-28 3.4948649e-27 5.6617131e-30], sum to 1.0000
[2019-03-23 23:37:58,451] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0642
[2019-03-23 23:37:58,456] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.75, 37.0, 1.0, 2.0, 0.3436397087191615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 431080.6970949088, 431080.6970949088, 121064.0703985398], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1362600.0000, 
sim time next is 1363200.0000, 
raw observation next is [28.5, 38.0, 1.0, 2.0, 0.3440861351982615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 431580.8006293134, 431580.8006293139, 121121.6725543311], 
processed observation next is [1.0, 0.782608695652174, 0.6111111111111112, 0.38, 1.0, 1.0, 0.21915016095031128, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1541360002247548, 0.15413600022475496, 0.23292629337371365], 
reward next is 0.7671, 
noisyNet noise sample is [array([-1.1308928], dtype=float32), -2.0898705]. 
=============================================
[2019-03-23 23:38:07,420] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 23:38:07,421] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:38:07,423] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:38:07,423] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:38:07,424] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:38:07,427] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:38:07,430] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:38:07,429] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:38:07,430] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:38:07,431] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:38:07,432] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:38:07,456] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run62
[2019-03-23 23:38:07,457] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run62
[2019-03-23 23:38:07,505] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run62
[2019-03-23 23:38:07,506] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run62
[2019-03-23 23:38:07,560] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run62
[2019-03-23 23:38:51,941] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.08708009]
[2019-03-23 23:38:51,943] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.677843875, 93.47696532, 1.0, 2.0, 0.85514825631651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 978745.0463640704, 978745.0463640699, 207810.6415853392]
[2019-03-23 23:38:51,944] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:38:51,947] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.3128285e-21 1.0000000e+00 2.9653301e-34 1.3954503e-31 1.8356870e-36], sampled 0.6977436321071105
[2019-03-23 23:39:34,166] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.08708009]
[2019-03-23 23:39:34,167] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.66666666666667, 74.0, 1.0, 2.0, 0.4732574531753648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 568513.0078403082, 568513.0078403078, 138900.8020211278]
[2019-03-23 23:39:34,168] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:39:34,172] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.3128285e-21 1.0000000e+00 2.9653301e-34 1.3954503e-31 1.8356870e-36], sampled 0.8517364201468708
[2019-03-23 23:39:40,625] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.08708009]
[2019-03-23 23:39:40,627] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.48208925, 71.06707452333333, 1.0, 2.0, 0.3599576808705854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 459652.499045808, 459652.4990458085, 123305.9277578433]
[2019-03-23 23:39:40,628] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:39:40,632] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.3128285e-21 1.0000000e+00 2.9653301e-34 1.3954503e-31 1.8356870e-36], sampled 0.2322513263946755
[2019-03-23 23:39:44,044] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.08708009]
[2019-03-23 23:39:44,047] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [18.6, 66.0, 1.0, 2.0, 0.3575031879868213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 461190.0504919371, 461190.0504919376, 112245.9074955836]
[2019-03-23 23:39:44,047] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:39:44,053] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.3128285e-21 1.0000000e+00 2.9653301e-34 1.3954503e-31 1.8356870e-36], sampled 0.9286772278700115
[2019-03-23 23:39:46,560] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.08708009]
[2019-03-23 23:39:46,562] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [17.08333333333334, 99.16666666666667, 1.0, 2.0, 0.2949511600895584, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 376261.1988722346, 376261.1988722346, 114953.585272396]
[2019-03-23 23:39:46,562] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:39:46,566] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.3128285e-21 1.0000000e+00 2.9653301e-34 1.3954503e-31 1.8356870e-36], sampled 0.02582980531302581
[2019-03-23 23:39:51,631] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:39:51,947] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:39:51,995] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:39:52,028] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:39:52,108] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:39:53,125] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1525000, evaluation results [1525000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:39:58,376] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.6167774e-16 1.0000000e+00 2.3673095e-25 1.2963432e-24 2.1765780e-26], sum to 1.0000
[2019-03-23 23:39:58,380] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7015
[2019-03-23 23:39:58,385] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1315313.923850265 W.
[2019-03-23 23:39:58,390] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.6, 42.66666666666667, 1.0, 2.0, 0.9249430801089141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.224505271719412, 6.9112, 121.9246734332529, 1315313.923850265, 1154875.423505181, 227276.2405718954], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1610400.0000, 
sim time next is 1611000.0000, 
raw observation next is [27.65, 42.5, 1.0, 2.0, 0.3398002409071737, 1.0, 1.0, 0.3398002409071737, 1.0, 1.0, 0.5548649882064705, 6.9112, 6.9112, 121.94756008, 1243653.988165223, 1243653.988165223, 270539.3288433561], 
processed observation next is [1.0, 0.6521739130434783, 0.5796296296296296, 0.425, 1.0, 1.0, 0.21404790584187347, 1.0, 0.5, 0.21404790584187347, 1.0, 0.5, 0.443581235258088, 0.0, 0.0, 0.8096049824067558, 0.4441621386304368, 0.4441621386304368, 0.5202679400833772], 
reward next is 0.4797, 
noisyNet noise sample is [array([-2.2407222], dtype=float32), 0.95906407]. 
=============================================
[2019-03-23 23:39:58,414] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[49.43089]
 [49.43089]
 [49.43089]
 [49.43089]
 [49.43089]], R is [[49.41631317]
 [48.92214966]
 [48.43292999]
 [48.47605896]
 [48.46565628]].
[2019-03-23 23:40:01,044] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.7673422e-22 1.0000000e+00 1.6004707e-32 6.4131569e-32 5.6757085e-36], sum to 1.0000
[2019-03-23 23:40:01,051] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1755
[2019-03-23 23:40:01,057] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.4, 88.0, 1.0, 2.0, 0.3124994016960991, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 398291.2026140673, 398291.2026140668, 117132.2620315457], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1666800.0000, 
sim time next is 1667400.0000, 
raw observation next is [18.43333333333333, 87.66666666666667, 1.0, 2.0, 0.3171486204085118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 404203.7703401901, 404203.7703401901, 117718.9145142041], 
processed observation next is [1.0, 0.30434782608695654, 0.2382716049382715, 0.8766666666666667, 1.0, 1.0, 0.1870816909625141, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14435848940721074, 0.14435848940721074, 0.22638252791193095], 
reward next is 0.7736, 
noisyNet noise sample is [array([-0.508908], dtype=float32), 0.67087054]. 
=============================================
[2019-03-23 23:40:04,326] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.2028466e-20 1.0000000e+00 7.0760610e-32 3.3423341e-29 9.9045363e-35], sum to 1.0000
[2019-03-23 23:40:04,336] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7194
[2019-03-23 23:40:04,342] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 79.0, 1.0, 2.0, 0.4085984947186581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 504372.9057820008, 504372.9057820003, 129792.8448064123], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1720200.0000, 
sim time next is 1720800.0000, 
raw observation next is [22.1, 79.0, 1.0, 2.0, 0.4066329579763808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 502409.6434119284, 502409.6434119279, 129524.5902848779], 
processed observation next is [1.0, 0.9565217391304348, 0.3740740740740741, 0.79, 1.0, 1.0, 0.29361066425759624, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17943201550426013, 0.17943201550425997, 0.2490857505478421], 
reward next is 0.7509, 
noisyNet noise sample is [array([-0.84015334], dtype=float32), -0.6293625]. 
=============================================
[2019-03-23 23:40:14,917] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0067997e-19 1.0000000e+00 1.6756362e-31 1.9284610e-24 3.3128381e-34], sum to 1.0000
[2019-03-23 23:40:14,925] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6116
[2019-03-23 23:40:14,937] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1433786.917887674 W.
[2019-03-23 23:40:14,941] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.45, 65.5, 1.0, 2.0, 0.9938319035464932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.394328219432983, 6.9112, 121.9239923312691, 1433786.917887674, 1186386.248338774, 241976.501334294], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1949400.0000, 
sim time next is 1950000.0000, 
raw observation next is [26.7, 64.33333333333333, 1.0, 2.0, 0.5599370578605909, 1.0, 1.0, 0.5599370578605909, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9257516585687, 1310402.148672789, 1310402.148672789, 256110.203526715], 
processed observation next is [1.0, 0.5652173913043478, 0.5444444444444444, 0.6433333333333333, 1.0, 1.0, 0.476115545072132, 1.0, 0.5, 0.476115545072132, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094601971676119, 0.46800076738313895, 0.46800076738313895, 0.4925196221667596], 
reward next is 0.5075, 
noisyNet noise sample is [array([1.0307007], dtype=float32), -0.18835238]. 
=============================================
[2019-03-23 23:40:14,959] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[70.64584]
 [70.64584]
 [70.64584]
 [70.64584]
 [70.64584]], R is [[70.44686127]
 [69.74239349]
 [69.04496765]
 [68.98417664]
 [68.89346313]].
[2019-03-23 23:40:16,152] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.3993408e-18 1.0000000e+00 1.4120685e-28 8.1438110e-25 1.9856986e-29], sum to 1.0000
[2019-03-23 23:40:16,159] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8512
[2019-03-23 23:40:16,165] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.85, 78.5, 1.0, 2.0, 0.5383205959244461, 1.0, 1.0, 0.5383205959244461, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9257870269841, 1272392.626482244, 1272392.626482243, 249516.3909910257], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1943400.0000, 
sim time next is 1944000.0000, 
raw observation next is [24.1, 77.0, 1.0, 2.0, 0.9946466830908137, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.417091961230948, 6.9112, 121.9239289241205, 1449667.404559332, 1190609.995356826, 242315.1028362399], 
processed observation next is [1.0, 0.5217391304347826, 0.4481481481481482, 0.77, 1.0, 1.0, 0.9936270036795402, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.05058919612309483, 0.0, 0.809448096106386, 0.51773835877119, 0.42521785548458074, 0.46599058237738444], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.37964207], dtype=float32), 2.4072175]. 
=============================================
[2019-03-23 23:40:16,187] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[58.894382]
 [58.894382]
 [58.894382]
 [58.894382]
 [58.894382]], R is [[58.30543518]
 [58.24254227]
 [57.6601181 ]
 [57.56566238]
 [56.99000549]].
[2019-03-23 23:40:17,089] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.9647815e-17 1.0000000e+00 5.4358741e-29 7.0389837e-26 2.8150521e-30], sum to 1.0000
[2019-03-23 23:40:17,097] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6006
[2019-03-23 23:40:17,101] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.7, 77.33333333333334, 1.0, 2.0, 0.559975905935405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 654338.1253912471, 654338.1253912471, 152086.2231920943], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2064000.0000, 
sim time next is 2064600.0000, 
raw observation next is [25.55, 77.5, 1.0, 2.0, 0.5539844438216828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 648893.3454298056, 648893.3454298056, 151158.3628880849], 
processed observation next is [0.0, 0.9130434782608695, 0.5018518518518519, 0.775, 1.0, 1.0, 0.46902909978771756, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2317476233677877, 0.2317476233677877, 0.29068915940016327], 
reward next is 0.7093, 
noisyNet noise sample is [array([-1.7124411], dtype=float32), 0.09095472]. 
=============================================
[2019-03-23 23:40:17,965] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3371277e-22 1.0000000e+00 1.8191180e-35 5.0563049e-30 2.8347299e-37], sum to 1.0000
[2019-03-23 23:40:17,976] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0408
[2019-03-23 23:40:17,984] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.71666666666667, 83.66666666666667, 1.0, 2.0, 0.5158818936842905, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 614304.2007000119, 614304.2007000115, 145375.1164685083], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1977000.0000, 
sim time next is 1977600.0000, 
raw observation next is [23.33333333333334, 84.33333333333334, 1.0, 2.0, 0.502483169565479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 601442.6010756982, 601442.6010756982, 143362.7858336034], 
processed observation next is [1.0, 0.9130434782608695, 0.4197530864197533, 0.8433333333333334, 1.0, 1.0, 0.4077180590065226, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21480092895560648, 0.21480092895560648, 0.27569766506462196], 
reward next is 0.7243, 
noisyNet noise sample is [array([-0.5702377], dtype=float32), -0.15675259]. 
=============================================
[2019-03-23 23:40:30,573] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.2616584e-13 1.0000000e+00 4.2619988e-21 9.2253854e-21 1.2737467e-22], sum to 1.0000
[2019-03-23 23:40:30,582] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2407
[2019-03-23 23:40:30,596] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1620644.439335647 W.
[2019-03-23 23:40:30,601] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.78333333333333, 86.00000000000001, 1.0, 2.0, 0.7106065363021399, 1.0, 2.0, 0.7106065363021399, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1620644.439335647, 1620644.439335648, 308199.5693098499], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2214600.0000, 
sim time next is 2215200.0000, 
raw observation next is [25.56666666666667, 87.0, 1.0, 2.0, 0.6919672258314961, 1.0, 2.0, 0.6919672258314961, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1578096.625443981, 1578096.625443981, 301135.0059726233], 
processed observation next is [1.0, 0.6521739130434783, 0.5024691358024692, 0.87, 1.0, 1.0, 0.6332943164660667, 1.0, 1.0, 0.6332943164660667, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5636059376585647, 0.5636059376585647, 0.5791057807165833], 
reward next is 0.4209, 
noisyNet noise sample is [array([-0.07885192], dtype=float32), -0.69306475]. 
=============================================
[2019-03-23 23:40:43,011] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-23 23:40:43,011] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:40:43,012] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:40:43,012] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:40:43,013] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:40:43,014] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:40:43,013] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:40:43,015] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:40:43,016] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:40:43,015] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:40:43,017] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:40:43,038] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run63
[2019-03-23 23:40:43,063] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run63
[2019-03-23 23:40:43,096] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run63
[2019-03-23 23:40:43,097] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run63
[2019-03-23 23:40:43,144] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run63
[2019-03-23 23:40:53,453] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.09885426]
[2019-03-23 23:40:53,453] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [32.82487899333334, 34.35307440333334, 1.0, 2.0, 0.4381639062097298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 531049.8528209924, 531049.8528209924, 133804.8591694241]
[2019-03-23 23:40:53,453] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:40:53,458] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.0040236e-17 1.0000000e+00 5.1614314e-27 6.1836085e-25 7.2833049e-29], sampled 0.792050511185606
[2019-03-23 23:41:02,046] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.09885426]
[2019-03-23 23:41:02,047] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.13333333333334, 55.66666666666667, 1.0, 2.0, 0.9040961416686679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.06763361983057, 6.9112, 121.9250854549617, 1205875.9312171, 1125768.564860441, 222357.2920624555]
[2019-03-23 23:41:02,047] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:41:02,052] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.0040236e-17 1.0000000e+00 5.1614314e-27 6.1836085e-25 7.2833049e-29], sampled 0.19012686835266868
[2019-03-23 23:41:40,494] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.09885426]
[2019-03-23 23:41:40,497] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.0, 89.0, 1.0, 2.0, 0.5444996678321364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 637090.9299022375, 637090.9299022375, 149565.8625070378]
[2019-03-23 23:41:40,498] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:41:40,500] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.0040236e-17 1.0000000e+00 5.1614314e-27 6.1836085e-25 7.2833049e-29], sampled 0.15859747169507854
[2019-03-23 23:41:41,989] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.09885426]
[2019-03-23 23:41:41,990] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.0, 74.0, 1.0, 2.0, 0.7006280070087786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 798518.1007053027, 798518.1007053027, 176265.4006905106]
[2019-03-23 23:41:41,992] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:41:41,995] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.0040236e-17 1.0000000e+00 5.1614314e-27 6.1836085e-25 7.2833049e-29], sampled 0.15925209738150825
[2019-03-23 23:42:14,327] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.09885426]
[2019-03-23 23:42:14,328] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [31.0, 49.0, 1.0, 2.0, 0.5580195494863893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 652648.6042078888, 652648.6042078884, 151786.5286853809]
[2019-03-23 23:42:14,331] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:42:14,334] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.0040236e-17 1.0000000e+00 5.1614314e-27 6.1836085e-25 7.2833049e-29], sampled 0.7452083299636248
[2019-03-23 23:42:26,752] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:42:27,112] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:42:27,162] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:42:27,313] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:42:27,340] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:42:28,354] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1550000, evaluation results [1550000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:42:32,070] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.1455513e-20 1.0000000e+00 1.7890401e-32 3.1425164e-29 1.9410729e-33], sum to 1.0000
[2019-03-23 23:42:32,078] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1250
[2019-03-23 23:42:32,087] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 87.66666666666667, 1.0, 2.0, 0.5438887946281804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 640082.8378376578, 640082.8378376578, 149621.2618700154], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2629200.0000, 
sim time next is 2629800.0000, 
raw observation next is [23.75, 87.0, 1.0, 2.0, 0.5367374160216688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 633760.4096457134, 633760.4096457134, 148537.1651921099], 
processed observation next is [0.0, 0.43478260869565216, 0.4351851851851852, 0.87, 1.0, 1.0, 0.44849692383531997, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22634300344489763, 0.22634300344489763, 0.28564839460021135], 
reward next is 0.7144, 
noisyNet noise sample is [array([1.625581], dtype=float32), -1.3166958]. 
=============================================
[2019-03-23 23:42:42,886] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.1143174e-18 1.0000000e+00 4.1718836e-30 7.9572498e-26 1.8560624e-31], sum to 1.0000
[2019-03-23 23:42:42,888] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0130
[2019-03-23 23:42:42,890] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1851531.452305914 W.
[2019-03-23 23:42:42,895] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 80.66666666666667, 1.0, 2.0, 0.5411595133313253, 1.0, 2.0, 0.5411595133313253, 1.0, 1.0, 0.8615435695584002, 6.9112, 6.9112, 121.94756008, 1851531.452305914, 1851531.452305914, 364249.6250367611], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2911200.0000, 
sim time next is 2911800.0000, 
raw observation next is [28.25, 79.83333333333334, 1.0, 2.0, 0.8368190771526489, 1.0, 2.0, 0.8368190771526489, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1908798.554587961, 1908798.554587961, 359204.2489061358], 
processed observation next is [1.0, 0.6956521739130435, 0.6018518518518519, 0.7983333333333335, 1.0, 1.0, 0.8057369966102963, 1.0, 1.0, 0.8057369966102963, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6817137694957003, 0.6817137694957003, 0.6907774017425689], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2949364], dtype=float32), 1.8342146]. 
=============================================
[2019-03-23 23:42:49,338] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.8810134e-18 1.0000000e+00 5.2056625e-28 1.8570437e-27 1.7601963e-31], sum to 1.0000
[2019-03-23 23:42:49,346] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3720
[2019-03-23 23:42:49,353] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 91.0, 1.0, 2.0, 0.5109770216483458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 611542.9561815572, 611542.9561815572, 144706.5845021327], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2858400.0000, 
sim time next is 2859000.0000, 
raw observation next is [22.41666666666667, 92.5, 1.0, 2.0, 0.977860647871295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.316422299488847, 6.9112, 122.6799032636202, 1378114.35210626, 1169321.295599735, 238300.2825366607], 
processed observation next is [1.0, 0.08695652173913043, 0.38580246913580263, 0.925, 1.0, 1.0, 0.9736436284182084, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.04052222994888473, 0.0, 0.8144669795627594, 0.4921836971808071, 0.41761474842847685, 0.45826977410896286], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.46640712], dtype=float32), 1.2138169]. 
=============================================
[2019-03-23 23:42:49,374] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[59.434822]
 [59.434822]
 [59.434822]
 [59.434822]
 [59.434822]], R is [[58.84047318]
 [58.9737854 ]
 [59.1041832 ]
 [59.23161316]
 [59.3558197 ]].
[2019-03-23 23:42:55,316] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.0035866e-19 1.0000000e+00 5.3799864e-30 6.1607633e-27 1.5066493e-32], sum to 1.0000
[2019-03-23 23:42:55,327] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2848
[2019-03-23 23:42:55,335] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.764176001203987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 870986.02369769, 870986.02369769, 188645.5451731574], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2949600.0000, 
sim time next is 2950200.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.7663132779779147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 873423.4189212293, 873423.4189212293, 189074.2470928747], 
processed observation next is [1.0, 0.13043478260869565, 0.48148148148148145, 0.94, 1.0, 1.0, 0.7218015214022794, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31193693532901046, 0.31193693532901046, 0.36360432133245135], 
reward next is 0.6364, 
noisyNet noise sample is [array([1.0504291], dtype=float32), 0.057427216]. 
=============================================
[2019-03-23 23:42:55,986] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.0824696e-18 1.0000000e+00 1.3672610e-29 1.9977214e-26 2.4941502e-30], sum to 1.0000
[2019-03-23 23:42:55,995] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9503
[2019-03-23 23:42:56,007] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.58333333333333, 86.5, 1.0, 2.0, 0.788158763910957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 898780.6227630901, 898780.6227630901, 193523.26491131], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2967000.0000, 
sim time next is 2967600.0000, 
raw observation next is [25.66666666666667, 87.0, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.952433606564314, 6.9112, 121.9223099799755, 1696368.875019027, 1163180.527546398, 245581.324300049], 
processed observation next is [1.0, 0.34782608695652173, 0.506172839506173, 0.87, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.10412336065643144, 0.0, 0.8094373480008464, 0.6058460267925097, 0.41542161698085645, 0.4722717775000942], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.21752252], dtype=float32), 0.44519725]. 
=============================================
[2019-03-23 23:42:56,537] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2384021e-14 1.0000000e+00 8.0934846e-25 1.2103335e-21 4.8300894e-27], sum to 1.0000
[2019-03-23 23:42:56,542] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4971
[2019-03-23 23:42:56,545] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 86.0, 1.0, 2.0, 0.7667353336988039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 875966.1327951702, 875966.1327951702, 189265.5532478711], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2966400.0000, 
sim time next is 2967000.0000, 
raw observation next is [25.58333333333333, 86.5, 1.0, 2.0, 0.788158763910957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 898780.6227630901, 898780.6227630901, 193523.26491131], 
processed observation next is [1.0, 0.34782608695652173, 0.5030864197530862, 0.865, 1.0, 1.0, 0.7478080522749487, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.32099307955824646, 0.32099307955824646, 0.3721601248294423], 
reward next is 0.6278, 
noisyNet noise sample is [array([0.80124557], dtype=float32), -0.29095572]. 
=============================================
[2019-03-23 23:42:56,559] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[51.712627]
 [51.712627]
 [51.712627]
 [51.712627]
 [51.712627]], R is [[51.82333755]
 [51.94113159]
 [52.03728485]
 [52.12451553]
 [52.18919373]].
[2019-03-23 23:42:58,831] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1312216e-16 1.0000000e+00 1.4609613e-27 8.9882121e-25 6.6556227e-30], sum to 1.0000
[2019-03-23 23:42:58,839] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1127
[2019-03-23 23:42:58,842] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 97.0, 1.0, 2.0, 0.751228509497946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 856220.5985305964, 856220.5985305959, 186067.2622278956], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3036600.0000, 
sim time next is 3037200.0000, 
raw observation next is [25.0, 98.0, 1.0, 2.0, 0.7724411847718551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 880411.8552250122, 880411.8552250122, 190310.3286549824], 
processed observation next is [1.0, 0.13043478260869565, 0.48148148148148145, 0.98, 1.0, 1.0, 0.7290966485379227, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31443280543750435, 0.31443280543750435, 0.36598140125958156], 
reward next is 0.6340, 
noisyNet noise sample is [array([-0.25702488], dtype=float32), 0.69341934]. 
=============================================
[2019-03-23 23:43:00,907] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.05646325e-17 1.00000000e+00 6.28912809e-28 8.21581993e-27
 1.02540716e-29], sum to 1.0000
[2019-03-23 23:43:00,915] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4762
[2019-03-23 23:43:00,924] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2297749.997678408 W.
[2019-03-23 23:43:00,926] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 82.5, 1.0, 2.0, 1.007116642353448, 1.0, 2.0, 1.007116642353448, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2297749.997678408, 2297749.997678409, 436772.4681818694], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3061800.0000, 
sim time next is 3062400.0000, 
raw observation next is [29.33333333333334, 80.33333333333334, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 7.081516657353557, 6.9112, 121.9253166225986, 2414512.400917903, 2327295.568947375, 443049.4948094928], 
processed observation next is [1.0, 0.43478260869565216, 0.6419753086419755, 0.8033333333333335, 1.0, 1.0, 1.0238095238095237, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.25, 0.017031665735355705, 0.0, 0.8094573089811758, 0.8623258574706797, 0.8311769889097768, 0.8520182592490246], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.360756], dtype=float32), -0.6442897]. 
=============================================
[2019-03-23 23:43:05,020] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.2119679e-19 1.0000000e+00 1.0955688e-31 4.8390685e-28 1.4236511e-32], sum to 1.0000
[2019-03-23 23:43:05,024] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5535
[2019-03-23 23:43:05,030] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1627657.110221894 W.
[2019-03-23 23:43:05,033] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.95, 35.0, 1.0, 2.0, 0.4682970641913922, 1.0, 1.0, 0.4682970641913922, 1.0, 2.0, 0.7467731754074933, 6.9112, 6.9112, 121.94756008, 1627657.110221894, 1627657.110221894, 328406.4809987514], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3151800.0000, 
sim time next is 3152400.0000, 
raw observation next is [32.96666666666667, 36.0, 1.0, 2.0, 0.7492000632094341, 1.0, 2.0, 0.7492000632094341, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1742408.987817745, 1742408.987817745, 324907.0344326771], 
processed observation next is [1.0, 0.4782608695652174, 0.7765432098765432, 0.36, 1.0, 1.0, 0.7014286466778977, 1.0, 1.0, 0.7014286466778977, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.6222889242206232, 0.6222889242206232, 0.6248212200628406], 
reward next is 0.3752, 
noisyNet noise sample is [array([0.14628431], dtype=float32), -0.8956007]. 
=============================================
[2019-03-23 23:43:06,329] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.8685505e-17 1.0000000e+00 5.5846075e-27 2.2204231e-25 7.2892777e-30], sum to 1.0000
[2019-03-23 23:43:06,341] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9727
[2019-03-23 23:43:06,353] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1552661.34514408 W.
[2019-03-23 23:43:06,357] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.5, 37.0, 1.0, 2.0, 0.4538838178804608, 1.0, 2.0, 0.4538838178804608, 1.0, 1.0, 0.7225978200296593, 6.9112, 6.9112, 121.94756008, 1552661.34514408, 1552661.34514408, 321489.9482786423], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3155400.0000, 
sim time next is 3156000.0000, 
raw observation next is [33.66666666666666, 36.66666666666667, 1.0, 2.0, 0.4414681295353185, 1.0, 2.0, 0.4414681295353185, 1.0, 2.0, 0.7028316398334525, 6.9112, 6.9112, 121.94756008, 1510147.459658487, 1510147.459658487, 315723.5963046983], 
processed observation next is [1.0, 0.5217391304347826, 0.8024691358024688, 0.3666666666666667, 1.0, 1.0, 0.33508110658966495, 1.0, 1.0, 0.33508110658966495, 1.0, 1.0, 0.6285395497918156, 0.0, 0.0, 0.8096049824067558, 0.5393383784494596, 0.5393383784494596, 0.6071607621244198], 
reward next is 0.3928, 
noisyNet noise sample is [array([-0.05593104], dtype=float32), -0.3781031]. 
=============================================
[2019-03-23 23:43:06,368] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[54.54835]
 [54.54835]
 [54.54835]
 [54.54835]
 [54.54835]], R is [[54.39569855]
 [54.23348999]
 [54.11036301]
 [53.94659042]
 [53.40712357]].
[2019-03-23 23:43:18,172] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.06347003e-18 1.00000000e+00 4.03262196e-30 1.35753205e-29
 1.14971914e-32], sum to 1.0000
[2019-03-23 23:43:18,178] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6396
[2019-03-23 23:43:18,184] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.16666666666666, 92.5, 1.0, 2.0, 0.6566356313974391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 758412.7379660967, 758412.7379660967, 168590.7318271912], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3394200.0000, 
sim time next is 3394800.0000, 
raw observation next is [24.4, 91.0, 1.0, 2.0, 0.6528926096285191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 753492.5181797235, 753492.5181797231, 167879.703057833], 
processed observation next is [1.0, 0.30434782608695654, 0.4592592592592592, 0.91, 1.0, 1.0, 0.5867769162244275, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2691044707784727, 0.26910447077847255, 0.322845582803525], 
reward next is 0.6772, 
noisyNet noise sample is [array([-0.20514527], dtype=float32), -0.75641847]. 
=============================================
[2019-03-23 23:43:18,592] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 23:43:18,593] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:43:18,594] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:43:18,595] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:43:18,596] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:43:18,597] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:43:18,598] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:43:18,598] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:43:18,598] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:43:18,603] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:43:18,604] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:43:18,620] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run64
[2019-03-23 23:43:18,645] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run64
[2019-03-23 23:43:18,646] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run64
[2019-03-23 23:43:18,693] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run64
[2019-03-23 23:43:18,735] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run64
[2019-03-23 23:43:33,984] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.041818347]
[2019-03-23 23:43:33,986] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [37.46666666666667, 19.0, 1.0, 2.0, 0.5872423452915185, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9501056409379464, 6.911199999999999, 6.9112, 121.9260426156618, 1414703.169463423, 1414703.169463423, 286848.6326596778]
[2019-03-23 23:43:33,989] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:43:33,992] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.8731250e-17 1.0000000e+00 5.7303147e-28 8.6389298e-26 5.2206713e-30], sampled 0.8361633430388763
[2019-03-23 23:43:33,993] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1414703.169463423 W.
[2019-03-23 23:43:55,627] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.041818347]
[2019-03-23 23:43:55,628] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.5, 79.0, 1.0, 2.0, 0.8908257681791325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1018493.634963818, 1018493.634963818, 215583.1625663603]
[2019-03-23 23:43:55,629] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:43:55,631] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.8731250e-17 1.0000000e+00 5.7303147e-28 8.6389298e-26 5.2206713e-30], sampled 0.5399543526392202
[2019-03-23 23:44:26,097] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.041818347]
[2019-03-23 23:44:26,099] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.8, 82.33333333333334, 1.0, 2.0, 0.6047483126334425, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 694777.6817195241, 694777.6817195236, 159170.5128690961]
[2019-03-23 23:44:26,100] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:44:26,103] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.8731250e-17 1.0000000e+00 5.7303147e-28 8.6389298e-26 5.2206713e-30], sampled 0.10092159316226623
[2019-03-23 23:44:29,341] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.041818347]
[2019-03-23 23:44:29,344] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.48286895, 91.83135318000001, 1.0, 2.0, 0.5471268454054501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 642107.7916209886, 642107.7916209886, 150079.5406904651]
[2019-03-23 23:44:29,346] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:44:29,349] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.8731250e-17 1.0000000e+00 5.7303147e-28 8.6389298e-26 5.2206713e-30], sampled 0.6886254282971539
[2019-03-23 23:44:42,238] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.041818347]
[2019-03-23 23:44:42,239] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.66666666666666, 90.66666666666667, 1.0, 2.0, 0.5984264097135898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 701458.5011705921, 701458.5011705921, 158714.1171389692]
[2019-03-23 23:44:42,241] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:44:42,244] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.8731250e-17 1.0000000e+00 5.7303147e-28 8.6389298e-26 5.2206713e-30], sampled 0.3926684624575043
[2019-03-23 23:44:52,626] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.041818347]
[2019-03-23 23:44:52,628] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.8, 88.66666666666666, 1.0, 2.0, 0.5838567497582866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 672747.7608658688, 672747.7608658692, 155682.0205466852]
[2019-03-23 23:44:52,630] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:44:52,633] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.8731250e-17 1.0000000e+00 5.7303147e-28 8.6389298e-26 5.2206713e-30], sampled 0.3264321980663839
[2019-03-23 23:45:02,363] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:45:02,574] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:45:02,755] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:45:02,804] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:45:02,875] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:45:03,894] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1575000, evaluation results [1575000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:45:04,191] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.5784258e-16 1.0000000e+00 6.3175556e-26 2.8378783e-22 5.3055817e-28], sum to 1.0000
[2019-03-23 23:45:04,195] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2094
[2019-03-23 23:45:04,198] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.7, 95.5, 1.0, 2.0, 0.6749444009392372, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 780949.8653227201, 780949.8653227201, 172030.8053114395], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3393000.0000, 
sim time next is 3393600.0000, 
raw observation next is [23.93333333333333, 94.0, 1.0, 2.0, 0.6572234887431746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 759739.1805682823, 759739.1805682823, 168728.9813807404], 
processed observation next is [1.0, 0.2608695652173913, 0.4419753086419752, 0.94, 1.0, 1.0, 0.5919327246942555, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2713354216315294, 0.2713354216315294, 0.3244788103475777], 
reward next is 0.6755, 
noisyNet noise sample is [array([0.7337585], dtype=float32), -0.20432073]. 
=============================================
[2019-03-23 23:45:06,370] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.5062023e-17 1.0000000e+00 1.5432543e-26 4.3859433e-23 5.1026199e-28], sum to 1.0000
[2019-03-23 23:45:06,378] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0985
[2019-03-23 23:45:06,383] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 85.0, 1.0, 2.0, 0.6318879348253258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 724043.1903297909, 724043.1903297905, 163843.6231246729], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3452400.0000, 
sim time next is 3453000.0000, 
raw observation next is [25.41666666666666, 86.50000000000001, 1.0, 2.0, 0.6348926682742062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 726746.3053090471, 726746.3053090471, 164342.5197619563], 
processed observation next is [1.0, 1.0, 0.49691358024691334, 0.8650000000000001, 1.0, 1.0, 0.5653484146121502, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25955225189608827, 0.25955225189608827, 0.31604330723453133], 
reward next is 0.6840, 
noisyNet noise sample is [array([-0.03248802], dtype=float32), -0.22671303]. 
=============================================
[2019-03-23 23:45:06,407] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[53.462044]
 [53.462044]
 [53.462044]
 [53.462044]
 [53.462044]], R is [[53.61137772]
 [53.76018143]
 [53.9041748 ]
 [54.04329681]
 [54.17711639]].
[2019-03-23 23:45:13,161] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.7388184e-18 1.0000000e+00 7.9104704e-31 3.4767804e-27 7.1860673e-32], sum to 1.0000
[2019-03-23 23:45:13,171] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0376
[2019-03-23 23:45:13,177] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.31666666666667, 91.33333333333334, 1.0, 2.0, 0.7917044281719876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 950155.273229649, 950155.2732296486, 196445.8910493538], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3574200.0000, 
sim time next is 3574800.0000, 
raw observation next is [22.4, 91.0, 1.0, 2.0, 0.8720249397678693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1045760.656697897, 1045760.656697897, 213756.5660985068], 
processed observation next is [1.0, 0.391304347826087, 0.38518518518518513, 0.91, 1.0, 1.0, 0.847648737818892, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3734859488206775, 0.3734859488206775, 0.4110703194202054], 
reward next is 0.5889, 
noisyNet noise sample is [array([0.748998], dtype=float32), 0.31375477]. 
=============================================
[2019-03-23 23:45:16,430] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.8984446e-19 1.0000000e+00 2.0427050e-31 3.9653062e-29 3.8366189e-33], sum to 1.0000
[2019-03-23 23:45:16,438] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1185
[2019-03-23 23:45:16,446] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 83.0, 1.0, 2.0, 0.5637545925133072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 657345.8346910371, 657345.8346910371, 152655.478699044], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3610800.0000, 
sim time next is 3611400.0000, 
raw observation next is [24.95, 82.16666666666667, 1.0, 2.0, 0.5583996991353304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 652701.9635590657, 652701.9635590657, 151832.7828345678], 
processed observation next is [1.0, 0.8260869565217391, 0.47962962962962963, 0.8216666666666668, 1.0, 1.0, 0.47428535611348854, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23310784412823776, 0.23310784412823776, 0.2919861208357073], 
reward next is 0.7080, 
noisyNet noise sample is [array([-0.639491], dtype=float32), 1.1724197]. 
=============================================
[2019-03-23 23:45:20,496] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.3068293e-17 1.0000000e+00 6.8166575e-29 3.4961449e-27 1.4321996e-29], sum to 1.0000
[2019-03-23 23:45:20,508] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4187
[2019-03-23 23:45:20,518] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.85, 95.0, 1.0, 2.0, 0.6619080476174652, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 754366.5642945742, 754366.5642945742, 169056.8864071425], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3720600.0000, 
sim time next is 3721200.0000, 
raw observation next is [24.8, 95.33333333333334, 1.0, 2.0, 0.6635585669257925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 756248.5640490529, 756248.5640490529, 169358.608599605], 
processed observation next is [1.0, 0.043478260869565216, 0.4740740740740741, 0.9533333333333335, 1.0, 1.0, 0.5994744844354672, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27008877287466176, 0.27008877287466176, 0.3256896319223173], 
reward next is 0.6743, 
noisyNet noise sample is [array([0.8092791], dtype=float32), 0.61264765]. 
=============================================
[2019-03-23 23:45:22,802] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.5984201e-19 1.0000000e+00 5.5751031e-31 1.3121526e-27 6.7631318e-33], sum to 1.0000
[2019-03-23 23:45:22,811] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4379
[2019-03-23 23:45:22,817] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 100.0, 1.0, 2.0, 0.7115210916734526, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 810939.7091208806, 810939.709120881, 178332.4423425056], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3738600.0000, 
sim time next is 3739200.0000, 
raw observation next is [24.0, 100.0, 1.0, 2.0, 0.7042707718813074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 802671.9979848696, 802671.9979848696, 176950.1710607985], 
processed observation next is [1.0, 0.2608695652173913, 0.4444444444444444, 1.0, 1.0, 1.0, 0.6479413950967945, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.286668570708882, 0.286668570708882, 0.34028879050153554], 
reward next is 0.6597, 
noisyNet noise sample is [array([0.02413103], dtype=float32), 1.5036013]. 
=============================================
[2019-03-23 23:45:23,655] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.5809762e-19 1.0000000e+00 8.0050676e-29 1.9233218e-28 5.3146257e-32], sum to 1.0000
[2019-03-23 23:45:23,660] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1609
[2019-03-23 23:45:23,665] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1712089.959488585 W.
[2019-03-23 23:45:23,668] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.5, 94.0, 1.0, 2.0, 0.7506644138166229, 1.0, 2.0, 0.7506644138166229, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1712089.959488585, 1712089.959488585, 323790.8816566199], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3749400.0000, 
sim time next is 3750000.0000, 
raw observation next is [26.66666666666667, 94.0, 1.0, 2.0, 0.4922165024236912, 1.0, 2.0, 0.4922165024236912, 1.0, 1.0, 0.7836247022308618, 6.911200000000001, 6.9112, 121.94756008, 1683919.275111076, 1683919.275111075, 339785.2234813828], 
processed observation next is [1.0, 0.391304347826087, 0.5432098765432101, 0.94, 1.0, 1.0, 0.39549583621867995, 1.0, 1.0, 0.39549583621867995, 1.0, 0.5, 0.7295308777885773, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6013997411110985, 0.6013997411110982, 0.6534331220795824], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.588265], dtype=float32), 0.9863523]. 
=============================================
[2019-03-23 23:45:23,693] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[59.054283]
 [59.054283]
 [59.054283]
 [59.054283]
 [59.054283]], R is [[58.4637413 ]
 [57.87910461]
 [57.30031586]
 [56.727314  ]
 [56.42460632]].
[2019-03-23 23:45:29,412] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8631393e-19 1.0000000e+00 1.7296973e-31 9.4082024e-28 9.4643651e-34], sum to 1.0000
[2019-03-23 23:45:29,420] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7177
[2019-03-23 23:45:29,427] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.0, 53.0, 1.0, 2.0, 0.7032069573763973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 801458.9126472514, 801458.912647251, 176753.3682251929], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3855600.0000, 
sim time next is 3856200.0000, 
raw observation next is [33.16666666666666, 52.5, 1.0, 2.0, 0.7006856184424781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 798583.7956781811, 798583.7956781811, 176275.5099570889], 
processed observation next is [0.0, 0.6521739130434783, 0.7839506172839502, 0.525, 1.0, 1.0, 0.6436733552886644, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28520849845649326, 0.28520849845649326, 0.33899136530209406], 
reward next is 0.6610, 
noisyNet noise sample is [array([0.14114808], dtype=float32), 0.42827216]. 
=============================================
[2019-03-23 23:45:32,045] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4297403e-18 1.0000000e+00 2.1382666e-28 3.6916510e-27 2.5243290e-31], sum to 1.0000
[2019-03-23 23:45:32,048] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.7818071e-17 1.0000000e+00 1.4174113e-28 1.2895496e-27 9.6653058e-31], sum to 1.0000
[2019-03-23 23:45:32,054] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5282
[2019-03-23 23:45:32,056] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1026
[2019-03-23 23:45:32,058] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.7538073365757941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 859161.4912816457, 859161.4912816457, 186583.8622495098], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3920400.0000, 
sim time next is 3921000.0000, 
raw observation next is [27.16666666666666, 87.33333333333334, 1.0, 2.0, 0.7508021557287434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 855734.3860518129, 855734.3860518129, 185987.3922403012], 
processed observation next is [0.0, 0.391304347826087, 0.5617283950617282, 0.8733333333333334, 1.0, 1.0, 0.7033358996770755, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.30561942358993316, 0.30561942358993316, 0.35766806200057927], 
reward next is 0.6423, 
noisyNet noise sample is [array([-0.68131036], dtype=float32), -0.5293448]. 
=============================================
[2019-03-23 23:45:32,062] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 0.7765975303168591, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 885151.9042056603, 885151.9042056603, 191160.1568265931], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3933000.0000, 
sim time next is 3933600.0000, 
raw observation next is [31.0, 70.0, 1.0, 2.0, 0.8042962351058892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 916741.2722920439, 916741.2722920434, 196837.0731188326], 
processed observation next is [0.0, 0.5217391304347826, 0.7037037037037037, 0.7, 1.0, 1.0, 0.767019327507011, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3274075972471585, 0.32740759724715834, 0.37853283292083195], 
reward next is 0.6215, 
noisyNet noise sample is [array([1.8687973], dtype=float32), -0.04815956]. 
=============================================
[2019-03-23 23:45:32,079] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[59.967487]
 [59.967487]
 [59.967487]
 [59.967487]
 [59.967487]], R is [[60.01014328]
 [60.05122757]
 [60.0919838 ]
 [60.13389587]
 [60.1812973 ]].
[2019-03-23 23:45:34,675] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.1379839e-20 1.0000000e+00 3.7864736e-32 3.6955519e-28 1.1440529e-33], sum to 1.0000
[2019-03-23 23:45:34,681] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1914
[2019-03-23 23:45:34,684] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.6, 73.66666666666667, 1.0, 2.0, 0.7423474053223714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 846092.6793553596, 846092.6793553596, 184320.3143431704], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3954000.0000, 
sim time next is 3954600.0000, 
raw observation next is [29.45, 75.0, 1.0, 2.0, 0.7617416275711769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 868209.8224328343, 868209.8224328343, 188166.5914588837], 
processed observation next is [0.0, 0.782608695652174, 0.6462962962962963, 0.75, 1.0, 1.0, 0.7163590804418772, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3100749365831551, 0.3100749365831551, 0.3618588297286225], 
reward next is 0.6381, 
noisyNet noise sample is [array([-0.62210184], dtype=float32), -1.8900329]. 
=============================================
[2019-03-23 23:45:36,436] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0895298e-16 1.0000000e+00 4.6555911e-26 7.5902875e-25 3.2113637e-28], sum to 1.0000
[2019-03-23 23:45:36,443] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9832
[2019-03-23 23:45:36,450] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.06666666666666, 90.33333333333334, 1.0, 2.0, 0.9786965521115527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.013411275253004, 6.9112, 121.9256262888341, 1168047.667993936, 1115706.538248124, 235620.255715307], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3987600.0000, 
sim time next is 3988200.0000, 
raw observation next is [25.03333333333333, 90.66666666666667, 1.0, 2.0, 0.9986361031830637, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.136257208712515, 6.9112, 121.9249813622353, 1253749.512617926, 1138501.109511543, 240391.7721034198], 
processed observation next is [1.0, 0.13043478260869565, 0.482716049382716, 0.9066666666666667, 1.0, 1.0, 0.9983763133131711, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.022505720871251533, 0.0, 0.8094550832010098, 0.44776768307783077, 0.4066075391112654, 0.46229186942965345], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7397876], dtype=float32), 0.46042892]. 
=============================================
[2019-03-23 23:45:36,588] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.7744444e-17 1.0000000e+00 6.8787626e-25 4.0441289e-23 7.1945848e-28], sum to 1.0000
[2019-03-23 23:45:36,598] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0621
[2019-03-23 23:45:36,607] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1623327.48297734 W.
[2019-03-23 23:45:36,610] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.8, 94.0, 1.0, 2.0, 0.4745213472453721, 1.0, 2.0, 0.4745213472453721, 1.0, 2.0, 0.7554534388960067, 6.911200000000001, 6.9112, 121.94756008, 1623327.48297734, 1623327.48297734, 331259.9235530238], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4008600.0000, 
sim time next is 4009200.0000, 
raw observation next is [24.86666666666667, 94.0, 1.0, 2.0, 0.5012194422005776, 1.0, 2.0, 0.5012194422005776, 1.0, 2.0, 0.7979576755609437, 6.9112, 6.9112, 121.94756008, 1714748.739899428, 1714748.739899428, 344187.957436409], 
processed observation next is [1.0, 0.391304347826087, 0.47654320987654336, 0.94, 1.0, 1.0, 0.40621362166735425, 1.0, 1.0, 0.40621362166735425, 1.0, 1.0, 0.7474470944511796, 0.0, 0.0, 0.8096049824067558, 0.6124102642497957, 0.6124102642497957, 0.6618999181469404], 
reward next is 0.3381, 
noisyNet noise sample is [array([0.7444392], dtype=float32), 0.18815567]. 
=============================================
[2019-03-23 23:45:39,555] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.9996023e-16 1.0000000e+00 4.7837753e-25 1.8671199e-23 6.9241434e-27], sum to 1.0000
[2019-03-23 23:45:39,565] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.1298916e-16 1.0000000e+00 1.0881998e-25 4.5673429e-24 6.0429601e-28], sum to 1.0000
[2019-03-23 23:45:39,567] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6576
[2019-03-23 23:45:39,571] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8326
[2019-03-23 23:45:39,573] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1396145.075891649 W.
[2019-03-23 23:45:39,575] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 100.0, 1.0, 2.0, 0.5349849792198182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 653149.4059390601, 653149.4059390601, 149001.8145038577], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4083600.0000, 
sim time next is 4084200.0000, 
raw observation next is [20.5, 100.0, 1.0, 2.0, 0.5394100534561743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 656780.2870240242, 656780.2870240242, 149678.0993755022], 
processed observation next is [1.0, 0.2608695652173913, 0.3148148148148148, 1.0, 1.0, 1.0, 0.45167863506687417, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23456438822286577, 0.23456438822286577, 0.2878424987990427], 
reward next is 0.7122, 
noisyNet noise sample is [array([0.02325408], dtype=float32), -0.5514627]. 
=============================================
[2019-03-23 23:45:39,582] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.0, 83.0, 1.0, 2.0, 0.4058857718050249, 1.0, 2.0, 0.4058857718050249, 1.0, 2.0, 0.646412575215977, 6.9112, 6.9112, 121.94756008, 1396145.075891649, 1396145.075891649, 299718.3158442399], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4093200.0000, 
sim time next is 4093800.0000, 
raw observation next is [24.33333333333333, 82.33333333333334, 1.0, 2.0, 0.4001795538961463, 1.0, 2.0, 0.4001795538961463, 1.0, 2.0, 0.6371380934093551, 6.911199999999999, 6.9112, 121.94756008, 1370582.822545575, 1370582.822545576, 297173.5898605568], 
processed observation next is [1.0, 0.391304347826087, 0.45679012345678993, 0.8233333333333335, 1.0, 1.0, 0.2859280403525551, 1.0, 1.0, 0.2859280403525551, 1.0, 1.0, 0.5464226167616939, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.4894938651948482, 0.48949386519484855, 0.5714876728087631], 
reward next is 0.4285, 
noisyNet noise sample is [array([-0.64406246], dtype=float32), 1.0180146]. 
=============================================
[2019-03-23 23:45:42,330] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.8848660e-17 1.0000000e+00 1.5258742e-26 5.9286822e-27 3.3656968e-29], sum to 1.0000
[2019-03-23 23:45:42,339] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4708
[2019-03-23 23:45:42,345] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1503616.444010919 W.
[2019-03-23 23:45:42,354] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.36666666666667, 75.33333333333334, 1.0, 2.0, 0.6919527305775368, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1503616.444010919, 1503616.44401092, 315771.6809662692], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4098000.0000, 
sim time next is 4098600.0000, 
raw observation next is [26.55, 73.5, 1.0, 2.0, 0.4372760833158242, 1.0, 1.0, 0.4372760833158242, 1.0, 2.0, 0.6961577657266037, 6.911199999999999, 6.9112, 121.94756008, 1495793.559038583, 1495793.559038584, 313795.8814079587], 
processed observation next is [1.0, 0.43478260869565216, 0.5388888888888889, 0.735, 1.0, 1.0, 0.3300905753759812, 1.0, 0.5, 0.3300905753759812, 1.0, 1.0, 0.6201972071582545, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5342119853709225, 0.5342119853709228, 0.6034536180922282], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0472178], dtype=float32), -0.14370519]. 
=============================================
[2019-03-23 23:45:47,230] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.6039441e-18 1.0000000e+00 2.9278305e-28 1.0842220e-25 2.6254790e-30], sum to 1.0000
[2019-03-23 23:45:47,238] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4664
[2019-03-23 23:45:47,238] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1806847.488007318 W.
[2019-03-23 23:45:47,246] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.63333333333333, 47.16666666666667, 1.0, 2.0, 0.5281126253747813, 1.0, 1.0, 0.5281126253747813, 1.0, 2.0, 0.8407724990241059, 6.9112, 6.9112, 121.94756008, 1806847.488007318, 1806847.488007318, 357601.261095915], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4189800.0000, 
sim time next is 4190400.0000, 
raw observation next is [32.0, 46.0, 1.0, 2.0, 0.5349438332469922, 1.0, 2.0, 0.5349438332469922, 1.0, 2.0, 0.851648004433574, 6.911199999999999, 6.9112, 121.94756008, 1830243.244360636, 1830243.244360636, 361070.7863752139], 
processed observation next is [1.0, 0.5217391304347826, 0.7407407407407407, 0.46, 1.0, 1.0, 0.4463617062464193, 1.0, 1.0, 0.4463617062464193, 1.0, 1.0, 0.8145600055419674, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.65365830155737, 0.65365830155737, 0.6943668968754113], 
reward next is 0.3056, 
noisyNet noise sample is [array([-0.9545922], dtype=float32), 1.0867835]. 
=============================================
[2019-03-23 23:45:47,802] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.16069318e-19 1.00000000e+00 3.19177072e-30 1.09986325e-27
 5.39953081e-33], sum to 1.0000
[2019-03-23 23:45:47,810] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4935
[2019-03-23 23:45:47,815] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 74.0, 1.0, 2.0, 0.6130068705476998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 705931.64816092, 705931.64816092, 160687.686198488], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4312800.0000, 
sim time next is 4313400.0000, 
raw observation next is [26.78333333333333, 74.0, 1.0, 2.0, 0.6027933885313154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 696414.5724932022, 696414.5724932022, 159016.3283177271], 
processed observation next is [1.0, 0.9565217391304348, 0.5475308641975308, 0.74, 1.0, 1.0, 0.527134986346804, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24871949017614364, 0.24871949017614364, 0.30580063138024444], 
reward next is 0.6942, 
noisyNet noise sample is [array([0.3959095], dtype=float32), 2.3981144]. 
=============================================
[2019-03-23 23:45:49,917] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.3366931e-20 1.0000000e+00 2.6912581e-31 3.0027077e-29 1.9211977e-33], sum to 1.0000
[2019-03-23 23:45:49,922] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5561
[2019-03-23 23:45:49,927] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1698353.928945941 W.
[2019-03-23 23:45:49,933] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 66.0, 1.0, 2.0, 0.4964318046467857, 1.0, 2.0, 0.4964318046467857, 1.0, 1.0, 0.7903356006528374, 6.9112, 6.9112, 121.94756008, 1698353.928945941, 1698353.928945941, 341841.1708801939], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4266000.0000, 
sim time next is 4266600.0000, 
raw observation next is [27.5, 62.66666666666666, 1.0, 2.0, 0.7294979787950802, 0.0, 1.0, 0.0, 1.0, 2.0, 0.984679538741559, 6.911199999999999, 6.9112, 121.9260426156618, 1558766.940515101, 1558766.940515102, 320358.7373534622], 
processed observation next is [1.0, 0.391304347826087, 0.5740740740740741, 0.6266666666666666, 1.0, 1.0, 0.6779737842798573, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9808494234269488, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5567024787553932, 0.5567024787553936, 0.6160744949105043], 
reward next is 0.3839, 
noisyNet noise sample is [array([-0.3945566], dtype=float32), 1.0102412]. 
=============================================
[2019-03-23 23:45:54,127] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-23 23:45:54,130] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:45:54,131] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:45:54,133] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:45:54,136] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:45:54,139] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:45:54,139] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:45:54,140] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:45:54,141] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:45:54,141] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:45:54,142] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:45:54,153] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run65
[2019-03-23 23:45:54,182] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run65
[2019-03-23 23:45:54,183] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run65
[2019-03-23 23:45:54,231] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run65
[2019-03-23 23:45:54,232] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run65
[2019-03-23 23:46:12,494] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.044825975]
[2019-03-23 23:46:12,495] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.73760294, 30.60790409833333, 1.0, 2.0, 0.3348270763225552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 424299.6012647042, 424299.6012647042, 119969.9571829402]
[2019-03-23 23:46:12,495] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:46:12,498] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.8877966e-20 1.0000000e+00 8.7695587e-32 2.6012257e-29 4.7165099e-34], sampled 0.6803719777656015
[2019-03-23 23:46:24,954] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.044825975]
[2019-03-23 23:46:24,955] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [33.47150150166667, 30.33339275333333, 1.0, 2.0, 0.6854376094904671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 834016.01274081, 834016.01274081, 175642.5635800955]
[2019-03-23 23:46:24,956] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:46:24,957] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.8877966e-20 1.0000000e+00 8.7695587e-32 2.6012257e-29 4.7165099e-34], sampled 0.7146529524053208
[2019-03-23 23:47:08,227] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.044825975]
[2019-03-23 23:47:08,228] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.81857011166667, 90.45078168666669, 1.0, 2.0, 0.4071312646597531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 503221.1595361136, 503221.1595361136, 129600.7722687739]
[2019-03-23 23:47:08,229] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:47:08,232] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.8877966e-20 1.0000000e+00 8.7695587e-32 2.6012257e-29 4.7165099e-34], sampled 0.28129640536265643
[2019-03-23 23:47:10,903] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.044825975]
[2019-03-23 23:47:10,905] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.0, 62.0, 1.0, 2.0, 0.5430446493156165, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 638608.0999968847, 638608.0999968847, 149463.115299686]
[2019-03-23 23:47:10,908] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:47:10,911] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.8877966e-20 1.0000000e+00 8.7695587e-32 2.6012257e-29 4.7165099e-34], sampled 0.9771273661209257
[2019-03-23 23:47:34,384] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.044825975]
[2019-03-23 23:47:34,387] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.02163666333334, 85.19135576333335, 1.0, 2.0, 0.4683359653283214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 562994.5208693688, 562994.5208693688, 138164.7818694482]
[2019-03-23 23:47:34,390] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:47:34,395] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.8877966e-20 1.0000000e+00 8.7695587e-32 2.6012257e-29 4.7165099e-34], sampled 0.43297822163137
[2019-03-23 23:47:38,715] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:47:38,943] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:47:38,983] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:47:39,160] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:47:39,240] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:47:40,256] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1600000, evaluation results [1600000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:47:40,816] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.717665e-20 1.000000e+00 1.273436e-29 1.067549e-29 9.226701e-33], sum to 1.0000
[2019-03-23 23:47:40,824] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1451
[2019-03-23 23:47:40,832] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 100.0, 1.0, 2.0, 0.5909916341898739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 685852.9834937097, 685852.9834937097, 157124.9032834593], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4547400.0000, 
sim time next is 4548000.0000, 
raw observation next is [23.0, 100.0, 1.0, 2.0, 0.5899673678709547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 684687.6299580224, 684687.6299580224, 156950.3573207229], 
processed observation next is [0.0, 0.6521739130434783, 0.4074074074074074, 1.0, 1.0, 1.0, 0.5118659141320889, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24453129641357943, 0.24453129641357943, 0.3018276102321594], 
reward next is 0.6982, 
noisyNet noise sample is [array([0.6420402], dtype=float32), -0.07628833]. 
=============================================
[2019-03-23 23:47:40,856] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[65.37431]
 [65.37431]
 [65.37431]
 [65.37431]
 [65.37431]], R is [[65.41874695]
 [65.46239471]
 [65.50502014]
 [65.54541016]
 [65.58348083]].
[2019-03-23 23:47:42,293] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.3118289e-18 1.0000000e+00 9.5972402e-28 1.6830082e-25 3.5811652e-30], sum to 1.0000
[2019-03-23 23:47:42,304] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1296
[2019-03-23 23:47:42,312] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.06666666666667, 52.33333333333334, 1.0, 2.0, 0.6168467829441551, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 702987.3756855804, 702987.3756855804, 161000.4038753851], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4382400.0000, 
sim time next is 4383000.0000, 
raw observation next is [31.8, 54.0, 1.0, 2.0, 0.6120392894671025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 697506.039217221, 697506.039217221, 160162.1839853225], 
processed observation next is [1.0, 0.7391304347826086, 0.7333333333333334, 0.54, 1.0, 1.0, 0.5381420112703601, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24910929972043605, 0.24910929972043605, 0.3080041999717741], 
reward next is 0.6920, 
noisyNet noise sample is [array([0.15859778], dtype=float32), 1.3527931]. 
=============================================
[2019-03-23 23:47:42,329] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[57.900566]
 [57.900566]
 [57.900566]
 [57.900566]
 [57.900566]], R is [[58.01355362]
 [58.12380219]
 [58.12092972]
 [57.69907379]
 [57.278759  ]].
[2019-03-23 23:47:42,570] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.9172556e-17 1.0000000e+00 4.5321012e-28 1.1975810e-26 9.6118762e-32], sum to 1.0000
[2019-03-23 23:47:42,576] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8361
[2019-03-23 23:47:42,587] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 92.66666666666667, 1.0, 2.0, 0.4932093234130112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 592070.1774641596, 592070.1774641596, 141969.0978907556], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4416000.0000, 
sim time next is 4416600.0000, 
raw observation next is [22.08333333333334, 93.33333333333334, 1.0, 2.0, 0.4924315465572257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 591144.5452017398, 591144.5452017398, 141847.9263127429], 
processed observation next is [0.0, 0.08695652173913043, 0.373456790123457, 0.9333333333333335, 1.0, 1.0, 0.39575184113955447, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2111230518577642, 0.2111230518577642, 0.27278447367835174], 
reward next is 0.7272, 
noisyNet noise sample is [array([0.60158294], dtype=float32), 0.29445457]. 
=============================================
[2019-03-23 23:47:43,543] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.5324038e-22 1.0000000e+00 3.0750950e-32 3.9069118e-30 5.2525771e-36], sum to 1.0000
[2019-03-23 23:47:43,550] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1510
[2019-03-23 23:47:43,556] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 79.00000000000001, 1.0, 2.0, 0.6902049288007159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 786632.6387768381, 786632.6387768381, 174298.2837485489], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4396200.0000, 
sim time next is 4396800.0000, 
raw observation next is [27.4, 79.0, 1.0, 2.0, 0.6879747634897274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 784089.5996775646, 784089.5996775646, 173878.9654873349], 
processed observation next is [1.0, 0.9130434782608695, 0.5703703703703703, 0.79, 1.0, 1.0, 0.6285413851068183, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2800319998848445, 0.2800319998848445, 0.3343826259371825], 
reward next is 0.6656, 
noisyNet noise sample is [array([-0.92536867], dtype=float32), -0.5412463]. 
=============================================
[2019-03-23 23:47:45,638] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0272888e-17 1.0000000e+00 1.0403388e-31 1.3466711e-27 6.2593142e-33], sum to 1.0000
[2019-03-23 23:47:45,646] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6592
[2019-03-23 23:47:45,650] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.13333333333333, 93.0, 1.0, 2.0, 0.4917592436488276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 590265.8153994323, 590265.8153994323, 141740.5404740471], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4422000.0000, 
sim time next is 4422600.0000, 
raw observation next is [22.2, 92.5, 1.0, 2.0, 0.4917286225811751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 590180.9990871004, 590180.9990871004, 141734.0876063672], 
processed observation next is [0.0, 0.17391304347826086, 0.37777777777777777, 0.925, 1.0, 1.0, 0.3949150268823513, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.210778928245393, 0.210778928245393, 0.2725655530891677], 
reward next is 0.7274, 
noisyNet noise sample is [array([0.480813], dtype=float32), 0.011863572]. 
=============================================
[2019-03-23 23:47:49,493] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.7480310e-20 1.0000000e+00 5.5246918e-32 4.6197289e-27 1.9246243e-32], sum to 1.0000
[2019-03-23 23:47:49,504] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9735
[2019-03-23 23:47:49,507] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.13333333333333, 97.33333333333334, 1.0, 2.0, 0.578271964736055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 673448.390880859, 673448.390880859, 155062.7265424226], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4519200.0000, 
sim time next is 4519800.0000, 
raw observation next is [23.2, 96.0, 1.0, 2.0, 0.5737905303137593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 669586.40940304, 669586.40940304, 154364.5706221937], 
processed observation next is [0.0, 0.30434782608695654, 0.4148148148148148, 0.96, 1.0, 1.0, 0.49260777418304674, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23913800335822855, 0.23913800335822855, 0.2968549435042187], 
reward next is 0.7031, 
noisyNet noise sample is [array([0.04129524], dtype=float32), -0.01821337]. 
=============================================
[2019-03-23 23:48:00,073] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.7607197e-17 1.0000000e+00 9.5715743e-28 3.9778738e-25 2.8612936e-29], sum to 1.0000
[2019-03-23 23:48:00,080] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8112
[2019-03-23 23:48:00,088] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2982327.183694463 W.
[2019-03-23 23:48:00,093] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.86666666666667, 81.0, 1.0, 2.0, 1.02, 1.0, 2.0, 0.8711136519817984, 1.0, 1.0, 0.9977734948820727, 7.123980091835128, 6.9112, 121.94756008, 2982327.183694463, 2873345.528956316, 535392.2141847397], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4887600.0000, 
sim time next is 4888200.0000, 
raw observation next is [31.33333333333333, 79.0, 1.0, 2.0, 0.8487923425711539, 1.0, 2.0, 0.7377608332620117, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2525137.258313053, 2525137.258313053, 471616.2435404123], 
processed observation next is [1.0, 0.5652173913043478, 0.7160493827160492, 0.79, 1.0, 1.0, 0.8199908840132785, 1.0, 1.0, 0.6878105157881091, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8096049824067558, 0.9018347351118046, 0.9018347351118046, 0.9069543145007929], 
reward next is 0.0930, 
noisyNet noise sample is [array([1.6321745], dtype=float32), 1.1974978]. 
=============================================
[2019-03-23 23:48:06,247] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.48172810e-14 1.00000000e+00 2.49533783e-24 1.33283095e-20
 1.04331477e-25], sum to 1.0000
[2019-03-23 23:48:06,254] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9124
[2019-03-23 23:48:06,257] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 98.0, 1.0, 2.0, 0.6126414045648831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 709703.7496831086, 709703.7496831086, 160821.0001328653], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4774800.0000, 
sim time next is 4775400.0000, 
raw observation next is [23.5, 97.0, 1.0, 2.0, 0.6621073012490472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 766322.8285972446, 766322.8285972446, 169668.4565109144], 
processed observation next is [1.0, 0.2608695652173913, 0.42592592592592593, 0.97, 1.0, 1.0, 0.5977467872012466, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27368672449901593, 0.27368672449901593, 0.32628549329022], 
reward next is 0.6737, 
noisyNet noise sample is [array([-0.7048935], dtype=float32), -0.972686]. 
=============================================
[2019-03-23 23:48:08,030] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.8092256e-18 1.0000000e+00 2.5829244e-28 6.1007557e-26 3.0663461e-31], sum to 1.0000
[2019-03-23 23:48:08,038] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9314
[2019-03-23 23:48:08,046] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 93.5, 1.0, 2.0, 0.7176788201727875, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 817961.5826010258, 817961.5826010254, 179519.5176256431], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4829400.0000, 
sim time next is 4830000.0000, 
raw observation next is [26.0, 93.33333333333334, 1.0, 2.0, 0.7161129893294881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 816176.0047484041, 816176.0047484041, 179218.4222270717], 
processed observation next is [1.0, 0.9130434782608695, 0.5185185185185185, 0.9333333333333335, 1.0, 1.0, 0.6620392730112953, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2914914302672872, 0.2914914302672872, 0.34465081197513786], 
reward next is 0.6553, 
noisyNet noise sample is [array([-1.1139212], dtype=float32), -1.6266693]. 
=============================================
[2019-03-23 23:48:08,058] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[63.103527]
 [63.103527]
 [63.103527]
 [63.103527]
 [63.103527]], R is [[63.12783813]
 [63.15132904]
 [63.1738472 ]
 [63.19503784]
 [63.21410751]].
[2019-03-23 23:48:16,319] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.2308712e-21 1.0000000e+00 3.3049795e-31 8.1029169e-30 1.2554943e-34], sum to 1.0000
[2019-03-23 23:48:16,326] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5685
[2019-03-23 23:48:16,330] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.85, 96.0, 1.0, 2.0, 0.5439166532064743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 639517.5005571898, 639517.5005571898, 149601.2848293927], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5031000.0000, 
sim time next is 5031600.0000, 
raw observation next is [22.9, 95.33333333333334, 1.0, 2.0, 0.5413844697896034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 636949.5576073806, 636949.557607381, 149203.2884560294], 
processed observation next is [0.0, 0.21739130434782608, 0.4037037037037037, 0.9533333333333335, 1.0, 1.0, 0.4540291307019088, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22748198485977877, 0.22748198485977894, 0.2869294008769796], 
reward next is 0.7131, 
noisyNet noise sample is [array([-0.598316], dtype=float32), 0.5042819]. 
=============================================
[2019-03-23 23:48:22,163] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.07312364e-19 1.00000000e+00 4.02949824e-31 2.63490443e-27
 3.16650444e-33], sum to 1.0000
[2019-03-23 23:48:22,172] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8006
[2019-03-23 23:48:22,176] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.9, 99.0, 1.0, 2.0, 0.6997310125369762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 797495.2484367747, 797495.2484367747, 176093.1684611981], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5117400.0000, 
sim time next is 5118000.0000, 
raw observation next is [24.93333333333333, 99.33333333333333, 1.0, 2.0, 0.7022769168756194, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 800398.3735999414, 800398.3735999409, 176575.8795022956], 
processed observation next is [0.0, 0.21739130434782608, 0.47901234567901224, 0.9933333333333333, 1.0, 1.0, 0.6455677581852612, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.28585656199997905, 0.2858565619999789, 0.3395689990428762], 
reward next is 0.6604, 
noisyNet noise sample is [array([0.37602425], dtype=float32), -0.6449515]. 
=============================================
[2019-03-23 23:48:22,192] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[65.22336]
 [65.22336]
 [65.22336]
 [65.22336]
 [65.22336]], R is [[65.23155975]
 [65.24060822]
 [65.25045776]
 [65.26107788]
 [65.27186584]].
[2019-03-23 23:48:30,480] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-23 23:48:30,484] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:48:30,485] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:48:30,486] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:48:30,487] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:48:30,490] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:48:30,491] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:48:30,491] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:48:30,491] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:48:30,493] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:48:30,495] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:48:30,512] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run66
[2019-03-23 23:48:30,512] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run66
[2019-03-23 23:48:30,560] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run66
[2019-03-23 23:48:30,586] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run66
[2019-03-23 23:48:30,608] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run66
[2019-03-23 23:48:46,000] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.03171073]
[2019-03-23 23:48:46,001] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [39.0, 13.33333333333333, 1.0, 2.0, 0.8178881577375459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1015144.104733252, 1015144.104733252, 203054.869864178]
[2019-03-23 23:48:46,003] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:48:46,005] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.4959250e-19 1.0000000e+00 9.0951064e-31 2.2665725e-28 5.7790785e-33], sampled 0.35728626502665295
[2019-03-23 23:48:46,708] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.03171073]
[2019-03-23 23:48:46,711] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [33.25, 29.0, 1.0, 2.0, 0.9051399032794158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.978751374349955, 6.9112, 121.9257173744958, 1143867.814642963, 1109275.565578507, 222102.183736297]
[2019-03-23 23:48:46,713] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:48:46,716] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.4959250e-19 1.0000000e+00 9.0951064e-31 2.2665725e-28 5.7790785e-33], sampled 0.8439441003438649
[2019-03-23 23:48:54,324] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.03171073]
[2019-03-23 23:48:54,324] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.15, 77.0, 1.0, 2.0, 0.3842636436347148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 476630.7353764325, 476630.7353764325, 126435.7443800559]
[2019-03-23 23:48:54,325] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:48:54,327] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.4959250e-19 1.0000000e+00 9.0951064e-31 2.2665725e-28 5.7790785e-33], sampled 0.1975648420219096
[2019-03-23 23:49:03,338] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.03171073]
[2019-03-23 23:49:03,339] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.429913945, 89.33077532833335, 1.0, 2.0, 0.4068758442600448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 504460.8452388335, 504460.8452388335, 129599.050745776]
[2019-03-23 23:49:03,340] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:49:03,347] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.4959250e-19 1.0000000e+00 9.0951064e-31 2.2665725e-28 5.7790785e-33], sampled 0.9219212983679986
[2019-03-23 23:49:40,202] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.03171073]
[2019-03-23 23:49:40,204] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.51810342, 94.04277949, 1.0, 2.0, 0.9671766108308727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.942437927258876, 6.9112, 121.9256591470935, 1118534.853241741, 1102538.292781746, 232894.6744897685]
[2019-03-23 23:49:40,205] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:49:40,208] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.4959250e-19 1.0000000e+00 9.0951064e-31 2.2665725e-28 5.7790785e-33], sampled 0.3276334092484219
[2019-03-23 23:50:15,183] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:50:15,636] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:50:15,640] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:50:15,644] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:50:15,689] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:50:16,703] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1625000, evaluation results [1625000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:50:19,193] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.91714061e-16 1.00000000e+00 1.01750706e-25 8.73897113e-24
 2.09907875e-27], sum to 1.0000
[2019-03-23 23:50:19,200] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2560
[2019-03-23 23:50:19,204] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.93333333333334, 84.33333333333334, 1.0, 2.0, 0.7657825724417399, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 889990.058810675, 889990.058810675, 189834.3537747633], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5282400.0000, 
sim time next is 5283000.0000, 
raw observation next is [24.85, 84.5, 1.0, 2.0, 0.7290319679811303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 848400.0330399806, 848400.0330399806, 182576.9569712107], 
processed observation next is [1.0, 0.13043478260869565, 0.475925925925926, 0.845, 1.0, 1.0, 0.6774190095013456, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3030000117999931, 0.3030000117999931, 0.3511095326369436], 
reward next is 0.6489, 
noisyNet noise sample is [array([-1.9524397], dtype=float32), 0.60717124]. 
=============================================
[2019-03-23 23:50:19,246] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[51.061142]
 [51.061142]
 [51.061142]
 [51.061142]
 [51.061142]], R is [[51.19942856]
 [51.32236862]
 [51.40084839]
 [51.49229431]
 [51.59607315]].
[2019-03-23 23:50:24,147] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2703011e-15 1.0000000e+00 3.3028865e-24 5.8876361e-21 2.1009555e-25], sum to 1.0000
[2019-03-23 23:50:24,156] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5665
[2019-03-23 23:50:24,165] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1887307.244142438 W.
[2019-03-23 23:50:24,169] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.5, 80.0, 1.0, 2.0, 0.5516049099196986, 1.0, 1.0, 0.5516049099196986, 1.0, 2.0, 0.878172981109908, 6.9112, 6.9112, 121.94756008, 1887307.244142438, 1887307.244142438, 369638.6835877748], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5398200.0000, 
sim time next is 5398800.0000, 
raw observation next is [27.33333333333334, 81.33333333333334, 1.0, 2.0, 0.8180316474391575, 1.0, 2.0, 0.8180316474391575, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426037912, 1865899.343112458, 1865899.343112458, 351261.846847995], 
processed observation next is [1.0, 0.4782608695652174, 0.5679012345679014, 0.8133333333333335, 1.0, 1.0, 0.7833710088561399, 1.0, 1.0, 0.7833710088561399, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621287413275, 0.6663926225401636, 0.6663926225401636, 0.6755035516307596], 
reward next is 0.3245, 
noisyNet noise sample is [array([-1.280507], dtype=float32), 0.9143978]. 
=============================================
[2019-03-23 23:50:30,695] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.7495889e-20 1.0000000e+00 1.5870848e-30 7.5840242e-28 2.1867736e-33], sum to 1.0000
[2019-03-23 23:50:30,702] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3821
[2019-03-23 23:50:30,706] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 88.5, 1.0, 2.0, 0.6767768588703053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 771320.8489896905, 771320.848989691, 171793.6432992636], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5524200.0000, 
sim time next is 5524800.0000, 
raw observation next is [25.96666666666667, 89.0, 1.0, 2.0, 0.6795173350306508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 774445.7404686357, 774445.7404686357, 172302.1657943083], 
processed observation next is [1.0, 0.9565217391304348, 0.517283950617284, 0.89, 1.0, 1.0, 0.618473017893632, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2765877644530842, 0.2765877644530842, 0.33135031883520827], 
reward next is 0.6686, 
noisyNet noise sample is [array([-0.39702857], dtype=float32), -1.0828493]. 
=============================================
[2019-03-23 23:50:33,690] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0573422e-17 1.0000000e+00 1.6795616e-28 1.3973828e-25 2.2293470e-29], sum to 1.0000
[2019-03-23 23:50:33,697] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9901
[2019-03-23 23:50:33,710] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1595616.37714986 W.
[2019-03-23 23:50:33,721] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.96666666666667, 82.66666666666667, 1.0, 2.0, 0.6996422331428541, 1.0, 2.0, 0.6996422331428541, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426155844, 1595616.37714986, 1595616.37714986, 304029.1463540169], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5562600.0000, 
sim time next is 5563200.0000, 
raw observation next is [26.03333333333333, 82.33333333333334, 1.0, 2.0, 0.7365095110074007, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1554473.516663485, 1554473.516663485, 323964.6840225011], 
processed observation next is [1.0, 0.391304347826087, 0.519753086419753, 0.8233333333333335, 1.0, 1.0, 0.6863208464373818, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, 0.0, 0.0, 0.8094621288201359, 0.5551691130941018, 0.5551691130941018, 0.6230090077355791], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2442489], dtype=float32), -0.07327508]. 
=============================================
[2019-03-23 23:50:35,849] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.8228362e-18 1.0000000e+00 1.0346285e-30 4.6360080e-26 3.4383621e-33], sum to 1.0000
[2019-03-23 23:50:35,859] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2559
[2019-03-23 23:50:35,864] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2522270.138533395 W.
[2019-03-23 23:50:35,868] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.7, 79.0, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 7.291674451212445, 6.9112, 121.9243663846286, 2522270.138533395, 2327435.891697005, 443048.799689853], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5583600.0000, 
sim time next is 5584200.0000, 
raw observation next is [28.38333333333333, 80.00000000000001, 1.0, 2.0, 0.647241769369027, 1.0, 2.0, 0.6369855466609481, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2179792.18558728, 2179792.18558728, 415363.9190524073], 
processed observation next is [1.0, 0.6521739130434783, 0.60679012345679, 0.8000000000000002, 1.0, 1.0, 0.5800497254393179, 1.0, 1.0, 0.5678399365011286, 1.0, 0.5, 0.9972168686025908, 0.0, 0.0, 0.8096049824067558, 0.7784972091383143, 0.7784972091383143, 0.7987767674084756], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9345135], dtype=float32), -0.11534088]. 
=============================================
[2019-03-23 23:50:36,660] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0904685e-18 1.0000000e+00 9.9105382e-29 1.2502756e-26 9.1179941e-32], sum to 1.0000
[2019-03-23 23:50:36,669] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2758
[2019-03-23 23:50:36,675] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333334, 95.66666666666666, 1.0, 2.0, 0.6315028945720793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 720224.5809745941, 720224.5809745941, 163607.1322121412], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5642400.0000, 
sim time next is 5643000.0000, 
raw observation next is [24.4, 95.5, 1.0, 2.0, 0.6338604019379994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 722386.0257502102, 722386.0257502102, 163999.3525966698], 
processed observation next is [0.0, 0.30434782608695654, 0.4592592592592592, 0.955, 1.0, 1.0, 0.5641195261166659, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25799500919650364, 0.25799500919650364, 0.3153833703782112], 
reward next is 0.6846, 
noisyNet noise sample is [array([-1.1863489], dtype=float32), -0.7668368]. 
=============================================
[2019-03-23 23:50:36,687] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[64.66626]
 [64.66626]
 [64.66626]
 [64.66626]
 [64.66626]], R is [[64.704216  ]
 [64.74254608]
 [64.78153992]
 [64.82118225]
 [64.8615799 ]].
[2019-03-23 23:50:37,181] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.32594383e-19 1.00000000e+00 8.98512911e-32 1.00439756e-28
 1.31121289e-33], sum to 1.0000
[2019-03-23 23:50:37,186] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8837
[2019-03-23 23:50:37,191] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 97.0, 1.0, 2.0, 0.5872549618468059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 679585.1008348123, 679585.1008348123, 156396.6314352482], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5631000.0000, 
sim time next is 5631600.0000, 
raw observation next is [23.5, 97.0, 1.0, 2.0, 0.5861188761182717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 678270.840149452, 678270.840149452, 156202.8190717093], 
processed observation next is [0.0, 0.17391304347826086, 0.42592592592592593, 0.97, 1.0, 1.0, 0.5072843763312759, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24223958576766141, 0.24223958576766141, 0.30039003667636405], 
reward next is 0.6996, 
noisyNet noise sample is [array([-1.9729067], dtype=float32), 0.79447377]. 
=============================================
[2019-03-23 23:50:42,451] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.7246473e-22 1.0000000e+00 4.1519206e-33 1.0819535e-33 2.6222681e-36], sum to 1.0000
[2019-03-23 23:50:42,462] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5981
[2019-03-23 23:50:42,474] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 71.33333333333334, 1.0, 2.0, 0.5789852915586078, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 672264.3503161912, 672264.3503161912, 155093.4591573004], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5768400.0000, 
sim time next is 5769000.0000, 
raw observation next is [26.85, 72.0, 1.0, 2.0, 0.5767372812473405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 670163.688285594, 670163.688285594, 154735.8817524811], 
processed observation next is [0.0, 0.782608695652174, 0.55, 0.72, 1.0, 1.0, 0.49611581100873864, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23934417438771213, 0.23934417438771213, 0.29756900337015596], 
reward next is 0.7024, 
noisyNet noise sample is [array([-0.12095606], dtype=float32), -0.40558213]. 
=============================================
[2019-03-23 23:50:42,492] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[76.36186]
 [76.36186]
 [76.36186]
 [76.36186]
 [76.36186]], R is [[76.30067444]
 [76.2394104 ]
 [76.17805481]
 [76.11649323]
 [76.05435181]].
[2019-03-23 23:50:43,689] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3557263e-21 1.0000000e+00 2.0280593e-33 1.5798430e-29 1.2908733e-35], sum to 1.0000
[2019-03-23 23:50:43,698] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6082
[2019-03-23 23:50:43,701] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.2, 78.66666666666667, 1.0, 2.0, 0.5462266869282787, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 642061.3050683191, 642061.3050683186, 149973.6122061635], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5775600.0000, 
sim time next is 5776200.0000, 
raw observation next is [25.1, 79.0, 1.0, 2.0, 0.543665885485874, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 639657.8298117267, 639657.8298117267, 149578.1290886214], 
processed observation next is [0.0, 0.8695652173913043, 0.4851851851851852, 0.79, 1.0, 1.0, 0.4567451017688976, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22844922493275954, 0.22844922493275954, 0.28765024824734886], 
reward next is 0.7123, 
noisyNet noise sample is [array([-0.00380991], dtype=float32), -1.3897533]. 
=============================================
[2019-03-23 23:50:46,550] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0735909e-18 1.0000000e+00 5.3622426e-30 4.1354131e-28 9.9147534e-33], sum to 1.0000
[2019-03-23 23:50:46,560] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9646
[2019-03-23 23:50:46,568] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1683681.079660355 W.
[2019-03-23 23:50:46,574] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 58.0, 1.0, 2.0, 0.7382202910509804, 1.0, 2.0, 0.7382202910509804, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1683681.079660355, 1683681.079660355, 318885.6607331043], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6018000.0000, 
sim time next is 6018600.0000, 
raw observation next is [29.0, 58.0, 1.0, 2.0, 0.7441744385928958, 1.0, 2.0, 0.7441744385928958, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1697273.782214271, 1697273.782214272, 321224.6886305038], 
processed observation next is [1.0, 0.6521739130434783, 0.6296296296296297, 0.58, 1.0, 1.0, 0.6954457602296378, 1.0, 1.0, 0.6954457602296378, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6061692079336681, 0.6061692079336686, 0.6177397858278919], 
reward next is 0.3823, 
noisyNet noise sample is [array([0.9006273], dtype=float32), 1.3900794]. 
=============================================
[2019-03-23 23:50:51,136] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.6093830e-19 1.0000000e+00 2.1614475e-31 4.7345170e-27 5.8342775e-33], sum to 1.0000
[2019-03-23 23:50:51,144] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6036
[2019-03-23 23:50:51,148] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.83333333333333, 77.66666666666667, 1.0, 2.0, 0.3550474142840928, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 446987.2389432958, 446987.2389432958, 122595.3190878374], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5899800.0000, 
sim time next is 5900400.0000, 
raw observation next is [21.0, 77.0, 1.0, 2.0, 0.3517448257975024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 442437.5985458789, 442437.5985458789, 122150.8068210318], 
processed observation next is [1.0, 0.30434782608695654, 0.3333333333333333, 0.77, 1.0, 1.0, 0.2282676497589314, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1580134280520996, 0.1580134280520996, 0.23490539773275346], 
reward next is 0.7651, 
noisyNet noise sample is [array([0.05407136], dtype=float32), 0.21676205]. 
=============================================
[2019-03-23 23:51:03,569] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.0229597e-21 1.0000000e+00 1.3699326e-31 1.3648640e-29 7.3336090e-34], sum to 1.0000
[2019-03-23 23:51:03,577] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9237
[2019-03-23 23:51:03,580] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.23333333333333, 71.0, 1.0, 2.0, 0.5390181173937724, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 635713.1273696017, 635713.1273696017, 148879.8173068573], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6128400.0000, 
sim time next is 6129000.0000, 
raw observation next is [26.15, 71.5, 1.0, 2.0, 0.5387126521117381, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 635369.0226849256, 635369.0226849256, 148830.569582913], 
processed observation next is [1.0, 0.9565217391304348, 0.524074074074074, 0.715, 1.0, 1.0, 0.4508483953711168, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22691750810175915, 0.22691750810175915, 0.28621263381329426], 
reward next is 0.7138, 
noisyNet noise sample is [array([1.3570778], dtype=float32), -2.1273649]. 
=============================================
[2019-03-23 23:51:03,593] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[67.92089]
 [67.92089]
 [67.92089]
 [67.92089]
 [67.92089]], R is [[67.95547485]
 [67.98960876]
 [68.02333069]
 [68.05653381]
 [68.08905792]].
[2019-03-23 23:51:07,011] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-23 23:51:07,012] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:51:07,013] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:51:07,014] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:51:07,016] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:51:07,017] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:51:07,019] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:51:07,020] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:51:07,020] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:51:07,020] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:51:07,021] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:51:07,042] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run67
[2019-03-23 23:51:07,043] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run67
[2019-03-23 23:51:07,095] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run67
[2019-03-23 23:51:07,118] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run67
[2019-03-23 23:51:07,152] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run67
[2019-03-23 23:51:29,574] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.052287765]
[2019-03-23 23:51:29,575] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.41950112333333, 86.95535484333334, 1.0, 2.0, 0.4110746052561527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 503839.736399739, 503839.736399739, 130052.7768506483]
[2019-03-23 23:51:29,575] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:51:29,577] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.9385617e-20 1.0000000e+00 2.9421219e-32 9.8174798e-30 1.5604389e-34], sampled 0.7804866474565875
[2019-03-23 23:51:38,103] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.052287765]
[2019-03-23 23:51:38,103] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.40380956, 35.63624974, 1.0, 2.0, 0.6477064410741074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 821042.4877685711, 821042.4877685711, 169287.1001399365]
[2019-03-23 23:51:38,104] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:51:38,107] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.9385617e-20 1.0000000e+00 2.9421219e-32 9.8174798e-30 1.5604389e-34], sampled 0.4159870048712069
[2019-03-23 23:51:41,650] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.052287765]
[2019-03-23 23:51:41,652] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.43333333333334, 71.66666666666666, 1.0, 2.0, 0.5993518994662593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 689317.0912123594, 689317.0912123594, 158273.4127797359]
[2019-03-23 23:51:41,653] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:51:41,655] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.9385617e-20 1.0000000e+00 2.9421219e-32 9.8174798e-30 1.5604389e-34], sampled 0.9025506330055404
[2019-03-23 23:51:56,921] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.052287765]
[2019-03-23 23:51:56,922] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.06666666666666, 81.66666666666667, 1.0, 2.0, 0.7243825469330544, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 825606.1501616294, 825606.150161629, 180814.8717058795]
[2019-03-23 23:51:56,923] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:51:56,927] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.9385617e-20 1.0000000e+00 2.9421219e-32 9.8174798e-30 1.5604389e-34], sampled 0.8604106896907634
[2019-03-23 23:51:59,744] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.052287765]
[2019-03-23 23:51:59,746] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [30.31006511666667, 69.98512717666667, 1.0, 2.0, 0.7946699697110474, 1.0, 1.0, 0.7946699697110474, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9257076527852, 1812558.174012271, 1812558.174012272, 341557.939682004]
[2019-03-23 23:51:59,747] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:51:59,750] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.9385617e-20 1.0000000e+00 2.9421219e-32 9.8174798e-30 1.5604389e-34], sampled 0.960303355351609
[2019-03-23 23:51:59,752] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1812558.174012271 W.
[2019-03-23 23:52:24,279] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.052287765]
[2019-03-23 23:52:24,280] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.11625655666667, 76.56134781333333, 1.0, 2.0, 0.3189903953258409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 404727.2115785937, 404727.2115785932, 117940.9396854982]
[2019-03-23 23:52:24,282] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:52:24,285] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.9385617e-20 1.0000000e+00 2.9421219e-32 9.8174798e-30 1.5604389e-34], sampled 0.45519304761173063
[2019-03-23 23:52:38,350] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.052287765]
[2019-03-23 23:52:38,351] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.69838487, 51.42000638, 1.0, 2.0, 0.5000236151997371, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 599747.2537336687, 599747.2537336687, 143019.2713324403]
[2019-03-23 23:52:38,353] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:52:38,355] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.9385617e-20 1.0000000e+00 2.9421219e-32 9.8174798e-30 1.5604389e-34], sampled 0.008314100567851312
[2019-03-23 23:52:51,731] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:52:52,137] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:52:52,310] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:52:52,375] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:52:52,417] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:52:53,434] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1650000, evaluation results [1650000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:52:57,500] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5677487e-18 1.0000000e+00 8.9266787e-31 5.3542479e-31 5.8442376e-32], sum to 1.0000
[2019-03-23 23:52:57,509] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0567
[2019-03-23 23:52:57,513] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.81666666666667, 78.0, 1.0, 2.0, 0.5809760559518485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 676224.6971419407, 676224.6971419412, 155505.2926710593], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6300600.0000, 
sim time next is 6301200.0000, 
raw observation next is [25.63333333333333, 79.0, 1.0, 2.0, 0.5801445960835416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 675673.0520231838, 675673.0520231838, 155382.5489331268], 
processed observation next is [0.0, 0.9565217391304348, 0.5049382716049381, 0.79, 1.0, 1.0, 0.5001721381946924, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2413118042939942, 0.2413118042939942, 0.29881259410216693], 
reward next is 0.7012, 
noisyNet noise sample is [array([1.0880283], dtype=float32), 0.75283206]. 
=============================================
[2019-03-23 23:53:06,583] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.0234742e-13 1.0000000e+00 1.0817094e-19 2.1735740e-19 1.5886850e-21], sum to 1.0000
[2019-03-23 23:53:06,591] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2233
[2019-03-23 23:53:06,609] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2114325.196837681 W.
[2019-03-23 23:53:06,613] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.5, 55.0, 1.0, 2.0, 0.617877202882221, 1.0, 2.0, 0.617877202882221, 1.0, 1.0, 0.9836806298441441, 6.911199999999999, 6.9112, 121.94756008, 2114325.196837681, 2114325.196837682, 405202.0187188351], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6453600.0000, 
sim time next is 6454200.0000, 
raw observation next is [31.45, 55.0, 1.0, 2.0, 0.6181023684364721, 1.0, 2.0, 0.6181023684364721, 1.0, 2.0, 0.984039100739642, 6.9112, 6.9112, 121.94756008, 2115096.607329814, 2115096.607329814, 405326.88003142], 
processed observation next is [1.0, 0.6956521739130435, 0.7203703703703703, 0.55, 1.0, 1.0, 0.5453599624243716, 1.0, 1.0, 0.5453599624243716, 1.0, 1.0, 0.9800488759245524, 0.0, 0.0, 0.8096049824067558, 0.7553916454749336, 0.7553916454749336, 0.7794747692911923], 
reward next is 0.2205, 
noisyNet noise sample is [array([-0.48843363], dtype=float32), -0.17565799]. 
=============================================
[2019-03-23 23:53:09,270] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.84981570e-17 1.00000000e+00 1.03200525e-26 1.39322512e-26
 3.91423805e-29], sum to 1.0000
[2019-03-23 23:53:09,278] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3133
[2019-03-23 23:53:09,288] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2132515.137580723 W.
[2019-03-23 23:53:09,295] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.9, 82.0, 1.0, 2.0, 0.9347796711929727, 1.0, 2.0, 0.9347796711929727, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2132515.137580723, 2132515.137580723, 402595.6262757124], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6516000.0000, 
sim time next is 6516600.0000, 
raw observation next is [28.03333333333333, 81.50000000000001, 1.0, 2.0, 0.57712560341085, 1.0, 2.0, 0.57712560341085, 1.0, 1.0, 0.9188027562987823, 6.9112, 6.9112, 121.94756008, 1974722.400553012, 1974722.400553012, 383053.3735773791], 
processed observation next is [1.0, 0.43478260869565216, 0.5938271604938271, 0.8150000000000002, 1.0, 1.0, 0.4965780992986309, 1.0, 1.0, 0.4965780992986309, 1.0, 0.5, 0.8985034453734777, 0.0, 0.0, 0.8096049824067558, 0.7052580001975043, 0.7052580001975043, 0.7366411030334213], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.05299734], dtype=float32), -0.2450781]. 
=============================================
[2019-03-23 23:53:09,616] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2859792e-18 1.0000000e+00 3.6097794e-28 1.9512069e-25 3.6772390e-30], sum to 1.0000
[2019-03-23 23:53:09,626] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1485
[2019-03-23 23:53:09,636] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2184022.079215945 W.
[2019-03-23 23:53:09,640] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.76666666666667, 82.5, 1.0, 2.0, 0.6497108949273107, 1.0, 2.0, 0.6382201094400901, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2184022.079215945, 2184022.079215945, 415999.9114367143], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6515400.0000, 
sim time next is 6516000.0000, 
raw observation next is [27.9, 82.0, 1.0, 2.0, 0.6232008783934662, 1.0, 2.0, 0.6232008783934662, 1.0, 2.0, 0.9921560946380534, 6.911200000000001, 6.9112, 121.94756008, 2132564.129173053, 2132564.129173052, 408161.4588422534], 
processed observation next is [1.0, 0.43478260869565216, 0.5888888888888888, 0.82, 1.0, 1.0, 0.5514296171350788, 1.0, 1.0, 0.5514296171350788, 1.0, 1.0, 0.9901951182975668, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7616300461332332, 0.7616300461332328, 0.7849258823889489], 
reward next is 0.2151, 
noisyNet noise sample is [array([-0.8808347], dtype=float32), -0.4584852]. 
=============================================
[2019-03-23 23:53:09,654] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[57.25549]
 [57.25549]
 [57.25549]
 [57.25549]
 [57.25549]], R is [[56.89800644]
 [56.52902603]
 [56.18240356]
 [55.86688614]
 [55.57394409]].
[2019-03-23 23:53:14,590] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.4114879e-19 1.0000000e+00 1.9177893e-29 7.1492243e-28 1.3421757e-31], sum to 1.0000
[2019-03-23 23:53:14,602] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3603
[2019-03-23 23:53:14,614] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1334229.457214697 W.
[2019-03-23 23:53:14,618] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 51.5, 1.0, 2.0, 0.5625765142314343, 1.0, 2.0, 0.5625765142314343, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.926042615633, 1334229.457214697, 1334229.457214697, 257724.1997659646], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6793800.0000, 
sim time next is 6794400.0000, 
raw observation next is [28.0, 52.00000000000001, 1.0, 2.0, 0.4515016743480427, 1.0, 2.0, 0.4515016743480427, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1073552.89493084, 1073552.894930841, 222724.9364607846], 
processed observation next is [1.0, 0.6521739130434783, 0.5925925925925926, 0.52, 1.0, 1.0, 0.347025802795289, 1.0, 1.0, 0.347025802795289, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.38341174818958573, 0.38341174818958607, 0.4283171855015089], 
reward next is 0.5717, 
noisyNet noise sample is [array([0.40285006], dtype=float32), -0.34866896]. 
=============================================
[2019-03-23 23:53:20,869] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.5295291e-20 1.0000000e+00 3.9286936e-34 8.8359890e-30 2.8316295e-36], sum to 1.0000
[2019-03-23 23:53:20,875] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6082
[2019-03-23 23:53:20,880] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.05, 33.5, 1.0, 2.0, 0.8195301993023086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260425848816, 1040553.207292237, 1040553.207292237, 203814.9327012603], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6696600.0000, 
sim time next is 6697200.0000, 
raw observation next is [28.2, 33.0, 1.0, 2.0, 0.621672585835254, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156524, 789495.1336702545, 789495.1336702545, 164531.115799601], 
processed observation next is [1.0, 0.5217391304347826, 0.6, 0.33, 1.0, 1.0, 0.5496102212324452, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288200736, 0.2819625477393766, 0.2819625477393766, 0.3164059919223096], 
reward next is 0.6836, 
noisyNet noise sample is [array([1.9367744], dtype=float32), -1.065353]. 
=============================================
[2019-03-23 23:53:31,200] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.8863527e-20 1.0000000e+00 3.9522371e-32 8.9199099e-30 1.1373989e-34], sum to 1.0000
[2019-03-23 23:53:31,211] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6378
[2019-03-23 23:53:31,214] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.2, 72.0, 1.0, 2.0, 0.4105530689806585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 506774.4371653355, 506774.4371653359, 130071.1324403012], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6913800.0000, 
sim time next is 6914400.0000, 
raw observation next is [23.16666666666667, 72.33333333333333, 1.0, 2.0, 0.4112048771921649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 507460.512861023, 507460.5128610226, 130161.2760578632], 
processed observation next is [0.0, 0.0, 0.4135802469135804, 0.7233333333333333, 1.0, 1.0, 0.2990534252287677, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18123589745036536, 0.18123589745036522, 0.25031014626512155], 
reward next is 0.7497, 
noisyNet noise sample is [array([0.16213651], dtype=float32), -1.6624637]. 
=============================================
[2019-03-23 23:53:32,522] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3774233e-20 1.0000000e+00 3.7185380e-32 9.0664234e-31 4.7250255e-35], sum to 1.0000
[2019-03-23 23:53:32,530] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9715
[2019-03-23 23:53:32,534] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.33333333333334, 51.0, 1.0, 2.0, 0.5423544118301165, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 637023.1647379935, 637023.1647379935, 149317.912949085], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6960000.0000, 
sim time next is 6960600.0000, 
raw observation next is [30.5, 50.5, 1.0, 2.0, 0.5447708521170459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 639294.0155717502, 639294.0155717502, 149690.3510431191], 
processed observation next is [0.0, 0.5652173913043478, 0.6851851851851852, 0.505, 1.0, 1.0, 0.45806053823457843, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22831929127562509, 0.22831929127562509, 0.287866059698306], 
reward next is 0.7121, 
noisyNet noise sample is [array([1.0270694], dtype=float32), 0.9457898]. 
=============================================
[2019-03-23 23:53:33,373] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.7515664e-23 1.0000000e+00 7.9687261e-35 1.0860566e-31 2.3419477e-37], sum to 1.0000
[2019-03-23 23:53:33,385] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3786
[2019-03-23 23:53:33,394] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.5, 53.5, 1.0, 2.0, 0.529985691695724, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 625446.7565765228, 625446.7565765228, 147426.8171063525], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6957000.0000, 
sim time next is 6957600.0000, 
raw observation next is [29.66666666666667, 53.0, 1.0, 2.0, 0.5327738407030639, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 628119.4119056661, 628119.4119056661, 147853.7391272896], 
processed observation next is [0.0, 0.5217391304347826, 0.6543209876543211, 0.53, 1.0, 1.0, 0.44377838178936174, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22432836139488074, 0.22432836139488074, 0.28433411370632616], 
reward next is 0.7157, 
noisyNet noise sample is [array([-1.49505], dtype=float32), 0.12559249]. 
=============================================
[2019-03-23 23:53:34,189] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.2574915e-20 1.0000000e+00 5.2968377e-31 4.2942337e-27 8.0558685e-34], sum to 1.0000
[2019-03-23 23:53:34,195] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4211
[2019-03-23 23:53:34,202] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.21666666666667, 86.66666666666667, 1.0, 2.0, 0.4134262051690388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 510114.426958031, 510114.426958031, 130476.7507855101], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6930600.0000, 
sim time next is 6931200.0000, 
raw observation next is [21.33333333333334, 86.33333333333334, 1.0, 2.0, 0.4163100644701059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 513133.3807447147, 513133.3807447147, 130877.0320757055], 
processed observation next is [0.0, 0.21739130434782608, 0.3456790123456792, 0.8633333333333334, 1.0, 1.0, 0.3051310291310784, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18326192169454097, 0.18326192169454097, 0.2516866001455875], 
reward next is 0.7483, 
noisyNet noise sample is [array([-0.3681061], dtype=float32), -0.5950095]. 
=============================================
[2019-03-23 23:53:43,630] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-23 23:53:43,631] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:53:43,631] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:53:43,632] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:53:43,635] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:53:43,635] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:53:43,636] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:53:43,637] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:53:43,637] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:53:43,638] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:53:43,640] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:53:43,663] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run68
[2019-03-23 23:53:43,689] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run68
[2019-03-23 23:53:43,713] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run68
[2019-03-23 23:53:43,735] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run68
[2019-03-23 23:53:43,759] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run68
[2019-03-23 23:54:16,395] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.06777675]
[2019-03-23 23:54:16,398] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.4591968, 94.75873544000001, 1.0, 2.0, 0.4543719719292652, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 551465.1640526968, 551465.1640526968, 136233.2046634351]
[2019-03-23 23:54:16,399] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:54:16,402] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [5.0966269e-21 1.0000000e+00 1.7900018e-33 8.5356566e-31 1.0640005e-35], sampled 0.8461334472109018
[2019-03-23 23:54:24,593] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.06777675]
[2019-03-23 23:54:24,594] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.5, 86.5, 1.0, 2.0, 0.6272289199613283, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 716000.2585091724, 716000.2585091724, 162882.8755484515]
[2019-03-23 23:54:24,595] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:54:24,598] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.0966269e-21 1.0000000e+00 1.7900018e-33 8.5356566e-31 1.0640005e-35], sampled 0.4062658782877724
[2019-03-23 23:54:25,130] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.06777675]
[2019-03-23 23:54:25,131] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.95, 81.0, 1.0, 2.0, 0.6011008178770356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 692517.8270083712, 692517.8270083712, 158632.3012117277]
[2019-03-23 23:54:25,132] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:54:25,134] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.0966269e-21 1.0000000e+00 1.7900018e-33 8.5356566e-31 1.0640005e-35], sampled 0.8176206641840537
[2019-03-23 23:54:36,016] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.06777675]
[2019-03-23 23:54:36,017] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.8, 81.0, 1.0, 2.0, 0.771816592869658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 879699.5502335092, 879699.5502335092, 190186.5105161167]
[2019-03-23 23:54:36,019] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:54:36,023] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.0966269e-21 1.0000000e+00 1.7900018e-33 8.5356566e-31 1.0640005e-35], sampled 0.0052901280308785825
[2019-03-23 23:54:53,244] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.06777675]
[2019-03-23 23:54:53,245] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.75430810333333, 102.149346075, 1.0, 2.0, 0.5536195251566282, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8813803141785376, 6.9112, 6.9112, 121.9260425056757, 1262321.60223002, 1262321.60223002, 276251.520742226]
[2019-03-23 23:54:53,246] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:54:53,248] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.0966269e-21 1.0000000e+00 1.7900018e-33 8.5356566e-31 1.0640005e-35], sampled 0.052034060635606005
[2019-03-23 23:55:19,126] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.06777675]
[2019-03-23 23:55:19,128] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.83333333333333, 88.0, 1.0, 2.0, 0.5924824690202164, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 683308.732143937, 683308.732143937, 157182.8715275171]
[2019-03-23 23:55:19,130] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:55:19,132] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.0966269e-21 1.0000000e+00 1.7900018e-33 8.5356566e-31 1.0640005e-35], sampled 0.02220519773043661
[2019-03-23 23:55:28,568] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:55:28,815] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:55:28,940] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:55:28,951] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:55:29,015] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:55:30,032] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1675000, evaluation results [1675000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:55:34,817] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9199263e-22 1.0000000e+00 1.2576568e-33 2.6852167e-32 1.0009282e-36], sum to 1.0000
[2019-03-23 23:55:34,823] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4830
[2019-03-23 23:55:34,829] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.15, 80.0, 1.0, 2.0, 0.3708236512007216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 463179.6834949369, 463179.6834949369, 124660.4459647746], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7252200.0000, 
sim time next is 7252800.0000, 
raw observation next is [21.06666666666667, 80.33333333333334, 1.0, 2.0, 0.3694538484126905, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 461694.139102767, 461694.139102767, 124478.5747352673], 
processed observation next is [1.0, 0.9565217391304348, 0.3358024691358026, 0.8033333333333335, 1.0, 1.0, 0.2493498195389173, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1648907639652739, 0.1648907639652739, 0.23938187449089868], 
reward next is 0.7606, 
noisyNet noise sample is [array([-1.0124081], dtype=float32), -1.3604681]. 
=============================================
[2019-03-23 23:55:35,653] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.4421940e-18 1.0000000e+00 2.1574205e-30 2.0466010e-27 1.1931587e-32], sum to 1.0000
[2019-03-23 23:55:35,659] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6789
[2019-03-23 23:55:35,665] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 78.33333333333333, 1.0, 2.0, 0.38142853099401, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 475035.81730457, 475035.81730457, 126084.9738479952], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7249200.0000, 
sim time next is 7249800.0000, 
raw observation next is [21.5, 78.66666666666667, 1.0, 2.0, 0.3789640473880412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 472295.1838054849, 472295.1838054849, 125752.6083572864], 
processed observation next is [1.0, 0.9130434782608695, 0.35185185185185186, 0.7866666666666667, 1.0, 1.0, 0.2606714849857633, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16867685135910176, 0.16867685135910176, 0.2418319391486277], 
reward next is 0.7582, 
noisyNet noise sample is [array([-0.22524166], dtype=float32), 0.81015956]. 
=============================================
[2019-03-23 23:55:38,812] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.1012005e-19 1.0000000e+00 2.6696043e-29 2.5509048e-28 2.6077207e-31], sum to 1.0000
[2019-03-23 23:55:38,821] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1108
[2019-03-23 23:55:38,830] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1544686.255269044 W.
[2019-03-23 23:55:38,834] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.88333333333333, 61.16666666666666, 1.0, 2.0, 0.4453766188458563, 1.0, 2.0, 0.4453766188458563, 1.0, 1.0, 0.7099855429262556, 6.9112, 6.9112, 121.94756008, 1544686.255269044, 1544686.255269044, 317632.5790138463], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7314600.0000, 
sim time next is 7315200.0000, 
raw observation next is [26.9, 61.0, 1.0, 2.0, 0.6615814600763767, 1.0, 2.0, 0.6615814600763767, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1545403.56543527, 1545403.56543527, 291647.5361039295], 
processed observation next is [1.0, 0.6956521739130435, 0.5518518518518518, 0.61, 1.0, 1.0, 0.5971207858052104, 1.0, 1.0, 0.5971207858052104, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5519298447983108, 0.5519298447983108, 0.5608606463537106], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7335537], dtype=float32), 0.68707484]. 
=============================================
[2019-03-23 23:55:42,863] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.6850195e-19 1.0000000e+00 2.1791980e-31 2.8347414e-29 2.6944193e-33], sum to 1.0000
[2019-03-23 23:55:42,870] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7684
[2019-03-23 23:55:42,875] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.96666666666667, 85.83333333333334, 1.0, 2.0, 0.3972623683990515, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 492399.8274076884, 492399.8274076884, 128238.0749310361], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7344600.0000, 
sim time next is 7345200.0000, 
raw observation next is [20.93333333333334, 85.66666666666667, 1.0, 2.0, 0.3936933990508909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 488343.7337531163, 488343.7337531159, 127746.228495835], 
processed observation next is [1.0, 0.0, 0.3308641975308645, 0.8566666666666667, 1.0, 1.0, 0.2782064274415368, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17440847634039866, 0.17440847634039855, 0.24566582403045192], 
reward next is 0.7543, 
noisyNet noise sample is [array([0.95311874], dtype=float32), -0.8470263]. 
=============================================
[2019-03-23 23:55:45,514] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.7844553e-23 1.0000000e+00 5.6462099e-36 1.6490663e-31 2.9315946e-37], sum to 1.0000
[2019-03-23 23:55:45,522] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1729
[2019-03-23 23:55:45,527] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.7, 93.33333333333334, 1.0, 2.0, 0.3754560350963287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 467689.6465647614, 467689.6465647614, 125267.5077177709], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7438800.0000, 
sim time next is 7439400.0000, 
raw observation next is [19.65, 93.5, 1.0, 2.0, 0.3744653175367746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 466647.3483365036, 466647.3483365036, 125135.9892738588], 
processed observation next is [0.0, 0.08695652173913043, 0.28333333333333327, 0.935, 1.0, 1.0, 0.25531585421044595, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.166659767263037, 0.166659767263037, 0.24064613321895922], 
reward next is 0.7594, 
noisyNet noise sample is [array([1.5140421], dtype=float32), 0.42996973]. 
=============================================
[2019-03-23 23:55:47,777] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.7328175e-20 1.0000000e+00 9.4731466e-33 1.4361216e-30 2.0547989e-35], sum to 1.0000
[2019-03-23 23:55:47,788] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1633
[2019-03-23 23:55:47,797] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.9, 92.5, 1.0, 2.0, 0.3803009537742372, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 473095.6242887283, 473095.6242887279, 125919.0130290878], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7435800.0000, 
sim time next is 7436400.0000, 
raw observation next is [19.86666666666667, 92.66666666666667, 1.0, 2.0, 0.3797144451492913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 472454.093893419, 472454.093893419, 125840.2092169544], 
processed observation next is [0.0, 0.043478260869565216, 0.2913580246913582, 0.9266666666666667, 1.0, 1.0, 0.26156481565391826, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16873360496193537, 0.16873360496193537, 0.24200040234029693], 
reward next is 0.7580, 
noisyNet noise sample is [array([1.0524192], dtype=float32), 0.6740738]. 
=============================================
[2019-03-23 23:55:49,471] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.8751096e-20 1.0000000e+00 7.9996256e-31 6.1489409e-31 1.9843770e-33], sum to 1.0000
[2019-03-23 23:55:49,481] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9188
[2019-03-23 23:55:49,487] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333333, 74.33333333333334, 1.0, 2.0, 0.509598815871246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 605074.1236647009, 605074.1236647009, 144308.425016194], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7482000.0000, 
sim time next is 7482600.0000, 
raw observation next is [25.3, 74.5, 1.0, 2.0, 0.5093271692112175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 604828.7724804659, 604828.7724804656, 144268.3128904964], 
processed observation next is [0.0, 0.6086956521739131, 0.49259259259259264, 0.745, 1.0, 1.0, 0.41586567763240173, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2160102758858807, 0.21601027588588056, 0.27743906325095463], 
reward next is 0.7226, 
noisyNet noise sample is [array([1.061893], dtype=float32), 0.0463363]. 
=============================================
[2019-03-23 23:55:52,012] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.5430519e-21 1.0000000e+00 1.5013955e-30 5.5609865e-28 1.2704100e-34], sum to 1.0000
[2019-03-23 23:55:52,021] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0798
[2019-03-23 23:55:52,024] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.9, 87.66666666666666, 1.0, 2.0, 0.4771896816415909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 572160.1558727993, 572160.1558727993, 139465.5090735751], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7551600.0000, 
sim time next is 7552200.0000, 
raw observation next is [23.1, 86.83333333333333, 1.0, 2.0, 0.4817097468288104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 576662.2134818739, 576662.2134818734, 140127.9247231103], 
processed observation next is [0.0, 0.391304347826087, 0.41111111111111115, 0.8683333333333333, 1.0, 1.0, 0.38298779384382187, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20595079052924067, 0.2059507905292405, 0.26947677831367367], 
reward next is 0.7305, 
noisyNet noise sample is [array([-1.0286416], dtype=float32), -1.5634276]. 
=============================================
[2019-03-23 23:55:52,040] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.3949347e-19 1.0000000e+00 1.5269484e-30 1.4372097e-26 1.7541101e-31], sum to 1.0000
[2019-03-23 23:55:52,048] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0607
[2019-03-23 23:55:52,051] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.9, 96.0, 1.0, 2.0, 0.4376790944393379, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 533168.5250358587, 533168.5250358587, 133815.1866299729], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7530600.0000, 
sim time next is 7531200.0000, 
raw observation next is [20.9, 96.0, 1.0, 2.0, 0.4377585527517444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 533265.4717438206, 533265.471743821, 133826.8733552294], 
processed observation next is [0.0, 0.17391304347826086, 0.32962962962962955, 0.96, 1.0, 1.0, 0.3306649437520767, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19045195419422165, 0.1904519541942218, 0.25735937183697966], 
reward next is 0.7426, 
noisyNet noise sample is [array([0.33163884], dtype=float32), -0.8004072]. 
=============================================
[2019-03-23 23:55:52,250] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.4269890e-20 1.0000000e+00 1.6788792e-32 2.4140300e-31 1.3892861e-35], sum to 1.0000
[2019-03-23 23:55:52,261] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1242
[2019-03-23 23:55:52,266] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 82.0, 1.0, 2.0, 0.5119955442291906, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 605914.2625093966, 605914.2625093966, 144611.1797825487], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7556400.0000, 
sim time next is 7557000.0000, 
raw observation next is [24.66666666666666, 80.66666666666667, 1.0, 2.0, 0.5167539991449835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 610653.8632399567, 610653.8632399562, 145333.639502016], 
processed observation next is [0.0, 0.4782608695652174, 0.4691358024691356, 0.8066666666666668, 1.0, 1.0, 0.4247071418392661, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21809066544284167, 0.2180906654428415, 0.27948776827310773], 
reward next is 0.7205, 
noisyNet noise sample is [array([1.4382527], dtype=float32), 0.1729528]. 
=============================================
[2019-03-23 23:55:52,280] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[73.25573]
 [73.25573]
 [73.25573]
 [73.25573]
 [73.25573]], R is [[73.24369049]
 [73.2331543 ]
 [73.22400665]
 [73.21621704]
 [73.20976257]].
[2019-03-23 23:55:55,545] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.1089711e-21 1.0000000e+00 5.9973821e-33 6.5988204e-29 1.2594566e-34], sum to 1.0000
[2019-03-23 23:55:55,554] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1956
[2019-03-23 23:55:55,557] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.7, 85.33333333333333, 1.0, 2.0, 0.5157446209856511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 612699.841394145, 612699.841394145, 145298.9343371062], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7594800.0000, 
sim time next is 7595400.0000, 
raw observation next is [23.65, 85.66666666666667, 1.0, 2.0, 0.5154528694282259, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 612403.2816684177, 612403.2816684177, 145254.2658743413], 
processed observation next is [0.0, 0.9130434782608695, 0.4314814814814814, 0.8566666666666667, 1.0, 1.0, 0.42315817789074506, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21871545773872061, 0.21871545773872061, 0.27933512668142557], 
reward next is 0.7207, 
noisyNet noise sample is [array([0.38917536], dtype=float32), -0.9280682]. 
=============================================
[2019-03-23 23:55:55,697] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2948575e-21 1.0000000e+00 4.1228623e-34 9.1756061e-31 2.4196569e-36], sum to 1.0000
[2019-03-23 23:55:55,708] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7283
[2019-03-23 23:55:55,714] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.4, 87.0, 1.0, 2.0, 0.5089571798216583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 605412.4574962032, 605412.4574962032, 144248.5903848878], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7597800.0000, 
sim time next is 7598400.0000, 
raw observation next is [23.33333333333333, 87.33333333333334, 1.0, 2.0, 0.5074777448385149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 603897.961687279, 603897.961687279, 144023.465570806], 
processed observation next is [0.0, 0.9565217391304348, 0.4197530864197529, 0.8733333333333334, 1.0, 1.0, 0.413663981950613, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21567784345974253, 0.21567784345974253, 0.2769682030207808], 
reward next is 0.7230, 
noisyNet noise sample is [array([-0.24844748], dtype=float32), 2.426155]. 
=============================================
[2019-03-23 23:55:55,897] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.8441395e-19 1.0000000e+00 4.0502725e-31 1.8239120e-28 5.8962984e-33], sum to 1.0000
[2019-03-23 23:55:55,904] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1388
[2019-03-23 23:55:55,907] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.8, 91.0, 1.0, 2.0, 0.4497881518818608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 554000.2346855943, 554000.2346855948, 135774.926110511], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7632000.0000, 
sim time next is 7632600.0000, 
raw observation next is [21.06666666666667, 90.16666666666667, 1.0, 2.0, 0.4478691962653354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 550493.3492629561, 550493.3492629561, 135459.0862993331], 
processed observation next is [1.0, 0.34782608695652173, 0.3358024691358026, 0.9016666666666667, 1.0, 1.0, 0.3427014241253992, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19660476759391288, 0.19660476759391288, 0.2604982428833329], 
reward next is 0.7395, 
noisyNet noise sample is [array([-0.91827184], dtype=float32), -1.2145599]. 
=============================================
[2019-03-23 23:55:56,822] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.9184812e-20 1.0000000e+00 1.5387599e-30 2.6401250e-28 5.9841474e-34], sum to 1.0000
[2019-03-23 23:55:56,830] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9363
[2019-03-23 23:55:56,836] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1469461.55388862 W.
[2019-03-23 23:55:56,844] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.2, 66.0, 1.0, 2.0, 1.003529735406163, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.44546570194014, 6.9112, 121.9238355045802, 1469461.55388862, 1195874.714940447, 244256.5036903485], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7657200.0000, 
sim time next is 7657800.0000, 
raw observation next is [26.05, 66.0, 1.0, 2.0, 0.4057325094140054, 1.0, 1.0, 0.4057325094140054, 1.0, 1.0, 0.647383174095975, 6.9112, 6.9112, 121.94756008, 1414526.658205114, 1414526.658205114, 299679.0011283642], 
processed observation next is [1.0, 0.6521739130434783, 0.5203703703703704, 0.66, 1.0, 1.0, 0.2925387016833398, 1.0, 0.5, 0.2925387016833398, 1.0, 0.5, 0.5592289676199688, 0.0, 0.0, 0.8096049824067558, 0.5051880922161122, 0.5051880922161122, 0.5763057714007004], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2667128], dtype=float32), -0.35896066]. 
=============================================
[2019-03-23 23:56:03,420] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.4052468e-21 1.0000000e+00 5.3766571e-32 2.6709082e-29 9.2331307e-36], sum to 1.0000
[2019-03-23 23:56:03,427] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7973
[2019-03-23 23:56:03,433] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 71.5, 1.0, 2.0, 0.3617771086920903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 458227.8575588129, 458227.8575588129, 123527.794654248], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7785000.0000, 
sim time next is 7785600.0000, 
raw observation next is [21.13333333333333, 71.0, 1.0, 2.0, 0.3515287252218045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 445460.430723584, 445460.430723584, 122160.4864204521], 
processed observation next is [1.0, 0.08695652173913043, 0.33827160493827146, 0.71, 1.0, 1.0, 0.2280103871688149, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1590930109727086, 0.1590930109727086, 0.23492401234702326], 
reward next is 0.7651, 
noisyNet noise sample is [array([-0.1124385], dtype=float32), 0.18687512]. 
=============================================
[2019-03-23 23:56:03,769] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:56:03,769] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:56:03,827] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run9
[2019-03-23 23:56:07,213] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.9968323e-22 1.0000000e+00 3.4941342e-33 2.6976191e-32 2.3439062e-36], sum to 1.0000
[2019-03-23 23:56:07,222] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9518
[2019-03-23 23:56:07,226] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.9, 68.0, 1.0, 2.0, 0.4566334956476324, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 554902.9374261406, 554902.9374261406, 136592.8213404809], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7941600.0000, 
sim time next is 7942200.0000, 
raw observation next is [24.76666666666667, 68.66666666666667, 1.0, 2.0, 0.4558021369667031, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 554193.0335248316, 554193.0335248316, 136477.1169163056], 
processed observation next is [1.0, 0.9565217391304348, 0.4728395061728396, 0.6866666666666668, 1.0, 1.0, 0.35214540115083703, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19792608340172557, 0.19792608340172557, 0.26245599406981845], 
reward next is 0.7375, 
noisyNet noise sample is [array([-0.8669685], dtype=float32), -0.9382428]. 
=============================================
[2019-03-23 23:56:08,316] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.6058500e-20 1.0000000e+00 6.9457657e-32 3.8554355e-29 6.0232841e-35], sum to 1.0000
[2019-03-23 23:56:08,323] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1935
[2019-03-23 23:56:08,326] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.46666666666667, 71.66666666666667, 1.0, 2.0, 0.4168390452591194, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 513009.4173097277, 513009.4173097272, 130933.4420308272], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7861200.0000, 
sim time next is 7861800.0000, 
raw observation next is [23.38333333333333, 72.33333333333333, 1.0, 2.0, 0.4182689471960223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 514639.5537558015, 514639.5537558015, 131135.7481375911], 
processed observation next is [1.0, 1.0, 0.4216049382716048, 0.7233333333333333, 1.0, 1.0, 0.3074630323762171, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18379984062707197, 0.18379984062707197, 0.25218413103382903], 
reward next is 0.7478, 
noisyNet noise sample is [array([0.04555473], dtype=float32), -1.3935828]. 
=============================================
[2019-03-23 23:56:08,586] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:56:08,586] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:56:08,621] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run9
[2019-03-23 23:56:11,553] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:56:11,554] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:56:11,603] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run9
[2019-03-23 23:56:11,996] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:56:11,997] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:56:12,051] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run9
[2019-03-23 23:56:12,517] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:56:12,517] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:56:12,527] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run9
[2019-03-23 23:56:12,688] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:56:12,688] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:56:12,695] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run9
[2019-03-23 23:56:12,721] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:56:12,721] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:56:12,734] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run9
[2019-03-23 23:56:12,873] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:56:12,873] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:56:12,885] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run9
[2019-03-23 23:56:12,953] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:56:12,954] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:56:12,963] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:56:12,964] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:56:12,966] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run9
[2019-03-23 23:56:13,007] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run9
[2019-03-23 23:56:13,225] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:56:13,225] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:56:13,228] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run9
[2019-03-23 23:56:13,256] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:56:13,257] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:56:13,267] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run9
[2019-03-23 23:56:13,549] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:56:13,549] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:56:13,559] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run9
[2019-03-23 23:56:13,669] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:56:13,669] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:56:13,673] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run9
[2019-03-23 23:56:13,717] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:56:13,720] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:56:13,723] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run9
[2019-03-23 23:56:14,185] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-23 23:56:14,185] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:56:14,189] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run9
[2019-03-23 23:56:16,710] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.1559257e-20 1.0000000e+00 4.6948149e-31 6.6014391e-29 2.7594522e-33], sum to 1.0000
[2019-03-23 23:56:16,711] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9102
[2019-03-23 23:56:16,714] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1317958.291599917 W.
[2019-03-23 23:56:16,723] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.93333333333333, 37.66666666666666, 1.0, 2.0, 0.5431089643901147, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8830480746768199, 6.911200000000001, 6.9112, 121.9260425106245, 1317958.291599917, 1317958.291599917, 269909.5052222476], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 56400.0000, 
sim time next is 57000.0000, 
raw observation next is [29.91666666666667, 37.83333333333334, 1.0, 2.0, 0.5477876547475264, 1.0, 1.0, 0.5477876547475264, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156298, 1325873.114902151, 1325873.114902151, 253772.2613049433], 
processed observation next is [1.0, 0.6521739130434783, 0.6635802469135804, 0.3783333333333334, 1.0, 1.0, 0.46165196993753144, 1.0, 0.5, 0.46165196993753144, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288199235, 0.47352611246505394, 0.47352611246505394, 0.4880235794325833], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8243923], dtype=float32), 0.44272742]. 
=============================================
[2019-03-23 23:56:16,753] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[72.675934]
 [72.675934]
 [72.675934]
 [72.675934]
 [72.675934]], R is [[71.9491806 ]
 [71.22969055]
 [70.51739502]
 [69.81222534]
 [69.63509369]].
[2019-03-23 23:56:17,530] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.46379817e-20 1.00000000e+00 4.46079276e-31 1.15427805e-29
 6.59490305e-34], sum to 1.0000
[2019-03-23 23:56:17,537] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1219
[2019-03-23 23:56:17,542] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.03333333333333, 74.0, 1.0, 2.0, 0.4140282987794167, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 510096.2735931953, 510096.2735931953, 130544.057390051], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 92400.0000, 
sim time next is 93000.0000, 
raw observation next is [22.91666666666666, 74.5, 1.0, 2.0, 0.4121979849723029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 508143.0141626775, 508143.0141626775, 130289.753999777], 
processed observation next is [1.0, 0.043478260869565216, 0.4043209876543208, 0.745, 1.0, 1.0, 0.3002356963955988, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18147964791524196, 0.18147964791524196, 0.2505572192303404], 
reward next is 0.7494, 
noisyNet noise sample is [array([-0.10585465], dtype=float32), 1.7700373]. 
=============================================
[2019-03-23 23:56:17,561] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[67.44198]
 [67.44198]
 [67.44198]
 [67.44198]
 [67.44198]], R is [[67.51701355]
 [67.59079742]
 [67.66371155]
 [67.73565674]
 [67.80638885]].
[2019-03-23 23:56:21,241] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.8167020e-18 1.0000000e+00 1.0289886e-29 5.6513857e-27 2.4831246e-33], sum to 1.0000
[2019-03-23 23:56:21,248] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0503
[2019-03-23 23:56:21,261] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1356258.948007923 W.
[2019-03-23 23:56:21,265] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.56666666666667, 54.5, 1.0, 2.0, 0.5717026451129167, 1.0, 1.0, 0.5717026451129167, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260424940737, 1356258.948007923, 1356258.948007923, 260816.5636636609], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 121800.0000, 
sim time next is 122400.0000, 
raw observation next is [28.0, 53.0, 1.0, 2.0, 0.5824464015456308, 1.0, 2.0, 0.5824464015456308, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156247, 1377809.130727815, 1377809.130727815, 264318.2236756517], 
processed observation next is [1.0, 0.43478260869565216, 0.5925925925925926, 0.53, 1.0, 1.0, 0.5029123827924176, 1.0, 1.0, 0.5029123827924176, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288198895, 0.4920746895456482, 0.4920746895456482, 0.5083042762993302], 
reward next is 0.4917, 
noisyNet noise sample is [array([-0.05373969], dtype=float32), -0.27370614]. 
=============================================
[2019-03-23 23:56:21,290] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-23 23:56:21,291] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:56:21,292] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:56:21,293] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:56:21,294] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:56:21,294] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:56:21,296] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:56:21,296] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:56:21,297] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:56:21,295] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:56:21,302] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:56:21,323] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run69
[2019-03-23 23:56:21,323] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run69
[2019-03-23 23:56:21,372] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run69
[2019-03-23 23:56:21,407] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run69
[2019-03-23 23:56:21,409] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run69
[2019-03-23 23:56:31,385] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.051104434]
[2019-03-23 23:56:31,386] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.08333333333334, 58.16666666666667, 1.0, 2.0, 0.3544620074480995, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 445187.3791796606, 445187.3791796606, 122502.0821886794]
[2019-03-23 23:56:31,387] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:56:31,389] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.2247254e-19 1.0000000e+00 9.0937575e-30 2.0683810e-27 8.2694723e-32], sampled 0.29449707815986836
[2019-03-23 23:56:34,678] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.051104434]
[2019-03-23 23:56:34,679] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.55, 53.16666666666667, 1.0, 2.0, 0.3380434119975058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 426298.4244697891, 426298.4244697895, 120364.8640642073]
[2019-03-23 23:56:34,680] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:56:34,685] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.2247254e-19 1.0000000e+00 9.0937575e-30 2.0683810e-27 8.2694723e-32], sampled 0.11910112777621984
[2019-03-23 23:56:36,800] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.051104434]
[2019-03-23 23:56:36,801] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.53333333333333, 86.0, 1.0, 2.0, 0.37904646852781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 472436.8791013752, 472436.8791013752, 125764.6725463718]
[2019-03-23 23:56:36,803] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:56:36,806] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.2247254e-19 1.0000000e+00 9.0937575e-30 2.0683810e-27 8.2694723e-32], sampled 0.6439957123779867
[2019-03-23 23:56:38,573] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.051104434]
[2019-03-23 23:56:38,576] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [32.25, 26.0, 1.0, 2.0, 0.3789287462809612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 474734.4962608797, 474734.4962608792, 125792.7743504222]
[2019-03-23 23:56:38,579] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-23 23:56:38,581] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.2247254e-19 1.0000000e+00 9.0937575e-30 2.0683810e-27 8.2694723e-32], sampled 0.28046296476872523
[2019-03-23 23:56:39,210] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.051104434]
[2019-03-23 23:56:39,211] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.46666666666667, 37.66666666666667, 1.0, 2.0, 0.3332765718383235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 422255.6496842938, 422255.6496842943, 119767.4743699399]
[2019-03-23 23:56:39,213] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:56:39,216] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.2247254e-19 1.0000000e+00 9.0937575e-30 2.0683810e-27 8.2694723e-32], sampled 0.03923946852230398
[2019-03-23 23:56:39,395] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.051104434]
[2019-03-23 23:56:39,396] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.0, 43.33333333333333, 1.0, 2.0, 0.3537991133916186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 444706.5610068096, 444706.5610068096, 122419.1274169559]
[2019-03-23 23:56:39,397] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:56:39,400] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.2247254e-19 1.0000000e+00 9.0937575e-30 2.0683810e-27 8.2694723e-32], sampled 0.3823598274743625
[2019-03-23 23:56:43,273] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.051104434]
[2019-03-23 23:56:43,275] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.53358059, 87.55244282, 1.0, 2.0, 0.4174415740161578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 512053.7619742228, 512053.7619742224, 130975.9144213324]
[2019-03-23 23:56:43,276] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:56:43,278] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.2247254e-19 1.0000000e+00 9.0937575e-30 2.0683810e-27 8.2694723e-32], sampled 0.7716411754123407
[2019-03-23 23:56:43,758] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.051104434]
[2019-03-23 23:56:43,759] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.0817925, 70.4984656, 1.0, 2.0, 0.4788765296095616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 599923.8770539515, 599923.8770539515, 140414.2708034546]
[2019-03-23 23:56:43,760] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-23 23:56:43,762] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.2247254e-19 1.0000000e+00 9.0937575e-30 2.0683810e-27 8.2694723e-32], sampled 0.7631744911861797
[2019-03-23 23:56:57,055] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.051104434]
[2019-03-23 23:56:57,058] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.7, 78.0, 1.0, 2.0, 0.9737628098240001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.99449288221103, 6.9112, 121.9254885675954, 1154850.149826358, 1112196.943323669, 234572.2519151389]
[2019-03-23 23:56:57,059] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-23 23:56:57,062] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.2247254e-19 1.0000000e+00 9.0937575e-30 2.0683810e-27 8.2694723e-32], sampled 0.4080819453761505
[2019-03-23 23:57:05,881] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.051104434]
[2019-03-23 23:57:05,882] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.28567378333333, 70.91800972666667, 1.0, 2.0, 0.4779451859774487, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7623445560897892, 6.911199999999999, 6.9112, 121.9260426156388, 1108633.313798259, 1108633.31379826, 249041.0875183569]
[2019-03-23 23:57:05,882] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:57:05,887] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.2247254e-19 1.0000000e+00 9.0937575e-30 2.0683810e-27 8.2694723e-32], sampled 0.7702792209556897
[2019-03-23 23:57:14,964] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.051104434]
[2019-03-23 23:57:14,967] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.03729398166667, 104.7270889666667, 1.0, 2.0, 0.4798821150366713, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 579209.4156264362, 579209.4156264362, 140009.331346057]
[2019-03-23 23:57:14,968] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:57:14,971] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.2247254e-19 1.0000000e+00 9.0937575e-30 2.0683810e-27 8.2694723e-32], sampled 0.2975096008326994
[2019-03-23 23:57:18,449] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.051104434]
[2019-03-23 23:57:18,451] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.7, 74.0, 1.0, 2.0, 0.4374092811286966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 533172.4700180356, 533172.4700180356, 133784.98525337]
[2019-03-23 23:57:18,452] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:57:18,454] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.2247254e-19 1.0000000e+00 9.0937575e-30 2.0683810e-27 8.2694723e-32], sampled 0.7803356059773816
[2019-03-23 23:58:06,576] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-23 23:58:06,633] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-23 23:58:06,749] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-23 23:58:06,763] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-23 23:58:06,808] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-23 23:58:07,823] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1700000, evaluation results [1700000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-23 23:58:18,138] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.4484898e-22 1.0000000e+00 8.7311921e-35 3.6879997e-30 3.4238680e-36], sum to 1.0000
[2019-03-23 23:58:18,155] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6601
[2019-03-23 23:58:18,160] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.93333333333333, 31.0, 1.0, 2.0, 0.3325545561061453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 425608.33375291, 425608.33375291, 119694.2766720755], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 315600.0000, 
sim time next is 316200.0000, 
raw observation next is [27.96666666666667, 31.0, 1.0, 2.0, 0.3330331224214904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 426119.9960390076, 426119.9960390081, 119756.2165729614], 
processed observation next is [0.0, 0.6521739130434783, 0.5913580246913581, 0.31, 1.0, 1.0, 0.20599181240653622, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15218571287107416, 0.15218571287107432, 0.23030041648646424], 
reward next is 0.7697, 
noisyNet noise sample is [array([-0.6483956], dtype=float32), -0.99275994]. 
=============================================
[2019-03-23 23:58:18,705] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.0372068e-24 1.0000000e+00 1.1361017e-35 2.8699456e-33 0.0000000e+00], sum to 1.0000
[2019-03-23 23:58:18,717] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9834
[2019-03-23 23:58:18,721] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.05, 30.5, 1.0, 2.0, 0.3339844640617451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 427462.48097898, 427462.48097898, 119879.4076667391], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 318600.0000, 
sim time next is 319200.0000, 
raw observation next is [28.06666666666667, 30.33333333333334, 1.0, 2.0, 0.3340941402873989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 427698.6664708984, 427698.666470898, 119893.5936040193], 
processed observation next is [0.0, 0.6956521739130435, 0.5950617283950619, 0.3033333333333334, 1.0, 1.0, 0.20725492891357014, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15274952373960657, 0.15274952373960643, 0.23056460308465251], 
reward next is 0.7694, 
noisyNet noise sample is [array([-0.8622314], dtype=float32), -0.79652244]. 
=============================================
[2019-03-23 23:58:19,126] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.6201179e-21 1.0000000e+00 1.9990188e-32 2.1024655e-30 1.4489338e-35], sum to 1.0000
[2019-03-23 23:58:19,134] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3525
[2019-03-23 23:58:19,138] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.3, 32.33333333333334, 1.0, 2.0, 0.3286328031850325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 421341.1647495348, 421341.1647495348, 119187.3425323361], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 324600.0000, 
sim time next is 325200.0000, 
raw observation next is [27.2, 32.66666666666667, 1.0, 2.0, 0.3270127819072783, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 419291.4868759005, 419291.4868759, 118979.0523089686], 
processed observation next is [0.0, 0.782608695652174, 0.5629629629629629, 0.3266666666666667, 1.0, 1.0, 0.1988247403658075, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14974695959853587, 0.1497469595985357, 0.2288058698249396], 
reward next is 0.7712, 
noisyNet noise sample is [array([1.3447423], dtype=float32), 0.17421578]. 
=============================================
[2019-03-23 23:58:26,748] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.3024664e-19 1.0000000e+00 1.9562475e-30 9.3819232e-30 3.0245805e-32], sum to 1.0000
[2019-03-23 23:58:26,757] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4649
[2019-03-23 23:58:26,762] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.86666666666667, 58.33333333333334, 1.0, 2.0, 0.4055739164982482, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 515059.7543549297, 515059.7543549297, 129601.7806134468], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 614400.0000, 
sim time next is 615000.0000, 
raw observation next is [22.68333333333333, 59.16666666666666, 1.0, 2.0, 0.3898441125751264, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 495341.2492589524, 495341.2492589524, 127386.3378734541], 
processed observation next is [1.0, 0.08695652173913043, 0.39567901234567887, 0.5916666666666666, 1.0, 1.0, 0.2736239435418172, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1769075890210544, 0.1769075890210544, 0.24497372667971942], 
reward next is 0.7550, 
noisyNet noise sample is [array([1.3117546], dtype=float32), 0.6517853]. 
=============================================
[2019-03-23 23:58:26,788] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[73.19067]
 [73.19067]
 [73.19067]
 [73.19067]
 [73.19067]], R is [[73.21379089]
 [73.23241425]
 [73.23815155]
 [73.22059631]
 [73.16820526]].
[2019-03-23 23:58:27,924] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.3355198e-20 1.0000000e+00 1.7253404e-32 4.0658455e-31 3.5719347e-34], sum to 1.0000
[2019-03-23 23:58:27,934] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1619
[2019-03-23 23:58:27,940] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.05, 31.0, 1.0, 2.0, 0.3539523856827818, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 445513.3244456212, 445513.3244456212, 122448.1894671045], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 499800.0000, 
sim time next is 500400.0000, 
raw observation next is [29.8, 32.0, 1.0, 2.0, 0.3520439919387051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 442907.6813709488, 442907.6813709484, 122191.7861614836], 
processed observation next is [1.0, 0.8260869565217391, 0.6592592592592593, 0.32, 1.0, 1.0, 0.2286237999270299, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15818131477533887, 0.1581813147753387, 0.23498420415669924], 
reward next is 0.7650, 
noisyNet noise sample is [array([1.0153791], dtype=float32), 2.3835876]. 
=============================================
[2019-03-23 23:58:28,636] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.4128768e-20 1.0000000e+00 1.9470520e-31 3.0738681e-29 8.9512804e-35], sum to 1.0000
[2019-03-23 23:58:28,643] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4800
[2019-03-23 23:58:28,649] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.8, 43.0, 1.0, 2.0, 0.3465234689286242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 436376.7417234753, 436376.7417234753, 121467.607445339], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 507600.0000, 
sim time next is 508200.0000, 
raw observation next is [26.53333333333333, 43.83333333333334, 1.0, 2.0, 0.3449825594508871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 434750.182432936, 434750.182432936, 121268.9986678743], 
processed observation next is [1.0, 0.9130434782608695, 0.5382716049382715, 0.4383333333333334, 1.0, 1.0, 0.22021733267962754, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15526792229747713, 0.15526792229747713, 0.2332096128228352], 
reward next is 0.7668, 
noisyNet noise sample is [array([1.5285122], dtype=float32), -0.09022751]. 
=============================================
[2019-03-23 23:58:29,693] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.3517858e-21 1.0000000e+00 1.5669133e-31 4.0204704e-31 4.0597307e-35], sum to 1.0000
[2019-03-23 23:58:29,700] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0241
[2019-03-23 23:58:29,704] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.95, 74.5, 1.0, 2.0, 0.3365909667225497, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 429482.3378652162, 429482.3378652162, 120216.0685059634], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 531000.0000, 
sim time next is 531600.0000, 
raw observation next is [19.86666666666667, 75.0, 1.0, 2.0, 0.3293455430465352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 420313.636904403, 420313.636904403, 119278.4122688979], 
processed observation next is [1.0, 0.13043478260869565, 0.2913580246913582, 0.75, 1.0, 1.0, 0.20160183696016093, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15011201318014392, 0.15011201318014392, 0.2293815620555729], 
reward next is 0.7706, 
noisyNet noise sample is [array([0.44463107], dtype=float32), -0.7253405]. 
=============================================
[2019-03-23 23:58:33,197] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.9769903e-20 1.0000000e+00 2.2845465e-31 4.7302856e-30 4.8799632e-35], sum to 1.0000
[2019-03-23 23:58:33,206] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4148
[2019-03-23 23:58:33,210] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.7, 51.0, 1.0, 2.0, 0.3360650690401358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 424937.752278861, 424937.752278861, 120120.6976543885], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 607200.0000, 
sim time next is 607800.0000, 
raw observation next is [24.55, 51.5, 1.0, 2.0, 0.3341991769342739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 422794.366228377, 422794.3662283766, 119880.853147273], 
processed observation next is [1.0, 0.0, 0.46481481481481485, 0.515, 1.0, 1.0, 0.2073799725408023, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15099798793870606, 0.15099798793870592, 0.23054010220629423], 
reward next is 0.7695, 
noisyNet noise sample is [array([-0.5515774], dtype=float32), -0.23530902]. 
=============================================
[2019-03-23 23:58:33,274] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.0959108e-21 1.0000000e+00 1.7161097e-34 9.5419936e-31 3.5049555e-36], sum to 1.0000
[2019-03-23 23:58:33,282] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9561
[2019-03-23 23:58:33,292] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 53.5, 1.0, 2.0, 0.3304259988119207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 418723.6066734471, 418723.6066734471, 119399.9257189983], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 610200.0000, 
sim time next is 610800.0000, 
raw observation next is [23.86666666666667, 54.0, 1.0, 2.0, 0.3280047833264226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 415817.6351890377, 415817.6351890381, 119089.6952246346], 
processed observation next is [1.0, 0.043478260869565216, 0.4395061728395063, 0.54, 1.0, 1.0, 0.20000569443621735, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14850629828179918, 0.14850629828179931, 0.22901864466275884], 
reward next is 0.7710, 
noisyNet noise sample is [array([0.0685886], dtype=float32), -1.0407674]. 
=============================================
[2019-03-23 23:58:36,598] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.4656718e-18 1.0000000e+00 2.5383913e-29 1.9563924e-27 6.2306792e-33], sum to 1.0000
[2019-03-23 23:58:36,603] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6005
[2019-03-23 23:58:36,612] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.73333333333333, 23.66666666666666, 1.0, 2.0, 0.37482560073877, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 474639.0142959536, 474639.0142959536, 125297.1632472843], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 676200.0000, 
sim time next is 676800.0000, 
raw observation next is [31.5, 24.0, 1.0, 2.0, 0.3703597514155632, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 469381.2747686252, 469381.2747686252, 124691.4605375297], 
processed observation next is [1.0, 0.8695652173913043, 0.7222222222222222, 0.24, 1.0, 1.0, 0.25042827549471813, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16763616956022329, 0.16763616956022329, 0.2397912702644802], 
reward next is 0.7602, 
noisyNet noise sample is [array([0.07888746], dtype=float32), -1.4496876]. 
=============================================
[2019-03-23 23:58:37,146] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.5337510e-20 1.0000000e+00 1.4388241e-31 3.2224431e-29 1.5045063e-33], sum to 1.0000
[2019-03-23 23:58:37,154] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6946
[2019-03-23 23:58:37,160] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.41666666666667, 51.33333333333334, 1.0, 2.0, 0.4312403895342496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 528450.5809883499, 528450.5809883499, 132960.9283829814], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 911400.0000, 
sim time next is 912000.0000, 
raw observation next is [27.63333333333334, 50.66666666666667, 1.0, 2.0, 0.4328400703884011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 529888.6139624728, 529888.6139624728, 133180.5529042904], 
processed observation next is [0.0, 0.5652173913043478, 0.5790123456790126, 0.5066666666666667, 1.0, 1.0, 0.3248096076052394, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.189245933558026, 0.189245933558026, 0.2561164478928662], 
reward next is 0.7439, 
noisyNet noise sample is [array([0.06164135], dtype=float32), 0.028309649]. 
=============================================
[2019-03-23 23:58:37,186] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[67.76524]
 [67.76524]
 [67.76524]
 [67.76524]
 [67.76524]], R is [[67.8314743 ]
 [67.89746857]
 [67.96331024]
 [68.02894592]
 [68.09428406]].
[2019-03-23 23:58:40,183] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.41735981e-21 1.00000000e+00 1.03893835e-32 3.05988909e-28
 6.03220596e-35], sum to 1.0000
[2019-03-23 23:58:40,193] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5072
[2019-03-23 23:58:40,199] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 35.0, 1.0, 2.0, 0.327102015425896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 415985.3842173752, 415985.3842173748, 118983.421041947], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 770400.0000, 
sim time next is 771000.0000, 
raw observation next is [27.53333333333333, 35.66666666666667, 1.0, 2.0, 0.3254252375552784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 413866.4897098139, 413866.4897098139, 118768.5235119553], 
processed observation next is [1.0, 0.9565217391304348, 0.5753086419753086, 0.3566666666666667, 1.0, 1.0, 0.1969348066134267, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1478094606106478, 0.1478094606106478, 0.22840100675376018], 
reward next is 0.7716, 
noisyNet noise sample is [array([0.36222473], dtype=float32), 0.24879265]. 
=============================================
[2019-03-23 23:58:40,217] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[71.83111]
 [71.83111]
 [71.83111]
 [71.83111]
 [71.83111]], R is [[71.88440704]
 [71.93675232]
 [71.98800659]
 [72.03825378]
 [72.08770752]].
[2019-03-23 23:58:42,878] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.5772584e-21 1.0000000e+00 3.4803526e-33 5.7275962e-31 2.0569546e-36], sum to 1.0000
[2019-03-23 23:58:42,885] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4307
[2019-03-23 23:58:42,889] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 50.0, 1.0, 2.0, 0.2964549217519448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 378666.6722420549, 378666.6722420549, 115139.4056233057], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 784800.0000, 
sim time next is 785400.0000, 
raw observation next is [23.73333333333333, 50.5, 1.0, 2.0, 0.2967150461636717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 378966.7859959558, 378966.7859959562, 115171.3815422247], 
processed observation next is [0.0, 0.08695652173913043, 0.4345679012345678, 0.505, 1.0, 1.0, 0.16275600733770443, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13534528071284135, 0.13534528071284152, 0.2214834260427398], 
reward next is 0.7785, 
noisyNet noise sample is [array([1.009728], dtype=float32), -0.40539882]. 
=============================================
[2019-03-23 23:58:45,155] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.9909878e-19 1.0000000e+00 1.2127357e-30 1.6305229e-27 9.0636477e-33], sum to 1.0000
[2019-03-23 23:58:45,161] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6303
[2019-03-23 23:58:45,165] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.83333333333333, 36.0, 1.0, 2.0, 0.451744172047828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 549252.22961249, 549252.22961249, 135869.1248977841], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 832200.0000, 
sim time next is 832800.0000, 
raw observation next is [31.86666666666667, 36.0, 1.0, 2.0, 0.4455503786818603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 541494.6762637255, 541494.676263726, 134940.0873601997], 
processed observation next is [0.0, 0.6521739130434783, 0.7358024691358026, 0.36, 1.0, 1.0, 0.3399409270022146, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1933909558084734, 0.19339095580847357, 0.259500168000384], 
reward next is 0.7405, 
noisyNet noise sample is [array([1.0766579], dtype=float32), 0.002594492]. 
=============================================
[2019-03-23 23:58:46,875] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.5847475e-19 1.0000000e+00 9.1602175e-31 6.2279620e-28 1.2870351e-32], sum to 1.0000
[2019-03-23 23:58:46,881] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4273
[2019-03-23 23:58:46,888] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.3, 65.33333333333334, 1.0, 2.0, 0.3813466816399761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 476272.3008159588, 476272.3008159588, 126099.3659897173], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 868800.0000, 
sim time next is 869400.0000, 
raw observation next is [23.15, 66.0, 1.0, 2.0, 0.3796661821620908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 474414.937108692, 474414.937108692, 125872.5142660699], 
processed observation next is [0.0, 0.043478260869565216, 0.4129629629629629, 0.66, 1.0, 1.0, 0.26150735971677475, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16943390611024714, 0.16943390611024714, 0.24206252743474982], 
reward next is 0.7579, 
noisyNet noise sample is [array([1.5844113], dtype=float32), -0.72435355]. 
=============================================
[2019-03-23 23:58:48,934] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3711018e-19 1.0000000e+00 1.4646078e-31 6.5126370e-31 1.3508183e-34], sum to 1.0000
[2019-03-23 23:58:48,939] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5107
[2019-03-23 23:58:48,947] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.4, 55.33333333333334, 1.0, 2.0, 0.4239073159646483, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 520819.4290387398, 520819.4290387394, 131930.4639743404], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 908400.0000, 
sim time next is 909000.0000, 
raw observation next is [26.6, 54.5, 1.0, 2.0, 0.4254299416644912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 522432.4346310052, 522432.4346310052, 132144.5054575859], 
processed observation next is [0.0, 0.5217391304347826, 0.5407407407407407, 0.545, 1.0, 1.0, 0.31598802579106094, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18658301236821614, 0.18658301236821614, 0.254124048956896], 
reward next is 0.7459, 
noisyNet noise sample is [array([1.5016973], dtype=float32), -0.83136594]. 
=============================================
[2019-03-23 23:58:48,967] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[78.668274]
 [78.668274]
 [78.668274]
 [78.668274]
 [78.668274]], R is [[78.62745667]
 [78.58747101]
 [78.54850769]
 [78.51056671]
 [78.47377777]].
[2019-03-23 23:58:49,370] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.8167413e-19 1.0000000e+00 1.0710687e-30 3.5002516e-29 2.9045384e-34], sum to 1.0000
[2019-03-23 23:58:49,377] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8926
[2019-03-23 23:58:49,380] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.6, 54.5, 1.0, 2.0, 0.4254299416644912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 522432.4346310052, 522432.4346310052, 132144.5054575859], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 909000.0000, 
sim time next is 909600.0000, 
raw observation next is [26.8, 53.66666666666667, 1.0, 2.0, 0.4263529685522383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 523325.9816310186, 523325.9816310182, 132272.2031328146], 
processed observation next is [0.0, 0.5217391304347826, 0.5481481481481482, 0.5366666666666667, 1.0, 1.0, 0.31708686732409325, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18690213629679236, 0.18690213629679223, 0.2543696214092589], 
reward next is 0.7456, 
noisyNet noise sample is [array([0.00075168], dtype=float32), -0.11387408]. 
=============================================
[2019-03-23 23:58:49,553] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0653814e-20 1.0000000e+00 2.4596581e-34 2.7401751e-31 4.0578998e-37], sum to 1.0000
[2019-03-23 23:58:49,556] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0350
[2019-03-23 23:58:49,566] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.3, 64.33333333333334, 1.0, 2.0, 0.3659421541361879, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 458111.4296373353, 458111.4296373348, 124017.5790771113], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 897600.0000, 
sim time next is 898200.0000, 
raw observation next is [23.45, 64.0, 1.0, 2.0, 0.3704828104529171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 463277.4087245807, 463277.4087245811, 124623.7059617012], 
processed observation next is [0.0, 0.391304347826087, 0.42407407407407405, 0.64, 1.0, 1.0, 0.25057477434871084, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16545621740163596, 0.1654562174016361, 0.23966097300327152], 
reward next is 0.7603, 
noisyNet noise sample is [array([-0.29642552], dtype=float32), 0.100166835]. 
=============================================
[2019-03-23 23:58:50,069] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.5083497e-21 1.0000000e+00 3.6139017e-34 4.3237654e-30 3.3434825e-36], sum to 1.0000
[2019-03-23 23:58:50,075] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1755
[2019-03-23 23:58:50,080] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.8, 51.0, 1.0, 2.0, 0.3717171662203355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 464671.8909849741, 464671.8909849741, 124788.7705950211], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 934200.0000, 
sim time next is 934800.0000, 
raw observation next is [25.63333333333333, 51.66666666666666, 1.0, 2.0, 0.370520688703766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 463343.5782282517, 463343.5782282521, 124629.0723544001], 
processed observation next is [0.0, 0.8260869565217391, 0.5049382716049381, 0.5166666666666666, 1.0, 1.0, 0.2506198675044833, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16547984936723276, 0.1654798493672329, 0.23967129298923096], 
reward next is 0.7603, 
noisyNet noise sample is [array([-0.53278613], dtype=float32), -1.0792449]. 
=============================================
[2019-03-23 23:58:50,232] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.4438043e-20 1.0000000e+00 3.2039035e-33 2.2675757e-28 1.3782552e-33], sum to 1.0000
[2019-03-23 23:58:50,238] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7936
[2019-03-23 23:58:50,242] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.96666666666667, 46.33333333333334, 1.0, 2.0, 0.3825008799429552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 477215.2071600215, 477215.207160021, 126249.1967258868], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 930000.0000, 
sim time next is 930600.0000, 
raw observation next is [26.8, 47.0, 1.0, 2.0, 0.3811214651478214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 475594.6298961016, 475594.6298961016, 126060.9792502758], 
processed observation next is [0.0, 0.782608695652174, 0.5481481481481482, 0.47, 1.0, 1.0, 0.26323983946169216, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16985522496289343, 0.16985522496289343, 0.24242496009668424], 
reward next is 0.7576, 
noisyNet noise sample is [array([-0.6843256], dtype=float32), -1.1467317]. 
=============================================
[2019-03-23 23:58:52,402] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.7379849e-20 1.0000000e+00 5.8661907e-33 3.0839188e-31 7.7943523e-35], sum to 1.0000
[2019-03-23 23:58:52,411] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4401
[2019-03-23 23:58:52,415] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.2, 52.83333333333334, 1.0, 2.0, 0.3653936762924772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 457813.4915812078, 457813.4915812078, 123949.8791626764], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 936600.0000, 
sim time next is 937200.0000, 
raw observation next is [25.1, 52.66666666666667, 1.0, 2.0, 0.3625831757925715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 454931.0175890447, 454931.0175890447, 123581.5277674839], 
processed observation next is [0.0, 0.8695652173913043, 0.4851851851851852, 0.5266666666666667, 1.0, 1.0, 0.2411704473721089, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16247536342465882, 0.16247536342465882, 0.23765678416823827], 
reward next is 0.7623, 
noisyNet noise sample is [array([1.6314458], dtype=float32), 1.5003617]. 
=============================================
[2019-03-23 23:58:52,574] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.1742711e-22 1.0000000e+00 8.9663179e-35 1.9201133e-33 4.7650959e-37], sum to 1.0000
[2019-03-23 23:58:52,582] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7829
[2019-03-23 23:58:52,591] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.48333333333333, 58.16666666666666, 1.0, 2.0, 0.3612248139314164, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 460717.4273424086, 460717.4273424081, 123474.2938817726], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 978600.0000, 
sim time next is 979200.0000, 
raw observation next is [22.6, 58.0, 1.0, 2.0, 0.3504355139519673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 446601.6844684683, 446601.6844684683, 122032.3558596755], 
processed observation next is [1.0, 0.34782608695652173, 0.39259259259259266, 0.58, 1.0, 1.0, 0.22670894518091347, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15950060159588153, 0.15950060159588153, 0.2346776074224529], 
reward next is 0.7653, 
noisyNet noise sample is [array([0.17250283], dtype=float32), -1.5079446]. 
=============================================
[2019-03-23 23:58:54,860] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1034830e-17 1.0000000e+00 6.2198630e-29 1.4148792e-26 4.1404738e-31], sum to 1.0000
[2019-03-23 23:58:54,864] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0729
[2019-03-23 23:58:54,873] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.1, 68.0, 1.0, 2.0, 0.3021621178102815, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 388218.5580073925, 388218.5580073925, 115840.7062789806], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1152000.0000, 
sim time next is 1152600.0000, 
raw observation next is [20.15, 67.83333333333334, 1.0, 2.0, 0.2985849221628472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 383557.3391461615, 383557.339146161, 115398.7819286563], 
processed observation next is [1.0, 0.34782608695652173, 0.3018518518518518, 0.6783333333333335, 1.0, 1.0, 0.16498205019386572, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13698476398077197, 0.13698476398077178, 0.2219207344781852], 
reward next is 0.7781, 
noisyNet noise sample is [array([0.8957433], dtype=float32), -0.0523898]. 
=============================================
[2019-03-23 23:58:57,759] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-23 23:58:57,762] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-23 23:58:57,763] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:58:57,764] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-23 23:58:57,764] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-23 23:58:57,765] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:58:57,766] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-23 23:58:57,766] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-23 23:58:57,767] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:58:57,765] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:58:57,767] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-23 23:58:57,785] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run70
[2019-03-23 23:58:57,809] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run70
[2019-03-23 23:58:57,810] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run70
[2019-03-23 23:58:57,858] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run70
[2019-03-23 23:58:57,891] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run70
[2019-03-23 23:59:16,530] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.029425232]
[2019-03-23 23:59:16,531] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.16666666666667, 72.33333333333333, 1.0, 2.0, 0.3779539564823479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 472378.8796024134, 472378.879602413, 125639.2303853604]
[2019-03-23 23:59:16,533] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:59:16,534] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.3753652e-20 1.0000000e+00 9.2565258e-33 3.8012681e-30 5.6516643e-35], sampled 0.7438529921264334
[2019-03-23 23:59:27,618] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.029425232]
[2019-03-23 23:59:27,620] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.4, 66.66666666666667, 1.0, 2.0, 0.7918561582764031, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 910004.666436342, 910004.666436342, 194649.0597900895]
[2019-03-23 23:59:27,622] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:59:27,624] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.3753652e-20 1.0000000e+00 9.2565258e-33 3.8012681e-30 5.6516643e-35], sampled 0.3006103628966832
[2019-03-23 23:59:35,162] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.029425232]
[2019-03-23 23:59:35,162] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.0, 70.0, 1.0, 2.0, 0.7188212743653065, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 819264.370205691, 819264.370205691, 179741.2958998838]
[2019-03-23 23:59:35,164] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:59:35,167] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.3753652e-20 1.0000000e+00 9.2565258e-33 3.8012681e-30 5.6516643e-35], sampled 0.6204225322906467
[2019-03-23 23:59:41,917] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.029425232]
[2019-03-23 23:59:41,918] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.12258286, 98.96123326, 1.0, 2.0, 0.5175271228071087, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 612079.5521700907, 612079.5521700907, 145476.9177327643]
[2019-03-23 23:59:41,919] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:59:41,922] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.3753652e-20 1.0000000e+00 9.2565258e-33 3.8012681e-30 5.6516643e-35], sampled 0.36365355723577275
[2019-03-23 23:59:42,253] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.029425232]
[2019-03-23 23:59:42,253] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.19852954, 78.206709535, 1.0, 2.0, 0.9943078832048831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.109590930704432, 6.9112, 121.925157678469, 1235146.092647101, 1133552.941513014, 239351.8821059109]
[2019-03-23 23:59:42,255] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-23 23:59:42,260] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.3753652e-20 1.0000000e+00 9.2565258e-33 3.8012681e-30 5.6516643e-35], sampled 0.13030639464665117
[2019-03-23 23:59:59,859] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.029425232]
[2019-03-23 23:59:59,860] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [20.0, 94.0, 1.0, 2.0, 0.494335881693811, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 612174.5720739255, 612174.5720739255, 142692.8218022422]
[2019-03-23 23:59:59,861] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-23 23:59:59,864] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.3753652e-20 1.0000000e+00 9.2565258e-33 3.8012681e-30 5.6516643e-35], sampled 0.727725632409677
[2019-03-24 00:00:05,704] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.029425232]
[2019-03-24 00:00:05,705] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.0, 94.0, 1.0, 2.0, 0.6671041451900106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 760291.4147917377, 760291.4147917377, 170008.5559345791]
[2019-03-24 00:00:05,707] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:00:05,711] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.3753652e-20 1.0000000e+00 9.2565258e-33 3.8012681e-30 5.6516643e-35], sampled 0.9226679790068998
[2019-03-24 00:00:42,796] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 00:00:43,349] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 00:00:43,389] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 00:00:43,397] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 00:00:43,519] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 00:00:44,537] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1725000, evaluation results [1725000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 00:00:47,079] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1219398e-22 1.0000000e+00 1.8681343e-35 5.4616189e-32 1.3122310e-37], sum to 1.0000
[2019-03-24 00:00:47,092] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0496
[2019-03-24 00:00:47,095] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.93333333333333, 29.33333333333334, 1.0, 2.0, 0.5218282450925776, 1.0, 2.0, 0.5218282450925776, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260425337822, 1279062.626670815, 1279062.626670816, 245752.2552989275], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1354800.0000, 
sim time next is 1355400.0000, 
raw observation next is [30.95, 29.0, 1.0, 2.0, 0.9388005462405846, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.31421233072831, 6.9112, 121.9243297978865, 1377896.024586161, 1171520.589623961, 230525.9508681911], 
processed observation next is [1.0, 0.6956521739130435, 0.7018518518518518, 0.29, 1.0, 1.0, 0.9271435074292674, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.040301233072831, 0.0, 0.8094507574913129, 0.49210572306648603, 0.41840021057998605, 0.44331913628498293], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9580214], dtype=float32), 0.44550163]. 
=============================================
[2019-03-24 00:00:50,938] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.3097923e-20 1.0000000e+00 7.6833949e-32 3.0472128e-30 3.6144807e-34], sum to 1.0000
[2019-03-24 00:00:50,949] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7282
[2019-03-24 00:00:50,951] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.95, 67.5, 1.0, 2.0, 0.7227678928463744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 912072.3880998166, 912072.3880998166, 183668.1309998129], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1176600.0000, 
sim time next is 1177200.0000, 
raw observation next is [21.9, 68.0, 1.0, 2.0, 0.7330785276424029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 924842.8634783081, 924842.8634783076, 185724.3367977001], 
processed observation next is [1.0, 0.6521739130434783, 0.36666666666666664, 0.68, 1.0, 1.0, 0.682236342431432, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.33030102267082434, 0.3303010226708242, 0.35716218614942324], 
reward next is 0.6428, 
noisyNet noise sample is [array([-0.04981325], dtype=float32), 0.8906454]. 
=============================================
[2019-03-24 00:00:51,537] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.8261373e-22 1.0000000e+00 1.6004446e-34 1.7828405e-32 4.2196769e-37], sum to 1.0000
[2019-03-24 00:00:51,545] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9575
[2019-03-24 00:00:51,549] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.26666666666667, 81.0, 1.0, 2.0, 0.3475096675432442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 438048.4804608754, 438048.4804608754, 121603.2986556565], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1192800.0000, 
sim time next is 1193400.0000, 
raw observation next is [20.2, 81.5, 1.0, 2.0, 0.3474305155465945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 437959.4448598127, 437959.4448598127, 121592.9953803159], 
processed observation next is [1.0, 0.8260869565217391, 0.3037037037037037, 0.815, 1.0, 1.0, 0.2231315661268982, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1564140874499331, 0.1564140874499331, 0.23383268342368443], 
reward next is 0.7662, 
noisyNet noise sample is [array([-0.4769245], dtype=float32), 0.8785817]. 
=============================================
[2019-03-24 00:00:55,456] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3159432e-18 1.0000000e+00 1.1145853e-30 5.2310207e-29 4.1496721e-33], sum to 1.0000
[2019-03-24 00:00:55,468] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8902
[2019-03-24 00:00:55,472] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.7, 78.66666666666667, 1.0, 2.0, 0.6267874899171222, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 788290.6235061765, 788290.6235061765, 165368.7629141376], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1243200.0000, 
sim time next is 1243800.0000, 
raw observation next is [20.9, 77.5, 1.0, 2.0, 0.6824334575424247, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 857861.1609261443, 857861.1609261443, 175745.6599418427], 
processed observation next is [1.0, 0.391304347826087, 0.32962962962962955, 0.775, 1.0, 1.0, 0.6219445923124103, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.30637898604505154, 0.30637898604505154, 0.3379724229650821], 
reward next is 0.6620, 
noisyNet noise sample is [array([-0.16315195], dtype=float32), -1.9343575]. 
=============================================
[2019-03-24 00:00:56,196] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.4755808e-20 1.0000000e+00 5.9392352e-33 6.7973313e-31 6.5686409e-34], sum to 1.0000
[2019-03-24 00:00:56,207] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3657
[2019-03-24 00:00:56,212] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 81.33333333333334, 1.0, 2.0, 0.3962839516709105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 490937.0195801841, 490937.0195801846, 128095.1939043202], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1290000.0000, 
sim time next is 1290600.0000, 
raw observation next is [21.4, 82.5, 1.0, 2.0, 0.3951004080636598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 489764.0622078954, 489764.0622078954, 127935.9275438229], 
processed observation next is [1.0, 0.9565217391304348, 0.3481481481481481, 0.825, 1.0, 1.0, 0.27988143817102357, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17491573650281977, 0.17491573650281977, 0.2460306298919671], 
reward next is 0.7540, 
noisyNet noise sample is [array([1.6412973], dtype=float32), 0.3882596]. 
=============================================
[2019-03-24 00:00:57,292] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.2656407e-19 1.0000000e+00 2.2882871e-32 4.9290707e-29 1.7140627e-33], sum to 1.0000
[2019-03-24 00:00:57,302] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7752
[2019-03-24 00:00:57,306] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.06666666666667, 86.0, 1.0, 2.0, 0.3633694465966808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 455571.8980364757, 455571.8980364757, 123681.8531703116], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1298400.0000, 
sim time next is 1299000.0000, 
raw observation next is [19.98333333333333, 86.0, 1.0, 2.0, 0.3614184378642232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 453589.4943546316, 453589.4943546316, 123426.8805597462], 
processed observation next is [1.0, 0.0, 0.2956790123456789, 0.86, 1.0, 1.0, 0.2397838546002657, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.161996247983797, 0.161996247983797, 0.23735938569181964], 
reward next is 0.7626, 
noisyNet noise sample is [array([0.29339084], dtype=float32), -1.7121465]. 
=============================================
[2019-03-24 00:00:57,328] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[74.5591]
 [74.5591]
 [74.5591]
 [74.5591]
 [74.5591]], R is [[74.57614899]
 [74.59254456]
 [74.60843658]
 [74.62368011]
 [74.63790131]].
[2019-03-24 00:00:58,069] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.00792895e-20 1.00000000e+00 2.19805459e-34 2.22959987e-31
 2.79588702e-36], sum to 1.0000
[2019-03-24 00:00:58,080] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7114
[2019-03-24 00:00:58,089] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.26666666666667, 76.0, 1.0, 2.0, 0.3924717455632475, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 486920.04134081, 486920.0413408104, 127577.7280099854], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1324200.0000, 
sim time next is 1324800.0000, 
raw observation next is [22.5, 75.0, 1.0, 2.0, 0.4321703962579347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 535503.5314597348, 535503.5314597352, 133244.1401478062], 
processed observation next is [1.0, 0.34782608695652173, 0.3888888888888889, 0.75, 1.0, 1.0, 0.32401237649754133, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19125126123561956, 0.19125126123561972, 0.25623873105347345], 
reward next is 0.7438, 
noisyNet noise sample is [array([0.5318033], dtype=float32), -0.8543621]. 
=============================================
[2019-03-24 00:00:59,668] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.2650554e-17 1.0000000e+00 2.4891720e-28 5.2070209e-25 4.6894295e-30], sum to 1.0000
[2019-03-24 00:00:59,679] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5927
[2019-03-24 00:00:59,685] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.78333333333333, 32.16666666666666, 1.0, 2.0, 0.8750661217093381, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9259435408563, 1088791.050434423, 1088791.050434423, 215717.1730232328], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1349400.0000, 
sim time next is 1350000.0000, 
raw observation next is [30.8, 32.0, 1.0, 2.0, 0.9117745270366118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.117109306708771, 6.9112, 121.9252142198068, 1240390.937590327, 1134947.685002988, 224124.2832618803], 
processed observation next is [1.0, 0.6521739130434783, 0.6962962962962963, 0.32, 1.0, 1.0, 0.8949696750435855, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.02059093067087714, 0.0, 0.8094566291331298, 0.44299676342511685, 0.40533845892963855, 0.4310082370420775], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.15915586], dtype=float32), -0.3266327]. 
=============================================
[2019-03-24 00:00:59,701] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[63.414165]
 [63.414165]
 [63.414165]
 [63.414165]
 [63.414165]], R is [[62.7800293 ]
 [62.73738861]
 [62.53969193]
 [61.96379471]
 [61.34415817]].
[2019-03-24 00:00:59,721] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.1654686e-18 1.0000000e+00 1.9992974e-28 2.2475394e-25 8.5360469e-31], sum to 1.0000
[2019-03-24 00:00:59,730] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6982
[2019-03-24 00:00:59,732] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.38333333333333, 73.0, 1.0, 2.0, 0.3504082629110976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 441690.9391372222, 441690.9391372222, 121986.3201811687], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1486200.0000, 
sim time next is 1486800.0000, 
raw observation next is [21.3, 74.0, 1.0, 2.0, 0.3535875687449763, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 445399.9744480085, 445399.9744480085, 122404.3581507018], 
processed observation next is [0.0, 0.21739130434782608, 0.3444444444444445, 0.74, 1.0, 1.0, 0.23046139136306706, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15907141944571732, 0.15907141944571732, 0.2353929964436573], 
reward next is 0.7646, 
noisyNet noise sample is [array([0.21147451], dtype=float32), 1.0242733]. 
=============================================
[2019-03-24 00:01:00,328] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.93090425e-17 1.00000000e+00 5.25871079e-29 1.20892294e-26
 8.70597071e-30], sum to 1.0000
[2019-03-24 00:01:00,338] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4092
[2019-03-24 00:01:00,350] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1408351.819342346 W.
[2019-03-24 00:01:00,355] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.9, 30.0, 1.0, 2.0, 0.9475187065602483, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.357868720546576, 6.9112, 121.9241728857045, 1408351.819342346, 1179621.019254806, 232532.6176568613], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1353600.0000, 
sim time next is 1354200.0000, 
raw observation next is [30.91666666666666, 29.66666666666666, 1.0, 2.0, 0.3973391159664876, 1.0, 1.0, 0.3973391159664876, 1.0, 1.0, 0.6482406069717436, 6.911199999999999, 6.9112, 121.94756008, 1452857.503461627, 1452857.503461627, 294857.9361628256], 
processed observation next is [1.0, 0.6956521739130435, 0.7006172839506171, 0.29666666666666663, 1.0, 1.0, 0.2825465666267709, 1.0, 0.5, 0.2825465666267709, 1.0, 0.5, 0.5603007587146794, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5188776798077239, 0.5188776798077239, 0.5670344926208185], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.1737555], dtype=float32), 0.48307258]. 
=============================================
[2019-03-24 00:01:02,984] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.3873484e-20 1.0000000e+00 5.3899643e-32 8.1089159e-30 1.9595832e-33], sum to 1.0000
[2019-03-24 00:01:02,990] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0154
[2019-03-24 00:01:02,994] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.6, 40.33333333333334, 1.0, 2.0, 0.3420946011876468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 430344.150892112, 430344.150892112, 120879.7653846796], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1412400.0000, 
sim time next is 1413000.0000, 
raw observation next is [27.95, 39.0, 1.0, 2.0, 0.3446063188525286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 433410.1780763817, 433410.1780763812, 121207.8066334204], 
processed observation next is [0.0, 0.34782608695652173, 0.5907407407407407, 0.39, 1.0, 1.0, 0.21976942720539122, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15478934931299346, 0.1547893493129933, 0.23309193583350077], 
reward next is 0.7669, 
noisyNet noise sample is [array([-0.07034806], dtype=float32), -2.0059643]. 
=============================================
[2019-03-24 00:01:03,029] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[74.63393]
 [74.63393]
 [74.63393]
 [74.63393]
 [74.63393]], R is [[74.65449524]
 [74.67549133]
 [74.69659424]
 [74.71803284]
 [74.7405777 ]].
[2019-03-24 00:01:08,206] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.9080005e-20 1.0000000e+00 2.3977018e-32 1.9182659e-28 9.7495674e-35], sum to 1.0000
[2019-03-24 00:01:08,216] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6691
[2019-03-24 00:01:08,221] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.2, 58.0, 1.0, 2.0, 0.5234344943096633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 621257.1205871544, 621257.1205871544, 146509.7598599237], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1535400.0000, 
sim time next is 1536000.0000, 
raw observation next is [27.7, 60.0, 1.0, 2.0, 0.5200757473328845, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 618357.1735305368, 618357.1735305368, 146011.6221403368], 
processed observation next is [0.0, 0.782608695652174, 0.5814814814814815, 0.6, 1.0, 1.0, 0.4286616039677197, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22084184768947743, 0.22084184768947743, 0.28079158103910923], 
reward next is 0.7192, 
noisyNet noise sample is [array([-0.193109], dtype=float32), -1.5832127]. 
=============================================
[2019-03-24 00:01:08,242] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[71.29372]
 [71.29372]
 [71.29372]
 [71.29372]
 [71.29372]], R is [[71.29998779]
 [71.30524445]
 [71.30853271]
 [71.30570984]
 [71.30850983]].
[2019-03-24 00:01:12,403] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.2828680e-18 1.0000000e+00 1.3413843e-28 1.2107915e-27 9.1649315e-32], sum to 1.0000
[2019-03-24 00:01:12,410] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2419
[2019-03-24 00:01:12,416] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.96666666666667, 41.16666666666667, 1.0, 2.0, 0.888824928357155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.981323017653143, 6.9112, 121.9256285281452, 1145662.122428003, 1109752.991821075, 218923.8915796218], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1615800.0000, 
sim time next is 1616400.0000, 
raw observation next is [28.0, 41.0, 1.0, 2.0, 0.8850770793212619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.956441739411328, 6.9112, 121.9256781451328, 1128304.191686146, 1105136.446701741, 218071.8986537937], 
processed observation next is [1.0, 0.7391304347826086, 0.5925925925925926, 0.41, 1.0, 1.0, 0.8631869991919784, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.004524173941132759, 0.0, 0.8094597091148461, 0.4029657827450521, 0.39469158810776467, 0.4193690358726802], 
reward next is 0.3544, 
noisyNet noise sample is [array([0.64658725], dtype=float32), -0.32863927]. 
=============================================
[2019-03-24 00:01:17,966] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.4365211e-20 1.0000000e+00 3.2580128e-31 8.5016179e-27 7.8243887e-33], sum to 1.0000
[2019-03-24 00:01:17,973] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9083
[2019-03-24 00:01:17,977] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.7, 68.66666666666667, 1.0, 2.0, 0.8346867452009404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1029446.831919689, 1029446.831919689, 206522.9454101389], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1700400.0000, 
sim time next is 1701000.0000, 
raw observation next is [23.75, 68.5, 1.0, 2.0, 0.8655830326733904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 1067155.455176147, 1067155.455176146, 213329.6457437523], 
processed observation next is [1.0, 0.6956521739130435, 0.4351851851851852, 0.685, 1.0, 1.0, 0.8399798008016552, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.38112694827719534, 0.381126948277195, 0.4102493187379852], 
reward next is 0.5898, 
noisyNet noise sample is [array([1.3847526], dtype=float32), 0.18790297]. 
=============================================
[2019-03-24 00:01:17,987] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[68.321686]
 [68.321686]
 [68.321686]
 [68.321686]
 [68.321686]], R is [[68.22822571]
 [68.14878845]
 [68.08181   ]
 [67.40099335]
 [66.72698212]].
[2019-03-24 00:01:24,549] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.4183745e-20 1.0000000e+00 1.7968921e-32 8.8883886e-30 2.7439679e-34], sum to 1.0000
[2019-03-24 00:01:24,555] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9265
[2019-03-24 00:01:24,558] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.75, 65.0, 1.0, 2.0, 0.6005102148633794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 688854.058490721, 688854.058490721, 158386.7279439515], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2050200.0000, 
sim time next is 2050800.0000, 
raw observation next is [28.63333333333333, 65.66666666666667, 1.0, 2.0, 0.6013776537253146, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 689753.4332320658, 689753.4332320653, 158531.7395171375], 
processed observation next is [0.0, 0.7391304347826086, 0.6160493827160493, 0.6566666666666667, 1.0, 1.0, 0.5254495877682317, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2463405118685949, 0.24634051186859474, 0.30486872984064906], 
reward next is 0.6951, 
noisyNet noise sample is [array([-1.033391], dtype=float32), 1.0252641]. 
=============================================
[2019-03-24 00:01:27,711] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.8296876e-22 1.0000000e+00 4.3934061e-33 1.4406270e-29 5.1960244e-34], sum to 1.0000
[2019-03-24 00:01:27,720] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2116
[2019-03-24 00:01:27,726] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.81666666666667, 83.66666666666666, 1.0, 2.0, 0.7742189989889957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 951331.3442675844, 951331.3442675844, 193570.2054619326], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1864200.0000, 
sim time next is 1864800.0000, 
raw observation next is [21.8, 84.0, 1.0, 2.0, 0.7446317800083466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 914628.1381730991, 914628.1381730991, 187512.5707800933], 
processed observation next is [1.0, 0.6086956521739131, 0.362962962962963, 0.84, 1.0, 1.0, 0.6959902142956508, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3266529064903925, 0.3266529064903925, 0.36060109765402554], 
reward next is 0.6394, 
noisyNet noise sample is [array([0.22703552], dtype=float32), -0.24305525]. 
=============================================
[2019-03-24 00:01:34,208] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.0380456e-18 1.0000000e+00 2.3124285e-31 2.5546346e-28 1.7227623e-32], sum to 1.0000
[2019-03-24 00:01:34,215] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9613
[2019-03-24 00:01:34,219] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.08333333333333, 50.83333333333334, 1.0, 2.0, 0.5647441972343634, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 655601.7109051317, 655601.7109051317, 152691.9813807503], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2137800.0000, 
sim time next is 2138400.0000, 
raw observation next is [30.9, 52.0, 1.0, 2.0, 0.5703371119338457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 661069.2286146615, 661069.2286146615, 153582.1347182315], 
processed observation next is [0.0, 0.782608695652174, 0.7, 0.52, 1.0, 1.0, 0.4884965618260068, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23609615307666482, 0.23609615307666482, 0.29535025907352214], 
reward next is 0.7046, 
noisyNet noise sample is [array([0.35285628], dtype=float32), -0.9924627]. 
=============================================
[2019-03-24 00:01:34,507] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-24 00:01:34,509] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:01:34,511] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:01:34,510] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:01:34,512] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:01:34,512] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:01:34,514] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:01:34,513] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:01:34,518] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:01:34,514] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:01:34,519] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:01:34,536] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run71
[2019-03-24 00:01:34,536] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run71
[2019-03-24 00:01:34,585] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run71
[2019-03-24 00:01:34,609] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run71
[2019-03-24 00:01:34,634] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run71
[2019-03-24 00:01:37,299] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0123947]
[2019-03-24 00:01:37,300] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [19.5, 43.0, 1.0, 2.0, 0.2353440973354794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 303569.8958648192, 303569.8958648196, 83027.37131908884]
[2019-03-24 00:01:37,302] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:01:37,305] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.3104015e-20 1.0000000e+00 8.1718472e-33 3.3951346e-30 4.9514445e-35], sampled 0.6255999134054369
[2019-03-24 00:02:10,253] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0123947]
[2019-03-24 00:02:10,254] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.27015188666667, 96.50317237000002, 1.0, 2.0, 0.6629292264170668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 755530.9598522815, 755530.9598522815, 169241.6615378617]
[2019-03-24 00:02:10,256] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:02:10,259] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.3104015e-20 1.0000000e+00 8.1718472e-33 3.3951346e-30 4.9514445e-35], sampled 0.2348418541780567
[2019-03-24 00:02:17,505] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0123947]
[2019-03-24 00:02:17,507] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [36.0, 29.0, 1.0, 2.0, 0.6390906499291568, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9779786863757965, 6.911199999999999, 6.9112, 121.9260426156618, 1460371.200541441, 1460371.200541442, 302673.5168800125]
[2019-03-24 00:02:17,508] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:02:17,512] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.3104015e-20 1.0000000e+00 8.1718472e-33 3.3951346e-30 4.9514445e-35], sampled 0.4857655662965864
[2019-03-24 00:02:17,513] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1460371.200541441 W.
[2019-03-24 00:02:50,901] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0123947]
[2019-03-24 00:02:50,902] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [35.56666666666667, 36.33333333333333, 1.0, 2.0, 0.8675738158044585, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999998, 6.9112, 121.9260426156618, 1704070.342352984, 1704070.342352985, 350050.6708193486]
[2019-03-24 00:02:50,904] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:02:50,908] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.3104015e-20 1.0000000e+00 8.1718472e-33 3.3951346e-30 4.9514445e-35], sampled 0.606827038505946
[2019-03-24 00:02:50,909] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1704070.342352984 W.
[2019-03-24 00:02:55,753] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0123947]
[2019-03-24 00:02:55,755] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.26666666666667, 57.66666666666667, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 8.505006145045678, 6.9112, 121.9198741621382, 2005788.597746187, 1189658.690246378, 247045.5350792308]
[2019-03-24 00:02:55,756] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:02:55,760] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.3104015e-20 1.0000000e+00 8.1718472e-33 3.3951346e-30 4.9514445e-35], sampled 0.7255733275237063
[2019-03-24 00:02:55,764] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2005788.597746187 W.
[2019-03-24 00:03:00,293] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0123947]
[2019-03-24 00:03:00,294] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.82124650333333, 78.81391467499999, 1.0, 2.0, 0.908644950606357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1035758.89178611, 1035758.891786109, 219408.3580215882]
[2019-03-24 00:03:00,295] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:03:00,300] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.3104015e-20 1.0000000e+00 8.1718472e-33 3.3951346e-30 4.9514445e-35], sampled 0.10964559186987066
[2019-03-24 00:03:12,281] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0123947]
[2019-03-24 00:03:12,283] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.11837553833333, 102.4246185916667, 1.0, 2.0, 0.486993995994496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 587743.7742523536, 587743.7742523536, 141108.5292136548]
[2019-03-24 00:03:12,284] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:03:12,286] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.3104015e-20 1.0000000e+00 8.1718472e-33 3.3951346e-30 4.9514445e-35], sampled 0.2513327521526374
[2019-03-24 00:03:12,552] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0123947]
[2019-03-24 00:03:12,552] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.0, 41.0, 1.0, 2.0, 0.2888979565551592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 370808.9999548111, 370808.9999548111, 114213.8789705712]
[2019-03-24 00:03:12,554] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:03:12,558] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.3104015e-20 1.0000000e+00 8.1718472e-33 3.3951346e-30 4.9514445e-35], sampled 0.8084649938633988
[2019-03-24 00:03:17,510] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0123947]
[2019-03-24 00:03:17,513] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.671302495, 68.37845062333334, 1.0, 2.0, 0.2841850074720926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 363942.5616680299, 363942.5616680303, 113645.5157023678]
[2019-03-24 00:03:17,513] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:03:17,516] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.3104015e-20 1.0000000e+00 8.1718472e-33 3.3951346e-30 4.9514445e-35], sampled 0.6623486105612646
[2019-03-24 00:03:19,284] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 00:03:19,561] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 00:03:19,784] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 00:03:19,785] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 00:03:19,806] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 00:03:20,823] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1750000, evaluation results [1750000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 00:03:25,602] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.6038848e-20 1.0000000e+00 1.0909350e-32 1.9292359e-29 6.2651158e-34], sum to 1.0000
[2019-03-24 00:03:25,608] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7293
[2019-03-24 00:03:25,613] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.86666666666667, 90.33333333333333, 1.0, 2.0, 0.4515707080069766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 547833.4032518009, 547833.4032518006, 135806.2651613702], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2098200.0000, 
sim time next is 2098800.0000, 
raw observation next is [22.0, 90.0, 1.0, 2.0, 0.4554272849326774, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 551679.174389162, 551679.1743891616, 136357.3280289862], 
processed observation next is [0.0, 0.30434782608695654, 0.37037037037037035, 0.9, 1.0, 1.0, 0.3516991487293779, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19702827656755786, 0.19702827656755773, 0.26222563082497347], 
reward next is 0.7378, 
noisyNet noise sample is [array([0.27863404], dtype=float32), 1.4155726]. 
=============================================
[2019-03-24 00:03:29,845] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2327712e-19 1.0000000e+00 2.4972729e-30 2.7604383e-28 1.6705303e-31], sum to 1.0000
[2019-03-24 00:03:29,858] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6419
[2019-03-24 00:03:29,862] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.06666666666667, 89.0, 1.0, 2.0, 0.600877259537118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 702135.375749168, 702135.375749168, 159044.5051388009], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2182800.0000, 
sim time next is 2183400.0000, 
raw observation next is [24.1, 89.0, 1.0, 2.0, 0.5851769999182485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 683388.0095935089, 683388.0095935084, 156321.5314949953], 
processed observation next is [1.0, 0.2608695652173913, 0.4481481481481482, 0.89, 1.0, 1.0, 0.506163095140772, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24406714628339604, 0.24406714628339587, 0.30061832979806785], 
reward next is 0.6994, 
noisyNet noise sample is [array([0.38355726], dtype=float32), -2.0443127]. 
=============================================
[2019-03-24 00:03:34,110] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.2321996e-20 1.0000000e+00 1.7375937e-31 8.5029067e-29 3.0251672e-33], sum to 1.0000
[2019-03-24 00:03:34,117] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1615
[2019-03-24 00:03:34,124] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.4, 95.16666666666667, 1.0, 2.0, 0.4164290415373986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 512100.9669835112, 512100.9669835112, 130864.1754999739], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2265000.0000, 
sim time next is 2265600.0000, 
raw observation next is [20.4, 95.33333333333334, 1.0, 2.0, 0.4120643149659357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 506610.2435691757, 506610.2435691757, 130236.0139397872], 
processed observation next is [1.0, 0.21739130434782608, 0.31111111111111106, 0.9533333333333335, 1.0, 1.0, 0.30007656543563777, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1809322298461342, 0.1809322298461342, 0.2504538729611292], 
reward next is 0.7495, 
noisyNet noise sample is [array([-0.35900444], dtype=float32), -1.584963]. 
=============================================
[2019-03-24 00:03:35,699] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.0688508e-19 1.0000000e+00 3.1169399e-31 9.6223468e-29 2.6227022e-33], sum to 1.0000
[2019-03-24 00:03:35,707] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6494
[2019-03-24 00:03:35,713] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.73333333333333, 93.0, 1.0, 2.0, 0.7611306274317263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 919818.4526819576, 919818.4526819586, 190377.7526134822], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2280000.0000, 
sim time next is 2280600.0000, 
raw observation next is [21.9, 92.5, 1.0, 2.0, 0.785284678944667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 947321.2004984561, 947321.2004984561, 195291.7951742032], 
processed observation next is [1.0, 0.391304347826087, 0.36666666666666664, 0.925, 1.0, 1.0, 0.7443865225531751, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.33832900017802003, 0.33832900017802003, 0.3755611445657754], 
reward next is 0.6244, 
noisyNet noise sample is [array([-0.61354846], dtype=float32), 1.2117378]. 
=============================================
[2019-03-24 00:03:37,539] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.7555129e-19 1.0000000e+00 1.7838492e-30 4.9047300e-27 4.2830674e-31], sum to 1.0000
[2019-03-24 00:03:37,545] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5804
[2019-03-24 00:03:37,549] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 96.0, 1.0, 2.0, 0.4896094906252275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 588301.5979496023, 588301.5979496023, 141426.9974333128], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2347200.0000, 
sim time next is 2347800.0000, 
raw observation next is [21.68333333333333, 96.0, 1.0, 2.0, 0.5625342460256423, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 676144.3946712234, 676144.3946712234, 153252.8189502048], 
processed observation next is [1.0, 0.17391304347826086, 0.35864197530864184, 0.96, 1.0, 1.0, 0.4792074357448122, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24148014095400835, 0.24148014095400835, 0.2947169595196246], 
reward next is 0.7053, 
noisyNet noise sample is [array([-0.46210003], dtype=float32), -0.3976991]. 
=============================================
[2019-03-24 00:03:44,643] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.5128332e-20 1.0000000e+00 8.9148363e-31 9.6076440e-28 1.8221679e-34], sum to 1.0000
[2019-03-24 00:03:44,653] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7085
[2019-03-24 00:03:44,666] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1532491.888844817 W.
[2019-03-24 00:03:44,671] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [34.4, 23.66666666666667, 1.0, 2.0, 0.4268239517893661, 1.0, 1.0, 0.4268239517893661, 1.0, 2.0, 0.6880278478430575, 6.911199999999999, 6.9112, 121.94756008, 1532491.888844817, 1532491.888844818, 308703.7713023561], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2475600.0000, 
sim time next is 2476200.0000, 
raw observation next is [34.34999999999999, 23.83333333333333, 1.0, 2.0, 0.6864830610749577, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9577953069121936, 6.9112, 6.9112, 121.9260426156618, 1546774.323524172, 1546774.323524172, 304266.4920893055], 
processed observation next is [1.0, 0.6521739130434783, 0.8277777777777773, 0.23833333333333329, 1.0, 1.0, 0.6267655488987591, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9472441336402421, 0.0, 0.0, 0.8094621288201359, 0.5524194012586329, 0.5524194012586329, 0.5851278694025105], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4925364], dtype=float32), -0.47255751]. 
=============================================
[2019-03-24 00:03:46,123] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.6580795e-18 1.0000000e+00 1.4786839e-28 3.1753824e-26 1.8158078e-31], sum to 1.0000
[2019-03-24 00:03:46,133] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0486
[2019-03-24 00:03:46,137] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.9, 47.0, 1.0, 2.0, 0.37879048434143, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 472393.7393056062, 472393.7393056062, 125734.9420301856], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2503200.0000, 
sim time next is 2503800.0000, 
raw observation next is [26.8, 47.5, 1.0, 2.0, 0.3789824441734111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 472583.400942294, 472583.400942294, 125760.3394696272], 
processed observation next is [1.0, 1.0, 0.5481481481481482, 0.475, 1.0, 1.0, 0.2606933859207275, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16877978605081928, 0.16877978605081928, 0.24184680667236], 
reward next is 0.7582, 
noisyNet noise sample is [array([0.21153104], dtype=float32), -1.020418]. 
=============================================
[2019-03-24 00:03:56,511] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.2376982e-21 1.0000000e+00 5.5554627e-32 6.6323780e-31 1.5259670e-34], sum to 1.0000
[2019-03-24 00:03:56,517] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5658
[2019-03-24 00:03:56,521] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.03333333333333, 84.66666666666667, 1.0, 2.0, 0.4036481447708115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 500493.2848324688, 500493.2848324693, 129142.0752542292], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2699400.0000, 
sim time next is 2700000.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.3929639115003881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 488877.1281617631, 488877.1281617631, 127674.5992172964], 
processed observation next is [0.0, 0.2608695652173913, 0.3333333333333333, 0.83, 1.0, 1.0, 0.27733798988141445, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1745989743434868, 0.1745989743434868, 0.2455280754178777], 
reward next is 0.7545, 
noisyNet noise sample is [array([1.1815951], dtype=float32), 0.6228722]. 
=============================================
[2019-03-24 00:03:56,535] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[73.123825]
 [73.123825]
 [73.123825]
 [73.123825]
 [73.123825]], R is [[73.14705658]
 [73.16723633]
 [73.18424988]
 [73.19802094]
 [73.20862579]].
[2019-03-24 00:04:00,441] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.45718121e-19 1.00000000e+00 1.42572381e-29 4.66858707e-28
 1.13989326e-32], sum to 1.0000
[2019-03-24 00:04:00,445] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8073
[2019-03-24 00:04:00,449] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 84.0, 1.0, 2.0, 0.6518209374643252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 742864.8672195461, 742864.8672195461, 167221.2449869135], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2757600.0000, 
sim time next is 2758200.0000, 
raw observation next is [25.91666666666667, 84.83333333333333, 1.0, 2.0, 0.6449019684677452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 734975.7019669173, 734975.7019669173, 165973.6906181919], 
processed observation next is [0.0, 0.9565217391304348, 0.5154320987654323, 0.8483333333333333, 1.0, 1.0, 0.5772642481758871, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26249132213104187, 0.26249132213104187, 0.3191801742657537], 
reward next is 0.6808, 
noisyNet noise sample is [array([0.18481778], dtype=float32), 0.92353857]. 
=============================================
[2019-03-24 00:04:04,386] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.3600523e-16 1.0000000e+00 6.8025921e-25 6.6677174e-23 3.0509060e-26], sum to 1.0000
[2019-03-24 00:04:04,394] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4640
[2019-03-24 00:04:04,400] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.75, 90.66666666666666, 1.0, 2.0, 0.6969909531675894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 798129.9592200142, 798129.9592200142, 175762.5962305657], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2955000.0000, 
sim time next is 2955600.0000, 
raw observation next is [24.7, 90.0, 1.0, 2.0, 0.6936515931652869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 796742.8556693759, 796742.8556693759, 175254.352029655], 
processed observation next is [1.0, 0.21739130434782608, 0.4703703703703703, 0.9, 1.0, 1.0, 0.6352995156729606, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28455101988191994, 0.28455101988191994, 0.33702760005702886], 
reward next is 0.6630, 
noisyNet noise sample is [array([-0.560248], dtype=float32), 1.030127]. 
=============================================
[2019-03-24 00:04:06,856] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.7055812e-17 1.0000000e+00 1.2895004e-27 2.3770724e-26 1.0045115e-30], sum to 1.0000
[2019-03-24 00:04:06,862] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6441
[2019-03-24 00:04:06,866] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 97.0, 1.0, 2.0, 0.7233293949645598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156391, 859858.0827012532, 859858.0827012532, 182256.779974207], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2860800.0000, 
sim time next is 2861400.0000, 
raw observation next is [22.08333333333334, 98.5, 1.0, 2.0, 0.7131265264424352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 846304.3052005868, 846304.3052005868, 180205.9357649265], 
processed observation next is [1.0, 0.08695652173913043, 0.373456790123457, 0.985, 1.0, 1.0, 0.6584839600505181, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.30225153757163814, 0.30225153757163814, 0.3465498764710125], 
reward next is 0.6535, 
noisyNet noise sample is [array([0.8378755], dtype=float32), 0.1689711]. 
=============================================
[2019-03-24 00:04:07,231] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0012477e-16 1.0000000e+00 7.4405919e-30 2.4609739e-25 1.5573312e-31], sum to 1.0000
[2019-03-24 00:04:07,237] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7812
[2019-03-24 00:04:07,241] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1363097.945146616 W.
[2019-03-24 00:04:07,244] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.41666666666666, 84.83333333333333, 1.0, 2.0, 0.3985187057322228, 1.0, 2.0, 0.3985187057322228, 1.0, 1.0, 0.6344547583738439, 6.911200000000001, 6.9112, 121.94756008, 1363097.945146616, 1363097.945146616, 296433.8528175304], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2891400.0000, 
sim time next is 2892000.0000, 
raw observation next is [24.53333333333333, 85.66666666666667, 1.0, 2.0, 0.6566240320130907, 0.0, 1.0, 0.0, 1.0, 2.0, 0.993015318050254, 6.911199999999999, 6.9112, 121.9260426156618, 1467120.048395604, 1467120.048395605, 308704.9725499117], 
processed observation next is [1.0, 0.4782608695652174, 0.46419753086419746, 0.8566666666666667, 1.0, 1.0, 0.5912190857298699, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9912691475628174, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5239714458555729, 0.5239714458555732, 0.5936634087498303], 
reward next is 0.4063, 
noisyNet noise sample is [array([0.04073804], dtype=float32), -0.057524882]. 
=============================================
[2019-03-24 00:04:07,263] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[66.951454]
 [66.951454]
 [66.951454]
 [66.951454]
 [66.951454]], R is [[66.68827057]
 [66.02138519]
 [65.36117554]
 [64.70756531]
 [64.06049347]].
[2019-03-24 00:04:08,413] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.3173023e-17 1.0000000e+00 2.4997954e-25 4.4437690e-26 6.4334828e-28], sum to 1.0000
[2019-03-24 00:04:08,420] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9797
[2019-03-24 00:04:08,425] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.6852007309650351, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 780926.4050572189, 780926.4050572184, 173360.7346072997], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2929200.0000, 
sim time next is 2929800.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.6850219263724854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 780722.5168627085, 780722.516862708, 173327.3514514834], 
processed observation next is [1.0, 0.9130434782608695, 0.5185185185185185, 0.89, 1.0, 1.0, 0.6250261028243873, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27882947030811017, 0.27882947030811, 0.33332182971439117], 
reward next is 0.6667, 
noisyNet noise sample is [array([-0.14227414], dtype=float32), 0.21700189]. 
=============================================
[2019-03-24 00:04:10,831] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-24 00:04:10,832] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:04:10,832] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:04:10,832] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:04:10,833] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:04:10,837] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:04:10,837] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:04:10,838] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:04:10,840] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:04:10,837] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:04:10,842] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:04:10,862] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run72
[2019-03-24 00:04:10,886] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run72
[2019-03-24 00:04:10,887] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run72
[2019-03-24 00:04:10,907] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run72
[2019-03-24 00:04:10,957] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run72
[2019-03-24 00:04:14,049] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.015928306]
[2019-03-24 00:04:14,050] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.41959032, 15.33257957, 1.0, 2.0, 0.337195183281272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 434984.6702944297, 434984.6702944297, 105646.2524124122]
[2019-03-24 00:04:14,051] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:04:14,053] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.7637023e-18 1.0000000e+00 3.0282345e-28 5.0663938e-26 3.0795355e-30], sampled 0.2165455326187109
[2019-03-24 00:04:45,559] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.015928306]
[2019-03-24 00:04:45,563] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.85316241333333, 84.61538207666666, 1.0, 2.0, 0.8666738859420999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1007976.367406444, 1007976.367406444, 211150.9049684208]
[2019-03-24 00:04:45,564] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:04:45,567] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.7637023e-18 1.0000000e+00 3.0282345e-28 5.0663938e-26 3.0795355e-30], sampled 0.435758163123914
[2019-03-24 00:04:50,758] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.015928306]
[2019-03-24 00:04:50,759] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.33333333333334, 71.66666666666667, 1.0, 2.0, 0.6212514669149591, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 712794.1143787366, 712794.1143787366, 162007.1551948467]
[2019-03-24 00:04:50,760] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:04:50,765] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.7637023e-18 1.0000000e+00 3.0282345e-28 5.0663938e-26 3.0795355e-30], sampled 0.651777504596138
[2019-03-24 00:04:57,586] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.015928306]
[2019-03-24 00:04:57,588] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.65686334166667, 92.98521902499999, 1.0, 2.0, 0.4391882958419726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 538274.410572258, 538274.4105722576, 134128.8647725048]
[2019-03-24 00:04:57,588] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:04:57,592] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.7637023e-18 1.0000000e+00 3.0282345e-28 5.0663938e-26 3.0795355e-30], sampled 0.5295439107062252
[2019-03-24 00:04:57,773] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.015928306]
[2019-03-24 00:04:57,775] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [32.0, 75.0, 1.0, 2.0, 0.9377162258184623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999997, 6.9112, 121.9260426156618, 1068920.177446763, 1068920.177446765, 226054.396218566]
[2019-03-24 00:04:57,776] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:04:57,779] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [8.7637023e-18 1.0000000e+00 3.0282345e-28 5.0663938e-26 3.0795355e-30], sampled 0.7258177806520623
[2019-03-24 00:05:04,723] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.015928306]
[2019-03-24 00:05:04,726] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.33333333333333, 72.0, 1.0, 2.0, 0.733201891679128, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1550698.08660901, 1550698.08660901, 323344.0136504623]
[2019-03-24 00:05:04,727] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:05:04,731] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.7637023e-18 1.0000000e+00 3.0282345e-28 5.0663938e-26 3.0795355e-30], sampled 0.15792859023517203
[2019-03-24 00:05:04,734] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1550698.08660901 W.
[2019-03-24 00:05:20,416] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.015928306]
[2019-03-24 00:05:20,418] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.58333333333333, 70.66666666666667, 1.0, 2.0, 0.7135079553857083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 813205.3923715006, 813205.3923715001, 178719.1221274775]
[2019-03-24 00:05:20,420] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:05:20,424] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.7637023e-18 1.0000000e+00 3.0282345e-28 5.0663938e-26 3.0795355e-30], sampled 0.47446980347592693
[2019-03-24 00:05:49,500] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.015928306]
[2019-03-24 00:05:49,502] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [19.6, 93.66666666666667, 1.0, 2.0, 0.372897787701007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 464885.5970020148, 464885.5970020148, 124925.9950172434]
[2019-03-24 00:05:49,502] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:05:49,505] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.7637023e-18 1.0000000e+00 3.0282345e-28 5.0663938e-26 3.0795355e-30], sampled 0.022508068527806846
[2019-03-24 00:05:56,041] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 00:05:56,239] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 00:05:56,423] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 00:05:56,437] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 00:05:56,542] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 00:05:57,560] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1775000, evaluation results [1775000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 00:05:58,161] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.519486e-17 1.000000e+00 3.169380e-26 7.861846e-26 6.890879e-30], sum to 1.0000
[2019-03-24 00:05:58,174] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4828
[2019-03-24 00:05:58,177] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.7210584644233614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 821815.5366538906, 821815.5366538906, 180165.8044961319], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2962200.0000, 
sim time next is 2962800.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.7814390797003891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 890673.4217528201, 890673.4217528201, 192130.8853718969], 
processed observation next is [1.0, 0.30434782608695654, 0.48148148148148145, 0.94, 1.0, 1.0, 0.7398084282147489, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3180976506260072, 0.3180976506260072, 0.3694824718690325], 
reward next is 0.6305, 
noisyNet noise sample is [array([0.2696887], dtype=float32), -1.6545744]. 
=============================================
[2019-03-24 00:06:07,773] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.7545499e-18 1.0000000e+00 3.3295829e-29 1.1097758e-27 8.1099321e-31], sum to 1.0000
[2019-03-24 00:06:07,785] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5658
[2019-03-24 00:06:07,789] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.86666666666667, 54.66666666666666, 1.0, 2.0, 0.7312190424790237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 869284.599869317, 869284.599869317, 183812.4506216194], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3138000.0000, 
sim time next is 3138600.0000, 
raw observation next is [29.33333333333334, 53.83333333333334, 1.0, 2.0, 0.7481737970442174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 885268.9045452969, 885268.9045452964, 187013.6533374556], 
processed observation next is [1.0, 0.30434782608695654, 0.6419753086419755, 0.5383333333333334, 1.0, 1.0, 0.7002069012431159, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3161674659090346, 0.31616746590903444, 0.35964164103356844], 
reward next is 0.6404, 
noisyNet noise sample is [array([-0.84859824], dtype=float32), 1.6242551]. 
=============================================
[2019-03-24 00:06:10,513] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.7718138e-16 1.0000000e+00 1.5721029e-25 5.0117141e-23 3.2033269e-27], sum to 1.0000
[2019-03-24 00:06:10,521] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1009
[2019-03-24 00:06:10,525] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.11666666666667, 32.0, 1.0, 2.0, 0.4621072971902645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 554438.0441760543, 554438.0441760548, 137185.2190074873], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3174600.0000, 
sim time next is 3175200.0000, 
raw observation next is [34.0, 32.0, 1.0, 2.0, 0.4635255584370927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 556982.5311336396, 556982.5311336396, 137428.3246140689], 
processed observation next is [1.0, 0.782608695652174, 0.8148148148148148, 0.32, 1.0, 1.0, 0.3613399505203485, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19892233254772843, 0.19892233254772843, 0.2642852396424402], 
reward next is 0.7357, 
noisyNet noise sample is [array([-0.5919821], dtype=float32), 1.5466454]. 
=============================================
[2019-03-24 00:06:12,155] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.4616688e-20 1.0000000e+00 8.3131284e-30 1.1986133e-27 9.0431339e-33], sum to 1.0000
[2019-03-24 00:06:12,161] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3698
[2019-03-24 00:06:12,166] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.73333333333334, 85.66666666666667, 1.0, 2.0, 0.587887632377947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 682910.1485737475, 682910.1485737475, 156622.8312954947], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3205200.0000, 
sim time next is 3205800.0000, 
raw observation next is [24.55, 85.0, 1.0, 2.0, 0.5747180400149255, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 671342.2983639446, 671342.2983639446, 154550.5050408131], 
processed observation next is [0.0, 0.08695652173913043, 0.46481481481481485, 0.85, 1.0, 1.0, 0.49371195239872084, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23976510655855165, 0.23976510655855165, 0.2972125096938713], 
reward next is 0.7028, 
noisyNet noise sample is [array([0.3307136], dtype=float32), -1.795167]. 
=============================================
[2019-03-24 00:06:20,630] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.7162423e-17 1.0000000e+00 1.4690247e-28 1.9191390e-26 1.5960582e-30], sum to 1.0000
[2019-03-24 00:06:20,636] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7166
[2019-03-24 00:06:20,639] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.8, 83.0, 1.0, 2.0, 0.7414505728593513, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 850319.5889179686, 850319.5889179686, 184406.0381754394], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3398400.0000, 
sim time next is 3399000.0000, 
raw observation next is [26.0, 82.33333333333334, 1.0, 2.0, 0.860166784669735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 984644.4854469792, 984644.4854469792, 208906.5570230112], 
processed observation next is [1.0, 0.34782608695652173, 0.5185185185185185, 0.8233333333333335, 1.0, 1.0, 0.8335318865115893, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.35165874480249254, 0.35165874480249254, 0.4017433788904062], 
reward next is 0.5983, 
noisyNet noise sample is [array([0.5871968], dtype=float32), 0.6115446]. 
=============================================
[2019-03-24 00:06:20,657] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[65.55335]
 [65.55335]
 [65.55335]
 [65.55335]
 [65.55335]], R is [[65.49607849]
 [65.48648834]
 [65.458992  ]
 [65.43392944]
 [65.40856934]].
[2019-03-24 00:06:21,582] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.7864978e-18 1.0000000e+00 9.7680673e-28 1.9629933e-27 2.1260480e-30], sum to 1.0000
[2019-03-24 00:06:21,588] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7432
[2019-03-24 00:06:21,596] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333334, 91.66666666666667, 1.0, 2.0, 0.5867458169640085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 683288.7418216369, 683288.7418216369, 156504.2895804916], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3375600.0000, 
sim time next is 3376200.0000, 
raw observation next is [23.71666666666667, 91.33333333333334, 1.0, 2.0, 0.5787987882306725, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 676247.3386554389, 676247.3386554389, 155248.1786727169], 
processed observation next is [1.0, 0.043478260869565216, 0.4339506172839507, 0.9133333333333334, 1.0, 1.0, 0.49856998598889585, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24151690666265674, 0.24151690666265674, 0.2985541897552248], 
reward next is 0.7014, 
noisyNet noise sample is [array([0.92801285], dtype=float32), 0.5970523]. 
=============================================
[2019-03-24 00:06:26,046] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.8184437e-18 1.0000000e+00 1.6503590e-28 7.3809219e-28 1.2343683e-31], sum to 1.0000
[2019-03-24 00:06:26,049] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5164
[2019-03-24 00:06:26,056] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.6552193067615371, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 746739.794642817, 746739.7946428175, 167838.955642237], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3477600.0000, 
sim time next is 3478200.0000, 
raw observation next is [25.0, 94.00000000000001, 1.0, 2.0, 0.7696491179793005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 877227.6962586077, 877227.6962586077, 189744.9324378186], 
processed observation next is [1.0, 0.2608695652173913, 0.48148148148148145, 0.9400000000000002, 1.0, 1.0, 0.7257727594991672, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3132956058066456, 0.3132956058066456, 0.3648941008419589], 
reward next is 0.6351, 
noisyNet noise sample is [array([0.06808104], dtype=float32), -1.2790676]. 
=============================================
[2019-03-24 00:06:26,322] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.5287793e-18 1.0000000e+00 1.5461635e-28 7.5133706e-25 3.8130611e-30], sum to 1.0000
[2019-03-24 00:06:26,330] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0366
[2019-03-24 00:06:26,335] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 100.0, 1.0, 2.0, 0.7279124184573589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 829631.4554496525, 829631.4554496525, 181491.0226340376], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3469200.0000, 
sim time next is 3469800.0000, 
raw observation next is [24.0, 100.0, 1.0, 2.0, 0.7164636182076453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 816575.8401431678, 816575.8401431678, 179279.9595190936], 
processed observation next is [1.0, 0.13043478260869565, 0.4444444444444444, 1.0, 1.0, 1.0, 0.6624566883424349, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2916342286225599, 0.2916342286225599, 0.3447691529213338], 
reward next is 0.6552, 
noisyNet noise sample is [array([1.2337962], dtype=float32), -0.6943324]. 
=============================================
[2019-03-24 00:06:30,703] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.4408055e-19 1.0000000e+00 3.8427621e-30 2.5314207e-28 1.6955877e-32], sum to 1.0000
[2019-03-24 00:06:30,710] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8159
[2019-03-24 00:06:30,716] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2041136.506502784 W.
[2019-03-24 00:06:30,727] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.21666666666667, 86.16666666666667, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 8.561577191486034, 6.9112, 121.9192135118186, 2041136.506502784, 1196043.211930735, 247373.7166173951], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3589800.0000, 
sim time next is 3590400.0000, 
raw observation next is [24.43333333333333, 83.33333333333334, 1.0, 2.0, 0.6966505714910868, 1.0, 1.0, 0.6966505714910868, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9250487310027, 1602584.051992062, 1602584.051992061, 303599.5237514444], 
processed observation next is [1.0, 0.5652173913043478, 0.4604938271604937, 0.8333333333333335, 1.0, 1.0, 0.6388697279655795, 1.0, 0.5, 0.6388697279655795, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094555304595668, 0.5723514471400222, 0.5723514471400218, 0.5838452379835469], 
reward next is 0.4162, 
noisyNet noise sample is [array([-0.850272], dtype=float32), -0.5871979]. 
=============================================
[2019-03-24 00:06:32,102] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.1914794e-18 1.0000000e+00 1.4628050e-30 2.8975878e-27 6.7436108e-31], sum to 1.0000
[2019-03-24 00:06:32,110] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6064
[2019-03-24 00:06:32,116] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.83333333333334, 1.0, 2.0, 0.5970164049240443, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 710941.8698211858, 710941.8698211854, 158923.0936490918], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3564600.0000, 
sim time next is 3565200.0000, 
raw observation next is [23.0, 90.66666666666667, 1.0, 2.0, 0.56905775209379, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 676225.4736011276, 676225.4736011276, 154069.6146731727], 
processed observation next is [1.0, 0.2608695652173913, 0.4074074074074074, 0.9066666666666667, 1.0, 1.0, 0.48697351439736897, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24150909771468843, 0.24150909771468843, 0.29628772052533214], 
reward next is 0.7037, 
noisyNet noise sample is [array([2.1601317], dtype=float32), 0.94318557]. 
=============================================
[2019-03-24 00:06:34,988] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.0994105e-20 1.0000000e+00 5.2276641e-31 1.2565385e-27 1.3795386e-33], sum to 1.0000
[2019-03-24 00:06:34,997] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3304
[2019-03-24 00:06:35,001] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.91666666666666, 46.66666666666667, 1.0, 2.0, 0.6658839917960894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 758900.1307135943, 758900.1307135943, 169785.935332221], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3863400.0000, 
sim time next is 3864000.0000, 
raw observation next is [33.93333333333334, 47.33333333333334, 1.0, 2.0, 0.6766988075582572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 771231.8493581153, 771231.8493581153, 171779.9631265689], 
processed observation next is [0.0, 0.7391304347826086, 0.8123456790123458, 0.47333333333333344, 1.0, 1.0, 0.6151176280455443, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27543994619932693, 0.27543994619932693, 0.33034608293570944], 
reward next is 0.6697, 
noisyNet noise sample is [array([0.99398917], dtype=float32), -0.48071578]. 
=============================================
[2019-03-24 00:06:35,024] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[69.73557]
 [69.73557]
 [69.73557]
 [69.73557]
 [69.73557]], R is [[69.70786285]
 [69.68427277]
 [69.65802002]
 [69.62891388]
 [69.59882355]].
[2019-03-24 00:06:37,588] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.3562097e-17 1.0000000e+00 5.0756545e-28 5.0589445e-24 3.4998890e-30], sum to 1.0000
[2019-03-24 00:06:37,596] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1263
[2019-03-24 00:06:37,604] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1639163.046004168 W.
[2019-03-24 00:06:37,609] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.75, 95.66666666666667, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.830594728986208, 6.9112, 123.2776490220669, 1639163.046004168, 1163131.599010828, 245785.9300534966], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3723000.0000, 
sim time next is 3723600.0000, 
raw observation next is [24.8, 95.33333333333333, 1.0, 2.0, 0.5432235338284264, 1.0, 1.0, 0.5432235338284264, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9254889562031, 1238598.285524721, 1238598.285524721, 249073.695149826], 
processed observation next is [1.0, 0.08695652173913043, 0.4740740740740741, 0.9533333333333333, 1.0, 1.0, 0.4562184926528885, 1.0, 0.5, 0.4562184926528885, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094584530970954, 0.4423565305445432, 0.4423565305445432, 0.4789878752881269], 
reward next is 0.5210, 
noisyNet noise sample is [array([-0.35755062], dtype=float32), -1.0138929]. 
=============================================
[2019-03-24 00:06:40,480] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.57449729e-18 1.00000000e+00 3.63993537e-29 1.00132944e-28
 8.95273331e-31], sum to 1.0000
[2019-03-24 00:06:40,486] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2963
[2019-03-24 00:06:40,492] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 83.66666666666667, 1.0, 2.0, 0.6708706713591295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 764586.2250604063, 764586.2250604063, 170699.6495331947], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3973200.0000, 
sim time next is 3973800.0000, 
raw observation next is [26.05, 83.83333333333333, 1.0, 2.0, 0.6680540989716354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 761374.6045867384, 761374.6045867384, 170181.3048766101], 
processed observation next is [0.0, 1.0, 0.5203703703703704, 0.8383333333333333, 1.0, 1.0, 0.6048263082995659, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27191950163812084, 0.27191950163812084, 0.32727174014732713], 
reward next is 0.6727, 
noisyNet noise sample is [array([1.1424881], dtype=float32), -2.2461395]. 
=============================================
[2019-03-24 00:06:47,770] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-24 00:06:47,773] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:06:47,774] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:06:47,778] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:06:47,780] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:06:47,781] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:06:47,782] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:06:47,784] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:06:47,784] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:06:47,786] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:06:47,786] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:06:47,803] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run73
[2019-03-24 00:06:47,827] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run73
[2019-03-24 00:06:47,860] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run73
[2019-03-24 00:06:47,889] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run73
[2019-03-24 00:06:47,890] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run73
[2019-03-24 00:06:52,759] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.010762623]
[2019-03-24 00:06:52,760] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.33333333333333, 53.16666666666666, 1.0, 2.0, 0.2329149728820485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 300435.959247678, 300435.959247678, 91445.54698436831]
[2019-03-24 00:06:52,763] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:06:52,764] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.0019481e-18 1.0000000e+00 2.8029984e-29 5.7171739e-27 2.4040500e-31], sampled 0.12965491116789274
[2019-03-24 00:06:56,664] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.010762623]
[2019-03-24 00:06:56,665] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [18.6, 74.0, 1.0, 2.0, 0.2822235964931357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 364054.0230534871, 364054.0230534871, 110471.3897438404]
[2019-03-24 00:06:56,667] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:06:56,669] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.0019481e-18 1.0000000e+00 2.8029984e-29 5.7171739e-27 2.4040500e-31], sampled 0.09444885998786545
[2019-03-24 00:07:00,414] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.010762623]
[2019-03-24 00:07:00,415] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.0, 44.0, 1.0, 2.0, 0.2671449077239851, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 344598.9149262772, 344598.9149262772, 103861.022874908]
[2019-03-24 00:07:00,417] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:07:00,419] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.0019481e-18 1.0000000e+00 2.8029984e-29 5.7171739e-27 2.4040500e-31], sampled 0.23517462378757714
[2019-03-24 00:07:34,411] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.010762623]
[2019-03-24 00:07:34,412] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.73955442333333, 105.84006055, 1.0, 2.0, 0.5062994194693001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 603844.8480520535, 603844.8480520535, 143887.8854499803]
[2019-03-24 00:07:34,413] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:07:34,417] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.0019481e-18 1.0000000e+00 2.8029984e-29 5.7171739e-27 2.4040500e-31], sampled 0.4191330000774597
[2019-03-24 00:07:36,143] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.010762623]
[2019-03-24 00:07:36,146] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.13333333333333, 83.0, 1.0, 2.0, 0.572018744352392, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 665100.0669923825, 665100.0669923825, 153958.57008619]
[2019-03-24 00:07:36,147] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:07:36,150] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.0019481e-18 1.0000000e+00 2.8029984e-29 5.7171739e-27 2.4040500e-31], sampled 0.5992300893883353
[2019-03-24 00:08:32,670] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 00:08:33,018] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 00:08:33,344] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 00:08:33,357] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 00:08:33,361] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 00:08:34,378] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1800000, evaluation results [1800000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 00:08:37,393] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4224798e-15 1.0000000e+00 3.0366825e-26 6.6068185e-25 6.7025544e-30], sum to 1.0000
[2019-03-24 00:08:37,405] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6205
[2019-03-24 00:08:37,410] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.3, 76.33333333333333, 1.0, 2.0, 0.7723117779333354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 880264.2753882443, 880264.2753882443, 190290.488525072], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3955200.0000, 
sim time next is 3955800.0000, 
raw observation next is [29.15, 77.66666666666667, 1.0, 2.0, 0.7791968963456898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 888116.3315116852, 888116.3315116852, 191684.4756632553], 
processed observation next is [0.0, 0.782608695652174, 0.6351851851851852, 0.7766666666666667, 1.0, 1.0, 0.7371391623162974, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31718440411131615, 0.31718440411131615, 0.36862399166010634], 
reward next is 0.6314, 
noisyNet noise sample is [array([-0.16033362], dtype=float32), 2.1913586]. 
=============================================
[2019-03-24 00:08:41,974] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.9827699e-14 1.0000000e+00 2.6784375e-22 6.3095308e-20 8.2128284e-23], sum to 1.0000
[2019-03-24 00:08:41,980] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0187
[2019-03-24 00:08:41,986] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1745416.829829531 W.
[2019-03-24 00:08:41,993] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.33333333333334, 87.33333333333334, 1.0, 2.0, 0.765262290894643, 1.0, 2.0, 0.765262290894643, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156606, 1745416.829829531, 1745416.829829531, 329609.31438839], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4029600.0000, 
sim time next is 4030200.0000, 
raw observation next is [26.5, 86.5, 1.0, 2.0, 0.7757624483173788, 1.0, 2.0, 0.7757624483173788, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1769389.398348468, 1769389.398348469, 333840.9210164375], 
processed observation next is [1.0, 0.6521739130434783, 0.5370370370370371, 0.865, 1.0, 1.0, 0.7330505337111652, 1.0, 1.0, 0.7330505337111652, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6319247851244528, 0.6319247851244533, 0.6420017711854568], 
reward next is 0.3580, 
noisyNet noise sample is [array([2.1630719], dtype=float32), -0.90048975]. 
=============================================
[2019-03-24 00:08:47,164] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4322467e-17 1.0000000e+00 1.9472259e-28 2.0630798e-25 1.3410408e-29], sum to 1.0000
[2019-03-24 00:08:47,165] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1770
[2019-03-24 00:08:47,168] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1769621.441203915 W.
[2019-03-24 00:08:47,171] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.83333333333333, 65.66666666666667, 1.0, 2.0, 0.5172428125675093, 1.0, 2.0, 0.5172428125675093, 1.0, 1.0, 0.8234674030298399, 6.9112, 6.9112, 121.94756008, 1769621.441203915, 1769621.441203915, 352132.630536637], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4111800.0000, 
sim time next is 4112400.0000, 
raw observation next is [28.86666666666667, 67.33333333333334, 1.0, 2.0, 0.8374012117678163, 1.0, 2.0, 0.8374012117678163, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1910127.833509928, 1910127.833509928, 359450.991213483], 
processed observation next is [1.0, 0.6086956521739131, 0.6246913580246916, 0.6733333333333335, 1.0, 1.0, 0.8064300140093051, 1.0, 1.0, 0.8064300140093051, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6821885119678315, 0.6821885119678315, 0.6912519061797749], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.2230474], dtype=float32), 1.077872]. 
=============================================
[2019-03-24 00:08:56,227] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.3361820e-17 1.0000000e+00 3.3735024e-27 1.7808775e-23 3.6363707e-28], sum to 1.0000
[2019-03-24 00:08:56,234] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3719
[2019-03-24 00:08:56,238] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 74.0, 1.0, 2.0, 0.6131164073776061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 706066.4528876122, 706066.4528876122, 160707.257370925], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4311600.0000, 
sim time next is 4312200.0000, 
raw observation next is [27.0, 74.0, 1.0, 2.0, 0.6137890269806593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 706835.9890686683, 706835.9890686683, 160824.697162276], 
processed observation next is [1.0, 0.9130434782608695, 0.5555555555555556, 0.74, 1.0, 1.0, 0.5402250321198325, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25244142466738156, 0.25244142466738156, 0.3092782637736077], 
reward next is 0.6907, 
noisyNet noise sample is [array([-1.1542548], dtype=float32), 1.0129787]. 
=============================================
[2019-03-24 00:08:59,825] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.5136024e-17 1.0000000e+00 2.9276629e-28 6.2084970e-25 3.4643699e-30], sum to 1.0000
[2019-03-24 00:08:59,834] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3660
[2019-03-24 00:08:59,838] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.1, 83.0, 1.0, 2.0, 0.7063758447674884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 805072.4531963737, 805072.4531963737, 177354.4338556909], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4480200.0000, 
sim time next is 4480800.0000, 
raw observation next is [27.06666666666667, 83.33333333333334, 1.0, 2.0, 0.706060880115109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 804713.2924504514, 804713.2924504514, 177294.5574506612], 
processed observation next is [0.0, 0.8695652173913043, 0.5580246913580248, 0.8333333333333335, 1.0, 1.0, 0.6500724763275108, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2873976044465898, 0.2873976044465898, 0.3409510720205023], 
reward next is 0.6590, 
noisyNet noise sample is [array([0.0822361], dtype=float32), -0.3642658]. 
=============================================
[2019-03-24 00:09:00,880] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.4763558e-16 1.0000000e+00 3.5233388e-26 2.5482757e-23 6.6516920e-29], sum to 1.0000
[2019-03-24 00:09:00,890] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3238
[2019-03-24 00:09:00,894] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.08333333333334, 80.66666666666667, 1.0, 2.0, 0.5165449123113544, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 616515.4783129157, 616515.4783129157, 145534.3336140488], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4403400.0000, 
sim time next is 4404000.0000, 
raw observation next is [23.66666666666667, 83.33333333333334, 1.0, 2.0, 0.5127554782571664, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 612428.8256038601, 612428.8256038601, 144945.0718299522], 
processed observation next is [1.0, 1.0, 0.43209876543209896, 0.8333333333333335, 1.0, 1.0, 0.4199469979251981, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21872458057280716, 0.21872458057280716, 0.2787405227499081], 
reward next is 0.7213, 
noisyNet noise sample is [array([-0.7722901], dtype=float32), 1.1272511]. 
=============================================
[2019-03-24 00:09:00,910] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[59.082474]
 [59.082474]
 [59.082474]
 [59.082474]
 [59.082474]], R is [[59.21291351]
 [59.34091187]
 [59.46570206]
 [59.58466721]
 [59.69741058]].
[2019-03-24 00:09:03,868] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.126335e-20 1.000000e+00 7.552403e-30 5.565165e-29 9.558086e-33], sum to 1.0000
[2019-03-24 00:09:03,876] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5416
[2019-03-24 00:09:03,880] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 94.0, 1.0, 2.0, 0.7141546593023169, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 813942.8506548419, 813942.8506548419, 178843.1136300523], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4654800.0000, 
sim time next is 4655400.0000, 
raw observation next is [26.0, 94.00000000000001, 1.0, 2.0, 0.7182002721906589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 818556.2155551764, 818556.2155551764, 179620.2185993912], 
processed observation next is [1.0, 0.9130434782608695, 0.5185185185185185, 0.9400000000000002, 1.0, 1.0, 0.6645241335603082, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29234150555542016, 0.29234150555542016, 0.34542349730652155], 
reward next is 0.6546, 
noisyNet noise sample is [array([2.0955071], dtype=float32), -1.4514527]. 
=============================================
[2019-03-24 00:09:06,646] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.8341442e-18 1.0000000e+00 1.6476038e-28 2.3052199e-27 9.9397574e-31], sum to 1.0000
[2019-03-24 00:09:06,658] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2738
[2019-03-24 00:09:06,663] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.7072838569960311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 806107.879373672, 806107.879373672, 177527.620172185], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4485600.0000, 
sim time next is 4486200.0000, 
raw observation next is [26.73333333333333, 84.33333333333333, 1.0, 2.0, 0.6878113538315278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 783903.2653246428, 783903.2653246428, 173849.0769777434], 
processed observation next is [0.0, 0.9565217391304348, 0.545679012345679, 0.8433333333333333, 1.0, 1.0, 0.6283468497994379, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2799654519016581, 0.2799654519016581, 0.3343251480341219], 
reward next is 0.6657, 
noisyNet noise sample is [array([0.72203606], dtype=float32), -0.77109104]. 
=============================================
[2019-03-24 00:09:11,302] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.0408899e-18 1.0000000e+00 1.0548994e-27 3.3111839e-26 1.2075694e-31], sum to 1.0000
[2019-03-24 00:09:11,316] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3873
[2019-03-24 00:09:11,319] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.13333333333333, 99.66666666666666, 1.0, 2.0, 0.4839474435163825, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 582815.624805106, 582815.624805106, 140593.5783564216], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4599600.0000, 
sim time next is 4600200.0000, 
raw observation next is [21.06666666666667, 99.83333333333334, 1.0, 2.0, 0.4796460240427888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 578124.1239498281, 578124.1239498281, 139946.0620563609], 
processed observation next is [1.0, 0.21739130434782608, 0.3358024691358026, 0.9983333333333334, 1.0, 1.0, 0.38053098100331995, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2064729014106529, 0.2064729014106529, 0.26912704241607865], 
reward next is 0.7309, 
noisyNet noise sample is [array([0.78221405], dtype=float32), -1.1100453]. 
=============================================
[2019-03-24 00:09:16,199] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.0370407e-20 1.0000000e+00 3.9082701e-29 9.9567362e-28 8.1200244e-31], sum to 1.0000
[2019-03-24 00:09:16,210] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8168
[2019-03-24 00:09:16,219] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.6667898871059881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 759933.0806957921, 759933.0806957921, 169950.8790615674], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4669200.0000, 
sim time next is 4669800.0000, 
raw observation next is [24.96666666666667, 94.16666666666667, 1.0, 2.0, 0.6664008042301973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 759489.4275498703, 759489.4275498699, 169879.4283484655], 
processed observation next is [1.0, 0.043478260869565216, 0.48024691358024696, 0.9416666666666668, 1.0, 1.0, 0.6028581002740444, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2712462241249537, 0.2712462241249535, 0.32669120836243365], 
reward next is 0.6733, 
noisyNet noise sample is [array([-0.35368618], dtype=float32), -1.5040413]. 
=============================================
[2019-03-24 00:09:24,418] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-24 00:09:24,420] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:09:24,422] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:09:24,422] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:09:24,424] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:09:24,424] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:09:24,425] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:09:24,423] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:09:24,425] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:09:24,426] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:09:24,427] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:09:24,447] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run74
[2019-03-24 00:09:24,472] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run74
[2019-03-24 00:09:24,473] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run74
[2019-03-24 00:09:24,495] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run74
[2019-03-24 00:09:24,548] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run74
[2019-03-24 00:09:41,372] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.059155423]
[2019-03-24 00:09:41,373] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.812377575, 66.30258652, 1.0, 2.0, 0.401385981316254, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 496645.3843377543, 496645.3843377538, 128798.6459012536]
[2019-03-24 00:09:41,374] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:09:41,377] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.5528456e-17 1.0000000e+00 7.3508283e-28 1.1427055e-25 7.3099950e-30], sampled 0.38124402626682197
[2019-03-24 00:10:13,123] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.059155423]
[2019-03-24 00:10:13,124] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.83333333333334, 59.33333333333334, 1.0, 2.0, 0.5632134923403735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 658231.4706967279, 658231.4706967279, 152631.1490786336]
[2019-03-24 00:10:13,125] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:10:13,129] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.5528456e-17 1.0000000e+00 7.3508283e-28 1.1427055e-25 7.3099950e-30], sampled 0.6161064044850241
[2019-03-24 00:10:50,797] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.059155423]
[2019-03-24 00:10:50,798] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.06666666666667, 72.0, 1.0, 2.0, 0.776754437580997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 885330.8475818072, 885330.8475818067, 191179.0015544075]
[2019-03-24 00:10:50,800] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:10:50,804] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.5528456e-17 1.0000000e+00 7.3508283e-28 1.1427055e-25 7.3099950e-30], sampled 0.06682766545647179
[2019-03-24 00:10:52,381] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.059155423]
[2019-03-24 00:10:52,382] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.83333333333334, 89.83333333333334, 1.0, 2.0, 0.5127360491575796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 611929.024594523, 611929.024594523, 144924.4549483934]
[2019-03-24 00:10:52,383] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:10:52,385] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.5528456e-17 1.0000000e+00 7.3508283e-28 1.1427055e-25 7.3099950e-30], sampled 0.5406247093242108
[2019-03-24 00:11:09,947] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 00:11:10,222] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 00:11:10,323] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 00:11:10,353] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 00:11:10,470] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 00:11:11,489] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1825000, evaluation results [1825000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 00:11:15,395] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.0233526e-15 1.0000000e+00 2.5400262e-23 2.9132338e-22 3.3416888e-26], sum to 1.0000
[2019-03-24 00:11:15,405] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0791
[2019-03-24 00:11:15,410] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2576878.867870937 W.
[2019-03-24 00:11:15,414] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.8, 77.5, 1.0, 2.0, 0.8789831078154253, 1.0, 2.0, 0.7528562158841475, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2576878.867870937, 2576878.867870936, 480798.7048832946], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4897800.0000, 
sim time next is 4898400.0000, 
raw observation next is [31.06666666666667, 73.66666666666667, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 8.692515864010659, 6.9112, 121.9187951286826, 3240510.362550596, 2328371.650238687, 443050.2319955258], 
processed observation next is [1.0, 0.6956521739130435, 0.7061728395061729, 0.7366666666666667, 1.0, 1.0, 1.0238095238095237, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.25, 0.17813158640106588, 0.0, 0.8094140130434493, 1.1573251294823557, 0.831561303656674, 0.8520196769144728], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3748872], dtype=float32), -0.33343822]. 
=============================================
[2019-03-24 00:11:19,476] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.3009557e-16 1.0000000e+00 1.0524331e-24 8.3208360e-23 6.6654370e-28], sum to 1.0000
[2019-03-24 00:11:19,482] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1781
[2019-03-24 00:11:19,486] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.8, 84.0, 1.0, 2.0, 0.6411756970243518, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 730726.9564584243, 730726.9564584239, 165308.7693553006], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4987200.0000, 
sim time next is 4987800.0000, 
raw observation next is [26.85, 84.0, 1.0, 2.0, 0.635591790152156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 724360.1537901179, 724360.1537901179, 164311.6950573481], 
processed observation next is [1.0, 0.7391304347826086, 0.55, 0.84, 1.0, 1.0, 0.5661807025620905, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2587000549250421, 0.2587000549250421, 0.3159840289564386], 
reward next is 0.6840, 
noisyNet noise sample is [array([0.32658422], dtype=float32), -1.0345708]. 
=============================================
[2019-03-24 00:11:21,342] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.1420976e-18 1.0000000e+00 7.3444622e-29 2.9656105e-28 2.4952052e-31], sum to 1.0000
[2019-03-24 00:11:21,349] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2557
[2019-03-24 00:11:21,354] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 100.0, 1.0, 2.0, 0.5777342261666353, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 670528.9499301063, 670528.9499301063, 154868.8205309012], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5011800.0000, 
sim time next is 5012400.0000, 
raw observation next is [23.0, 100.0, 1.0, 2.0, 0.578488704346654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 671384.0336533926, 671384.0336533926, 154995.6165582723], 
processed observation next is [0.0, 0.0, 0.4074074074074074, 1.0, 1.0, 1.0, 0.4982008385079214, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2397800120190688, 0.2397800120190688, 0.2980684933812929], 
reward next is 0.7019, 
noisyNet noise sample is [array([-0.8901041], dtype=float32), 1.0691335]. 
=============================================
[2019-03-24 00:11:23,525] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6041931e-17 1.0000000e+00 1.0362252e-28 7.4188966e-26 9.6084404e-30], sum to 1.0000
[2019-03-24 00:11:23,534] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2456
[2019-03-24 00:11:23,546] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.5371888271469287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 632838.4490636433, 632838.4490636433, 148551.9812808732], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5032800.0000, 
sim time next is 5033400.0000, 
raw observation next is [23.16666666666667, 94.00000000000001, 1.0, 2.0, 0.5424196175897927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 637582.8454560855, 637582.8454560855, 149348.8565323888], 
processed observation next is [0.0, 0.2608695652173913, 0.4135802469135804, 0.9400000000000002, 1.0, 1.0, 0.455261449511658, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2277081590914591, 0.2277081590914591, 0.2872093394853631], 
reward next is 0.7128, 
noisyNet noise sample is [array([0.4661088], dtype=float32), -0.10559687]. 
=============================================
[2019-03-24 00:11:27,630] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.3155377e-17 1.0000000e+00 5.1599157e-27 7.8773616e-27 1.9889586e-29], sum to 1.0000
[2019-03-24 00:11:27,642] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0427
[2019-03-24 00:11:27,648] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.13333333333333, 95.33333333333334, 1.0, 2.0, 0.7367783672500761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 839741.8743177919, 839741.8743177919, 183226.9877760185], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5125200.0000, 
sim time next is 5125800.0000, 
raw observation next is [26.41666666666666, 94.16666666666666, 1.0, 2.0, 0.7470121768882841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 851412.3198257467, 851412.3198257467, 185239.0775706492], 
processed observation next is [0.0, 0.30434782608695654, 0.5339506172839504, 0.9416666666666665, 1.0, 1.0, 0.6988240201051001, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.30407582850919523, 0.30407582850919523, 0.35622899532817154], 
reward next is 0.6438, 
noisyNet noise sample is [array([-0.10694199], dtype=float32), -0.3491021]. 
=============================================
[2019-03-24 00:11:29,617] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.3949480e-19 1.0000000e+00 2.2906411e-28 7.7718154e-28 1.5519175e-30], sum to 1.0000
[2019-03-24 00:11:29,625] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5589
[2019-03-24 00:11:29,633] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333334, 87.33333333333334, 1.0, 2.0, 0.6467019701916081, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 738673.6612897813, 738673.6612897813, 166380.0732500962], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5178000.0000, 
sim time next is 5178600.0000, 
raw observation next is [25.2, 87.5, 1.0, 2.0, 0.6412505915160818, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 734230.792993664, 734230.792993664, 165489.4683118558], 
processed observation next is [0.0, 0.9565217391304348, 0.4888888888888889, 0.875, 1.0, 1.0, 0.5729173708524783, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2622252832120229, 0.2622252832120229, 0.3182489775227996], 
reward next is 0.6818, 
noisyNet noise sample is [array([-1.1080486], dtype=float32), -0.3748791]. 
=============================================
[2019-03-24 00:11:30,886] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.0305530e-17 1.0000000e+00 7.5877067e-26 9.9861495e-26 1.0850887e-29], sum to 1.0000
[2019-03-24 00:11:30,894] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4196
[2019-03-24 00:11:30,898] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.6748494630513809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 769123.0988516951, 769123.0988516951, 171435.6612174352], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5187000.0000, 
sim time next is 5187600.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.6746178602351648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 768859.0097118813, 768859.0097118813, 171392.8369413446], 
processed observation next is [1.0, 0.043478260869565216, 0.48148148148148145, 0.94, 1.0, 1.0, 0.6126403098037676, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27459250346852904, 0.27459250346852904, 0.32960160950258577], 
reward next is 0.6704, 
noisyNet noise sample is [array([1.5684917], dtype=float32), -0.49003658]. 
=============================================
[2019-03-24 00:11:52,561] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.8236963e-17 1.0000000e+00 2.8990376e-26 3.0278743e-22 8.8260266e-28], sum to 1.0000
[2019-03-24 00:11:52,567] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6176
[2019-03-24 00:11:52,573] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1434784.69650295 W.
[2019-03-24 00:11:52,581] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.55, 80.0, 1.0, 2.0, 0.6291863153986742, 1.0, 2.0, 0.6291863153986742, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1434784.69650295, 1434784.696502951, 278226.0582251372], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5567400.0000, 
sim time next is 5568000.0000, 
raw observation next is [26.63333333333333, 79.66666666666667, 1.0, 2.0, 0.4035384769522683, 1.0, 2.0, 0.4035384769522683, 1.0, 1.0, 0.6424463976386916, 6.911199999999999, 6.9112, 121.94756008, 1380283.096591783, 1380283.096591784, 298635.6526362668], 
processed observation next is [1.0, 0.43478260869565216, 0.5419753086419752, 0.7966666666666667, 1.0, 1.0, 0.2899267582765099, 1.0, 1.0, 0.2899267582765099, 1.0, 0.5, 0.5530579970483644, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.49295824878277966, 0.49295824878278, 0.5742993319928207], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.20657614], dtype=float32), -1.4540806]. 
=============================================
[2019-03-24 00:11:52,602] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[57.32439]
 [57.32439]
 [57.32439]
 [57.32439]
 [57.32439]], R is [[56.75114822]
 [56.64858627]
 [56.08209991]
 [55.52127838]
 [54.96606445]].
[2019-03-24 00:11:53,648] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.0073077e-19 1.0000000e+00 3.6501156e-28 3.1924802e-28 3.9654836e-31], sum to 1.0000
[2019-03-24 00:11:53,655] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0053
[2019-03-24 00:11:53,664] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2060471.313989197 W.
[2019-03-24 00:11:53,670] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.75, 82.0, 1.0, 2.0, 0.602157413803799, 1.0, 2.0, 0.602157413803799, 1.0, 2.0, 0.9586542136735074, 6.9112, 6.9112, 121.94756008, 2060471.313989197, 2060471.313989197, 396552.3184782906], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5585400.0000, 
sim time next is 5586000.0000, 
raw observation next is [27.43333333333334, 83.0, 1.0, 2.0, 0.8968005154618044, 1.0, 2.0, 0.8968005154618044, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 2045773.946298403, 2045773.946298402, 385377.8965077722], 
processed observation next is [1.0, 0.6521739130434783, 0.5716049382716052, 0.83, 1.0, 1.0, 0.8771434707878624, 1.0, 1.0, 0.8771434707878624, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7306335522494296, 0.7306335522494293, 0.7411113394380234], 
reward next is 0.2589, 
noisyNet noise sample is [array([-0.9730185], dtype=float32), 0.75956887]. 
=============================================
[2019-03-24 00:11:53,694] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[65.976]
 [65.976]
 [65.976]
 [65.976]
 [65.976]], R is [[65.57512665]
 [65.1567688 ]
 [64.72270966]
 [64.28921509]
 [63.79072189]].
[2019-03-24 00:11:56,825] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.6846186e-20 1.0000000e+00 6.3137844e-30 1.6315673e-28 3.5523710e-32], sum to 1.0000
[2019-03-24 00:11:56,833] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9741
[2019-03-24 00:11:56,843] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.4, 67.0, 1.0, 2.0, 0.7185985838306056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 819010.4268365062, 819010.4268365062, 179697.6033102869], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5673600.0000, 
sim time next is 5674200.0000, 
raw observation next is [30.48333333333333, 66.66666666666667, 1.0, 2.0, 0.7096859762006885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 808847.0751153987, 808847.0751153987, 177988.8774762318], 
processed observation next is [0.0, 0.6956521739130435, 0.6845679012345678, 0.6666666666666667, 1.0, 1.0, 0.6543880669055816, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2888739553983567, 0.2888739553983567, 0.3422863028389073], 
reward next is 0.6577, 
noisyNet noise sample is [array([-1.076137], dtype=float32), -1.3129622]. 
=============================================
[2019-03-24 00:12:00,371] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.775552e-16 1.000000e+00 3.630949e-29 3.026390e-26 2.203540e-31], sum to 1.0000
[2019-03-24 00:12:00,384] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6572
[2019-03-24 00:12:00,395] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.86666666666667, 71.66666666666667, 1.0, 2.0, 0.4717541661659754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 568742.5230502022, 568742.5230502022, 138740.6800086603], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5740800.0000, 
sim time next is 5741400.0000, 
raw observation next is [25.08333333333334, 70.83333333333333, 1.0, 2.0, 0.4755360917848987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 572522.4175965707, 572522.4175965707, 139292.987909511], 
processed observation next is [0.0, 0.43478260869565216, 0.4845679012345681, 0.7083333333333333, 1.0, 1.0, 0.3756382045058318, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20447229199877523, 0.20447229199877523, 0.26787113059521345], 
reward next is 0.7321, 
noisyNet noise sample is [array([0.5082887], dtype=float32), 0.9406457]. 
=============================================
[2019-03-24 00:12:01,606] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-24 00:12:01,607] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:12:01,608] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:12:01,610] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:12:01,612] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:12:01,611] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:12:01,613] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:12:01,616] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:12:01,614] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:12:01,617] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:12:01,621] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:12:01,637] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run75
[2019-03-24 00:12:01,664] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run75
[2019-03-24 00:12:01,688] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run75
[2019-03-24 00:12:01,709] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run75
[2019-03-24 00:12:01,732] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run75
[2019-03-24 00:12:28,084] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.015994433]
[2019-03-24 00:12:28,084] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.25, 43.0, 1.0, 2.0, 0.4890352452792303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 583582.3326686894, 583582.3326686899, 141194.1054226471]
[2019-03-24 00:12:28,085] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:12:28,088] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.9105056e-18 1.0000000e+00 2.4113082e-29 5.0495279e-27 1.9773063e-31], sampled 0.615935898478678
[2019-03-24 00:12:42,414] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.015994433]
[2019-03-24 00:12:42,415] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.0, 62.0, 1.0, 2.0, 0.5290994361691453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 622536.5957764031, 622536.5957764031, 147207.5850624897]
[2019-03-24 00:12:42,417] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:12:42,421] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.9105056e-18 1.0000000e+00 2.4113082e-29 5.0495279e-27 1.9773063e-31], sampled 0.15391163453567525
[2019-03-24 00:12:58,815] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.015994433]
[2019-03-24 00:12:58,817] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.30714984666667, 91.63661362666666, 1.0, 2.0, 0.5502313156286545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 646751.1197326162, 646751.1197326162, 150632.4613701761]
[2019-03-24 00:12:58,817] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:12:58,820] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.9105056e-18 1.0000000e+00 2.4113082e-29 5.0495279e-27 1.9773063e-31], sampled 0.27497267425279015
[2019-03-24 00:13:25,322] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.015994433]
[2019-03-24 00:13:25,323] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.64594862666667, 55.89808237333334, 1.0, 2.0, 0.6247139314036723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 711957.3086512175, 711957.3086512175, 162383.2546116978]
[2019-03-24 00:13:25,325] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:13:25,326] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.9105056e-18 1.0000000e+00 2.4113082e-29 5.0495279e-27 1.9773063e-31], sampled 0.4571508326281859
[2019-03-24 00:13:46,694] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 00:13:47,218] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 00:13:47,287] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 00:13:47,382] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 00:13:47,493] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 00:13:48,510] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1850000, evaluation results [1850000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 00:13:53,499] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.4357579e-18 1.0000000e+00 1.9429139e-29 3.1981237e-28 2.5299589e-31], sum to 1.0000
[2019-03-24 00:13:53,504] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3112
[2019-03-24 00:13:53,511] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.28333333333333, 67.16666666666667, 1.0, 2.0, 0.4231987419491907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 519863.0729555229, 519863.0729555234, 131825.5131220128], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5863800.0000, 
sim time next is 5864400.0000, 
raw observation next is [24.1, 68.0, 1.0, 2.0, 0.422017560661073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 518759.2091526674, 518759.209152667, 131663.7134801377], 
processed observation next is [1.0, 0.9130434782608695, 0.4481481481481482, 0.68, 1.0, 1.0, 0.3119256674536583, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18527114612595263, 0.1852711461259525, 0.2531994490002648], 
reward next is 0.7468, 
noisyNet noise sample is [array([1.4883091], dtype=float32), -1.0159663]. 
=============================================
[2019-03-24 00:13:56,442] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.4593966e-19 1.0000000e+00 3.4329547e-30 3.5903486e-27 2.6794253e-32], sum to 1.0000
[2019-03-24 00:13:56,450] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3276
[2019-03-24 00:13:56,462] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1401236.276570723 W.
[2019-03-24 00:13:56,466] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.1, 54.5, 1.0, 2.0, 0.5843043770939524, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9428674090184606, 6.9112, 6.9112, 121.9260426156442, 1401236.276570723, 1401236.276570723, 286006.9079776427], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5916600.0000, 
sim time next is 5917200.0000, 
raw observation next is [27.26666666666667, 53.66666666666667, 1.0, 2.0, 0.5854313362217053, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9446729696758764, 6.911199999999999, 6.9112, 121.9260426156618, 1403906.086524205, 1403906.086524206, 286437.8045793195], 
processed observation next is [1.0, 0.4782608695652174, 0.5654320987654322, 0.5366666666666667, 1.0, 1.0, 0.506465876454411, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9308412120948456, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5013950309015018, 0.5013950309015022, 0.5508419318833068], 
reward next is 0.4492, 
noisyNet noise sample is [array([-0.40382832], dtype=float32), 0.6567473]. 
=============================================
[2019-03-24 00:13:57,765] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.7737710e-17 1.0000000e+00 3.2343044e-28 1.0500546e-25 6.1861878e-30], sum to 1.0000
[2019-03-24 00:13:57,776] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7654
[2019-03-24 00:13:57,781] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.26666666666667, 53.66666666666667, 1.0, 2.0, 0.4502283911245488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 541382.4215708927, 541382.4215708927, 135448.7086869905], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5938800.0000, 
sim time next is 5939400.0000, 
raw observation next is [28.13333333333333, 54.33333333333334, 1.0, 2.0, 0.4588929920233066, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 551760.5064526052, 551760.5064526048, 136742.4866515697], 
processed observation next is [1.0, 0.7391304347826086, 0.5975308641975308, 0.5433333333333334, 1.0, 1.0, 0.3558249905039364, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1970573237330733, 0.19705732373307314, 0.2629663204837879], 
reward next is 0.7370, 
noisyNet noise sample is [array([0.34660283], dtype=float32), 0.5627003]. 
=============================================
[2019-03-24 00:13:59,015] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.6801149e-18 1.0000000e+00 1.2321167e-28 6.1704238e-29 9.4144975e-33], sum to 1.0000
[2019-03-24 00:13:59,023] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8872
[2019-03-24 00:13:59,027] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666666, 61.66666666666667, 1.0, 2.0, 0.4812901867726291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 579001.4724363487, 579001.4724363487, 140162.2800339864], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5946000.0000, 
sim time next is 5946600.0000, 
raw observation next is [26.53333333333333, 62.33333333333333, 1.0, 2.0, 0.4828152826537106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 580937.862329826, 580937.8623298255, 140401.1376925959], 
processed observation next is [1.0, 0.8260869565217391, 0.5382716049382715, 0.6233333333333333, 1.0, 1.0, 0.3843039079210841, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20747780797493787, 0.2074778079749377, 0.2700021878703767], 
reward next is 0.7300, 
noisyNet noise sample is [array([-1.4428225], dtype=float32), 1.2968166]. 
=============================================
[2019-03-24 00:13:59,056] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.5186234e-19 1.0000000e+00 4.8086273e-30 5.1276354e-28 2.7732129e-33], sum to 1.0000
[2019-03-24 00:13:59,063] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8986
[2019-03-24 00:13:59,071] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.6, 84.0, 1.0, 2.0, 0.4606573856079867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 559119.1993514259, 559119.1993514259, 137178.2494934613], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5961600.0000, 
sim time next is 5962200.0000, 
raw observation next is [22.6, 83.5, 1.0, 2.0, 0.4575130799846978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 555938.3395941849, 555938.3395941849, 136724.045576379], 
processed observation next is [1.0, 0.0, 0.39259259259259266, 0.835, 1.0, 1.0, 0.3541822380770212, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19854940699792317, 0.19854940699792317, 0.2629308568776519], 
reward next is 0.7371, 
noisyNet noise sample is [array([-0.25591484], dtype=float32), 1.0145154]. 
=============================================
[2019-03-24 00:13:59,277] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.0505793e-19 1.0000000e+00 4.4823683e-32 3.8169488e-29 4.5931785e-34], sum to 1.0000
[2019-03-24 00:13:59,287] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1696
[2019-03-24 00:13:59,297] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.63333333333333, 85.0, 1.0, 2.0, 0.4680733910078664, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 566588.464542882, 566588.4645428816, 138254.3504390669], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5960400.0000, 
sim time next is 5961000.0000, 
raw observation next is [22.61666666666667, 84.5, 1.0, 2.0, 0.4644893139551739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 563012.2965859825, 563012.2965859821, 137734.3198713312], 
processed observation next is [1.0, 1.0, 0.39320987654321005, 0.845, 1.0, 1.0, 0.3624872785180641, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20107582020927947, 0.2010758202092793, 0.2648736920602523], 
reward next is 0.7351, 
noisyNet noise sample is [array([1.522395], dtype=float32), 0.82745504]. 
=============================================
[2019-03-24 00:13:59,314] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[72.850845]
 [72.850845]
 [72.850845]
 [72.850845]
 [72.850845]], R is [[72.85746002]
 [72.86300659]
 [72.86759186]
 [72.87111664]
 [72.87345123]].
[2019-03-24 00:14:08,066] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.7864014e-17 1.0000000e+00 1.3205737e-27 9.0104825e-27 4.0790233e-29], sum to 1.0000
[2019-03-24 00:14:08,073] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6441
[2019-03-24 00:14:08,077] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.15, 67.0, 1.0, 2.0, 0.5475112469230538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 642874.459054597, 642874.459054597, 150155.9837151123], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6121800.0000, 
sim time next is 6122400.0000, 
raw observation next is [27.06666666666666, 67.33333333333333, 1.0, 2.0, 0.5474847406658112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 643137.6318613628, 643137.6318613628, 150163.9271989192], 
processed observation next is [1.0, 0.8695652173913043, 0.5580246913580245, 0.6733333333333333, 1.0, 1.0, 0.46129135793548953, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22969201137905815, 0.22969201137905815, 0.2887767830748446], 
reward next is 0.7112, 
noisyNet noise sample is [array([0.88491035], dtype=float32), -0.6754546]. 
=============================================
[2019-03-24 00:14:09,990] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.7239961e-20 1.0000000e+00 7.4968572e-31 4.0051382e-28 7.4103002e-33], sum to 1.0000
[2019-03-24 00:14:09,996] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1008
[2019-03-24 00:14:10,000] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.5029722230282271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 599971.1349403046, 599971.134940305, 143365.5439581852], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6156000.0000, 
sim time next is 6156600.0000, 
raw observation next is [23.1, 88.66666666666667, 1.0, 2.0, 0.5549871217794411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 661297.9489648854, 661297.9489648854, 151776.353902127], 
processed observation next is [1.0, 0.2608695652173913, 0.41111111111111115, 0.8866666666666667, 1.0, 1.0, 0.47022276402314417, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2361778389160305, 0.2361778389160305, 0.2918776036579366], 
reward next is 0.7081, 
noisyNet noise sample is [array([0.11171738], dtype=float32), -0.33257303]. 
=============================================
[2019-03-24 00:14:13,484] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5881603e-18 1.0000000e+00 2.6069561e-30 1.1334236e-25 7.6272092e-32], sum to 1.0000
[2019-03-24 00:14:13,492] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9290
[2019-03-24 00:14:13,500] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.7, 79.5, 1.0, 2.0, 0.4829971590577603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 581853.8291645476, 581853.8291645471, 140452.8016966138], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6229800.0000, 
sim time next is 6230400.0000, 
raw observation next is [23.6, 80.0, 1.0, 2.0, 0.4819038910454678, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 580811.0063003647, 580811.0063003651, 140293.1122472875], 
processed observation next is [0.0, 0.08695652173913043, 0.4296296296296297, 0.8, 1.0, 1.0, 0.3832189179112712, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20743250225013027, 0.20743250225013038, 0.26979444662939905], 
reward next is 0.7302, 
noisyNet noise sample is [array([-0.40100956], dtype=float32), 0.35790452]. 
=============================================
[2019-03-24 00:14:15,741] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.4386815e-19 1.0000000e+00 5.6591217e-30 8.0504864e-28 3.4151238e-31], sum to 1.0000
[2019-03-24 00:14:15,751] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2774
[2019-03-24 00:14:15,755] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.85, 70.33333333333334, 1.0, 2.0, 0.6167696259737453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 706642.7882387614, 706642.7882387614, 161171.5111000415], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6264600.0000, 
sim time next is 6265200.0000, 
raw observation next is [28.0, 69.66666666666667, 1.0, 2.0, 0.6206446055521606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 710569.650567974, 710569.650567974, 161826.4541939824], 
processed observation next is [0.0, 0.5217391304347826, 0.5925925925925926, 0.6966666666666668, 1.0, 1.0, 0.5483864351811436, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25377487520284786, 0.25377487520284786, 0.31120471960381235], 
reward next is 0.6888, 
noisyNet noise sample is [array([-0.30801335], dtype=float32), -0.65153384]. 
=============================================
[2019-03-24 00:14:16,287] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.9974540e-19 1.0000000e+00 3.0671081e-30 2.3131314e-26 2.0154660e-32], sum to 1.0000
[2019-03-24 00:14:16,295] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3488
[2019-03-24 00:14:16,299] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.3, 82.0, 1.0, 2.0, 0.5234428896076553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 620369.8874552537, 620369.8874552537, 146476.4672036263], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6249600.0000, 
sim time next is 6250200.0000, 
raw observation next is [24.45, 81.66666666666667, 1.0, 2.0, 0.52710024936154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 623702.0935820583, 623702.0935820579, 147026.8696770885], 
processed observation next is [0.0, 0.34782608695652173, 0.4611111111111111, 0.8166666666666668, 1.0, 1.0, 0.43702410638278566, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22275074770787798, 0.2227507477078778, 0.28274398014824714], 
reward next is 0.7173, 
noisyNet noise sample is [array([-1.2614592], dtype=float32), 0.1829552]. 
=============================================
[2019-03-24 00:14:19,446] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.1836430e-18 1.0000000e+00 9.9547078e-31 1.6159914e-25 2.8330398e-32], sum to 1.0000
[2019-03-24 00:14:19,454] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3274
[2019-03-24 00:14:19,458] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.58333333333334, 68.5, 1.0, 2.0, 0.6874704824929522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 783514.5733882051, 783514.5733882051, 173786.5186927887], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6347400.0000, 
sim time next is 6348000.0000, 
raw observation next is [29.66666666666667, 68.0, 1.0, 2.0, 0.6824928855910766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 777838.6954080922, 777838.6954080922, 172857.26718646], 
processed observation next is [0.0, 0.4782608695652174, 0.6543209876543211, 0.68, 1.0, 1.0, 0.6220153399893769, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2777995340743187, 0.2777995340743187, 0.33241782151242305], 
reward next is 0.6676, 
noisyNet noise sample is [array([0.10459207], dtype=float32), 0.570566]. 
=============================================
[2019-03-24 00:14:19,474] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[71.11092]
 [71.11092]
 [71.11092]
 [71.11092]
 [71.11092]], R is [[71.06739807]
 [71.02252197]
 [70.97390747]
 [70.92692566]
 [70.88182831]].
[2019-03-24 00:14:21,660] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.1140370e-18 1.0000000e+00 1.2870966e-28 1.1046404e-26 6.5775520e-31], sum to 1.0000
[2019-03-24 00:14:21,669] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8820
[2019-03-24 00:14:21,674] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.3, 79.5, 1.0, 2.0, 0.689184536121613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 785469.0923787908, 785469.0923787908, 174105.4848360732], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6391800.0000, 
sim time next is 6392400.0000, 
raw observation next is [27.2, 80.0, 1.0, 2.0, 0.688501652681309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 784690.4063132785, 784690.406313278, 173977.442048638], 
processed observation next is [0.0, 1.0, 0.5629629629629629, 0.8, 1.0, 1.0, 0.6291686341444155, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.28024657368331374, 0.28024657368331357, 0.3345720039396885], 
reward next is 0.6654, 
noisyNet noise sample is [array([1.4136648], dtype=float32), 0.92408174]. 
=============================================
[2019-03-24 00:14:28,079] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.6707020e-16 1.0000000e+00 5.8633955e-25 2.1653186e-23 3.5651664e-28], sum to 1.0000
[2019-03-24 00:14:28,087] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1229
[2019-03-24 00:14:28,093] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.3, 86.66666666666667, 1.0, 2.0, 0.8055780646491063, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 918203.1839134406, 918203.1839134406, 197092.4732846916], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6500400.0000, 
sim time next is 6501000.0000, 
raw observation next is [26.3, 86.83333333333333, 1.0, 2.0, 0.7983526763896818, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 909962.7494446449, 909962.7494446449, 195597.3045824893], 
processed observation next is [1.0, 0.21739130434782608, 0.5296296296296297, 0.8683333333333333, 1.0, 1.0, 0.7599436623686687, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3249866962302303, 0.3249866962302303, 0.3761486626586333], 
reward next is 0.6239, 
noisyNet noise sample is [array([0.43827766], dtype=float32), 1.6242592]. 
=============================================
[2019-03-24 00:14:28,107] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[57.64994]
 [57.64994]
 [57.64994]
 [57.64994]
 [57.64994]], R is [[57.69729233]
 [57.74129486]
 [57.77670288]
 [57.81676102]
 [57.85016632]].
[2019-03-24 00:14:37,296] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.8483540e-21 1.0000000e+00 5.4644714e-33 9.0614838e-30 2.0186494e-34], sum to 1.0000
[2019-03-24 00:14:37,303] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7323
[2019-03-24 00:14:37,306] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.16666666666667, 42.0, 1.0, 2.0, 0.2834216597875697, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 365427.2031072191, 365427.2031072191, 113539.3881441376], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6654000.0000, 
sim time next is 6654600.0000, 
raw observation next is [24.05, 42.5, 1.0, 2.0, 0.2823445318158689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 364063.6566930427, 364063.6566930427, 113409.3463181063], 
processed observation next is [1.0, 0.0, 0.4462962962962963, 0.425, 1.0, 1.0, 0.14564825216174868, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13002273453322954, 0.13002273453322954, 0.21809489676558905], 
reward next is 0.7819, 
noisyNet noise sample is [array([-0.39743665], dtype=float32), 0.4307236]. 
=============================================
[2019-03-24 00:14:38,322] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-24 00:14:38,323] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:14:38,324] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:14:38,324] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:14:38,325] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:14:38,327] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:14:38,327] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:14:38,328] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:14:38,324] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:14:38,328] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:14:38,330] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:14:38,349] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run76
[2019-03-24 00:14:38,374] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run76
[2019-03-24 00:14:38,397] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run76
[2019-03-24 00:14:38,398] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run76
[2019-03-24 00:14:38,398] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run76
[2019-03-24 00:14:47,380] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0018436773]
[2019-03-24 00:14:47,380] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.0, 35.0, 1.0, 2.0, 0.4502420202506385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 560785.2446366333, 560785.2446366329, 135983.8079204814]
[2019-03-24 00:14:47,381] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:14:47,384] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.2423020e-19 1.0000000e+00 7.0297925e-30 1.6670961e-27 5.6189764e-32], sampled 0.9406854986108563
[2019-03-24 00:15:00,382] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0018436773]
[2019-03-24 00:15:00,383] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.5, 97.0, 1.0, 2.0, 0.5510850228074531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 673975.3413272387, 673975.3413272387, 151704.1234067603]
[2019-03-24 00:15:00,384] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:15:00,387] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.2423020e-19 1.0000000e+00 7.0297925e-30 1.6670961e-27 5.6189764e-32], sampled 0.9289722200600107
[2019-03-24 00:15:01,526] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0018436773]
[2019-03-24 00:15:01,527] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [19.0, 100.0, 1.0, 2.0, 0.379043263459772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 472073.3415309682, 472073.3415309682, 125757.3060209133]
[2019-03-24 00:15:01,528] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:15:01,530] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.2423020e-19 1.0000000e+00 7.0297925e-30 1.6670961e-27 5.6189764e-32], sampled 0.4966193633386875
[2019-03-24 00:15:19,788] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0018436773]
[2019-03-24 00:15:19,789] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.69657626, 91.38109576, 1.0, 2.0, 0.543591823264942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 637637.2823027625, 637637.2823027625, 149486.0472810443]
[2019-03-24 00:15:19,790] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:15:19,794] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.2423020e-19 1.0000000e+00 7.0297925e-30 1.6670961e-27 5.6189764e-32], sampled 0.7390790641197053
[2019-03-24 00:15:25,283] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0018436773]
[2019-03-24 00:15:25,284] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [35.0, 60.0, 1.0, 2.0, 0.9590590303179474, 1.0, 2.0, 0.7928941771354084, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 126.5187974635173, 2713980.209956166, 2713980.209956166, 507585.8481893402]
[2019-03-24 00:15:25,285] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:15:25,290] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.2423020e-19 1.0000000e+00 7.0297925e-30 1.6670961e-27 5.6189764e-32], sampled 0.22037593697820912
[2019-03-24 00:15:25,291] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 0, 1] for the demand 2713980.209956166 W.
[2019-03-24 00:16:15,267] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0018436773]
[2019-03-24 00:16:15,269] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.58944296, 94.28118487666667, 1.0, 2.0, 0.4742195398713804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 583223.023313834, 583223.023313834, 139459.670676756]
[2019-03-24 00:16:15,270] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:16:15,273] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.2423020e-19 1.0000000e+00 7.0297925e-30 1.6670961e-27 5.6189764e-32], sampled 0.06374416596143484
[2019-03-24 00:16:23,755] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 00:16:23,971] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 00:16:24,005] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 00:16:24,094] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 00:16:24,209] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 00:16:25,228] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1875000, evaluation results [1875000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 00:16:26,090] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.3149350e-20 1.0000000e+00 3.4857886e-32 4.7630435e-29 1.1478249e-34], sum to 1.0000
[2019-03-24 00:16:26,096] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2428
[2019-03-24 00:16:26,102] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.86666666666667, 50.0, 1.0, 2.0, 0.3311351454490649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 418882.9389094019, 418882.9389094014, 119484.322363319], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6727200.0000, 
sim time next is 6727800.0000, 
raw observation next is [24.58333333333333, 51.5, 1.0, 2.0, 0.3323099419423593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 420316.7687968348, 420316.7687968348, 119635.4956889874], 
processed observation next is [1.0, 0.8695652173913043, 0.46604938271604923, 0.515, 1.0, 1.0, 0.20513088326471346, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1501131317131553, 0.1501131317131553, 0.2300682609403604], 
reward next is 0.7699, 
noisyNet noise sample is [array([-2.1423395], dtype=float32), -1.3182068]. 
=============================================
[2019-03-24 00:16:26,936] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.0771483e-21 1.0000000e+00 1.5687709e-34 4.3150465e-31 5.4467522e-36], sum to 1.0000
[2019-03-24 00:16:26,946] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9961
[2019-03-24 00:16:26,952] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.03333333333333, 55.33333333333334, 1.0, 2.0, 0.4394320728422613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 535239.8508782705, 535239.8508782705, 134071.2876402762], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6862800.0000, 
sim time next is 6863400.0000, 
raw observation next is [27.3, 54.0, 1.0, 2.0, 0.4398108389590517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 535687.1572695966, 535687.1572695961, 134126.6789417417], 
processed observation next is [0.0, 0.43478260869565216, 0.5666666666666667, 0.54, 1.0, 1.0, 0.3331081416179187, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1913168418819988, 0.19131684188199863, 0.25793592104181096], 
reward next is 0.7421, 
noisyNet noise sample is [array([-0.3452771], dtype=float32), 0.39976773]. 
=============================================
[2019-03-24 00:16:36,732] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.8071631e-19 1.0000000e+00 6.1549016e-31 5.7871229e-28 1.9164627e-32], sum to 1.0000
[2019-03-24 00:16:36,744] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7766
[2019-03-24 00:16:36,753] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.65, 64.5, 1.0, 2.0, 0.4233873475125478, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 520648.1975017693, 520648.1975017689, 131867.1965551804], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6904200.0000, 
sim time next is 6904800.0000, 
raw observation next is [24.5, 65.0, 1.0, 2.0, 0.4219579989451635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 519351.7907946567, 519351.7907946563, 131672.2314362967], 
processed observation next is [0.0, 0.9565217391304348, 0.46296296296296297, 0.65, 1.0, 1.0, 0.31185476064900414, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1854827824266631, 0.18548278242666297, 0.2532158296851859], 
reward next is 0.7468, 
noisyNet noise sample is [array([0.6812649], dtype=float32), -0.19929567]. 
=============================================
[2019-03-24 00:16:51,771] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2685505e-19 1.0000000e+00 3.3399091e-31 3.5175339e-28 1.9786086e-34], sum to 1.0000
[2019-03-24 00:16:51,773] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.8108537e-20 1.0000000e+00 3.6423646e-30 5.3992537e-29 1.7088194e-34], sum to 1.0000
[2019-03-24 00:16:51,777] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4493
[2019-03-24 00:16:51,779] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1985
[2019-03-24 00:16:51,782] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.7, 93.66666666666667, 1.0, 2.0, 0.3754489556995086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 467446.2398679872, 467446.2398679868, 125261.8691501793], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7183200.0000, 
sim time next is 7183800.0000, 
raw observation next is [19.7, 93.5, 1.0, 2.0, 0.3741352488826688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 465938.7995226177, 465938.7995226177, 125085.0817495343], 
processed observation next is [1.0, 0.13043478260869565, 0.28518518518518515, 0.935, 1.0, 1.0, 0.25492291533651046, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16640671411522062, 0.16640671411522062, 0.2405482341337198], 
reward next is 0.7595, 
noisyNet noise sample is [array([-0.9385988], dtype=float32), 0.84717697]. 
=============================================
[2019-03-24 00:16:51,783] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 60.66666666666667, 1.0, 2.0, 0.7793286017603701, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 974234.697860783, 974234.697860783, 195042.0005182442], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7136400.0000, 
sim time next is 7137000.0000, 
raw observation next is [23.85, 61.0, 1.0, 2.0, 0.7752830534295493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 969131.4845427837, 969131.4845427832, 194198.5020030016], 
processed observation next is [1.0, 0.6086956521739131, 0.43888888888888894, 0.61, 1.0, 1.0, 0.7324798255113681, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.34611838733670847, 0.3461183873367083, 0.37345865769808], 
reward next is 0.6265, 
noisyNet noise sample is [array([-0.2247502], dtype=float32), -0.037651755]. 
=============================================
[2019-03-24 00:16:51,812] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[76.91256]
 [76.91256]
 [76.91256]
 [76.91256]
 [76.91256]], R is [[76.76998138]
 [76.62719727]
 [76.47826385]
 [76.33100891]
 [76.19057465]].
[2019-03-24 00:16:51,845] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.9004074e-20 1.0000000e+00 1.2167950e-30 3.2742165e-27 1.0617149e-33], sum to 1.0000
[2019-03-24 00:16:51,861] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0761
[2019-03-24 00:16:51,870] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.7, 93.16666666666666, 1.0, 2.0, 0.3728903853533176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 464632.555560694, 464632.5555606935, 124920.2368460677], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7185000.0000, 
sim time next is 7185600.0000, 
raw observation next is [19.7, 93.0, 1.0, 2.0, 0.3716086723071907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 463156.6129633108, 463156.6129633108, 124748.1803286566], 
processed observation next is [1.0, 0.17391304347826086, 0.28518518518518515, 0.93, 1.0, 1.0, 0.2519150860799889, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16541307605832528, 0.16541307605832528, 0.23990034678587807], 
reward next is 0.7601, 
noisyNet noise sample is [array([-0.24064562], dtype=float32), 0.9165274]. 
=============================================
[2019-03-24 00:16:52,468] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.3760206e-20 1.0000000e+00 6.9607855e-30 7.8503038e-27 1.1988200e-33], sum to 1.0000
[2019-03-24 00:16:52,477] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7915
[2019-03-24 00:16:52,483] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 78.0, 1.0, 2.0, 0.7524859448479796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 930684.1379439892, 930684.1379439892, 189277.8111770307], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7204200.0000, 
sim time next is 7204800.0000, 
raw observation next is [22.33333333333334, 78.0, 1.0, 2.0, 0.7722032393597588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 952772.09762612, 952772.09762612, 193263.1264515275], 
processed observation next is [1.0, 0.391304347826087, 0.38271604938271625, 0.78, 1.0, 1.0, 0.728813380190189, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3402757491521857, 0.3402757491521857, 0.3716598585606298], 
reward next is 0.6283, 
noisyNet noise sample is [array([-2.9323416], dtype=float32), -2.5893335]. 
=============================================
[2019-03-24 00:17:02,001] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.9032535e-19 1.0000000e+00 2.5613161e-30 3.3868853e-28 2.9286050e-33], sum to 1.0000
[2019-03-24 00:17:02,007] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6474
[2019-03-24 00:17:02,011] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.06666666666667, 95.0, 1.0, 2.0, 0.5807459129423262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 727543.1348178821, 727543.1348178821, 157148.8893411237], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7374000.0000, 
sim time next is 7374600.0000, 
raw observation next is [19.1, 95.0, 1.0, 2.0, 0.6568069229579003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 822154.4706793258, 822154.4706793258, 170836.2642611451], 
processed observation next is [1.0, 0.34782608695652173, 0.262962962962963, 0.95, 1.0, 1.0, 0.5914368130451194, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2936265966711878, 0.2936265966711878, 0.328531277425279], 
reward next is 0.6715, 
noisyNet noise sample is [array([1.054143], dtype=float32), 0.83080405]. 
=============================================
[2019-03-24 00:17:04,074] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.2452803e-22 1.0000000e+00 1.0258981e-33 8.2889627e-31 7.8737509e-36], sum to 1.0000
[2019-03-24 00:17:04,090] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5525
[2019-03-24 00:17:04,098] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.3, 90.0, 1.0, 2.0, 0.3840881073214752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 477198.1306143554, 477198.1306143554, 126428.3204310284], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7426800.0000, 
sim time next is 7427400.0000, 
raw observation next is [20.26666666666667, 90.16666666666667, 1.0, 2.0, 0.3834649242957094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 476457.1854599906, 476457.1854599906, 126342.9532770697], 
processed observation next is [1.0, 1.0, 0.3061728395061729, 0.9016666666666667, 1.0, 1.0, 0.26602967178060644, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1701632805214252, 0.1701632805214252, 0.24296721784051864], 
reward next is 0.7570, 
noisyNet noise sample is [array([-0.09384973], dtype=float32), 0.16786121]. 
=============================================
[2019-03-24 00:17:09,159] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.1048426e-19 1.0000000e+00 3.7125038e-30 2.7392490e-28 1.8771820e-31], sum to 1.0000
[2019-03-24 00:17:09,168] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4023
[2019-03-24 00:17:09,173] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.9, 96.0, 1.0, 2.0, 0.4407385888749622, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 536763.7118942149, 536763.7118942144, 134261.845780394], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7524000.0000, 
sim time next is 7524600.0000, 
raw observation next is [20.9, 96.0, 1.0, 2.0, 0.4394773957613979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 535349.2350271017, 535349.2350271012, 134079.5545276153], 
processed observation next is [0.0, 0.08695652173913043, 0.32962962962962955, 0.96, 1.0, 1.0, 0.33271118543023553, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19119615536682205, 0.19119615536682188, 0.257845297168491], 
reward next is 0.7422, 
noisyNet noise sample is [array([1.1955302], dtype=float32), -1.4551965]. 
=============================================
[2019-03-24 00:17:11,017] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.4931197e-20 1.0000000e+00 6.9337240e-31 1.0740822e-26 5.3494068e-32], sum to 1.0000
[2019-03-24 00:17:11,035] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6948
[2019-03-24 00:17:11,040] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.1, 83.0, 1.0, 2.0, 0.51758781431491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 613976.1040458686, 613976.1040458686, 145558.3927005146], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7590600.0000, 
sim time next is 7591200.0000, 
raw observation next is [24.03333333333333, 83.33333333333334, 1.0, 2.0, 0.515677485915133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 611933.3422622832, 611933.3422622832, 145261.8125859998], 
processed observation next is [0.0, 0.8695652173913043, 0.4456790123456789, 0.8333333333333335, 1.0, 1.0, 0.42342557847039636, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2185476222365297, 0.2185476222365297, 0.27934963958846115], 
reward next is 0.7207, 
noisyNet noise sample is [array([-0.37377545], dtype=float32), -1.4926113]. 
=============================================
[2019-03-24 00:17:12,620] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0985474e-18 1.0000000e+00 4.2213963e-31 9.7231621e-27 1.2268479e-31], sum to 1.0000
[2019-03-24 00:17:12,630] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4678
[2019-03-24 00:17:12,634] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.43333333333333, 93.33333333333334, 1.0, 2.0, 0.3195808758382006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 404580.8508700525, 404580.8508700525, 118008.4428024334], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7710000.0000, 
sim time next is 7710600.0000, 
raw observation next is [18.51666666666667, 93.16666666666666, 1.0, 2.0, 0.3247758804541591, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 410851.1282702397, 410851.1282702397, 118667.4958831026], 
processed observation next is [1.0, 0.21739130434782608, 0.24135802469135811, 0.9316666666666665, 1.0, 1.0, 0.19616176244542752, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1467325458107999, 0.1467325458107999, 0.22820672285212038], 
reward next is 0.7718, 
noisyNet noise sample is [array([0.39390224], dtype=float32), 0.07574326]. 
=============================================
[2019-03-24 00:17:13,006] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.3726393e-21 1.0000000e+00 1.9882044e-32 9.9097394e-30 1.6265714e-35], sum to 1.0000
[2019-03-24 00:17:13,014] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6364
[2019-03-24 00:17:13,021] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.26666666666667, 87.66666666666667, 1.0, 2.0, 0.5061438873906381, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 602556.7381091772, 602556.7381091772, 143821.7029485145], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7599000.0000, 
sim time next is 7599600.0000, 
raw observation next is [23.2, 88.0, 1.0, 2.0, 0.5048441690310732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 601256.5090055052, 601256.5090055052, 143625.6206045605], 
processed observation next is [0.0, 1.0, 0.4148148148148148, 0.88, 1.0, 1.0, 0.4105287726560395, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21473446750196615, 0.21473446750196615, 0.27620311654723173], 
reward next is 0.7238, 
noisyNet noise sample is [array([-0.5172047], dtype=float32), -0.607905]. 
=============================================
[2019-03-24 00:17:14,124] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1047966e-18 1.0000000e+00 2.0261216e-30 2.1129289e-27 2.6598607e-33], sum to 1.0000
[2019-03-24 00:17:14,132] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7281
[2019-03-24 00:17:14,140] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 88.5, 1.0, 2.0, 0.5756228112746771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 703884.8272197307, 703884.8272197312, 155858.9875080073], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7633800.0000, 
sim time next is 7634400.0000, 
raw observation next is [21.86666666666667, 87.66666666666666, 1.0, 2.0, 0.659931492006515, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 804839.3817493186, 804839.3817493186, 170891.3799739987], 
processed observation next is [1.0, 0.34782608695652173, 0.36543209876543226, 0.8766666666666666, 1.0, 1.0, 0.5951565381029941, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2874426363390423, 0.2874426363390423, 0.32863726918076674], 
reward next is 0.6714, 
noisyNet noise sample is [array([0.42743093], dtype=float32), 0.93685246]. 
=============================================
[2019-03-24 00:17:15,198] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-24 00:17:15,202] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:17:15,202] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:17:15,203] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:17:15,203] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:17:15,204] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:17:15,207] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:17:15,205] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:17:15,207] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:17:15,211] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:17:15,213] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:17:15,227] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run77
[2019-03-24 00:17:15,252] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run77
[2019-03-24 00:17:15,252] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run77
[2019-03-24 00:17:15,252] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run77
[2019-03-24 00:17:15,327] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run77
[2019-03-24 00:17:25,136] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.009852014]
[2019-03-24 00:17:25,137] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.0, 31.83333333333333, 1.0, 2.0, 0.2631776260095107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 339480.2564430371, 339480.2564430367, 87678.82270352471]
[2019-03-24 00:17:25,138] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:17:25,141] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.0200248e-19 1.0000000e+00 5.5724056e-30 1.3681598e-27 4.4784031e-32], sampled 0.5870598993666242
[2019-03-24 00:17:29,893] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.009852014]
[2019-03-24 00:17:29,894] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [33.0, 24.0, 1.0, 2.0, 0.6235460527491428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 779774.7496382772, 779774.7496382772, 164705.743122242]
[2019-03-24 00:17:29,894] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:17:29,902] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [8.0200248e-19 1.0000000e+00 5.5724056e-30 1.3681598e-27 4.4784031e-32], sampled 0.6598032245770895
[2019-03-24 00:17:31,330] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.009852014]
[2019-03-24 00:17:31,330] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [17.77398224, 76.97611346, 1.0, 2.0, 0.2420329168313209, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 312199.5161551479, 312199.5161551479, 99481.90726260578]
[2019-03-24 00:17:31,331] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:17:31,334] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [8.0200248e-19 1.0000000e+00 5.5724056e-30 1.3681598e-27 4.4784031e-32], sampled 0.77056999926108
[2019-03-24 00:17:57,347] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.009852014]
[2019-03-24 00:17:57,348] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.05, 86.0, 1.0, 2.0, 0.7057457797451582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 804353.977111366, 804353.977111366, 177236.5544577891]
[2019-03-24 00:17:57,351] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:17:57,355] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [8.0200248e-19 1.0000000e+00 5.5724056e-30 1.3681598e-27 4.4784031e-32], sampled 0.34848767922667534
[2019-03-24 00:18:18,883] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.009852014]
[2019-03-24 00:18:18,884] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.23333333333333, 92.33333333333334, 1.0, 2.0, 0.6193797597561895, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 729258.0000037871, 729258.0000037871, 162524.9759580969]
[2019-03-24 00:18:18,885] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:18:18,893] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.0200248e-19 1.0000000e+00 5.5724056e-30 1.3681598e-27 4.4784031e-32], sampled 0.6140470272343778
[2019-03-24 00:18:59,218] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.009852014]
[2019-03-24 00:18:59,220] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.76666666666667, 47.0, 1.0, 2.0, 0.5985073855125559, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 754782.6333829669, 754782.6333829669, 160332.3113652731]
[2019-03-24 00:18:59,223] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:18:59,225] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.0200248e-19 1.0000000e+00 5.5724056e-30 1.3681598e-27 4.4784031e-32], sampled 0.11125902014794453
[2019-03-24 00:19:00,510] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 00:19:00,771] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 00:19:00,856] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 00:19:00,910] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 00:19:01,025] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 00:19:02,043] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1900000, evaluation results [1900000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 00:19:06,641] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:19:06,643] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:19:06,702] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run10
[2019-03-24 00:19:13,179] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:19:13,179] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:19:13,248] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run10
[2019-03-24 00:19:13,798] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.6169151e-19 1.0000000e+00 8.8042270e-30 2.0005944e-28 2.6942986e-31], sum to 1.0000
[2019-03-24 00:19:13,803] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4783
[2019-03-24 00:19:13,811] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.46666666666667, 86.5, 1.0, 2.0, 0.4335263569412632, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 540251.0489424433, 540251.0489424429, 133507.5148013026], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7877400.0000, 
sim time next is 7878000.0000, 
raw observation next is [20.33333333333334, 87.0, 1.0, 2.0, 0.4028683367536679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 502506.5080832604, 502506.5080832604, 129093.3776847009], 
processed observation next is [1.0, 0.17391304347826086, 0.3086419753086422, 0.87, 1.0, 1.0, 0.28912897232579515, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17946661002973585, 0.17946661002973585, 0.24825649554750173], 
reward next is 0.7517, 
noisyNet noise sample is [array([-0.29393357], dtype=float32), 0.1386101]. 
=============================================
[2019-03-24 00:19:13,845] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[72.28806]
 [72.28806]
 [72.28806]
 [72.28806]
 [72.28806]], R is [[72.31694031]
 [72.3370285 ]
 [72.36595917]
 [72.39176941]
 [72.41652679]].
[2019-03-24 00:19:17,791] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:19:17,792] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:19:17,838] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run10
[2019-03-24 00:19:18,451] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:19:18,451] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:19:18,476] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run10
[2019-03-24 00:19:18,551] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:19:18,552] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:19:18,558] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run10
[2019-03-24 00:19:19,007] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:19:19,008] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:19:19,020] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run10
[2019-03-24 00:19:19,054] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:19:19,057] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:19:19,057] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:19:19,060] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:19:19,071] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run10
[2019-03-24 00:19:19,094] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run10
[2019-03-24 00:19:19,125] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:19:19,126] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:19:19,130] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run10
[2019-03-24 00:19:19,182] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:19:19,182] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:19:19,197] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run10
[2019-03-24 00:19:19,295] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:19:19,296] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:19:19,307] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run10
[2019-03-24 00:19:19,349] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:19:19,350] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:19:19,355] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run10
[2019-03-24 00:19:19,401] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:19:19,401] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:19:19,411] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run10
[2019-03-24 00:19:19,559] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:19:19,559] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:19:19,563] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run10
[2019-03-24 00:19:19,682] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:19:19,682] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:19:19,688] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run10
[2019-03-24 00:19:19,929] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:19:19,929] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:19:19,932] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run10
[2019-03-24 00:19:27,003] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.1911110e-19 1.0000000e+00 1.8792884e-31 1.2833356e-29 7.8821130e-34], sum to 1.0000
[2019-03-24 00:19:27,010] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3679
[2019-03-24 00:19:27,012] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.15, 67.5, 1.0, 2.0, 0.8966374627770286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.942507658957289, 6.9112, 121.9258920135454, 1118582.767430565, 1102550.467600627, 220267.0781275363], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 117000.0000, 
sim time next is 117600.0000, 
raw observation next is [24.56666666666666, 65.66666666666666, 1.0, 2.0, 0.9383444480888354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.208449209795532, 6.9112, 121.924824153858, 1304112.557663013, 1151895.915599401, 229899.4735073483], 
processed observation next is [1.0, 0.34782608695652173, 0.46543209876543185, 0.6566666666666666, 1.0, 1.0, 0.9266005334390898, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.029724920979553194, 0.0, 0.8094540395008697, 0.4657544848796475, 0.41139139842835754, 0.442114372129516], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.8846077], dtype=float32), -0.5219191]. 
=============================================
[2019-03-24 00:19:29,448] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.649566e-20 1.000000e+00 9.151935e-32 4.070381e-29 5.855300e-34], sum to 1.0000
[2019-03-24 00:19:29,451] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7083
[2019-03-24 00:19:29,455] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.8, 14.0, 1.0, 2.0, 0.3640096294853751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 469586.1291278343, 469586.1291278343, 117217.3569698697], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 162000.0000, 
sim time next is 162600.0000, 
raw observation next is [31.71666666666667, 13.66666666666667, 1.0, 2.0, 0.3651903129889456, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 471109.7231940877, 471109.7231940872, 116206.5387123522], 
processed observation next is [1.0, 0.9130434782608695, 0.730246913580247, 0.1366666666666667, 1.0, 1.0, 0.24427418212969715, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16825347256931703, 0.16825347256931686, 0.2234741129083696], 
reward next is 0.7765, 
noisyNet noise sample is [array([-0.5317285], dtype=float32), 0.2486887]. 
=============================================
[2019-03-24 00:19:36,995] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3231356e-19 1.0000000e+00 4.9708500e-32 3.2742916e-27 7.0730312e-34], sum to 1.0000
[2019-03-24 00:19:37,000] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0635
[2019-03-24 00:19:37,007] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.7, 30.0, 1.0, 2.0, 0.3047116897681467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 393069.9487109467, 393069.9487109467, 105556.2794029256], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 297000.0000, 
sim time next is 297600.0000, 
raw observation next is [25.83333333333334, 29.66666666666666, 1.0, 2.0, 0.3056912864413071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 394333.9271658415, 394333.9271658415, 105963.9426582767], 
processed observation next is [0.0, 0.43478260869565216, 0.5123456790123458, 0.29666666666666663, 1.0, 1.0, 0.17344200766822276, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14083354541637197, 0.14083354541637197, 0.2037768128043783], 
reward next is 0.7962, 
noisyNet noise sample is [array([-0.01757553], dtype=float32), 0.14485535]. 
=============================================
[2019-03-24 00:19:37,343] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.0596015e-20 1.0000000e+00 4.0319236e-33 7.1251801e-29 5.5367305e-35], sum to 1.0000
[2019-03-24 00:19:37,351] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9241
[2019-03-24 00:19:37,358] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.8, 30.33333333333334, 1.0, 2.0, 0.317767662704615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 409916.3066156639, 409916.3066156639, 116732.6948921115], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 303600.0000, 
sim time next is 304200.0000, 
raw observation next is [26.9, 30.5, 1.0, 2.0, 0.3176557778469826, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 409689.1743081359, 409689.1743081359, 117770.8497025641], 
processed observation next is [0.0, 0.5217391304347826, 0.5518518518518518, 0.305, 1.0, 1.0, 0.18768544981783647, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14631756225290568, 0.14631756225290568, 0.22648240327416172], 
reward next is 0.7735, 
noisyNet noise sample is [array([-0.5051601], dtype=float32), 0.44249183]. 
=============================================
[2019-03-24 00:19:44,315] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.5505002e-20 1.0000000e+00 5.3876621e-32 6.8231839e-30 1.8203477e-34], sum to 1.0000
[2019-03-24 00:19:44,326] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6540
[2019-03-24 00:19:44,334] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.6, 65.0, 1.0, 2.0, 0.2818822319432028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 361996.4781312163, 361996.4781312163, 113364.4831033546], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 439200.0000, 
sim time next is 439800.0000, 
raw observation next is [20.45, 65.66666666666667, 1.0, 2.0, 0.473164692001275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 607661.9530161567, 607661.9530161567, 139646.6648940011], 
processed observation next is [1.0, 0.08695652173913043, 0.31296296296296294, 0.6566666666666667, 1.0, 1.0, 0.3728151095253273, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2170221260771988, 0.2170221260771988, 0.2685512786423098], 
reward next is 0.7314, 
noisyNet noise sample is [array([0.9631988], dtype=float32), 0.54006606]. 
=============================================
[2019-03-24 00:19:49,625] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.7452397e-16 1.0000000e+00 5.7297439e-29 2.4924445e-25 2.2753200e-30], sum to 1.0000
[2019-03-24 00:19:49,631] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2227
[2019-03-24 00:19:49,634] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.05, 69.0, 1.0, 2.0, 0.3509416765387949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 446445.5500425329, 446445.5500425329, 122095.4644776218], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 541800.0000, 
sim time next is 542400.0000, 
raw observation next is [21.23333333333333, 68.0, 1.0, 2.0, 0.3441840716333947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 437700.01137077, 437700.0113707695, 121202.3824591959], 
processed observation next is [1.0, 0.2608695652173913, 0.34197530864197523, 0.68, 1.0, 1.0, 0.2192667519445175, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15632143263241785, 0.15632143263241768, 0.23308150472922287], 
reward next is 0.7669, 
noisyNet noise sample is [array([0.62644374], dtype=float32), -1.441624]. 
=============================================
[2019-03-24 00:19:51,200] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.04567375e-17 1.00000000e+00 5.33794688e-26 2.19951807e-23
 3.23316958e-28], sum to 1.0000
[2019-03-24 00:19:51,206] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5055
[2019-03-24 00:19:51,212] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1453012.149668832 W.
[2019-03-24 00:19:51,219] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.3, 30.0, 1.0, 2.0, 0.6039797262115684, 1.0, 2.0, 0.6039797262115684, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1453012.149668832, 1453012.149668832, 272699.4067975716], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 579600.0000, 
sim time next is 580200.0000, 
raw observation next is [32.15, 30.33333333333333, 1.0, 2.0, 0.2786841782439395, 1.0, 2.0, 0.2786841782439395, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 676589.0154530279, 676589.0154530284, 177191.5130975003], 
processed observation next is [1.0, 0.7391304347826086, 0.7462962962962962, 0.3033333333333333, 1.0, 1.0, 0.14129068838564224, 1.0, 1.0, 0.14129068838564224, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2416389340903671, 0.24163893409036727, 0.3407529098028852], 
reward next is 0.6592, 
noisyNet noise sample is [array([-1.5070232], dtype=float32), -0.2446961]. 
=============================================
[2019-03-24 00:19:52,791] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-24 00:19:52,792] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:19:52,793] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:19:52,793] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:19:52,795] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:19:52,795] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:19:52,796] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:19:52,796] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:19:52,797] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:19:52,797] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:19:52,800] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:19:52,818] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run78
[2019-03-24 00:19:52,843] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run78
[2019-03-24 00:19:52,868] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run78
[2019-03-24 00:19:52,869] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run78
[2019-03-24 00:19:52,915] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run78
[2019-03-24 00:19:59,032] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), -0.0003520421]
[2019-03-24 00:19:59,033] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [17.03333333333333, 88.0, 1.0, 2.0, 0.2534472840079909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 326926.1381901086, 326926.1381901086, 108691.6850848211]
[2019-03-24 00:19:59,034] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:19:59,036] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [7.9694251e-20 1.0000000e+00 1.1125839e-31 4.0668734e-29 8.4174588e-34], sampled 0.026239247973953828
[2019-03-24 00:20:10,864] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), -0.0003520421]
[2019-03-24 00:20:10,866] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.64957711, 67.93275134000001, 1.0, 2.0, 0.322642101792673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 411411.5377888284, 411411.5377888284, 118417.0044973745]
[2019-03-24 00:20:10,866] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:20:10,868] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [7.9694251e-20 1.0000000e+00 1.1125839e-31 4.0668734e-29 8.4174588e-34], sampled 0.8457988421223901
[2019-03-24 00:20:31,481] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), -0.0003520421]
[2019-03-24 00:20:31,482] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.94426085, 72.27077614, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 1.0, 2.0, 0.9977734948820727, 97.79068362230333, 6.9112, 121.94756008, 49565400.62026992, 3018769.206175023, 512318.6681985061]
[2019-03-24 00:20:31,483] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:20:31,487] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.6056790e-20 1.0000000e+00 3.1136703e-32 1.2625721e-29 2.1425876e-34], sampled 0.8749322571350477
[2019-03-24 00:20:31,488] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 0, 1] for the demand 49565400.62026992 W.
[2019-03-24 00:20:34,306] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), -0.0003520421]
[2019-03-24 00:20:34,308] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.73572437666667, 91.42476288, 1.0, 2.0, 0.4964748044315728, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 593059.956327776, 593059.956327776, 142376.3078177323]
[2019-03-24 00:20:34,310] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:20:34,312] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [7.9694251e-20 1.0000000e+00 1.1125839e-31 4.0668734e-29 8.4174588e-34], sampled 0.08308428678406121
[2019-03-24 00:20:44,860] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), -0.0003520421]
[2019-03-24 00:20:44,862] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.4, 77.66666666666667, 1.0, 2.0, 0.7226863957642677, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 823671.9438658712, 823671.9438658712, 180485.2558668803]
[2019-03-24 00:20:44,863] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:20:44,865] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [7.9694251e-20 1.0000000e+00 1.1125839e-31 4.0668734e-29 8.4174588e-34], sampled 0.8396753114928468
[2019-03-24 00:20:46,849] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), -0.0003520421]
[2019-03-24 00:20:46,854] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.75, 73.33333333333334, 1.0, 2.0, 0.810357313024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 923653.8854429105, 923653.8854429105, 198093.5459826341]
[2019-03-24 00:20:46,855] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:20:46,859] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.9694251e-20 1.0000000e+00 1.1125839e-31 4.0668734e-29 8.4174588e-34], sampled 0.1923188197910244
[2019-03-24 00:20:48,975] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), -0.0003520421]
[2019-03-24 00:20:48,977] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.86928741, 81.52869623, 1.0, 2.0, 0.703557293990322, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426156358, 1516861.557890716, 1516861.557890715, 317878.4629417916]
[2019-03-24 00:20:48,977] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:20:48,981] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [7.9694251e-20 1.0000000e+00 1.1125839e-31 4.0668734e-29 8.4174588e-34], sampled 0.2707127634627887
[2019-03-24 00:20:48,982] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1516861.557890716 W.
[2019-03-24 00:21:04,382] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), -0.0003520421]
[2019-03-24 00:21:04,383] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.93333333333333, 93.33333333333334, 1.0, 2.0, 0.6180821306600206, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 704395.8824153928, 704395.8824153928, 161216.4075677597]
[2019-03-24 00:21:04,383] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:21:04,388] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [7.9694251e-20 1.0000000e+00 1.1125839e-31 4.0668734e-29 8.4174588e-34], sampled 0.5214601917405
[2019-03-24 00:21:07,384] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), -0.0003520421]
[2019-03-24 00:21:07,385] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.25, 89.66666666666666, 1.0, 2.0, 0.6581740852846251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 750108.9418511656, 750108.9418511656, 168374.4787442558]
[2019-03-24 00:21:07,385] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:21:07,390] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.9694251e-20 1.0000000e+00 1.1125839e-31 4.0668734e-29 8.4174588e-34], sampled 0.1894833068884132
[2019-03-24 00:21:29,003] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), -0.0003520421]
[2019-03-24 00:21:29,005] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [32.66666666666666, 42.33333333333333, 1.0, 2.0, 0.5825331440219765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 683621.5161575683, 683621.5161575683, 156013.9479614535]
[2019-03-24 00:21:29,006] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:21:29,009] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.9694251e-20 1.0000000e+00 1.1125839e-31 4.0668734e-29 8.4174588e-34], sampled 0.49035754787227115
[2019-03-24 00:21:35,531] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), -0.0003520421]
[2019-03-24 00:21:35,532] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [14.35, 85.0, 1.0, 2.0, 0.5076093788085231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 654914.3311892244, 654914.3311892244, 129209.5741991082]
[2019-03-24 00:21:35,532] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:21:35,536] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.9694251e-20 1.0000000e+00 1.1125839e-31 4.0668734e-29 8.4174588e-34], sampled 0.4707956893146985
[2019-03-24 00:21:38,081] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 00:21:38,354] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 00:21:38,569] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 00:21:38,592] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 00:21:38,625] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 00:21:39,641] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1925000, evaluation results [1925000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 00:21:46,726] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2088599e-16 1.0000000e+00 1.5685850e-27 6.6986607e-25 4.6770872e-29], sum to 1.0000
[2019-03-24 00:21:46,733] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4589
[2019-03-24 00:21:46,742] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1351509.340514427 W.
[2019-03-24 00:21:46,758] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.0, 28.33333333333334, 1.0, 2.0, 0.9276535110892663, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.276389419952443, 6.9112, 121.9246891790776, 1351509.340514427, 1164501.793133832, 228040.2150631931], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 739200.0000, 
sim time next is 739800.0000, 
raw observation next is [31.3, 27.0, 1.0, 2.0, 0.3586894564511384, 1.0, 1.0, 0.3586894564511384, 1.0, 1.0, 0.588867403743041, 6.911200000000001, 6.9112, 121.94756008, 1320793.125658624, 1320793.125658624, 277979.2501531601], 
processed observation next is [1.0, 0.5652173913043478, 0.7148148148148148, 0.27, 1.0, 1.0, 0.2365350672037362, 1.0, 0.5, 0.2365350672037362, 1.0, 0.5, 0.48608425467880123, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.47171183059236577, 0.47171183059236577, 0.5345754810637694], 
reward next is 0.4654, 
noisyNet noise sample is [array([-0.3453211], dtype=float32), 0.59043914]. 
=============================================
[2019-03-24 00:21:55,333] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6974942e-20 1.0000000e+00 4.9056505e-33 6.5496599e-31 1.7002234e-34], sum to 1.0000
[2019-03-24 00:21:55,343] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7637
[2019-03-24 00:21:55,349] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.73333333333333, 66.0, 1.0, 2.0, 0.327520891391778, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 415783.3863912287, 415783.3863912287, 119032.3155656178], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 888600.0000, 
sim time next is 889200.0000, 
raw observation next is [21.8, 66.0, 1.0, 2.0, 0.3291722579744827, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 417600.3411074098, 417600.3411074094, 119242.4737166924], 
processed observation next is [0.0, 0.30434782608695654, 0.362962962962963, 0.66, 1.0, 1.0, 0.2013955452077175, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14914297896693207, 0.14914297896693193, 0.2293124494551777], 
reward next is 0.7707, 
noisyNet noise sample is [array([-1.5104036], dtype=float32), -1.8050493]. 
=============================================
[2019-03-24 00:21:58,447] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.0047956e-20 1.0000000e+00 2.8134726e-31 4.3455211e-32 1.7395151e-33], sum to 1.0000
[2019-03-24 00:21:58,454] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2382
[2019-03-24 00:21:58,459] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.95, 58.33333333333334, 1.0, 2.0, 0.3401718822859179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 438825.738604555, 438825.738604555, 119563.6406718922], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 961800.0000, 
sim time next is 962400.0000, 
raw observation next is [20.9, 58.66666666666667, 1.0, 2.0, 0.31021692716266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 400173.4109208743, 400173.4109208738, 115670.5106288517], 
processed observation next is [1.0, 0.13043478260869565, 0.32962962962962955, 0.5866666666666667, 1.0, 1.0, 0.17882967519364282, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14291907532888368, 0.1429190753288835, 0.22244328967086865], 
reward next is 0.7776, 
noisyNet noise sample is [array([-0.6247948], dtype=float32), -1.9039315]. 
=============================================
[2019-03-24 00:22:09,264] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.9558284e-20 1.0000000e+00 3.6049279e-32 3.2315141e-30 1.8322827e-33], sum to 1.0000
[2019-03-24 00:22:09,274] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4509
[2019-03-24 00:22:09,279] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.78333333333333, 76.5, 1.0, 2.0, 0.2787632795616618, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 358684.1325584986, 358684.1325584986, 112986.0276861038], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1141800.0000, 
sim time next is 1142400.0000, 
raw observation next is [18.86666666666667, 76.0, 1.0, 2.0, 0.2712903170955951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 349015.4611896209, 349015.4611896209, 112096.3647437751], 
processed observation next is [1.0, 0.21739130434782608, 0.25432098765432115, 0.76, 1.0, 1.0, 0.1324884727328513, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.12464837899629318, 0.12464837899629318, 0.21556993219956752], 
reward next is 0.7844, 
noisyNet noise sample is [array([0.06507027], dtype=float32), -0.14338417]. 
=============================================
[2019-03-24 00:22:09,792] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.2867840e-19 1.0000000e+00 4.7700003e-32 1.3841591e-29 1.3614914e-33], sum to 1.0000
[2019-03-24 00:22:09,800] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1707
[2019-03-24 00:22:09,808] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.05, 66.5, 1.0, 2.0, 0.7562135972804426, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 954740.6628942362, 954740.6628942357, 190423.8269393101], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1175400.0000, 
sim time next is 1176000.0000, 
raw observation next is [22.0, 67.0, 1.0, 2.0, 0.7318763470977377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 923777.7452962294, 923777.7452962289, 185489.321547264], 
processed observation next is [1.0, 0.6086956521739131, 0.37037037037037035, 0.67, 1.0, 1.0, 0.6808051751163544, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.32992062332008193, 0.32992062332008176, 0.3567102337447385], 
reward next is 0.6433, 
noisyNet noise sample is [array([-0.8430279], dtype=float32), -2.0858057]. 
=============================================
[2019-03-24 00:22:09,829] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[74.93498]
 [74.93498]
 [74.93498]
 [74.93498]
 [74.93498]], R is [[74.82891846]
 [74.71442413]
 [74.60147095]
 [74.49404907]
 [74.41407013]].
[2019-03-24 00:22:14,738] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2103035e-17 1.0000000e+00 4.0281215e-28 3.5655354e-27 1.0463178e-29], sum to 1.0000
[2019-03-24 00:22:14,745] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3021
[2019-03-24 00:22:14,751] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1433282.001185846 W.
[2019-03-24 00:22:14,755] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.16666666666666, 56.33333333333334, 1.0, 2.0, 0.966021467752141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.39360407898837, 6.9112, 121.9238210668446, 1433282.001185846, 1186252.497030171, 236511.0259439779], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1263000.0000, 
sim time next is 1263600.0000, 
raw observation next is [26.2, 56.0, 1.0, 2.0, 0.3628090969713298, 1.0, 1.0, 0.3628090969713298, 1.0, 1.0, 0.5847783382875947, 6.9112, 6.9112, 121.94756008, 1302198.888026593, 1302198.888026593, 280770.1011071727], 
processed observation next is [1.0, 0.6521739130434783, 0.5259259259259259, 0.56, 1.0, 1.0, 0.241439401156345, 1.0, 0.5, 0.241439401156345, 1.0, 0.5, 0.4809729228594934, 0.0, 0.0, 0.8096049824067558, 0.46507103143806894, 0.46507103143806894, 0.5399425021291783], 
reward next is 0.4601, 
noisyNet noise sample is [array([2.598466], dtype=float32), 0.6425643]. 
=============================================
[2019-03-24 00:22:19,270] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.2920457e-18 1.0000000e+00 3.0805388e-27 9.5415497e-25 3.6312657e-30], sum to 1.0000
[2019-03-24 00:22:19,277] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7579
[2019-03-24 00:22:19,284] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.4, 40.0, 1.0, 2.0, 0.3409766782552281, 1.0, 1.0, 0.3409766782552281, 1.0, 1.0, 0.5556739703948284, 6.911199999999999, 6.9112, 121.94756008, 1244877.107500611, 1244877.107500612, 271134.7711868837], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1339200.0000, 
sim time next is 1339800.0000, 
raw observation next is [28.58333333333334, 39.33333333333334, 1.0, 2.0, 0.886673841064387, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.917185900841426, 6.9112, 121.9258920065308, 1100917.67654465, 1097852.364086525, 218208.8593259147], 
processed observation next is [1.0, 0.5217391304347826, 0.6141975308641977, 0.3933333333333334, 1.0, 1.0, 0.8650879060290321, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.000598590084142625, 0.0, 0.8094611289321285, 0.39318488448023214, 0.3920901300309018, 0.41963242178060517], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.02817743], dtype=float32), -0.17683113]. 
=============================================
[2019-03-24 00:22:19,346] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.1963993e-16 1.0000000e+00 2.7937050e-26 3.9338556e-25 1.6167113e-27], sum to 1.0000
[2019-03-24 00:22:19,352] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7741
[2019-03-24 00:22:19,356] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.8, 32.0, 1.0, 2.0, 0.9117745266374151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.117109306708771, 6.9112, 121.9252142198068, 1240390.937590327, 1134947.685002988, 224124.2831811878], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1350000.0000, 
sim time next is 1350600.0000, 
raw observation next is [30.81666666666667, 31.66666666666667, 1.0, 2.0, 0.9711255820475001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.52026348315719, 6.9112, 121.923475423717, 1521642.166395336, 1209753.7925905, 238227.8324252222], 
processed observation next is [1.0, 0.6521739130434783, 0.6969135802469137, 0.3166666666666667, 1.0, 1.0, 0.9656256929136906, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.06090634831571897, 0.0, 0.8094450853353139, 0.5434436308554771, 0.4320549259251786, 0.4581304469715812], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.19338281], dtype=float32), -0.26023757]. 
=============================================
[2019-03-24 00:22:20,890] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.3300287e-19 1.0000000e+00 2.0918575e-30 3.6213371e-28 1.7729175e-33], sum to 1.0000
[2019-03-24 00:22:20,899] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4132
[2019-03-24 00:22:20,905] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.06666666666667, 66.66666666666667, 1.0, 2.0, 0.3051332238944034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 389379.7005899875, 389379.7005899875, 116212.0635328357], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1390200.0000, 
sim time next is 1390800.0000, 
raw observation next is [21.03333333333333, 66.33333333333334, 1.0, 2.0, 0.3024861393324098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 386299.6031691252, 386299.6031691252, 115883.9032731179], 
processed observation next is [0.0, 0.08695652173913043, 0.3345679012345678, 0.6633333333333334, 1.0, 1.0, 0.1696263563481069, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1379641439889733, 0.1379641439889733, 0.22285366014061136], 
reward next is 0.7771, 
noisyNet noise sample is [array([-1.1803389], dtype=float32), 1.125989]. 
=============================================
[2019-03-24 00:22:21,311] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2603601e-19 1.0000000e+00 5.2982925e-31 9.8217273e-27 1.0351959e-32], sum to 1.0000
[2019-03-24 00:22:21,316] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6378
[2019-03-24 00:22:21,319] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.71666666666667, 65.83333333333333, 1.0, 2.0, 0.355107587726221, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 446213.079922707, 446213.0799227065, 122591.1234609422], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1378200.0000, 
sim time next is 1378800.0000, 
raw observation next is [22.5, 67.0, 1.0, 2.0, 0.3536854616876471, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 444588.2323553088, 444588.2323553088, 122404.2449590412], 
processed observation next is [1.0, 1.0, 0.3888888888888889, 0.67, 1.0, 1.0, 0.23057793058053225, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1587815115554674, 0.1587815115554674, 0.23539277876738693], 
reward next is 0.7646, 
noisyNet noise sample is [array([1.7083313], dtype=float32), 1.9951497]. 
=============================================
[2019-03-24 00:22:28,441] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.0457809e-20 1.0000000e+00 2.8660564e-29 6.9549004e-28 1.6833811e-32], sum to 1.0000
[2019-03-24 00:22:28,443] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9068
[2019-03-24 00:22:28,448] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 69.33333333333334, 1.0, 2.0, 0.3871088853160263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 483393.1992034506, 483393.1992034501, 126894.7890214228], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1556400.0000, 
sim time next is 1557000.0000, 
raw observation next is [22.6, 70.0, 1.0, 2.0, 0.3867182427415263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 482894.4651534687, 482894.4651534682, 126840.3839731678], 
processed observation next is [1.0, 0.0, 0.39259259259259266, 0.7, 1.0, 1.0, 0.2699026699303884, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1724623089833817, 0.1724623089833815, 0.243923815333015], 
reward next is 0.7561, 
noisyNet noise sample is [array([0.27835885], dtype=float32), 0.9891914]. 
=============================================
[2019-03-24 00:22:28,480] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[75.47757]
 [75.47757]
 [75.47757]
 [75.47757]
 [75.47757]], R is [[75.47886658]
 [75.48004913]
 [75.4812851 ]
 [75.48249054]
 [75.48342133]].
[2019-03-24 00:22:28,550] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5530233e-17 1.0000000e+00 4.0877642e-28 2.4059025e-24 3.6369773e-30], sum to 1.0000
[2019-03-24 00:22:28,556] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7620
[2019-03-24 00:22:28,560] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.2, 71.5, 1.0, 2.0, 0.5048353941747977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 605144.8280509411, 605144.8280509406, 143766.1228044478], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1539000.0000, 
sim time next is 1539600.0000, 
raw observation next is [24.7, 74.0, 1.0, 2.0, 0.5008325263600499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 601367.0922144974, 601367.0922144974, 143170.0690369012], 
processed observation next is [0.0, 0.8260869565217391, 0.4703703703703703, 0.74, 1.0, 1.0, 0.405753007571488, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21477396150517764, 0.21477396150517764, 0.2753270558401946], 
reward next is 0.7247, 
noisyNet noise sample is [array([-0.23411915], dtype=float32), -0.51939696]. 
=============================================
[2019-03-24 00:22:29,594] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-24 00:22:29,596] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:22:29,597] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:22:29,598] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:22:29,599] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:22:29,600] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:22:29,601] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:22:29,601] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:22:29,602] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:22:29,598] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:22:29,607] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:22:29,626] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run79
[2019-03-24 00:22:29,647] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run79
[2019-03-24 00:22:29,671] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run79
[2019-03-24 00:22:29,701] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run79
[2019-03-24 00:22:29,721] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run79
[2019-03-24 00:22:45,822] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), -0.026533065]
[2019-03-24 00:22:45,823] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [17.60310254666667, 87.78441588333334, 1.0, 2.0, 0.2560643381605117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 329372.8811815078, 329372.8811815078, 110314.5467592808]
[2019-03-24 00:22:45,824] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:22:45,827] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0857986e-18 1.0000000e+00 8.2021226e-30 1.8494226e-27 6.7894238e-32], sampled 0.294563279127217
[2019-03-24 00:22:48,743] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), -0.026533065]
[2019-03-24 00:22:48,743] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.65580779333334, 41.21031489333333, 1.0, 2.0, 0.3178808677013996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 402927.9383229965, 402927.9383229965, 117797.604722075]
[2019-03-24 00:22:48,745] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:22:48,749] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0857986e-18 1.0000000e+00 8.2021226e-30 1.8494226e-27 6.7894238e-32], sampled 0.4703500441469647
[2019-03-24 00:22:49,735] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), -0.026533065]
[2019-03-24 00:22:49,738] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.79363715833334, 40.94634379666667, 1.0, 2.0, 0.3587521342647208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 453524.3047177665, 453524.3047177665, 123112.7125979203]
[2019-03-24 00:22:49,738] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:22:49,742] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0857986e-18 1.0000000e+00 8.2021226e-30 1.8494226e-27 6.7894238e-32], sampled 0.5268425047043401
[2019-03-24 00:22:59,075] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), -0.026533065]
[2019-03-24 00:22:59,075] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.5, 65.0, 1.0, 2.0, 0.2971874237354103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 378915.3677143677, 378915.3677143673, 115227.8033285366]
[2019-03-24 00:22:59,076] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:22:59,080] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0857986e-18 1.0000000e+00 8.2021226e-30 1.8494226e-27 6.7894238e-32], sampled 0.42744543195143814
[2019-03-24 00:23:08,352] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), -0.026533065]
[2019-03-24 00:23:08,353] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.10847919333333, 93.06878078666668, 1.0, 2.0, 0.673340126210536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 767402.0529003631, 767402.0529003631, 171156.6433118259]
[2019-03-24 00:23:08,354] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:23:08,356] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0857986e-18 1.0000000e+00 8.2021226e-30 1.8494226e-27 6.7894238e-32], sampled 0.2024914494017629
[2019-03-24 00:23:30,833] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), -0.026533065]
[2019-03-24 00:23:30,834] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.35952996333333, 84.30174444, 1.0, 2.0, 0.5994133000356733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 691307.2153653244, 691307.2153653244, 158375.3387629815]
[2019-03-24 00:23:30,835] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:23:30,838] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0857986e-18 1.0000000e+00 8.2021226e-30 1.8494226e-27 6.7894238e-32], sampled 0.8001684240867502
[2019-03-24 00:23:58,518] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), -0.026533065]
[2019-03-24 00:23:58,520] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.25, 54.66666666666666, 1.0, 2.0, 0.3742304108712131, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5960234685546071, 6.911199999999999, 6.9112, 121.9255581419343, 858289.6257882502, 858289.6257882507, 216197.9927963014]
[2019-03-24 00:23:58,520] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:23:58,522] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0857986e-18 1.0000000e+00 8.2021226e-30 1.8494226e-27 6.7894238e-32], sampled 0.8842299818945999
[2019-03-24 00:24:00,235] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), -0.026533065]
[2019-03-24 00:24:00,237] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.87452769, 48.385423235, 1.0, 2.0, 0.4680113896888363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 561355.9246925222, 561355.9246925217, 138073.5174711558]
[2019-03-24 00:24:00,239] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:24:00,243] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0857986e-18 1.0000000e+00 8.2021226e-30 1.8494226e-27 6.7894238e-32], sampled 0.27612091951923445
[2019-03-24 00:24:12,154] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), -0.026533065]
[2019-03-24 00:24:12,155] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.35119225, 89.88733072, 1.0, 2.0, 0.410490725184962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 503227.6862601362, 503227.6862601362, 129973.7983387759]
[2019-03-24 00:24:12,158] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:24:12,162] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0857986e-18 1.0000000e+00 8.2021226e-30 1.8494226e-27 6.7894238e-32], sampled 0.9257244562400576
[2019-03-24 00:24:14,660] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 00:24:15,019] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 00:24:15,155] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 00:24:15,255] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 00:24:15,290] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 00:24:16,306] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1950000, evaluation results [1950000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 00:24:18,817] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.9216014e-18 1.0000000e+00 2.4957801e-28 7.6601190e-27 5.5324769e-31], sum to 1.0000
[2019-03-24 00:24:18,826] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2860
[2019-03-24 00:24:18,834] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.21666666666667, 44.5, 1.0, 2.0, 0.9150792787086329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.15524568726855, 6.9112, 121.9248644239894, 1266996.563421162, 1142024.566620557, 224960.4502779216], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1605000.0000, 
sim time next is 1605600.0000, 
raw observation next is [27.3, 44.0, 1.0, 2.0, 0.9244866222428172, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.220453519157253, 6.9112, 121.9245040674804, 1312487.698963093, 1154124.254754734, 227165.1752354394], 
processed observation next is [1.0, 0.6086956521739131, 0.5666666666666667, 0.44, 1.0, 1.0, 0.9101031217176395, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.03092535191572532, 0.0, 0.8094519144601888, 0.46874560677253324, 0.41218723384097644, 0.4368561062219989], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.07144324], dtype=float32), 0.4226978]. 
=============================================
[2019-03-24 00:24:22,948] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.8223300e-19 1.0000000e+00 4.6539458e-31 5.7999446e-27 8.5324203e-34], sum to 1.0000
[2019-03-24 00:24:22,955] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2466
[2019-03-24 00:24:22,960] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 77.5, 1.0, 2.0, 0.7131363732294191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 885519.9339120357, 885519.9339120357, 181494.2885604014], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1852200.0000, 
sim time next is 1852800.0000, 
raw observation next is [21.93333333333333, 77.66666666666667, 1.0, 2.0, 0.6975985345610465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 865605.3143313347, 865605.3143313347, 178446.2490060664], 
processed observation next is [1.0, 0.43478260869565216, 0.36790123456790114, 0.7766666666666667, 1.0, 1.0, 0.6399982554298173, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.30914475511833384, 0.30914475511833384, 0.34316586347320466], 
reward next is 0.6568, 
noisyNet noise sample is [array([0.21780263], dtype=float32), 0.16533831]. 
=============================================
[2019-03-24 00:24:35,218] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.9192693e-18 1.0000000e+00 3.7386946e-31 4.1874012e-28 1.0476302e-32], sum to 1.0000
[2019-03-24 00:24:35,230] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9344
[2019-03-24 00:24:35,237] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 78.0, 1.0, 2.0, 0.5066610724121237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 604089.8906944225, 604089.8906944221, 143937.5748744318], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2068800.0000, 
sim time next is 2069400.0000, 
raw observation next is [24.35, 78.0, 1.0, 2.0, 0.4992800653075349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 596843.699152977, 596843.6991529766, 142831.1219742649], 
processed observation next is [0.0, 0.9565217391304348, 0.4574074074074075, 0.78, 1.0, 1.0, 0.4039048396518272, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21315846398320606, 0.21315846398320593, 0.27467523456589404], 
reward next is 0.7253, 
noisyNet noise sample is [array([0.6908414], dtype=float32), -0.29768223]. 
=============================================
[2019-03-24 00:24:35,814] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.1672053e-18 1.0000000e+00 1.8110622e-31 2.1627199e-29 1.2401020e-32], sum to 1.0000
[2019-03-24 00:24:35,826] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9604
[2019-03-24 00:24:35,832] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 91.0, 1.0, 2.0, 0.4237390034338812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 520227.641577825, 520227.641577825, 131895.9374686377], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1889400.0000, 
sim time next is 1890000.0000, 
raw observation next is [21.0, 91.0, 1.0, 2.0, 0.4247045381488383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 521412.1813828419, 521412.1813828419, 132035.8254089319], 
processed observation next is [1.0, 0.9130434782608695, 0.3333333333333333, 0.91, 1.0, 1.0, 0.3151244501771885, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18621863620815782, 0.18621863620815782, 0.2539150488633306], 
reward next is 0.7461, 
noisyNet noise sample is [array([-1.615721], dtype=float32), 0.5404889]. 
=============================================
[2019-03-24 00:24:35,847] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[77.605675]
 [77.605675]
 [77.605675]
 [77.605675]
 [77.605675]], R is [[77.57571411]
 [77.54631042]
 [77.51731873]
 [77.48843384]
 [77.45977783]].
[2019-03-24 00:24:44,994] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.3258609e-20 1.0000000e+00 2.3553042e-31 6.6255072e-29 1.0606786e-33], sum to 1.0000
[2019-03-24 00:24:45,002] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4102
[2019-03-24 00:24:45,007] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 78.66666666666667, 1.0, 2.0, 0.4839988202271064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 581349.8269153845, 581349.8269153845, 140549.3174520034], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2071200.0000, 
sim time next is 2071800.0000, 
raw observation next is [23.9, 79.0, 1.0, 2.0, 0.4812316632542629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 578528.5895406122, 578528.5895406127, 140139.4401367291], 
processed observation next is [0.0, 1.0, 0.4407407407407407, 0.79, 1.0, 1.0, 0.38241864673126535, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20661735340736148, 0.20661735340736165, 0.26949892333986364], 
reward next is 0.7305, 
noisyNet noise sample is [array([-1.2276496], dtype=float32), 0.9840252]. 
=============================================
[2019-03-24 00:24:47,524] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.1386226e-18 1.0000000e+00 4.0657567e-29 4.5956158e-26 5.0177768e-31], sum to 1.0000
[2019-03-24 00:24:47,530] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6299
[2019-03-24 00:24:47,534] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 69.66666666666667, 1.0, 2.0, 0.9668101509933418, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.159576512516633, 6.9112, 121.9249837409901, 1270017.558305576, 1142827.688854592, 234937.5336325364], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2305200.0000, 
sim time next is 2305800.0000, 
raw observation next is [26.15, 69.0, 1.0, 2.0, 0.985193328049987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.305304786507813, 6.9112, 121.9241891880713, 1371682.206114689, 1169868.398604256, 239598.011975412], 
processed observation next is [1.0, 0.6956521739130435, 0.524074074074074, 0.69, 1.0, 1.0, 0.982373009583318, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.03941047865078131, 0.0, 0.8094498239883638, 0.48988650218381746, 0.4178101423586629, 0.46076540764502305], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.00768414], dtype=float32), 1.9427764]. 
=============================================
[2019-03-24 00:24:53,233] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0915142e-16 1.0000000e+00 3.2544811e-26 6.0711848e-24 4.5901444e-28], sum to 1.0000
[2019-03-24 00:24:53,240] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7827
[2019-03-24 00:24:53,246] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.15, 95.0, 1.0, 2.0, 0.5556374386458544, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 650952.2454627176, 650952.2454627176, 151437.7085635419], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2225400.0000, 
sim time next is 2226000.0000, 
raw observation next is [23.1, 95.0, 1.0, 2.0, 0.556775559304582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 652940.2185374167, 652940.2185374167, 151654.4667394505], 
processed observation next is [1.0, 0.782608695652174, 0.41111111111111115, 0.95, 1.0, 1.0, 0.47235185631497856, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23319293519193451, 0.23319293519193451, 0.291643205268174], 
reward next is 0.7084, 
noisyNet noise sample is [array([1.4257733], dtype=float32), -0.20675999]. 
=============================================
[2019-03-24 00:24:53,260] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[59.56586]
 [59.56586]
 [59.56586]
 [59.56586]
 [59.56586]], R is [[59.67855453]
 [59.7905426 ]
 [59.90231323]
 [60.01327133]
 [60.12296295]].
[2019-03-24 00:24:56,951] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.3323513e-15 1.0000000e+00 3.8301127e-25 4.8675734e-23 1.7547636e-26], sum to 1.0000
[2019-03-24 00:24:56,960] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5364
[2019-03-24 00:24:56,970] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.3, 71.5, 1.0, 2.0, 0.4922005960630865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 589404.1311654939, 589404.1311654939, 141760.3001033608], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2313000.0000, 
sim time next is 2313600.0000, 
raw observation next is [25.2, 72.0, 1.0, 2.0, 0.493199603001033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 590793.2305399342, 590793.2305399338, 141923.0234670839], 
processed observation next is [1.0, 0.782608695652174, 0.4888888888888889, 0.72, 1.0, 1.0, 0.39666619404884884, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2109975823356908, 0.21099758233569063, 0.27292889128285364], 
reward next is 0.7271, 
noisyNet noise sample is [array([1.1528494], dtype=float32), -0.8629553]. 
=============================================
[2019-03-24 00:24:59,855] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.9791154e-18 1.0000000e+00 5.9833377e-30 2.4257400e-27 8.5698117e-32], sum to 1.0000
[2019-03-24 00:24:59,863] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1096
[2019-03-24 00:24:59,869] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1583916.345648385 W.
[2019-03-24 00:24:59,872] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.83333333333333, 37.0, 1.0, 2.0, 0.447619209370149, 1.0, 2.0, 0.447619209370149, 1.0, 2.0, 0.7170474700290467, 6.911199999999999, 6.9112, 121.94756008, 1583916.345648385, 1583916.345648386, 318569.7550299193], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2389800.0000, 
sim time next is 2390400.0000, 
raw observation next is [30.8, 37.0, 1.0, 2.0, 0.44682158037527, 1.0, 2.0, 0.44682158037527, 1.0, 2.0, 0.7156894376105515, 6.911199999999999, 6.9112, 121.94756008, 1580571.677844704, 1580571.677844704, 318202.9476906845], 
processed observation next is [1.0, 0.6956521739130435, 0.6962962962962963, 0.37, 1.0, 1.0, 0.34145426235151183, 1.0, 1.0, 0.34145426235151183, 1.0, 1.0, 0.6446117970131893, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5644898849445371, 0.5644898849445371, 0.6119287455590087], 
reward next is 0.3881, 
noisyNet noise sample is [array([-0.30102628], dtype=float32), -1.1217756]. 
=============================================
[2019-03-24 00:25:01,611] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6179727e-16 1.0000000e+00 2.0026381e-23 1.1374877e-23 1.0763299e-26], sum to 1.0000
[2019-03-24 00:25:01,620] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1300
[2019-03-24 00:25:01,623] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.7, 54.0, 1.0, 2.0, 0.3873916604473849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 481776.8396765483, 481776.8396765483, 126895.4593176796], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2410200.0000, 
sim time next is 2410800.0000, 
raw observation next is [25.46666666666667, 55.0, 1.0, 2.0, 0.3895451603603229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 484669.687639064, 484669.6876390636, 127199.0478734369], 
processed observation next is [1.0, 0.9130434782608695, 0.4987654320987655, 0.55, 1.0, 1.0, 0.2732680480480034, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17309631701395142, 0.17309631701395128, 0.24461355360276327], 
reward next is 0.7554, 
noisyNet noise sample is [array([-0.7118445], dtype=float32), 1.08811]. 
=============================================
[2019-03-24 00:25:06,248] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-24 00:25:06,250] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:25:06,251] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:25:06,252] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:25:06,253] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:25:06,254] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:25:06,255] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:25:06,256] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:25:06,258] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:25:06,258] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:25:06,258] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:25:06,280] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run80
[2019-03-24 00:25:06,304] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run80
[2019-03-24 00:25:06,327] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run80
[2019-03-24 00:25:06,362] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run80
[2019-03-24 00:25:06,385] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run80
[2019-03-24 00:25:09,678] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.07700788]
[2019-03-24 00:25:09,679] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [13.05, 75.0, 1.0, 2.0, 0.1613691527030976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 208136.8114484817, 208136.8114484817, 69352.59296204252]
[2019-03-24 00:25:09,681] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:25:09,683] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.4666709e-16 1.0000000e+00 2.3182373e-26 2.6781179e-24 2.8050431e-28], sampled 0.7997193730741196
[2019-03-24 00:25:28,945] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.07700788]
[2019-03-24 00:25:28,946] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [19.0, 94.0, 1.0, 2.0, 0.3540592631778162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 444677.4595381388, 444677.4595381388, 122448.3182944794]
[2019-03-24 00:25:28,948] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:25:28,950] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.4666709e-16 1.0000000e+00 2.3182373e-26 2.6781179e-24 2.8050431e-28], sampled 0.15341209322342242
[2019-03-24 00:25:30,391] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.07700788]
[2019-03-24 00:25:30,391] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.63333333333333, 61.66666666666667, 1.0, 2.0, 0.3468530352886198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 434904.271987447, 434904.271987447, 121483.1534584577]
[2019-03-24 00:25:30,395] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:25:30,399] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.4666709e-16 1.0000000e+00 2.3182373e-26 2.6781179e-24 2.8050431e-28], sampled 0.6198077498203893
[2019-03-24 00:25:39,507] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.07700788]
[2019-03-24 00:25:39,509] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.38333333333333, 64.66666666666666, 1.0, 2.0, 0.5972002737706126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 690381.1845872696, 690381.18458727, 158069.7731016061]
[2019-03-24 00:25:39,511] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:25:39,515] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.4666709e-16 1.0000000e+00 2.3182373e-26 2.6781179e-24 2.8050431e-28], sampled 0.34885461532498685
[2019-03-24 00:25:45,154] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.07700788]
[2019-03-24 00:25:45,156] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.0, 100.0, 1.0, 2.0, 0.580265093969274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 673386.3109974633, 673386.3109974633, 155294.0356786821]
[2019-03-24 00:25:45,157] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:25:45,159] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.4666709e-16 1.0000000e+00 2.3182373e-26 2.6781179e-24 2.8050431e-28], sampled 0.3471120169006505
[2019-03-24 00:25:58,754] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.07700788]
[2019-03-24 00:25:58,756] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [19.080531745, 94.22391265833335, 1.0, 2.0, 0.4023948188039161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 506024.5637191019, 506024.5637191019, 129096.12714484]
[2019-03-24 00:25:58,757] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:25:58,760] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.4666709e-16 1.0000000e+00 2.3182373e-26 2.6781179e-24 2.8050431e-28], sampled 0.7902435605484717
[2019-03-24 00:26:13,371] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.07700788]
[2019-03-24 00:26:13,372] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.0, 52.0, 1.0, 2.0, 0.5246255455077842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 618137.4123552067, 618137.4123552067, 146522.2679273186]
[2019-03-24 00:26:13,372] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:26:13,375] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.4666709e-16 1.0000000e+00 2.3182373e-26 2.6781179e-24 2.8050431e-28], sampled 0.23459953364454156
[2019-03-24 00:26:29,294] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.07700788]
[2019-03-24 00:26:29,297] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.83410248, 71.10782802333334, 1.0, 2.0, 0.7075729111777438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 806437.4944642042, 806437.4944642042, 177586.6467943201]
[2019-03-24 00:26:29,299] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:26:29,302] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.4666709e-16 1.0000000e+00 2.3182373e-26 2.6781179e-24 2.8050431e-28], sampled 0.029011467570929983
[2019-03-24 00:26:34,422] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.07700788]
[2019-03-24 00:26:34,423] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.98111185, 37.27680842, 1.0, 2.0, 0.5486906544601191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 702532.2336082945, 702532.2336082945, 151825.4776703414]
[2019-03-24 00:26:34,423] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:26:34,427] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.4666709e-16 1.0000000e+00 2.3182373e-26 2.6781179e-24 2.8050431e-28], sampled 0.8829989776782546
[2019-03-24 00:26:51,210] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.07700788]
[2019-03-24 00:26:51,211] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.38547182166667, 47.34666955666667, 1.0, 2.0, 0.7535331508611447, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 934265.4208052907, 934265.4208052907, 189548.5355379276]
[2019-03-24 00:26:51,213] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:26:51,215] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.4666709e-16 1.0000000e+00 2.3182373e-26 2.6781179e-24 2.8050431e-28], sampled 0.23242959593489865
[2019-03-24 00:26:51,702] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 00:26:51,955] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 00:26:51,976] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 00:26:52,009] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 00:26:52,046] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 00:26:53,060] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1975000, evaluation results [1975000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 00:26:53,607] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1518816e-20 1.0000000e+00 1.0275799e-30 2.1412775e-29 5.7724496e-32], sum to 1.0000
[2019-03-24 00:26:53,615] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4263
[2019-03-24 00:26:53,618] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2292205.323722025 W.
[2019-03-24 00:26:53,623] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.85, 68.5, 1.0, 2.0, 1.004689496832238, 1.0, 2.0, 1.004689496832238, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2292205.323722025, 2292205.323722025, 435595.1083724545], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2802600.0000, 
sim time next is 2803200.0000, 
raw observation next is [30.13333333333333, 66.66666666666667, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 6.931712256337188, 6.9112, 121.9258180731557, 2337699.648255399, 2327195.55899076, 443048.1735232617], 
processed observation next is [1.0, 0.43478260869565216, 0.6716049382716048, 0.6666666666666667, 1.0, 1.0, 1.0238095238095237, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.25, 0.002051225633718801, 0.0, 0.8094606380914031, 0.8348927315197854, 0.8311412710681285, 0.8520157183139647], 
reward next is 0.0454, 
noisyNet noise sample is [array([0.67529017], dtype=float32), 1.1702843]. 
=============================================
[2019-03-24 00:26:55,767] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.7657154e-17 1.0000000e+00 1.3534942e-28 2.2763240e-25 1.6948005e-30], sum to 1.0000
[2019-03-24 00:26:55,772] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2917
[2019-03-24 00:26:55,780] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1543250.778940829 W.
[2019-03-24 00:26:55,785] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.40000000000001, 30.0, 1.0, 2.0, 0.6844081730149287, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9581411537773159, 6.911199999999999, 6.9112, 121.9260426156618, 1543250.778940829, 1543250.778940829, 304119.6698971787], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2547600.0000, 
sim time next is 2548200.0000, 
raw observation next is [32.5, 30.0, 1.0, 2.0, 0.4363695010400807, 1.0, 1.0, 0.4363695010400807, 1.0, 2.0, 0.7015791987172257, 6.9112, 6.9112, 121.94756008, 1558369.980212783, 1558369.980212783, 313200.6881372536], 
processed observation next is [1.0, 0.4782608695652174, 0.7592592592592593, 0.3, 1.0, 1.0, 0.3290113107620009, 1.0, 0.5, 0.3290113107620009, 1.0, 1.0, 0.6269739983965322, 0.0, 0.0, 0.8096049824067558, 0.5565607072188511, 0.5565607072188511, 0.6023090156485645], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8079004], dtype=float32), 0.19086292]. 
=============================================
[2019-03-24 00:27:00,185] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.0895833e-21 1.0000000e+00 4.3907444e-32 3.1509687e-28 1.6799611e-33], sum to 1.0000
[2019-03-24 00:27:00,194] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1844
[2019-03-24 00:27:00,198] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 87.0, 1.0, 2.0, 0.6744957465466783, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 768719.7674911079, 768719.7674911079, 171370.5010092201], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2921400.0000, 
sim time next is 2922000.0000, 
raw observation next is [26.0, 86.33333333333334, 1.0, 2.0, 0.66714343368321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 760336.2136723698, 760336.2136723694, 170015.5611629209], 
processed observation next is [1.0, 0.8260869565217391, 0.5185185185185185, 0.8633333333333334, 1.0, 1.0, 0.6037421829562024, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2715486477401321, 0.27154864774013193, 0.32695300223638635], 
reward next is 0.6730, 
noisyNet noise sample is [array([-0.00660677], dtype=float32), 2.7788203]. 
=============================================
[2019-03-24 00:27:00,213] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[76.06013]
 [76.06013]
 [76.06013]
 [76.06013]
 [76.06013]], R is [[75.97257996]
 [75.88329315]
 [75.7928772 ]
 [75.70226288]
 [75.61183929]].
[2019-03-24 00:27:03,220] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.1987083e-19 1.0000000e+00 1.1992878e-31 7.5436577e-28 1.8384178e-31], sum to 1.0000
[2019-03-24 00:27:03,228] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5718
[2019-03-24 00:27:03,244] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1753840.871553967 W.
[2019-03-24 00:27:03,251] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 84.0, 1.0, 2.0, 0.7689521138687319, 1.0, 2.0, 0.7689521138687319, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1753840.871553967, 1753840.871553967, 331093.0267075803], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2973600.0000, 
sim time next is 2974200.0000, 
raw observation next is [28.06666666666667, 83.33333333333333, 1.0, 2.0, 0.8441611308153839, 1.0, 2.0, 0.8441611308153839, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1925563.957751113, 1925563.957751113, 362341.432294569], 
processed observation next is [1.0, 0.43478260869565216, 0.5950617283950619, 0.8333333333333333, 1.0, 1.0, 0.8144775366849808, 1.0, 1.0, 0.8144775366849808, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6877014134825403, 0.6877014134825403, 0.696810446720325], 
reward next is 0.3032, 
noisyNet noise sample is [array([0.41955307], dtype=float32), -2.0874138]. 
=============================================
[2019-03-24 00:27:03,686] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.0780078e-16 1.0000000e+00 1.7596032e-26 2.4423268e-24 1.6865268e-29], sum to 1.0000
[2019-03-24 00:27:03,695] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3602
[2019-03-24 00:27:03,696] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1871567.180285922 W.
[2019-03-24 00:27:03,702] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.16666666666667, 83.16666666666667, 1.0, 2.0, 0.5470093620053343, 1.0, 2.0, 0.5470093620053343, 1.0, 1.0, 0.8708567191636932, 6.9112, 6.9112, 121.94756008, 1871567.180285922, 1871567.180285922, 367260.452432239], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2981400.0000, 
sim time next is 2982000.0000, 
raw observation next is [28.33333333333334, 82.33333333333334, 1.0, 2.0, 0.8988318465643124, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1739751.02225646, 1739751.02225646, 356718.2396663267], 
processed observation next is [1.0, 0.5217391304347826, 0.6049382716049385, 0.8233333333333335, 1.0, 1.0, 0.8795617221003719, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6213396508058786, 0.6213396508058786, 0.685996614742936], 
reward next is 0.3140, 
noisyNet noise sample is [array([0.19895191], dtype=float32), 0.62551075]. 
=============================================
[2019-03-24 00:27:03,726] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[69.277596]
 [69.277596]
 [69.277596]
 [69.277596]
 [69.277596]], R is [[68.89883423]
 [68.2098465 ]
 [67.77857208]
 [67.31797791]
 [66.64479828]].
[2019-03-24 00:27:05,194] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.1784714e-19 1.0000000e+00 1.3120775e-27 4.5429115e-24 3.9950915e-31], sum to 1.0000
[2019-03-24 00:27:05,202] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4092
[2019-03-24 00:27:05,207] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 76.5, 1.0, 2.0, 0.4813489062786498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 578247.1507391747, 578247.1507391747, 140143.362340001], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2705400.0000, 
sim time next is 2706000.0000, 
raw observation next is [24.53333333333333, 77.33333333333333, 1.0, 2.0, 0.495471365508902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 592616.8356698862, 592616.8356698862, 142246.3618813923], 
processed observation next is [0.0, 0.30434782608695654, 0.46419753086419746, 0.7733333333333333, 1.0, 1.0, 0.39937067322488334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21164886988210221, 0.21164886988210221, 0.27355069592575443], 
reward next is 0.7264, 
noisyNet noise sample is [array([1.4466058], dtype=float32), 1.3683554]. 
=============================================
[2019-03-24 00:27:05,225] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[72.87776]
 [72.87776]
 [72.87776]
 [72.87776]
 [72.87776]], R is [[72.8754425 ]
 [72.87718201]
 [72.88275909]
 [72.89143372]
 [72.90298462]].
[2019-03-24 00:27:08,827] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.0074106e-17 1.0000000e+00 5.6322069e-28 5.7676717e-25 1.5833786e-29], sum to 1.0000
[2019-03-24 00:27:08,836] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0172
[2019-03-24 00:27:08,843] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 89.0, 1.0, 2.0, 0.5970381451777205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 698698.5881410378, 698698.5881410378, 158424.7525219857], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2786400.0000, 
sim time next is 2787000.0000, 
raw observation next is [24.16666666666666, 89.0, 1.0, 2.0, 0.6799426287078839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 793487.2784934413, 793487.2784934408, 173276.9660388982], 
processed observation next is [1.0, 0.2608695652173913, 0.45061728395061706, 0.89, 1.0, 1.0, 0.6189793198903379, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2833883137476576, 0.28338831374765744, 0.3332249346901888], 
reward next is 0.6668, 
noisyNet noise sample is [array([-0.4301845], dtype=float32), -0.64155346]. 
=============================================
[2019-03-24 00:27:08,863] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[64.67896]
 [64.67896]
 [64.67896]
 [64.67896]
 [64.67896]], R is [[64.69894409]
 [64.74729156]
 [64.79771423]
 [64.84736633]
 [64.89486694]].
[2019-03-24 00:27:17,915] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.8840708e-16 1.0000000e+00 1.5933596e-27 2.3963662e-25 3.3842874e-29], sum to 1.0000
[2019-03-24 00:27:17,921] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6302
[2019-03-24 00:27:17,924] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.2, 90.0, 1.0, 2.0, 0.6460838069726847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 736323.2552639624, 736323.2552639624, 166186.2659664574], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2935800.0000, 
sim time next is 2936400.0000, 
raw observation next is [25.16666666666667, 90.33333333333334, 1.0, 2.0, 0.6465684997179202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 736875.9112433739, 736875.9112433739, 166273.5592879111], 
processed observation next is [1.0, 1.0, 0.4876543209876545, 0.9033333333333334, 1.0, 1.0, 0.579248213949905, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.263169968301205, 0.263169968301205, 0.31975684478444444], 
reward next is 0.6802, 
noisyNet noise sample is [array([0.76532036], dtype=float32), 0.29336816]. 
=============================================
[2019-03-24 00:27:19,153] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.8444862e-18 1.0000000e+00 7.7976811e-28 3.2752085e-24 3.4513281e-28], sum to 1.0000
[2019-03-24 00:27:19,160] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0210
[2019-03-24 00:27:19,167] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2140067.737349953 W.
[2019-03-24 00:27:19,174] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.2, 82.0, 1.0, 2.0, 0.6253910394527292, 1.0, 2.0, 0.6253910394527292, 1.0, 2.0, 0.9956429023729662, 6.911199999999999, 6.9112, 121.94756008, 2140067.737349953, 2140067.737349954, 409383.3959125736], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2975400.0000, 
sim time next is 2976000.0000, 
raw observation next is [28.26666666666667, 81.33333333333333, 1.0, 2.0, 0.5824937046869147, 1.0, 2.0, 0.5824937046869147, 1.0, 2.0, 0.9273489483571307, 6.9112, 6.9112, 121.94756008, 1993110.662821796, 1993110.662821796, 385919.7955256929], 
processed observation next is [1.0, 0.43478260869565216, 0.6024691358024692, 0.8133333333333332, 1.0, 1.0, 0.5029686960558509, 1.0, 1.0, 0.5029686960558509, 1.0, 1.0, 0.9091861854464134, 0.0, 0.0, 0.8096049824067558, 0.71182523672207, 0.71182523672207, 0.7421534529340249], 
reward next is 0.2578, 
noisyNet noise sample is [array([-1.1767029], dtype=float32), 0.9132664]. 
=============================================
[2019-03-24 00:27:19,189] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[62.075535]
 [62.075535]
 [62.075535]
 [62.075535]
 [62.075535]], R is [[61.71263123]
 [61.30822754]
 [60.69514465]
 [60.08819199]
 [59.85059357]].
[2019-03-24 00:27:25,107] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.0222279e-13 1.0000000e+00 2.0982046e-21 1.1700931e-19 9.5213069e-23], sum to 1.0000
[2019-03-24 00:27:25,120] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2662
[2019-03-24 00:27:25,123] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.33333333333334, 77.66666666666667, 1.0, 2.0, 0.7770540344689791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 885672.5200793952, 885672.5200793952, 191250.8589372976], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3091200.0000, 
sim time next is 3091800.0000, 
raw observation next is [29.16666666666667, 78.33333333333334, 1.0, 2.0, 0.7794578058965158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 888413.8844666367, 888413.8844666367, 191738.1306273028], 
processed observation next is [1.0, 0.782608695652174, 0.6358024691358026, 0.7833333333333334, 1.0, 1.0, 0.7374497689244236, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3172906730237988, 0.3172906730237988, 0.3687271742832746], 
reward next is 0.6313, 
noisyNet noise sample is [array([-0.30214873], dtype=float32), -1.8350663]. 
=============================================
[2019-03-24 00:27:35,687] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.3632085e-21 1.0000000e+00 4.5690864e-31 8.9806535e-29 1.1225977e-32], sum to 1.0000
[2019-03-24 00:27:35,695] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8297
[2019-03-24 00:27:35,703] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.63333333333333, 93.33333333333334, 1.0, 2.0, 0.5322021016505292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 631744.1470481162, 631744.1470481162, 147930.9573877037], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3288000.0000, 
sim time next is 3288600.0000, 
raw observation next is [22.45, 93.0, 1.0, 2.0, 0.521608904554189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 621764.1691819209, 621764.1691819209, 146317.3848632402], 
processed observation next is [0.0, 0.043478260869565216, 0.387037037037037, 0.93, 1.0, 1.0, 0.43048679113593924, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22205863185068606, 0.22205863185068606, 0.28137958627546195], 
reward next is 0.7186, 
noisyNet noise sample is [array([0.43137792], dtype=float32), -0.36019495]. 
=============================================
[2019-03-24 00:27:38,621] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.676384e-18 1.000000e+00 1.377528e-28 6.036492e-26 9.843720e-32], sum to 1.0000
[2019-03-24 00:27:38,631] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5368
[2019-03-24 00:27:38,634] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.9, 72.0, 1.0, 2.0, 0.6823775197035824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 777707.1459409852, 777707.1459409852, 172835.4935248699], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3342600.0000, 
sim time next is 3343200.0000, 
raw observation next is [28.86666666666667, 72.66666666666666, 1.0, 2.0, 0.6961356639143245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 793395.4481353826, 793395.4481353823, 175414.4201401927], 
processed observation next is [0.0, 0.6956521739130435, 0.6246913580246916, 0.7266666666666666, 1.0, 1.0, 0.6382567427551482, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.28335551719120805, 0.28335551719120794, 0.33733542334652444], 
reward next is 0.6627, 
noisyNet noise sample is [array([0.16169184], dtype=float32), -1.0993953]. 
=============================================
[2019-03-24 00:27:43,056] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-24 00:27:43,066] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:27:43,067] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:27:43,068] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:27:43,069] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:27:43,070] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:27:43,070] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:27:43,081] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:27:43,081] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:27:43,084] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run81
[2019-03-24 00:27:43,084] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run81
[2019-03-24 00:27:43,107] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:27:43,110] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:27:43,137] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run81
[2019-03-24 00:27:43,163] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run81
[2019-03-24 00:27:43,193] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run81
[2019-03-24 00:28:30,580] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.11416709]
[2019-03-24 00:28:30,582] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.05, 85.5, 1.0, 2.0, 0.6376178340559719, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 726670.2545664095, 726670.2545664095, 164670.1299351478]
[2019-03-24 00:28:30,583] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:28:30,584] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.6588231e-13 1.0000000e+00 2.1807223e-21 9.3588080e-20 4.5914696e-23], sampled 0.3153786242457589
[2019-03-24 00:28:59,287] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.11416709]
[2019-03-24 00:28:59,288] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.66240761333333, 66.06361322333333, 1.0, 2.0, 0.6443164301449765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 762976.5726516105, 762976.5726516105, 167183.0274189245]
[2019-03-24 00:28:59,289] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:28:59,292] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.6588231e-13 1.0000000e+00 2.1807223e-21 9.3588080e-20 4.5914696e-23], sampled 0.1458996044147156
[2019-03-24 00:29:03,391] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.11416709]
[2019-03-24 00:29:03,392] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.33750355, 86.21605753333333, 1.0, 2.0, 0.5138639438789647, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 612087.736823457, 612087.7368234565, 145059.8753514382]
[2019-03-24 00:29:03,394] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:29:03,396] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.6588231e-13 1.0000000e+00 2.1807223e-21 9.3588080e-20 4.5914696e-23], sampled 0.5276095055741553
[2019-03-24 00:29:34,227] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 00:29:34,349] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 00:29:34,415] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 00:29:34,462] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 00:29:34,500] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 00:29:35,517] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 2000000, evaluation results [2000000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 00:29:37,943] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.6813660e-17 1.0000000e+00 1.1335399e-26 7.1708679e-25 6.4501124e-30], sum to 1.0000
[2019-03-24 00:29:37,953] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5527
[2019-03-24 00:29:37,962] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2045031.890232057 W.
[2019-03-24 00:29:37,966] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.25, 84.0, 1.0, 2.0, 0.5976505168532352, 1.0, 2.0, 0.5976505168532352, 1.0, 2.0, 0.9514790869488235, 6.911199999999999, 6.9112, 121.94756008, 2045031.890232057, 2045031.890232057, 394096.9606407356], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3508200.0000, 
sim time next is 3508800.0000, 
raw observation next is [28.16666666666666, 85.66666666666666, 1.0, 2.0, 0.9198804851660002, 1.0, 2.0, 0.9198804851660002, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2098485.647801395, 2098485.647801395, 395782.3659525889], 
processed observation next is [1.0, 0.6086956521739131, 0.5987654320987652, 0.8566666666666666, 1.0, 1.0, 0.9046196251976193, 1.0, 1.0, 0.9046196251976193, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.7494591599290696, 0.7494591599290696, 0.7611199345242095], 
reward next is 0.2389, 
noisyNet noise sample is [array([1.2235423], dtype=float32), -0.04820171]. 
=============================================
[2019-03-24 00:30:00,561] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.5996692e-18 1.0000000e+00 1.8366840e-26 5.1387287e-24 2.7031137e-29], sum to 1.0000
[2019-03-24 00:30:00,567] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6224
[2019-03-24 00:30:00,571] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.11666666666667, 93.16666666666667, 1.0, 2.0, 0.739287966639277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 842603.7581764528, 842603.7581764538, 183716.7778123635], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3887400.0000, 
sim time next is 3888000.0000, 
raw observation next is [26.0, 94.0, 1.0, 2.0, 0.7385263505095606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 841735.2292184276, 841735.2292184276, 183567.4584407163], 
processed observation next is [0.0, 0.0, 0.5185185185185185, 0.94, 1.0, 1.0, 0.688721845844715, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.300619724720867, 0.300619724720867, 0.3530143431552236], 
reward next is 0.6470, 
noisyNet noise sample is [array([0.17111143], dtype=float32), 0.41594398]. 
=============================================
[2019-03-24 00:30:00,592] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[63.13457]
 [63.13457]
 [63.13457]
 [63.13457]
 [63.13457]], R is [[63.15020752]
 [63.16540527]
 [63.18131638]
 [63.19986343]
 [63.21499252]].
[2019-03-24 00:30:05,718] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.5744732e-17 1.0000000e+00 8.6331976e-26 2.7591821e-23 4.7229496e-29], sum to 1.0000
[2019-03-24 00:30:05,726] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2063
[2019-03-24 00:30:05,732] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 91.66666666666666, 1.0, 2.0, 0.9345234462582778, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156443, 1066169.15065594, 1066169.15065594, 225345.4441119333], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3991200.0000, 
sim time next is 3991800.0000, 
raw observation next is [24.75, 91.83333333333333, 1.0, 2.0, 0.9144675083667446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1044024.007062391, 1044024.00706239, 220809.7872252928], 
processed observation next is [1.0, 0.17391304347826086, 0.4722222222222222, 0.9183333333333333, 1.0, 1.0, 0.8981756051985055, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3728657168079968, 0.3728657168079964, 0.42463420620248615], 
reward next is 0.5754, 
noisyNet noise sample is [array([-1.1311128], dtype=float32), -0.43183556]. 
=============================================
[2019-03-24 00:30:05,926] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.8914285e-16 1.0000000e+00 1.5970916e-25 2.0556258e-24 3.1934059e-28], sum to 1.0000
[2019-03-24 00:30:05,934] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5766
[2019-03-24 00:30:05,941] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2020849.589813647 W.
[2019-03-24 00:30:05,947] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.4, 87.66666666666667, 1.0, 2.0, 0.5905951566515385, 1.0, 1.0, 0.5905951566515385, 1.0, 1.0, 0.9402467237306821, 6.9112, 6.9112, 122.6481493992758, 2020849.589813647, 2020849.589813647, 390453.393339048], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3982800.0000, 
sim time next is 3983400.0000, 
raw observation next is [25.35, 88.0, 1.0, 2.0, 0.4745980570153059, 1.0, 2.0, 0.4745980570153059, 1.0, 2.0, 0.755575563348004, 6.9112, 6.9112, 121.94756008, 1623590.143885509, 1623590.143885509, 331296.5143142306], 
processed observation next is [1.0, 0.08695652173913043, 0.4944444444444445, 0.88, 1.0, 1.0, 0.3745214964467927, 1.0, 1.0, 0.3745214964467927, 1.0, 1.0, 0.6944694541850049, 0.0, 0.0, 0.8096049824067558, 0.5798536228162533, 0.5798536228162533, 0.6371086813735204], 
reward next is 0.3629, 
noisyNet noise sample is [array([-0.19521132], dtype=float32), -0.3421477]. 
=============================================
[2019-03-24 00:30:06,206] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.3968782e-15 1.0000000e+00 2.1173780e-24 2.6629647e-20 1.0810744e-26], sum to 1.0000
[2019-03-24 00:30:06,211] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8581
[2019-03-24 00:30:06,218] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1546094.347284603 W.
[2019-03-24 00:30:06,224] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.66666666666667, 94.00000000000001, 1.0, 2.0, 0.4519660471462251, 1.0, 2.0, 0.4519660471462251, 1.0, 1.0, 0.7195446665633236, 6.911200000000001, 6.9112, 121.94756008, 1546094.347284603, 1546094.347284602, 320593.6945191305], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4007400.0000, 
sim time next is 4008000.0000, 
raw observation next is [24.73333333333333, 94.0, 1.0, 2.0, 0.6922817979490676, 1.0, 2.0, 0.6922817979490676, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1578814.776497527, 1578814.776497528, 301253.315559344], 
processed observation next is [1.0, 0.391304347826087, 0.4716049382716048, 0.94, 1.0, 1.0, 0.6336688070822234, 1.0, 1.0, 0.6336688070822234, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5638624201776882, 0.5638624201776885, 0.5793332991525847], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9046749], dtype=float32), 0.058691923]. 
=============================================
[2019-03-24 00:30:06,244] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[56.14904]
 [56.14904]
 [56.14904]
 [56.14904]
 [56.14904]], R is [[55.5875473 ]
 [55.03167343]
 [54.92818832]
 [54.74397659]
 [54.56148529]].
[2019-03-24 00:30:07,856] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.2568085e-11 1.0000000e+00 4.7693977e-18 1.8594712e-16 7.9909214e-19], sum to 1.0000
[2019-03-24 00:30:07,872] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5581
[2019-03-24 00:30:07,881] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.0, 34.0, 1.0, 2.0, 0.4694272301067115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 560675.824354778, 560675.824354778, 138203.1077982534], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4212000.0000, 
sim time next is 4212600.0000, 
raw observation next is [33.83333333333334, 34.66666666666667, 1.0, 2.0, 0.4902584777314581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 584237.3744225979, 584237.3744225975, 141354.530929548], 
processed observation next is [1.0, 0.782608695652174, 0.8086419753086423, 0.34666666666666673, 1.0, 1.0, 0.39316485444221205, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20865620515092784, 0.20865620515092767, 0.2718356364029769], 
reward next is 0.7282, 
noisyNet noise sample is [array([0.9022564], dtype=float32), -0.6185509]. 
=============================================
[2019-03-24 00:30:09,298] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.5052090e-14 1.0000000e+00 8.4342888e-22 4.1650987e-20 1.7821541e-24], sum to 1.0000
[2019-03-24 00:30:09,304] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0590
[2019-03-24 00:30:09,308] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.16666666666666, 96.0, 1.0, 2.0, 0.6432201923596365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 734674.6909072524, 734674.6909072524, 165752.6029487009], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4054800.0000, 
sim time next is 4055400.0000, 
raw observation next is [24.25, 94.0, 1.0, 2.0, 0.6277624505740885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 719807.7341837866, 719807.7341837866, 163135.641455112], 
processed observation next is [1.0, 0.9565217391304348, 0.4537037037037037, 0.94, 1.0, 1.0, 0.5568600602072482, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2570741907799238, 0.2570741907799238, 0.3137223874136769], 
reward next is 0.6863, 
noisyNet noise sample is [array([-1.3907226], dtype=float32), 1.0263726]. 
=============================================
[2019-03-24 00:30:10,053] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.0800947e-18 1.0000000e+00 8.4339048e-29 8.2321999e-26 5.7492870e-32], sum to 1.0000
[2019-03-24 00:30:10,059] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1234
[2019-03-24 00:30:10,066] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.15, 96.5, 1.0, 2.0, 0.4678262314666509, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 576209.2482661438, 576209.2482661438, 138501.161176072], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4080600.0000, 
sim time next is 4081200.0000, 
raw observation next is [20.1, 97.66666666666666, 1.0, 2.0, 0.4457470319325644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 548340.6811479942, 548340.6811479942, 135154.6661254478], 
processed observation next is [1.0, 0.21739130434782608, 0.30000000000000004, 0.9766666666666666, 1.0, 1.0, 0.3401750380149576, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19583595755285507, 0.19583595755285507, 0.259912819472015], 
reward next is 0.7401, 
noisyNet noise sample is [array([-2.0755014], dtype=float32), -0.26899406]. 
=============================================
[2019-03-24 00:30:18,478] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.1825138e-19 1.0000000e+00 1.2533531e-30 1.4098463e-27 1.0832513e-31], sum to 1.0000
[2019-03-24 00:30:18,490] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6177
[2019-03-24 00:30:18,498] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 74.33333333333334, 1.0, 2.0, 0.5843962243930172, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 721161.3012016342, 721161.3012016342, 157548.1954942732], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4243200.0000, 
sim time next is 4243800.0000, 
raw observation next is [22.4, 76.16666666666666, 1.0, 2.0, 0.5468234927078347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 676119.8158428255, 676119.8158428255, 151186.5162142489], 
processed observation next is [1.0, 0.08695652173913043, 0.38518518518518513, 0.7616666666666666, 1.0, 1.0, 0.46050415798551747, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2414713628010091, 0.2414713628010091, 0.2907433004120171], 
reward next is 0.7093, 
noisyNet noise sample is [array([0.4486071], dtype=float32), 0.6374642]. 
=============================================
[2019-03-24 00:30:19,248] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3174645e-19 1.0000000e+00 1.4506306e-29 2.2376479e-27 2.1121903e-32], sum to 1.0000
[2019-03-24 00:30:19,255] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6984
[2019-03-24 00:30:19,259] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 74.33333333333334, 1.0, 2.0, 0.5843962243930172, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 721161.3012016342, 721161.3012016342, 157548.1954942732], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4243200.0000, 
sim time next is 4243800.0000, 
raw observation next is [22.4, 76.16666666666666, 1.0, 2.0, 0.5468234927078347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 676119.8158428255, 676119.8158428255, 151186.5162142489], 
processed observation next is [1.0, 0.08695652173913043, 0.38518518518518513, 0.7616666666666666, 1.0, 1.0, 0.46050415798551747, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2414713628010091, 0.2414713628010091, 0.2907433004120171], 
reward next is 0.7093, 
noisyNet noise sample is [array([-0.01623414], dtype=float32), -0.64740163]. 
=============================================
[2019-03-24 00:30:22,217] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.18721875e-16 1.00000000e+00 6.10175972e-25 3.01770371e-22
 1.26629285e-26], sum to 1.0000
[2019-03-24 00:30:22,222] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4237
[2019-03-24 00:30:22,225] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 74.0, 1.0, 2.0, 0.6131164073776061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 706066.4528876122, 706066.4528876122, 160707.257370925], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4311600.0000, 
sim time next is 4312200.0000, 
raw observation next is [27.0, 74.0, 1.0, 2.0, 0.6137890269806593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 706835.9890686683, 706835.9890686683, 160824.697162276], 
processed observation next is [1.0, 0.9130434782608695, 0.5555555555555556, 0.74, 1.0, 1.0, 0.5402250321198325, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25244142466738156, 0.25244142466738156, 0.3092782637736077], 
reward next is 0.6907, 
noisyNet noise sample is [array([-0.7634848], dtype=float32), -0.17308109]. 
=============================================
[2019-03-24 00:30:23,178] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.8568816e-19 1.0000000e+00 1.1596310e-30 1.4265685e-27 6.8011928e-32], sum to 1.0000
[2019-03-24 00:30:23,183] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9574
[2019-03-24 00:30:23,192] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.46666666666667, 82.33333333333334, 1.0, 2.0, 0.5443882045860622, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 642110.5865007332, 642110.5865007332, 149762.1769909678], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4326000.0000, 
sim time next is 4326600.0000, 
raw observation next is [24.33333333333334, 82.16666666666667, 1.0, 2.0, 0.5372210442668518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 635520.2301888248, 635520.2301888248, 148663.5569216581], 
processed observation next is [1.0, 0.043478260869565216, 0.4567901234567903, 0.8216666666666668, 1.0, 1.0, 0.4490726717462521, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22697151078172315, 0.22697151078172315, 0.28589145561857326], 
reward next is 0.7141, 
noisyNet noise sample is [array([0.98564345], dtype=float32), -0.029316526]. 
=============================================
[2019-03-24 00:30:25,303] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-24 00:30:25,305] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:30:25,307] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:30:25,315] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:30:25,317] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:30:25,318] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:30:25,320] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:30:25,320] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:30:25,321] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:30:25,322] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:30:25,322] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:30:25,346] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run82
[2019-03-24 00:30:25,369] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run82
[2019-03-24 00:30:25,371] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run82
[2019-03-24 00:30:25,372] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run82
[2019-03-24 00:30:25,420] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run82
[2019-03-24 00:30:48,800] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.10758892]
[2019-03-24 00:30:48,802] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.95, 93.50000000000001, 1.0, 2.0, 0.4736728456293824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 578943.8698578692, 578943.8698578692, 139277.2850250245]
[2019-03-24 00:30:48,803] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:30:48,807] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.0903857e-16 1.0000000e+00 3.3248680e-25 3.1806730e-23 4.8683434e-27], sampled 0.10057308261680364
[2019-03-24 00:30:50,394] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.10758892]
[2019-03-24 00:30:50,396] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [18.30710981333333, 84.22381969, 1.0, 2.0, 0.2956606049124343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 378888.9353058984, 378888.935305898, 115041.9749313326]
[2019-03-24 00:30:50,398] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:30:50,403] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.0903857e-16 1.0000000e+00 3.3248680e-25 3.1806730e-23 4.8683434e-27], sampled 0.8009319450414357
[2019-03-24 00:31:06,394] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.10758892]
[2019-03-24 00:31:06,398] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.11666666666667, 53.5, 1.0, 2.0, 0.485437578205541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 593913.2467645991, 593913.2467645991, 141112.4745942715]
[2019-03-24 00:31:06,400] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:31:06,403] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.0903857e-16 1.0000000e+00 3.3248680e-25 3.1806730e-23 4.8683434e-27], sampled 0.7696954303186291
[2019-03-24 00:31:40,666] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.10758892]
[2019-03-24 00:31:40,667] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.88531319666667, 90.63359852666667, 1.0, 2.0, 0.686903877747091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 782868.480501302, 782868.480501302, 173679.5342317302]
[2019-03-24 00:31:40,668] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:31:40,672] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [7.0903857e-16 1.0000000e+00 3.3248680e-25 3.1806730e-23 4.8683434e-27], sampled 0.022957112138154545
[2019-03-24 00:32:12,650] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 00:32:12,789] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 00:32:12,840] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 00:32:12,914] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 00:32:12,955] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 00:32:13,971] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 2025000, evaluation results [2025000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 00:32:18,028] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.8523037e-19 1.0000000e+00 1.4234244e-30 7.3024696e-30 4.0861967e-32], sum to 1.0000
[2019-03-24 00:32:18,039] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4437
[2019-03-24 00:32:18,046] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.9, 77.0, 1.0, 2.0, 0.6376975047696746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 727754.4905832832, 727754.4905832832, 164732.8213618477], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4444200.0000, 
sim time next is 4444800.0000, 
raw observation next is [26.86666666666667, 76.33333333333334, 1.0, 2.0, 0.632328222919329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 723774.7210932643, 723774.7210932638, 163883.7900131957], 
processed observation next is [0.0, 0.43478260869565216, 0.5506172839506175, 0.7633333333333334, 1.0, 1.0, 0.5622955034753917, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.258490971819023, 0.2584909718190228, 0.315161134640761], 
reward next is 0.6848, 
noisyNet noise sample is [array([-2.0829725], dtype=float32), -0.66339105]. 
=============================================
[2019-03-24 00:32:20,989] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.0888134e-18 1.0000000e+00 1.9052266e-28 7.7340564e-26 2.7398824e-31], sum to 1.0000
[2019-03-24 00:32:21,001] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7264
[2019-03-24 00:32:21,017] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1854863.522686751 W.
[2019-03-24 00:32:21,019] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.9996675479903658, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1854863.522686751, 1854863.522686751, 379353.5577593552], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4795800.0000, 
sim time next is 4796400.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.6333580333420605, 1.0, 1.0, 0.6333580333420605, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1444306.774463165, 1444306.774463166, 279706.6792834121], 
processed observation next is [1.0, 0.5217391304347826, 0.5185185185185185, 0.89, 1.0, 1.0, 0.5635214682643578, 1.0, 0.5, 0.5635214682643578, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.515823848022559, 0.5158238480225593, 0.537897460160408], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.457824], dtype=float32), 1.7126496]. 
=============================================
[2019-03-24 00:32:24,415] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.5522908e-18 1.0000000e+00 1.4357272e-30 2.0929631e-26 7.3886538e-32], sum to 1.0000
[2019-03-24 00:32:24,424] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8215
[2019-03-24 00:32:24,429] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 100.0, 1.0, 2.0, 0.5899673678709547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 684687.6299580224, 684687.6299580224, 156950.3573207229], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4548000.0000, 
sim time next is 4548600.0000, 
raw observation next is [23.0, 100.0, 1.0, 2.0, 0.5888154923415688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 683354.0126905383, 683354.0126905383, 156753.2271978864], 
processed observation next is [0.0, 0.6521739130434783, 0.4074074074074074, 1.0, 1.0, 1.0, 0.5104946337399628, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2440550045323351, 0.2440550045323351, 0.3014485138420892], 
reward next is 0.6986, 
noisyNet noise sample is [array([-0.61298007], dtype=float32), -1.8691733]. 
=============================================
[2019-03-24 00:32:25,730] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.07697146e-17 1.00000000e+00 1.07469587e-28 5.59358388e-27
 7.91394481e-30], sum to 1.0000
[2019-03-24 00:32:25,738] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1145
[2019-03-24 00:32:25,742] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 98.0, 1.0, 2.0, 0.4896455103047287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 587154.631144536, 587154.631144536, 141391.2481097938], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4586400.0000, 
sim time next is 4587000.0000, 
raw observation next is [21.5, 98.33333333333334, 1.0, 2.0, 0.7865505204837915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 122.2837805496811, 943407.5784880484, 943407.5784880479, 195401.7936060465], 
processed observation next is [1.0, 0.08695652173913043, 0.35185185185185186, 0.9833333333333334, 1.0, 1.0, 0.7458934767664184, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8118371366807928, 0.33693127803144585, 0.3369312780314457, 0.3757726800116279], 
reward next is 0.6242, 
noisyNet noise sample is [array([0.31200537], dtype=float32), -1.1906195]. 
=============================================
[2019-03-24 00:32:25,764] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[68.98802]
 [68.98802]
 [68.98802]
 [68.98802]
 [68.98802]], R is [[68.92236328]
 [68.96123505]
 [69.00034332]
 [69.03975677]
 [69.07961273]].
[2019-03-24 00:32:26,117] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.2982246e-18 1.0000000e+00 6.5596680e-29 1.1097256e-26 6.0221675e-32], sum to 1.0000
[2019-03-24 00:32:26,125] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0571
[2019-03-24 00:32:26,133] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.31666666666667, 99.33333333333334, 1.0, 2.0, 0.4962766267248202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 595537.9283003111, 595537.9283003111, 142441.2958198189], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4578600.0000, 
sim time next is 4579200.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.485498669125758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 585090.7789500315, 585090.7789500315, 140847.245355948], 
processed observation next is [1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.38749841562590237, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2089609924821541, 0.2089609924821541, 0.2708600872229769], 
reward next is 0.7291, 
noisyNet noise sample is [array([-0.14445616], dtype=float32), -0.03932012]. 
=============================================
[2019-03-24 00:32:28,729] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.4420263e-14 1.0000000e+00 1.7701761e-23 1.3685353e-20 4.4904453e-25], sum to 1.0000
[2019-03-24 00:32:28,734] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7640
[2019-03-24 00:32:28,740] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1790212.172218556 W.
[2019-03-24 00:32:28,743] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.66666666666667, 65.83333333333334, 1.0, 2.0, 0.5232552553243183, 1.0, 2.0, 0.5232552553243183, 1.0, 1.0, 0.8330394077102701, 6.911200000000001, 6.9112, 121.94756008, 1790212.172218556, 1790212.172218556, 355149.5992529562], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4639800.0000, 
sim time next is 4640400.0000, 
raw observation next is [29.6, 65.0, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 7.175788514170749, 6.9112, 121.9251763954801, 2013711.022160385, 1878219.016857941, 383183.7352170671], 
processed observation next is [1.0, 0.7391304347826086, 0.6518518518518519, 0.65, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 0.026458851417074936, 0.0, 0.8094563780189349, 0.7191825079144232, 0.6707925060206932, 0.7368917984943598], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0332677], dtype=float32), 1.3254914]. 
=============================================
[2019-03-24 00:32:31,989] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0652083e-17 1.0000000e+00 6.0588639e-28 9.5914728e-25 3.2903260e-30], sum to 1.0000
[2019-03-24 00:32:31,996] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2316
[2019-03-24 00:32:32,002] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 85.66666666666667, 1.0, 2.0, 0.6852771126488032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 781013.5019618964, 781013.5019618964, 173375.9017401159], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4990800.0000, 
sim time next is 4991400.0000, 
raw observation next is [26.5, 86.5, 1.0, 2.0, 0.6881858257256694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 784330.2718419184, 784330.2718419184, 173919.5616812157], 
processed observation next is [1.0, 0.782608695652174, 0.5370370370370371, 0.865, 1.0, 1.0, 0.628792649673416, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28011795422925656, 0.28011795422925656, 0.33446069554079944], 
reward next is 0.6655, 
noisyNet noise sample is [array([-0.38921592], dtype=float32), 0.040595602]. 
=============================================
[2019-03-24 00:32:36,271] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.7211770e-17 1.0000000e+00 1.2386821e-27 1.9455369e-24 1.0547781e-28], sum to 1.0000
[2019-03-24 00:32:36,280] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4097
[2019-03-24 00:32:36,286] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 78.0, 1.0, 2.0, 0.6002352684911779, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 715399.1818101091, 715399.1818101091, 159507.9042993387], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4953600.0000, 
sim time next is 4954200.0000, 
raw observation next is [24.58333333333334, 78.83333333333333, 1.0, 2.0, 0.6426762023879594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 764585.5794506848, 764585.5794506858, 167027.4465527595], 
processed observation next is [1.0, 0.34782608695652173, 0.4660493827160496, 0.7883333333333333, 1.0, 1.0, 0.5746145266523326, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.2730662783752446, 0.27306627837524494, 0.32120662798607597], 
reward next is 0.6788, 
noisyNet noise sample is [array([0.38576603], dtype=float32), 0.90166706]. 
=============================================
[2019-03-24 00:32:43,756] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.9865794e-17 1.0000000e+00 4.2694104e-25 2.0047793e-22 1.8351204e-28], sum to 1.0000
[2019-03-24 00:32:43,767] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4015
[2019-03-24 00:32:43,773] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.18333333333333, 92.66666666666667, 1.0, 2.0, 0.8788151756388153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1001733.885485655, 1001733.885485654, 212774.4716153327], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4913400.0000, 
sim time next is 4914000.0000, 
raw observation next is [28.0, 94.0, 1.0, 2.0, 0.8810913866892764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1004330.167460785, 1004330.167460785, 213276.3099089607], 
processed observation next is [1.0, 0.9130434782608695, 0.5925925925925926, 0.94, 1.0, 1.0, 0.8584421270110434, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.35868934552170895, 0.35868934552170895, 0.41014674982492444], 
reward next is 0.5899, 
noisyNet noise sample is [array([1.587938], dtype=float32), 1.875227]. 
=============================================
[2019-03-24 00:32:43,798] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[60.87642]
 [60.87642]
 [60.87642]
 [60.87642]
 [60.87642]], R is [[60.8575058 ]
 [60.83974838]
 [60.8228302 ]
 [60.80642319]
 [60.79061508]].
[2019-03-24 00:32:57,197] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.0664425e-18 1.0000000e+00 6.5308549e-29 1.8778456e-26 8.4754365e-31], sum to 1.0000
[2019-03-24 00:32:57,205] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3038
[2019-03-24 00:32:57,213] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2049597.679499898 W.
[2019-03-24 00:32:57,217] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.3, 88.0, 1.0, 2.0, 0.898474793842267, 1.0, 2.0, 0.898474793842267, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260425084035, 2049597.679499898, 2049597.679499898, 386127.7980700257], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5475600.0000, 
sim time next is 5476200.0000, 
raw observation next is [28.43333333333334, 87.50000000000001, 1.0, 2.0, 0.6302465056047843, 1.0, 2.0, 0.6284879147788268, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2150677.904392376, 2150677.904392376, 411022.0715859083], 
processed observation next is [1.0, 0.391304347826087, 0.6086419753086423, 0.8750000000000001, 1.0, 1.0, 0.5598172685771242, 1.0, 1.0, 0.5577237080700319, 1.0, 0.5, 0.9972168686025908, 0.0, 0.0, 0.8096049824067558, 0.7680992515687057, 0.7680992515687057, 0.7904270607421313], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.73214203], dtype=float32), 0.6756059]. 
=============================================
[2019-03-24 00:33:00,190] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.8335879e-13 1.0000000e+00 1.2901489e-21 6.8467662e-19 1.9946718e-22], sum to 1.0000
[2019-03-24 00:33:00,197] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1972
[2019-03-24 00:33:00,205] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2064980.074389297 W.
[2019-03-24 00:33:00,207] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.13333333333333, 73.0, 1.0, 2.0, 0.6034735439837455, 1.0, 2.0, 0.6034735439837455, 1.0, 2.0, 0.96074953578335, 6.911200000000001, 6.9112, 121.94756008, 2064980.074389297, 2064980.074389296, 397271.409266212], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5242200.0000, 
sim time next is 5242800.0000, 
raw observation next is [29.26666666666667, 72.0, 1.0, 2.0, 0.8898131039081052, 1.0, 2.0, 0.8898131039081052, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2029816.204790492, 2029816.204790492, 382264.7000601271], 
processed observation next is [1.0, 0.6956521739130435, 0.6395061728395063, 0.72, 1.0, 1.0, 0.8688251237001252, 1.0, 1.0, 0.8688251237001252, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.7249343588537471, 0.7249343588537471, 0.7351244231925522], 
reward next is 0.2649, 
noisyNet noise sample is [array([-0.68224], dtype=float32), -1.7551026]. 
=============================================
[2019-03-24 00:33:00,392] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.957267e-13 1.000000e+00 9.373028e-20 3.943995e-19 7.673592e-22], sum to 1.0000
[2019-03-24 00:33:00,398] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3905
[2019-03-24 00:33:00,406] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.61666666666667, 87.33333333333333, 1.0, 2.0, 0.6548021054484232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 746264.0875455833, 746264.0875455833, 167761.848516209], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5273400.0000, 
sim time next is 5274000.0000, 
raw observation next is [25.6, 87.0, 1.0, 2.0, 0.6492839682388071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 739972.1479863283, 739972.1479863283, 166762.9130553889], 
processed observation next is [1.0, 0.043478260869565216, 0.5037037037037038, 0.87, 1.0, 1.0, 0.5824809145700084, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2642757671379744, 0.2642757671379744, 0.3206979097219017], 
reward next is 0.6793, 
noisyNet noise sample is [array([-0.5766266], dtype=float32), 0.046701774]. 
=============================================
[2019-03-24 00:33:00,412] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.21461435e-13 1.00000000e+00 2.84075007e-21 1.03238306e-19
 2.77444526e-22], sum to 1.0000
[2019-03-24 00:33:00,419] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6006
[2019-03-24 00:33:00,423] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[43.621834]
 [43.621834]
 [43.621834]
 [43.621834]
 [43.621834]], R is [[43.86491776]
 [44.10364914]
 [44.33871841]
 [44.57090378]
 [44.79995728]].
[2019-03-24 00:33:00,434] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1979592.481092851 W.
[2019-03-24 00:33:00,441] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.66666666666666, 71.5, 1.0, 2.0, 0.8678208419508383, 1.0, 2.0, 0.8678208419508383, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1979592.481092851, 1979592.481092851, 372576.7493899771], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5230200.0000, 
sim time next is 5230800.0000, 
raw observation next is [30.0, 70.0, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 8.859160130695846, 6.9112, 121.9180849004128, 2876590.623434368, 1879126.035327828, 377107.1019226803], 
processed observation next is [1.0, 0.5652173913043478, 0.6666666666666666, 0.7, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, 0.19479601306958463, 0.0, 0.8094092978663231, 1.027353794083703, 0.67111644118851, 0.7252059652359236], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6294301], dtype=float32), 0.5082243]. 
=============================================
[2019-03-24 00:33:03,349] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.0492429e-18 1.0000000e+00 5.4990514e-28 6.8996556e-25 1.1814295e-30], sum to 1.0000
[2019-03-24 00:33:03,355] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5626
[2019-03-24 00:33:03,360] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.96666666666667, 88.33333333333334, 1.0, 2.0, 0.4782902832544462, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7665418907020649, 6.9112, 6.9112, 121.9258591645552, 1129483.720127803, 1129483.720127803, 248588.9174237262], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5303400.0000, 
sim time next is 5304000.0000, 
raw observation next is [23.13333333333334, 87.66666666666667, 1.0, 2.0, 0.8651998365630807, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260425597225, 1028514.919260851, 1028514.919260852, 211861.4844265482], 
processed observation next is [1.0, 0.391304347826087, 0.4123456790123459, 0.8766666666666667, 1.0, 1.0, 0.8395236149560485, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621284487572, 0.36732675687887534, 0.3673267568788757, 0.4074259315895158], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.19807902], dtype=float32), -0.70406854]. 
=============================================
[2019-03-24 00:33:03,373] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[65.08178]
 [65.08178]
 [65.08178]
 [65.08178]
 [65.08178]], R is [[64.43096161]
 [63.78665161]
 [63.14878464]
 [63.0050354 ]
 [62.37498474]].
[2019-03-24 00:33:03,636] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-24 00:33:03,640] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:33:03,641] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:33:03,642] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:33:03,643] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:33:03,644] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:33:03,645] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:33:03,646] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:33:03,649] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:33:03,643] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:33:03,650] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:33:03,666] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run83
[2019-03-24 00:33:03,692] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run83
[2019-03-24 00:33:03,717] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run83
[2019-03-24 00:33:03,718] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run83
[2019-03-24 00:33:03,764] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run83
[2019-03-24 00:33:05,123] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0948094]
[2019-03-24 00:33:05,125] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [18.55, 69.5, 1.0, 2.0, 0.2267714151773852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 292509.901114371, 292509.901114371, 95164.1488762965]
[2019-03-24 00:33:05,125] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:33:05,127] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.7630320e-17 1.0000000e+00 7.5764520e-27 1.0168363e-24 9.2334805e-29], sampled 0.5582300231481028
[2019-03-24 00:33:17,281] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0948094]
[2019-03-24 00:33:17,284] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [19.21666666666667, 77.83333333333333, 1.0, 2.0, 0.2981838286482383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 381382.3113779348, 381382.3113779348, 115352.6252718801]
[2019-03-24 00:33:17,285] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:33:17,289] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.7630320e-17 1.0000000e+00 7.5764520e-27 1.0168363e-24 9.2334805e-29], sampled 0.22362764856220319
[2019-03-24 00:33:21,702] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0948094]
[2019-03-24 00:33:21,702] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.41837970666667, 61.53871201333334, 1.0, 2.0, 0.4185348006672726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 513375.0785360895, 513375.0785360895, 131132.4869276777]
[2019-03-24 00:33:21,706] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:33:21,712] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.7630320e-17 1.0000000e+00 7.5764520e-27 1.0168363e-24 9.2334805e-29], sampled 0.9084996748127637
[2019-03-24 00:33:26,638] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0948094]
[2019-03-24 00:33:26,638] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.0, 61.0, 1.0, 2.0, 0.3653081025247344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 456471.1179105428, 456471.1179105428, 123916.9605799742]
[2019-03-24 00:33:26,640] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:33:26,643] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.7630320e-17 1.0000000e+00 7.5764520e-27 1.0168363e-24 9.2334805e-29], sampled 0.4278064900891322
[2019-03-24 00:33:40,972] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0948094]
[2019-03-24 00:33:40,972] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.33333333333334, 72.33333333333334, 1.0, 2.0, 0.5589320255755945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 653846.88069046, 653846.88069046, 151943.4986263032]
[2019-03-24 00:33:40,973] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:33:40,975] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.7630320e-17 1.0000000e+00 7.5764520e-27 1.0168363e-24 9.2334805e-29], sampled 0.037069110040495956
[2019-03-24 00:33:43,167] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0948094]
[2019-03-24 00:33:43,168] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.27064766, 99.94917066000001, 1.0, 2.0, 0.489000300564024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 587942.9561106539, 587942.9561106539, 141345.4137116111]
[2019-03-24 00:33:43,170] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:33:43,173] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.7630320e-17 1.0000000e+00 7.5764520e-27 1.0168363e-24 9.2334805e-29], sampled 0.557168621611488
[2019-03-24 00:33:43,395] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0948094]
[2019-03-24 00:33:43,396] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.0, 82.5, 1.0, 2.0, 1.007137629873883, 1.0, 2.0, 1.007137629873883, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2297797.942608556, 2297797.942608556, 436782.6510504903]
[2019-03-24 00:33:43,396] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:33:43,399] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.7630320e-17 1.0000000e+00 7.5764520e-27 1.0168363e-24 9.2334805e-29], sampled 0.8990926052704166
[2019-03-24 00:33:43,402] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2297797.942608556 W.
[2019-03-24 00:33:48,795] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0948094]
[2019-03-24 00:33:48,796] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [35.6, 30.5, 1.0, 2.0, 0.8162031995187179, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9815308975367127, 6.911199999999999, 6.9112, 121.9260426156618, 1662872.109286901, 1662872.109286902, 336690.8710654462]
[2019-03-24 00:33:48,798] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:33:48,801] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.7630320e-17 1.0000000e+00 7.5764520e-27 1.0168363e-24 9.2334805e-29], sampled 0.07280466811344832
[2019-03-24 00:33:48,802] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1662872.109286901 W.
[2019-03-24 00:33:58,136] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0948094]
[2019-03-24 00:33:58,137] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.65, 90.0, 1.0, 2.0, 0.4566332529957027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 555985.3329643497, 555985.3329643497, 136625.41463578]
[2019-03-24 00:33:58,138] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:33:58,142] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.7630320e-17 1.0000000e+00 7.5764520e-27 1.0168363e-24 9.2334805e-29], sampled 0.7480525195977447
[2019-03-24 00:34:06,683] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0948094]
[2019-03-24 00:34:06,684] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.1, 65.5, 1.0, 2.0, 0.6851519831807749, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.925323683636, 1495854.382220768, 1495854.382220768, 314554.0564329664]
[2019-03-24 00:34:06,684] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:34:06,687] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.7630320e-17 1.0000000e+00 7.5764520e-27 1.0168363e-24 9.2334805e-29], sampled 0.9284598558189772
[2019-03-24 00:34:06,687] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1495854.382220768 W.
[2019-03-24 00:34:08,092] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0948094]
[2019-03-24 00:34:08,094] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.987697255, 104.8299687083333, 1.0, 2.0, 0.5815767434573837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 676147.164413411, 676147.1644134106, 155573.0253682536]
[2019-03-24 00:34:08,096] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:34:08,098] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.7630320e-17 1.0000000e+00 7.5764520e-27 1.0168363e-24 9.2334805e-29], sampled 0.8746198646199543
[2019-03-24 00:34:35,279] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0948094]
[2019-03-24 00:34:35,281] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.8, 78.0, 1.0, 2.0, 0.4291414769872715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 525901.6028709454, 525901.6028709454, 132655.1261700755]
[2019-03-24 00:34:35,282] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:34:35,285] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.7630320e-17 1.0000000e+00 7.5764520e-27 1.0168363e-24 9.2334805e-29], sampled 0.22968073177319814
[2019-03-24 00:34:50,560] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 00:34:50,657] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 00:34:50,740] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 00:34:50,784] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 00:34:50,940] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 00:34:51,957] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 2050000, evaluation results [2050000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 00:34:52,601] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.8606632e-16 1.0000000e+00 4.8415475e-26 1.5984653e-22 4.3823534e-28], sum to 1.0000
[2019-03-24 00:34:52,607] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8335
[2019-03-24 00:34:52,611] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.31666666666666, 74.33333333333334, 1.0, 2.0, 0.6267917534622638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 715940.8744332732, 715940.8744332737, 162827.6415798493], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5346600.0000, 
sim time next is 5347200.0000, 
raw observation next is [27.23333333333333, 74.66666666666667, 1.0, 2.0, 0.6223710949060081, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 711330.9323446238, 711330.9323446234, 162069.9800174295], 
processed observation next is [1.0, 0.9130434782608695, 0.5641975308641974, 0.7466666666666667, 1.0, 1.0, 0.5504417796500096, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.25404676155165135, 0.2540467615516512, 0.31167303849505673], 
reward next is 0.6883, 
noisyNet noise sample is [array([1.4943101], dtype=float32), 0.3288387]. 
=============================================
[2019-03-24 00:34:57,915] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.3107793e-14 1.0000000e+00 5.1743943e-23 3.1759476e-21 1.3359893e-24], sum to 1.0000
[2019-03-24 00:34:57,920] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1313
[2019-03-24 00:34:57,930] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1602765.430691171 W.
[2019-03-24 00:34:57,934] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 81.0, 1.0, 2.0, 0.7027741246196036, 1.0, 2.0, 0.7027741246196036, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1602765.430691171, 1602765.430691171, 305216.7308049368], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5392800.0000, 
sim time next is 5393400.0000, 
raw observation next is [27.16666666666666, 80.16666666666667, 1.0, 2.0, 0.9998422847540922, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1855063.012390576, 1855063.012390577, 379393.9262248068], 
processed observation next is [1.0, 0.43478260869565216, 0.5617283950617282, 0.8016666666666667, 1.0, 1.0, 0.9998122437548717, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6625225044252058, 0.6625225044252061, 0.7296037042784747], 
reward next is 0.2704, 
noisyNet noise sample is [array([-0.1292061], dtype=float32), -0.57926446]. 
=============================================
[2019-03-24 00:35:07,638] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0276319e-13 1.0000000e+00 2.2122243e-23 8.4182858e-21 8.8842711e-26], sum to 1.0000
[2019-03-24 00:35:07,645] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0950
[2019-03-24 00:35:07,650] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1384910.198513151 W.
[2019-03-24 00:35:07,654] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.71666666666667, 79.33333333333334, 1.0, 2.0, 0.6073349498200191, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9668970196319061, 6.911199999999999, 6.9112, 121.9260426156618, 1384910.198513151, 1384910.198513152, 296724.7174202061], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5568600.0000, 
sim time next is 5569200.0000, 
raw observation next is [26.8, 79.0, 1.0, 2.0, 0.718604653968115, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1534036.52157956, 1534036.521579561, 320632.4337465102], 
processed observation next is [1.0, 0.4782608695652174, 0.5481481481481482, 0.79, 1.0, 1.0, 0.6650055404382321, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5478701862784142, 0.5478701862784147, 0.6166008341279042], 
reward next is 0.3834, 
noisyNet noise sample is [array([1.0764616], dtype=float32), 0.040946]. 
=============================================
[2019-03-24 00:35:13,402] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.3901863e-17 1.0000000e+00 3.3233396e-29 5.0800404e-25 1.9109831e-29], sum to 1.0000
[2019-03-24 00:35:13,408] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3468
[2019-03-24 00:35:13,414] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.18333333333334, 93.66666666666667, 1.0, 2.0, 0.5533873227214262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 650048.0915623149, 650048.0915623144, 151137.8781468041], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5701800.0000, 
sim time next is 5702400.0000, 
raw observation next is [23.1, 94.0, 1.0, 2.0, 0.5505829811972482, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 647286.0818777919, 647286.0818777919, 150696.1030139421], 
processed observation next is [0.0, 0.0, 0.41111111111111115, 0.94, 1.0, 1.0, 0.4649797395205336, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23117360067063997, 0.23117360067063997, 0.2898001981037348], 
reward next is 0.7102, 
noisyNet noise sample is [array([-1.2772396], dtype=float32), 0.10561676]. 
=============================================
[2019-03-24 00:35:13,914] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.2704032e-20 1.0000000e+00 3.2577289e-30 5.5656554e-28 2.7099341e-32], sum to 1.0000
[2019-03-24 00:35:13,919] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1618
[2019-03-24 00:35:13,924] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.95, 97.0, 1.0, 2.0, 0.5092100330453363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 607666.6994001782, 607666.6994001782, 144361.5665911681], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5710200.0000, 
sim time next is 5710800.0000, 
raw observation next is [21.9, 97.0, 1.0, 2.0, 0.5073335924601324, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 605987.5222317474, 605987.5222317474, 144084.5163284274], 
processed observation next is [0.0, 0.08695652173913043, 0.36666666666666664, 0.97, 1.0, 1.0, 0.41349237197634814, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21642411508276693, 0.21642411508276693, 0.27708560832389884], 
reward next is 0.7229, 
noisyNet noise sample is [array([-0.824742], dtype=float32), 0.56540734]. 
=============================================
[2019-03-24 00:35:14,820] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4409703e-18 1.0000000e+00 9.3473430e-30 1.9916700e-28 1.6145131e-32], sum to 1.0000
[2019-03-24 00:35:14,826] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7410
[2019-03-24 00:35:14,833] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.6, 95.66666666666666, 1.0, 2.0, 0.5380245497184571, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 636104.9230310883, 636104.9230310883, 148780.3495015105], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5705400.0000, 
sim time next is 5706000.0000, 
raw observation next is [22.5, 96.0, 1.0, 2.0, 0.5350670661116638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 633332.6251288911, 633332.6251288911, 148326.7380706022], 
processed observation next is [0.0, 0.043478260869565216, 0.3888888888888889, 0.96, 1.0, 1.0, 0.4465084120376949, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22619022326031823, 0.22619022326031823, 0.2852437270588504], 
reward next is 0.7148, 
noisyNet noise sample is [array([-1.5864351], dtype=float32), -0.91542083]. 
=============================================
[2019-03-24 00:35:14,856] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[76.3726]
 [76.3726]
 [76.3726]
 [76.3726]
 [76.3726]], R is [[76.32363129]
 [76.27427673]
 [76.22438812]
 [76.17379761]
 [76.12291718]].
[2019-03-24 00:35:16,518] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.0668552e-19 1.0000000e+00 3.4868943e-31 5.1314901e-28 2.1422139e-32], sum to 1.0000
[2019-03-24 00:35:16,527] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7207
[2019-03-24 00:35:16,534] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.4, 74.0, 1.0, 2.0, 0.5708042198235168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 664864.2054856966, 664864.2054856966, 153806.6022367868], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5770800.0000, 
sim time next is 5771400.0000, 
raw observation next is [26.23333333333333, 74.66666666666667, 1.0, 2.0, 0.5679535832223236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 662255.8335748088, 662255.8335748088, 153359.1038053811], 
processed observation next is [0.0, 0.8260869565217391, 0.5271604938271603, 0.7466666666666667, 1.0, 1.0, 0.4856590276456233, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2365199405624317, 0.2365199405624317, 0.29492135347188675], 
reward next is 0.7051, 
noisyNet noise sample is [array([-0.10665416], dtype=float32), -1.171358]. 
=============================================
[2019-03-24 00:35:30,397] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.1030056e-16 1.0000000e+00 1.1406983e-24 5.7652359e-23 1.4877268e-26], sum to 1.0000
[2019-03-24 00:35:30,404] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3541
[2019-03-24 00:35:30,412] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1764527.866524772 W.
[2019-03-24 00:35:30,416] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 56.0, 1.0, 2.0, 0.5157554799236446, 1.0, 2.0, 0.5157554799236446, 1.0, 1.0, 0.8210995210217648, 6.9112, 6.9112, 121.94756008, 1764527.866524772, 1764527.866524772, 351389.3263936819], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6021600.0000, 
sim time next is 6022200.0000, 
raw observation next is [29.0, 55.5, 1.0, 2.0, 0.7638505638863204, 1.0, 2.0, 0.7638505638863204, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1747405.423729334, 1747405.423729335, 329316.872948232], 
processed observation next is [1.0, 0.6956521739130435, 0.6296296296296297, 0.555, 1.0, 1.0, 0.7188697189122862, 1.0, 1.0, 0.7188697189122862, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6240733656176193, 0.6240733656176196, 0.6333016787465999], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.20674945], dtype=float32), -1.4903265]. 
=============================================
[2019-03-24 00:35:32,039] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.0083953e-19 1.0000000e+00 5.1125127e-30 6.7682850e-28 1.8286039e-32], sum to 1.0000
[2019-03-24 00:35:32,045] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2710
[2019-03-24 00:35:32,050] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.7, 68.0, 1.0, 2.0, 0.53157685498925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 627423.874803813, 627423.874803813, 147688.5035493986], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6033600.0000, 
sim time next is 6034200.0000, 
raw observation next is [26.58333333333333, 68.5, 1.0, 2.0, 0.5314543853025507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 627501.3068747489, 627501.3068747489, 147677.5293536417], 
processed observation next is [1.0, 0.8695652173913043, 0.5401234567901233, 0.685, 1.0, 1.0, 0.44220760155065564, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22410760959812462, 0.22410760959812462, 0.28399524875700327], 
reward next is 0.7160, 
noisyNet noise sample is [array([1.0207161], dtype=float32), 0.058842313]. 
=============================================
[2019-03-24 00:35:32,653] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.4070059e-17 1.0000000e+00 3.4592762e-28 9.5993325e-27 1.2651852e-29], sum to 1.0000
[2019-03-24 00:35:32,662] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3864
[2019-03-24 00:35:32,668] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2210739.722806599 W.
[2019-03-24 00:35:32,674] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.53333333333333, 51.66666666666667, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 7.560150345749154, 6.9112, 121.9235127762199, 2210739.722806599, 1878426.038568066, 381799.5672495501], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6099600.0000, 
sim time next is 6100200.0000, 
raw observation next is [30.5, 52.0, 1.0, 2.0, 0.9105586355547696, 1.0, 1.0, 0.9105586355547696, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9256518285686, 2077195.367653838, 2077195.367653838, 391555.2400698164], 
processed observation next is [1.0, 0.6086956521739131, 0.6851851851851852, 0.52, 1.0, 1.0, 0.8935221851842495, 1.0, 0.5, 0.8935221851842495, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094595344002271, 0.7418554884477992, 0.7418554884477992, 0.7529908462881085], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5036587], dtype=float32), 0.3362043]. 
=============================================
[2019-03-24 00:35:36,946] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0669402e-18 1.0000000e+00 3.4303253e-29 1.3145510e-29 3.5185734e-32], sum to 1.0000
[2019-03-24 00:35:36,950] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5173
[2019-03-24 00:35:36,956] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.65, 69.0, 1.0, 2.0, 0.5421877155717058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 638415.0841002653, 638415.0841002653, 149356.2520180021], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6125400.0000, 
sim time next is 6126000.0000, 
raw observation next is [26.56666666666666, 69.33333333333333, 1.0, 2.0, 0.5418404163150948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 638313.9322040154, 638313.9322040151, 149311.9670174203], 
processed observation next is [1.0, 0.9130434782608695, 0.5395061728395059, 0.6933333333333332, 1.0, 1.0, 0.45457192418463666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2279692615014341, 0.22796926150143396, 0.2871383981104237], 
reward next is 0.7129, 
noisyNet noise sample is [array([-0.4502188], dtype=float32), -0.73500174]. 
=============================================
[2019-03-24 00:35:36,968] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[71.41812]
 [71.41812]
 [71.41812]
 [71.41812]
 [71.41812]], R is [[71.41680145]
 [71.4154129 ]
 [71.41388702]
 [71.41196442]
 [71.40962219]].
[2019-03-24 00:35:41,684] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-24 00:35:41,687] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:35:41,687] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:35:41,688] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:35:41,689] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:35:41,690] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:35:41,690] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:35:41,691] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:35:41,691] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:35:41,692] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:35:41,693] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:35:41,716] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run84
[2019-03-24 00:35:41,745] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run84
[2019-03-24 00:35:41,768] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run84
[2019-03-24 00:35:41,769] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run84
[2019-03-24 00:35:41,825] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run84
[2019-03-24 00:35:45,429] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.07487926]
[2019-03-24 00:35:45,430] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [32.913844645, 28.41589120833333, 1.0, 2.0, 0.3830764380276907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 474077.6987808908, 474077.6987808908, 126248.0277382401]
[2019-03-24 00:35:45,434] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:35:45,436] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.7778208e-18 1.0000000e+00 2.1300836e-29 4.8398462e-27 1.9354259e-31], sampled 0.7483848449908274
[2019-03-24 00:35:52,681] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.07487926]
[2019-03-24 00:35:52,682] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [18.75, 35.0, 1.0, 2.0, 0.2252674572772786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 290569.5952446765, 290569.5952446765, 78297.46782509478]
[2019-03-24 00:35:52,683] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:35:52,686] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.7778208e-18 1.0000000e+00 2.1300836e-29 4.8398462e-27 1.9354259e-31], sampled 0.1907118989398755
[2019-03-24 00:35:55,960] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.07487926]
[2019-03-24 00:35:55,961] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [33.0, 24.0, 1.0, 2.0, 0.6235460527491428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 779774.7496382772, 779774.7496382772, 164705.743122242]
[2019-03-24 00:35:55,962] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:35:55,966] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.7778208e-18 1.0000000e+00 2.1300836e-29 4.8398462e-27 1.9354259e-31], sampled 0.8461390670391192
[2019-03-24 00:36:13,674] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.07487926]
[2019-03-24 00:36:13,676] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.5, 43.5, 1.0, 2.0, 0.6295682753187045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 722563.0314031927, 722563.0314031922, 163489.5309367838]
[2019-03-24 00:36:13,676] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:36:13,679] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.7778208e-18 1.0000000e+00 2.1300836e-29 4.8398462e-27 1.9354259e-31], sampled 0.9784033847837843
[2019-03-24 00:36:16,466] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.07487926]
[2019-03-24 00:36:16,466] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.50652372, 63.48495849, 1.0, 2.0, 0.5261129725556061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 621503.2756055149, 621503.2756055144, 146826.6457342698]
[2019-03-24 00:36:16,467] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:36:16,472] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.7778208e-18 1.0000000e+00 2.1300836e-29 4.8398462e-27 1.9354259e-31], sampled 0.4629634143640443
[2019-03-24 00:36:28,007] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.07487926]
[2019-03-24 00:36:28,008] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.0, 54.5, 1.0, 2.0, 0.6631746223338001, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426156304, 1470770.92999405, 1470770.929994049, 310670.4987232278]
[2019-03-24 00:36:28,008] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:36:28,011] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.7778208e-18 1.0000000e+00 2.1300836e-29 4.8398462e-27 1.9354259e-31], sampled 0.5267723933988392
[2019-03-24 00:36:28,013] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1470770.92999405 W.
[2019-03-24 00:36:34,016] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.07487926]
[2019-03-24 00:36:34,018] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.33333333333334, 67.66666666666667, 1.0, 2.0, 0.7761942524843201, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 884691.9900825083, 884691.9900825083, 191077.9826159291]
[2019-03-24 00:36:34,019] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:36:34,022] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.7778208e-18 1.0000000e+00 2.1300836e-29 4.8398462e-27 1.9354259e-31], sampled 0.06748999899280761
[2019-03-24 00:36:55,123] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.07487926]
[2019-03-24 00:36:55,125] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.0, 94.0, 1.0, 2.0, 0.6249205126147891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 712192.8489809054, 712192.8489809054, 162418.5379890014]
[2019-03-24 00:36:55,126] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:36:55,129] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.7778208e-18 1.0000000e+00 2.1300836e-29 4.8398462e-27 1.9354259e-31], sampled 0.28596011803184984
[2019-03-24 00:36:58,772] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.07487926]
[2019-03-24 00:36:58,773] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.03333333333333, 83.66666666666667, 1.0, 2.0, 0.5692167462264173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 662601.0310407811, 662601.0310407811, 153521.6059305991]
[2019-03-24 00:36:58,775] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:36:58,777] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.7778208e-18 1.0000000e+00 2.1300836e-29 4.8398462e-27 1.9354259e-31], sampled 0.46045342792626487
[2019-03-24 00:37:00,312] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.07487926]
[2019-03-24 00:37:00,314] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.9, 49.0, 1.0, 2.0, 0.5467753174195374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 641133.6365797037, 641133.6365797032, 149997.9688422817]
[2019-03-24 00:37:00,314] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:37:00,316] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.7778208e-18 1.0000000e+00 2.1300836e-29 4.8398462e-27 1.9354259e-31], sampled 0.7648297495705073
[2019-03-24 00:37:20,907] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.07487926]
[2019-03-24 00:37:20,909] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.20066607666666, 69.11307551333333, 1.0, 2.0, 0.4012234590049541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 493079.7143327915, 493079.7143327915, 128694.093490697]
[2019-03-24 00:37:20,911] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:37:20,913] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.7778208e-18 1.0000000e+00 2.1300836e-29 4.8398462e-27 1.9354259e-31], sampled 0.8432447449904412
[2019-03-24 00:37:29,038] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 00:37:29,147] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 00:37:29,301] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 00:37:29,303] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 00:37:29,313] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 00:37:30,330] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 2075000, evaluation results [2075000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 00:37:33,320] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.8932241e-18 1.0000000e+00 5.6106528e-29 9.3935861e-25 1.3368628e-29], sum to 1.0000
[2019-03-24 00:37:33,327] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9253
[2019-03-24 00:37:33,333] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666666, 84.33333333333333, 1.0, 2.0, 0.5676646365629173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 663814.5876128008, 663814.5876128008, 153393.3632568787], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6307800.0000, 
sim time next is 6308400.0000, 
raw observation next is [24.63333333333333, 84.66666666666667, 1.0, 2.0, 0.5680117045376761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 664046.8248260171, 664046.8248260171, 153444.1466019438], 
processed observation next is [0.0, 0.0, 0.46790123456790106, 0.8466666666666667, 1.0, 1.0, 0.4857282196877097, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2371595802950061, 0.2371595802950061, 0.2950848973114304], 
reward next is 0.7049, 
noisyNet noise sample is [array([0.34782398], dtype=float32), -0.94689614]. 
=============================================
[2019-03-24 00:37:33,498] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.9785972e-20 1.0000000e+00 7.9787618e-28 1.1696612e-25 2.7320992e-29], sum to 1.0000
[2019-03-24 00:37:33,507] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9878
[2019-03-24 00:37:33,511] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.46666666666667, 86.33333333333334, 1.0, 2.0, 0.5734593131208833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 669545.532335665, 669545.532335665, 154323.921626353], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6311400.0000, 
sim time next is 6312000.0000, 
raw observation next is [24.43333333333334, 86.66666666666667, 1.0, 2.0, 0.5742936660962548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 670351.0677679334, 670351.0677679334, 154457.4849294374], 
processed observation next is [0.0, 0.043478260869565216, 0.4604938271604941, 0.8666666666666667, 1.0, 1.0, 0.4932067453526842, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23941109563140478, 0.23941109563140478, 0.2970336248643027], 
reward next is 0.7030, 
noisyNet noise sample is [array([0.19177237], dtype=float32), 0.7992773]. 
=============================================
[2019-03-24 00:37:33,530] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[65.25692]
 [65.25692]
 [65.25692]
 [65.25692]
 [65.25692]], R is [[65.30731964]
 [65.35746765]
 [65.40740204]
 [65.45713806]
 [65.5067749 ]].
[2019-03-24 00:37:44,825] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9097673e-17 1.0000000e+00 1.6229051e-24 5.5053833e-23 1.8762417e-26], sum to 1.0000
[2019-03-24 00:37:44,834] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1581
[2019-03-24 00:37:44,844] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1318453.945279335 W.
[2019-03-24 00:37:44,849] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.8, 82.0, 1.0, 2.0, 0.3854776970259548, 1.0, 2.0, 0.3854776970259548, 1.0, 1.0, 0.6136930477974626, 6.9112, 6.9112, 121.94756008, 1318453.945279335, 1318453.945279335, 290779.0130332595], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6489000.0000, 
sim time next is 6489600.0000, 
raw observation next is [26.76666666666667, 82.33333333333333, 1.0, 2.0, 0.5013854595244869, 1.0, 2.0, 0.5013854595244869, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426155619, 1143132.554267045, 1143132.554267045, 235811.7299338742], 
processed observation next is [1.0, 0.08695652173913043, 0.5469135802469137, 0.8233333333333333, 1.0, 1.0, 0.40641126133867483, 1.0, 1.0, 0.40641126133867483, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288194727, 0.4082616265239447, 0.4082616265239447, 0.4534840960266811], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.03835609], dtype=float32), 1.2630482]. 
=============================================
[2019-03-24 00:37:47,076] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.4504235e-12 1.0000000e+00 3.1096163e-21 4.5322777e-19 7.3163853e-22], sum to 1.0000
[2019-03-24 00:37:47,084] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3353
[2019-03-24 00:37:47,088] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.2, 85.0, 1.0, 2.0, 0.7093769431456124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 808494.6765562912, 808494.6765562912, 177928.6725031548], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6548400.0000, 
sim time next is 6549000.0000, 
raw observation next is [27.13333333333333, 85.50000000000001, 1.0, 2.0, 0.7116904817464083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 811132.8696934327, 811132.8696934327, 178370.8463065555], 
processed observation next is [1.0, 0.8260869565217391, 0.5604938271604937, 0.8550000000000001, 1.0, 1.0, 0.6567743830314384, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2896903106047974, 0.2896903106047974, 0.3430208582818375], 
reward next is 0.6570, 
noisyNet noise sample is [array([0.7931566], dtype=float32), 0.46940294]. 
=============================================
[2019-03-24 00:37:47,110] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[48.90772]
 [48.90772]
 [48.90772]
 [48.90772]
 [48.90772]], R is [[49.07562256]
 [49.24269485]
 [49.40977859]
 [49.57682419]
 [49.7447052 ]].
[2019-03-24 00:37:48,990] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.6889304e-19 1.0000000e+00 1.0136342e-30 1.4173316e-26 4.1697474e-32], sum to 1.0000
[2019-03-24 00:37:48,998] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6234
[2019-03-24 00:37:49,002] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.43333333333333, 51.33333333333333, 1.0, 2.0, 0.3775980824452433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 478312.4833680392, 478312.4833680392, 125678.8448900079], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6594000.0000, 
sim time next is 6594600.0000, 
raw observation next is [24.36666666666667, 51.66666666666667, 1.0, 2.0, 0.3690168466289894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 467478.9231557175, 467478.9231557175, 124507.1630464031], 
processed observation next is [1.0, 0.30434782608695654, 0.4580246913580248, 0.5166666666666667, 1.0, 1.0, 0.2488295793202255, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1669567582698991, 0.1669567582698991, 0.23943685201231366], 
reward next is 0.7606, 
noisyNet noise sample is [array([-0.75031245], dtype=float32), -0.15276417]. 
=============================================
[2019-03-24 00:37:53,117] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.8276796e-21 1.0000000e+00 1.5532662e-32 5.7608651e-29 3.2154373e-33], sum to 1.0000
[2019-03-24 00:37:53,129] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6088
[2019-03-24 00:37:53,140] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.21666666666667, 51.16666666666667, 1.0, 2.0, 0.376815483784276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 482693.0523720703, 482693.0523720703, 125595.3107556165], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6682200.0000, 
sim time next is 6682800.0000, 
raw observation next is [23.43333333333334, 50.33333333333334, 1.0, 2.0, 0.4705817381555523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 602336.7627038907, 602336.7627038902, 139251.9643351559], 
processed observation next is [1.0, 0.34782608695652173, 0.42345679012345705, 0.5033333333333334, 1.0, 1.0, 0.36974016447089564, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21512027239424666, 0.2151202723942465, 0.26779223910606903], 
reward next is 0.7322, 
noisyNet noise sample is [array([0.31964713], dtype=float32), 0.40590563]. 
=============================================
[2019-03-24 00:37:57,301] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9031277e-20 1.0000000e+00 2.9786557e-31 2.5587490e-29 6.4852540e-35], sum to 1.0000
[2019-03-24 00:37:57,313] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8173
[2019-03-24 00:37:57,316] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.25, 84.0, 1.0, 2.0, 0.3411026552211762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 437197.6729404968, 437197.6729404964, 120806.0428680504], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6755400.0000, 
sim time next is 6756000.0000, 
raw observation next is [18.16666666666667, 84.33333333333334, 1.0, 2.0, 0.3329347918984714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 426913.1180678604, 426913.11806786, 119742.4029301858], 
processed observation next is [1.0, 0.17391304347826086, 0.22839506172839524, 0.8433333333333334, 1.0, 1.0, 0.20587475226008503, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1524689707385216, 0.15246897073852145, 0.23027385178881885], 
reward next is 0.7697, 
noisyNet noise sample is [array([-0.07198004], dtype=float32), 0.3227369]. 
=============================================
[2019-03-24 00:37:57,344] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[78.33771]
 [78.33771]
 [78.33771]
 [78.33771]
 [78.33771]], R is [[78.32406616]
 [78.3085022 ]
 [78.29098511]
 [78.26650238]
 [78.25614929]].
[2019-03-24 00:38:02,571] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.2881909e-18 1.0000000e+00 7.5778395e-27 7.3809503e-28 9.8793501e-31], sum to 1.0000
[2019-03-24 00:38:02,578] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7330
[2019-03-24 00:38:02,585] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.81666666666667, 88.83333333333334, 1.0, 2.0, 0.3656277161631885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 457971.0973072104, 457971.0973072104, 123979.3247839935], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7163400.0000, 
sim time next is 7164000.0000, 
raw observation next is [19.8, 89.0, 1.0, 2.0, 0.3679258012408874, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 460826.0895088419, 460826.0895088419, 124289.7046231619], 
processed observation next is [1.0, 0.9565217391304348, 0.2888888888888889, 0.89, 1.0, 1.0, 0.2475307157629612, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16458074625315783, 0.16458074625315783, 0.23901866273684982], 
reward next is 0.7610, 
noisyNet noise sample is [array([-0.5212416], dtype=float32), 1.201709]. 
=============================================
[2019-03-24 00:38:02,597] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[69.84459]
 [69.84459]
 [69.84459]
 [69.84459]
 [69.84459]], R is [[69.90712738]
 [69.96963501]
 [70.03209686]
 [70.09394073]
 [70.15522003]].
[2019-03-24 00:38:04,857] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.9579540e-18 1.0000000e+00 2.0966369e-28 3.2254999e-25 1.1278699e-30], sum to 1.0000
[2019-03-24 00:38:04,865] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8521
[2019-03-24 00:38:04,872] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333334, 57.33333333333334, 1.0, 2.0, 0.4578550625095087, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 555977.8706047739, 555977.8706047734, 136763.9601366578], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6895200.0000, 
sim time next is 6895800.0000, 
raw observation next is [26.7, 57.5, 1.0, 2.0, 0.4542724941885968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 552426.3162521408, 552426.3162521413, 136250.3760305796], 
processed observation next is [0.0, 0.8260869565217391, 0.5444444444444444, 0.575, 1.0, 1.0, 0.3503243978435676, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19729511294719315, 0.19729511294719332, 0.26201995390496075], 
reward next is 0.7380, 
noisyNet noise sample is [array([-0.47531098], dtype=float32), 0.8660874]. 
=============================================
[2019-03-24 00:38:12,038] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.1430548e-20 1.0000000e+00 2.1646255e-30 1.2334281e-29 2.2392806e-33], sum to 1.0000
[2019-03-24 00:38:12,043] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5270
[2019-03-24 00:38:12,050] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 87.0, 1.0, 2.0, 0.4946124618754451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 610530.3801565828, 610530.3801565828, 142689.4460914669], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7012800.0000, 
sim time next is 7013400.0000, 
raw observation next is [21.01666666666667, 87.66666666666667, 1.0, 2.0, 0.5481723195881592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 676657.2751228169, 676657.2751228169, 151384.4194440593], 
processed observation next is [1.0, 0.17391304347826086, 0.3339506172839507, 0.8766666666666667, 1.0, 1.0, 0.462109904271618, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24166331254386317, 0.24166331254386317, 0.2911238835462679], 
reward next is 0.7089, 
noisyNet noise sample is [array([1.2037475], dtype=float32), 1.3285016]. 
=============================================
[2019-03-24 00:38:15,447] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.05078385e-18 1.00000000e+00 1.61683910e-29 2.03119450e-26
 1.00408245e-30], sum to 1.0000
[2019-03-24 00:38:15,451] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2105
[2019-03-24 00:38:15,459] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 82.0, 1.0, 2.0, 0.4864112974547585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 584636.4465450408, 584636.4465450408, 140936.3698471362], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7077600.0000, 
sim time next is 7078200.0000, 
raw observation next is [23.51666666666667, 82.00000000000001, 1.0, 2.0, 0.4874199933667194, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 585664.9700193924, 585664.9700193924, 141086.5413068859], 
processed observation next is [1.0, 0.9565217391304348, 0.4265432098765433, 0.8200000000000002, 1.0, 1.0, 0.3897857063889516, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20916606072121158, 0.20916606072121158, 0.27132027174401135], 
reward next is 0.7287, 
noisyNet noise sample is [array([-0.22337705], dtype=float32), -0.69716096]. 
=============================================
[2019-03-24 00:38:17,534] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0832218e-17 1.0000000e+00 1.4763618e-28 1.5345198e-25 1.5901337e-29], sum to 1.0000
[2019-03-24 00:38:17,538] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9277
[2019-03-24 00:38:17,543] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.8, 93.33333333333333, 1.0, 2.0, 0.3819378418192347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 475240.9952889422, 475240.9952889422, 126146.579307154], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7175400.0000, 
sim time next is 7176000.0000, 
raw observation next is [19.8, 93.66666666666667, 1.0, 2.0, 0.3829225307563668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 476212.9006011125, 476212.900601112, 126277.139942002], 
processed observation next is [1.0, 0.043478260869565216, 0.2888888888888889, 0.9366666666666668, 1.0, 1.0, 0.2653839651861509, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17007603592896875, 0.17007603592896856, 0.24284065373461924], 
reward next is 0.7572, 
noisyNet noise sample is [array([-1.5709975], dtype=float32), -0.4809118]. 
=============================================
[2019-03-24 00:38:17,565] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[72.27554]
 [72.27554]
 [72.27554]
 [72.27554]
 [72.27554]], R is [[72.30994415]
 [72.34425354]
 [72.37873077]
 [72.41373444]
 [72.44908142]].
[2019-03-24 00:38:19,096] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.06685826e-19 1.00000000e+00 8.66835395e-31 2.19042753e-28
 1.01794990e-32], sum to 1.0000
[2019-03-24 00:38:19,106] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1598
[2019-03-24 00:38:19,115] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.05, 75.5, 1.0, 2.0, 0.5009502607539799, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 596024.7641865816, 596024.7641865811, 142989.9042389468], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7479000.0000, 
sim time next is 7479600.0000, 
raw observation next is [25.16666666666666, 75.0, 1.0, 2.0, 0.5030415437532999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 598094.6477220455, 598094.647722046, 143303.1420661158], 
processed observation next is [0.0, 0.5652173913043478, 0.4876543209876541, 0.75, 1.0, 1.0, 0.40838279018249984, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21360523132930198, 0.21360523132930215, 0.27558296551176115], 
reward next is 0.7244, 
noisyNet noise sample is [array([-0.43324333], dtype=float32), 0.9552708]. 
=============================================
[2019-03-24 00:38:19,115] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.6076873e-19 1.0000000e+00 1.5253779e-28 1.3193458e-26 6.0110590e-32], sum to 1.0000
[2019-03-24 00:38:19,126] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1225
[2019-03-24 00:38:19,134] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 60.66666666666667, 1.0, 2.0, 0.7793286017603701, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 974234.697860783, 974234.697860783, 195042.0005182442], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7136400.0000, 
sim time next is 7137000.0000, 
raw observation next is [23.85, 61.0, 1.0, 2.0, 0.7752830534295493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 969131.4845427837, 969131.4845427832, 194198.5020030016], 
processed observation next is [1.0, 0.6086956521739131, 0.43888888888888894, 0.61, 1.0, 1.0, 0.7324798255113681, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.34611838733670847, 0.3461183873367083, 0.37345865769808], 
reward next is 0.6265, 
noisyNet noise sample is [array([-0.10298347], dtype=float32), -1.1815958]. 
=============================================
[2019-03-24 00:38:19,154] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[74.88658]
 [74.88658]
 [74.88658]
 [74.88658]
 [74.88658]], R is [[74.76425171]
 [74.64152527]
 [74.51245117]
 [74.38484955]
 [74.26387024]].
[2019-03-24 00:38:19,744] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-24 00:38:19,745] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:38:19,746] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:38:19,746] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:38:19,747] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:38:19,747] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:38:19,747] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:38:19,747] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:38:19,748] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:38:19,748] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:38:19,753] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:38:19,776] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run85
[2019-03-24 00:38:19,802] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run85
[2019-03-24 00:38:19,826] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run85
[2019-03-24 00:38:19,827] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run85
[2019-03-24 00:38:19,882] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run85
[2019-03-24 00:38:22,733] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.038650557]
[2019-03-24 00:38:22,735] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [18.66666666666667, 48.33333333333334, 1.0, 2.0, 0.2249872147780612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 290208.0456626163, 290208.0456626163, 81645.35726274863]
[2019-03-24 00:38:22,735] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:38:22,739] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.5046203e-19 1.0000000e+00 3.7908835e-31 1.2183941e-28 2.8156170e-33], sampled 0.46600816829819935
[2019-03-24 00:38:36,567] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.038650557]
[2019-03-24 00:38:36,569] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [34.25, 25.0, 1.0, 2.0, 0.9472010769546569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.285726898795612, 6.9112, 121.9242662046402, 1358024.158532422, 1166235.705832293, 232103.5080897655]
[2019-03-24 00:38:36,570] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:38:36,574] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.5046203e-19 1.0000000e+00 3.7908835e-31 1.2183941e-28 2.8156170e-33], sampled 0.8233500144487561
[2019-03-24 00:38:36,576] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1358024.158532422 W.
[2019-03-24 00:39:07,035] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.038650557]
[2019-03-24 00:39:07,035] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.83333333333334, 59.5, 1.0, 2.0, 0.9050140419135153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1031617.254769674, 1031617.254769673, 218588.8273104979]
[2019-03-24 00:39:07,037] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:39:07,041] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.5046203e-19 1.0000000e+00 3.7908835e-31 1.2183941e-28 2.8156170e-33], sampled 0.3406166276372544
[2019-03-24 00:39:41,651] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.038650557]
[2019-03-24 00:39:41,653] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.15865399, 48.77989454, 1.0, 2.0, 0.4913145692731302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 591020.1989122945, 591020.198912294, 141715.1394180573]
[2019-03-24 00:39:41,654] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:39:41,657] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.5046203e-19 1.0000000e+00 3.7908835e-31 1.2183941e-28 2.8156170e-33], sampled 0.18775000592914348
[2019-03-24 00:39:48,114] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.038650557]
[2019-03-24 00:39:48,115] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.01666666666667, 73.5, 1.0, 2.0, 0.9880502621295214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.071037369364934, 6.9112, 121.9253410844645, 1208249.777846264, 1126399.229579239, 237852.0003110407]
[2019-03-24 00:39:48,116] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:39:48,121] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.5046203e-19 1.0000000e+00 3.7908835e-31 1.2183941e-28 2.8156170e-33], sampled 0.5119336845612332
[2019-03-24 00:39:54,771] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.038650557]
[2019-03-24 00:39:54,772] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.30699052, 74.142366995, 1.0, 2.0, 0.5000851864678655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 595804.8838570405, 595804.8838570405, 142884.9052055913]
[2019-03-24 00:39:54,773] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:39:54,776] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.5046203e-19 1.0000000e+00 3.7908835e-31 1.2183941e-28 2.8156170e-33], sampled 0.1264890895036097
[2019-03-24 00:40:07,580] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 00:40:07,694] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 00:40:07,727] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 00:40:07,824] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 00:40:07,895] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 00:40:08,915] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 2100000, evaluation results [2100000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 00:40:15,813] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.0330016e-18 1.0000000e+00 4.3434562e-29 4.1104103e-26 4.1116524e-32], sum to 1.0000
[2019-03-24 00:40:15,822] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9433
[2019-03-24 00:40:15,828] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1373032.049366217 W.
[2019-03-24 00:40:15,834] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.9, 61.0, 1.0, 2.0, 0.3940212007334566, 1.0, 2.0, 0.3940212007334566, 1.0, 1.0, 0.6286405744974753, 6.9112, 6.9112, 121.94756008, 1373032.049366217, 1373032.049366217, 294542.6964805342], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7316400.0000, 
sim time next is 7317000.0000, 
raw observation next is [26.9, 61.0, 1.0, 2.0, 0.3732552053636318, 1.0, 2.0, 0.3732552053636318, 1.0, 2.0, 0.595324250799423, 6.9112, 6.9112, 121.94756008, 1298430.867141559, 1298430.867141559, 285625.254284035], 
processed observation next is [1.0, 0.6956521739130435, 0.5518518518518518, 0.61, 1.0, 1.0, 0.2538752444805141, 1.0, 1.0, 0.2538752444805141, 1.0, 1.0, 0.49415531349927866, 0.0, 0.0, 0.8096049824067558, 0.4637253096934139, 0.4637253096934139, 0.5492793351616058], 
reward next is 0.4507, 
noisyNet noise sample is [array([2.8609953], dtype=float32), 2.5008242]. 
=============================================
[2019-03-24 00:40:15,859] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[71.46405]
 [71.46405]
 [71.46405]
 [71.46405]
 [71.46405]], R is [[71.20013428]
 [70.48813629]
 [69.78325653]
 [69.47453308]
 [69.21974182]].
[2019-03-24 00:40:25,863] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.8168310e-18 1.0000000e+00 5.6790175e-30 1.4910434e-28 4.3414783e-32], sum to 1.0000
[2019-03-24 00:40:25,870] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5019
[2019-03-24 00:40:25,876] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 90.0, 1.0, 2.0, 0.4988357179932236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 595573.9374663914, 595573.9374663914, 142734.5847357158], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7502400.0000, 
sim time next is 7503000.0000, 
raw observation next is [22.75, 90.16666666666667, 1.0, 2.0, 0.4975755980044434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 594380.6618371808, 594380.6618371808, 142548.3080495407], 
processed observation next is [0.0, 0.8695652173913043, 0.39814814814814814, 0.9016666666666667, 1.0, 1.0, 0.40187571191005167, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21227880779899316, 0.21227880779899316, 0.27413136163373214], 
reward next is 0.7259, 
noisyNet noise sample is [array([-0.33174646], dtype=float32), 0.6845835]. 
=============================================
[2019-03-24 00:40:25,891] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[77.08587]
 [77.08587]
 [77.08587]
 [77.08587]
 [77.08587]], R is [[77.04087067]
 [76.99597168]
 [76.95145416]
 [76.90703583]
 [76.86232758]].
[2019-03-24 00:40:31,869] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.9304704e-19 1.0000000e+00 4.7939383e-30 2.2335630e-27 3.9204038e-32], sum to 1.0000
[2019-03-24 00:40:31,880] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8640
[2019-03-24 00:40:31,886] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.23333333333333, 82.33333333333334, 1.0, 2.0, 0.5185570612384228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 614689.676513498, 614689.6765134975, 145696.5626484852], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7589400.0000, 
sim time next is 7590000.0000, 
raw observation next is [24.16666666666667, 82.66666666666667, 1.0, 2.0, 0.5187675649650323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 615154.7032985943, 615154.7032985943, 145738.6370561701], 
processed observation next is [0.0, 0.8695652173913043, 0.45061728395061745, 0.8266666666666667, 1.0, 1.0, 0.4271042440059908, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21969810832092654, 0.21969810832092654, 0.280266609723404], 
reward next is 0.7197, 
noisyNet noise sample is [array([-1.6547502], dtype=float32), -1.197551]. 
=============================================
[2019-03-24 00:40:31,913] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[73.74428]
 [73.74428]
 [73.74428]
 [73.74428]
 [73.74428]], R is [[73.72657013]
 [73.7091217 ]
 [73.69203186]
 [73.67537689]
 [73.65909576]].
[2019-03-24 00:40:34,325] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:40:34,325] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:40:34,368] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run11
[2019-03-24 00:40:36,143] A3C_AGENT_WORKER-Thread-22 INFO:Local step 132500, global step 2113703: loss 0.0009
[2019-03-24 00:40:36,146] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 132500, global step 2113704: learning rate 0.0005
[2019-03-24 00:40:36,176] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3514272e-18 1.0000000e+00 4.0278695e-31 1.4624940e-28 1.1829965e-34], sum to 1.0000
[2019-03-24 00:40:36,182] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2653
[2019-03-24 00:40:36,185] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.61666666666667, 85.33333333333334, 1.0, 2.0, 0.3385942369323159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 427448.1318835791, 427448.1318835791, 120442.2441809481], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7685400.0000, 
sim time next is 7686000.0000, 
raw observation next is [19.6, 86.0, 1.0, 2.0, 0.3400644004480801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 428982.3128328914, 428982.3128328914, 120630.1886110381], 
processed observation next is [1.0, 1.0, 0.28148148148148155, 0.86, 1.0, 1.0, 0.21436238148580966, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1532079688688898, 0.1532079688688898, 0.23198113194430403], 
reward next is 0.7680, 
noisyNet noise sample is [array([1.7055367], dtype=float32), 2.0222144]. 
=============================================
[2019-03-24 00:40:36,204] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[76.24251]
 [76.24251]
 [76.24251]
 [76.24251]
 [76.24251]], R is [[76.24810791]
 [76.25400543]
 [76.25995636]
 [76.2658844 ]
 [76.27227783]].
[2019-03-24 00:40:40,270] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:40:40,271] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:40:40,324] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run11
[2019-03-24 00:40:42,069] A3C_AGENT_WORKER-Thread-18 INFO:Local step 132500, global step 2116808: loss 0.0481
[2019-03-24 00:40:42,072] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 132500, global step 2116809: learning rate 0.0005
[2019-03-24 00:40:44,256] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.8530900e-19 1.0000000e+00 7.8801193e-29 1.4478292e-27 2.3159321e-32], sum to 1.0000
[2019-03-24 00:40:44,262] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2634
[2019-03-24 00:40:44,268] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1325883.719222858 W.
[2019-03-24 00:40:44,274] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 33.5, 1.0, 2.0, 0.3681814404334016, 1.0, 1.0, 0.3681814404334016, 1.0, 2.0, 0.5944999664535764, 6.911200000000001, 6.9112, 121.94756008, 1325883.719222858, 1325883.719222857, 282928.2902668589], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7833000.0000, 
sim time next is 7833600.0000, 
raw observation next is [31.0, 33.0, 1.0, 2.0, 0.5327102065140044, 1.0, 2.0, 0.5327102065140044, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156291, 1289614.045520629, 1289614.045520628, 248808.6527717814], 
processed observation next is [1.0, 0.6956521739130435, 0.7037037037037037, 0.33, 1.0, 1.0, 0.44370262680238615, 1.0, 1.0, 0.44370262680238615, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288199189, 0.46057644482879606, 0.46057644482879573, 0.4784781784072719], 
reward next is 0.5215, 
noisyNet noise sample is [array([-1.2608974], dtype=float32), 0.18894441]. 
=============================================
[2019-03-24 00:40:48,232] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:40:48,233] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:40:48,281] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run11
[2019-03-24 00:40:48,513] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:40:48,514] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:40:48,558] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run11
[2019-03-24 00:40:48,860] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:40:48,861] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:40:48,908] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run11
[2019-03-24 00:40:49,191] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:40:49,191] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:40:49,197] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run11
[2019-03-24 00:40:49,460] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:40:49,460] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:40:49,466] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run11
[2019-03-24 00:40:49,496] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:40:49,496] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:40:49,502] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run11
[2019-03-24 00:40:49,560] A3C_AGENT_WORKER-Thread-22 INFO:Local step 133000, global step 2120518: loss 0.0007
[2019-03-24 00:40:49,561] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 133000, global step 2120518: learning rate 0.0005
[2019-03-24 00:40:49,611] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:40:49,611] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:40:49,615] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run11
[2019-03-24 00:40:49,802] A3C_AGENT_WORKER-Thread-2 INFO:Local step 132500, global step 2120590: loss 0.0029
[2019-03-24 00:40:49,804] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 132500, global step 2120590: learning rate 0.0005
[2019-03-24 00:40:49,824] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:40:49,824] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:40:49,834] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run11
[2019-03-24 00:40:49,964] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:40:49,964] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:40:49,965] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:40:49,966] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:40:49,972] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run11
[2019-03-24 00:40:50,006] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run11
[2019-03-24 00:40:50,105] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:40:50,105] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:40:50,108] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run11
[2019-03-24 00:40:50,184] A3C_AGENT_WORKER-Thread-21 INFO:Local step 132500, global step 2120665: loss 0.0005
[2019-03-24 00:40:50,185] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 132500, global step 2120665: learning rate 0.0005
[2019-03-24 00:40:50,245] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:40:50,245] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:40:50,249] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run11
[2019-03-24 00:40:50,324] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:40:50,325] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:40:50,334] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run11
[2019-03-24 00:40:50,433] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 00:40:50,433] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:40:50,437] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run11
[2019-03-24 00:40:51,089] A3C_AGENT_WORKER-Thread-11 INFO:Local step 132500, global step 2120790: loss 0.0004
[2019-03-24 00:40:51,090] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 132500, global step 2120790: learning rate 0.0005
[2019-03-24 00:40:51,203] A3C_AGENT_WORKER-Thread-14 INFO:Local step 132500, global step 2120830: loss 0.0004
[2019-03-24 00:40:51,204] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 132500, global step 2120830: learning rate 0.0005
[2019-03-24 00:40:51,460] A3C_AGENT_WORKER-Thread-19 INFO:Local step 132500, global step 2120937: loss 0.0029
[2019-03-24 00:40:51,465] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 132500, global step 2120938: learning rate 0.0005
[2019-03-24 00:40:51,487] A3C_AGENT_WORKER-Thread-9 INFO:Local step 132500, global step 2120944: loss 0.0005
[2019-03-24 00:40:51,491] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 132500, global step 2120944: learning rate 0.0005
[2019-03-24 00:40:51,552] A3C_AGENT_WORKER-Thread-13 INFO:Local step 132500, global step 2120973: loss 0.0000
[2019-03-24 00:40:51,553] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 132500, global step 2120974: learning rate 0.0005
[2019-03-24 00:40:51,792] A3C_AGENT_WORKER-Thread-16 INFO:Local step 132500, global step 2121098: loss 0.0006
[2019-03-24 00:40:51,797] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 132500, global step 2121098: learning rate 0.0005
[2019-03-24 00:40:51,940] A3C_AGENT_WORKER-Thread-12 INFO:Local step 132500, global step 2121186: loss 0.0000
[2019-03-24 00:40:51,941] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 132500, global step 2121188: learning rate 0.0005
[2019-03-24 00:40:52,017] A3C_AGENT_WORKER-Thread-17 INFO:Local step 132500, global step 2121225: loss 0.0004
[2019-03-24 00:40:52,020] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 132500, global step 2121228: learning rate 0.0005
[2019-03-24 00:40:52,104] A3C_AGENT_WORKER-Thread-3 INFO:Local step 132500, global step 2121286: loss 0.0036
[2019-03-24 00:40:52,105] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 132500, global step 2121287: learning rate 0.0005
[2019-03-24 00:40:52,261] A3C_AGENT_WORKER-Thread-10 INFO:Local step 132500, global step 2121373: loss 0.0020
[2019-03-24 00:40:52,262] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 132500, global step 2121373: learning rate 0.0005
[2019-03-24 00:40:52,293] A3C_AGENT_WORKER-Thread-20 INFO:Local step 132500, global step 2121384: loss 0.0001
[2019-03-24 00:40:52,295] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 132500, global step 2121385: learning rate 0.0005
[2019-03-24 00:40:52,506] A3C_AGENT_WORKER-Thread-15 INFO:Local step 132500, global step 2121503: loss 0.0002
[2019-03-24 00:40:52,509] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 132500, global step 2121503: learning rate 0.0005
[2019-03-24 00:40:55,062] A3C_AGENT_WORKER-Thread-18 INFO:Local step 133000, global step 2122807: loss 0.0804
[2019-03-24 00:40:55,064] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 133000, global step 2122807: learning rate 0.0005
[2019-03-24 00:40:56,968] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.8696749e-19 1.0000000e+00 1.4869926e-29 8.7336640e-26 6.4618996e-33], sum to 1.0000
[2019-03-24 00:40:56,974] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3367
[2019-03-24 00:40:56,977] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 74.33333333333334, 1.0, 2.0, 0.4179660163344289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 520461.4568880743, 520461.4568880743, 131233.9405592615], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 111000.0000, 
sim time next is 111600.0000, 
raw observation next is [22.3, 74.0, 1.0, 2.0, 0.4136813112113084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 514799.7847577648, 514799.7847577648, 130611.1060573111], 
processed observation next is [1.0, 0.30434782608695654, 0.38148148148148153, 0.74, 1.0, 1.0, 0.3020015609658434, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.183857065984916, 0.183857065984916, 0.2511752039563675], 
reward next is 0.7488, 
noisyNet noise sample is [array([-2.6572237], dtype=float32), -0.4517952]. 
=============================================
[2019-03-24 00:40:59,323] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-24 00:40:59,324] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:40:59,324] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:40:59,325] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:40:59,325] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:40:59,326] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:40:59,326] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:40:59,326] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:40:59,327] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:40:59,328] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:40:59,328] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:40:59,352] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run86
[2019-03-24 00:40:59,352] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run86
[2019-03-24 00:40:59,399] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run86
[2019-03-24 00:40:59,425] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run86
[2019-03-24 00:40:59,462] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run86
[2019-03-24 00:41:10,884] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), -0.0018540764]
[2019-03-24 00:41:10,885] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.16489171, 65.967110975, 1.0, 2.0, 0.4052802860140675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 500256.8711133399, 500256.8711133399, 129321.2863897205]
[2019-03-24 00:41:10,886] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:41:10,889] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.5539055e-17 1.0000000e+00 6.5052012e-27 8.8983175e-25 7.5045901e-29], sampled 0.7131337128629859
[2019-03-24 00:41:25,606] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), -0.0018540764]
[2019-03-24 00:41:25,607] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [18.89105794, 94.65638991, 1.0, 2.0, 0.3364539729380583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 423924.7881920474, 423924.7881920479, 120154.1093621596]
[2019-03-24 00:41:25,607] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:41:25,612] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.5539055e-17 1.0000000e+00 6.5052012e-27 8.8983175e-25 7.5045901e-29], sampled 0.39176482801904766
[2019-03-24 00:41:42,342] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), -0.0018540764]
[2019-03-24 00:41:42,345] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.0, 59.0, 1.0, 2.0, 0.6005400790501694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 688678.0387181161, 688678.0387181161, 158381.8906304828]
[2019-03-24 00:41:42,346] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:41:42,348] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.5539055e-17 1.0000000e+00 6.5052012e-27 8.8983175e-25 7.5045901e-29], sampled 0.5985864526188449
[2019-03-24 00:41:54,286] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), -0.0018540764]
[2019-03-24 00:41:54,287] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.0, 89.0, 1.0, 2.0, 0.729548953258009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 831497.6926371425, 831497.692637142, 181817.0384919027]
[2019-03-24 00:41:54,288] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:41:54,293] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.5539055e-17 1.0000000e+00 6.5052012e-27 8.8983175e-25 7.5045901e-29], sampled 0.07576554765156074
[2019-03-24 00:42:03,520] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), -0.0018540764]
[2019-03-24 00:42:03,524] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.4, 55.0, 1.0, 2.0, 0.8353993352865046, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 977141.2757711324, 977141.2757711324, 204629.8211651521]
[2019-03-24 00:42:03,525] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:42:03,527] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.5539055e-17 1.0000000e+00 6.5052012e-27 8.8983175e-25 7.5045901e-29], sampled 0.42197047255396725
[2019-03-24 00:42:12,188] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), -0.0018540764]
[2019-03-24 00:42:12,189] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.38333333333333, 65.66666666666666, 1.0, 2.0, 0.9870808364668697, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1840493.914242747, 1840493.914242747, 376428.1999357973]
[2019-03-24 00:42:12,191] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:42:12,194] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.5539055e-17 1.0000000e+00 6.5052012e-27 8.8983175e-25 7.5045901e-29], sampled 0.07806858236864411
[2019-03-24 00:42:12,196] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1840493.914242747 W.
[2019-03-24 00:42:46,540] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 00:42:47,143] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 00:42:47,281] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 00:42:47,443] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 00:42:47,594] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 00:42:48,613] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 2125000, evaluation results [2125000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 00:42:53,099] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.39412885e-20 1.00000000e+00 1.04825944e-29 1.90779481e-27
 2.26104869e-33], sum to 1.0000
[2019-03-24 00:42:53,107] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4878
[2019-03-24 00:42:53,114] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.93333333333333, 19.33333333333334, 1.0, 2.0, 0.3706512586053405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 474308.9644928267, 474308.9644928267, 124752.6699334582], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 238800.0000, 
sim time next is 239400.0000, 
raw observation next is [31.7, 20.0, 1.0, 2.0, 0.3691642237337795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 472295.9795243677, 472295.9795243677, 124550.3422959634], 
processed observation next is [0.0, 0.782608695652174, 0.7296296296296296, 0.2, 1.0, 1.0, 0.2490050282544994, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16867713554441705, 0.16867713554441705, 0.23951988903069885], 
reward next is 0.7605, 
noisyNet noise sample is [array([-2.0320463], dtype=float32), -1.2939786]. 
=============================================
[2019-03-24 00:42:54,113] A3C_AGENT_WORKER-Thread-22 INFO:Local step 133500, global step 2127676: loss 0.0011
[2019-03-24 00:42:54,115] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 133500, global step 2127677: learning rate 0.0005
[2019-03-24 00:42:54,872] A3C_AGENT_WORKER-Thread-2 INFO:Local step 133000, global step 2128053: loss 0.0297
[2019-03-24 00:42:54,878] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 133000, global step 2128054: learning rate 0.0005
[2019-03-24 00:42:55,116] A3C_AGENT_WORKER-Thread-21 INFO:Local step 133000, global step 2128169: loss 0.0064
[2019-03-24 00:42:55,119] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 133000, global step 2128170: learning rate 0.0005
[2019-03-24 00:42:56,031] A3C_AGENT_WORKER-Thread-11 INFO:Local step 133000, global step 2128617: loss 0.0130
[2019-03-24 00:42:56,037] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 133000, global step 2128618: learning rate 0.0005
[2019-03-24 00:42:56,191] A3C_AGENT_WORKER-Thread-14 INFO:Local step 133000, global step 2128693: loss 0.0067
[2019-03-24 00:42:56,195] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 133000, global step 2128694: learning rate 0.0005
[2019-03-24 00:42:56,362] A3C_AGENT_WORKER-Thread-19 INFO:Local step 133000, global step 2128776: loss 0.0003
[2019-03-24 00:42:56,364] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 133000, global step 2128777: learning rate 0.0005
[2019-03-24 00:42:56,493] A3C_AGENT_WORKER-Thread-9 INFO:Local step 133000, global step 2128845: loss 0.0025
[2019-03-24 00:42:56,494] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 133000, global step 2128845: learning rate 0.0005
[2019-03-24 00:42:56,651] A3C_AGENT_WORKER-Thread-13 INFO:Local step 133000, global step 2128915: loss 0.0066
[2019-03-24 00:42:56,656] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 133000, global step 2128917: learning rate 0.0005
[2019-03-24 00:42:57,016] A3C_AGENT_WORKER-Thread-16 INFO:Local step 133000, global step 2129069: loss 0.0027
[2019-03-24 00:42:57,019] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 133000, global step 2129071: learning rate 0.0005
[2019-03-24 00:42:57,193] A3C_AGENT_WORKER-Thread-12 INFO:Local step 133000, global step 2129144: loss 0.0029
[2019-03-24 00:42:57,195] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 133000, global step 2129144: learning rate 0.0005
[2019-03-24 00:42:57,355] A3C_AGENT_WORKER-Thread-10 INFO:Local step 133000, global step 2129211: loss 0.0421
[2019-03-24 00:42:57,357] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 133000, global step 2129211: learning rate 0.0005
[2019-03-24 00:42:57,584] A3C_AGENT_WORKER-Thread-3 INFO:Local step 133000, global step 2129318: loss 0.0192
[2019-03-24 00:42:57,586] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 133000, global step 2129319: learning rate 0.0005
[2019-03-24 00:42:57,766] A3C_AGENT_WORKER-Thread-17 INFO:Local step 133000, global step 2129411: loss 0.0028
[2019-03-24 00:42:57,768] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 133000, global step 2129411: learning rate 0.0005
[2019-03-24 00:42:57,822] A3C_AGENT_WORKER-Thread-20 INFO:Local step 133000, global step 2129438: loss 0.0031
[2019-03-24 00:42:57,825] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 133000, global step 2129438: learning rate 0.0005
[2019-03-24 00:42:58,125] A3C_AGENT_WORKER-Thread-15 INFO:Local step 133000, global step 2129598: loss 0.0009
[2019-03-24 00:42:58,126] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 133000, global step 2129598: learning rate 0.0005
[2019-03-24 00:42:59,237] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.0782600e-19 1.0000000e+00 1.7546395e-30 6.6114190e-29 4.3509243e-34], sum to 1.0000
[2019-03-24 00:42:59,245] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1229
[2019-03-24 00:42:59,253] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.13333333333333, 61.33333333333334, 1.0, 2.0, 0.2656191090711274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 342630.297918618, 342630.297918618, 97017.58108577123], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 358800.0000, 
sim time next is 359400.0000, 
raw observation next is [18.96666666666667, 62.16666666666666, 1.0, 2.0, 0.2597914457999629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 335111.3726342439, 335111.3726342439, 95844.8715887455], 
processed observation next is [1.0, 0.13043478260869565, 0.25802469135802475, 0.6216666666666666, 1.0, 1.0, 0.11879934023805105, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.11968263308365855, 0.11968263308365855, 0.1843170607475875], 
reward next is 0.8157, 
noisyNet noise sample is [array([-1.0190799], dtype=float32), 2.13229]. 
=============================================
[2019-03-24 00:43:00,530] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.4366419e-19 1.0000000e+00 8.2926045e-30 3.2710830e-27 9.6588189e-31], sum to 1.0000
[2019-03-24 00:43:00,541] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0039
[2019-03-24 00:43:00,547] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.95, 62.0, 1.0, 2.0, 0.2311742207469147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 298190.1345361223, 298190.1345361223, 91122.53726009889], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 365400.0000, 
sim time next is 366000.0000, 
raw observation next is [19.36666666666667, 60.0, 1.0, 2.0, 0.235350587573424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 303578.2692670079, 303578.2692670079, 92471.90490485393], 
processed observation next is [1.0, 0.21739130434782608, 0.27283950617283964, 0.6, 1.0, 1.0, 0.08970308044455239, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.10842081045250282, 0.10842081045250282, 0.17783058635548832], 
reward next is 0.8222, 
noisyNet noise sample is [array([1.3358533], dtype=float32), 0.24665415]. 
=============================================
[2019-03-24 00:43:00,563] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[76.38224]
 [76.38224]
 [76.38224]
 [76.38224]
 [76.38224]], R is [[76.44058228]
 [76.50094604]
 [76.56227875]
 [76.62121582]
 [76.68218231]].
[2019-03-24 00:43:00,591] A3C_AGENT_WORKER-Thread-18 INFO:Local step 133500, global step 2130874: loss 0.0025
[2019-03-24 00:43:00,592] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 133500, global step 2130874: learning rate 0.0005
[2019-03-24 00:43:06,876] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.8700836e-17 1.0000000e+00 1.5539332e-28 3.1273454e-26 1.9668365e-29], sum to 1.0000
[2019-03-24 00:43:06,882] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1981
[2019-03-24 00:43:06,883] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1333292.30035087 W.
[2019-03-24 00:43:06,891] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.5, 24.0, 1.0, 2.0, 0.5402386030486944, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8917256481642288, 6.911199999999999, 6.9112, 121.9260426156618, 1333292.30035087, 1333292.30035087, 267508.2312211142], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 489600.0000, 
sim time next is 490200.0000, 
raw observation next is [32.53333333333334, 23.66666666666667, 1.0, 2.0, 0.4966359555207204, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8235846465546313, 6.9112, 6.9112, 121.9260426156618, 1230661.922362143, 1230661.922362143, 251759.711095143], 
processed observation next is [1.0, 0.6956521739130435, 0.7604938271604941, 0.23666666666666672, 1.0, 1.0, 0.4007570899056195, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7794808081932891, 0.0, 0.0, 0.8094621288201359, 0.43952211512933675, 0.43952211512933675, 0.48415329056758266], 
reward next is 0.5158, 
noisyNet noise sample is [array([-0.48653945], dtype=float32), 0.635214]. 
=============================================
[2019-03-24 00:43:09,694] A3C_AGENT_WORKER-Thread-22 INFO:Local step 134000, global step 2135563: loss 0.0018
[2019-03-24 00:43:09,695] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 134000, global step 2135563: learning rate 0.0005
[2019-03-24 00:43:10,597] A3C_AGENT_WORKER-Thread-2 INFO:Local step 133500, global step 2136019: loss 0.1405
[2019-03-24 00:43:10,601] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 133500, global step 2136020: learning rate 0.0005
[2019-03-24 00:43:11,005] A3C_AGENT_WORKER-Thread-21 INFO:Local step 133500, global step 2136235: loss 0.1719
[2019-03-24 00:43:11,008] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 133500, global step 2136235: learning rate 0.0005
[2019-03-24 00:43:11,881] A3C_AGENT_WORKER-Thread-14 INFO:Local step 133500, global step 2136685: loss 0.0042
[2019-03-24 00:43:11,884] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 133500, global step 2136685: learning rate 0.0005
[2019-03-24 00:43:11,894] A3C_AGENT_WORKER-Thread-11 INFO:Local step 133500, global step 2136690: loss 0.0015
[2019-03-24 00:43:11,896] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 133500, global step 2136690: learning rate 0.0005
[2019-03-24 00:43:11,925] A3C_AGENT_WORKER-Thread-19 INFO:Local step 133500, global step 2136708: loss 0.0003
[2019-03-24 00:43:11,932] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 133500, global step 2136708: learning rate 0.0005
[2019-03-24 00:43:12,145] A3C_AGENT_WORKER-Thread-9 INFO:Local step 133500, global step 2136822: loss 0.0000
[2019-03-24 00:43:12,146] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 133500, global step 2136822: learning rate 0.0005
[2019-03-24 00:43:12,552] A3C_AGENT_WORKER-Thread-13 INFO:Local step 133500, global step 2137034: loss 0.0041
[2019-03-24 00:43:12,555] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 133500, global step 2137034: learning rate 0.0005
[2019-03-24 00:43:12,618] A3C_AGENT_WORKER-Thread-16 INFO:Local step 133500, global step 2137063: loss 0.0110
[2019-03-24 00:43:12,622] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 133500, global step 2137063: learning rate 0.0005
[2019-03-24 00:43:12,720] A3C_AGENT_WORKER-Thread-12 INFO:Local step 133500, global step 2137123: loss 0.0064
[2019-03-24 00:43:12,723] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 133500, global step 2137123: learning rate 0.0005
[2019-03-24 00:43:12,865] A3C_AGENT_WORKER-Thread-10 INFO:Local step 133500, global step 2137195: loss 0.0208
[2019-03-24 00:43:12,867] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 133500, global step 2137195: learning rate 0.0005
[2019-03-24 00:43:13,136] A3C_AGENT_WORKER-Thread-17 INFO:Local step 133500, global step 2137329: loss 0.0000
[2019-03-24 00:43:13,138] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 133500, global step 2137329: learning rate 0.0005
[2019-03-24 00:43:13,319] A3C_AGENT_WORKER-Thread-3 INFO:Local step 133500, global step 2137425: loss 0.0004
[2019-03-24 00:43:13,321] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 133500, global step 2137427: learning rate 0.0005
[2019-03-24 00:43:13,403] A3C_AGENT_WORKER-Thread-20 INFO:Local step 133500, global step 2137469: loss 0.0114
[2019-03-24 00:43:13,404] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 133500, global step 2137469: learning rate 0.0005
[2019-03-24 00:43:13,524] A3C_AGENT_WORKER-Thread-15 INFO:Local step 133500, global step 2137529: loss 0.0307
[2019-03-24 00:43:13,526] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 133500, global step 2137531: learning rate 0.0005
[2019-03-24 00:43:14,591] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.4510445e-17 1.0000000e+00 2.9147240e-29 1.1977186e-25 4.4778612e-30], sum to 1.0000
[2019-03-24 00:43:14,600] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7360
[2019-03-24 00:43:14,603] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.06666666666667, 65.16666666666667, 1.0, 2.0, 0.305672672079111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 390975.8709444478, 390975.8709444478, 116280.8449591544], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 882600.0000, 
sim time next is 883200.0000, 
raw observation next is [21.13333333333333, 65.33333333333334, 1.0, 2.0, 0.3077348920318592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 393305.6928160409, 393305.6928160409, 116537.8975447615], 
processed observation next is [0.0, 0.21739130434782608, 0.33827160493827146, 0.6533333333333334, 1.0, 1.0, 0.17587487146649908, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14046631886287175, 0.14046631886287175, 0.22411134143223363], 
reward next is 0.7759, 
noisyNet noise sample is [array([-0.19714093], dtype=float32), 0.07305036]. 
=============================================
[2019-03-24 00:43:15,535] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.0442205e-17 1.0000000e+00 4.4586919e-27 2.5955215e-25 9.5817621e-29], sum to 1.0000
[2019-03-24 00:43:15,543] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9839
[2019-03-24 00:43:15,546] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.86666666666667, 47.16666666666666, 1.0, 2.0, 0.3577349622317351, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 458619.9961860183, 458619.9961860183, 123007.8150713748], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 705000.0000, 
sim time next is 705600.0000, 
raw observation next is [23.7, 48.0, 1.0, 2.0, 0.3727381455115308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 477855.862380466, 477855.862380466, 125036.4133247596], 
processed observation next is [1.0, 0.17391304347826086, 0.4333333333333333, 0.48, 1.0, 1.0, 0.25325969703753665, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17066280799302358, 0.17066280799302358, 0.2404546410091531], 
reward next is 0.7595, 
noisyNet noise sample is [array([1.5826745], dtype=float32), 1.4987069]. 
=============================================
[2019-03-24 00:43:16,021] A3C_AGENT_WORKER-Thread-18 INFO:Local step 134000, global step 2138815: loss 0.0657
[2019-03-24 00:43:16,023] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 134000, global step 2138815: learning rate 0.0005
[2019-03-24 00:43:17,210] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0577532e-18 1.0000000e+00 1.3946321e-29 1.1660654e-26 1.1297203e-32], sum to 1.0000
[2019-03-24 00:43:17,220] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8318
[2019-03-24 00:43:17,226] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.36666666666667, 40.33333333333334, 1.0, 2.0, 0.5487269821491416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 702753.9202166636, 702753.9202166636, 151831.8181791723], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 699600.0000, 
sim time next is 700200.0000, 
raw observation next is [25.2, 41.0, 1.0, 2.0, 0.4613610181087041, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 590990.0776161806, 590990.0776161811, 137839.1675416604], 
processed observation next is [1.0, 0.08695652173913043, 0.4888888888888889, 0.41, 1.0, 1.0, 0.3587631167960763, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21106788486292166, 0.21106788486292183, 0.2650753221955008], 
reward next is 0.7349, 
noisyNet noise sample is [array([0.12432417], dtype=float32), 0.9605382]. 
=============================================
[2019-03-24 00:43:17,371] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.1085254e-16 1.0000000e+00 1.2868371e-27 1.2329333e-23 2.1602368e-30], sum to 1.0000
[2019-03-24 00:43:17,378] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3157
[2019-03-24 00:43:17,383] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 38.5, 1.0, 2.0, 0.3110322589490981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 397705.7050359992, 397705.7050359992, 116950.8965419829], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 696600.0000, 
sim time next is 697200.0000, 
raw observation next is [25.96666666666667, 38.66666666666667, 1.0, 2.0, 0.3093868043859512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 395881.618448371, 395881.618448371, 116744.6728593018], 
processed observation next is [1.0, 0.043478260869565216, 0.517283950617284, 0.3866666666666667, 1.0, 1.0, 0.17784143379279901, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14138629230298966, 0.14138629230298966, 0.2245089862678881], 
reward next is 0.7755, 
noisyNet noise sample is [array([-0.12784055], dtype=float32), -0.20824577]. 
=============================================
[2019-03-24 00:43:24,556] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.7097026e-20 1.0000000e+00 2.1559232e-30 1.3203463e-28 3.2565932e-33], sum to 1.0000
[2019-03-24 00:43:24,567] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7996
[2019-03-24 00:43:24,573] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.66666666666667, 36.0, 1.0, 2.0, 0.438269050794096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 533971.5955793229, 533971.5955793229, 133904.4701485721], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 829200.0000, 
sim time next is 829800.0000, 
raw observation next is [31.7, 36.0, 1.0, 2.0, 0.43899512636268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 534639.0548523968, 534639.0548523964, 134004.931017975], 
processed observation next is [0.0, 0.6086956521739131, 0.7296296296296296, 0.36, 1.0, 1.0, 0.33213705519366665, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19094251959014172, 0.19094251959014155, 0.2577017904191827], 
reward next is 0.7423, 
noisyNet noise sample is [array([0.28189966], dtype=float32), 0.029119724]. 
=============================================
[2019-03-24 00:43:24,777] A3C_AGENT_WORKER-Thread-22 INFO:Local step 134500, global step 2143328: loss 0.0006
[2019-03-24 00:43:24,778] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 134500, global step 2143328: learning rate 0.0005
[2019-03-24 00:43:25,114] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.7785842e-19 1.0000000e+00 7.2781392e-29 4.1963444e-26 2.7383150e-31], sum to 1.0000
[2019-03-24 00:43:25,119] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2479
[2019-03-24 00:43:25,124] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.33333333333334, 36.83333333333334, 1.0, 2.0, 0.4378718886673434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 533816.5471119578, 533816.5471119573, 133855.5488402667], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 839400.0000, 
sim time next is 840000.0000, 
raw observation next is [31.26666666666667, 36.66666666666667, 1.0, 2.0, 0.4347342156469842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 530726.8673165791, 530726.8673165791, 133416.2168742236], 
processed observation next is [0.0, 0.7391304347826086, 0.7135802469135804, 0.3666666666666667, 1.0, 1.0, 0.32706454243688593, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1895453097559211, 0.1895453097559211, 0.2565696478350454], 
reward next is 0.7434, 
noisyNet noise sample is [array([0.63664144], dtype=float32), -0.38082278]. 
=============================================
[2019-03-24 00:43:25,146] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[71.45138]
 [71.45138]
 [71.45138]
 [71.45138]
 [71.45138]], R is [[71.48029327]
 [71.5080719 ]
 [71.5351181 ]
 [71.5614624 ]
 [71.58712006]].
[2019-03-24 00:43:26,085] A3C_AGENT_WORKER-Thread-2 INFO:Local step 134000, global step 2143999: loss 0.0229
[2019-03-24 00:43:26,086] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 134000, global step 2143999: learning rate 0.0005
[2019-03-24 00:43:26,622] A3C_AGENT_WORKER-Thread-21 INFO:Local step 134000, global step 2144274: loss 0.0245
[2019-03-24 00:43:26,623] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 134000, global step 2144274: learning rate 0.0005
[2019-03-24 00:43:26,643] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0451179e-20 1.0000000e+00 1.5206340e-32 1.5782476e-28 1.4720222e-33], sum to 1.0000
[2019-03-24 00:43:26,650] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8103
[2019-03-24 00:43:26,653] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.76666666666667, 66.33333333333334, 1.0, 2.0, 0.3379137662042673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 428373.8733191731, 428373.8733191731, 120371.727495494], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 877200.0000, 
sim time next is 877800.0000, 
raw observation next is [21.68333333333334, 66.16666666666666, 1.0, 2.0, 0.3349065986664459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 425028.9059156064, 425028.9059156064, 119984.6153110949], 
processed observation next is [0.0, 0.13043478260869565, 0.3586419753086422, 0.6616666666666666, 1.0, 1.0, 0.20822214126957844, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1517960378270023, 0.1517960378270023, 0.23073964482902865], 
reward next is 0.7693, 
noisyNet noise sample is [array([0.29745972], dtype=float32), -1.5938605]. 
=============================================
[2019-03-24 00:43:26,843] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.5752890e-19 1.0000000e+00 8.2501427e-28 1.0937480e-24 1.2219449e-29], sum to 1.0000
[2019-03-24 00:43:26,848] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3476
[2019-03-24 00:43:26,852] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.61666666666667, 65.5, 1.0, 2.0, 0.8352862333969907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1038189.56546573, 1038189.56546573, 206861.7718831782], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1252200.0000, 
sim time next is 1252800.0000, 
raw observation next is [23.8, 65.0, 1.0, 2.0, 0.8482774958145343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1053028.478191957, 1053028.478191957, 209681.8105979235], 
processed observation next is [1.0, 0.5217391304347826, 0.43703703703703706, 0.65, 1.0, 1.0, 0.8193779712077789, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3760815993542704, 0.3760815993542704, 0.4032342511498529], 
reward next is 0.5968, 
noisyNet noise sample is [array([0.21088597], dtype=float32), -0.72875285]. 
=============================================
[2019-03-24 00:43:27,279] A3C_AGENT_WORKER-Thread-19 INFO:Local step 134000, global step 2144609: loss 0.0433
[2019-03-24 00:43:27,283] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 134000, global step 2144610: learning rate 0.0005
[2019-03-24 00:43:27,444] A3C_AGENT_WORKER-Thread-14 INFO:Local step 134000, global step 2144694: loss 0.0009
[2019-03-24 00:43:27,446] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 134000, global step 2144694: learning rate 0.0005
[2019-03-24 00:43:27,507] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.5727523e-19 1.0000000e+00 6.2021402e-29 7.3218353e-28 2.3606832e-31], sum to 1.0000
[2019-03-24 00:43:27,516] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7449
[2019-03-24 00:43:27,527] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1500323.055866683 W.
[2019-03-24 00:43:27,531] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.23333333333333, 55.66666666666667, 1.0, 2.0, 0.9844545748335785, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.489703814670716, 6.9112, 121.923642579508, 1500323.055866683, 1204083.228077346, 240822.1750020956], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1264800.0000, 
sim time next is 1265400.0000, 
raw observation next is [26.25, 55.5, 1.0, 2.0, 0.3735046776078823, 1.0, 1.0, 0.3735046776078823, 1.0, 1.0, 0.6017239113884698, 6.9112, 6.9112, 121.94756008, 1339341.333496941, 1339341.333496941, 285305.222498703], 
processed observation next is [1.0, 0.6521739130434783, 0.5277777777777778, 0.555, 1.0, 1.0, 0.25417223524747895, 1.0, 0.5, 0.25417223524747895, 1.0, 0.5, 0.5021548892355873, 0.0, 0.0, 0.8096049824067558, 0.4783361905346218, 0.4783361905346218, 0.5486638894205826], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.85438734], dtype=float32), -0.82326835]. 
=============================================
[2019-03-24 00:43:27,532] A3C_AGENT_WORKER-Thread-11 INFO:Local step 134000, global step 2144738: loss 0.0053
[2019-03-24 00:43:27,535] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 134000, global step 2144738: learning rate 0.0005
[2019-03-24 00:43:27,645] A3C_AGENT_WORKER-Thread-9 INFO:Local step 134000, global step 2144797: loss 0.0002
[2019-03-24 00:43:27,647] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 134000, global step 2144797: learning rate 0.0005
[2019-03-24 00:43:28,110] A3C_AGENT_WORKER-Thread-12 INFO:Local step 134000, global step 2145036: loss 0.0136
[2019-03-24 00:43:28,114] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 134000, global step 2145036: learning rate 0.0005
[2019-03-24 00:43:28,353] A3C_AGENT_WORKER-Thread-16 INFO:Local step 134000, global step 2145157: loss 0.0236
[2019-03-24 00:43:28,354] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 134000, global step 2145157: learning rate 0.0005
[2019-03-24 00:43:28,386] A3C_AGENT_WORKER-Thread-13 INFO:Local step 134000, global step 2145171: loss 0.0576
[2019-03-24 00:43:28,387] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 134000, global step 2145172: learning rate 0.0005
[2019-03-24 00:43:28,553] A3C_AGENT_WORKER-Thread-10 INFO:Local step 134000, global step 2145260: loss 0.0011
[2019-03-24 00:43:28,554] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 134000, global step 2145260: learning rate 0.0005
[2019-03-24 00:43:28,885] A3C_AGENT_WORKER-Thread-17 INFO:Local step 134000, global step 2145433: loss 0.0120
[2019-03-24 00:43:28,887] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 134000, global step 2145433: learning rate 0.0005
[2019-03-24 00:43:28,930] A3C_AGENT_WORKER-Thread-20 INFO:Local step 134000, global step 2145459: loss 0.0144
[2019-03-24 00:43:28,931] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 134000, global step 2145460: learning rate 0.0005
[2019-03-24 00:43:29,007] A3C_AGENT_WORKER-Thread-3 INFO:Local step 134000, global step 2145496: loss 0.0229
[2019-03-24 00:43:29,009] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 134000, global step 2145496: learning rate 0.0005
[2019-03-24 00:43:29,162] A3C_AGENT_WORKER-Thread-15 INFO:Local step 134000, global step 2145579: loss 0.0004
[2019-03-24 00:43:29,164] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 134000, global step 2145579: learning rate 0.0005
[2019-03-24 00:43:31,662] A3C_AGENT_WORKER-Thread-18 INFO:Local step 134500, global step 2146862: loss 0.0016
[2019-03-24 00:43:31,667] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 134500, global step 2146866: learning rate 0.0005
[2019-03-24 00:43:37,730] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-24 00:43:37,731] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:43:37,732] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:43:37,733] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:43:37,733] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:43:37,734] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:43:37,734] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:43:37,734] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:43:37,735] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:43:37,736] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:43:37,739] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:43:37,765] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run87
[2019-03-24 00:43:37,766] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run87
[2019-03-24 00:43:37,790] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run87
[2019-03-24 00:43:37,813] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run87
[2019-03-24 00:43:37,868] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run87
[2019-03-24 00:43:44,255] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0368421]
[2019-03-24 00:43:44,256] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [18.74113502833333, 53.12756084666667, 1.0, 2.0, 0.2167885766096285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 279630.80247059, 279630.8024705895, 82376.19826479795]
[2019-03-24 00:43:44,257] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:43:44,262] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.5791147e-18 1.0000000e+00 8.6560043e-29 1.7140622e-26 7.7083230e-31], sampled 0.4481214164502989
[2019-03-24 00:43:53,734] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0368421]
[2019-03-24 00:43:53,736] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [19.37061668333333, 82.31211054166667, 1.0, 2.0, 0.312250913682706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 396933.4829938876, 396933.4829938872, 117095.6677229907]
[2019-03-24 00:43:53,738] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:43:53,743] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.5791147e-18 1.0000000e+00 8.6560043e-29 1.7140622e-26 7.7083230e-31], sampled 0.12223603896597768
[2019-03-24 00:44:07,863] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0368421]
[2019-03-24 00:44:07,864] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.2, 64.0, 1.0, 2.0, 0.4648890660713781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 560045.730384336, 560045.730384336, 137683.0132125911]
[2019-03-24 00:44:07,865] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:44:07,869] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.5791147e-18 1.0000000e+00 8.6560043e-29 1.7140622e-26 7.7083230e-31], sampled 0.25189967762126386
[2019-03-24 00:44:08,655] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0368421]
[2019-03-24 00:44:08,657] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [34.5, 37.5, 1.0, 2.0, 0.6702243243309347, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9950964448083034, 6.9112, 6.9112, 121.9260426156618, 1480989.183088346, 1480989.183088346, 311451.6916078692]
[2019-03-24 00:44:08,658] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:44:08,662] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.5791147e-18 1.0000000e+00 8.6560043e-29 1.7140622e-26 7.7083230e-31], sampled 0.24772913979094213
[2019-03-24 00:44:08,664] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1480989.183088346 W.
[2019-03-24 00:44:24,732] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0368421]
[2019-03-24 00:44:24,736] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.0, 89.0, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 7.114009435624981, 6.9112, 121.9251265306791, 1982041.528956024, 1878185.75133522, 383408.7775105725]
[2019-03-24 00:44:24,737] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:44:24,740] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.5791147e-18 1.0000000e+00 8.6560043e-29 1.7140622e-26 7.7083230e-31], sampled 0.0017586228543561289
[2019-03-24 00:44:24,743] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 1982041.528956024 W.
[2019-03-24 00:44:38,920] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0368421]
[2019-03-24 00:44:38,922] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.5, 86.0, 1.0, 2.0, 0.5495435826434066, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 641902.9141293531, 641902.9141293531, 150347.9288258821]
[2019-03-24 00:44:38,922] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:44:38,924] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.5791147e-18 1.0000000e+00 8.6560043e-29 1.7140622e-26 7.7083230e-31], sampled 0.09479709796643931
[2019-03-24 00:44:40,783] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0368421]
[2019-03-24 00:44:40,784] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.90647293, 95.44468377, 1.0, 2.0, 0.5549750350267558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 651814.0835338162, 651814.0835338162, 151396.7244888017]
[2019-03-24 00:44:40,786] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:44:40,789] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.5791147e-18 1.0000000e+00 8.6560043e-29 1.7140622e-26 7.7083230e-31], sampled 0.3435749898267657
[2019-03-24 00:44:48,064] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0368421]
[2019-03-24 00:44:48,065] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.9, 85.5, 1.0, 2.0, 0.7181165996343591, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 818460.8003034717, 818460.8003034717, 179602.4803715475]
[2019-03-24 00:44:48,067] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:44:48,069] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.5791147e-18 1.0000000e+00 8.6560043e-29 1.7140622e-26 7.7083230e-31], sampled 0.35565772661539563
[2019-03-24 00:45:05,821] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0368421]
[2019-03-24 00:45:05,823] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [32.704146205, 58.72587478666667, 1.0, 2.0, 0.7229570161121747, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 823980.5455018732, 823980.5455018732, 180541.5181312919]
[2019-03-24 00:45:05,824] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:45:05,826] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.5791147e-18 1.0000000e+00 8.6560043e-29 1.7140622e-26 7.7083230e-31], sampled 0.7806588973328515
[2019-03-24 00:45:23,396] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0368421]
[2019-03-24 00:45:23,397] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.0, 52.0, 1.0, 2.0, 0.6703388371253236, 0.0, 2.0, 0.0, 1.0, 2.0, 0.973003152289283, 6.9112, 6.9112, 121.9260426156618, 1502356.772242223, 1502356.772242223, 306965.48470629]
[2019-03-24 00:45:23,398] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:45:23,400] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.5791147e-18 1.0000000e+00 8.6560043e-29 1.7140622e-26 7.7083230e-31], sampled 0.3720876684880352
[2019-03-24 00:45:23,401] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1502356.772242223 W.
[2019-03-24 00:45:25,673] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 00:45:26,030] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 00:45:26,042] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 00:45:26,109] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 00:45:26,128] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 00:45:27,147] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 2150000, evaluation results [2150000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 00:45:29,724] A3C_AGENT_WORKER-Thread-22 INFO:Local step 135000, global step 2151254: loss 0.0119
[2019-03-24 00:45:29,727] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 135000, global step 2151255: learning rate 0.0005
[2019-03-24 00:45:31,152] A3C_AGENT_WORKER-Thread-2 INFO:Local step 134500, global step 2151961: loss 0.0183
[2019-03-24 00:45:31,156] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 134500, global step 2151962: learning rate 0.0005
[2019-03-24 00:45:31,706] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.5380065e-18 1.0000000e+00 1.0458036e-28 7.4147017e-28 1.0407006e-30], sum to 1.0000
[2019-03-24 00:45:31,718] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4919
[2019-03-24 00:45:31,722] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.98333333333333, 93.0, 1.0, 2.0, 0.3229156692643885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 410859.2258725596, 410859.2258725601, 118448.7151948811], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1221000.0000, 
sim time next is 1221600.0000, 
raw observation next is [17.96666666666667, 93.0, 1.0, 2.0, 0.3107261150373243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 395422.7609170292, 395422.7609170292, 116906.5736437366], 
processed observation next is [1.0, 0.13043478260869565, 0.22098765432098771, 0.93, 1.0, 1.0, 0.17943585123490985, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1412224146132247, 0.1412224146132247, 0.22482033393026268], 
reward next is 0.7752, 
noisyNet noise sample is [array([-0.8373481], dtype=float32), 1.0442334]. 
=============================================
[2019-03-24 00:45:31,882] A3C_AGENT_WORKER-Thread-21 INFO:Local step 134500, global step 2152313: loss 0.0139
[2019-03-24 00:45:31,883] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 134500, global step 2152314: learning rate 0.0005
[2019-03-24 00:45:32,181] A3C_AGENT_WORKER-Thread-19 INFO:Local step 134500, global step 2152459: loss 0.0053
[2019-03-24 00:45:32,184] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 134500, global step 2152461: learning rate 0.0005
[2019-03-24 00:45:32,557] A3C_AGENT_WORKER-Thread-9 INFO:Local step 134500, global step 2152644: loss 0.0038
[2019-03-24 00:45:32,560] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 134500, global step 2152645: learning rate 0.0005
[2019-03-24 00:45:32,745] A3C_AGENT_WORKER-Thread-14 INFO:Local step 134500, global step 2152734: loss 0.0113
[2019-03-24 00:45:32,750] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 134500, global step 2152735: learning rate 0.0005
[2019-03-24 00:45:32,895] A3C_AGENT_WORKER-Thread-11 INFO:Local step 134500, global step 2152805: loss 0.0206
[2019-03-24 00:45:32,897] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 134500, global step 2152805: learning rate 0.0005
[2019-03-24 00:45:33,504] A3C_AGENT_WORKER-Thread-16 INFO:Local step 134500, global step 2153095: loss 0.0094
[2019-03-24 00:45:33,505] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 134500, global step 2153096: learning rate 0.0005
[2019-03-24 00:45:33,614] A3C_AGENT_WORKER-Thread-13 INFO:Local step 134500, global step 2153146: loss 0.0183
[2019-03-24 00:45:33,618] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 134500, global step 2153148: learning rate 0.0005
[2019-03-24 00:45:33,665] A3C_AGENT_WORKER-Thread-12 INFO:Local step 134500, global step 2153168: loss 0.0159
[2019-03-24 00:45:33,669] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 134500, global step 2153168: learning rate 0.0005
[2019-03-24 00:45:33,852] A3C_AGENT_WORKER-Thread-10 INFO:Local step 134500, global step 2153249: loss 0.0014
[2019-03-24 00:45:33,855] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 134500, global step 2153249: learning rate 0.0005
[2019-03-24 00:45:34,356] A3C_AGENT_WORKER-Thread-3 INFO:Local step 134500, global step 2153456: loss 0.0268
[2019-03-24 00:45:34,357] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 134500, global step 2153456: learning rate 0.0005
[2019-03-24 00:45:34,395] A3C_AGENT_WORKER-Thread-17 INFO:Local step 134500, global step 2153471: loss 0.0210
[2019-03-24 00:45:34,397] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 134500, global step 2153473: learning rate 0.0005
[2019-03-24 00:45:34,601] A3C_AGENT_WORKER-Thread-15 INFO:Local step 134500, global step 2153561: loss 0.0010
[2019-03-24 00:45:34,603] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 134500, global step 2153561: learning rate 0.0005
[2019-03-24 00:45:34,609] A3C_AGENT_WORKER-Thread-20 INFO:Local step 134500, global step 2153563: loss 0.0010
[2019-03-24 00:45:34,610] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 134500, global step 2153563: learning rate 0.0005
[2019-03-24 00:45:35,015] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.0079353e-19 1.0000000e+00 1.5434764e-28 1.8788908e-27 4.1018946e-31], sum to 1.0000
[2019-03-24 00:45:35,023] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5952
[2019-03-24 00:45:35,028] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.01666666666667, 93.0, 1.0, 2.0, 0.3187481317550348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 405412.9230549557, 405412.9230549553, 117917.519327507], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1219800.0000, 
sim time next is 1220400.0000, 
raw observation next is [18.0, 93.0, 1.0, 2.0, 0.3164611352423088, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 402578.0262655262, 402578.0262655262, 117628.2260382225], 
processed observation next is [1.0, 0.13043478260869565, 0.2222222222222222, 0.93, 1.0, 1.0, 0.1862632562408438, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14377786652340221, 0.14377786652340221, 0.22620812699658174], 
reward next is 0.7738, 
noisyNet noise sample is [array([-0.90802634], dtype=float32), 1.6442715]. 
=============================================
[2019-03-24 00:45:37,156] A3C_AGENT_WORKER-Thread-18 INFO:Local step 135000, global step 2154877: loss 0.0060
[2019-03-24 00:45:37,158] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 135000, global step 2154878: learning rate 0.0005
[2019-03-24 00:45:37,277] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.8489064e-17 1.0000000e+00 3.3745675e-29 1.3417791e-27 1.5511836e-30], sum to 1.0000
[2019-03-24 00:45:37,282] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6450
[2019-03-24 00:45:37,285] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.55, 25.5, 1.0, 2.0, 0.4121997081104231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 505878.8770841433, 505878.8770841428, 130231.791035645], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1513800.0000, 
sim time next is 1514400.0000, 
raw observation next is [34.7, 25.0, 1.0, 2.0, 0.4115146387352607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 505273.9342128329, 505273.9342128329, 130140.2626642844], 
processed observation next is [0.0, 0.5217391304347826, 0.8407407407407409, 0.25, 1.0, 1.0, 0.29942218897054845, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18045497650458317, 0.18045497650458317, 0.2502697358928546], 
reward next is 0.7497, 
noisyNet noise sample is [array([-0.6804802], dtype=float32), -1.4233876]. 
=============================================
[2019-03-24 00:45:42,622] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9812291e-20 1.0000000e+00 4.8507230e-31 4.8140075e-29 3.0802506e-31], sum to 1.0000
[2019-03-24 00:45:42,631] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3807
[2019-03-24 00:45:42,637] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.25, 67.0, 1.0, 2.0, 0.34774254664627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 438251.7122242584, 438251.712224258, 121632.7878486285], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1380600.0000, 
sim time next is 1381200.0000, 
raw observation next is [22.16666666666667, 67.0, 1.0, 2.0, 0.3459913338513887, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 436437.0426920408, 436437.0426920408, 121406.9478576484], 
processed observation next is [1.0, 1.0, 0.3765432098765434, 0.67, 1.0, 1.0, 0.22141825458498654, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15587037239001456, 0.15587037239001456, 0.2334748997262469], 
reward next is 0.7665, 
noisyNet noise sample is [array([1.0162207], dtype=float32), -0.45695534]. 
=============================================
[2019-03-24 00:45:45,566] A3C_AGENT_WORKER-Thread-22 INFO:Local step 135500, global step 2159204: loss 0.0070
[2019-03-24 00:45:45,568] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 135500, global step 2159205: learning rate 0.0005
[2019-03-24 00:45:47,110] A3C_AGENT_WORKER-Thread-2 INFO:Local step 135000, global step 2160006: loss 0.0226
[2019-03-24 00:45:47,113] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 135000, global step 2160006: learning rate 0.0005
[2019-03-24 00:45:47,700] A3C_AGENT_WORKER-Thread-19 INFO:Local step 135000, global step 2160307: loss 0.0078
[2019-03-24 00:45:47,701] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 135000, global step 2160307: learning rate 0.0005
[2019-03-24 00:45:47,798] A3C_AGENT_WORKER-Thread-21 INFO:Local step 135000, global step 2160356: loss 0.0244
[2019-03-24 00:45:47,801] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 135000, global step 2160357: learning rate 0.0005
[2019-03-24 00:45:48,438] A3C_AGENT_WORKER-Thread-11 INFO:Local step 135000, global step 2160690: loss 0.0032
[2019-03-24 00:45:48,440] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 135000, global step 2160691: learning rate 0.0005
[2019-03-24 00:45:48,552] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.9274792e-19 1.0000000e+00 4.6041036e-28 8.5441895e-24 2.6206360e-30], sum to 1.0000
[2019-03-24 00:45:48,559] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5845
[2019-03-24 00:45:48,563] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.3, 63.83333333333333, 1.0, 2.0, 0.3346001137098937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 423835.8588279076, 423835.8588279076, 119938.1200779544], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1480200.0000, 
sim time next is 1480800.0000, 
raw observation next is [22.2, 64.66666666666667, 1.0, 2.0, 0.3369182329251828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 426627.154279145, 426627.154279145, 120237.8356696304], 
processed observation next is [0.0, 0.13043478260869565, 0.37777777777777777, 0.6466666666666667, 1.0, 1.0, 0.21061694395855096, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15236684081398036, 0.15236684081398036, 0.23122660705698153], 
reward next is 0.7688, 
noisyNet noise sample is [array([0.12591179], dtype=float32), 1.1609961]. 
=============================================
[2019-03-24 00:45:48,592] A3C_AGENT_WORKER-Thread-9 INFO:Local step 135000, global step 2160767: loss 0.0134
[2019-03-24 00:45:48,594] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 135000, global step 2160769: learning rate 0.0005
[2019-03-24 00:45:48,617] A3C_AGENT_WORKER-Thread-14 INFO:Local step 135000, global step 2160782: loss 0.0147
[2019-03-24 00:45:48,620] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 135000, global step 2160783: learning rate 0.0005
[2019-03-24 00:45:49,267] A3C_AGENT_WORKER-Thread-12 INFO:Local step 135000, global step 2161108: loss 0.0235
[2019-03-24 00:45:49,270] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 135000, global step 2161108: learning rate 0.0005
[2019-03-24 00:45:49,305] A3C_AGENT_WORKER-Thread-16 INFO:Local step 135000, global step 2161128: loss 0.0271
[2019-03-24 00:45:49,306] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 135000, global step 2161128: learning rate 0.0005
[2019-03-24 00:45:49,364] A3C_AGENT_WORKER-Thread-13 INFO:Local step 135000, global step 2161162: loss 0.0056
[2019-03-24 00:45:49,366] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 135000, global step 2161162: learning rate 0.0005
[2019-03-24 00:45:49,548] A3C_AGENT_WORKER-Thread-10 INFO:Local step 135000, global step 2161256: loss 0.0146
[2019-03-24 00:45:49,550] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 135000, global step 2161256: learning rate 0.0005
[2019-03-24 00:45:49,986] A3C_AGENT_WORKER-Thread-15 INFO:Local step 135000, global step 2161478: loss 0.0025
[2019-03-24 00:45:49,988] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 135000, global step 2161478: learning rate 0.0005
[2019-03-24 00:45:50,080] A3C_AGENT_WORKER-Thread-20 INFO:Local step 135000, global step 2161525: loss 0.0088
[2019-03-24 00:45:50,081] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 135000, global step 2161525: learning rate 0.0005
[2019-03-24 00:45:50,110] A3C_AGENT_WORKER-Thread-3 INFO:Local step 135000, global step 2161541: loss 0.0031
[2019-03-24 00:45:50,114] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 135000, global step 2161541: learning rate 0.0005
[2019-03-24 00:45:50,275] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.5210606e-16 1.0000000e+00 1.4207724e-29 3.0590620e-27 6.3014378e-31], sum to 1.0000
[2019-03-24 00:45:50,283] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2743
[2019-03-24 00:45:50,291] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.05, 85.0, 1.0, 2.0, 0.5093079375004854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 639345.0963212316, 639345.0963212316, 145241.2631753161], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1571400.0000, 
sim time next is 1572000.0000, 
raw observation next is [19.93333333333333, 85.66666666666667, 1.0, 2.0, 0.551187254699389, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 692192.5733327593, 692192.5733327593, 152130.4314236871], 
processed observation next is [1.0, 0.17391304347826086, 0.293827160493827, 0.8566666666666667, 1.0, 1.0, 0.46569911273736786, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24721163333312832, 0.24721163333312832, 0.2925585219686291], 
reward next is 0.7074, 
noisyNet noise sample is [array([-1.0310909], dtype=float32), 0.32939145]. 
=============================================
[2019-03-24 00:45:50,307] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[72.44647]
 [72.44647]
 [72.44647]
 [72.44647]
 [72.44647]], R is [[72.42945099]
 [72.42584229]
 [72.42004395]
 [72.37179565]
 [72.35533142]].
[2019-03-24 00:45:50,380] A3C_AGENT_WORKER-Thread-17 INFO:Local step 135000, global step 2161675: loss 0.0268
[2019-03-24 00:45:50,381] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 135000, global step 2161675: learning rate 0.0005
[2019-03-24 00:45:52,849] A3C_AGENT_WORKER-Thread-18 INFO:Local step 135500, global step 2162920: loss 0.0647
[2019-03-24 00:45:52,850] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 135500, global step 2162920: learning rate 0.0005
[2019-03-24 00:45:57,629] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.1598508e-19 1.0000000e+00 6.7155552e-30 2.2475704e-28 4.0500828e-33], sum to 1.0000
[2019-03-24 00:45:57,639] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4489
[2019-03-24 00:45:57,643] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.26666666666667, 68.33333333333334, 1.0, 2.0, 0.4213212279668661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 535084.5768863673, 535084.5768863673, 131865.9304038599], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1650000.0000, 
sim time next is 1650600.0000, 
raw observation next is [21.05, 69.5, 1.0, 2.0, 0.3651215079834854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 463991.5962578292, 463991.5962578287, 123990.9323758967], 
processed observation next is [1.0, 0.08695652173913043, 0.3351851851851852, 0.695, 1.0, 1.0, 0.24419227140891123, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16571128437779614, 0.16571128437779598, 0.23844410072287825], 
reward next is 0.7616, 
noisyNet noise sample is [array([-0.5238979], dtype=float32), -0.0777522]. 
=============================================
[2019-03-24 00:46:02,151] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.5276284e-18 1.0000000e+00 4.3609697e-30 6.8824570e-27 6.9041104e-31], sum to 1.0000
[2019-03-24 00:46:02,159] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2114
[2019-03-24 00:46:02,167] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1444189.560530039 W.
[2019-03-24 00:46:02,177] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.15, 66.66666666666667, 1.0, 2.0, 0.4113351314012652, 1.0, 1.0, 0.4113351314012652, 1.0, 1.0, 0.6573833995129617, 6.9112, 6.9112, 121.94756008, 1444189.560530039, 1444189.560530039, 302127.0242912758], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1771800.0000, 
sim time next is 1772400.0000, 
raw observation next is [25.2, 66.33333333333334, 1.0, 2.0, 0.4696213962270018, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7553409019825591, 6.911200000000001, 6.9112, 121.9260425356339, 1118735.404327914, 1118735.404327913, 245293.3932960805], 
processed observation next is [1.0, 0.5217391304347826, 0.4888888888888889, 0.6633333333333334, 1.0, 1.0, 0.3685969002702402, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.6941761274781988, 8.881784197001253e-17, 0.0, 0.8094621282888339, 0.39954835868854066, 0.39954835868854033, 0.47171806403092403], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7367118], dtype=float32), 0.37714937]. 
=============================================
[2019-03-24 00:46:02,181] A3C_AGENT_WORKER-Thread-22 INFO:Local step 136000, global step 2167252: loss 0.0068
[2019-03-24 00:46:02,182] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 136000, global step 2167252: learning rate 0.0005
[2019-03-24 00:46:04,066] A3C_AGENT_WORKER-Thread-2 INFO:Local step 135500, global step 2168218: loss 0.0910
[2019-03-24 00:46:04,072] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 135500, global step 2168220: learning rate 0.0005
[2019-03-24 00:46:04,255] A3C_AGENT_WORKER-Thread-19 INFO:Local step 135500, global step 2168312: loss 0.1109
[2019-03-24 00:46:04,257] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 135500, global step 2168312: learning rate 0.0005
[2019-03-24 00:46:04,381] A3C_AGENT_WORKER-Thread-21 INFO:Local step 135500, global step 2168379: loss 0.1254
[2019-03-24 00:46:04,387] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 135500, global step 2168381: learning rate 0.0005
[2019-03-24 00:46:04,836] A3C_AGENT_WORKER-Thread-11 INFO:Local step 135500, global step 2168613: loss 0.0924
[2019-03-24 00:46:04,837] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 135500, global step 2168613: learning rate 0.0005
[2019-03-24 00:46:04,939] A3C_AGENT_WORKER-Thread-9 INFO:Local step 135500, global step 2168660: loss 0.1005
[2019-03-24 00:46:04,942] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 135500, global step 2168662: learning rate 0.0005
[2019-03-24 00:46:05,171] A3C_AGENT_WORKER-Thread-14 INFO:Local step 135500, global step 2168782: loss 0.0624
[2019-03-24 00:46:05,173] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 135500, global step 2168783: learning rate 0.0005
[2019-03-24 00:46:05,613] A3C_AGENT_WORKER-Thread-12 INFO:Local step 135500, global step 2169006: loss 0.0052
[2019-03-24 00:46:05,620] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 135500, global step 2169009: learning rate 0.0005
[2019-03-24 00:46:05,792] A3C_AGENT_WORKER-Thread-13 INFO:Local step 135500, global step 2169100: loss 0.0025
[2019-03-24 00:46:05,798] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 135500, global step 2169101: learning rate 0.0005
[2019-03-24 00:46:06,021] A3C_AGENT_WORKER-Thread-16 INFO:Local step 135500, global step 2169214: loss 0.0093
[2019-03-24 00:46:06,026] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 135500, global step 2169215: learning rate 0.0005
[2019-03-24 00:46:06,205] A3C_AGENT_WORKER-Thread-10 INFO:Local step 135500, global step 2169309: loss 0.0011
[2019-03-24 00:46:06,207] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 135500, global step 2169310: learning rate 0.0005
[2019-03-24 00:46:06,337] A3C_AGENT_WORKER-Thread-15 INFO:Local step 135500, global step 2169381: loss 0.0001
[2019-03-24 00:46:06,341] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 135500, global step 2169381: learning rate 0.0005
[2019-03-24 00:46:06,669] A3C_AGENT_WORKER-Thread-20 INFO:Local step 135500, global step 2169552: loss 0.0098
[2019-03-24 00:46:06,675] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 135500, global step 2169552: learning rate 0.0005
[2019-03-24 00:46:06,723] A3C_AGENT_WORKER-Thread-3 INFO:Local step 135500, global step 2169578: loss 0.0094
[2019-03-24 00:46:06,728] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 135500, global step 2169579: learning rate 0.0005
[2019-03-24 00:46:06,927] A3C_AGENT_WORKER-Thread-17 INFO:Local step 135500, global step 2169680: loss 0.0036
[2019-03-24 00:46:06,932] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 135500, global step 2169681: learning rate 0.0005
[2019-03-24 00:46:07,540] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.7278283e-19 1.0000000e+00 4.8568914e-30 2.7785343e-29 1.3034885e-32], sum to 1.0000
[2019-03-24 00:46:07,551] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4527
[2019-03-24 00:46:07,554] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.96666666666667, 83.66666666666667, 1.0, 2.0, 0.3661199651335592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 461351.0107296385, 461351.0107296385, 124087.1220542682], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1837200.0000, 
sim time next is 1837800.0000, 
raw observation next is [20.1, 83.0, 1.0, 2.0, 0.3629908797728466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 457155.5864622861, 457155.5864622861, 123661.5328101723], 
processed observation next is [1.0, 0.2608695652173913, 0.30000000000000004, 0.83, 1.0, 1.0, 0.24165580925338884, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16326985230795932, 0.16326985230795932, 0.23781064001956212], 
reward next is 0.7622, 
noisyNet noise sample is [array([-0.8642128], dtype=float32), -1.0368052]. 
=============================================
[2019-03-24 00:46:09,165] A3C_AGENT_WORKER-Thread-18 INFO:Local step 136000, global step 2170839: loss 0.0005
[2019-03-24 00:46:09,168] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 136000, global step 2170839: learning rate 0.0005
[2019-03-24 00:46:16,606] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.1873866e-18 1.0000000e+00 1.5810746e-27 1.2418628e-25 4.0910180e-31], sum to 1.0000
[2019-03-24 00:46:16,615] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1759
[2019-03-24 00:46:16,623] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.35, 98.0, 1.0, 2.0, 0.5247841329304803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 619794.6712019248, 619794.6712019248, 146606.6178025482], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2256600.0000, 
sim time next is 2257200.0000, 
raw observation next is [22.2, 98.0, 1.0, 2.0, 0.5160748755089949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 611295.7919596261, 611295.7919596261, 145281.9931182174], 
processed observation next is [1.0, 0.13043478260869565, 0.37777777777777777, 0.98, 1.0, 1.0, 0.423898661320232, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21831992569986647, 0.21831992569986647, 0.27938844830426424], 
reward next is 0.7206, 
noisyNet noise sample is [array([-0.18033437], dtype=float32), -0.76972544]. 
=============================================
[2019-03-24 00:46:17,289] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-24 00:46:17,291] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:46:17,292] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:46:17,293] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:46:17,294] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:46:17,294] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:46:17,295] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:46:17,296] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:46:17,296] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:46:17,295] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:46:17,296] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:46:17,309] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run88
[2019-03-24 00:46:17,332] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run88
[2019-03-24 00:46:17,355] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run88
[2019-03-24 00:46:17,355] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run88
[2019-03-24 00:46:17,404] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run88
[2019-03-24 00:46:21,471] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.010525645]
[2019-03-24 00:46:21,472] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.21532079333333, 47.803036685, 1.0, 2.0, 0.2651661442565795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 342045.8743107476, 342045.8743107476, 103047.1709976105]
[2019-03-24 00:46:21,474] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:46:21,476] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.3307701e-18 1.0000000e+00 4.9351666e-29 1.0209592e-26 4.2864345e-31], sampled 0.8642683918497734
[2019-03-24 00:46:32,671] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.010525645]
[2019-03-24 00:46:32,675] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [16.41085190333333, 60.25044137, 1.0, 2.0, 0.192883927806244, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 248791.7226079226, 248791.7226079226, 75974.34615937558]
[2019-03-24 00:46:32,677] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:46:32,680] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.3307701e-18 1.0000000e+00 4.9351666e-29 1.0209592e-26 4.2864345e-31], sampled 0.24325036238873798
[2019-03-24 00:46:43,352] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.010525645]
[2019-03-24 00:46:43,353] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.86390559, 53.76274168, 1.0, 2.0, 0.3249889160219345, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 417317.6779113632, 417317.6779113632, 118716.0731257963]
[2019-03-24 00:46:43,355] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:46:43,358] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.3307701e-18 1.0000000e+00 4.9351666e-29 1.0209592e-26 4.2864345e-31], sampled 0.9245633806995768
[2019-03-24 00:47:22,498] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.010525645]
[2019-03-24 00:47:22,499] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.0, 86.0, 1.0, 2.0, 0.4496932095274092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 556954.1969189148, 556954.1969189143, 135834.2909151702]
[2019-03-24 00:47:22,501] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:47:22,504] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.3307701e-18 1.0000000e+00 4.9351666e-29 1.0209592e-26 4.2864345e-31], sampled 0.8439881753465162
[2019-03-24 00:47:32,517] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.010525645]
[2019-03-24 00:47:32,520] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [33.26040699000001, 81.33709469166666, 1.0, 2.0, 0.9828901070348381, 1.0, 2.0, 0.9828901070348381, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9259480897951, 2242407.420749065, 2242407.420749065, 425128.4719692171]
[2019-03-24 00:47:32,521] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:47:32,524] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.3307701e-18 1.0000000e+00 4.9351666e-29 1.0209592e-26 4.2864345e-31], sampled 0.4655135645753641
[2019-03-24 00:47:32,527] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2242407.420749065 W.
[2019-03-24 00:48:05,254] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 00:48:05,898] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 00:48:06,015] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 00:48:06,060] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 00:48:06,072] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 00:48:07,092] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 2175000, evaluation results [2175000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 00:48:07,795] A3C_AGENT_WORKER-Thread-22 INFO:Local step 136500, global step 2175339: loss 0.0248
[2019-03-24 00:48:07,797] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 136500, global step 2175339: learning rate 0.0005
[2019-03-24 00:48:09,684] A3C_AGENT_WORKER-Thread-19 INFO:Local step 136000, global step 2176262: loss 0.0089
[2019-03-24 00:48:09,685] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 136000, global step 2176263: learning rate 0.0005
[2019-03-24 00:48:09,735] A3C_AGENT_WORKER-Thread-2 INFO:Local step 136000, global step 2176286: loss 0.0037
[2019-03-24 00:48:09,743] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 136000, global step 2176286: learning rate 0.0005
[2019-03-24 00:48:09,974] A3C_AGENT_WORKER-Thread-21 INFO:Local step 136000, global step 2176403: loss 0.0094
[2019-03-24 00:48:09,977] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 136000, global step 2176403: learning rate 0.0005
[2019-03-24 00:48:10,236] A3C_AGENT_WORKER-Thread-11 INFO:Local step 136000, global step 2176527: loss 0.0012
[2019-03-24 00:48:10,238] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 136000, global step 2176529: learning rate 0.0005
[2019-03-24 00:48:10,324] A3C_AGENT_WORKER-Thread-9 INFO:Local step 136000, global step 2176574: loss 0.0002
[2019-03-24 00:48:10,326] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 136000, global step 2176574: learning rate 0.0005
[2019-03-24 00:48:10,633] A3C_AGENT_WORKER-Thread-14 INFO:Local step 136000, global step 2176726: loss 0.0112
[2019-03-24 00:48:10,634] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 136000, global step 2176726: learning rate 0.0005
[2019-03-24 00:48:11,301] A3C_AGENT_WORKER-Thread-12 INFO:Local step 136000, global step 2177052: loss 0.0061
[2019-03-24 00:48:11,306] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 136000, global step 2177052: learning rate 0.0005
[2019-03-24 00:48:11,562] A3C_AGENT_WORKER-Thread-16 INFO:Local step 136000, global step 2177177: loss 0.0032
[2019-03-24 00:48:11,567] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 136000, global step 2177179: learning rate 0.0005
[2019-03-24 00:48:11,610] A3C_AGENT_WORKER-Thread-10 INFO:Local step 136000, global step 2177204: loss 0.0002
[2019-03-24 00:48:11,613] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 136000, global step 2177206: learning rate 0.0005
[2019-03-24 00:48:11,668] A3C_AGENT_WORKER-Thread-13 INFO:Local step 136000, global step 2177229: loss 0.0009
[2019-03-24 00:48:11,669] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 136000, global step 2177229: learning rate 0.0005
[2019-03-24 00:48:12,028] A3C_AGENT_WORKER-Thread-15 INFO:Local step 136000, global step 2177396: loss 0.0022
[2019-03-24 00:48:12,033] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 136000, global step 2177397: learning rate 0.0005
[2019-03-24 00:48:12,224] A3C_AGENT_WORKER-Thread-20 INFO:Local step 136000, global step 2177493: loss 0.0054
[2019-03-24 00:48:12,225] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 136000, global step 2177493: learning rate 0.0005
[2019-03-24 00:48:12,252] A3C_AGENT_WORKER-Thread-3 INFO:Local step 136000, global step 2177507: loss 0.0068
[2019-03-24 00:48:12,254] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 136000, global step 2177507: learning rate 0.0005
[2019-03-24 00:48:12,705] A3C_AGENT_WORKER-Thread-17 INFO:Local step 136000, global step 2177725: loss 0.0197
[2019-03-24 00:48:12,706] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 136000, global step 2177726: learning rate 0.0005
[2019-03-24 00:48:12,942] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.3131523e-17 1.0000000e+00 4.0865166e-28 1.9872799e-24 1.0686491e-29], sum to 1.0000
[2019-03-24 00:48:12,951] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7102
[2019-03-24 00:48:12,960] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.45, 80.5, 1.0, 2.0, 0.5704104593919354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 663989.3012820509, 663989.3012820504, 153721.937805052], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2158200.0000, 
sim time next is 2158800.0000, 
raw observation next is [25.36666666666667, 81.0, 1.0, 2.0, 0.5693743025814705, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 662907.6950306101, 662907.6950306101, 153553.3460403517], 
processed observation next is [0.0, 1.0, 0.49506172839506185, 0.81, 1.0, 1.0, 0.4873503602160363, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23675274822521788, 0.23675274822521788, 0.29529489623144556], 
reward next is 0.7047, 
noisyNet noise sample is [array([0.0802328], dtype=float32), -0.37524945]. 
=============================================
[2019-03-24 00:48:15,188] A3C_AGENT_WORKER-Thread-18 INFO:Local step 136500, global step 2178895: loss 0.0634
[2019-03-24 00:48:15,190] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 136500, global step 2178895: learning rate 0.0005
[2019-03-24 00:48:16,276] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.2553170e-16 1.0000000e+00 6.1201727e-26 2.2803156e-23 1.7211969e-27], sum to 1.0000
[2019-03-24 00:48:16,285] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6755
[2019-03-24 00:48:16,291] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.75, 89.83333333333333, 1.0, 2.0, 0.705226143296477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 827451.1912768594, 827451.1912768594, 178272.225411337], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2178600.0000, 
sim time next is 2179200.0000, 
raw observation next is [23.8, 89.66666666666667, 1.0, 2.0, 0.6650567299520084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 779819.9792611891, 779819.9792611891, 170670.9893353782], 
processed observation next is [1.0, 0.21739130434782608, 0.43703703703703706, 0.8966666666666667, 1.0, 1.0, 0.601258011847629, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27850713545042466, 0.27850713545042466, 0.32821344102957345], 
reward next is 0.6718, 
noisyNet noise sample is [array([0.5131652], dtype=float32), 0.11534766]. 
=============================================
[2019-03-24 00:48:20,150] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.4342742e-17 1.0000000e+00 2.6115572e-28 1.0793448e-24 3.2188665e-30], sum to 1.0000
[2019-03-24 00:48:20,158] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7907
[2019-03-24 00:48:20,174] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.4, 96.0, 1.0, 2.0, 0.4213850374793857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 517407.3622732415, 517407.3622732415, 131557.3662005997], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2269800.0000, 
sim time next is 2270400.0000, 
raw observation next is [20.4, 96.0, 1.0, 2.0, 0.4227916523796962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 519134.5993493839, 519134.5993493839, 131760.6692666854], 
processed observation next is [1.0, 0.2608695652173913, 0.31111111111111106, 0.96, 1.0, 1.0, 0.312847205213924, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1854052140533514, 0.1854052140533514, 0.25338590243593345], 
reward next is 0.7466, 
noisyNet noise sample is [array([0.40445036], dtype=float32), 1.8276109]. 
=============================================
[2019-03-24 00:48:21,062] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1701932e-16 1.0000000e+00 3.4706321e-27 4.9017420e-25 7.2465258e-30], sum to 1.0000
[2019-03-24 00:48:21,070] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0205
[2019-03-24 00:48:21,074] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.73333333333333, 96.0, 1.0, 2.0, 0.6788867757876778, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 829392.6976834217, 829392.6976834217, 174500.7403044499], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2276400.0000, 
sim time next is 2277000.0000, 
raw observation next is [20.9, 95.5, 1.0, 2.0, 0.7663074427298493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 934285.1730905622, 934285.1730905632, 191714.2739000642], 
processed observation next is [1.0, 0.34782608695652173, 0.32962962962962955, 0.955, 1.0, 1.0, 0.721794574678392, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.33367327610377223, 0.33367327610377256, 0.36868129596166194], 
reward next is 0.6313, 
noisyNet noise sample is [array([1.0239307], dtype=float32), 0.3193013]. 
=============================================
[2019-03-24 00:48:21,096] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[69.431435]
 [69.431435]
 [69.431435]
 [69.431435]
 [69.431435]], R is [[69.36843872]
 [69.33917236]
 [69.3760376 ]
 [69.42211914]
 [69.46104431]].
[2019-03-24 00:48:22,018] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.1705566e-18 1.0000000e+00 7.5372185e-27 1.5445228e-23 6.5034086e-29], sum to 1.0000
[2019-03-24 00:48:22,026] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9732
[2019-03-24 00:48:22,032] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1359135.458549279 W.
[2019-03-24 00:48:22,042] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.6, 86.0, 1.0, 2.0, 0.9821762490134588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.287320572126373, 6.9112, 121.9245189289949, 1359135.458549279, 1166530.515322892, 238879.8972074021], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2287200.0000, 
sim time next is 2287800.0000, 
raw observation next is [23.7, 85.5, 1.0, 2.0, 0.3543192054391589, 1.0, 1.0, 0.3543192054391589, 1.0, 1.0, 0.5643398416306268, 6.9112, 6.9112, 121.94756008, 1219896.201387088, 1219896.201387088, 277691.636685291], 
processed observation next is [1.0, 0.4782608695652174, 0.4333333333333333, 0.855, 1.0, 1.0, 0.23133238742757012, 1.0, 0.5, 0.23133238742757012, 1.0, 0.5, 0.45542480203828345, 0.0, 0.0, 0.8096049824067558, 0.4356772147811029, 0.4356772147811029, 0.5340223782409442], 
reward next is 0.4660, 
noisyNet noise sample is [array([-1.3187312], dtype=float32), -0.13405915]. 
=============================================
[2019-03-24 00:48:22,090] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.7746742e-17 1.0000000e+00 3.3409862e-27 3.4314167e-26 1.3850042e-29], sum to 1.0000
[2019-03-24 00:48:22,096] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2052
[2019-03-24 00:48:22,107] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1438238.855465001 W.
[2019-03-24 00:48:22,111] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.56666666666666, 35.66666666666666, 1.0, 2.0, 0.5973228446870207, 1.0, 2.0, 0.5973228446870207, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1438238.855465001, 1438238.855465001, 270410.5432022117], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2540400.0000, 
sim time next is 2541000.0000, 
raw observation next is [30.73333333333333, 34.83333333333334, 1.0, 2.0, 0.4019876986682276, 1.0, 2.0, 0.4019876986682276, 1.0, 1.0, 0.6474581072158796, 6.911199999999999, 6.9112, 121.94756008, 1440896.708929031, 1440896.708929031, 297636.4937714906], 
processed observation next is [1.0, 0.391304347826087, 0.6938271604938271, 0.34833333333333344, 1.0, 1.0, 0.2880805936526519, 1.0, 1.0, 0.2880805936526519, 1.0, 0.5, 0.5593226340198495, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5146059674746539, 0.5146059674746539, 0.5723778726374819], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.4686182], dtype=float32), 0.91692734]. 
=============================================
[2019-03-24 00:48:22,123] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[69.68347]
 [69.68347]
 [69.68347]
 [69.68347]
 [69.68347]], R is [[68.98664856]
 [68.77676392]
 [68.08899689]
 [67.85595703]
 [67.61306763]].
[2019-03-24 00:48:23,635] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.4704851e-17 1.0000000e+00 1.3025412e-29 5.2200048e-26 5.9341231e-31], sum to 1.0000
[2019-03-24 00:48:23,647] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7166
[2019-03-24 00:48:23,652] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 82.5, 1.0, 2.0, 0.4696722654527678, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 567674.5294159328, 567674.5294159328, 138470.5893298454], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2323800.0000, 
sim time next is 2324400.0000, 
raw observation next is [22.96666666666667, 83.33333333333334, 1.0, 2.0, 0.468475655081486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 566399.445040213, 566399.445040213, 138293.9376769062], 
processed observation next is [1.0, 0.9130434782608695, 0.4061728395061729, 0.8333333333333335, 1.0, 1.0, 0.3672329227160548, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20228551608579035, 0.20228551608579035, 0.26594988014789656], 
reward next is 0.7341, 
noisyNet noise sample is [array([0.11945709], dtype=float32), -0.6952461]. 
=============================================
[2019-03-24 00:48:23,956] A3C_AGENT_WORKER-Thread-22 INFO:Local step 137000, global step 2183316: loss 0.0015
[2019-03-24 00:48:23,957] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 137000, global step 2183316: learning rate 0.0005
[2019-03-24 00:48:25,860] A3C_AGENT_WORKER-Thread-2 INFO:Local step 136500, global step 2184303: loss 0.0537
[2019-03-24 00:48:25,861] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 136500, global step 2184303: learning rate 0.0005
[2019-03-24 00:48:25,903] A3C_AGENT_WORKER-Thread-21 INFO:Local step 136500, global step 2184326: loss 0.0802
[2019-03-24 00:48:25,906] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 136500, global step 2184328: learning rate 0.0005
[2019-03-24 00:48:25,983] A3C_AGENT_WORKER-Thread-19 INFO:Local step 136500, global step 2184367: loss 0.0843
[2019-03-24 00:48:25,985] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 136500, global step 2184369: learning rate 0.0005
[2019-03-24 00:48:26,241] A3C_AGENT_WORKER-Thread-9 INFO:Local step 136500, global step 2184500: loss 0.1061
[2019-03-24 00:48:26,243] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 136500, global step 2184501: learning rate 0.0005
[2019-03-24 00:48:26,389] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.2527550e-16 1.0000000e+00 3.4483556e-27 4.7693102e-24 3.0529868e-28], sum to 1.0000
[2019-03-24 00:48:26,395] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7436
[2019-03-24 00:48:26,401] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.13333333333333, 61.66666666666667, 1.0, 2.0, 0.3811058109836294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 474904.7333167108, 474904.7333167108, 126045.9315545064], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2414400.0000, 
sim time next is 2415000.0000, 
raw observation next is [23.91666666666666, 62.83333333333334, 1.0, 2.0, 0.3815154235522328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 475508.6745527202, 475508.6745527197, 126104.1635692375], 
processed observation next is [1.0, 0.9565217391304348, 0.4413580246913578, 0.6283333333333334, 1.0, 1.0, 0.2637088375621819, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1698245266259715, 0.1698245266259713, 0.24250800686391827], 
reward next is 0.7575, 
noisyNet noise sample is [array([0.26622355], dtype=float32), 0.6905545]. 
=============================================
[2019-03-24 00:48:26,423] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[67.69819]
 [67.69819]
 [67.69819]
 [67.69819]
 [67.69819]], R is [[67.77870178]
 [67.85852051]
 [67.93757629]
 [68.01583862]
 [68.09314728]].
[2019-03-24 00:48:26,526] A3C_AGENT_WORKER-Thread-11 INFO:Local step 136500, global step 2184645: loss 0.1093
[2019-03-24 00:48:26,532] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 136500, global step 2184645: learning rate 0.0005
[2019-03-24 00:48:26,789] A3C_AGENT_WORKER-Thread-14 INFO:Local step 136500, global step 2184781: loss 0.0875
[2019-03-24 00:48:26,792] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 136500, global step 2184783: learning rate 0.0005
[2019-03-24 00:48:26,852] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.0260014e-16 1.0000000e+00 1.3965827e-26 3.5463853e-25 8.0397717e-29], sum to 1.0000
[2019-03-24 00:48:26,867] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1967
[2019-03-24 00:48:26,873] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 63.33333333333334, 1.0, 2.0, 0.3573889652369676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 448982.3204113223, 448982.3204113219, 122893.9134373079], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2418000.0000, 
sim time next is 2418600.0000, 
raw observation next is [22.95, 63.16666666666666, 1.0, 2.0, 0.3513750922220865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 442290.8304224999, 442290.8304224999, 122106.0050100347], 
processed observation next is [1.0, 1.0, 0.4055555555555555, 0.6316666666666666, 1.0, 1.0, 0.2278274907405792, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15796101086517855, 0.15796101086517855, 0.2348192404039129], 
reward next is 0.7652, 
noisyNet noise sample is [array([-0.3927036], dtype=float32), -0.78230387]. 
=============================================
[2019-03-24 00:48:27,301] A3C_AGENT_WORKER-Thread-12 INFO:Local step 136500, global step 2185040: loss 0.0073
[2019-03-24 00:48:27,304] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 136500, global step 2185042: learning rate 0.0005
[2019-03-24 00:48:27,409] A3C_AGENT_WORKER-Thread-16 INFO:Local step 136500, global step 2185094: loss 0.0163
[2019-03-24 00:48:27,413] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 136500, global step 2185095: learning rate 0.0005
[2019-03-24 00:48:27,543] A3C_AGENT_WORKER-Thread-10 INFO:Local step 136500, global step 2185166: loss 0.0013
[2019-03-24 00:48:27,545] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 136500, global step 2185166: learning rate 0.0005
[2019-03-24 00:48:27,725] A3C_AGENT_WORKER-Thread-13 INFO:Local step 136500, global step 2185260: loss 0.0005
[2019-03-24 00:48:27,725] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 136500, global step 2185260: learning rate 0.0005
[2019-03-24 00:48:28,105] A3C_AGENT_WORKER-Thread-15 INFO:Local step 136500, global step 2185455: loss 0.0081
[2019-03-24 00:48:28,109] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 136500, global step 2185455: learning rate 0.0005
[2019-03-24 00:48:28,247] A3C_AGENT_WORKER-Thread-3 INFO:Local step 136500, global step 2185529: loss 0.0030
[2019-03-24 00:48:28,249] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 136500, global step 2185529: learning rate 0.0005
[2019-03-24 00:48:28,264] A3C_AGENT_WORKER-Thread-20 INFO:Local step 136500, global step 2185537: loss 0.0005
[2019-03-24 00:48:28,265] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 136500, global step 2185537: learning rate 0.0005
[2019-03-24 00:48:28,401] A3C_AGENT_WORKER-Thread-17 INFO:Local step 136500, global step 2185609: loss 0.0016
[2019-03-24 00:48:28,406] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 136500, global step 2185612: learning rate 0.0005
[2019-03-24 00:48:29,826] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.1569124e-17 1.0000000e+00 1.1807510e-27 8.0688882e-24 2.0783933e-28], sum to 1.0000
[2019-03-24 00:48:29,833] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8407
[2019-03-24 00:48:29,838] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.33333333333334, 33.0, 1.0, 2.0, 0.3290749942637201, 1.0, 2.0, 0.3290749942637201, 1.0, 2.0, 0.5344212435453375, 6.911200000000001, 6.9112, 121.94756008, 1195796.798805335, 1195796.798805334, 266541.7900026229], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2452800.0000, 
sim time next is 2453400.0000, 
raw observation next is [30.6, 32.0, 1.0, 2.0, 0.9333809506778168, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.232811398335112, 6.9112, 121.9246840710885, 1321108.426116872, 1156416.47994706, 229037.8649264053], 
processed observation next is [1.0, 0.391304347826087, 0.688888888888889, 0.32, 1.0, 1.0, 0.9206916079497819, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.03216113983351123, 0.0, 0.809453109496956, 0.4718244378988829, 0.4130058856953786, 0.44045743255077946], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8127385], dtype=float32), 2.0861063]. 
=============================================
[2019-03-24 00:48:31,013] A3C_AGENT_WORKER-Thread-18 INFO:Local step 137000, global step 2186947: loss 0.0101
[2019-03-24 00:48:31,016] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 137000, global step 2186949: learning rate 0.0005
[2019-03-24 00:48:31,235] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.6828602e-18 1.0000000e+00 3.7456647e-29 1.8765996e-26 2.6997838e-30], sum to 1.0000
[2019-03-24 00:48:31,240] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2687
[2019-03-24 00:48:31,245] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 97.0, 1.0, 2.0, 0.540568202211106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 638698.3872514431, 638698.3872514431, 149180.0193241225], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2853000.0000, 
sim time next is 2853600.0000, 
raw observation next is [22.66666666666666, 96.0, 1.0, 2.0, 0.5420500040597784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 639883.7637113745, 639883.7637113745, 149400.1401901021], 
processed observation next is [1.0, 0.0, 0.3950617283950615, 0.96, 1.0, 1.0, 0.4548214334044981, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22852991561120517, 0.22852991561120517, 0.2873079619040425], 
reward next is 0.7127, 
noisyNet noise sample is [array([-0.6659665], dtype=float32), 0.8572848]. 
=============================================
[2019-03-24 00:48:32,490] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.3515408e-18 1.0000000e+00 3.8017779e-29 5.5612229e-27 2.0987793e-30], sum to 1.0000
[2019-03-24 00:48:32,497] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5490
[2019-03-24 00:48:32,501] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.25, 54.83333333333334, 1.0, 2.0, 0.6316914366261032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 719912.9796798103, 719912.9796798103, 163614.4649415837], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2739000.0000, 
sim time next is 2739600.0000, 
raw observation next is [31.1, 56.0, 1.0, 2.0, 0.637984176867282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 727087.960380671, 727087.960380671, 164734.9683219793], 
processed observation next is [0.0, 0.7391304347826086, 0.7074074074074075, 0.56, 1.0, 1.0, 0.5690287819848595, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2596742715645253, 0.2596742715645253, 0.31679801600380636], 
reward next is 0.6832, 
noisyNet noise sample is [array([0.36665308], dtype=float32), 0.86129427]. 
=============================================
[2019-03-24 00:48:32,576] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.8575565e-19 1.0000000e+00 3.0578923e-29 1.0501175e-27 2.8215644e-32], sum to 1.0000
[2019-03-24 00:48:32,583] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5323
[2019-03-24 00:48:32,592] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1415654.288600646 W.
[2019-03-24 00:48:32,594] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.4, 36.5, 1.0, 2.0, 0.5866413717156037, 1.0, 1.0, 0.5866413717156037, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1415654.288600646, 1415654.288600646, 266808.2686723173], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2539800.0000, 
sim time next is 2540400.0000, 
raw observation next is [30.56666666666666, 35.66666666666666, 1.0, 2.0, 0.5966630583584409, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9576184355092866, 6.911199999999999, 6.9112, 121.9260426156618, 1438269.288187254, 1438269.288187254, 288368.1614502828], 
processed observation next is [1.0, 0.391304347826087, 0.687654320987654, 0.3566666666666666, 1.0, 1.0, 0.5198369742362392, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9470230443866081, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5136676029240193, 0.5136676029240193, 0.5545541566351592], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1387197], dtype=float32), 1.7412052]. 
=============================================
[2019-03-24 00:48:34,874] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.9406472e-17 1.0000000e+00 1.1585715e-27 1.5321692e-24 1.9185587e-28], sum to 1.0000
[2019-03-24 00:48:34,883] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4161
[2019-03-24 00:48:34,886] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.6, 64.0, 1.0, 2.0, 0.5013315521229745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 599791.3945577956, 599791.3945577956, 143171.8190985648], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2584800.0000, 
sim time next is 2585400.0000, 
raw observation next is [26.35, 65.33333333333334, 1.0, 2.0, 0.500466627995941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 598922.0960266674, 598922.0960266674, 143041.6198984788], 
processed observation next is [1.0, 0.9565217391304348, 0.5314814814814816, 0.6533333333333334, 1.0, 1.0, 0.40531741428088214, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21390074858095265, 0.21390074858095265, 0.2750800382663054], 
reward next is 0.7249, 
noisyNet noise sample is [array([0.5639985], dtype=float32), 0.9969633]. 
=============================================
[2019-03-24 00:48:39,593] A3C_AGENT_WORKER-Thread-22 INFO:Local step 137500, global step 2191315: loss 0.0004
[2019-03-24 00:48:39,594] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 137500, global step 2191315: learning rate 0.0005
[2019-03-24 00:48:41,493] A3C_AGENT_WORKER-Thread-19 INFO:Local step 137000, global step 2192292: loss 0.0027
[2019-03-24 00:48:41,493] A3C_AGENT_WORKER-Thread-21 INFO:Local step 137000, global step 2192292: loss 0.0015
[2019-03-24 00:48:41,495] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 137000, global step 2192292: learning rate 0.0005
[2019-03-24 00:48:41,500] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 137000, global step 2192294: learning rate 0.0005
[2019-03-24 00:48:41,545] A3C_AGENT_WORKER-Thread-2 INFO:Local step 137000, global step 2192316: loss 0.0023
[2019-03-24 00:48:41,547] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 137000, global step 2192316: learning rate 0.0005
[2019-03-24 00:48:41,889] A3C_AGENT_WORKER-Thread-9 INFO:Local step 137000, global step 2192498: loss 0.0049
[2019-03-24 00:48:41,891] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 137000, global step 2192498: learning rate 0.0005
[2019-03-24 00:48:42,198] A3C_AGENT_WORKER-Thread-11 INFO:Local step 137000, global step 2192651: loss 0.0020
[2019-03-24 00:48:42,199] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 137000, global step 2192652: learning rate 0.0005
[2019-03-24 00:48:42,248] A3C_AGENT_WORKER-Thread-14 INFO:Local step 137000, global step 2192681: loss 0.0043
[2019-03-24 00:48:42,249] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 137000, global step 2192681: learning rate 0.0005
[2019-03-24 00:48:42,839] A3C_AGENT_WORKER-Thread-12 INFO:Local step 137000, global step 2192988: loss 0.0025
[2019-03-24 00:48:42,841] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 137000, global step 2192988: learning rate 0.0005
[2019-03-24 00:48:43,118] A3C_AGENT_WORKER-Thread-10 INFO:Local step 137000, global step 2193132: loss 0.0067
[2019-03-24 00:48:43,121] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 137000, global step 2193133: learning rate 0.0005
[2019-03-24 00:48:43,155] A3C_AGENT_WORKER-Thread-16 INFO:Local step 137000, global step 2193150: loss 0.0062
[2019-03-24 00:48:43,155] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 137000, global step 2193150: learning rate 0.0005
[2019-03-24 00:48:43,457] A3C_AGENT_WORKER-Thread-13 INFO:Local step 137000, global step 2193303: loss 0.0001
[2019-03-24 00:48:43,458] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 137000, global step 2193303: learning rate 0.0005
[2019-03-24 00:48:43,539] A3C_AGENT_WORKER-Thread-3 INFO:Local step 137000, global step 2193351: loss 0.0057
[2019-03-24 00:48:43,541] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 137000, global step 2193351: learning rate 0.0005
[2019-03-24 00:48:43,752] A3C_AGENT_WORKER-Thread-15 INFO:Local step 137000, global step 2193460: loss 0.0122
[2019-03-24 00:48:43,756] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 137000, global step 2193461: learning rate 0.0005
[2019-03-24 00:48:44,046] A3C_AGENT_WORKER-Thread-20 INFO:Local step 137000, global step 2193612: loss 0.0093
[2019-03-24 00:48:44,050] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 137000, global step 2193614: learning rate 0.0005
[2019-03-24 00:48:44,129] A3C_AGENT_WORKER-Thread-17 INFO:Local step 137000, global step 2193655: loss 0.0028
[2019-03-24 00:48:44,130] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 137000, global step 2193655: learning rate 0.0005
[2019-03-24 00:48:44,413] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.4152366e-16 1.0000000e+00 3.5091476e-26 1.8223848e-25 1.0214962e-27], sum to 1.0000
[2019-03-24 00:48:44,422] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2138
[2019-03-24 00:48:44,427] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 94.0, 1.0, 2.0, 0.6597399492486619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 751894.4035702609, 751894.4035702604, 168659.7031069087], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2766000.0000, 
sim time next is 2766600.0000, 
raw observation next is [24.5, 94.0, 1.0, 2.0, 0.6518766736000849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 743235.5905917881, 743235.5905917881, 167246.4320610408], 
processed observation next is [1.0, 0.0, 0.46296296296296297, 0.94, 1.0, 1.0, 0.5855674685715296, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26544128235421, 0.26544128235421, 0.32162775396354], 
reward next is 0.6784, 
noisyNet noise sample is [array([0.5842946], dtype=float32), -0.9807425]. 
=============================================
[2019-03-24 00:48:47,010] A3C_AGENT_WORKER-Thread-18 INFO:Local step 137500, global step 2195140: loss 0.0182
[2019-03-24 00:48:47,013] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 137500, global step 2195140: learning rate 0.0005
[2019-03-24 00:48:48,160] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.8814474e-16 1.0000000e+00 4.4258893e-25 1.5532608e-24 3.2781157e-27], sum to 1.0000
[2019-03-24 00:48:48,167] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3689
[2019-03-24 00:48:48,171] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.83333333333334, 70.66666666666667, 1.0, 2.0, 0.6795815737279838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 774518.9902854369, 774518.9902854369, 172314.1513497765], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2841000.0000, 
sim time next is 2841600.0000, 
raw observation next is [28.66666666666667, 71.33333333333334, 1.0, 2.0, 0.6778806273293413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 772579.4450334242, 772579.4450334242, 171998.2318263067], 
processed observation next is [1.0, 0.9130434782608695, 0.6172839506172841, 0.7133333333333334, 1.0, 1.0, 0.6165245563444539, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27592123036908006, 0.27592123036908006, 0.3307658304352052], 
reward next is 0.6692, 
noisyNet noise sample is [array([0.412667], dtype=float32), -0.6275518]. 
=============================================
[2019-03-24 00:48:49,719] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2342506e-16 1.0000000e+00 2.3936867e-27 4.9734501e-24 6.1929943e-28], sum to 1.0000
[2019-03-24 00:48:49,728] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0652
[2019-03-24 00:48:49,733] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.00000000000001, 1.0, 2.0, 0.5691350708377527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 683119.485250628, 683119.485250628, 154335.1069546173], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2873400.0000, 
sim time next is 2874000.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5315716039274221, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 638016.850732596, 638016.850732596, 148088.1144290869], 
processed observation next is [1.0, 0.2608695652173913, 0.37037037037037035, 0.94, 1.0, 1.0, 0.4423471475326453, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22786316097592715, 0.22786316097592715, 0.2847848354405518], 
reward next is 0.7152, 
noisyNet noise sample is [array([0.8436043], dtype=float32), -0.9579152]. 
=============================================
[2019-03-24 00:48:49,755] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[60.053513]
 [60.053513]
 [60.053513]
 [60.053513]
 [60.053513]], R is [[60.16819   ]
 [60.26971054]
 [60.38892746]
 [60.50540543]
 [60.61862946]].
[2019-03-24 00:48:51,151] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.1931724e-17 1.0000000e+00 6.8932823e-27 4.3786336e-25 1.6230628e-28], sum to 1.0000
[2019-03-24 00:48:51,160] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4850
[2019-03-24 00:48:51,165] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 94.0, 1.0, 2.0, 0.5305051270056265, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 634281.1623141796, 634281.1623141796, 147826.3930934278], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2871000.0000, 
sim time next is 2871600.0000, 
raw observation next is [22.13333333333333, 94.0, 1.0, 2.0, 0.5221099896723945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 625007.2064691097, 625007.2064691097, 146495.1361821729], 
processed observation next is [1.0, 0.21739130434782608, 0.3753086419753085, 0.94, 1.0, 1.0, 0.4310833210385649, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22321685945325348, 0.22321685945325348, 0.28172141573494786], 
reward next is 0.7183, 
noisyNet noise sample is [array([1.0540209], dtype=float32), -1.9605933]. 
=============================================
[2019-03-24 00:48:55,149] A3C_AGENT_WORKER-Thread-22 INFO:Local step 138000, global step 2199327: loss 0.0207
[2019-03-24 00:48:55,151] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 138000, global step 2199327: learning rate 0.0005
[2019-03-24 00:48:56,478] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-24 00:48:56,480] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:48:56,482] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:48:56,483] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:48:56,484] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:48:56,486] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:48:56,487] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:48:56,488] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:48:56,488] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:48:56,489] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:48:56,491] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:48:56,511] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run89
[2019-03-24 00:48:56,537] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run89
[2019-03-24 00:48:56,560] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run89
[2019-03-24 00:48:56,562] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run89
[2019-03-24 00:48:56,611] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run89
[2019-03-24 00:48:59,211] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.006987824]
[2019-03-24 00:48:59,212] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.83333333333334, 38.66666666666667, 1.0, 2.0, 0.3228019596746945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 416412.2498678816, 416412.2498678816, 100269.4072605166]
[2019-03-24 00:48:59,213] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:48:59,218] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.5506247e-16 1.0000000e+00 4.8098319e-25 4.3683444e-23 6.3550419e-27], sampled 0.8787435314516842
[2019-03-24 00:49:23,705] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.006987824]
[2019-03-24 00:49:23,707] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.05470686, 84.85924125333332, 1.0, 2.0, 0.4096280220663939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 506664.616417945, 506664.616417945, 129963.077991052]
[2019-03-24 00:49:23,708] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:49:23,709] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.5506247e-16 1.0000000e+00 4.8098319e-25 4.3683444e-23 6.3550419e-27], sampled 0.1641861545437019
[2019-03-24 00:50:06,744] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.006987824]
[2019-03-24 00:50:06,745] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [33.98437741000001, 68.91423242833334, 1.0, 2.0, 1.00846977548902, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.196848950506821, 6.9112, 121.9247935042728, 1296020.040194901, 1149743.745112824, 242799.1267811572]
[2019-03-24 00:50:06,745] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:50:06,747] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.5506247e-16 1.0000000e+00 4.8098319e-25 4.3683444e-23 6.3550419e-27], sampled 0.7318522840126667
[2019-03-24 00:50:06,748] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1296020.040194901 W.
[2019-03-24 00:50:10,429] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.006987824]
[2019-03-24 00:50:10,431] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.66666666666667, 81.0, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 8.539074622896768, 6.9112, 121.9194912403271, 1996948.611487933, 1163376.099016157, 245592.1931299276]
[2019-03-24 00:50:10,432] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:50:10,437] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.5506247e-16 1.0000000e+00 4.8098319e-25 4.3683444e-23 6.3550419e-27], sampled 0.8955535277447301
[2019-03-24 00:50:10,439] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 1996948.611487933 W.
[2019-03-24 00:50:44,764] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 00:50:44,837] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 00:50:44,953] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 00:50:45,095] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 00:50:45,099] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 00:50:46,117] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 2200000, evaluation results [2200000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 00:50:46,160] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.9289319e-16 1.0000000e+00 1.2359929e-25 1.3243859e-22 2.1939325e-27], sum to 1.0000
[2019-03-24 00:50:46,162] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7248
[2019-03-24 00:50:46,163] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1701247.528558022 W.
[2019-03-24 00:50:46,170] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.33333333333333, 85.66666666666667, 1.0, 2.0, 0.8651008387690075, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426156618, 1701247.528558022, 1701247.528558022, 349536.4648771599], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2972400.0000, 
sim time next is 2973000.0000, 
raw observation next is [27.66666666666667, 84.83333333333333, 1.0, 2.0, 0.8959679985563601, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1736481.913634674, 1736481.913634674, 356100.1211347933], 
processed observation next is [1.0, 0.391304347826087, 0.580246913580247, 0.8483333333333333, 1.0, 1.0, 0.876152379233762, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8094621288201359, 0.6201721120123835, 0.6201721120123835, 0.684807925259218], 
reward next is 0.3152, 
noisyNet noise sample is [array([0.96663547], dtype=float32), -0.20919351]. 
=============================================
[2019-03-24 00:50:46,198] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[62.645382]
 [62.645382]
 [62.645382]
 [62.645382]
 [62.645382]], R is [[62.33412552]
 [62.03860092]
 [61.74739838]
 [61.49662781]
 [61.3253479 ]].
[2019-03-24 00:50:46,689] A3C_AGENT_WORKER-Thread-2 INFO:Local step 137500, global step 2200274: loss 0.0161
[2019-03-24 00:50:46,690] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 137500, global step 2200274: learning rate 0.0005
[2019-03-24 00:50:46,706] A3C_AGENT_WORKER-Thread-19 INFO:Local step 137500, global step 2200282: loss 0.0270
[2019-03-24 00:50:46,710] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 137500, global step 2200283: learning rate 0.0005
[2019-03-24 00:50:46,794] A3C_AGENT_WORKER-Thread-21 INFO:Local step 137500, global step 2200326: loss 0.0308
[2019-03-24 00:50:46,796] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 137500, global step 2200327: learning rate 0.0005
[2019-03-24 00:50:46,917] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.6626774e-16 1.0000000e+00 4.4197288e-26 8.2891863e-23 3.3384636e-27], sum to 1.0000
[2019-03-24 00:50:46,923] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4227
[2019-03-24 00:50:46,928] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 96.0, 1.0, 2.0, 0.6696604098340553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 763206.2124771667, 763206.2124771667, 170478.0468787134], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3014400.0000, 
sim time next is 3015000.0000, 
raw observation next is [24.5, 97.0, 1.0, 2.0, 0.6675610301110462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 760812.3800345018, 760812.3800345018, 170091.8973812267], 
processed observation next is [1.0, 0.9130434782608695, 0.46296296296296297, 0.97, 1.0, 1.0, 0.6042393215607692, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2717187071551792, 0.2717187071551792, 0.3270998026562052], 
reward next is 0.6729, 
noisyNet noise sample is [array([0.38255256], dtype=float32), 0.90140796]. 
=============================================
[2019-03-24 00:50:46,946] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[62.541046]
 [62.541046]
 [62.541046]
 [62.541046]
 [62.541046]], R is [[62.58853912]
 [62.6348114 ]
 [62.68058395]
 [62.72579956]
 [62.77044296]].
[2019-03-24 00:50:47,073] A3C_AGENT_WORKER-Thread-9 INFO:Local step 137500, global step 2200456: loss 0.0216
[2019-03-24 00:50:47,075] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 137500, global step 2200457: learning rate 0.0005
[2019-03-24 00:50:47,218] A3C_AGENT_WORKER-Thread-11 INFO:Local step 137500, global step 2200524: loss 0.0272
[2019-03-24 00:50:47,221] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 137500, global step 2200524: learning rate 0.0005
[2019-03-24 00:50:47,757] A3C_AGENT_WORKER-Thread-14 INFO:Local step 137500, global step 2200786: loss 0.0179
[2019-03-24 00:50:47,761] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 137500, global step 2200786: learning rate 0.0005
[2019-03-24 00:50:48,372] A3C_AGENT_WORKER-Thread-12 INFO:Local step 137500, global step 2201081: loss 0.0142
[2019-03-24 00:50:48,374] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 137500, global step 2201081: learning rate 0.0005
[2019-03-24 00:50:48,416] A3C_AGENT_WORKER-Thread-16 INFO:Local step 137500, global step 2201099: loss 0.0075
[2019-03-24 00:50:48,418] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 137500, global step 2201099: learning rate 0.0005
[2019-03-24 00:50:48,523] A3C_AGENT_WORKER-Thread-10 INFO:Local step 137500, global step 2201154: loss 0.0302
[2019-03-24 00:50:48,527] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 137500, global step 2201155: learning rate 0.0005
[2019-03-24 00:50:48,908] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.8885819e-18 1.0000000e+00 6.6966318e-28 8.1977684e-24 3.4510630e-29], sum to 1.0000
[2019-03-24 00:50:48,914] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4883
[2019-03-24 00:50:48,918] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.25, 89.0, 1.0, 2.0, 0.7029316328388014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 801144.9558198173, 801144.9558198177, 176699.8361702037], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3007800.0000, 
sim time next is 3008400.0000, 
raw observation next is [26.33333333333333, 87.33333333333334, 1.0, 2.0, 0.6965778471637474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 793899.6714965801, 793899.6714965801, 175496.7159459192], 
processed observation next is [1.0, 0.8260869565217391, 0.530864197530864, 0.8733333333333334, 1.0, 1.0, 0.6387831513854135, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28353559696306435, 0.28353559696306435, 0.33749368451138306], 
reward next is 0.6625, 
noisyNet noise sample is [array([-1.0203146], dtype=float32), -0.9671673]. 
=============================================
[2019-03-24 00:50:48,933] A3C_AGENT_WORKER-Thread-13 INFO:Local step 137500, global step 2201352: loss 0.0004
[2019-03-24 00:50:48,937] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 137500, global step 2201353: learning rate 0.0005
[2019-03-24 00:50:49,112] A3C_AGENT_WORKER-Thread-3 INFO:Local step 137500, global step 2201443: loss 0.0001
[2019-03-24 00:50:49,114] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 137500, global step 2201443: learning rate 0.0005
[2019-03-24 00:50:49,201] A3C_AGENT_WORKER-Thread-15 INFO:Local step 137500, global step 2201485: loss 0.0009
[2019-03-24 00:50:49,204] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 137500, global step 2201485: learning rate 0.0005
[2019-03-24 00:50:49,555] A3C_AGENT_WORKER-Thread-20 INFO:Local step 137500, global step 2201657: loss 0.0010
[2019-03-24 00:50:49,555] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 137500, global step 2201657: learning rate 0.0005
[2019-03-24 00:50:49,625] A3C_AGENT_WORKER-Thread-17 INFO:Local step 137500, global step 2201693: loss 0.0059
[2019-03-24 00:50:49,627] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 137500, global step 2201693: learning rate 0.0005
[2019-03-24 00:50:52,343] A3C_AGENT_WORKER-Thread-18 INFO:Local step 138000, global step 2202959: loss 0.2091
[2019-03-24 00:50:52,344] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 138000, global step 2202960: learning rate 0.0005
[2019-03-24 00:50:53,933] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.0551210e-16 1.0000000e+00 2.1087117e-25 2.1271994e-23 2.1629696e-27], sum to 1.0000
[2019-03-24 00:50:53,941] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9021
[2019-03-24 00:50:53,947] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 58.5, 1.0, 2.0, 0.7222731072721863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 865844.4228313398, 865844.4228313398, 182334.1132085401], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3123000.0000, 
sim time next is 3123600.0000, 
raw observation next is [27.33333333333334, 59.66666666666666, 1.0, 2.0, 0.7017534219718824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 840483.618160428, 840483.6181604277, 178309.7348553585], 
processed observation next is [1.0, 0.13043478260869565, 0.5679012345679014, 0.5966666666666666, 1.0, 1.0, 0.6449445499665266, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3001727207715814, 0.3001727207715813, 0.3429033362603048], 
reward next is 0.6571, 
noisyNet noise sample is [array([-1.8825752], dtype=float32), 0.73897886]. 
=============================================
[2019-03-24 00:50:58,318] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.1682838e-18 1.0000000e+00 3.1251122e-28 5.5822009e-27 1.2040695e-30], sum to 1.0000
[2019-03-24 00:50:58,322] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7040
[2019-03-24 00:50:58,325] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 77.33333333333334, 1.0, 2.0, 0.6325958712483213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 724073.7752239255, 724073.7752239255, 163930.8332694805], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3194400.0000, 
sim time next is 3195000.0000, 
raw observation next is [26.5, 76.5, 1.0, 2.0, 0.6165856403400658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 710160.061140504, 710160.0611405035, 161319.4098633579], 
processed observation next is [1.0, 1.0, 0.5370370370370371, 0.765, 1.0, 1.0, 0.5435543337381735, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2536285932644657, 0.2536285932644655, 0.31022963435261136], 
reward next is 0.6898, 
noisyNet noise sample is [array([-0.7817903], dtype=float32), -0.27263066]. 
=============================================
[2019-03-24 00:50:58,362] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[72.071465]
 [72.071465]
 [72.071465]
 [72.071465]
 [72.071465]], R is [[72.04051971]
 [72.00485992]
 [71.96635437]
 [71.92803955]
 [71.89619446]].
[2019-03-24 00:51:01,058] A3C_AGENT_WORKER-Thread-22 INFO:Local step 138500, global step 2207367: loss 0.0083
[2019-03-24 00:51:01,060] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 138500, global step 2207369: learning rate 0.0005
[2019-03-24 00:51:01,379] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.2666355e-17 1.0000000e+00 1.2723387e-29 4.1083056e-28 3.8880722e-31], sum to 1.0000
[2019-03-24 00:51:01,386] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7941
[2019-03-24 00:51:01,396] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.75, 86.5, 1.0, 2.0, 0.7613243142715215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 867733.9122287877, 867733.9122287877, 188073.4312240109], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3485400.0000, 
sim time next is 3486000.0000, 
raw observation next is [26.0, 87.0, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.980273668499027, 6.9112, 121.9222091590134, 1710633.865388088, 1163189.807036133, 245582.905562069], 
processed observation next is [1.0, 0.34782608695652173, 0.5185185185185185, 0.87, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.10690736684990272, 0.0, 0.8094366786545045, 0.6109406662100314, 0.4154249310843332, 0.47227481838859425], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3014905], dtype=float32), 0.11577755]. 
=============================================
[2019-03-24 00:51:01,408] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[73.10786]
 [73.10786]
 [73.10786]
 [73.10786]
 [73.10786]], R is [[72.37678528]
 [72.29133606]
 [72.21852112]
 [72.14605713]
 [72.06624603]].
[2019-03-24 00:51:01,450] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2094036e-17 1.0000000e+00 1.8872070e-29 2.8166232e-28 5.8816381e-30], sum to 1.0000
[2019-03-24 00:51:01,456] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5995
[2019-03-24 00:51:01,460] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.03333333333333, 52.0, 1.0, 2.0, 0.5312279187013786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 625686.6586002983, 625686.6586002983, 147578.5212422718], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3238800.0000, 
sim time next is 3239400.0000, 
raw observation next is [30.01666666666667, 53.5, 1.0, 2.0, 0.5450065601841901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 638482.2916295945, 638482.2916295945, 149683.3631815191], 
processed observation next is [0.0, 0.4782608695652174, 0.6672839506172841, 0.535, 1.0, 1.0, 0.4583411430764168, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22802938986771232, 0.22802938986771232, 0.28785262150292135], 
reward next is 0.7121, 
noisyNet noise sample is [array([0.7595933], dtype=float32), 0.5319861]. 
=============================================
[2019-03-24 00:51:01,664] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.2132368e-17 1.0000000e+00 2.0032300e-27 7.4723543e-25 5.6380726e-29], sum to 1.0000
[2019-03-24 00:51:01,678] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2873
[2019-03-24 00:51:01,682] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 46.0, 1.0, 2.0, 0.5271903366549884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 623891.9955625709, 623891.9955625709, 147044.3631974255], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3243600.0000, 
sim time next is 3244200.0000, 
raw observation next is [31.0, 46.33333333333334, 1.0, 2.0, 0.5258961550290514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 622309.786574726, 622309.786574726, 146833.7960976989], 
processed observation next is [0.0, 0.5652173913043478, 0.7037037037037037, 0.46333333333333343, 1.0, 1.0, 0.4355906607488707, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22225349520525928, 0.22225349520525928, 0.28237268480326716], 
reward next is 0.7176, 
noisyNet noise sample is [array([-0.19774032], dtype=float32), -0.15597348]. 
=============================================
[2019-03-24 00:51:02,696] A3C_AGENT_WORKER-Thread-21 INFO:Local step 138000, global step 2208212: loss 0.0156
[2019-03-24 00:51:02,700] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 138000, global step 2208213: learning rate 0.0005
[2019-03-24 00:51:02,733] A3C_AGENT_WORKER-Thread-2 INFO:Local step 138000, global step 2208231: loss 0.0130
[2019-03-24 00:51:02,736] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 138000, global step 2208231: learning rate 0.0005
[2019-03-24 00:51:02,945] A3C_AGENT_WORKER-Thread-19 INFO:Local step 138000, global step 2208342: loss 0.0000
[2019-03-24 00:51:02,950] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 138000, global step 2208343: learning rate 0.0005
[2019-03-24 00:51:03,138] A3C_AGENT_WORKER-Thread-9 INFO:Local step 138000, global step 2208440: loss 0.0013
[2019-03-24 00:51:03,143] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 138000, global step 2208440: learning rate 0.0005
[2019-03-24 00:51:03,428] A3C_AGENT_WORKER-Thread-11 INFO:Local step 138000, global step 2208591: loss 0.0240
[2019-03-24 00:51:03,430] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 138000, global step 2208591: learning rate 0.0005
[2019-03-24 00:51:03,667] A3C_AGENT_WORKER-Thread-14 INFO:Local step 138000, global step 2208712: loss 0.0028
[2019-03-24 00:51:03,669] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 138000, global step 2208712: learning rate 0.0005
[2019-03-24 00:51:03,989] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.7292049e-19 1.0000000e+00 8.0917744e-28 5.2606650e-26 5.5584967e-31], sum to 1.0000
[2019-03-24 00:51:03,996] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0000
[2019-03-24 00:51:03,999] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.96666666666667, 93.33333333333334, 1.0, 2.0, 0.5418473262755364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 640300.9767796063, 640300.9767796058, 149393.3834556077], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3282600.0000, 
sim time next is 3283200.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.5478967285937212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 645976.409441284, 645976.409441284, 150329.111849044], 
processed observation next is [0.0, 0.0, 0.4074074074074074, 0.94, 1.0, 1.0, 0.46178181975442995, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2307058605147443, 0.2307058605147443, 0.28909444586354616], 
reward next is 0.7109, 
noisyNet noise sample is [array([0.8726443], dtype=float32), 0.91138893]. 
=============================================
[2019-03-24 00:51:04,314] A3C_AGENT_WORKER-Thread-12 INFO:Local step 138000, global step 2209044: loss 0.0010
[2019-03-24 00:51:04,315] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 138000, global step 2209045: learning rate 0.0005
[2019-03-24 00:51:04,384] A3C_AGENT_WORKER-Thread-16 INFO:Local step 138000, global step 2209081: loss 0.0012
[2019-03-24 00:51:04,386] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 138000, global step 2209082: learning rate 0.0005
[2019-03-24 00:51:04,406] A3C_AGENT_WORKER-Thread-10 INFO:Local step 138000, global step 2209090: loss 0.0015
[2019-03-24 00:51:04,408] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 138000, global step 2209090: learning rate 0.0005
[2019-03-24 00:51:05,013] A3C_AGENT_WORKER-Thread-13 INFO:Local step 138000, global step 2209406: loss 0.0059
[2019-03-24 00:51:05,015] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 138000, global step 2209406: learning rate 0.0005
[2019-03-24 00:51:05,161] A3C_AGENT_WORKER-Thread-3 INFO:Local step 138000, global step 2209481: loss 0.0030
[2019-03-24 00:51:05,163] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 138000, global step 2209482: learning rate 0.0005
[2019-03-24 00:51:05,228] A3C_AGENT_WORKER-Thread-15 INFO:Local step 138000, global step 2209514: loss 0.0054
[2019-03-24 00:51:05,229] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 138000, global step 2209514: learning rate 0.0005
[2019-03-24 00:51:05,421] A3C_AGENT_WORKER-Thread-17 INFO:Local step 138000, global step 2209612: loss 0.0292
[2019-03-24 00:51:05,423] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 138000, global step 2209612: learning rate 0.0005
[2019-03-24 00:51:05,497] A3C_AGENT_WORKER-Thread-20 INFO:Local step 138000, global step 2209649: loss 0.0175
[2019-03-24 00:51:05,499] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 138000, global step 2209651: learning rate 0.0005
[2019-03-24 00:51:06,900] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.7531049e-18 1.0000000e+00 3.0358684e-28 3.7450686e-27 1.0553038e-31], sum to 1.0000
[2019-03-24 00:51:06,908] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3779
[2019-03-24 00:51:06,912] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.7, 96.0, 1.0, 2.0, 0.6620022063601347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 754473.9283978356, 754473.9283978356, 169073.9856961255], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3722400.0000, 
sim time next is 3723000.0000, 
raw observation next is [24.75, 95.66666666666667, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.830594728986208, 6.9112, 123.2776490220669, 1639163.046004168, 1163131.599010828, 245785.9300534966], 
processed observation next is [1.0, 0.08695652173913043, 0.4722222222222222, 0.9566666666666667, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.09193947289862078, 0.0, 0.8184353897870679, 0.5854153735729172, 0.41540414250386715, 0.4726652501028781], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8275991], dtype=float32), -0.98168486]. 
=============================================
[2019-03-24 00:51:06,932] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[69.30775]
 [69.30775]
 [69.30775]
 [69.30775]
 [69.30775]], R is [[68.6146698 ]
 [68.6033783 ]
 [68.59162903]
 [68.58002472]
 [68.56911469]].
[2019-03-24 00:51:07,026] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4549066e-17 1.0000000e+00 2.0627167e-26 7.1391172e-27 2.0322608e-29], sum to 1.0000
[2019-03-24 00:51:07,034] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3677
[2019-03-24 00:51:07,038] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 86.0, 1.0, 2.0, 0.8419478080802272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 992834.9753227871, 992834.9753227871, 206414.4930890402], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3587400.0000, 
sim time next is 3588000.0000, 
raw observation next is [24.0, 87.0, 1.0, 2.0, 0.8618438369333191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1013835.535287393, 1013835.535287393, 210643.3967009101], 
processed observation next is [1.0, 0.5217391304347826, 0.4444444444444444, 0.87, 1.0, 1.0, 0.8355283773015704, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.36208411974549753, 0.36208411974549753, 0.40508345519405786], 
reward next is 0.5949, 
noisyNet noise sample is [array([-0.45070666], dtype=float32), -1.4143575]. 
=============================================
[2019-03-24 00:51:07,052] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[66.424805]
 [66.424805]
 [66.424805]
 [66.424805]
 [66.424805]], R is [[66.35547638]
 [66.29497528]
 [65.63202667]
 [64.97570801]
 [64.32595062]].
[2019-03-24 00:51:08,298] A3C_AGENT_WORKER-Thread-18 INFO:Local step 138500, global step 2211099: loss 0.0865
[2019-03-24 00:51:08,299] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 138500, global step 2211099: learning rate 0.0005
[2019-03-24 00:51:16,459] A3C_AGENT_WORKER-Thread-22 INFO:Local step 139000, global step 2215274: loss 0.0214
[2019-03-24 00:51:16,462] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 139000, global step 2215276: learning rate 0.0005
[2019-03-24 00:51:18,316] A3C_AGENT_WORKER-Thread-21 INFO:Local step 138500, global step 2216232: loss 0.0213
[2019-03-24 00:51:18,319] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 138500, global step 2216232: learning rate 0.0005
[2019-03-24 00:51:18,354] A3C_AGENT_WORKER-Thread-2 INFO:Local step 138500, global step 2216250: loss 0.0246
[2019-03-24 00:51:18,355] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 138500, global step 2216250: learning rate 0.0005
[2019-03-24 00:51:18,397] A3C_AGENT_WORKER-Thread-19 INFO:Local step 138500, global step 2216270: loss 0.0174
[2019-03-24 00:51:18,399] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 138500, global step 2216270: learning rate 0.0005
[2019-03-24 00:51:18,635] A3C_AGENT_WORKER-Thread-9 INFO:Local step 138500, global step 2216392: loss 0.0010
[2019-03-24 00:51:18,636] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 138500, global step 2216392: learning rate 0.0005
[2019-03-24 00:51:18,944] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.7882828e-17 1.0000000e+00 6.4049339e-27 1.2828592e-24 2.3178028e-27], sum to 1.0000
[2019-03-24 00:51:18,953] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7369
[2019-03-24 00:51:18,956] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 88.0, 1.0, 2.0, 0.5457005767406324, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 641986.4578980857, 641986.4578980857, 149909.4450543516], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3624000.0000, 
sim time next is 3624600.0000, 
raw observation next is [24.0, 85.0, 1.0, 2.0, 0.5352603653976642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 632176.4500010482, 632176.4500010482, 148302.9018014316], 
processed observation next is [1.0, 0.9565217391304348, 0.4444444444444444, 0.85, 1.0, 1.0, 0.4467385302353145, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22577730357180292, 0.22577730357180292, 0.28519788807967617], 
reward next is 0.7148, 
noisyNet noise sample is [array([-0.9285425], dtype=float32), -0.061573185]. 
=============================================
[2019-03-24 00:51:19,222] A3C_AGENT_WORKER-Thread-14 INFO:Local step 138500, global step 2216693: loss 0.0298
[2019-03-24 00:51:19,223] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 138500, global step 2216693: learning rate 0.0005
[2019-03-24 00:51:19,291] A3C_AGENT_WORKER-Thread-11 INFO:Local step 138500, global step 2216730: loss 0.0263
[2019-03-24 00:51:19,293] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 138500, global step 2216730: learning rate 0.0005
[2019-03-24 00:51:19,798] A3C_AGENT_WORKER-Thread-12 INFO:Local step 138500, global step 2216984: loss 0.0317
[2019-03-24 00:51:19,801] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 138500, global step 2216985: learning rate 0.0005
[2019-03-24 00:51:20,083] A3C_AGENT_WORKER-Thread-16 INFO:Local step 138500, global step 2217127: loss 0.0043
[2019-03-24 00:51:20,084] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 138500, global step 2217127: learning rate 0.0005
[2019-03-24 00:51:20,161] A3C_AGENT_WORKER-Thread-10 INFO:Local step 138500, global step 2217170: loss 0.0050
[2019-03-24 00:51:20,163] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 138500, global step 2217171: learning rate 0.0005
[2019-03-24 00:51:20,733] A3C_AGENT_WORKER-Thread-13 INFO:Local step 138500, global step 2217463: loss 0.0036
[2019-03-24 00:51:20,737] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 138500, global step 2217463: learning rate 0.0005
[2019-03-24 00:51:20,824] A3C_AGENT_WORKER-Thread-15 INFO:Local step 138500, global step 2217513: loss 0.0074
[2019-03-24 00:51:20,831] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 138500, global step 2217515: learning rate 0.0005
[2019-03-24 00:51:20,962] A3C_AGENT_WORKER-Thread-3 INFO:Local step 138500, global step 2217584: loss 0.0049
[2019-03-24 00:51:20,965] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 138500, global step 2217585: learning rate 0.0005
[2019-03-24 00:51:21,044] A3C_AGENT_WORKER-Thread-20 INFO:Local step 138500, global step 2217621: loss 0.0059
[2019-03-24 00:51:21,050] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 138500, global step 2217621: learning rate 0.0005
[2019-03-24 00:51:21,150] A3C_AGENT_WORKER-Thread-17 INFO:Local step 138500, global step 2217677: loss 0.0000
[2019-03-24 00:51:21,152] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 138500, global step 2217679: learning rate 0.0005
[2019-03-24 00:51:23,747] A3C_AGENT_WORKER-Thread-18 INFO:Local step 139000, global step 2219011: loss 0.0003
[2019-03-24 00:51:23,750] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 139000, global step 2219012: learning rate 0.0005
[2019-03-24 00:51:29,179] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4133746e-14 1.0000000e+00 2.0940833e-24 2.2276122e-22 8.7757725e-27], sum to 1.0000
[2019-03-24 00:51:29,186] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3963
[2019-03-24 00:51:29,198] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 79.0, 1.0, 2.0, 0.6266055113852503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 717501.9396928785, 717501.9396928785, 162882.9673076873], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3803400.0000, 
sim time next is 3804000.0000, 
raw observation next is [26.33333333333334, 80.66666666666667, 1.0, 2.0, 0.6309695370669983, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 721121.8955817649, 721121.8955817653, 163588.0578404977], 
processed observation next is [0.0, 0.0, 0.5308641975308644, 0.8066666666666668, 1.0, 1.0, 0.5606780203178551, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2575435341363446, 0.2575435341363448, 0.31459241892403406], 
reward next is 0.6854, 
noisyNet noise sample is [array([-0.81989944], dtype=float32), -0.3344795]. 
=============================================
[2019-03-24 00:51:29,215] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[61.646816]
 [61.646816]
 [61.646816]
 [61.646816]
 [61.646816]], R is [[61.71575546]
 [61.78536224]
 [61.85503006]
 [61.92412567]
 [61.99114609]].
[2019-03-24 00:51:30,389] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1153625e-17 1.0000000e+00 7.0931322e-27 2.8004819e-25 1.2090324e-28], sum to 1.0000
[2019-03-24 00:51:30,401] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2013
[2019-03-24 00:51:30,407] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.66666666666667, 59.0, 1.0, 2.0, 0.669489475163272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 763011.3027412394, 763011.3027412394, 170446.6460248948], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3792000.0000, 
sim time next is 3792600.0000, 
raw observation next is [30.5, 59.0, 1.0, 2.0, 0.6637572086087636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 756475.0649514459, 756475.0649514459, 169394.0642132334], 
processed observation next is [1.0, 0.9130434782608695, 0.6851851851851852, 0.59, 1.0, 1.0, 0.5997109626294805, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2701696660540878, 0.2701696660540878, 0.3257578157946796], 
reward next is 0.6742, 
noisyNet noise sample is [array([0.17474566], dtype=float32), -1.1387774]. 
=============================================
[2019-03-24 00:51:30,876] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2932664e-16 1.0000000e+00 1.4391297e-26 3.6970786e-26 1.6208477e-28], sum to 1.0000
[2019-03-24 00:51:30,880] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5086
[2019-03-24 00:51:30,890] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.5, 61.0, 1.0, 2.0, 0.6465257311494234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 736827.145683931, 736827.145683931, 166268.162857049], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3835800.0000, 
sim time next is 3836400.0000, 
raw observation next is [30.66666666666666, 61.66666666666667, 1.0, 2.0, 0.6693843567870451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 762891.4406287103, 762891.4406287099, 170429.6781177777], 
processed observation next is [0.0, 0.391304347826087, 0.6913580246913578, 0.6166666666666667, 1.0, 1.0, 0.606409948556006, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27246122879596796, 0.2724612287959678, 0.3277493809957263], 
reward next is 0.6723, 
noisyNet noise sample is [array([0.10559094], dtype=float32), 2.670348]. 
=============================================
[2019-03-24 00:51:31,701] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.0625767e-17 1.0000000e+00 5.8264219e-27 5.2450407e-24 1.1150882e-28], sum to 1.0000
[2019-03-24 00:51:31,709] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3696
[2019-03-24 00:51:31,716] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.7, 54.0, 1.0, 2.0, 0.6633544376759383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 756015.8060258911, 756015.8060258911, 169320.9014074612], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3839400.0000, 
sim time next is 3840000.0000, 
raw observation next is [31.93333333333333, 51.0, 1.0, 2.0, 0.6481785967793179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 738711.7777041461, 738711.7777041461, 166562.782038945], 
processed observation next is [0.0, 0.43478260869565216, 0.7382716049382715, 0.51, 1.0, 1.0, 0.5811649961658546, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2638256348943379, 0.2638256348943379, 0.32031304238258657], 
reward next is 0.6797, 
noisyNet noise sample is [array([-0.14421527], dtype=float32), 0.8957542]. 
=============================================
[2019-03-24 00:51:31,738] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[66.86633]
 [66.86633]
 [66.86633]
 [66.86633]
 [66.86633]], R is [[66.87734985]
 [66.88296509]
 [66.88694   ]
 [66.8848877 ]
 [66.87713623]].
[2019-03-24 00:51:32,122] A3C_AGENT_WORKER-Thread-22 INFO:Local step 139500, global step 2223289: loss 0.0390
[2019-03-24 00:51:32,124] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 139500, global step 2223290: learning rate 0.0005
[2019-03-24 00:51:33,903] A3C_AGENT_WORKER-Thread-19 INFO:Local step 139000, global step 2224211: loss 0.0003
[2019-03-24 00:51:33,912] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 139000, global step 2224212: learning rate 0.0005
[2019-03-24 00:51:34,014] A3C_AGENT_WORKER-Thread-2 INFO:Local step 139000, global step 2224269: loss 0.0086
[2019-03-24 00:51:34,019] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 139000, global step 2224269: learning rate 0.0005
[2019-03-24 00:51:34,040] A3C_AGENT_WORKER-Thread-21 INFO:Local step 139000, global step 2224279: loss 0.0099
[2019-03-24 00:51:34,043] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 139000, global step 2224279: learning rate 0.0005
[2019-03-24 00:51:34,145] A3C_AGENT_WORKER-Thread-9 INFO:Local step 139000, global step 2224339: loss 0.0003
[2019-03-24 00:51:34,149] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 139000, global step 2224340: learning rate 0.0005
[2019-03-24 00:51:34,745] A3C_AGENT_WORKER-Thread-14 INFO:Local step 139000, global step 2224647: loss 0.0039
[2019-03-24 00:51:34,749] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 139000, global step 2224649: learning rate 0.0005
[2019-03-24 00:51:34,756] A3C_AGENT_WORKER-Thread-11 INFO:Local step 139000, global step 2224651: loss 0.0026
[2019-03-24 00:51:34,758] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 139000, global step 2224652: learning rate 0.0005
[2019-03-24 00:51:35,440] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-24 00:51:35,441] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:51:35,441] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:51:35,442] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:51:35,444] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:51:35,443] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:51:35,445] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:51:35,449] A3C_AGENT_WORKER-Thread-12 INFO:Local step 139000, global step 2225000: loss 0.0071
[2019-03-24 00:51:35,449] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:51:35,450] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:51:35,451] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:51:35,452] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 139000, global step 2225000: learning rate 0.0005
[2019-03-24 00:51:35,452] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:51:35,472] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run90
[2019-03-24 00:51:35,498] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run90
[2019-03-24 00:51:35,521] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run90
[2019-03-24 00:51:35,522] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run90
[2019-03-24 00:51:35,567] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run90
[2019-03-24 00:52:02,349] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.023203943]
[2019-03-24 00:52:02,349] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.72962996, 54.6851051, 1.0, 2.0, 0.5361165472431862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 656922.2401181622, 656922.2401181622, 149255.7274149532]
[2019-03-24 00:52:02,350] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:52:02,353] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.8719260e-16 1.0000000e+00 3.3426070e-26 3.8630566e-24 3.9607878e-28], sampled 0.644801836865463
[2019-03-24 00:52:30,230] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.023203943]
[2019-03-24 00:52:30,231] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.77924898, 85.84062934, 1.0, 2.0, 0.8711027046003493, 1.0, 2.0, 0.8711027046003493, 0.0, 2.0, 0.0, 6.911199999999997, 6.9112, 121.9260426156618, 1987087.090789079, 1987087.090789081, 374013.1461091777]
[2019-03-24 00:52:30,232] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:52:30,236] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.8719260e-16 1.0000000e+00 3.3426070e-26 3.8630566e-24 3.9607878e-28], sampled 0.1957621425438767
[2019-03-24 00:52:30,237] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 1987087.090789079 W.
[2019-03-24 00:53:07,331] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.023203943]
[2019-03-24 00:53:07,332] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [20.5, 91.0, 1.0, 2.0, 0.3942202543922471, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 487269.1902649514, 487269.1902649509, 127780.4739219945]
[2019-03-24 00:53:07,334] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:53:07,337] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.8719260e-16 1.0000000e+00 3.3426070e-26 3.8630566e-24 3.9607878e-28], sampled 0.7018537122217081
[2019-03-24 00:53:09,109] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.023203943]
[2019-03-24 00:53:09,110] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.26666666666667, 50.0, 1.0, 2.0, 0.4425216931398862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 538382.4795429888, 538382.4795429888, 134508.9895004141]
[2019-03-24 00:53:09,111] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:53:09,114] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.8719260e-16 1.0000000e+00 3.3426070e-26 3.8630566e-24 3.9607878e-28], sampled 0.20491765440944376
[2019-03-24 00:53:24,109] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 00:53:24,239] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 00:53:24,490] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 00:53:24,568] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 00:53:24,611] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 00:53:25,628] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 2225000, evaluation results [2225000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 00:53:25,755] A3C_AGENT_WORKER-Thread-16 INFO:Local step 139000, global step 2225065: loss 0.0036
[2019-03-24 00:53:25,761] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 139000, global step 2225065: learning rate 0.0005
[2019-03-24 00:53:25,965] A3C_AGENT_WORKER-Thread-10 INFO:Local step 139000, global step 2225163: loss 0.0063
[2019-03-24 00:53:25,966] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 139000, global step 2225163: learning rate 0.0005
[2019-03-24 00:53:26,584] A3C_AGENT_WORKER-Thread-13 INFO:Local step 139000, global step 2225469: loss 0.0080
[2019-03-24 00:53:26,586] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 139000, global step 2225469: learning rate 0.0005
[2019-03-24 00:53:26,624] A3C_AGENT_WORKER-Thread-15 INFO:Local step 139000, global step 2225487: loss 0.0073
[2019-03-24 00:53:26,627] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 139000, global step 2225487: learning rate 0.0005
[2019-03-24 00:53:26,717] A3C_AGENT_WORKER-Thread-20 INFO:Local step 139000, global step 2225536: loss 0.0011
[2019-03-24 00:53:26,718] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 139000, global step 2225536: learning rate 0.0005
[2019-03-24 00:53:26,722] A3C_AGENT_WORKER-Thread-3 INFO:Local step 139000, global step 2225537: loss 0.0000
[2019-03-24 00:53:26,723] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 139000, global step 2225537: learning rate 0.0005
[2019-03-24 00:53:27,035] A3C_AGENT_WORKER-Thread-17 INFO:Local step 139000, global step 2225684: loss 0.0009
[2019-03-24 00:53:27,040] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 139000, global step 2225684: learning rate 0.0005
[2019-03-24 00:53:30,107] A3C_AGENT_WORKER-Thread-18 INFO:Local step 139500, global step 2227122: loss 0.1181
[2019-03-24 00:53:30,110] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 139500, global step 2227123: learning rate 0.0005
[2019-03-24 00:53:30,529] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.0586845e-15 1.0000000e+00 1.4136775e-24 1.3952764e-21 9.4756018e-26], sum to 1.0000
[2019-03-24 00:53:30,533] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4154
[2019-03-24 00:53:30,542] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.65, 86.5, 1.0, 2.0, 0.660744432026017, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 753039.7578387725, 753039.7578387725, 168842.7262019876], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3979800.0000, 
sim time next is 3980400.0000, 
raw observation next is [25.6, 86.66666666666667, 1.0, 2.0, 0.658279340239721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 750228.9576975147, 750228.9576975147, 168393.295580194], 
processed observation next is [1.0, 0.043478260869565216, 0.5037037037037038, 0.8666666666666667, 1.0, 1.0, 0.5931896907615726, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2679389134633981, 0.2679389134633981, 0.3238332607311423], 
reward next is 0.6762, 
noisyNet noise sample is [array([-1.2881643], dtype=float32), -0.66804975]. 
=============================================
[2019-03-24 00:53:31,974] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.7659845e-12 1.0000000e+00 1.8506582e-19 4.7826197e-20 1.1023659e-21], sum to 1.0000
[2019-03-24 00:53:31,989] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1358
[2019-03-24 00:53:31,992] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.3, 94.0, 1.0, 2.0, 0.8110699747695412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 929583.0077484575, 929583.007748457, 198504.3711269733], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4003200.0000, 
sim time next is 4003800.0000, 
raw observation next is [24.35, 94.00000000000001, 1.0, 2.0, 0.774259906716116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 886807.544539354, 886807.544539354, 190900.6015343669], 
processed observation next is [1.0, 0.34782608695652173, 0.4574074074074075, 0.9400000000000002, 1.0, 1.0, 0.7312617937096619, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31671698019262645, 0.31671698019262645, 0.36711654141224404], 
reward next is 0.6329, 
noisyNet noise sample is [array([-0.09940121], dtype=float32), 0.010229679]. 
=============================================
[2019-03-24 00:53:35,097] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.3157364e-18 1.0000000e+00 8.8946771e-27 3.3891745e-27 1.6665403e-30], sum to 1.0000
[2019-03-24 00:53:35,104] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7523
[2019-03-24 00:53:35,114] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1568375.10679983 W.
[2019-03-24 00:53:35,118] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.1, 68.0, 1.0, 2.0, 0.6865345313875316, 1.0, 1.0, 0.6865345313875316, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1568375.10679983, 1568375.10679983, 299235.7834571198], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4100400.0000, 
sim time next is 4101000.0000, 
raw observation next is [27.25, 68.33333333333334, 1.0, 2.0, 0.7256455767882949, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9930246931371809, 6.9112, 6.9112, 121.9260426156618, 1546292.46388633, 1546292.46388633, 321147.632902167], 
processed observation next is [1.0, 0.4782608695652174, 0.5648148148148148, 0.6833333333333335, 1.0, 1.0, 0.6733875914146368, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9912808664214762, 0.0, 0.0, 0.8094621288201359, 0.5522473085308321, 0.5522473085308321, 0.6175916017349365], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1524997], dtype=float32), 0.6966721]. 
=============================================
[2019-03-24 00:53:35,131] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[70.2826]
 [70.2826]
 [70.2826]
 [70.2826]
 [70.2826]], R is [[69.57976532]
 [69.30850983]
 [68.99166107]
 [68.6802597 ]
 [68.39000702]].
[2019-03-24 00:53:35,646] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.2914076e-15 1.0000000e+00 9.3598553e-25 5.4838960e-24 2.3252341e-26], sum to 1.0000
[2019-03-24 00:53:35,655] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6937
[2019-03-24 00:53:35,661] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.15, 96.5, 1.0, 2.0, 0.4678262314666509, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 576209.2482661438, 576209.2482661438, 138501.161176072], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4080600.0000, 
sim time next is 4081200.0000, 
raw observation next is [20.1, 97.66666666666666, 1.0, 2.0, 0.4457470319325644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 548340.6811479942, 548340.6811479942, 135154.6661254478], 
processed observation next is [1.0, 0.21739130434782608, 0.30000000000000004, 0.9766666666666666, 1.0, 1.0, 0.3401750380149576, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19583595755285507, 0.19583595755285507, 0.259912819472015], 
reward next is 0.7401, 
noisyNet noise sample is [array([0.4706856], dtype=float32), -1.0476322]. 
=============================================
[2019-03-24 00:53:38,245] A3C_AGENT_WORKER-Thread-22 INFO:Local step 140000, global step 2231273: loss 0.0078
[2019-03-24 00:53:38,248] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 140000, global step 2231273: learning rate 0.0005
[2019-03-24 00:53:38,613] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.0277495e-18 1.0000000e+00 1.8797636e-29 5.7107903e-26 1.3037385e-30], sum to 1.0000
[2019-03-24 00:53:38,621] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8135
[2019-03-24 00:53:38,627] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 91.0, 1.0, 2.0, 0.4495754593660087, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 547601.2038882084, 547601.2038882084, 135574.8591224398], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4149000.0000, 
sim time next is 4149600.0000, 
raw observation next is [21.33333333333334, 92.0, 1.0, 2.0, 0.447091540122169, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 544950.4612085358, 544950.4612085358, 135216.0390475166], 
processed observation next is [1.0, 0.0, 0.3456790123456792, 0.92, 1.0, 1.0, 0.3417756430025821, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1946251647173342, 0.1946251647173342, 0.2600308443221473], 
reward next is 0.7400, 
noisyNet noise sample is [array([1.0813332], dtype=float32), 0.45895028]. 
=============================================
[2019-03-24 00:53:40,288] A3C_AGENT_WORKER-Thread-21 INFO:Local step 139500, global step 2232320: loss 0.0299
[2019-03-24 00:53:40,290] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 139500, global step 2232320: learning rate 0.0005
[2019-03-24 00:53:40,331] A3C_AGENT_WORKER-Thread-9 INFO:Local step 139500, global step 2232342: loss 0.0172
[2019-03-24 00:53:40,337] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 139500, global step 2232343: learning rate 0.0005
[2019-03-24 00:53:40,383] A3C_AGENT_WORKER-Thread-19 INFO:Local step 139500, global step 2232366: loss 0.0323
[2019-03-24 00:53:40,387] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 139500, global step 2232368: learning rate 0.0005
[2019-03-24 00:53:40,530] A3C_AGENT_WORKER-Thread-2 INFO:Local step 139500, global step 2232441: loss 0.0295
[2019-03-24 00:53:40,534] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 139500, global step 2232441: learning rate 0.0005
[2019-03-24 00:53:41,093] A3C_AGENT_WORKER-Thread-14 INFO:Local step 139500, global step 2232735: loss 0.0745
[2019-03-24 00:53:41,097] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 139500, global step 2232735: learning rate 0.0005
[2019-03-24 00:53:41,163] A3C_AGENT_WORKER-Thread-11 INFO:Local step 139500, global step 2232766: loss 0.0743
[2019-03-24 00:53:41,164] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 139500, global step 2232766: learning rate 0.0005
[2019-03-24 00:53:41,761] A3C_AGENT_WORKER-Thread-12 INFO:Local step 139500, global step 2233079: loss 0.0452
[2019-03-24 00:53:41,763] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 139500, global step 2233079: learning rate 0.0005
[2019-03-24 00:53:41,864] A3C_AGENT_WORKER-Thread-10 INFO:Local step 139500, global step 2233131: loss 0.0742
[2019-03-24 00:53:41,866] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 139500, global step 2233131: learning rate 0.0005
[2019-03-24 00:53:41,924] A3C_AGENT_WORKER-Thread-16 INFO:Local step 139500, global step 2233162: loss 0.0471
[2019-03-24 00:53:41,928] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 139500, global step 2233162: learning rate 0.0005
[2019-03-24 00:53:42,506] A3C_AGENT_WORKER-Thread-15 INFO:Local step 139500, global step 2233465: loss 0.0988
[2019-03-24 00:53:42,509] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 139500, global step 2233466: learning rate 0.0005
[2019-03-24 00:53:42,545] A3C_AGENT_WORKER-Thread-13 INFO:Local step 139500, global step 2233477: loss 0.0032
[2019-03-24 00:53:42,547] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 139500, global step 2233478: learning rate 0.0005
[2019-03-24 00:53:42,678] A3C_AGENT_WORKER-Thread-3 INFO:Local step 139500, global step 2233549: loss 0.0065
[2019-03-24 00:53:42,684] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 139500, global step 2233550: learning rate 0.0005
[2019-03-24 00:53:42,731] A3C_AGENT_WORKER-Thread-17 INFO:Local step 139500, global step 2233570: loss 0.0977
[2019-03-24 00:53:42,732] A3C_AGENT_WORKER-Thread-20 INFO:Local step 139500, global step 2233571: loss 0.1065
[2019-03-24 00:53:42,734] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 139500, global step 2233571: learning rate 0.0005
[2019-03-24 00:53:42,734] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 139500, global step 2233571: learning rate 0.0005
[2019-03-24 00:53:42,835] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.4254776e-16 1.0000000e+00 8.2850560e-28 3.8889721e-26 8.8993130e-30], sum to 1.0000
[2019-03-24 00:53:42,844] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0566
[2019-03-24 00:53:42,848] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.66666666666667, 53.5, 1.0, 2.0, 0.8618923034903412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1047173.681189519, 1047173.681189519, 212016.0120692184], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4263000.0000, 
sim time next is 4263600.0000, 
raw observation next is [27.53333333333333, 56.00000000000001, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 8.194125495982636, 6.9112, 121.9213212878555, 1889941.298748285, 1232994.218095148, 249059.8236964876], 
processed observation next is [1.0, 0.34782608695652173, 0.5753086419753086, 0.56, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.12829254959826358, 0.0, 0.809430784113337, 0.6749790352672447, 0.44035507789112427, 0.4789611994163223], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.38406783], dtype=float32), 0.49033606]. 
=============================================
[2019-03-24 00:53:45,102] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.9778506e-15 1.0000000e+00 1.8964691e-26 2.5269779e-24 1.2981821e-27], sum to 1.0000
[2019-03-24 00:53:45,107] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5249
[2019-03-24 00:53:45,111] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.9, 62.5, 1.0, 2.0, 0.65622651571126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 796797.3480477565, 796797.3480477565, 170090.3462891639], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4260600.0000, 
sim time next is 4261200.0000, 
raw observation next is [26.53333333333333, 58.66666666666667, 1.0, 2.0, 0.6758993271741583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 821336.3357851495, 821336.3357851495, 173796.0542069971], 
processed observation next is [1.0, 0.30434782608695654, 0.5382716049382715, 0.5866666666666667, 1.0, 1.0, 0.6141658656835218, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29333440563755336, 0.29333440563755336, 0.3342231811673021], 
reward next is 0.6658, 
noisyNet noise sample is [array([0.594997], dtype=float32), -0.6797794]. 
=============================================
[2019-03-24 00:53:45,586] A3C_AGENT_WORKER-Thread-18 INFO:Local step 140000, global step 2235035: loss 0.0485
[2019-03-24 00:53:45,589] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 140000, global step 2235035: learning rate 0.0005
[2019-03-24 00:53:46,511] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.6001451e-17 1.0000000e+00 5.0732429e-25 2.1954178e-24 2.7749039e-27], sum to 1.0000
[2019-03-24 00:53:46,521] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1014
[2019-03-24 00:53:46,523] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.6949883398649036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 817901.6465955796, 817901.6465955796, 176421.0260183743], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4334400.0000, 
sim time next is 4335000.0000, 
raw observation next is [22.8, 93.33333333333334, 1.0, 2.0, 0.6601276689176622, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 780728.552444114, 780728.552444114, 170044.6125982598], 
processed observation next is [1.0, 0.17391304347826086, 0.4, 0.9333333333333335, 1.0, 1.0, 0.5953900820448359, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27883162587289784, 0.27883162587289784, 0.3270088703812688], 
reward next is 0.6730, 
noisyNet noise sample is [array([0.9097477], dtype=float32), 1.3781741]. 
=============================================
[2019-03-24 00:53:46,542] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[63.88298]
 [63.88298]
 [63.88298]
 [63.88298]
 [63.88298]], R is [[63.91714478]
 [63.93870163]
 [63.94067001]
 [63.93513489]
 [63.92268753]].
[2019-03-24 00:53:52,767] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.5539654e-18 1.0000000e+00 1.6515618e-28 4.6905842e-26 1.4651554e-31], sum to 1.0000
[2019-03-24 00:53:52,773] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0475
[2019-03-24 00:53:52,779] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.66666666666666, 68.0, 1.0, 2.0, 0.6529735032143044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 744179.0566972746, 744179.0566972746, 167430.2853066807], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4455600.0000, 
sim time next is 4456200.0000, 
raw observation next is [28.83333333333334, 66.5, 1.0, 2.0, 0.647354711370501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 737772.3657206857, 737772.3657206857, 166414.7957691248], 
processed observation next is [0.0, 0.5652173913043478, 0.623456790123457, 0.665, 1.0, 1.0, 0.5801841802029775, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2634901306145306, 0.2634901306145306, 0.32002845340216307], 
reward next is 0.6800, 
noisyNet noise sample is [array([-2.8222914], dtype=float32), 1.0116193]. 
=============================================
[2019-03-24 00:53:53,578] A3C_AGENT_WORKER-Thread-22 INFO:Local step 140500, global step 2239135: loss -103.0297
[2019-03-24 00:53:53,583] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 140500, global step 2239135: learning rate 0.0005
[2019-03-24 00:53:54,241] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.9551316e-17 1.0000000e+00 5.3640716e-27 1.8364389e-26 5.7884890e-29], sum to 1.0000
[2019-03-24 00:53:54,249] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3140
[2019-03-24 00:53:54,254] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.7034178820199884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 801699.4333667646, 801699.4333667646, 176792.2746753431], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4483200.0000, 
sim time next is 4483800.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.70774869391627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 806637.943608253, 806637.9436082535, 177616.2081375977], 
processed observation next is [0.0, 0.9130434782608695, 0.5555555555555556, 0.84, 1.0, 1.0, 0.6520817784717501, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.28808497986009035, 0.2880849798600905, 0.34156963103384175], 
reward next is 0.6584, 
noisyNet noise sample is [array([0.46807417], dtype=float32), 0.29662302]. 
=============================================
[2019-03-24 00:53:55,742] A3C_AGENT_WORKER-Thread-21 INFO:Local step 140000, global step 2240229: loss 0.0201
[2019-03-24 00:53:55,743] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 140000, global step 2240229: learning rate 0.0005
[2019-03-24 00:53:55,821] A3C_AGENT_WORKER-Thread-2 INFO:Local step 140000, global step 2240270: loss 0.0353
[2019-03-24 00:53:55,822] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 140000, global step 2240270: learning rate 0.0005
[2019-03-24 00:53:55,909] A3C_AGENT_WORKER-Thread-9 INFO:Local step 140000, global step 2240312: loss 0.0666
[2019-03-24 00:53:55,913] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 140000, global step 2240313: learning rate 0.0005
[2019-03-24 00:53:55,992] A3C_AGENT_WORKER-Thread-19 INFO:Local step 140000, global step 2240363: loss 0.0269
[2019-03-24 00:53:55,994] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 140000, global step 2240363: learning rate 0.0005
[2019-03-24 00:53:56,570] A3C_AGENT_WORKER-Thread-11 INFO:Local step 140000, global step 2240654: loss 0.0331
[2019-03-24 00:53:56,571] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 140000, global step 2240654: learning rate 0.0005
[2019-03-24 00:53:56,768] A3C_AGENT_WORKER-Thread-14 INFO:Local step 140000, global step 2240758: loss 0.0131
[2019-03-24 00:53:56,770] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 140000, global step 2240759: learning rate 0.0005
[2019-03-24 00:53:57,263] A3C_AGENT_WORKER-Thread-12 INFO:Local step 140000, global step 2241013: loss 0.0044
[2019-03-24 00:53:57,265] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 140000, global step 2241013: learning rate 0.0005
[2019-03-24 00:53:57,589] A3C_AGENT_WORKER-Thread-16 INFO:Local step 140000, global step 2241180: loss 0.0073
[2019-03-24 00:53:57,591] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 140000, global step 2241182: learning rate 0.0005
[2019-03-24 00:53:57,662] A3C_AGENT_WORKER-Thread-10 INFO:Local step 140000, global step 2241219: loss 0.0148
[2019-03-24 00:53:57,664] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 140000, global step 2241219: learning rate 0.0005
[2019-03-24 00:53:57,986] A3C_AGENT_WORKER-Thread-13 INFO:Local step 140000, global step 2241387: loss 0.0008
[2019-03-24 00:53:57,990] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 140000, global step 2241389: learning rate 0.0005
[2019-03-24 00:53:58,194] A3C_AGENT_WORKER-Thread-15 INFO:Local step 140000, global step 2241492: loss 0.0270
[2019-03-24 00:53:58,196] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 140000, global step 2241492: learning rate 0.0005
[2019-03-24 00:53:58,267] A3C_AGENT_WORKER-Thread-3 INFO:Local step 140000, global step 2241532: loss 0.0107
[2019-03-24 00:53:58,269] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 140000, global step 2241532: learning rate 0.0005
[2019-03-24 00:53:58,316] A3C_AGENT_WORKER-Thread-20 INFO:Local step 140000, global step 2241557: loss 0.0001
[2019-03-24 00:53:58,318] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 140000, global step 2241557: learning rate 0.0005
[2019-03-24 00:53:58,424] A3C_AGENT_WORKER-Thread-17 INFO:Local step 140000, global step 2241613: loss 0.0054
[2019-03-24 00:53:58,427] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 140000, global step 2241614: learning rate 0.0005
[2019-03-24 00:53:58,980] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.9894586e-18 1.0000000e+00 6.3975806e-28 6.0005554e-28 9.4215487e-31], sum to 1.0000
[2019-03-24 00:53:58,986] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3074
[2019-03-24 00:53:58,995] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.91666666666667, 94.33333333333334, 1.0, 2.0, 0.8064841011993698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 931277.5963693954, 931277.5963693954, 197906.5030882251], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4767000.0000, 
sim time next is 4767600.0000, 
raw observation next is [23.83333333333333, 94.66666666666667, 1.0, 2.0, 0.704385595516932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 813994.2241511536, 813994.2241511531, 177532.2869158768], 
processed observation next is [1.0, 0.17391304347826086, 0.43827160493827144, 0.9466666666666668, 1.0, 1.0, 0.6480780899011096, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2907122229111263, 0.29071222291112614, 0.34140824406899384], 
reward next is 0.6586, 
noisyNet noise sample is [array([-0.4954538], dtype=float32), -2.3640287]. 
=============================================
[2019-03-24 00:53:59,415] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.9298594e-16 1.0000000e+00 6.1077617e-27 4.7588399e-25 3.3950976e-29], sum to 1.0000
[2019-03-24 00:53:59,428] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2280
[2019-03-24 00:53:59,437] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.06666666666667, 98.0, 1.0, 2.0, 0.569772348042185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 664080.0430902912, 664080.0430902912, 153651.7259342367], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4567200.0000, 
sim time next is 4567800.0000, 
raw observation next is [23.03333333333333, 99.0, 1.0, 2.0, 0.5743130027320522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 668127.4514705838, 668127.4514705838, 154361.5200959739], 
processed observation next is [0.0, 0.8695652173913043, 0.4086419753086419, 0.99, 1.0, 1.0, 0.493229765157205, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2386169469537799, 0.2386169469537799, 0.2968490771076421], 
reward next is 0.7032, 
noisyNet noise sample is [array([0.466346], dtype=float32), 1.3576286]. 
=============================================
[2019-03-24 00:54:01,469] A3C_AGENT_WORKER-Thread-18 INFO:Local step 140500, global step 2243188: loss -143.3595
[2019-03-24 00:54:01,473] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 140500, global step 2243188: learning rate 0.0005
[2019-03-24 00:54:04,051] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.8716761e-16 1.0000000e+00 2.7538059e-25 4.3795712e-24 7.5112923e-29], sum to 1.0000
[2019-03-24 00:54:04,058] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2110
[2019-03-24 00:54:04,063] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.6, 89.0, 1.0, 2.0, 0.6742998717215981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 768496.4179262482, 768496.4179262482, 171333.7039570647], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4662000.0000, 
sim time next is 4662600.0000, 
raw observation next is [25.5, 89.83333333333334, 1.0, 2.0, 0.6689259112879898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 762368.6945120457, 762368.6945120452, 170343.0084551845], 
processed observation next is [1.0, 1.0, 0.5, 0.8983333333333334, 1.0, 1.0, 0.6058641801047497, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27227453375430205, 0.2722745337543019, 0.3275827085676625], 
reward next is 0.6724, 
noisyNet noise sample is [array([1.316971], dtype=float32), 0.82049674]. 
=============================================
[2019-03-24 00:54:05,670] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.9223741e-17 1.0000000e+00 3.1792472e-27 7.3682458e-25 9.4605988e-29], sum to 1.0000
[2019-03-24 00:54:05,677] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0321
[2019-03-24 00:54:05,681] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 92.0, 1.0, 2.0, 0.704287482935535, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 802691.0538926995, 802691.0538926995, 176958.6975358216], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4654200.0000, 
sim time next is 4654800.0000, 
raw observation next is [26.0, 94.0, 1.0, 2.0, 0.7141546593023169, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 813942.8506548419, 813942.8506548419, 178843.1136300523], 
processed observation next is [1.0, 0.9130434782608695, 0.5185185185185185, 0.94, 1.0, 1.0, 0.6597079277408535, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2906938752338721, 0.2906938752338721, 0.3439290646731775], 
reward next is 0.6561, 
noisyNet noise sample is [array([0.11873236], dtype=float32), 1.4946021]. 
=============================================
[2019-03-24 00:54:08,026] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.4480839e-17 1.0000000e+00 5.6117288e-27 3.8506537e-24 3.9210099e-28], sum to 1.0000
[2019-03-24 00:54:08,038] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5350
[2019-03-24 00:54:08,043] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1802679.493818128 W.
[2019-03-24 00:54:08,047] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.7903432821924139, 1.0, 2.0, 0.7903432821924139, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1802679.493818128, 1802679.493818128, 339780.1943198747], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4708800.0000, 
sim time next is 4709400.0000, 
raw observation next is [26.16666666666667, 89.0, 1.0, 2.0, 0.4772779965066877, 1.0, 2.0, 0.4772779965066877, 1.0, 1.0, 0.7598421142978198, 6.9112, 6.9112, 121.94756008, 1632766.537702675, 1632766.537702675, 332576.8594537139], 
processed observation next is [1.0, 0.5217391304347826, 0.5246913580246916, 0.89, 1.0, 1.0, 0.3777119006031996, 1.0, 1.0, 0.3777119006031996, 1.0, 0.5, 0.6998026428722748, 0.0, 0.0, 0.8096049824067558, 0.583130906322384, 0.583130906322384, 0.6395708835648345], 
reward next is 0.3604, 
noisyNet noise sample is [array([-0.86936146], dtype=float32), -0.44930616]. 
=============================================
[2019-03-24 00:54:09,026] A3C_AGENT_WORKER-Thread-22 INFO:Local step 141000, global step 2247052: loss 0.0224
[2019-03-24 00:54:09,027] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 141000, global step 2247053: learning rate 0.0005
[2019-03-24 00:54:11,465] A3C_AGENT_WORKER-Thread-21 INFO:Local step 140500, global step 2248305: loss -85.0093
[2019-03-24 00:54:11,469] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 140500, global step 2248307: learning rate 0.0005
[2019-03-24 00:54:11,504] A3C_AGENT_WORKER-Thread-2 INFO:Local step 140500, global step 2248325: loss -93.6253
[2019-03-24 00:54:11,506] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 140500, global step 2248325: learning rate 0.0005
[2019-03-24 00:54:11,555] A3C_AGENT_WORKER-Thread-9 INFO:Local step 140500, global step 2248351: loss -104.4322
[2019-03-24 00:54:11,558] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 140500, global step 2248352: learning rate 0.0005
[2019-03-24 00:54:11,976] A3C_AGENT_WORKER-Thread-19 INFO:Local step 140500, global step 2248572: loss -106.1361
[2019-03-24 00:54:11,977] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 140500, global step 2248572: learning rate 0.0005
[2019-03-24 00:54:12,321] A3C_AGENT_WORKER-Thread-11 INFO:Local step 140500, global step 2248746: loss -109.2097
[2019-03-24 00:54:12,322] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 140500, global step 2248746: learning rate 0.0005
[2019-03-24 00:54:12,480] A3C_AGENT_WORKER-Thread-14 INFO:Local step 140500, global step 2248828: loss -78.9398
[2019-03-24 00:54:12,481] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 140500, global step 2248828: learning rate 0.0005
[2019-03-24 00:54:12,765] A3C_AGENT_WORKER-Thread-12 INFO:Local step 140500, global step 2248971: loss -160.9583
[2019-03-24 00:54:12,766] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 140500, global step 2248971: learning rate 0.0005
[2019-03-24 00:54:13,272] A3C_AGENT_WORKER-Thread-16 INFO:Local step 140500, global step 2249233: loss -117.7463
[2019-03-24 00:54:13,274] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 140500, global step 2249233: learning rate 0.0005
[2019-03-24 00:54:13,280] A3C_AGENT_WORKER-Thread-10 INFO:Local step 140500, global step 2249233: loss -143.5345
[2019-03-24 00:54:13,282] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 140500, global step 2249235: learning rate 0.0005
[2019-03-24 00:54:13,472] A3C_AGENT_WORKER-Thread-13 INFO:Local step 140500, global step 2249334: loss -80.9593
[2019-03-24 00:54:13,475] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 140500, global step 2249334: learning rate 0.0005
[2019-03-24 00:54:13,852] A3C_AGENT_WORKER-Thread-15 INFO:Local step 140500, global step 2249523: loss -96.6574
[2019-03-24 00:54:13,852] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 140500, global step 2249523: learning rate 0.0005
[2019-03-24 00:54:13,889] A3C_AGENT_WORKER-Thread-3 INFO:Local step 140500, global step 2249542: loss -80.9728
[2019-03-24 00:54:13,892] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 140500, global step 2249542: learning rate 0.0005
[2019-03-24 00:54:13,935] A3C_AGENT_WORKER-Thread-20 INFO:Local step 140500, global step 2249564: loss -152.5471
[2019-03-24 00:54:13,937] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 140500, global step 2249564: learning rate 0.0005
[2019-03-24 00:54:14,018] A3C_AGENT_WORKER-Thread-17 INFO:Local step 140500, global step 2249606: loss -130.6728
[2019-03-24 00:54:14,020] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 140500, global step 2249606: learning rate 0.0005
[2019-03-24 00:54:14,773] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-24 00:54:14,776] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:54:14,780] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:54:14,778] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:54:14,777] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:54:14,781] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:54:14,783] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:54:14,782] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:54:14,786] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:54:14,787] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:54:14,787] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:54:14,801] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run91
[2019-03-24 00:54:14,827] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run91
[2019-03-24 00:54:14,852] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run91
[2019-03-24 00:54:14,875] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run91
[2019-03-24 00:54:14,909] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run91
[2019-03-24 00:54:26,932] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.018220976]
[2019-03-24 00:54:26,934] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [19.0, 46.33333333333333, 1.0, 2.0, 0.219642033912384, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 283312.0938699525, 283312.0938699525, 80780.27617093071]
[2019-03-24 00:54:26,937] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:54:26,940] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.3446284e-16 1.0000000e+00 1.0152893e-25 1.0782178e-23 1.2333495e-27], sampled 0.30042152850214476
[2019-03-24 00:54:42,659] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.018220976]
[2019-03-24 00:54:42,661] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.5, 59.0, 1.0, 2.0, 0.3548325898675403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 442739.5917700015, 442739.591770001, 122501.4952334375]
[2019-03-24 00:54:42,662] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:54:42,666] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.3446284e-16 1.0000000e+00 1.0152893e-25 1.0782178e-23 1.2333495e-27], sampled 0.25190317609023016
[2019-03-24 00:54:50,444] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.018220976]
[2019-03-24 00:54:50,445] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [31.57762505666667, 37.20727932333334, 1.0, 2.0, 0.5192289361103499, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8365489226248277, 6.911199999999999, 6.9112, 121.9260426156618, 1241357.614141244, 1241357.614141244, 262234.7663633928]
[2019-03-24 00:54:50,446] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:54:50,448] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.3446284e-16 1.0000000e+00 1.0152893e-25 1.0782178e-23 1.2333495e-27], sampled 0.7197779163926901
[2019-03-24 00:55:05,132] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.018220976]
[2019-03-24 00:55:05,133] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.1, 77.5, 1.0, 2.0, 0.9421001803316138, 1.0, 2.0, 0.9421001803316138, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 123.0848512560023, 2149211.179752586, 2149211.179752586, 406145.6390641514]
[2019-03-24 00:55:05,134] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:55:05,139] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.3446284e-16 1.0000000e+00 1.0152893e-25 1.0782178e-23 1.2333495e-27], sampled 0.4797998011701019
[2019-03-24 00:55:05,142] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2149211.179752586 W.
[2019-03-24 00:55:15,578] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.018220976]
[2019-03-24 00:55:15,579] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.15, 80.5, 1.0, 2.0, 0.5461442026833447, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 638747.838880179, 638747.838880179, 149823.9360397513]
[2019-03-24 00:55:15,580] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:55:15,583] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.3446284e-16 1.0000000e+00 1.0152893e-25 1.0782178e-23 1.2333495e-27], sampled 0.15409815205533972
[2019-03-24 00:55:18,276] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.018220976]
[2019-03-24 00:55:18,276] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.26917936666667, 103.9150472, 1.0, 2.0, 0.4769988933360444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 573984.5858530622, 573984.5858530622, 139507.621173133]
[2019-03-24 00:55:18,277] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:55:18,281] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.3446284e-16 1.0000000e+00 1.0152893e-25 1.0782178e-23 1.2333495e-27], sampled 0.03714821753087638
[2019-03-24 00:55:27,290] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.018220976]
[2019-03-24 00:55:27,291] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.0, 83.0, 1.0, 2.0, 0.5698500095122797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 664036.9879583791, 664036.9879583791, 153658.6267941313]
[2019-03-24 00:55:27,294] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:55:27,298] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.3446284e-16 1.0000000e+00 1.0152893e-25 1.0782178e-23 1.2333495e-27], sampled 0.7430976508988314
[2019-03-24 00:55:38,226] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.018220976]
[2019-03-24 00:55:38,228] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.46445211, 77.346512195, 1.0, 2.0, 0.5033925324841562, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 601692.0573350184, 601692.057335018, 143476.2913029241]
[2019-03-24 00:55:38,229] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 00:55:38,231] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.3446284e-16 1.0000000e+00 1.0152893e-25 1.0782178e-23 1.2333495e-27], sampled 0.7045784520136027
[2019-03-24 00:55:51,697] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.018220976]
[2019-03-24 00:55:51,699] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.70817421, 88.48153716, 1.0, 2.0, 0.5191990941000103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 613757.5272301526, 613757.5272301526, 145733.5755712295]
[2019-03-24 00:55:51,700] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:55:51,702] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.3446284e-16 1.0000000e+00 1.0152893e-25 1.0782178e-23 1.2333495e-27], sampled 0.8225971376889579
[2019-03-24 00:56:03,563] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 00:56:03,778] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.018220976]
[2019-03-24 00:56:03,779] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.130547155, 48.758484535, 1.0, 2.0, 0.5849292933550596, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 724804.2965473016, 724804.2965473016, 157713.4198821092]
[2019-03-24 00:56:03,781] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:56:03,783] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.3446284e-16 1.0000000e+00 1.0152893e-25 1.0782178e-23 1.2333495e-27], sampled 0.9801120914849438
[2019-03-24 00:56:03,848] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 00:56:03,977] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 00:56:04,060] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 00:56:04,073] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 00:56:05,089] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 2250000, evaluation results [2250000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 00:56:05,558] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.0015713e-16 1.0000000e+00 8.4504020e-27 1.1927188e-22 7.3675319e-28], sum to 1.0000
[2019-03-24 00:56:05,567] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3084
[2019-03-24 00:56:05,575] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2093834.760510654 W.
[2019-03-24 00:56:05,580] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.91666666666666, 69.5, 1.0, 2.0, 0.6118962168566294, 1.0, 2.0, 0.6118962168566294, 1.0, 1.0, 0.9741587053042863, 6.9112, 6.9112, 121.94756008, 2093834.760510654, 2093834.760510654, 401895.3563856798], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5231400.0000, 
sim time next is 5232000.0000, 
raw observation next is [29.83333333333334, 69.0, 1.0, 2.0, 0.9395228250894945, 1.0, 2.0, 0.9395228250894945, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156234, 2143348.693298906, 2143348.693298906, 404780.7964891566], 
processed observation next is [1.0, 0.5652173913043478, 0.6604938271604941, 0.69, 1.0, 1.0, 0.9280033632017791, 1.0, 1.0, 0.9280033632017791, 0.0, 0.5, -0.25, 0.0, 0.0, 0.809462128819881, 0.7654816761781807, 0.7654816761781807, 0.7784246086329935], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1157359], dtype=float32), -0.13816866]. 
=============================================
[2019-03-24 00:56:05,603] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[66.06257]
 [66.06257]
 [66.06257]
 [66.06257]
 [66.06257]], R is [[65.40193939]
 [64.74791718]
 [64.29318237]
 [63.65024948]
 [63.08182526]].
[2019-03-24 00:56:07,124] A3C_AGENT_WORKER-Thread-18 INFO:Local step 141000, global step 2250982: loss 0.0499
[2019-03-24 00:56:07,126] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 141000, global step 2250983: learning rate 0.0005
[2019-03-24 00:56:07,410] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.3871289e-14 1.0000000e+00 1.6237110e-23 6.3140092e-20 3.2094352e-24], sum to 1.0000
[2019-03-24 00:56:07,415] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1582
[2019-03-24 00:56:07,421] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 94.0, 1.0, 2.0, 0.8810913866892764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1004330.167460785, 1004330.167460785, 213276.3099089607], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4914000.0000, 
sim time next is 4914600.0000, 
raw observation next is [27.83333333333334, 94.00000000000001, 1.0, 2.0, 0.8735208562172335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 995695.1358563578, 995695.1358563578, 211609.8186663785], 
processed observation next is [1.0, 0.9130434782608695, 0.58641975308642, 0.9400000000000002, 1.0, 1.0, 0.8494295907348018, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.35560540566298493, 0.35560540566298493, 0.4069419589738048], 
reward next is 0.5931, 
noisyNet noise sample is [array([1.1673621], dtype=float32), 1.4348133]. 
=============================================
[2019-03-24 00:56:07,912] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.6335835e-15 1.0000000e+00 4.8367000e-23 1.0999248e-22 2.4503980e-25], sum to 1.0000
[2019-03-24 00:56:07,918] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0811
[2019-03-24 00:56:07,921] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 88.33333333333334, 1.0, 2.0, 0.6622743032780092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 754784.1858281881, 754784.1858281881, 169123.431820407], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5271600.0000, 
sim time next is 5272200.0000, 
raw observation next is [25.65, 88.0, 1.0, 2.0, 0.659966834499334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 752153.1076972845, 752153.1076972841, 168701.9102904235], 
processed observation next is [1.0, 0.0, 0.5055555555555555, 0.88, 1.0, 1.0, 0.5951986124992071, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26862610989188734, 0.2686261098918872, 0.3244267505585067], 
reward next is 0.6756, 
noisyNet noise sample is [array([-0.89533925], dtype=float32), 1.1397835]. 
=============================================
[2019-03-24 00:56:12,613] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.1020210e-14 1.0000000e+00 3.6574425e-23 2.6092364e-21 3.9032252e-26], sum to 1.0000
[2019-03-24 00:56:12,622] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0002
[2019-03-24 00:56:12,631] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1698615.603347046 W.
[2019-03-24 00:56:12,634] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.0, 75.66666666666667, 1.0, 2.0, 0.7447622050201782, 1.0, 2.0, 0.7447622050201782, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1698615.603347046, 1698615.603347046, 321457.8845859177], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4980000.0000, 
sim time next is 4980600.0000, 
raw observation next is [28.0, 76.5, 1.0, 2.0, 0.801724760415109, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426156618, 1628909.071698654, 1628909.071698654, 336576.0225996446], 
processed observation next is [1.0, 0.6521739130434783, 0.5925925925925926, 0.765, 1.0, 1.0, 0.763958048113225, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5817532398923764, 0.5817532398923764, 0.6472615819223935], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.75208616], dtype=float32), 1.6156907]. 
=============================================
[2019-03-24 00:56:15,430] A3C_AGENT_WORKER-Thread-22 INFO:Local step 141500, global step 2255160: loss -167.1373
[2019-03-24 00:56:15,431] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 141500, global step 2255160: learning rate 0.0005
[2019-03-24 00:56:16,576] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.6431686e-16 1.0000000e+00 1.6345538e-25 3.8295032e-23 4.7100720e-27], sum to 1.0000
[2019-03-24 00:56:16,584] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4249
[2019-03-24 00:56:16,588] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.75, 67.5, 1.0, 2.0, 0.7659019811227014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000003, 6.9112, 121.9260426156618, 872954.366765738, 872954.3667657367, 188999.8739331034], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5061000.0000, 
sim time next is 5061600.0000, 
raw observation next is [30.9, 66.0, 1.0, 2.0, 0.755402371367533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 860980.4735869243, 860980.4735869243, 186901.4406884585], 
processed observation next is [0.0, 0.6086956521739131, 0.7, 0.66, 1.0, 1.0, 0.7088123468661106, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.30749302628104436, 0.30749302628104436, 0.3594258474778048], 
reward next is 0.6406, 
noisyNet noise sample is [array([0.10697276], dtype=float32), -0.33707637]. 
=============================================
[2019-03-24 00:56:17,677] A3C_AGENT_WORKER-Thread-2 INFO:Local step 141000, global step 2256288: loss 0.0002
[2019-03-24 00:56:17,680] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 141000, global step 2256288: learning rate 0.0005
[2019-03-24 00:56:17,704] A3C_AGENT_WORKER-Thread-9 INFO:Local step 141000, global step 2256299: loss 0.0012
[2019-03-24 00:56:17,706] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 141000, global step 2256300: learning rate 0.0005
[2019-03-24 00:56:17,735] A3C_AGENT_WORKER-Thread-21 INFO:Local step 141000, global step 2256313: loss 0.0008
[2019-03-24 00:56:17,736] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 141000, global step 2256313: learning rate 0.0005
[2019-03-24 00:56:18,038] A3C_AGENT_WORKER-Thread-19 INFO:Local step 141000, global step 2256472: loss 0.0305
[2019-03-24 00:56:18,042] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 141000, global step 2256472: learning rate 0.0005
[2019-03-24 00:56:18,652] A3C_AGENT_WORKER-Thread-14 INFO:Local step 141000, global step 2256781: loss 0.0073
[2019-03-24 00:56:18,654] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 141000, global step 2256781: learning rate 0.0005
[2019-03-24 00:56:18,685] A3C_AGENT_WORKER-Thread-11 INFO:Local step 141000, global step 2256795: loss 0.0137
[2019-03-24 00:56:18,687] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 141000, global step 2256795: learning rate 0.0005
[2019-03-24 00:56:18,892] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.8542440e-18 1.0000000e+00 1.7387402e-24 1.6105090e-24 1.8587648e-28], sum to 1.0000
[2019-03-24 00:56:18,900] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0222
[2019-03-24 00:56:18,904] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 91.5, 1.0, 2.0, 0.8160938239423414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 930196.3898393563, 930196.3898393563, 199295.1949396227], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5088600.0000, 
sim time next is 5089200.0000, 
raw observation next is [27.33333333333334, 92.33333333333334, 1.0, 2.0, 0.8147154222686697, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 928624.3143419351, 928624.3143419351, 199006.4425251452], 
processed observation next is [0.0, 0.9130434782608695, 0.5679012345679014, 0.9233333333333335, 1.0, 1.0, 0.7794231217484162, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3316515408364054, 0.3316515408364054, 0.3827046971637407], 
reward next is 0.6173, 
noisyNet noise sample is [array([-1.6513175], dtype=float32), 1.6819321]. 
=============================================
[2019-03-24 00:56:19,113] A3C_AGENT_WORKER-Thread-12 INFO:Local step 141000, global step 2257018: loss 0.0067
[2019-03-24 00:56:19,116] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 141000, global step 2257018: learning rate 0.0005
[2019-03-24 00:56:19,192] A3C_AGENT_WORKER-Thread-16 INFO:Local step 141000, global step 2257058: loss 0.0088
[2019-03-24 00:56:19,194] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 141000, global step 2257059: learning rate 0.0005
[2019-03-24 00:56:19,411] A3C_AGENT_WORKER-Thread-13 INFO:Local step 141000, global step 2257164: loss 0.0000
[2019-03-24 00:56:19,414] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 141000, global step 2257165: learning rate 0.0005
[2019-03-24 00:56:19,559] A3C_AGENT_WORKER-Thread-10 INFO:Local step 141000, global step 2257239: loss 0.0000
[2019-03-24 00:56:19,563] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 141000, global step 2257240: learning rate 0.0005
[2019-03-24 00:56:19,990] A3C_AGENT_WORKER-Thread-20 INFO:Local step 141000, global step 2257465: loss 0.0037
[2019-03-24 00:56:19,994] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 141000, global step 2257468: learning rate 0.0005
[2019-03-24 00:56:20,081] A3C_AGENT_WORKER-Thread-3 INFO:Local step 141000, global step 2257509: loss 0.0001
[2019-03-24 00:56:20,084] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 141000, global step 2257509: learning rate 0.0005
[2019-03-24 00:56:20,148] A3C_AGENT_WORKER-Thread-15 INFO:Local step 141000, global step 2257543: loss 0.0002
[2019-03-24 00:56:20,151] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 141000, global step 2257545: learning rate 0.0005
[2019-03-24 00:56:20,257] A3C_AGENT_WORKER-Thread-17 INFO:Local step 141000, global step 2257599: loss 0.0063
[2019-03-24 00:56:20,259] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 141000, global step 2257600: learning rate 0.0005
[2019-03-24 00:56:23,057] A3C_AGENT_WORKER-Thread-18 INFO:Local step 141500, global step 2259044: loss -131.5506
[2019-03-24 00:56:23,063] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 141500, global step 2259046: learning rate 0.0005
[2019-03-24 00:56:26,582] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.1758287e-13 1.0000000e+00 2.1604611e-21 9.8337913e-21 3.8291816e-23], sum to 1.0000
[2019-03-24 00:56:26,588] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8353
[2019-03-24 00:56:26,596] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1548525.807541523 W.
[2019-03-24 00:56:26,600] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.35, 84.83333333333334, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.636046727138073, 6.9112, 123.0375373474031, 1548525.807541523, 1173955.71124367, 246373.6240687564], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5278200.0000, 
sim time next is 5278800.0000, 
raw observation next is [25.3, 84.66666666666667, 1.0, 2.0, 0.5633945907720542, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8969425369899576, 6.9112, 6.9112, 121.9256061153742, 1284628.66483937, 1284628.66483937, 279887.1134266637], 
processed observation next is [1.0, 0.08695652173913043, 0.49259259259259264, 0.8466666666666667, 1.0, 1.0, 0.48023165568101694, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.8711781712374469, 0.0, 0.0, 0.8094592309121545, 0.4587959517283464, 0.4587959517283464, 0.5382444488974302], 
reward next is 0.4618, 
noisyNet noise sample is [array([-0.27649072], dtype=float32), -0.74353546]. 
=============================================
[2019-03-24 00:56:31,190] A3C_AGENT_WORKER-Thread-22 INFO:Local step 142000, global step 2263206: loss 0.1352
[2019-03-24 00:56:31,191] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 142000, global step 2263206: learning rate 0.0005
[2019-03-24 00:56:31,869] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.2355083e-16 1.0000000e+00 3.1279569e-24 4.4380284e-25 1.3597561e-28], sum to 1.0000
[2019-03-24 00:56:31,882] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6327
[2019-03-24 00:56:31,888] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 91.0, 1.0, 2.0, 0.7197827614639732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 823473.9143371965, 823473.9143371965, 180078.6774006014], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5384400.0000, 
sim time next is 5385000.0000, 
raw observation next is [24.85, 91.0, 1.0, 2.0, 0.7273797538775442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 831228.4440848877, 831228.4440848877, 181501.3349821288], 
processed observation next is [1.0, 0.30434782608695654, 0.475925925925926, 0.91, 1.0, 1.0, 0.6754520879494573, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29686730145888846, 0.29686730145888846, 0.34904102881178617], 
reward next is 0.6510, 
noisyNet noise sample is [array([0.42334655], dtype=float32), -1.9596022]. 
=============================================
[2019-03-24 00:56:31,906] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[67.84706]
 [67.84706]
 [67.84706]
 [67.84706]
 [67.84706]], R is [[67.81954956]
 [67.79505157]
 [67.77462006]
 [67.75761414]
 [67.73158264]].
[2019-03-24 00:56:33,338] A3C_AGENT_WORKER-Thread-2 INFO:Local step 141500, global step 2264291: loss -166.2043
[2019-03-24 00:56:33,340] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 141500, global step 2264291: learning rate 0.0005
[2019-03-24 00:56:33,454] A3C_AGENT_WORKER-Thread-9 INFO:Local step 141500, global step 2264355: loss -145.2657
[2019-03-24 00:56:33,456] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 141500, global step 2264356: learning rate 0.0005
[2019-03-24 00:56:33,601] A3C_AGENT_WORKER-Thread-19 INFO:Local step 141500, global step 2264433: loss -148.0729
[2019-03-24 00:56:33,605] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 141500, global step 2264433: learning rate 0.0005
[2019-03-24 00:56:33,720] A3C_AGENT_WORKER-Thread-21 INFO:Local step 141500, global step 2264495: loss -127.0123
[2019-03-24 00:56:33,724] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 141500, global step 2264495: learning rate 0.0005
[2019-03-24 00:56:34,233] A3C_AGENT_WORKER-Thread-14 INFO:Local step 141500, global step 2264756: loss -159.3480
[2019-03-24 00:56:34,234] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 141500, global step 2264756: learning rate 0.0005
[2019-03-24 00:56:34,452] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.9119885e-15 1.0000000e+00 1.0704220e-25 6.8311221e-24 5.9154861e-28], sum to 1.0000
[2019-03-24 00:56:34,461] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6706
[2019-03-24 00:56:34,463] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.96666666666667, 85.66666666666667, 1.0, 2.0, 0.7794599975687846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 888416.3839484896, 888416.3839484891, 191738.312256187], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5435400.0000, 
sim time next is 5436000.0000, 
raw observation next is [27.9, 86.0, 1.0, 2.0, 0.778786306858889, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 887648.077077751, 887648.077077751, 191601.4642477507], 
processed observation next is [1.0, 0.9565217391304348, 0.5888888888888888, 0.86, 1.0, 1.0, 0.7366503653082013, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31701717038491106, 0.31701717038491106, 0.3684643543225975], 
reward next is 0.6315, 
noisyNet noise sample is [array([0.5148622], dtype=float32), -0.5372824]. 
=============================================
[2019-03-24 00:56:34,473] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[61.41261]
 [61.41261]
 [61.41261]
 [61.41261]
 [61.41261]], R is [[61.43001938]
 [61.44699097]
 [61.46339417]
 [61.47909927]
 [61.49407959]].
[2019-03-24 00:56:34,740] A3C_AGENT_WORKER-Thread-16 INFO:Local step 141500, global step 2265020: loss -137.0523
[2019-03-24 00:56:34,741] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 141500, global step 2265020: learning rate 0.0005
[2019-03-24 00:56:34,763] A3C_AGENT_WORKER-Thread-11 INFO:Local step 141500, global step 2265032: loss -157.9093
[2019-03-24 00:56:34,768] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 141500, global step 2265032: learning rate 0.0005
[2019-03-24 00:56:34,827] A3C_AGENT_WORKER-Thread-12 INFO:Local step 141500, global step 2265062: loss -118.2822
[2019-03-24 00:56:34,830] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 141500, global step 2265063: learning rate 0.0005
[2019-03-24 00:56:35,002] A3C_AGENT_WORKER-Thread-13 INFO:Local step 141500, global step 2265150: loss -96.0664
[2019-03-24 00:56:35,005] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 141500, global step 2265152: learning rate 0.0005
[2019-03-24 00:56:35,342] A3C_AGENT_WORKER-Thread-10 INFO:Local step 141500, global step 2265327: loss -126.4156
[2019-03-24 00:56:35,346] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 141500, global step 2265327: learning rate 0.0005
[2019-03-24 00:56:35,397] A3C_AGENT_WORKER-Thread-3 INFO:Local step 141500, global step 2265351: loss -142.1245
[2019-03-24 00:56:35,400] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 141500, global step 2265351: learning rate 0.0005
[2019-03-24 00:56:35,509] A3C_AGENT_WORKER-Thread-20 INFO:Local step 141500, global step 2265409: loss -132.4740
[2019-03-24 00:56:35,514] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 141500, global step 2265410: learning rate 0.0005
[2019-03-24 00:56:35,840] A3C_AGENT_WORKER-Thread-15 INFO:Local step 141500, global step 2265583: loss -102.0959
[2019-03-24 00:56:35,842] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 141500, global step 2265583: learning rate 0.0005
[2019-03-24 00:56:35,861] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.9868050e-16 1.0000000e+00 3.6246892e-24 2.5946729e-23 2.7845761e-26], sum to 1.0000
[2019-03-24 00:56:35,867] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1425
[2019-03-24 00:56:35,874] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.2, 94.0, 1.0, 2.0, 0.9192056043709997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156533, 1047805.148045537, 1047805.148045537, 221801.9867623872], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5456400.0000, 
sim time next is 5457000.0000, 
raw observation next is [26.2, 94.0, 1.0, 2.0, 0.9026381384635186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1028907.165777182, 1028907.165777182, 218060.6196077682], 
processed observation next is [1.0, 0.13043478260869565, 0.5259259259259259, 0.94, 1.0, 1.0, 0.8840930219803793, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.36746684492042214, 0.36746684492042214, 0.4193473453995542], 
reward next is 0.5807, 
noisyNet noise sample is [array([0.16776714], dtype=float32), -0.7185193]. 
=============================================
[2019-03-24 00:56:35,889] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[59.820473]
 [59.820473]
 [59.820473]
 [59.820473]
 [59.820473]], R is [[59.80292892]
 [59.77835846]
 [59.75415802]
 [59.75134659]
 [59.1538353 ]].
[2019-03-24 00:56:35,953] A3C_AGENT_WORKER-Thread-17 INFO:Local step 141500, global step 2265633: loss -132.6776
[2019-03-24 00:56:35,955] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 141500, global step 2265634: learning rate 0.0005
[2019-03-24 00:56:36,785] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.8398329e-16 1.0000000e+00 5.1365504e-25 1.0192339e-21 3.7742110e-27], sum to 1.0000
[2019-03-24 00:56:36,793] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7165
[2019-03-24 00:56:36,797] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.93333333333333, 80.0, 1.0, 2.0, 0.7683218459755021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 875714.0390243975, 875714.0390243975, 189487.9638079533], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5427600.0000, 
sim time next is 5428200.0000, 
raw observation next is [28.86666666666667, 80.5, 1.0, 2.0, 0.7704379923182566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 878127.3515113723, 878127.3515113723, 189914.0229608844], 
processed observation next is [1.0, 0.8260869565217391, 0.6246913580246916, 0.805, 1.0, 1.0, 0.7267118956169721, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3136169112540615, 0.3136169112540615, 0.36521927492477774], 
reward next is 0.6348, 
noisyNet noise sample is [array([-3.123268], dtype=float32), -0.27481034]. 
=============================================
[2019-03-24 00:56:38,485] A3C_AGENT_WORKER-Thread-18 INFO:Local step 142000, global step 2266931: loss 0.5450
[2019-03-24 00:56:38,487] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 142000, global step 2266931: learning rate 0.0005
[2019-03-24 00:56:38,648] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.5524240e-13 1.0000000e+00 3.6474145e-21 1.4388941e-18 5.6289138e-23], sum to 1.0000
[2019-03-24 00:56:38,659] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8613
[2019-03-24 00:56:38,676] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2135304.5010611 W.
[2019-03-24 00:56:38,683] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.55, 83.5, 1.0, 2.0, 0.6240007431600683, 1.0, 2.0, 0.6240007431600683, 1.0, 2.0, 0.9934295053962608, 6.9112, 6.9112, 121.94756008, 2135304.5010611, 2135304.5010611, 408607.4214431564], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5481000.0000, 
sim time next is 5481600.0000, 
raw observation next is [29.7, 83.0, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 7.3916963566957, 6.9112, 121.9245025101892, 2573556.640658804, 2327502.667816861, 443050.2855989102], 
processed observation next is [1.0, 0.43478260869565216, 0.6555555555555556, 0.83, 1.0, 1.0, 1.0238095238095237, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.25, 0.04804963566957001, 0.0, 0.8094519041213947, 0.9191273716638586, 0.8312509527917361, 0.8520197799979042], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0281239], dtype=float32), -0.6432607]. 
=============================================
[2019-03-24 00:56:42,342] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.6249746e-16 1.0000000e+00 3.4292970e-26 2.3423408e-22 9.7799609e-28], sum to 1.0000
[2019-03-24 00:56:42,353] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4373
[2019-03-24 00:56:42,361] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2361774.698582096 W.
[2019-03-24 00:56:42,368] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.5, 74.0, 1.0, 2.0, 0.7534602687009525, 1.0, 2.0, 0.6900947963269108, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2361774.698582096, 2361774.698582096, 443914.691109186], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5580000.0000, 
sim time next is 5580600.0000, 
raw observation next is [30.2, 74.83333333333334, 1.0, 2.0, 0.8322669103151411, 1.0, 2.0, 0.7294981171340051, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 122.9355304227544, 2496788.811681002, 2496788.811681002, 466961.5465221439], 
processed observation next is [1.0, 0.6086956521739131, 0.674074074074074, 0.7483333333333334, 1.0, 1.0, 0.800317750375168, 1.0, 1.0, 0.6779739489690537, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.816164078065901, 0.8917102898860721, 0.8917102898860721, 0.8980029740810459], 
reward next is 0.1020, 
noisyNet noise sample is [array([-0.05498412], dtype=float32), 1.3671036]. 
=============================================
[2019-03-24 00:56:44,199] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.4841054e-14 1.0000000e+00 1.8713045e-24 2.4120817e-21 8.8544006e-25], sum to 1.0000
[2019-03-24 00:56:44,203] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9175
[2019-03-24 00:56:44,210] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.6, 97.33333333333333, 1.0, 2.0, 0.5982115962947225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 690046.3545029548, 690046.3545029548, 158173.8431753124], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5618400.0000, 
sim time next is 5619000.0000, 
raw observation next is [23.6, 97.16666666666667, 1.0, 2.0, 0.5974881480415504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 689523.9733779839, 689523.9733779839, 158063.8456803849], 
processed observation next is [0.0, 0.0, 0.4296296296296297, 0.9716666666666667, 1.0, 1.0, 0.5208192238589885, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24625856192070852, 0.24625856192070852, 0.3039689340007402], 
reward next is 0.6960, 
noisyNet noise sample is [array([1.0335194], dtype=float32), 0.3112303]. 
=============================================
[2019-03-24 00:56:44,229] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[58.662273]
 [58.662273]
 [58.662273]
 [58.662273]
 [58.662273]], R is [[58.77167892]
 [58.87978363]
 [58.98644638]
 [59.09157181]
 [59.19507599]].
[2019-03-24 00:56:44,239] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.0355034e-17 1.0000000e+00 9.0654830e-25 1.1492827e-21 5.3563249e-26], sum to 1.0000
[2019-03-24 00:56:44,244] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6656
[2019-03-24 00:56:44,250] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1581517.151966296 W.
[2019-03-24 00:56:44,256] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.6, 78.33333333333334, 1.0, 2.0, 0.6934655183804806, 1.0, 2.0, 0.6934655183804806, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1581517.151966296, 1581517.151966297, 301699.0804215822], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5571600.0000, 
sim time next is 5572200.0000, 
raw observation next is [27.8, 78.16666666666666, 1.0, 2.0, 0.460070527499312, 1.0, 2.0, 0.460070527499312, 1.0, 1.0, 0.7324472632299363, 6.9112, 6.9112, 121.94756008, 1573846.799811534, 1573846.799811534, 324395.1032112935], 
processed observation next is [1.0, 0.4782608695652174, 0.5851851851851853, 0.7816666666666666, 1.0, 1.0, 0.35722681845156184, 1.0, 1.0, 0.35722681845156184, 1.0, 0.5, 0.6655590790374202, 0.0, 0.0, 0.8096049824067558, 0.5620881427898335, 0.5620881427898335, 0.6238367369447952], 
reward next is 0.3762, 
noisyNet noise sample is [array([0.86290145], dtype=float32), -0.27435327]. 
=============================================
[2019-03-24 00:56:46,680] A3C_AGENT_WORKER-Thread-22 INFO:Local step 142500, global step 2271127: loss -96.2245
[2019-03-24 00:56:46,682] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 142500, global step 2271128: learning rate 0.0005
[2019-03-24 00:56:49,039] A3C_AGENT_WORKER-Thread-9 INFO:Local step 142000, global step 2272327: loss 0.0367
[2019-03-24 00:56:49,042] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 142000, global step 2272329: learning rate 0.0005
[2019-03-24 00:56:49,051] A3C_AGENT_WORKER-Thread-21 INFO:Local step 142000, global step 2272334: loss 0.0536
[2019-03-24 00:56:49,053] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 142000, global step 2272335: learning rate 0.0005
[2019-03-24 00:56:49,188] A3C_AGENT_WORKER-Thread-19 INFO:Local step 142000, global step 2272403: loss 0.0640
[2019-03-24 00:56:49,190] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 142000, global step 2272403: learning rate 0.0005
[2019-03-24 00:56:49,350] A3C_AGENT_WORKER-Thread-2 INFO:Local step 142000, global step 2272485: loss 0.0811
[2019-03-24 00:56:49,350] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 142000, global step 2272485: learning rate 0.0005
[2019-03-24 00:56:49,863] A3C_AGENT_WORKER-Thread-14 INFO:Local step 142000, global step 2272747: loss 0.0261
[2019-03-24 00:56:49,865] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 142000, global step 2272749: learning rate 0.0005
[2019-03-24 00:56:50,343] A3C_AGENT_WORKER-Thread-16 INFO:Local step 142000, global step 2273000: loss 0.0004
[2019-03-24 00:56:50,345] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 142000, global step 2273000: learning rate 0.0005
[2019-03-24 00:56:50,464] A3C_AGENT_WORKER-Thread-12 INFO:Local step 142000, global step 2273064: loss 0.0000
[2019-03-24 00:56:50,467] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 142000, global step 2273064: learning rate 0.0005
[2019-03-24 00:56:50,536] A3C_AGENT_WORKER-Thread-11 INFO:Local step 142000, global step 2273100: loss 0.0050
[2019-03-24 00:56:50,539] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 142000, global step 2273101: learning rate 0.0005
[2019-03-24 00:56:50,643] A3C_AGENT_WORKER-Thread-13 INFO:Local step 142000, global step 2273154: loss 0.0001
[2019-03-24 00:56:50,644] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 142000, global step 2273154: learning rate 0.0005
[2019-03-24 00:56:50,798] A3C_AGENT_WORKER-Thread-10 INFO:Local step 142000, global step 2273233: loss 0.0004
[2019-03-24 00:56:50,800] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 142000, global step 2273233: learning rate 0.0005
[2019-03-24 00:56:51,065] A3C_AGENT_WORKER-Thread-3 INFO:Local step 142000, global step 2273370: loss 0.0095
[2019-03-24 00:56:51,070] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 142000, global step 2273371: learning rate 0.0005
[2019-03-24 00:56:51,167] A3C_AGENT_WORKER-Thread-20 INFO:Local step 142000, global step 2273424: loss 0.0145
[2019-03-24 00:56:51,169] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 142000, global step 2273425: learning rate 0.0005
[2019-03-24 00:56:51,348] A3C_AGENT_WORKER-Thread-15 INFO:Local step 142000, global step 2273514: loss 0.0010
[2019-03-24 00:56:51,351] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 142000, global step 2273515: learning rate 0.0005
[2019-03-24 00:56:51,677] A3C_AGENT_WORKER-Thread-17 INFO:Local step 142000, global step 2273685: loss 0.0058
[2019-03-24 00:56:51,681] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 142000, global step 2273687: learning rate 0.0005
[2019-03-24 00:56:53,980] A3C_AGENT_WORKER-Thread-18 INFO:Local step 142500, global step 2274874: loss -115.4673
[2019-03-24 00:56:53,982] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 142500, global step 2274875: learning rate 0.0005
[2019-03-24 00:56:54,228] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-24 00:56:54,232] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:56:54,232] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:56:54,232] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:56:54,233] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:56:54,233] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:56:54,232] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:56:54,233] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:56:54,236] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:56:54,235] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:56:54,236] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:56:54,251] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run92
[2019-03-24 00:56:54,275] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run92
[2019-03-24 00:56:54,299] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run92
[2019-03-24 00:56:54,300] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run92
[2019-03-24 00:56:54,352] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run92
[2019-03-24 00:57:19,732] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.034230262]
[2019-03-24 00:57:19,734] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.01666666666667, 81.83333333333334, 1.0, 2.0, 0.4291452787021878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 528392.0761727334, 528392.0761727334, 132721.1107294712]
[2019-03-24 00:57:19,736] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 00:57:19,740] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.4778463e-17 1.0000000e+00 4.5890592e-28 7.7549723e-26 4.2867473e-30], sampled 0.5930767927324335
[2019-03-24 00:57:41,954] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.034230262]
[2019-03-24 00:57:41,955] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.33333333333334, 75.0, 1.0, 2.0, 0.5313583422038549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 629100.6761031593, 629100.6761031593, 147729.8492652692]
[2019-03-24 00:57:41,956] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 00:57:41,958] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.4778463e-17 1.0000000e+00 4.5890592e-28 7.7549723e-26 4.2867473e-30], sampled 0.10063024511199958
[2019-03-24 00:57:52,830] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.034230262]
[2019-03-24 00:57:52,831] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.0, 62.0, 1.0, 2.0, 0.5766050708675744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 667303.5507137891, 667303.5507137891, 154590.8972316101]
[2019-03-24 00:57:52,832] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 00:57:52,836] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.4778463e-17 1.0000000e+00 4.5890592e-28 7.7549723e-26 4.2867473e-30], sampled 0.4045009688929645
[2019-03-24 00:58:27,503] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.034230262]
[2019-03-24 00:58:27,504] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [18.77480954333333, 79.08776613333333, 1.0, 2.0, 0.2895375349316321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 371214.6641325647, 371214.6641325647, 114292.7392364417]
[2019-03-24 00:58:27,505] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 00:58:27,508] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.4778463e-17 1.0000000e+00 4.5890592e-28 7.7549723e-26 4.2867473e-30], sampled 0.9775012314566537
[2019-03-24 00:58:43,649] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 00:58:43,782] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 00:58:43,860] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 00:58:43,882] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 00:58:43,917] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 00:58:44,936] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 2275000, evaluation results [2275000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 00:58:48,053] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.4849707e-18 1.0000000e+00 1.1543937e-27 1.5770652e-24 1.7582251e-29], sum to 1.0000
[2019-03-24 00:58:48,060] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0455
[2019-03-24 00:58:48,065] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.53333333333333, 45.0, 1.0, 2.0, 0.3629910496164841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 451634.0122678946, 451634.0122678946, 123567.3551112806], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5852400.0000, 
sim time next is 5853000.0000, 
raw observation next is [27.36666666666667, 46.0, 1.0, 2.0, 0.3674102477990184, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 456828.9431559573, 456828.9431559573, 124156.8183025117], 
processed observation next is [1.0, 0.7391304347826086, 0.569135802469136, 0.46, 1.0, 1.0, 0.24691696166549806, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16315319398427047, 0.16315319398427047, 0.2387631121202148], 
reward next is 0.7612, 
noisyNet noise sample is [array([0.09844644], dtype=float32), -0.703315]. 
=============================================
[2019-03-24 00:58:48,079] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[66.0918]
 [66.0918]
 [66.0918]
 [66.0918]
 [66.0918]], R is [[66.19211578]
 [66.29256439]
 [66.39336395]
 [65.72943115]
 [65.07213593]].
[2019-03-24 00:58:53,447] A3C_AGENT_WORKER-Thread-22 INFO:Local step 143000, global step 2279158: loss 0.0414
[2019-03-24 00:58:53,448] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 143000, global step 2279158: learning rate 0.0005
[2019-03-24 00:58:53,487] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.7068153e-16 1.0000000e+00 3.6744981e-26 4.7273982e-23 1.3925694e-29], sum to 1.0000
[2019-03-24 00:58:53,498] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8872
[2019-03-24 00:58:53,505] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.55, 74.5, 1.0, 2.0, 0.485579866758287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 583868.0260103213, 583868.0260103213, 140815.3472373937], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5952600.0000, 
sim time next is 5953200.0000, 
raw observation next is [24.33333333333333, 75.66666666666667, 1.0, 2.0, 0.4838867661827436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 582208.0135118129, 582208.0135118129, 140566.0875576438], 
processed observation next is [1.0, 0.9130434782608695, 0.45679012345678993, 0.7566666666666667, 1.0, 1.0, 0.3855794835508852, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20793143339707604, 0.20793143339707604, 0.270319399149315], 
reward next is 0.7297, 
noisyNet noise sample is [array([-0.19055231], dtype=float32), -0.21712339]. 
=============================================
[2019-03-24 00:58:55,598] A3C_AGENT_WORKER-Thread-9 INFO:Local step 142500, global step 2280268: loss -119.5629
[2019-03-24 00:58:55,599] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 142500, global step 2280268: learning rate 0.0005
[2019-03-24 00:58:55,769] A3C_AGENT_WORKER-Thread-19 INFO:Local step 142500, global step 2280354: loss -126.8904
[2019-03-24 00:58:55,770] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 142500, global step 2280354: learning rate 0.0005
[2019-03-24 00:58:55,997] A3C_AGENT_WORKER-Thread-21 INFO:Local step 142500, global step 2280472: loss -128.1376
[2019-03-24 00:58:56,005] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 142500, global step 2280472: learning rate 0.0005
[2019-03-24 00:58:56,107] A3C_AGENT_WORKER-Thread-2 INFO:Local step 142500, global step 2280524: loss -152.0270
[2019-03-24 00:58:56,109] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 142500, global step 2280526: learning rate 0.0005
[2019-03-24 00:58:56,542] A3C_AGENT_WORKER-Thread-14 INFO:Local step 142500, global step 2280751: loss -154.5727
[2019-03-24 00:58:56,543] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 142500, global step 2280751: learning rate 0.0005
[2019-03-24 00:58:57,141] A3C_AGENT_WORKER-Thread-16 INFO:Local step 142500, global step 2281065: loss -146.6258
[2019-03-24 00:58:57,142] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 142500, global step 2281066: learning rate 0.0005
[2019-03-24 00:58:57,230] A3C_AGENT_WORKER-Thread-11 INFO:Local step 142500, global step 2281111: loss -140.9151
[2019-03-24 00:58:57,231] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 142500, global step 2281111: learning rate 0.0005
[2019-03-24 00:58:57,235] A3C_AGENT_WORKER-Thread-12 INFO:Local step 142500, global step 2281112: loss -93.1764
[2019-03-24 00:58:57,236] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 142500, global step 2281112: learning rate 0.0005
[2019-03-24 00:58:57,295] A3C_AGENT_WORKER-Thread-13 INFO:Local step 142500, global step 2281140: loss -88.7238
[2019-03-24 00:58:57,298] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 142500, global step 2281141: learning rate 0.0005
[2019-03-24 00:58:57,587] A3C_AGENT_WORKER-Thread-3 INFO:Local step 142500, global step 2281297: loss -117.2907
[2019-03-24 00:58:57,591] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 142500, global step 2281298: learning rate 0.0005
[2019-03-24 00:58:57,631] A3C_AGENT_WORKER-Thread-10 INFO:Local step 142500, global step 2281315: loss -142.7764
[2019-03-24 00:58:57,632] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 142500, global step 2281315: learning rate 0.0005
[2019-03-24 00:58:57,685] A3C_AGENT_WORKER-Thread-20 INFO:Local step 142500, global step 2281341: loss -102.1363
[2019-03-24 00:58:57,687] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 142500, global step 2281341: learning rate 0.0005
[2019-03-24 00:58:58,036] A3C_AGENT_WORKER-Thread-15 INFO:Local step 142500, global step 2281523: loss -101.3211
[2019-03-24 00:58:58,038] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 142500, global step 2281523: learning rate 0.0005
[2019-03-24 00:58:58,305] A3C_AGENT_WORKER-Thread-17 INFO:Local step 142500, global step 2281660: loss -117.3955
[2019-03-24 00:58:58,306] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 142500, global step 2281660: learning rate 0.0005
[2019-03-24 00:59:00,589] A3C_AGENT_WORKER-Thread-18 INFO:Local step 143000, global step 2282838: loss 0.0004
[2019-03-24 00:59:00,597] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 143000, global step 2282843: learning rate 0.0005
[2019-03-24 00:59:04,952] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.6010192e-19 1.0000000e+00 1.9568999e-27 1.4004292e-26 1.6007601e-29], sum to 1.0000
[2019-03-24 00:59:04,957] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0047
[2019-03-24 00:59:04,963] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.5029722230282271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 599971.1349403046, 599971.134940305, 143365.5439581852], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6156000.0000, 
sim time next is 6156600.0000, 
raw observation next is [23.1, 88.66666666666667, 1.0, 2.0, 0.5549871217794411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 661297.9489648854, 661297.9489648854, 151776.353902127], 
processed observation next is [1.0, 0.2608695652173913, 0.41111111111111115, 0.8866666666666667, 1.0, 1.0, 0.47022276402314417, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2361778389160305, 0.2361778389160305, 0.2918776036579366], 
reward next is 0.7081, 
noisyNet noise sample is [array([-1.3441741], dtype=float32), -1.0058358]. 
=============================================
[2019-03-24 00:59:07,879] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.9939545e-17 1.0000000e+00 4.6347855e-27 3.4218746e-26 4.1811421e-29], sum to 1.0000
[2019-03-24 00:59:07,890] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9060
[2019-03-24 00:59:07,900] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2053187.871131749 W.
[2019-03-24 00:59:07,905] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.7, 55.0, 1.0, 2.0, 0.900046806053352, 1.0, 2.0, 0.900046806053352, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2053187.871131749, 2053187.871131749, 386829.3628872499], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6451200.0000, 
sim time next is 6451800.0000, 
raw observation next is [31.65, 55.0, 1.0, 2.0, 0.9754608416815189, 1.0, 2.0, 0.9754608416815189, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2225436.850999976, 2225436.850999976, 421591.4771167641], 
processed observation next is [1.0, 0.6956521739130435, 0.7277777777777777, 0.55, 1.0, 1.0, 0.9707867162875226, 1.0, 1.0, 0.9707867162875226, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.7947988753571343, 0.7947988753571343, 0.8107528406091618], 
reward next is 0.1892, 
noisyNet noise sample is [array([1.2415131], dtype=float32), -1.1025522]. 
=============================================
[2019-03-24 00:59:08,865] A3C_AGENT_WORKER-Thread-22 INFO:Local step 143500, global step 2287073: loss -71.7638
[2019-03-24 00:59:08,867] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 143500, global step 2287073: learning rate 0.0005
[2019-03-24 00:59:11,085] A3C_AGENT_WORKER-Thread-9 INFO:Local step 143000, global step 2288214: loss 0.0026
[2019-03-24 00:59:11,087] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 143000, global step 2288214: learning rate 0.0005
[2019-03-24 00:59:11,340] A3C_AGENT_WORKER-Thread-19 INFO:Local step 143000, global step 2288346: loss 0.0085
[2019-03-24 00:59:11,341] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 143000, global step 2288346: learning rate 0.0005
[2019-03-24 00:59:11,433] A3C_AGENT_WORKER-Thread-21 INFO:Local step 143000, global step 2288391: loss 0.0268
[2019-03-24 00:59:11,437] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 143000, global step 2288391: learning rate 0.0005
[2019-03-24 00:59:11,803] A3C_AGENT_WORKER-Thread-2 INFO:Local step 143000, global step 2288581: loss 0.0002
[2019-03-24 00:59:11,806] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 143000, global step 2288581: learning rate 0.0005
[2019-03-24 00:59:11,972] A3C_AGENT_WORKER-Thread-14 INFO:Local step 143000, global step 2288666: loss 0.0089
[2019-03-24 00:59:11,976] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 143000, global step 2288667: learning rate 0.0005
[2019-03-24 00:59:12,691] A3C_AGENT_WORKER-Thread-16 INFO:Local step 143000, global step 2289038: loss 0.0051
[2019-03-24 00:59:12,693] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 143000, global step 2289038: learning rate 0.0005
[2019-03-24 00:59:12,922] A3C_AGENT_WORKER-Thread-10 INFO:Local step 143000, global step 2289151: loss 0.0099
[2019-03-24 00:59:12,925] A3C_AGENT_WORKER-Thread-11 INFO:Local step 143000, global step 2289151: loss 0.0076
[2019-03-24 00:59:12,927] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 143000, global step 2289151: learning rate 0.0005
[2019-03-24 00:59:12,927] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 143000, global step 2289152: learning rate 0.0005
[2019-03-24 00:59:12,962] A3C_AGENT_WORKER-Thread-13 INFO:Local step 143000, global step 2289173: loss 0.0012
[2019-03-24 00:59:12,964] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 143000, global step 2289174: learning rate 0.0005
[2019-03-24 00:59:13,120] A3C_AGENT_WORKER-Thread-12 INFO:Local step 143000, global step 2289250: loss 0.0251
[2019-03-24 00:59:13,122] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 143000, global step 2289251: learning rate 0.0005
[2019-03-24 00:59:13,140] A3C_AGENT_WORKER-Thread-20 INFO:Local step 143000, global step 2289262: loss 0.0184
[2019-03-24 00:59:13,142] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 143000, global step 2289262: learning rate 0.0005
[2019-03-24 00:59:13,212] A3C_AGENT_WORKER-Thread-3 INFO:Local step 143000, global step 2289297: loss 0.0165
[2019-03-24 00:59:13,213] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 143000, global step 2289297: learning rate 0.0005
[2019-03-24 00:59:13,664] A3C_AGENT_WORKER-Thread-15 INFO:Local step 143000, global step 2289532: loss 0.0053
[2019-03-24 00:59:13,666] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 143000, global step 2289532: learning rate 0.0005
[2019-03-24 00:59:14,103] A3C_AGENT_WORKER-Thread-17 INFO:Local step 143000, global step 2289755: loss 0.0001
[2019-03-24 00:59:14,105] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 143000, global step 2289756: learning rate 0.0005
[2019-03-24 00:59:16,260] A3C_AGENT_WORKER-Thread-18 INFO:Local step 143500, global step 2290872: loss -66.8349
[2019-03-24 00:59:16,262] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 143500, global step 2290872: learning rate 0.0005
[2019-03-24 00:59:18,633] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.2863258e-14 1.0000000e+00 6.3982804e-23 5.6877375e-21 2.7426424e-24], sum to 1.0000
[2019-03-24 00:59:18,645] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8862
[2019-03-24 00:59:18,651] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.86666666666667, 92.0, 1.0, 2.0, 0.8110919966781789, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 924491.7907857075, 924491.7907857075, 198236.2963494006], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6414600.0000, 
sim time next is 6415200.0000, 
raw observation next is [24.9, 92.0, 1.0, 2.0, 0.7964312522410109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 907771.412252223, 907771.4122522225, 195197.8800778459], 
processed observation next is [1.0, 0.2608695652173913, 0.47777777777777775, 0.92, 1.0, 1.0, 0.7576562526678701, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.32420407580436533, 0.32420407580436517, 0.37538053861124215], 
reward next is 0.6246, 
noisyNet noise sample is [array([-0.41437355], dtype=float32), 0.28193077]. 
=============================================
[2019-03-24 00:59:24,316] A3C_AGENT_WORKER-Thread-22 INFO:Local step 144000, global step 2294962: loss 0.7310
[2019-03-24 00:59:24,318] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 144000, global step 2294962: learning rate 0.0005
[2019-03-24 00:59:25,460] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.6435410e-14 1.0000000e+00 3.5452024e-21 8.5078725e-21 2.9977387e-23], sum to 1.0000
[2019-03-24 00:59:25,467] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6982
[2019-03-24 00:59:25,472] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.3, 83.66666666666667, 1.0, 2.0, 0.7003084711907016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 798153.7304811114, 798153.7304811114, 176204.0178367818], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6547200.0000, 
sim time next is 6547800.0000, 
raw observation next is [27.25, 84.33333333333334, 1.0, 2.0, 0.7047850199830988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 803258.4043194287, 803258.4043194287, 177053.5986338145], 
processed observation next is [1.0, 0.782608695652174, 0.5648148148148148, 0.8433333333333334, 1.0, 1.0, 0.6485535952179748, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28687800154265314, 0.28687800154265314, 0.3404876896804125], 
reward next is 0.6595, 
noisyNet noise sample is [array([1.8116575], dtype=float32), -0.25987023]. 
=============================================
[2019-03-24 00:59:26,779] A3C_AGENT_WORKER-Thread-9 INFO:Local step 143500, global step 2296229: loss -68.5011
[2019-03-24 00:59:26,781] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 143500, global step 2296229: learning rate 0.0005
[2019-03-24 00:59:27,111] A3C_AGENT_WORKER-Thread-21 INFO:Local step 143500, global step 2296402: loss -66.6912
[2019-03-24 00:59:27,112] A3C_AGENT_WORKER-Thread-19 INFO:Local step 143500, global step 2296402: loss -75.9512
[2019-03-24 00:59:27,113] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 143500, global step 2296402: learning rate 0.0005
[2019-03-24 00:59:27,115] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 143500, global step 2296403: learning rate 0.0005
[2019-03-24 00:59:27,461] A3C_AGENT_WORKER-Thread-2 INFO:Local step 143500, global step 2296581: loss -76.6937
[2019-03-24 00:59:27,464] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 143500, global step 2296581: learning rate 0.0005
[2019-03-24 00:59:27,726] A3C_AGENT_WORKER-Thread-14 INFO:Local step 143500, global step 2296721: loss -80.0426
[2019-03-24 00:59:27,731] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 143500, global step 2296721: learning rate 0.0005
[2019-03-24 00:59:28,299] A3C_AGENT_WORKER-Thread-16 INFO:Local step 143500, global step 2297010: loss -37.2498
[2019-03-24 00:59:28,302] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 143500, global step 2297011: learning rate 0.0005
[2019-03-24 00:59:28,413] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.1343606e-16 1.0000000e+00 6.4553378e-28 9.6682852e-25 1.0618836e-28], sum to 1.0000
[2019-03-24 00:59:28,421] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2558
[2019-03-24 00:59:28,426] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.63333333333334, 45.33333333333334, 1.0, 2.0, 0.676832836626076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 856595.6659612665, 856595.6659612665, 174753.2421855305], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6600000.0000, 
sim time next is 6600600.0000, 
raw observation next is [25.8, 44.5, 1.0, 2.0, 0.6741456802161254, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 853339.6604784119, 853339.6604784115, 174243.0422386104], 
processed observation next is [1.0, 0.391304347826087, 0.5111111111111112, 0.445, 1.0, 1.0, 0.6120781907334826, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.30476416445657567, 0.3047641644565755, 0.3350827735357892], 
reward next is 0.6649, 
noisyNet noise sample is [array([1.218707], dtype=float32), -0.5764485]. 
=============================================
[2019-03-24 00:59:28,499] A3C_AGENT_WORKER-Thread-10 INFO:Local step 143500, global step 2297109: loss -65.4170
[2019-03-24 00:59:28,503] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 143500, global step 2297110: learning rate 0.0005
[2019-03-24 00:59:28,623] A3C_AGENT_WORKER-Thread-11 INFO:Local step 143500, global step 2297171: loss -73.9917
[2019-03-24 00:59:28,627] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 143500, global step 2297171: learning rate 0.0005
[2019-03-24 00:59:28,707] A3C_AGENT_WORKER-Thread-13 INFO:Local step 143500, global step 2297221: loss -73.9222
[2019-03-24 00:59:28,712] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 143500, global step 2297222: learning rate 0.0005
[2019-03-24 00:59:28,732] A3C_AGENT_WORKER-Thread-20 INFO:Local step 143500, global step 2297228: loss -54.6178
[2019-03-24 00:59:28,733] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 143500, global step 2297228: learning rate 0.0005
[2019-03-24 00:59:28,772] A3C_AGENT_WORKER-Thread-3 INFO:Local step 143500, global step 2297248: loss -55.3257
[2019-03-24 00:59:28,774] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 143500, global step 2297248: learning rate 0.0005
[2019-03-24 00:59:28,974] A3C_AGENT_WORKER-Thread-12 INFO:Local step 143500, global step 2297353: loss -53.2877
[2019-03-24 00:59:28,976] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 143500, global step 2297353: learning rate 0.0005
[2019-03-24 00:59:29,613] A3C_AGENT_WORKER-Thread-15 INFO:Local step 143500, global step 2297680: loss -71.5673
[2019-03-24 00:59:29,624] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 143500, global step 2297682: learning rate 0.0005
[2019-03-24 00:59:29,739] A3C_AGENT_WORKER-Thread-17 INFO:Local step 143500, global step 2297749: loss -73.0181
[2019-03-24 00:59:29,739] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 143500, global step 2297749: learning rate 0.0005
[2019-03-24 00:59:31,654] A3C_AGENT_WORKER-Thread-18 INFO:Local step 144000, global step 2298740: loss 0.0040
[2019-03-24 00:59:31,658] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 144000, global step 2298741: learning rate 0.0005
[2019-03-24 00:59:31,938] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.7751999e-20 1.0000000e+00 2.0941339e-29 9.7308381e-28 7.6986510e-32], sum to 1.0000
[2019-03-24 00:59:31,944] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0571
[2019-03-24 00:59:31,953] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.45, 35.5, 1.0, 2.0, 0.8704698806249654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.960473558777737, 6.9112, 121.925759954378, 1131116.634516287, 1105884.226897831, 215065.1163791966], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6694200.0000, 
sim time next is 6694800.0000, 
raw observation next is [27.6, 35.0, 1.0, 2.0, 0.8806273728823076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.028945682652712, 6.9112, 121.925445759016, 1178885.354332206, 1118589.335988953, 217360.7352372656], 
processed observation next is [1.0, 0.4782608695652174, 0.5777777777777778, 0.35, 1.0, 1.0, 0.8578897296217948, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.011774568265271235, 0.0, 0.809458166312695, 0.4210304836900736, 0.39949619142462606, 0.4180014139178184], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3345325], dtype=float32), 0.4669741]. 
=============================================
[2019-03-24 00:59:32,895] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.0696869e-17 1.0000000e+00 1.5862155e-27 2.9159993e-24 5.8407918e-29], sum to 1.0000
[2019-03-24 00:59:32,904] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3659
[2019-03-24 00:59:32,909] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.8, 31.0, 1.0, 2.0, 0.6439409038421204, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 817888.5092123831, 817888.5092123831, 168604.8578740173], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6699600.0000, 
sim time next is 6700200.0000, 
raw observation next is [28.95, 30.66666666666667, 1.0, 2.0, 0.5519914371912241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 700956.751567791, 700956.751567791, 152357.8970843423], 
processed observation next is [1.0, 0.5652173913043478, 0.6277777777777778, 0.3066666666666667, 1.0, 1.0, 0.46665647284669537, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2503416969884968, 0.2503416969884968, 0.29299595593142747], 
reward next is 0.7070, 
noisyNet noise sample is [array([0.35394135], dtype=float32), 0.35558763]. 
=============================================
[2019-03-24 00:59:34,114] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-24 00:59:34,115] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 00:59:34,116] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:59:34,118] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 00:59:34,120] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 00:59:34,123] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:59:34,123] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 00:59:34,124] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:59:34,124] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:59:34,128] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 00:59:34,129] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 00:59:34,142] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run93
[2019-03-24 00:59:34,164] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run93
[2019-03-24 00:59:34,188] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run93
[2019-03-24 00:59:34,215] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run93
[2019-03-24 00:59:34,246] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run93
[2019-03-24 01:01:17,419] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.051471323]
[2019-03-24 01:01:17,420] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.21999374, 95.75427273666668, 1.0, 2.0, 0.3837335099998615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 473808.6507208747, 473808.6507208747, 126313.1249548757]
[2019-03-24 01:01:17,421] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:01:17,424] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.2868142e-17 1.0000000e+00 4.3591113e-28 7.2286776e-26 3.7257833e-30], sampled 0.5331605948672788
[2019-03-24 01:01:20,893] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.051471323]
[2019-03-24 01:01:20,893] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [13.9, 88.0, 1.0, 2.0, 0.1652301970392768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 213117.5471139432, 213117.5471139427, 73582.1277866316]
[2019-03-24 01:01:20,894] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:01:20,897] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.2868142e-17 1.0000000e+00 4.3591113e-28 7.2286776e-26 3.7257833e-30], sampled 0.23186122792085062
[2019-03-24 01:01:23,723] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 01:01:23,772] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 01:01:23,775] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 01:01:23,906] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 01:01:23,918] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 01:01:24,937] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 2300000, evaluation results [2300000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 01:01:25,239] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.1635949e-18 1.0000000e+00 3.3208321e-28 2.1496347e-28 5.8324141e-31], sum to 1.0000
[2019-03-24 01:01:25,244] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4230
[2019-03-24 01:01:25,248] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 42.0, 1.0, 2.0, 0.3196574655663177, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 404617.4127628648, 404617.4127628648, 118017.4986277593], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6723600.0000, 
sim time next is 6724200.0000, 
raw observation next is [26.25, 43.0, 1.0, 2.0, 0.3180424702930228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 402652.0837525072, 402652.0837525072, 117813.3916239427], 
processed observation next is [1.0, 0.8260869565217391, 0.5277777777777778, 0.43, 1.0, 1.0, 0.18814579796788428, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14380431562589543, 0.14380431562589543, 0.2265642146614283], 
reward next is 0.7734, 
noisyNet noise sample is [array([0.2608754], dtype=float32), -1.3887805]. 
=============================================
[2019-03-24 01:01:28,772] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2774877e-16 1.0000000e+00 1.2923820e-26 9.7386567e-24 8.8774483e-29], sum to 1.0000
[2019-03-24 01:01:28,778] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5298
[2019-03-24 01:01:28,780] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.73333333333333, 62.33333333333334, 1.0, 2.0, 0.4862063722148026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 583057.1898966172, 583057.1898966172, 140858.1417607958], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6805200.0000, 
sim time next is 6805800.0000, 
raw observation next is [26.55, 63.0, 1.0, 2.0, 0.4833871908108887, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 580247.2279717482, 580247.2279717482, 140442.0000355048], 
processed observation next is [1.0, 0.782608695652174, 0.5388888888888889, 0.63, 1.0, 1.0, 0.38498475096534374, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20723115284705293, 0.20723115284705293, 0.27008076929904773], 
reward next is 0.7299, 
noisyNet noise sample is [array([0.33670598], dtype=float32), -0.6647676]. 
=============================================
[2019-03-24 01:01:30,685] A3C_AGENT_WORKER-Thread-22 INFO:Local step 144500, global step 2302902: loss 0.1247
[2019-03-24 01:01:30,690] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 144500, global step 2302904: learning rate 0.0005
[2019-03-24 01:01:33,353] A3C_AGENT_WORKER-Thread-9 INFO:Local step 144000, global step 2304276: loss 0.0216
[2019-03-24 01:01:33,355] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 144000, global step 2304278: learning rate 0.0005
[2019-03-24 01:01:33,539] A3C_AGENT_WORKER-Thread-19 INFO:Local step 144000, global step 2304372: loss 0.0125
[2019-03-24 01:01:33,541] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 144000, global step 2304373: learning rate 0.0005
[2019-03-24 01:01:33,577] A3C_AGENT_WORKER-Thread-21 INFO:Local step 144000, global step 2304393: loss 0.0057
[2019-03-24 01:01:33,578] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 144000, global step 2304393: learning rate 0.0005
[2019-03-24 01:01:33,675] A3C_AGENT_WORKER-Thread-2 INFO:Local step 144000, global step 2304441: loss 0.0010
[2019-03-24 01:01:33,676] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 144000, global step 2304441: learning rate 0.0005
[2019-03-24 01:01:34,459] A3C_AGENT_WORKER-Thread-14 INFO:Local step 144000, global step 2304773: loss 0.0162
[2019-03-24 01:01:34,462] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 144000, global step 2304773: learning rate 0.0005
[2019-03-24 01:01:34,870] A3C_AGENT_WORKER-Thread-16 INFO:Local step 144000, global step 2304988: loss 0.0069
[2019-03-24 01:01:34,873] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 144000, global step 2304989: learning rate 0.0005
[2019-03-24 01:01:35,095] A3C_AGENT_WORKER-Thread-10 INFO:Local step 144000, global step 2305104: loss 0.0044
[2019-03-24 01:01:35,097] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 144000, global step 2305104: learning rate 0.0005
[2019-03-24 01:01:35,313] A3C_AGENT_WORKER-Thread-13 INFO:Local step 144000, global step 2305212: loss 0.0164
[2019-03-24 01:01:35,316] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 144000, global step 2305212: learning rate 0.0005
[2019-03-24 01:01:35,410] A3C_AGENT_WORKER-Thread-20 INFO:Local step 144000, global step 2305264: loss 0.0120
[2019-03-24 01:01:35,414] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 144000, global step 2305264: learning rate 0.0005
[2019-03-24 01:01:35,461] A3C_AGENT_WORKER-Thread-12 INFO:Local step 144000, global step 2305291: loss 0.0006
[2019-03-24 01:01:35,464] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 144000, global step 2305291: learning rate 0.0005
[2019-03-24 01:01:35,466] A3C_AGENT_WORKER-Thread-3 INFO:Local step 144000, global step 2305292: loss 0.0001
[2019-03-24 01:01:35,473] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 144000, global step 2305292: learning rate 0.0005
[2019-03-24 01:01:35,552] A3C_AGENT_WORKER-Thread-11 INFO:Local step 144000, global step 2305337: loss 0.0042
[2019-03-24 01:01:35,555] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 144000, global step 2305337: learning rate 0.0005
[2019-03-24 01:01:36,043] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.191573e-18 1.000000e+00 2.646042e-29 8.946167e-26 1.338204e-30], sum to 1.0000
[2019-03-24 01:01:36,053] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1266
[2019-03-24 01:01:36,057] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.66666666666667, 53.0, 1.0, 2.0, 0.5327738407030639, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 628119.4119056661, 628119.4119056661, 147853.7391272896], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6957600.0000, 
sim time next is 6958200.0000, 
raw observation next is [29.83333333333333, 52.5, 1.0, 2.0, 0.5353514474197514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 630548.5466762512, 630548.5466762512, 148247.7503761069], 
processed observation next is [0.0, 0.5217391304347826, 0.6604938271604937, 0.525, 1.0, 1.0, 0.4468469612139897, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2251959095272326, 0.2251959095272326, 0.28509182764635943], 
reward next is 0.7149, 
noisyNet noise sample is [array([0.0022966], dtype=float32), 0.1641611]. 
=============================================
[2019-03-24 01:01:36,199] A3C_AGENT_WORKER-Thread-15 INFO:Local step 144000, global step 2305664: loss 0.0043
[2019-03-24 01:01:36,200] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 144000, global step 2305665: learning rate 0.0005
[2019-03-24 01:01:36,527] A3C_AGENT_WORKER-Thread-17 INFO:Local step 144000, global step 2305836: loss 0.0209
[2019-03-24 01:01:36,528] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 144000, global step 2305836: learning rate 0.0005
[2019-03-24 01:01:36,970] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.3177503e-18 1.0000000e+00 1.2380355e-26 2.0575086e-24 2.9972378e-29], sum to 1.0000
[2019-03-24 01:01:36,975] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8420
[2019-03-24 01:01:36,982] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.13333333333333, 46.66666666666667, 1.0, 2.0, 0.4965556250303706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 594122.7097011866, 594122.7097011866, 142423.1816464718], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6975600.0000, 
sim time next is 6976200.0000, 
raw observation next is [29.86666666666667, 47.33333333333333, 1.0, 2.0, 0.4923053538901081, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 589977.1692501822, 589977.1692501822, 141792.4381396049], 
processed observation next is [0.0, 0.7391304347826086, 0.6617283950617285, 0.4733333333333333, 1.0, 1.0, 0.3956016117739382, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21070613187506507, 0.21070613187506507, 0.2726777656530863], 
reward next is 0.7273, 
noisyNet noise sample is [array([1.2100744], dtype=float32), 2.885989]. 
=============================================
[2019-03-24 01:01:38,173] A3C_AGENT_WORKER-Thread-18 INFO:Local step 144500, global step 2306681: loss 0.0869
[2019-03-24 01:01:38,174] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 144500, global step 2306681: learning rate 0.0005
[2019-03-24 01:01:41,011] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.0472740e-17 1.0000000e+00 2.5553110e-25 1.9905868e-25 4.5724938e-28], sum to 1.0000
[2019-03-24 01:01:41,014] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0039
[2019-03-24 01:01:41,020] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.6, 91.0, 1.0, 2.0, 0.4825627817021838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 595782.2469060741, 595782.2469060741, 140806.6456583215], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7016400.0000, 
sim time next is 7017000.0000, 
raw observation next is [20.68333333333333, 90.66666666666667, 1.0, 2.0, 0.5715613862406655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 705282.2293120772, 705282.2293120772, 155334.9857008482], 
processed observation next is [1.0, 0.21739130434782608, 0.3216049382716048, 0.9066666666666667, 1.0, 1.0, 0.48995403123888753, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.251886510468599, 0.251886510468599, 0.29872112634778497], 
reward next is 0.7013, 
noisyNet noise sample is [array([0.04579648], dtype=float32), -0.25499752]. 
=============================================
[2019-03-24 01:01:41,042] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[71.93418]
 [71.93418]
 [71.93418]
 [71.93418]
 [71.93418]], R is [[71.91613007]
 [71.92618561]
 [71.93545532]
 [71.94255066]
 [71.94394684]].
[2019-03-24 01:01:46,323] A3C_AGENT_WORKER-Thread-22 INFO:Local step 145000, global step 2310872: loss 0.0062
[2019-03-24 01:01:46,328] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 145000, global step 2310872: learning rate 0.0005
[2019-03-24 01:01:49,110] A3C_AGENT_WORKER-Thread-9 INFO:Local step 144500, global step 2312295: loss 0.0941
[2019-03-24 01:01:49,111] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 144500, global step 2312295: learning rate 0.0005
[2019-03-24 01:01:49,207] A3C_AGENT_WORKER-Thread-21 INFO:Local step 144500, global step 2312349: loss 0.1433
[2019-03-24 01:01:49,210] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 144500, global step 2312350: learning rate 0.0005
[2019-03-24 01:01:49,222] A3C_AGENT_WORKER-Thread-19 INFO:Local step 144500, global step 2312355: loss 0.1495
[2019-03-24 01:01:49,223] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 144500, global step 2312355: learning rate 0.0005
[2019-03-24 01:01:49,368] A3C_AGENT_WORKER-Thread-2 INFO:Local step 144500, global step 2312431: loss 0.2367
[2019-03-24 01:01:49,369] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 144500, global step 2312432: learning rate 0.0005
[2019-03-24 01:01:50,192] A3C_AGENT_WORKER-Thread-14 INFO:Local step 144500, global step 2312842: loss 0.2240
[2019-03-24 01:01:50,193] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 144500, global step 2312842: learning rate 0.0005
[2019-03-24 01:01:50,460] A3C_AGENT_WORKER-Thread-16 INFO:Local step 144500, global step 2312978: loss 0.1257
[2019-03-24 01:01:50,463] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 144500, global step 2312979: learning rate 0.0005
[2019-03-24 01:01:50,648] A3C_AGENT_WORKER-Thread-10 INFO:Local step 144500, global step 2313077: loss 0.0997
[2019-03-24 01:01:50,652] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 144500, global step 2313077: learning rate 0.0005
[2019-03-24 01:01:50,775] A3C_AGENT_WORKER-Thread-20 INFO:Local step 144500, global step 2313140: loss 0.1824
[2019-03-24 01:01:50,777] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 144500, global step 2313143: learning rate 0.0005
[2019-03-24 01:01:50,814] A3C_AGENT_WORKER-Thread-13 INFO:Local step 144500, global step 2313159: loss 0.1557
[2019-03-24 01:01:50,819] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 144500, global step 2313160: learning rate 0.0005
[2019-03-24 01:01:51,165] A3C_AGENT_WORKER-Thread-12 INFO:Local step 144500, global step 2313337: loss 0.1233
[2019-03-24 01:01:51,166] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 144500, global step 2313337: learning rate 0.0005
[2019-03-24 01:01:51,223] A3C_AGENT_WORKER-Thread-3 INFO:Local step 144500, global step 2313369: loss 0.1355
[2019-03-24 01:01:51,224] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 144500, global step 2313369: learning rate 0.0005
[2019-03-24 01:01:51,248] A3C_AGENT_WORKER-Thread-11 INFO:Local step 144500, global step 2313380: loss 0.1340
[2019-03-24 01:01:51,250] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 144500, global step 2313380: learning rate 0.0005
[2019-03-24 01:01:51,753] A3C_AGENT_WORKER-Thread-15 INFO:Local step 144500, global step 2313636: loss 0.1379
[2019-03-24 01:01:51,755] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 144500, global step 2313637: learning rate 0.0005
[2019-03-24 01:01:52,000] A3C_AGENT_WORKER-Thread-17 INFO:Local step 144500, global step 2313769: loss 0.1149
[2019-03-24 01:01:52,002] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 144500, global step 2313769: learning rate 0.0005
[2019-03-24 01:01:53,581] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.9915888e-18 1.0000000e+00 4.2622237e-30 7.2899006e-27 6.1533993e-31], sum to 1.0000
[2019-03-24 01:01:53,591] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0707
[2019-03-24 01:01:53,595] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.25, 76.0, 1.0, 2.0, 0.3919717795157055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 486138.9148172616, 486138.9148172616, 127504.321175569], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7245000.0000, 
sim time next is 7245600.0000, 
raw observation next is [22.16666666666667, 76.33333333333333, 1.0, 2.0, 0.3896076922121052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 483439.1701342592, 483439.1701342587, 127180.1531026539], 
processed observation next is [1.0, 0.8695652173913043, 0.3765432098765434, 0.7633333333333333, 1.0, 1.0, 0.2733424907286967, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17265684647652116, 0.17265684647652096, 0.24457721750510367], 
reward next is 0.7554, 
noisyNet noise sample is [array([-1.1924487], dtype=float32), 1.2273914]. 
=============================================
[2019-03-24 01:01:53,839] A3C_AGENT_WORKER-Thread-18 INFO:Local step 145000, global step 2314707: loss 0.0009
[2019-03-24 01:01:53,842] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 145000, global step 2314708: learning rate 0.0005
[2019-03-24 01:02:02,253] A3C_AGENT_WORKER-Thread-22 INFO:Local step 145500, global step 2319031: loss 0.6197
[2019-03-24 01:02:02,262] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 145500, global step 2319031: learning rate 0.0005
[2019-03-24 01:02:04,540] A3C_AGENT_WORKER-Thread-9 INFO:Local step 145000, global step 2320199: loss 0.0027
[2019-03-24 01:02:04,542] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 145000, global step 2320199: learning rate 0.0005
[2019-03-24 01:02:04,625] A3C_AGENT_WORKER-Thread-2 INFO:Local step 145000, global step 2320241: loss 0.0094
[2019-03-24 01:02:04,626] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 145000, global step 2320241: learning rate 0.0005
[2019-03-24 01:02:04,843] A3C_AGENT_WORKER-Thread-21 INFO:Local step 145000, global step 2320351: loss 0.0190
[2019-03-24 01:02:04,845] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 145000, global step 2320352: learning rate 0.0005
[2019-03-24 01:02:04,952] A3C_AGENT_WORKER-Thread-19 INFO:Local step 145000, global step 2320392: loss 0.0072
[2019-03-24 01:02:04,953] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 145000, global step 2320392: learning rate 0.0005
[2019-03-24 01:02:05,822] A3C_AGENT_WORKER-Thread-14 INFO:Local step 145000, global step 2320844: loss 0.0139
[2019-03-24 01:02:05,823] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 145000, global step 2320844: learning rate 0.0005
[2019-03-24 01:02:06,259] A3C_AGENT_WORKER-Thread-20 INFO:Local step 145000, global step 2321059: loss 0.0002
[2019-03-24 01:02:06,261] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 145000, global step 2321059: learning rate 0.0005
[2019-03-24 01:02:06,326] A3C_AGENT_WORKER-Thread-16 INFO:Local step 145000, global step 2321094: loss 0.0038
[2019-03-24 01:02:06,334] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 145000, global step 2321099: learning rate 0.0005
[2019-03-24 01:02:06,383] A3C_AGENT_WORKER-Thread-13 INFO:Local step 145000, global step 2321120: loss 0.0114
[2019-03-24 01:02:06,390] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 145000, global step 2321122: learning rate 0.0005
[2019-03-24 01:02:06,470] A3C_AGENT_WORKER-Thread-10 INFO:Local step 145000, global step 2321168: loss 0.0219
[2019-03-24 01:02:06,476] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 145000, global step 2321171: learning rate 0.0005
[2019-03-24 01:02:06,514] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8708534e-18 1.0000000e+00 1.9642657e-28 2.1455839e-24 2.0151518e-31], sum to 1.0000
[2019-03-24 01:02:06,521] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2402
[2019-03-24 01:02:06,524] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 59.0, 1.0, 2.0, 0.4491442831810102, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 545563.7256091705, 545563.7256091705, 135464.973181522], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7756200.0000, 
sim time next is 7756800.0000, 
raw observation next is [26.23333333333333, 59.66666666666667, 1.0, 2.0, 0.4429258551867517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 539108.6202688181, 539108.6202688181, 134575.4205269449], 
processed observation next is [1.0, 0.782608695652174, 0.5271604938271603, 0.5966666666666667, 1.0, 1.0, 0.33681649426994253, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19253879295314932, 0.19253879295314932, 0.25879888562874015], 
reward next is 0.7412, 
noisyNet noise sample is [array([-0.54625446], dtype=float32), -0.21312578]. 
=============================================
[2019-03-24 01:02:06,651] A3C_AGENT_WORKER-Thread-3 INFO:Local step 145000, global step 2321260: loss 0.0109
[2019-03-24 01:02:06,653] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 145000, global step 2321260: learning rate 0.0005
[2019-03-24 01:02:06,957] A3C_AGENT_WORKER-Thread-11 INFO:Local step 145000, global step 2321417: loss 0.0184
[2019-03-24 01:02:06,961] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 145000, global step 2321417: learning rate 0.0005
[2019-03-24 01:02:07,044] A3C_AGENT_WORKER-Thread-12 INFO:Local step 145000, global step 2321463: loss 0.0117
[2019-03-24 01:02:07,048] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 145000, global step 2321463: learning rate 0.0005
[2019-03-24 01:02:07,592] A3C_AGENT_WORKER-Thread-17 INFO:Local step 145000, global step 2321742: loss 0.0250
[2019-03-24 01:02:07,598] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 145000, global step 2321742: learning rate 0.0005
[2019-03-24 01:02:07,693] A3C_AGENT_WORKER-Thread-15 INFO:Local step 145000, global step 2321793: loss 0.0093
[2019-03-24 01:02:07,695] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 145000, global step 2321795: learning rate 0.0005
[2019-03-24 01:02:09,136] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.5142206e-18 1.0000000e+00 1.2001369e-27 1.2250651e-25 3.7024745e-31], sum to 1.0000
[2019-03-24 01:02:09,147] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2116
[2019-03-24 01:02:09,155] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 84.66666666666667, 1.0, 2.0, 0.4944272570502453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 589003.7397275171, 589003.7397275171, 141996.2653553995], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7554000.0000, 
sim time next is 7554600.0000, 
raw observation next is [23.85, 84.0, 1.0, 2.0, 0.4987379226910527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 593153.3766666291, 593153.3766666291, 142633.6857086556], 
processed observation next is [0.0, 0.43478260869565216, 0.43888888888888894, 0.84, 1.0, 1.0, 0.4032594317750628, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21184049166665325, 0.21184049166665325, 0.2742955494397223], 
reward next is 0.7257, 
noisyNet noise sample is [array([1.0697664], dtype=float32), 0.94369674]. 
=============================================
[2019-03-24 01:02:09,431] A3C_AGENT_WORKER-Thread-18 INFO:Local step 145500, global step 2322689: loss 0.3921
[2019-03-24 01:02:09,437] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 145500, global step 2322689: learning rate 0.0005
[2019-03-24 01:02:10,495] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:02:10,496] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:02:10,549] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run12
[2019-03-24 01:02:13,847] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-24 01:02:13,850] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:02:13,851] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:02:13,851] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:02:13,853] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:02:13,851] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:02:13,853] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:02:13,855] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:02:13,855] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:02:13,856] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:02:13,857] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:02:13,872] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run94
[2019-03-24 01:02:13,899] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run94
[2019-03-24 01:02:13,900] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run94
[2019-03-24 01:02:13,919] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run94
[2019-03-24 01:02:13,982] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run94
[2019-03-24 01:02:22,002] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.029613357]
[2019-03-24 01:02:22,006] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [33.551220825, 13.60764096166667, 1.0, 2.0, 0.8259985034245777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1061341.928532014, 1061341.928532014, 205253.8180688738]
[2019-03-24 01:02:22,007] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:02:22,010] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.1656354e-16 1.0000000e+00 1.4464829e-26 1.7228482e-24 1.3862893e-28], sampled 0.8701212876715425
[2019-03-24 01:02:41,515] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.029613357]
[2019-03-24 01:02:41,517] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [19.0, 94.0, 1.0, 2.0, 0.3526210066409078, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 442873.4277646825, 442873.4277646825, 122257.2238204414]
[2019-03-24 01:02:41,519] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:02:41,521] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.1656354e-16 1.0000000e+00 1.4464829e-26 1.7228482e-24 1.3862893e-28], sampled 0.07180788197169696
[2019-03-24 01:02:48,979] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.029613357]
[2019-03-24 01:02:48,980] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [32.94458753, 30.639453935, 1.0, 2.0, 0.9118554231382086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.008227581487229, 6.9112, 121.9255493219101, 1164431.622371991, 1114745.029448723, 223561.3252491035]
[2019-03-24 01:02:48,981] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:02:48,984] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.1656354e-16 1.0000000e+00 1.4464829e-26 1.7228482e-24 1.3862893e-28], sampled 0.6163181098741984
[2019-03-24 01:03:00,610] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.029613357]
[2019-03-24 01:03:00,614] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.4, 89.66666666666667, 1.0, 2.0, 0.5354882124552915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 633276.560643355, 633276.560643355, 148373.6255908939]
[2019-03-24 01:03:00,615] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:03:00,618] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.1656354e-16 1.0000000e+00 1.4464829e-26 1.7228482e-24 1.3862893e-28], sampled 0.19208613190141766
[2019-03-24 01:03:01,030] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.029613357]
[2019-03-24 01:03:01,031] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.8, 74.0, 1.0, 2.0, 0.7063737143951642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 805070.0238879248, 805070.0238879248, 177355.3355605689]
[2019-03-24 01:03:01,032] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:03:01,035] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.1656354e-16 1.0000000e+00 1.4464829e-26 1.7228482e-24 1.3862893e-28], sampled 0.8363243480606077
[2019-03-24 01:03:15,771] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.029613357]
[2019-03-24 01:03:15,774] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.35, 81.5, 1.0, 2.0, 0.4679583901760464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 563867.8854007042, 563867.8854007038, 138152.2657180974]
[2019-03-24 01:03:15,775] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:03:15,777] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.1656354e-16 1.0000000e+00 1.4464829e-26 1.7228482e-24 1.3862893e-28], sampled 0.25656599643882483
[2019-03-24 01:03:22,632] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.029613357]
[2019-03-24 01:03:22,634] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.23333333333333, 92.66666666666667, 1.0, 2.0, 0.8074051819512356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 920286.9946751249, 920286.9946751249, 197481.7697285013]
[2019-03-24 01:03:22,635] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:03:22,637] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.1656354e-16 1.0000000e+00 1.4464829e-26 1.7228482e-24 1.3862893e-28], sampled 0.07310342261962
[2019-03-24 01:03:27,776] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.029613357]
[2019-03-24 01:03:27,778] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.02018593, 85.40291681, 1.0, 2.0, 0.5330901369976825, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 630458.0319384394, 630458.0319384394, 147984.3626493626]
[2019-03-24 01:03:27,778] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:03:27,781] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.1656354e-16 1.0000000e+00 1.4464829e-26 1.7228482e-24 1.3862893e-28], sampled 0.22343705910776956
[2019-03-24 01:03:32,579] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.029613357]
[2019-03-24 01:03:32,580] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [32.0, 49.0, 1.0, 2.0, 0.605926130966612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 696183.3693783558, 696183.3693783553, 159377.0989006576]
[2019-03-24 01:03:32,581] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:03:32,583] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.1656354e-16 1.0000000e+00 1.4464829e-26 1.7228482e-24 1.3862893e-28], sampled 0.13793043163464358
[2019-03-24 01:03:56,660] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.029613357]
[2019-03-24 01:03:56,660] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.33333333333333, 19.66666666666667, 1.0, 2.0, 0.3326422767198366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 429109.7409841028, 429109.7409841028, 112211.1965880883]
[2019-03-24 01:03:56,661] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:03:56,665] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.1656354e-16 1.0000000e+00 1.4464829e-26 1.7228482e-24 1.3862893e-28], sampled 0.026544742984742964
[2019-03-24 01:04:04,017] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 01:04:04,115] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 01:04:04,164] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 01:04:04,202] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 01:04:04,230] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 01:04:05,243] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 2325000, evaluation results [2325000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 01:04:05,289] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.3552491e-17 1.0000000e+00 1.4665514e-26 2.0955696e-24 2.3794470e-28], sum to 1.0000
[2019-03-24 01:04:05,300] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8385
[2019-03-24 01:04:05,303] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 66.0, 1.0, 2.0, 0.9347759804160407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.187344911678953, 6.9112, 121.9246027898247, 1289390.252834982, 1147981.046425654, 229072.6505701339], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7664400.0000, 
sim time next is 7665000.0000, 
raw observation next is [24.15, 66.5, 1.0, 2.0, 0.5397354961753158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.925876277626, 664293.0032020496, 664293.0032020496, 149931.3217149194], 
processed observation next is [1.0, 0.7391304347826086, 0.44999999999999996, 0.665, 1.0, 1.0, 0.4520660668753759, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094610245085576, 0.23724750114358917, 0.23724750114358917, 0.2883294648363835], 
reward next is 0.7117, 
noisyNet noise sample is [array([1.0763788], dtype=float32), -0.88416123]. 
=============================================
[2019-03-24 01:04:05,315] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[70.04078]
 [70.04078]
 [70.04078]
 [70.04078]
 [70.04078]], R is [[70.05203247]
 [69.35150909]
 [68.65799713]
 [67.97142029]
 [67.2917099 ]].
[2019-03-24 01:04:05,664] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.0981138e-16 1.0000000e+00 9.2249746e-26 1.0698719e-23 7.4912614e-29], sum to 1.0000
[2019-03-24 01:04:05,671] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2532
[2019-03-24 01:04:05,679] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1385329.518956989 W.
[2019-03-24 01:04:05,684] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.76666666666667, 76.33333333333334, 1.0, 2.0, 0.4050125121536117, 1.0, 2.0, 0.4050125121536117, 1.0, 2.0, 0.6447931096852054, 6.911200000000001, 6.9112, 121.94756008, 1385329.518956989, 1385329.518956989, 299284.8541339727], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7644000.0000, 
sim time next is 7644600.0000, 
raw observation next is [25.85, 75.5, 1.0, 2.0, 0.4114983250536268, 1.0, 2.0, 0.4114983250536268, 1.0, 2.0, 0.6551187350502089, 6.911199999999999, 6.9112, 121.94756008, 1407534.370942143, 1407534.370942144, 302155.6661719665], 
processed observation next is [1.0, 0.4782608695652174, 0.5129629629629631, 0.755, 1.0, 1.0, 0.2994027679209843, 1.0, 1.0, 0.2994027679209843, 1.0, 1.0, 0.568898418812761, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.502690846765051, 0.5026908467650514, 0.5810685887922433], 
reward next is 0.4189, 
noisyNet noise sample is [array([0.05045107], dtype=float32), -0.23538621]. 
=============================================
[2019-03-24 01:04:08,738] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:04:08,738] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:04:08,787] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run12
[2019-03-24 01:04:09,476] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.2157212e-17 1.0000000e+00 2.7570917e-28 4.1881222e-27 2.2956511e-30], sum to 1.0000
[2019-03-24 01:04:09,483] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0671
[2019-03-24 01:04:09,490] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.43333333333333, 74.0, 1.0, 2.0, 0.3503640758223995, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 440519.4059046807, 440519.4059046807, 121965.1395806959], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7775400.0000, 
sim time next is 7776000.0000, 
raw observation next is [21.4, 74.0, 1.0, 2.0, 0.3499820938754528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 440207.4466638992, 440207.4466638992, 121917.0039296335], 
processed observation next is [1.0, 0.0, 0.3481481481481481, 0.74, 1.0, 1.0, 0.22616915937553908, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15721694523710686, 0.15721694523710686, 0.23445577678775673], 
reward next is 0.7655, 
noisyNet noise sample is [array([-0.7329422], dtype=float32), -1.861492]. 
=============================================
[2019-03-24 01:04:09,510] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[72.75211]
 [72.75211]
 [72.75211]
 [72.75211]
 [72.75211]], R is [[72.79013062]
 [72.8276825 ]
 [72.86465454]
 [72.9008255 ]
 [72.93612671]].
[2019-03-24 01:04:11,165] A3C_AGENT_WORKER-Thread-21 INFO:Local step 145500, global step 2328066: loss 0.6925
[2019-03-24 01:04:11,167] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 145500, global step 2328066: learning rate 0.0005
[2019-03-24 01:04:11,217] A3C_AGENT_WORKER-Thread-19 INFO:Local step 145500, global step 2328092: loss 0.7309
[2019-03-24 01:04:11,221] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 145500, global step 2328092: learning rate 0.0005
[2019-03-24 01:04:11,234] A3C_AGENT_WORKER-Thread-2 INFO:Local step 145500, global step 2328097: loss 0.7377
[2019-03-24 01:04:11,236] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 145500, global step 2328099: learning rate 0.0005
[2019-03-24 01:04:11,447] A3C_AGENT_WORKER-Thread-9 INFO:Local step 145500, global step 2328210: loss 0.8200
[2019-03-24 01:04:11,450] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 145500, global step 2328211: learning rate 0.0005
[2019-03-24 01:04:12,310] A3C_AGENT_WORKER-Thread-14 INFO:Local step 145500, global step 2328652: loss 0.7474
[2019-03-24 01:04:12,312] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 145500, global step 2328652: learning rate 0.0005
[2019-03-24 01:04:12,678] A3C_AGENT_WORKER-Thread-20 INFO:Local step 145500, global step 2328841: loss 0.6528
[2019-03-24 01:04:12,681] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 145500, global step 2328841: learning rate 0.0005
[2019-03-24 01:04:12,688] A3C_AGENT_WORKER-Thread-16 INFO:Local step 145500, global step 2328845: loss 0.5982
[2019-03-24 01:04:12,690] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 145500, global step 2328846: learning rate 0.0005
[2019-03-24 01:04:12,765] A3C_AGENT_WORKER-Thread-13 INFO:Local step 145500, global step 2328880: loss 0.6412
[2019-03-24 01:04:12,766] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 145500, global step 2328880: learning rate 0.0005
[2019-03-24 01:04:12,939] A3C_AGENT_WORKER-Thread-10 INFO:Local step 145500, global step 2328968: loss 0.5707
[2019-03-24 01:04:12,943] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 145500, global step 2328970: learning rate 0.0005
[2019-03-24 01:04:13,087] A3C_AGENT_WORKER-Thread-3 INFO:Local step 145500, global step 2329046: loss 0.5670
[2019-03-24 01:04:13,090] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 145500, global step 2329046: learning rate 0.0005
[2019-03-24 01:04:13,459] A3C_AGENT_WORKER-Thread-11 INFO:Local step 145500, global step 2329237: loss 0.6475
[2019-03-24 01:04:13,461] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 145500, global step 2329237: learning rate 0.0005
[2019-03-24 01:04:13,707] A3C_AGENT_WORKER-Thread-12 INFO:Local step 145500, global step 2329368: loss 0.6977
[2019-03-24 01:04:13,709] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 145500, global step 2329369: learning rate 0.0005
[2019-03-24 01:04:14,193] A3C_AGENT_WORKER-Thread-17 INFO:Local step 145500, global step 2329618: loss 0.5979
[2019-03-24 01:04:14,196] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 145500, global step 2329618: learning rate 0.0005
[2019-03-24 01:04:14,201] A3C_AGENT_WORKER-Thread-15 INFO:Local step 145500, global step 2329620: loss 0.6003
[2019-03-24 01:04:14,203] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 145500, global step 2329620: learning rate 0.0005
[2019-03-24 01:04:14,431] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.7117771e-19 1.0000000e+00 1.1157179e-28 1.7524165e-25 4.4179332e-30], sum to 1.0000
[2019-03-24 01:04:14,437] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1987
[2019-03-24 01:04:14,448] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.46666666666667, 78.66666666666666, 1.0, 2.0, 0.41784129838776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 514069.6578362684, 514069.6578362684, 131073.0897320431], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7868400.0000, 
sim time next is 7869000.0000, 
raw observation next is [22.38333333333334, 79.33333333333334, 1.0, 2.0, 0.4171831434735224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 513190.7817546593, 513190.7817546589, 130976.6824213282], 
processed observation next is [1.0, 0.043478260869565216, 0.38456790123456813, 0.7933333333333334, 1.0, 1.0, 0.30617040889705055, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18328242205523546, 0.18328242205523532, 0.25187823542563115], 
reward next is 0.7481, 
noisyNet noise sample is [array([-0.31918836], dtype=float32), -1.0361303]. 
=============================================
[2019-03-24 01:04:14,477] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[72.79764]
 [72.79764]
 [72.79764]
 [72.79764]
 [72.79764]], R is [[72.81778717]
 [72.8375473 ]
 [72.85683441]
 [72.87595367]
 [72.89542389]].
[2019-03-24 01:04:16,849] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.6563718e-18 1.0000000e+00 1.4076000e-27 2.3368194e-27 3.0439364e-30], sum to 1.0000
[2019-03-24 01:04:16,857] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3419
[2019-03-24 01:04:16,863] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.35, 78.83333333333333, 1.0, 2.0, 0.3782182963420791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 472260.8182454479, 472260.8182454479, 125667.4037781121], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7887000.0000, 
sim time next is 7887600.0000, 
raw observation next is [21.5, 78.0, 1.0, 2.0, 0.4176058456776866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 521171.5420578849, 521171.5420578844, 131204.4873860599], 
processed observation next is [1.0, 0.30434782608695654, 0.35185185185185186, 0.78, 1.0, 1.0, 0.3066736258067698, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18613269359210174, 0.18613269359210158, 0.252316321896269], 
reward next is 0.7477, 
noisyNet noise sample is [array([0.49687728], dtype=float32), -0.018262785]. 
=============================================
[2019-03-24 01:04:19,322] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:04:19,323] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:04:19,358] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run12
[2019-03-24 01:04:19,382] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:04:19,385] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:04:19,451] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run12
[2019-03-24 01:04:19,498] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:04:19,499] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:04:19,531] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run12
[2019-03-24 01:04:19,649] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:04:19,650] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:04:19,665] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run12
[2019-03-24 01:04:20,159] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:04:20,159] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:04:20,174] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run12
[2019-03-24 01:04:20,631] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:04:20,631] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:04:20,634] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run12
[2019-03-24 01:04:20,658] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:04:20,661] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:04:20,678] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run12
[2019-03-24 01:04:20,741] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:04:20,742] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:04:20,745] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run12
[2019-03-24 01:04:20,817] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:04:20,817] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:04:20,825] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run12
[2019-03-24 01:04:20,945] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:04:20,945] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:04:20,953] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run12
[2019-03-24 01:04:21,059] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:04:21,059] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:04:21,062] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run12
[2019-03-24 01:04:21,128] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:04:21,128] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:04:21,133] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run12
[2019-03-24 01:04:21,318] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:04:21,318] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:04:21,319] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 01:04:21,319] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:04:21,324] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run12
[2019-03-24 01:04:21,370] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run12
[2019-03-24 01:04:21,457] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8233282e-20 1.0000000e+00 1.9546746e-29 3.3099590e-26 5.7929202e-32], sum to 1.0000
[2019-03-24 01:04:21,458] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0057
[2019-03-24 01:04:21,464] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.75, 52.5, 1.0, 2.0, 0.2467886479127456, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 318335.2631113364, 318335.2631113364, 90190.41061407594], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 275400.0000, 
sim time next is 276000.0000, 
raw observation next is [19.66666666666667, 52.66666666666666, 1.0, 2.0, 0.2459556674284209, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 317260.5706232851, 317260.5706232851, 89832.0595139028], 
processed observation next is [0.0, 0.17391304347826086, 0.28395061728395077, 0.5266666666666666, 1.0, 1.0, 0.10232817551002488, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.11330734665117324, 0.11330734665117324, 0.17275396060365925], 
reward next is 0.8272, 
noisyNet noise sample is [array([0.30972272], dtype=float32), 1.2487277]. 
=============================================
[2019-03-24 01:04:21,492] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[78.59084]
 [78.59084]
 [78.59084]
 [78.59084]
 [78.59084]], R is [[78.63218689]
 [78.67241669]
 [78.71154022]
 [78.74949646]
 [78.78630829]].
[2019-03-24 01:04:23,401] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.4979778e-18 1.0000000e+00 2.1800648e-29 8.1033626e-27 5.6118030e-31], sum to 1.0000
[2019-03-24 01:04:23,407] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2882
[2019-03-24 01:04:23,410] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.08333333333334, 40.66666666666667, 1.0, 2.0, 0.8778937930167372, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.968329703998267, 6.9112, 121.9258058301802, 1136597.133905615, 1107341.676078935, 216648.111862733], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 40200.0000, 
sim time next is 40800.0000, 
raw observation next is [27.26666666666667, 40.33333333333334, 1.0, 2.0, 0.891768625357326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.056331691195534, 6.9112, 121.9253268945307, 1197990.797752987, 1123670.836407546, 219788.9514315095], 
processed observation next is [1.0, 0.4782608695652174, 0.5654320987654322, 0.40333333333333343, 1.0, 1.0, 0.8711531254253881, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.014513169119553382, 0.0, 0.809457377176123, 0.42785385634035245, 0.401311013002695, 0.4226710604452105], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.83972347], dtype=float32), -3.0019586]. 
=============================================
[2019-03-24 01:04:24,766] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1717119e-16 1.0000000e+00 1.0171190e-25 2.1480253e-23 4.1180827e-27], sum to 1.0000
[2019-03-24 01:04:24,773] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2942
[2019-03-24 01:04:24,779] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.2, 42.0, 1.0, 2.0, 0.7477062963883013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 948227.809551375, 948227.8095513746, 188736.6149153968], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 37800.0000, 
sim time next is 38400.0000, 
raw observation next is [26.43333333333333, 41.66666666666667, 1.0, 2.0, 0.7421658518344307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 939907.2651692273, 939907.2651692268, 187599.3833434944], 
processed observation next is [1.0, 0.43478260869565216, 0.5345679012345678, 0.41666666666666674, 1.0, 1.0, 0.6930545855171795, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3356811661318669, 0.3356811661318667, 0.3607680448913354], 
reward next is 0.6392, 
noisyNet noise sample is [array([0.358396], dtype=float32), -1.3225131]. 
=============================================
[2019-03-24 01:04:35,063] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1246165e-17 1.0000000e+00 3.5668886e-31 3.4653404e-27 4.6430532e-33], sum to 1.0000
[2019-03-24 01:04:35,076] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7912
[2019-03-24 01:04:35,078] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.7, 44.0, 1.0, 2.0, 0.2923694243148889, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 377022.3170129617, 377022.3170129617, 114624.8321204878], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 255600.0000, 
sim time next is 256200.0000, 
raw observation next is [23.55, 44.33333333333334, 1.0, 2.0, 0.290052927981668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 374139.588606559, 374139.5886065595, 113535.5539049163], 
processed observation next is [0.0, 1.0, 0.4277777777777778, 0.4433333333333334, 1.0, 1.0, 0.15482491426389047, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13362128164519962, 0.13362128164519982, 0.2183376036633006], 
reward next is 0.7817, 
noisyNet noise sample is [array([-0.10406508], dtype=float32), 0.7536233]. 
=============================================
[2019-03-24 01:04:41,368] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.7104560e-18 1.0000000e+00 4.5021682e-29 5.3863990e-28 1.9351684e-30], sum to 1.0000
[2019-03-24 01:04:41,376] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3354
[2019-03-24 01:04:41,384] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1647756.803119402 W.
[2019-03-24 01:04:41,388] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [35.7, 19.33333333333334, 1.0, 2.0, 0.4578077516242407, 1.0, 1.0, 0.4578077516242407, 1.0, 2.0, 0.738912989645513, 6.911199999999999, 6.9112, 121.94756008, 1647756.803119402, 1647756.803119403, 322956.2535823696], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 657600.0000, 
sim time next is 658200.0000, 
raw observation next is [35.7, 19.16666666666667, 1.0, 2.0, 0.6859109742277921, 1.0, 2.0, 0.6859109742277921, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1658842.377855082, 1658842.377855082, 303003.9843867712], 
processed observation next is [1.0, 0.6086956521739131, 0.8777777777777779, 0.1916666666666667, 1.0, 1.0, 0.6260844931283239, 1.0, 1.0, 0.6260844931283239, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.592443706376815, 0.592443706376815, 0.5826999699745601], 
reward next is 0.4173, 
noisyNet noise sample is [array([0.42139858], dtype=float32), 0.46385977]. 
=============================================
[2019-03-24 01:04:43,304] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.2016014e-17 1.0000000e+00 7.7476056e-27 1.9360605e-24 7.2502072e-29], sum to 1.0000
[2019-03-24 01:04:43,318] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3988
[2019-03-24 01:04:43,321] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 31.0, 1.0, 2.0, 0.3403667822058052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 432087.0220231767, 432087.0220231767, 120696.7800041589], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 414000.0000, 
sim time next is 414600.0000, 
raw observation next is [28.85, 31.5, 1.0, 2.0, 0.3387899122941676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 430147.4844558146, 430147.4844558142, 120491.3588618335], 
processed observation next is [1.0, 0.8260869565217391, 0.6240740740740741, 0.315, 1.0, 1.0, 0.21284513368353286, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15362410159136236, 0.1536241015913622, 0.23171415165737214], 
reward next is 0.7683, 
noisyNet noise sample is [array([-1.0690651], dtype=float32), 2.047587]. 
=============================================
[2019-03-24 01:04:46,229] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.4897977e-16 1.0000000e+00 9.0821878e-28 4.8404394e-26 1.1274753e-28], sum to 1.0000
[2019-03-24 01:04:46,234] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6313
[2019-03-24 01:04:46,237] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.23333333333333, 23.33333333333334, 1.0, 2.0, 0.3725949731914964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 470233.096464657, 470233.0964646575, 124975.333281595], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 494400.0000, 
sim time next is 495000.0000, 
raw observation next is [32.0, 24.0, 1.0, 2.0, 0.3647992917945648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 460557.7546229645, 460557.7546229645, 123919.4037024819], 
processed observation next is [1.0, 0.7391304347826086, 0.7407407407407407, 0.24, 1.0, 1.0, 0.24380868070781522, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16448491236534446, 0.16448491236534446, 0.23830654558169595], 
reward next is 0.7617, 
noisyNet noise sample is [array([0.30593246], dtype=float32), 1.1829826]. 
=============================================
[2019-03-24 01:04:46,249] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[73.32715]
 [73.32715]
 [73.32715]
 [73.32715]
 [73.32715]], R is [[73.35557556]
 [73.38168335]
 [73.37097931]
 [72.63726807]
 [71.9108963 ]].
[2019-03-24 01:04:54,280] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.1612584e-19 1.0000000e+00 8.7343588e-27 8.5761821e-26 5.2960926e-30], sum to 1.0000
[2019-03-24 01:04:54,291] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0160
[2019-03-24 01:04:54,295] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 52.83333333333334, 1.0, 2.0, 0.4276898020606814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 524743.9361174764, 524743.936117476, 132460.6442614311], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 910200.0000, 
sim time next is 910800.0000, 
raw observation next is [27.2, 52.0, 1.0, 2.0, 0.4293459571620378, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 526569.5558470953, 526569.5558470953, 132696.3340628253], 
processed observation next is [0.0, 0.5652173913043478, 0.5629629629629629, 0.52, 1.0, 1.0, 0.32064994900242594, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18806055565967691, 0.18806055565967691, 0.25518525781312557], 
reward next is 0.7448, 
noisyNet noise sample is [array([-0.04400508], dtype=float32), 0.28328153]. 
=============================================
[2019-03-24 01:04:54,774] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.0779636e-19 1.0000000e+00 2.2093934e-28 4.1014646e-27 3.0435982e-31], sum to 1.0000
[2019-03-24 01:04:54,782] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8221
[2019-03-24 01:04:54,790] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1609829.842262607 W.
[2019-03-24 01:04:54,797] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [35.7, 19.66666666666667, 1.0, 2.0, 0.6644629556804291, 1.0, 1.0, 0.6644629556804291, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1609829.842262607, 1609829.842262607, 295009.5339830925], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 656400.0000, 
sim time next is 657000.0000, 
raw observation next is [35.7, 19.5, 1.0, 2.0, 0.4477356403158313, 1.0, 2.0, 0.4477356403158313, 1.0, 1.0, 0.7220458495293222, 6.9112, 6.9112, 121.94756008, 1608959.619756282, 1608959.619756282, 318303.3896074946], 
processed observation next is [1.0, 0.6086956521739131, 0.8777777777777779, 0.195, 1.0, 1.0, 0.34254242894741826, 1.0, 1.0, 0.34254242894741826, 1.0, 0.5, 0.6525573119116526, 0.0, 0.0, 0.8096049824067558, 0.5746284356272436, 0.5746284356272436, 0.6121219030913357], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5885689], dtype=float32), -0.82659173]. 
=============================================
[2019-03-24 01:04:54,816] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[74.16519]
 [74.16519]
 [74.16519]
 [74.16519]
 [74.16519]], R is [[73.42353821]
 [72.68930054]
 [71.96240997]
 [71.68134308]
 [71.36316681]].
[2019-03-24 01:04:55,056] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-24 01:04:55,057] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:04:55,058] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:04:55,058] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:04:55,059] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:04:55,060] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:04:55,061] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:04:55,060] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:04:55,062] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:04:55,062] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:04:55,067] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:04:55,087] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run95
[2019-03-24 01:04:55,112] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run95
[2019-03-24 01:04:55,135] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run95
[2019-03-24 01:04:55,160] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run95
[2019-03-24 01:04:55,160] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run95
[2019-03-24 01:05:04,518] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0015856269]
[2019-03-24 01:05:04,521] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.73572779, 34.10916355, 1.0, 2.0, 0.299743504726488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 386659.5009715087, 386659.5009715087, 113303.3782658189]
[2019-03-24 01:05:04,523] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:05:04,528] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.2441287e-17 1.0000000e+00 2.7976601e-27 3.8017709e-25 2.4101862e-29], sampled 0.936167060255764
[2019-03-24 01:05:46,045] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0015856269]
[2019-03-24 01:05:46,047] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.6, 75.5, 1.0, 2.0, 0.755632662212677, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 861243.0982916754, 861243.0982916754, 186954.8874932016]
[2019-03-24 01:05:46,049] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:05:46,053] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.2441287e-17 1.0000000e+00 2.7976601e-27 3.8017709e-25 2.4101862e-29], sampled 0.6789260787390252
[2019-03-24 01:06:05,953] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0015856269]
[2019-03-24 01:06:05,954] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.12282006833333, 71.24196892, 1.0, 2.0, 0.63002627024236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 718014.3686615464, 718014.3686615459, 163319.4892621532]
[2019-03-24 01:06:05,955] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:06:05,958] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.2441287e-17 1.0000000e+00 2.7976601e-27 3.8017709e-25 2.4101862e-29], sampled 0.2130896597238382
[2019-03-24 01:06:08,863] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0015856269]
[2019-03-24 01:06:08,865] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [32.2, 58.0, 1.0, 2.0, 0.5829993107301369, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9281538896443796, 6.911199999999999, 6.9112, 121.9260426156618, 1329369.310023626, 1329369.310023627, 287308.5921349278]
[2019-03-24 01:06:08,867] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:06:08,870] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.2441287e-17 1.0000000e+00 2.7976601e-27 3.8017709e-25 2.4101862e-29], sampled 0.8277236248126593
[2019-03-24 01:06:08,872] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1329369.310023626 W.
[2019-03-24 01:06:20,979] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0015856269]
[2019-03-24 01:06:20,981] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.61666666666667, 88.0, 1.0, 2.0, 0.5030350538919883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 603511.86460153, 603511.86460153, 143499.4137015121]
[2019-03-24 01:06:20,982] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:06:20,985] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.2441287e-17 1.0000000e+00 2.7976601e-27 3.8017709e-25 2.4101862e-29], sampled 0.9533887200184005
[2019-03-24 01:06:30,043] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0015856269]
[2019-03-24 01:06:30,045] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.872422795, 80.018446325, 1.0, 2.0, 0.3846814733960503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 476912.2237340314, 476912.2237340314, 126488.5878614005]
[2019-03-24 01:06:30,046] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:06:30,048] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.2441287e-17 1.0000000e+00 2.7976601e-27 3.8017709e-25 2.4101862e-29], sampled 0.8459156075978537
[2019-03-24 01:06:44,142] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 01:06:44,270] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 01:06:44,455] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 01:06:44,570] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 01:06:44,701] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 01:06:45,717] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 2350000, evaluation results [2350000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 01:06:50,137] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.0008429e-17 1.0000000e+00 8.1311727e-26 8.3825385e-25 1.0694938e-28], sum to 1.0000
[2019-03-24 01:06:50,145] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2746
[2019-03-24 01:06:50,151] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1346682.030777237 W.
[2019-03-24 01:06:50,157] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.9, 52.0, 1.0, 2.0, 0.5572111789107118, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9033959637956098, 6.911199999999999, 6.9112, 121.9260426156326, 1346682.030777237, 1346682.030777237, 275356.3018389781], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 730800.0000, 
sim time next is 731400.0000, 
raw observation next is [27.2, 50.16666666666667, 1.0, 2.0, 0.5662168284450296, 1.0, 1.0, 0.5662168284450296, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1365467.110128487, 1365467.110128487, 259787.9704802891], 
processed observation next is [1.0, 0.4782608695652174, 0.5629629629629629, 0.5016666666666667, 1.0, 1.0, 0.4835914624345591, 1.0, 0.5, 0.4835914624345591, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4876668250458882, 0.4876668250458882, 0.4995922509236329], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6965276], dtype=float32), 1.6556854]. 
=============================================
[2019-03-24 01:06:50,988] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.2318328e-16 1.0000000e+00 7.2651202e-24 2.3347391e-23 6.1085741e-28], sum to 1.0000
[2019-03-24 01:06:50,999] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8964
[2019-03-24 01:06:51,007] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.18333333333334, 23.0, 1.0, 2.0, 0.514671642145125, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8564093376113875, 6.911199999999999, 6.9112, 121.9260425228722, 1278951.485274782, 1278951.485274782, 257741.9654235601], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 742200.0000, 
sim time next is 742800.0000, 
raw observation next is [32.16666666666667, 23.0, 1.0, 2.0, 0.9431014324500478, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.397929660584504, 6.9112, 121.9239919809137, 1436299.348743183, 1187054.451160476, 231749.3693928587], 
processed observation next is [1.0, 0.6086956521739131, 0.7469135802469138, 0.23, 1.0, 1.0, 0.9322636100595808, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.048672966058450395, 0.0, 0.8094485147379183, 0.5129640531225654, 0.4239480182715986, 0.445671864217036], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.4766776], dtype=float32), -0.9255676]. 
=============================================
[2019-03-24 01:06:55,263] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.7021948e-19 1.0000000e+00 2.5705759e-30 1.7591469e-26 1.7687311e-31], sum to 1.0000
[2019-03-24 01:06:55,271] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3276
[2019-03-24 01:06:55,276] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.83333333333333, 40.33333333333334, 1.0, 2.0, 0.3928158625143366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 487587.4153472611, 487587.4153472606, 127630.8030431096], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 848400.0000, 
sim time next is 849000.0000, 
raw observation next is [28.61666666666667, 40.66666666666667, 1.0, 2.0, 0.3886469559690524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 483111.1005097752, 483111.1005097752, 127064.9745462146], 
processed observation next is [0.0, 0.8260869565217391, 0.6154320987654323, 0.40666666666666673, 1.0, 1.0, 0.27219875710601477, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17253967875349116, 0.17253967875349116, 0.2443557202811819], 
reward next is 0.7556, 
noisyNet noise sample is [array([1.3822807], dtype=float32), -1.1676424]. 
=============================================
[2019-03-24 01:06:55,294] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[75.406845]
 [75.406845]
 [75.406845]
 [75.406845]
 [75.406845]], R is [[75.40842438]
 [75.4088974 ]
 [75.40834045]
 [75.40679932]
 [75.40432739]].
[2019-03-24 01:06:55,758] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.8469784e-19 1.0000000e+00 2.2471653e-30 6.4311243e-29 2.3608812e-31], sum to 1.0000
[2019-03-24 01:06:55,767] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5807
[2019-03-24 01:06:55,779] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.43333333333334, 74.5, 1.0, 2.0, 0.2927424722341038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 375307.6200615665, 375307.6200615665, 114683.9360794238], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1119000.0000, 
sim time next is 1119600.0000, 
raw observation next is [19.3, 75.0, 1.0, 2.0, 0.2892488898256245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 371049.9269674128, 371049.9269674128, 114257.2517508903], 
processed observation next is [1.0, 1.0, 0.27037037037037037, 0.75, 1.0, 1.0, 0.15386772598288634, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1325178310597903, 0.1325178310597903, 0.2197254841363275], 
reward next is 0.7803, 
noisyNet noise sample is [array([2.2694705], dtype=float32), -0.74897534]. 
=============================================
[2019-03-24 01:07:05,151] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7571161e-17 1.0000000e+00 1.2429238e-26 1.0857384e-22 4.7000032e-27], sum to 1.0000
[2019-03-24 01:07:05,162] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2289
[2019-03-24 01:07:05,166] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.28333333333333, 53.33333333333334, 1.0, 2.0, 0.6968560615823733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 870666.5200076648, 870666.5200076643, 178431.6215826819], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 996600.0000, 
sim time next is 997200.0000, 
raw observation next is [25.3, 53.0, 1.0, 2.0, 0.7480375515767499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 935030.0220709128, 935030.0220709128, 188599.0079201574], 
processed observation next is [1.0, 0.5652173913043478, 0.49259259259259264, 0.53, 1.0, 1.0, 0.7000447042580356, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.33393929359675456, 0.33393929359675456, 0.3626903998464565], 
reward next is 0.6373, 
noisyNet noise sample is [array([2.7050827], dtype=float32), 0.29534602]. 
=============================================
[2019-03-24 01:07:13,084] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1980623e-16 1.0000000e+00 7.8432057e-28 1.3450866e-24 1.7347343e-29], sum to 1.0000
[2019-03-24 01:07:13,093] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7031
[2019-03-24 01:07:13,099] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.95, 26.66666666666666, 1.0, 2.0, 0.3763876562115646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 471808.0741199724, 471808.0741199724, 125448.4366130766], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1450200.0000, 
sim time next is 1450800.0000, 
raw observation next is [31.8, 27.0, 1.0, 2.0, 0.3750508425941144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 470268.3812071942, 470268.3812071938, 125267.7134060263], 
processed observation next is [0.0, 0.8260869565217391, 0.7333333333333334, 0.27, 1.0, 1.0, 0.2560129078501362, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16795299328828364, 0.1679529932882835, 0.2408994488577429], 
reward next is 0.7591, 
noisyNet noise sample is [array([0.02017697], dtype=float32), -1.0206739]. 
=============================================
[2019-03-24 01:07:13,304] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.4002510e-17 1.0000000e+00 2.3872841e-28 4.0002235e-27 8.1556347e-30], sum to 1.0000
[2019-03-24 01:07:13,313] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8353
[2019-03-24 01:07:13,317] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 65.0, 1.0, 2.0, 0.6814941947018979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 863278.7872275835, 863278.7872275835, 175652.5017574293], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1171800.0000, 
sim time next is 1172400.0000, 
raw observation next is [22.06666666666667, 65.0, 1.0, 2.0, 0.6366990245849542, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 805931.3262668117, 805931.3262668117, 167245.0667426792], 
processed observation next is [1.0, 0.5652173913043478, 0.3728395061728396, 0.65, 1.0, 1.0, 0.5674988387916121, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28783261652386133, 0.28783261652386133, 0.32162512835130613], 
reward next is 0.6784, 
noisyNet noise sample is [array([-0.64427435], dtype=float32), 0.16021498]. 
=============================================
[2019-03-24 01:07:31,207] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0815042e-17 1.0000000e+00 4.0101506e-29 1.0756286e-25 7.0484274e-30], sum to 1.0000
[2019-03-24 01:07:31,213] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8857
[2019-03-24 01:07:31,218] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [35.13333333333333, 24.66666666666667, 1.0, 2.0, 0.4151789534370213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 508747.9055829988, 508747.9055829988, 130637.071002131], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1521600.0000, 
sim time next is 1522200.0000, 
raw observation next is [34.96666666666667, 25.83333333333333, 1.0, 2.0, 0.4153908341900356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 507391.4184692099, 507391.4184692099, 130622.4885984796], 
processed observation next is [0.0, 0.6086956521739131, 0.8506172839506173, 0.2583333333333333, 1.0, 1.0, 0.30403670736909, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18121122088186067, 0.18121122088186067, 0.25119709345861463], 
reward next is 0.7488, 
noisyNet noise sample is [array([-1.0659133], dtype=float32), -0.13553187]. 
=============================================
[2019-03-24 01:07:35,070] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-24 01:07:35,072] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:07:35,074] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:07:35,074] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:07:35,075] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:07:35,075] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:07:35,076] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:07:35,076] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:07:35,077] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:07:35,078] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:07:35,079] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:07:35,102] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run96
[2019-03-24 01:07:35,102] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run96
[2019-03-24 01:07:35,149] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run96
[2019-03-24 01:07:35,172] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run96
[2019-03-24 01:07:35,173] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run96
[2019-03-24 01:07:36,147] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), -0.0022699009]
[2019-03-24 01:07:36,147] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.33333333333334, 53.0, 1.0, 2.0, 0.2402630521249172, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 309916.1280571762, 309916.1280571762, 92239.11356440133]
[2019-03-24 01:07:36,147] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:07:36,149] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.0906613e-17 1.0000000e+00 9.1740841e-27 1.1166357e-24 8.2192599e-29], sampled 0.6463718242856099
[2019-03-24 01:08:25,727] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), -0.0022699009]
[2019-03-24 01:08:25,728] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.5, 94.5, 1.0, 2.0, 0.5659090101261438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 659498.7813577587, 659498.7813577587, 153000.1087357659]
[2019-03-24 01:08:25,730] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:08:25,733] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.0906613e-17 1.0000000e+00 9.1740841e-27 1.1166357e-24 8.2192599e-29], sampled 0.28914603755588364
[2019-03-24 01:09:23,158] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), -0.0022699009]
[2019-03-24 01:09:23,159] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.13333333333333, 77.33333333333334, 1.0, 2.0, 0.3952941878584227, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 489787.4156123683, 489787.4156123683, 127958.2509225945]
[2019-03-24 01:09:23,161] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:09:23,165] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.0906613e-17 1.0000000e+00 9.1740841e-27 1.1166357e-24 8.2192599e-29], sampled 0.6980995938569924
[2019-03-24 01:09:24,202] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 01:09:24,258] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 01:09:24,298] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 01:09:24,433] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 01:09:24,465] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 01:09:25,479] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 2375000, evaluation results [2375000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 01:09:25,545] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.2875714e-19 1.0000000e+00 6.7751266e-29 6.9913198e-27 5.5734019e-31], sum to 1.0000
[2019-03-24 01:09:25,551] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8675
[2019-03-24 01:09:25,557] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.23333333333333, 78.0, 1.0, 2.0, 0.5941649780902696, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 743155.8489745704, 743155.8489745704, 159469.445173774], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1564800.0000, 
sim time next is 1565400.0000, 
raw observation next is [21.11666666666667, 78.5, 1.0, 2.0, 0.557758284804295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 698134.4300288918, 698134.4300288918, 153200.4713410867], 
processed observation next is [1.0, 0.08695652173913043, 0.33765432098765447, 0.785, 1.0, 1.0, 0.4735217676241607, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2493337250103185, 0.2493337250103185, 0.2946162910405513], 
reward next is 0.7054, 
noisyNet noise sample is [array([1.5368052], dtype=float32), 1.4978317]. 
=============================================
[2019-03-24 01:09:26,536] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.3171439e-16 1.0000000e+00 6.4647791e-27 7.8595405e-25 2.1865133e-27], sum to 1.0000
[2019-03-24 01:09:26,538] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9913
[2019-03-24 01:09:26,542] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.05, 45.5, 1.0, 2.0, 0.8724168729979053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260380611853, 1088209.046584792, 1088209.046584792, 215182.8736872958], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1603800.0000, 
sim time next is 1604400.0000, 
raw observation next is [27.13333333333333, 45.0, 1.0, 2.0, 0.9001811781015595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.053339004701847, 6.9112, 121.9254311302702, 1195902.745423373, 1123115.235822832, 221506.766881526], 
processed observation next is [1.0, 0.5652173913043478, 0.5604938271604937, 0.45, 1.0, 1.0, 0.8811680691685232, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.014213900470184716, 0.0, 0.8094580691930356, 0.42710812336549037, 0.40111258422244, 0.42597455169524234], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0257295], dtype=float32), -1.0713499]. 
=============================================
[2019-03-24 01:09:33,238] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.8950678e-18 1.0000000e+00 3.2240942e-27 2.5594962e-25 6.2295238e-30], sum to 1.0000
[2019-03-24 01:09:33,248] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8028
[2019-03-24 01:09:33,252] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333333, 80.66666666666667, 1.0, 2.0, 0.3790934535925704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 471938.9603949608, 471938.9603949604, 125760.1662097239], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1730400.0000, 
sim time next is 1731000.0000, 
raw observation next is [21.31666666666667, 80.83333333333333, 1.0, 2.0, 0.3787889983034531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 471526.4231619025, 471526.4231619025, 125717.7013505005], 
processed observation next is [1.0, 0.0, 0.34506172839506183, 0.8083333333333332, 1.0, 1.0, 0.26046309321839656, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16840229398639375, 0.16840229398639375, 0.24176481028942404], 
reward next is 0.7582, 
noisyNet noise sample is [array([-0.3242266], dtype=float32), -0.21399598]. 
=============================================
[2019-03-24 01:09:33,268] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[74.06613]
 [74.06613]
 [74.06613]
 [74.06613]
 [74.06613]], R is [[74.08370209]
 [74.10102081]
 [74.11804199]
 [74.13484192]
 [74.15157318]].
[2019-03-24 01:09:39,062] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.4692751e-16 1.0000000e+00 1.9863305e-26 2.3232580e-25 5.2160358e-29], sum to 1.0000
[2019-03-24 01:09:39,069] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1638
[2019-03-24 01:09:39,073] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.23333333333333, 92.0, 1.0, 2.0, 0.3725530434016894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 473362.1189830338, 473362.1189830338, 124999.8686884168], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1822200.0000, 
sim time next is 1822800.0000, 
raw observation next is [18.26666666666667, 92.0, 1.0, 2.0, 0.3408447097305241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 432897.3540817468, 432897.3540817468, 120760.8380247495], 
processed observation next is [1.0, 0.08695652173913043, 0.23209876543209887, 0.92, 1.0, 1.0, 0.2152913211077668, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15460619788633814, 0.15460619788633814, 0.23223238081682596], 
reward next is 0.7678, 
noisyNet noise sample is [array([-0.5822308], dtype=float32), -0.47596094]. 
=============================================
[2019-03-24 01:09:40,345] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.5374926e-15 1.0000000e+00 4.8346450e-26 1.1221105e-23 4.2367308e-27], sum to 1.0000
[2019-03-24 01:09:40,353] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4413
[2019-03-24 01:09:40,357] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.9, 91.66666666666666, 1.0, 2.0, 0.42340049099718, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 520004.9313856516, 520004.9313856516, 131852.0258825016], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1896000.0000, 
sim time next is 1896600.0000, 
raw observation next is [20.9, 91.83333333333333, 1.0, 2.0, 0.4216619803202408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 517713.452597391, 517713.452597391, 131596.4975930057], 
processed observation next is [1.0, 0.9565217391304348, 0.32962962962962955, 0.9183333333333333, 1.0, 1.0, 0.3115023575240962, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18489766164192534, 0.18489766164192534, 0.25307018767885714], 
reward next is 0.7469, 
noisyNet noise sample is [array([-1.1330608], dtype=float32), -0.39072904]. 
=============================================
[2019-03-24 01:09:43,628] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.8494949e-19 1.0000000e+00 1.2839429e-29 2.0361894e-27 1.1525747e-30], sum to 1.0000
[2019-03-24 01:09:43,635] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5703
[2019-03-24 01:09:43,642] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.06666666666667, 92.0, 1.0, 2.0, 0.3868195387417978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 480389.1251618484, 480389.1251618484, 126801.8812157684], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1903800.0000, 
sim time next is 1904400.0000, 
raw observation next is [20.0, 92.0, 1.0, 2.0, 0.38422171268601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 477601.3701964495, 477601.3701964495, 126451.6807122734], 
processed observation next is [1.0, 0.043478260869565216, 0.2962962962962963, 0.92, 1.0, 1.0, 0.26693061034048815, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1705719179273034, 0.1705719179273034, 0.24317630906206422], 
reward next is 0.7568, 
noisyNet noise sample is [array([1.3625598], dtype=float32), 0.27667105]. 
=============================================
[2019-03-24 01:09:44,094] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3326862e-16 1.0000000e+00 2.8980867e-26 8.7667185e-24 9.4910345e-29], sum to 1.0000
[2019-03-24 01:09:44,100] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0136
[2019-03-24 01:09:44,105] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.2, 89.0, 1.0, 2.0, 0.7446309474979087, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 914409.6628033674, 914409.6628033664, 187506.2372589713], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1933200.0000, 
sim time next is 1933800.0000, 
raw observation next is [21.31666666666667, 88.66666666666667, 1.0, 2.0, 0.775692770434059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 951376.5266671799, 951376.5266671799, 193823.7292652405], 
processed observation next is [1.0, 0.391304347826087, 0.34506172839506183, 0.8866666666666667, 1.0, 1.0, 0.7329675838500703, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.33977733095256424, 0.33977733095256424, 0.37273794089469325], 
reward next is 0.6273, 
noisyNet noise sample is [array([-0.20402528], dtype=float32), 2.3211815]. 
=============================================
[2019-03-24 01:09:52,989] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.4958977e-16 1.0000000e+00 7.2618714e-26 1.6791750e-23 4.9506661e-29], sum to 1.0000
[2019-03-24 01:09:52,991] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9867
[2019-03-24 01:09:52,999] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.6, 77.0, 1.0, 2.0, 0.5398349738647489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 633485.9029488236, 633485.9029488236, 148881.8168247118], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2109600.0000, 
sim time next is 2110200.0000, 
raw observation next is [25.83333333333334, 76.16666666666667, 1.0, 2.0, 0.5447324819581881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 637897.5769164736, 637897.5769164736, 149626.9681292682], 
processed observation next is [0.0, 0.43478260869565216, 0.5123456790123458, 0.7616666666666667, 1.0, 1.0, 0.4580148594740335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22782056318445484, 0.22782056318445484, 0.28774416947936193], 
reward next is 0.7123, 
noisyNet noise sample is [array([-0.00244381], dtype=float32), -0.6568406]. 
=============================================
[2019-03-24 01:09:59,015] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.5564901e-13 1.0000000e+00 8.5844475e-22 1.5258564e-19 1.1044736e-23], sum to 1.0000
[2019-03-24 01:09:59,023] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5760
[2019-03-24 01:09:59,028] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.05, 93.5, 1.0, 2.0, 0.5645650060233136, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8988058761877261, 6.911200000000001, 6.9112, 121.9260426155193, 1287299.635121173, 1287299.635121172, 280325.3629644639], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2219400.0000, 
sim time next is 2220000.0000, 
raw observation next is [23.83333333333333, 94.33333333333334, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 8.062581312494622, 6.9112, 121.9214409058082, 1764675.957323783, 1175088.06898805, 246261.9140431498], 
processed observation next is [1.0, 0.6956521739130435, 0.43827160493827144, 0.9433333333333335, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.11513813124946219, 0.0, 0.809431578252149, 0.6302414133299226, 0.41967431035287506, 0.4735806039291342], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.05452814], dtype=float32), -0.86619115]. 
=============================================
[2019-03-24 01:09:59,045] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[56.054485]
 [56.054485]
 [56.054485]
 [56.054485]
 [56.054485]], R is [[55.49394226]
 [55.3999176 ]
 [55.2792778 ]
 [54.72648621]
 [54.17922211]].
[2019-03-24 01:09:59,605] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5068211e-14 1.0000000e+00 1.9585768e-23 8.3091950e-23 3.6063989e-25], sum to 1.0000
[2019-03-24 01:09:59,615] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9381
[2019-03-24 01:09:59,621] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 95.66666666666667, 1.0, 2.0, 0.5355844393508734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 632312.6618941576, 632312.6618941572, 148346.0603482004], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2238000.0000, 
sim time next is 2238600.0000, 
raw observation next is [22.7, 95.83333333333333, 1.0, 2.0, 0.536546633640909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 633195.4509085536, 633195.4509085536, 148492.6259046195], 
processed observation next is [1.0, 0.9130434782608695, 0.39629629629629626, 0.9583333333333333, 1.0, 1.0, 0.4482698019534631, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22614123246734055, 0.22614123246734055, 0.28556274212426824], 
reward next is 0.7144, 
noisyNet noise sample is [array([-1.3195263], dtype=float32), -0.7827018]. 
=============================================
[2019-03-24 01:10:09,172] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3909328e-16 1.0000000e+00 8.8086027e-28 1.3486156e-25 4.0550824e-30], sum to 1.0000
[2019-03-24 01:10:09,181] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7817
[2019-03-24 01:10:09,186] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 49.0, 1.0, 2.0, 0.3854484863058197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 478805.5961316593, 478805.5961316593, 126614.6212483078], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2407200.0000, 
sim time next is 2407800.0000, 
raw observation next is [26.61666666666667, 50.0, 1.0, 2.0, 0.3856761159012064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 479106.5701891862, 479106.5701891862, 126646.5045917329], 
processed observation next is [1.0, 0.8695652173913043, 0.5413580246913582, 0.5, 1.0, 1.0, 0.2686620427395314, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1711094893532808, 0.1711094893532808, 0.24355097036871712], 
reward next is 0.7564, 
noisyNet noise sample is [array([0.6210759], dtype=float32), -0.75701404]. 
=============================================
[2019-03-24 01:10:10,834] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.1459560e-17 1.0000000e+00 1.3166458e-26 3.5177788e-26 1.1588892e-28], sum to 1.0000
[2019-03-24 01:10:10,841] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8200
[2019-03-24 01:10:10,844] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.3, 42.0, 1.0, 2.0, 0.4603023977506367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 572696.1778646032, 572696.1778646028, 137488.972846486], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2448000.0000, 
sim time next is 2448600.0000, 
raw observation next is [28.55, 40.83333333333334, 1.0, 2.0, 0.690414133870927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 858567.6507586589, 858567.6507586589, 177101.1202064626], 
processed observation next is [1.0, 0.34782608695652173, 0.612962962962963, 0.40833333333333344, 1.0, 1.0, 0.6314453974653893, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3066313038423782, 0.3066313038423782, 0.3405790773201204], 
reward next is 0.6594, 
noisyNet noise sample is [array([-1.2361041], dtype=float32), 0.33760646]. 
=============================================
[2019-03-24 01:10:11,015] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.2306681e-16 1.0000000e+00 1.2894864e-26 1.2873735e-25 2.3520562e-29], sum to 1.0000
[2019-03-24 01:10:11,020] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9289
[2019-03-24 01:10:11,025] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.4, 25.66666666666667, 1.0, 2.0, 0.3514089057461183, 1.0, 2.0, 0.3514089057461183, 1.0, 2.0, 0.571534884627151, 6.9112, 6.9112, 121.94756008, 1279641.212627853, 1279641.212627853, 275520.7261792365], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2457600.0000, 
sim time next is 2458200.0000, 
raw observation next is [32.65, 24.83333333333333, 1.0, 2.0, 0.9656706206585516, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.467543147877138, 6.9112, 121.9237205745606, 1484863.307217491, 1199971.315895048, 236831.3380996644], 
processed observation next is [1.0, 0.43478260869565216, 0.7648148148148147, 0.2483333333333333, 1.0, 1.0, 0.9591316912601805, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.055634314787713815, 0.0, 0.8094467128819766, 0.5303083240062468, 0.4285611842482314, 0.4554448809608931], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.3285513], dtype=float32), 0.13874963]. 
=============================================
[2019-03-24 01:10:14,310] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-24 01:10:14,313] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:10:14,316] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:10:14,316] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:10:14,318] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:10:14,320] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:10:14,320] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:10:14,321] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:10:14,323] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:10:14,323] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:10:14,325] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:10:14,343] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run97
[2019-03-24 01:10:14,344] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run97
[2019-03-24 01:10:14,403] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run97
[2019-03-24 01:10:14,427] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run97
[2019-03-24 01:10:14,427] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run97
[2019-03-24 01:10:19,174] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0070870887]
[2019-03-24 01:10:19,177] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.48549978333333, 44.102560235, 1.0, 2.0, 0.2564623992657825, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 330816.2275296233, 330816.2275296233, 92683.23585429564]
[2019-03-24 01:10:19,179] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:10:19,185] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.7793570e-17 1.0000000e+00 9.6921625e-28 1.1571019e-25 6.9141028e-30], sampled 0.7817183691519849
[2019-03-24 01:10:22,095] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0070870887]
[2019-03-24 01:10:22,096] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [32.70081816333333, 26.37266636666667, 1.0, 2.0, 0.8889614767343349, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9258759479374, 1096272.8962957, 1096272.896295699, 218607.1592590269]
[2019-03-24 01:10:22,096] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:10:22,099] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.7793570e-17 1.0000000e+00 9.6921625e-28 1.1571019e-25 6.9141028e-30], sampled 0.4042453340966532
[2019-03-24 01:10:49,477] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0070870887]
[2019-03-24 01:10:49,478] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.5, 60.0, 1.0, 2.0, 0.5033291480889426, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 600156.3929406203, 600156.3929406203, 143412.6350567758]
[2019-03-24 01:10:49,479] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:10:49,482] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.7793570e-17 1.0000000e+00 9.6921625e-28 1.1571019e-25 6.9141028e-30], sampled 0.06259172930626578
[2019-03-24 01:10:49,523] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0070870887]
[2019-03-24 01:10:49,524] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.0, 66.0, 1.0, 2.0, 0.6234055890424716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 710465.5609639862, 710465.5609639862, 162150.1425516844]
[2019-03-24 01:10:49,526] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:10:49,529] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.7793570e-17 1.0000000e+00 9.6921625e-28 1.1571019e-25 6.9141028e-30], sampled 0.7394899593484505
[2019-03-24 01:10:56,514] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0070870887]
[2019-03-24 01:10:56,516] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.33333333333333, 87.33333333333334, 1.0, 2.0, 0.6965778471637474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 793899.6714965801, 793899.6714965801, 175496.7159459192]
[2019-03-24 01:10:56,517] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:10:56,521] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.7793570e-17 1.0000000e+00 9.6921625e-28 1.1571019e-25 6.9141028e-30], sampled 0.5275705891918083
[2019-03-24 01:10:56,602] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0070870887]
[2019-03-24 01:10:56,604] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.05186642, 85.40058217666667, 1.0, 2.0, 0.5408184767936235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 636714.050580291, 636714.050580291, 149127.9096431395]
[2019-03-24 01:10:56,605] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:10:56,608] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.7793570e-17 1.0000000e+00 9.6921625e-28 1.1571019e-25 6.9141028e-30], sampled 0.18632612594085685
[2019-03-24 01:11:04,953] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0070870887]
[2019-03-24 01:11:04,954] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.2, 97.00000000000001, 1.0, 2.0, 0.5757428209664037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 669902.4003198837, 669902.4003198837, 154607.6809899292]
[2019-03-24 01:11:04,957] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:11:04,959] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.7793570e-17 1.0000000e+00 9.6921625e-28 1.1571019e-25 6.9141028e-30], sampled 0.35076505536169267
[2019-03-24 01:11:48,321] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0070870887]
[2019-03-24 01:11:48,323] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.0, 91.5, 1.0, 2.0, 0.4961829196308246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 588938.408154194, 588938.408154194, 142189.1616740044]
[2019-03-24 01:11:48,324] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:11:48,327] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.7793570e-17 1.0000000e+00 9.6921625e-28 1.1571019e-25 6.9141028e-30], sampled 0.31954663512349546
[2019-03-24 01:11:52,765] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.0070870887]
[2019-03-24 01:11:52,767] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.0, 94.0, 1.0, 2.0, 0.842430391365667, 1.0, 2.0, 0.842430391365667, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1921611.827444436, 1921611.827444436, 361599.8212250866]
[2019-03-24 01:11:52,770] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:11:52,774] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.7793570e-17 1.0000000e+00 9.6921625e-28 1.1571019e-25 6.9141028e-30], sampled 0.8086969238379663
[2019-03-24 01:11:52,776] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1921611.827444436 W.
[2019-03-24 01:12:03,550] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 01:12:03,592] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 01:12:03,700] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 01:12:03,726] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 01:12:03,943] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 01:12:04,960] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 2400000, evaluation results [2400000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 01:12:06,325] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.1603517e-17 1.0000000e+00 1.6213689e-26 3.3295022e-24 7.1408022e-28], sum to 1.0000
[2019-03-24 01:12:06,336] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5183
[2019-03-24 01:12:06,339] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.2, 30.0, 1.0, 2.0, 0.5237128524529298, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8467018400081955, 6.911199999999999, 6.9112, 121.9260426156618, 1260004.384863258, 1260004.384863259, 263479.1625944926], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2552400.0000, 
sim time next is 2553000.0000, 
raw observation next is [33.3, 30.0, 1.0, 2.0, 1.00220277666642, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.572155830971729, 6.9112, 121.9233272655128, 1557843.232353003, 1219382.309185019, 244953.6227430065], 
processed observation next is [1.0, 0.5652173913043478, 0.7888888888888888, 0.3, 1.0, 1.0, 1.0026223531743097, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.06609558309717292, 0.0, 0.8094441017189117, 0.5563725829832153, 0.4354936818517925, 0.47106465912116635], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3505617], dtype=float32), -0.1583368]. 
=============================================
[2019-03-24 01:12:06,356] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[67.24154]
 [67.24154]
 [67.24154]
 [67.24154]
 [67.24154]], R is [[66.56911469]
 [65.90342712]
 [65.74539948]
 [65.53668213]
 [64.88131714]].
[2019-03-24 01:12:08,663] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.4687311e-16 1.0000000e+00 8.1550912e-26 2.4765708e-24 3.8804049e-27], sum to 1.0000
[2019-03-24 01:12:08,672] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8720
[2019-03-24 01:12:08,682] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 93.16666666666666, 1.0, 2.0, 0.6310695122901797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 719917.3731354604, 719917.37313546, 163539.7570680994], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3030600.0000, 
sim time next is 3031200.0000, 
raw observation next is [24.8, 93.0, 1.0, 2.0, 0.6381245300490638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 727247.9918057821, 727247.9918057821, 164759.5367154349], 
processed observation next is [1.0, 0.08695652173913043, 0.4740740740740741, 0.93, 1.0, 1.0, 0.5691958691060283, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2597314256449222, 0.2597314256449222, 0.3168452629142979], 
reward next is 0.6832, 
noisyNet noise sample is [array([1.1361806], dtype=float32), 0.4303198]. 
=============================================
[2019-03-24 01:12:19,820] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.3611477e-16 1.0000000e+00 1.0964221e-23 1.5024428e-24 7.4459125e-27], sum to 1.0000
[2019-03-24 01:12:19,828] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5081
[2019-03-24 01:12:19,832] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.63333333333333, 86.0, 1.0, 2.0, 0.8173493832401187, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 932315.0957575438, 932315.0957575433, 199581.561170921], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2791200.0000, 
sim time next is 2791800.0000, 
raw observation next is [25.95, 84.5, 1.0, 2.0, 0.8691133478080072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 990667.927357428, 990667.927357428, 210627.3159220024], 
processed observation next is [1.0, 0.30434782608695654, 0.5166666666666666, 0.845, 1.0, 1.0, 0.8441825569142942, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3538099740562243, 0.3538099740562243, 0.40505253061923535], 
reward next is 0.5949, 
noisyNet noise sample is [array([-1.8655154], dtype=float32), 0.22872604]. 
=============================================
[2019-03-24 01:12:24,469] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.5158033e-15 1.0000000e+00 1.1175603e-24 5.7469672e-23 1.9102644e-26], sum to 1.0000
[2019-03-24 01:12:24,478] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2261
[2019-03-24 01:12:24,487] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1402741.701963573 W.
[2019-03-24 01:12:24,492] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.86666666666667, 87.33333333333334, 1.0, 2.0, 0.4100984507819262, 1.0, 2.0, 0.4100984507819262, 1.0, 1.0, 0.6528900896189395, 6.9112, 6.9112, 121.94756008, 1402741.701963573, 1402741.701963573, 301534.068709204], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2889600.0000, 
sim time next is 2890200.0000, 
raw observation next is [24.08333333333333, 85.66666666666666, 1.0, 2.0, 0.6145731094380734, 1.0, 2.0, 0.6145731094380734, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1411273.28564069, 1411273.285640691, 273577.8622685114], 
processed observation next is [1.0, 0.43478260869565216, 0.4475308641975307, 0.8566666666666666, 1.0, 1.0, 0.541158463616754, 1.0, 1.0, 0.541158463616754, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5040261734431035, 0.5040261734431039, 0.5261112735932911], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.0524651], dtype=float32), 1.0743974]. 
=============================================
[2019-03-24 01:12:27,111] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.2988936e-15 1.0000000e+00 5.1256900e-24 4.9315684e-23 1.4570279e-25], sum to 1.0000
[2019-03-24 01:12:27,131] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1429
[2019-03-24 01:12:27,144] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.9, 92.66666666666667, 1.0, 2.0, 0.7136778445344939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 813399.1226279062, 813399.1226279062, 178745.2402023711], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2953200.0000, 
sim time next is 2953800.0000, 
raw observation next is [24.85, 92.0, 1.0, 2.0, 0.6997706691639249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 797540.4692784223, 797540.4692784223, 176095.9878502875], 
processed observation next is [1.0, 0.17391304347826086, 0.475925925925926, 0.92, 1.0, 1.0, 0.6425841299570535, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2848358818851508, 0.2848358818851508, 0.3386461304813221], 
reward next is 0.6614, 
noisyNet noise sample is [array([0.17255235], dtype=float32), 2.1834252]. 
=============================================
[2019-03-24 01:12:32,225] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.9554732e-15 1.0000000e+00 9.1886943e-26 1.5129635e-22 2.1256375e-27], sum to 1.0000
[2019-03-24 01:12:32,233] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7470
[2019-03-24 01:12:32,238] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 96.0, 1.0, 2.0, 0.593603293646465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 686502.2740586746, 686502.2740586746, 157464.0472233082], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3026400.0000, 
sim time next is 3027000.0000, 
raw observation next is [23.83333333333333, 95.0, 1.0, 2.0, 0.5964517778516069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 689189.4835624424, 689189.4835624424, 157925.7887806739], 
processed observation next is [1.0, 0.0, 0.43827160493827144, 0.95, 1.0, 1.0, 0.5195854498233414, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24613910127230085, 0.24613910127230085, 0.30370343996283444], 
reward next is 0.6963, 
noisyNet noise sample is [array([-0.6513057], dtype=float32), -1.224856]. 
=============================================
[2019-03-24 01:12:32,253] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[68.176384]
 [68.176384]
 [68.176384]
 [68.176384]
 [68.176384]], R is [[68.19091797]
 [68.20619202]
 [68.2219696 ]
 [68.23822784]
 [68.25495911]].
[2019-03-24 01:12:36,089] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.3108981e-17 1.0000000e+00 1.4071061e-27 1.2781461e-23 2.2140845e-28], sum to 1.0000
[2019-03-24 01:12:36,104] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1080
[2019-03-24 01:12:36,108] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 91.0, 1.0, 2.0, 0.6528926096285191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 753492.5181797235, 753492.5181797231, 167879.703057833], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3394800.0000, 
sim time next is 3395400.0000, 
raw observation next is [24.63333333333333, 89.66666666666667, 1.0, 2.0, 0.7248771806136974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 835642.9057788991, 835642.9057788991, 181383.4263988528], 
processed observation next is [1.0, 0.30434782608695654, 0.46790123456790106, 0.8966666666666667, 1.0, 1.0, 0.6724728340639256, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2984438949210354, 0.2984438949210354, 0.34881428153625543], 
reward next is 0.6512, 
noisyNet noise sample is [array([-0.19262382], dtype=float32), 0.65024054]. 
=============================================
[2019-03-24 01:12:42,701] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.1154412e-16 1.0000000e+00 1.0504792e-25 3.6435169e-23 3.3790906e-28], sum to 1.0000
[2019-03-24 01:12:42,709] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9707
[2019-03-24 01:12:42,717] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 49.0, 1.0, 2.0, 0.5663411452420506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 662021.3457446035, 662021.3457446035, 153160.3021056365], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3261600.0000, 
sim time next is 3262200.0000, 
raw observation next is [30.56666666666667, 51.0, 1.0, 2.0, 0.5622422927515968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 657859.371571572, 657859.371571572, 152501.9857479914], 
processed observation next is [0.0, 0.782608695652174, 0.6876543209876544, 0.51, 1.0, 1.0, 0.47885987232332944, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23494977556127572, 0.23494977556127572, 0.29327304951536803], 
reward next is 0.7067, 
noisyNet noise sample is [array([0.16588968], dtype=float32), -1.2743207]. 
=============================================
[2019-03-24 01:12:46,948] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.8505339e-16 1.0000000e+00 3.4364881e-25 8.2260246e-24 8.2279531e-28], sum to 1.0000
[2019-03-24 01:12:46,962] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7292
[2019-03-24 01:12:46,971] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 100.0, 1.0, 2.0, 0.5337970848405502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 632303.5394192906, 632303.5394192906, 148138.756846108], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3307800.0000, 
sim time next is 3308400.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.5328915986284524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 631231.9948262519, 631231.9948262523, 147991.5395017288], 
processed observation next is [0.0, 0.30434782608695654, 0.37037037037037035, 1.0, 1.0, 1.0, 0.4439185697957766, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2254399981522328, 0.22543999815223298, 0.28459911442640157], 
reward next is 0.7154, 
noisyNet noise sample is [array([-1.0216899], dtype=float32), -0.44977704]. 
=============================================
[2019-03-24 01:12:51,949] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0614503e-13 1.0000000e+00 1.4507962e-22 4.5026523e-20 1.5693895e-24], sum to 1.0000
[2019-03-24 01:12:51,956] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4223
[2019-03-24 01:12:51,971] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1419541.242806919 W.
[2019-03-24 01:12:51,976] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.0, 59.0, 1.0, 2.0, 0.622507897329613, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9910528462155815, 6.911199999999999, 6.9112, 121.9260426156618, 1419541.242806919, 1419541.242806919, 302720.6820995535], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3414600.0000, 
sim time next is 3415200.0000, 
raw observation next is [31.0, 59.0, 1.0, 2.0, 0.4274704255074634, 1.0, 1.0, 0.4274704255074634, 1.0, 2.0, 0.6805468391477133, 6.9112, 6.9112, 121.94756008, 1462219.255072237, 1462219.255072237, 309324.6997942049], 
processed observation next is [1.0, 0.5217391304347826, 0.7037037037037037, 0.59, 1.0, 1.0, 0.3184171732231707, 1.0, 0.5, 0.3184171732231707, 1.0, 1.0, 0.6006835489346416, 0.0, 0.0, 0.8096049824067558, 0.522221162525799, 0.522221162525799, 0.5948551919119325], 
reward next is 0.4051, 
noisyNet noise sample is [array([1.1665311], dtype=float32), -2.4154232]. 
=============================================
[2019-03-24 01:12:53,977] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-24 01:12:53,982] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:12:53,983] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:12:53,983] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:12:53,983] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:12:53,984] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:12:53,985] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:12:53,987] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:12:53,986] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:12:53,988] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:12:53,988] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:12:54,010] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run98
[2019-03-24 01:12:54,036] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run98
[2019-03-24 01:12:54,075] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run98
[2019-03-24 01:12:54,113] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run98
[2019-03-24 01:12:54,114] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run98
[2019-03-24 01:12:56,376] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), -0.00852775]
[2019-03-24 01:12:56,377] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [19.0, 49.0, 1.0, 2.0, 0.2369899672769085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 305693.3234016882, 305693.3234016882, 84442.5776811339]
[2019-03-24 01:12:56,379] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:12:56,381] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.3184274e-15 1.0000000e+00 5.5451715e-25 3.9920303e-23 5.3691079e-27], sampled 0.3604891640214728
[2019-03-24 01:13:04,472] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), -0.00852775]
[2019-03-24 01:13:04,473] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.70501333, 11.69525558, 1.0, 2.0, 0.3451349555950667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 445217.2461919568, 445217.2461919563, 106218.4689081665]
[2019-03-24 01:13:04,474] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:13:04,477] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.3184274e-15 1.0000000e+00 5.5451715e-25 3.9920303e-23 5.3691079e-27], sampled 0.6303255830240531
[2019-03-24 01:13:21,340] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), -0.00852775]
[2019-03-24 01:13:21,341] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [18.73333333333333, 95.33333333333333, 1.0, 2.0, 0.3488720866674274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 438844.3730640692, 438844.3730640687, 121770.7700664825]
[2019-03-24 01:13:21,342] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:13:21,344] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.3184274e-15 1.0000000e+00 5.5451715e-25 3.9920303e-23 5.3691079e-27], sampled 0.8561708270788596
[2019-03-24 01:13:36,311] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), -0.00852775]
[2019-03-24 01:13:36,312] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.93333333333333, 70.0, 1.0, 2.0, 0.7191443104984475, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 819632.742024597, 819632.742024597, 179803.1506309699]
[2019-03-24 01:13:36,315] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:13:36,317] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.3184274e-15 1.0000000e+00 5.5451715e-25 3.9920303e-23 5.3691079e-27], sampled 0.6812699377478487
[2019-03-24 01:13:53,807] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), -0.00852775]
[2019-03-24 01:13:53,809] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [33.16666666666666, 73.66666666666666, 1.0, 2.0, 1.02, 1.0, 2.0, 0.8256556417198966, 1.0, 2.0, 0.9977734948820727, 6.921101310578614, 6.9112, 125.7216191019374, 2826317.202432999, 2821089.005484866, 527954.179435332]
[2019-03-24 01:13:53,810] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:13:53,813] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.3184274e-15 1.0000000e+00 5.5451715e-25 3.9920303e-23 5.3691079e-27], sampled 0.7900161480408481
[2019-03-24 01:13:53,814] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 0, 1] for the demand 2826317.202432999 W.
[2019-03-24 01:14:42,136] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 01:14:42,514] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 01:14:42,548] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 01:14:42,621] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 01:14:42,638] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 01:14:43,654] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 2425000, evaluation results [2425000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 01:14:45,134] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.2880402e-14 1.0000000e+00 7.1080482e-22 9.1964278e-22 6.5664910e-25], sum to 1.0000
[2019-03-24 01:14:45,141] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3483
[2019-03-24 01:14:45,147] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 100.0, 1.0, 2.0, 0.7164636182076453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 816575.8401431678, 816575.8401431678, 179279.9595190924], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3469800.0000, 
sim time next is 3470400.0000, 
raw observation next is [24.0, 100.0, 1.0, 2.0, 0.7207777460464513, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 821495.4206475157, 821495.4206475157, 180110.4614391861], 
processed observation next is [1.0, 0.17391304347826086, 0.4444444444444444, 1.0, 1.0, 1.0, 0.6675925548172039, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.293391221659827, 0.293391221659827, 0.3463662719984348], 
reward next is 0.6536, 
noisyNet noise sample is [array([1.4932926], dtype=float32), -0.29125684]. 
=============================================
[2019-03-24 01:14:56,337] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.2464573e-14 1.0000000e+00 1.1633436e-23 3.1165635e-21 1.8479577e-25], sum to 1.0000
[2019-03-24 01:14:56,342] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3935
[2019-03-24 01:14:56,348] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.05, 94.0, 1.0, 2.0, 0.6664844235449651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 759584.7747520634, 759584.7747520634, 169895.0626634595], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3713400.0000, 
sim time next is 3714000.0000, 
raw observation next is [25.03333333333333, 94.0, 1.0, 2.0, 0.6649509708696879, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 757836.2521168177, 757836.2521168177, 169613.8347962969], 
processed observation next is [1.0, 1.0, 0.482716049382716, 0.94, 1.0, 1.0, 0.6011321081781998, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2706558043274349, 0.2706558043274349, 0.3261804515313402], 
reward next is 0.6738, 
noisyNet noise sample is [array([-0.6999033], dtype=float32), 1.4344342]. 
=============================================
[2019-03-24 01:14:56,366] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[58.077015]
 [58.077015]
 [58.077015]
 [58.077015]
 [58.077015]], R is [[58.17006683]
 [58.26164627]
 [58.35172272]
 [58.44035721]
 [58.52783203]].
[2019-03-24 01:14:59,559] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.4161018e-13 1.0000000e+00 9.9782498e-22 4.0049234e-21 5.0153809e-25], sum to 1.0000
[2019-03-24 01:14:59,565] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0106
[2019-03-24 01:14:59,567] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.33333333333334, 36.66666666666666, 1.0, 2.0, 0.4905181437172998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 583457.4554271629, 583457.4554271629, 141354.0956366586], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4214400.0000, 
sim time next is 4215000.0000, 
raw observation next is [33.16666666666666, 37.33333333333334, 1.0, 2.0, 0.4946604107319735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 588082.3560883298, 588082.3560883298, 141987.5280761316], 
processed observation next is [1.0, 0.782608695652174, 0.7839506172839502, 0.3733333333333334, 1.0, 1.0, 0.39840525087139705, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2100294128886892, 0.2100294128886892, 0.2730529386079454], 
reward next is 0.7269, 
noisyNet noise sample is [array([0.05963982], dtype=float32), -1.6599134]. 
=============================================
[2019-03-24 01:14:59,578] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[55.690517]
 [55.690517]
 [55.690517]
 [55.690517]
 [55.690517]], R is [[55.86056519]
 [56.03012466]
 [56.19895935]
 [56.36611176]
 [56.53061676]].
[2019-03-24 01:15:20,642] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.8712138e-17 1.0000000e+00 3.4306428e-27 1.4349704e-24 4.0309304e-30], sum to 1.0000
[2019-03-24 01:15:20,649] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4304
[2019-03-24 01:15:20,656] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.7, 97.0, 1.0, 2.0, 0.4438754586426082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 541472.8789749192, 541472.8789749197, 134751.6725356173], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4154400.0000, 
sim time next is 4155000.0000, 
raw observation next is [20.58333333333333, 97.5, 1.0, 2.0, 0.599814376827198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 732046.9172706469, 732046.9172706469, 160019.9919539138], 
processed observation next is [1.0, 0.08695652173913043, 0.31790123456790104, 0.975, 1.0, 1.0, 0.5235885438419023, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2614453275966596, 0.2614453275966596, 0.3077307537575265], 
reward next is 0.6923, 
noisyNet noise sample is [array([-0.61813116], dtype=float32), -0.7252503]. 
=============================================
[2019-03-24 01:15:20,674] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[72.57332]
 [72.57332]
 [72.57332]
 [72.57332]
 [72.57332]], R is [[72.53985596]
 [72.55532074]
 [72.57043457]
 [72.58541107]
 [72.60061646]].
[2019-03-24 01:15:28,058] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.1120302e-16 1.0000000e+00 2.8614085e-25 1.8153224e-24 1.3114113e-28], sum to 1.0000
[2019-03-24 01:15:28,067] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5763
[2019-03-24 01:15:28,072] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 84.0, 1.0, 2.0, 0.6300045789409109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 718459.6462351831, 718459.6462351831, 163338.9606112594], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4320000.0000, 
sim time next is 4320600.0000, 
raw observation next is [25.83333333333334, 83.83333333333333, 1.0, 2.0, 0.629039042969281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 718316.1266784486, 718316.1266784486, 163215.4566752736], 
processed observation next is [1.0, 0.0, 0.5123456790123458, 0.8383333333333333, 1.0, 1.0, 0.5583798130586679, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25654147381373166, 0.25654147381373166, 0.31387587822168], 
reward next is 0.6861, 
noisyNet noise sample is [array([-0.266268], dtype=float32), 1.2092603]. 
=============================================
[2019-03-24 01:15:31,642] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2081235e-14 1.0000000e+00 5.8124736e-22 3.7426805e-21 6.4957138e-24], sum to 1.0000
[2019-03-24 01:15:31,651] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4401
[2019-03-24 01:15:31,657] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1816864.557538882 W.
[2019-03-24 01:15:31,664] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.8, 70.33333333333334, 1.0, 2.0, 0.5310374804462312, 1.0, 2.0, 0.5310374804462312, 1.0, 1.0, 0.8454289635537334, 6.9112, 6.9112, 121.94756008, 1816864.557538882, 1816864.557538882, 359083.684325552], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4358400.0000, 
sim time next is 4359000.0000, 
raw observation next is [29.0, 68.16666666666666, 1.0, 2.0, 0.9399584691735745, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1786698.756673917, 1786698.756673917, 365734.5383160291], 
processed observation next is [1.0, 0.43478260869565216, 0.6296296296296297, 0.6816666666666665, 1.0, 1.0, 0.9285219871113982, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6381066988121132, 0.6381066988121132, 0.7033356506077483], 
reward next is 0.2967, 
noisyNet noise sample is [array([-1.5550216], dtype=float32), 0.9530431]. 
=============================================
[2019-03-24 01:15:31,676] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[57.49433]
 [57.49433]
 [57.49433]
 [57.49433]
 [57.49433]], R is [[57.21605301]
 [56.95335007]
 [56.6983757 ]
 [56.43854141]
 [56.20455551]].
[2019-03-24 01:15:32,337] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-24 01:15:32,339] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:15:32,341] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:15:32,341] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:15:32,344] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:15:32,346] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:15:32,347] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:15:32,347] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:15:32,348] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:15:32,349] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:15:32,349] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:15:32,373] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run99
[2019-03-24 01:15:32,396] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run99
[2019-03-24 01:15:32,420] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run99
[2019-03-24 01:15:32,446] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run99
[2019-03-24 01:15:32,473] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run99
[2019-03-24 01:15:45,334] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), -0.0255218]
[2019-03-24 01:15:45,336] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.7983079, 60.970403205, 1.0, 2.0, 0.3954927612725395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 489769.9885294613, 489769.9885294613, 127980.2971692563]
[2019-03-24 01:15:45,337] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:15:45,341] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.8497946e-14 1.0000000e+00 5.2354284e-23 2.7966657e-21 6.6825556e-25], sampled 0.1548792245234485
[2019-03-24 01:16:02,028] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), -0.0255218]
[2019-03-24 01:16:02,029] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.98715694333333, 99.36150405666666, 1.0, 2.0, 0.4522751167153743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 547399.5118914675, 547399.5118914675, 135871.2287454991]
[2019-03-24 01:16:02,030] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 01:16:02,033] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.8497946e-14 1.0000000e+00 5.2354284e-23 2.7966657e-21 6.6825556e-25], sampled 0.8108014004369761
[2019-03-24 01:16:13,909] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), -0.0255218]
[2019-03-24 01:16:13,910] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.28969183, 84.95003502, 1.0, 2.0, 0.4849761031062386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 579729.1473370116, 579729.1473370116, 140601.1669454984]
[2019-03-24 01:16:13,911] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 01:16:13,913] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.8497946e-14 1.0000000e+00 5.2354284e-23 2.7966657e-21 6.6825556e-25], sampled 0.5484395281315676
[2019-03-24 01:16:24,434] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), -0.0255218]
[2019-03-24 01:16:24,435] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.6, 77.33333333333333, 1.0, 2.0, 0.5650486849921743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 662472.8971404704, 662472.8971404704, 153028.3968125821]
[2019-03-24 01:16:24,436] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:16:24,439] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.8497946e-14 1.0000000e+00 5.2354284e-23 2.7966657e-21 6.6825556e-25], sampled 0.11660833620526168
[2019-03-24 01:16:35,661] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), -0.0255218]
[2019-03-24 01:16:35,662] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.95, 77.0, 1.0, 2.0, 0.5594963474057484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 651700.0124983424, 651700.0124983424, 151915.6659137891]
[2019-03-24 01:16:35,665] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:16:35,669] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.8497946e-14 1.0000000e+00 5.2354284e-23 2.7966657e-21 6.6825556e-25], sampled 0.7600166270564506
[2019-03-24 01:17:21,014] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 01:17:21,076] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 01:17:21,175] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 01:17:21,241] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 01:17:21,307] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 01:17:22,322] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 2450000, evaluation results [2450000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 01:17:24,877] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3113837e-17 1.0000000e+00 7.9852864e-26 6.7701061e-24 5.1354037e-29], sum to 1.0000
[2019-03-24 01:17:24,884] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7352
[2019-03-24 01:17:24,892] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.33333333333334, 68.66666666666667, 1.0, 2.0, 0.6739670083472675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 768116.8650125649, 768116.8650125649, 171274.6241884334], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4468800.0000, 
sim time next is 4469400.0000, 
raw observation next is [29.25, 70.0, 1.0, 2.0, 0.6916875109710893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 788323.2196592778, 788323.2196592778, 174576.7692202626], 
processed observation next is [0.0, 0.7391304347826086, 0.6388888888888888, 0.7, 1.0, 1.0, 0.6329613225846301, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28154400702117066, 0.28154400702117066, 0.33572455619281266], 
reward next is 0.6643, 
noisyNet noise sample is [array([0.3971313], dtype=float32), -0.1773146]. 
=============================================
[2019-03-24 01:17:25,046] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2010962e-16 1.0000000e+00 8.8236447e-26 9.9783105e-25 1.9067908e-27], sum to 1.0000
[2019-03-24 01:17:25,053] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0170
[2019-03-24 01:17:25,065] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.00000000000001, 1.0, 2.0, 0.4923700510542962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 591088.5341329458, 591088.5341329458, 141838.9499276872], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4417800.0000, 
sim time next is 4418400.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.493023210909752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 591872.2335951088, 591872.2335951084, 141940.9146083254], 
processed observation next is [0.0, 0.13043478260869565, 0.37037037037037035, 0.94, 1.0, 1.0, 0.39645620346399046, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21138294056968174, 0.21138294056968157, 0.27296329732370267], 
reward next is 0.7270, 
noisyNet noise sample is [array([-1.0943938], dtype=float32), -0.73962]. 
=============================================
[2019-03-24 01:17:28,241] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.0137406e-15 1.0000000e+00 9.9149452e-25 2.4924756e-23 8.4249097e-27], sum to 1.0000
[2019-03-24 01:17:28,247] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2386
[2019-03-24 01:17:28,253] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 82.33333333333334, 1.0, 2.0, 0.7187977184932365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 819237.5084515006, 819237.5084515006, 179733.3894921857], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4477800.0000, 
sim time next is 4478400.0000, 
raw observation next is [27.2, 82.0, 1.0, 2.0, 0.7092177618125035, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 808313.1579388967, 808313.1579388962, 177895.9574639437], 
processed observation next is [0.0, 0.8695652173913043, 0.5629629629629629, 0.82, 1.0, 1.0, 0.6538306688244089, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2886832706924631, 0.2886832706924629, 0.34210761050758404], 
reward next is 0.6579, 
noisyNet noise sample is [array([0.53214365], dtype=float32), -1.8208201]. 
=============================================
[2019-03-24 01:17:34,175] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.4657312e-16 1.0000000e+00 4.9623231e-25 1.7201313e-22 1.2721555e-27], sum to 1.0000
[2019-03-24 01:17:34,182] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4847
[2019-03-24 01:17:34,190] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1559235.049345237 W.
[2019-03-24 01:17:34,194] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 80.66666666666667, 1.0, 2.0, 0.4558035306088807, 1.0, 2.0, 0.4558035306088807, 1.0, 1.0, 0.7256540652139827, 6.9112, 6.9112, 121.94756008, 1559235.049345237, 1559235.049345237, 322389.1445702846], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4614600.0000, 
sim time next is 4615200.0000, 
raw observation next is [26.0, 79.0, 1.0, 2.0, 0.6517115919207843, 1.0, 2.0, 0.6517115919207843, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1486200.757890946, 1486200.757890946, 286287.9739881776], 
processed observation next is [1.0, 0.43478260869565216, 0.5185185185185185, 0.79, 1.0, 1.0, 0.5853709427628384, 1.0, 1.0, 0.5853709427628384, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5307859849610521, 0.5307859849610521, 0.5505537961311108], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3111751], dtype=float32), -0.54542726]. 
=============================================
[2019-03-24 01:17:35,657] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.270529e-15 1.000000e+00 3.311353e-23 1.493053e-20 2.705750e-25], sum to 1.0000
[2019-03-24 01:17:35,663] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0868
[2019-03-24 01:17:35,667] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 94.0, 1.0, 2.0, 0.7141546593023169, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 813942.8506548419, 813942.8506548419, 178843.1136300523], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4654800.0000, 
sim time next is 4655400.0000, 
raw observation next is [26.0, 94.00000000000001, 1.0, 2.0, 0.7182002721906589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 818556.2155551764, 818556.2155551764, 179620.2185993912], 
processed observation next is [1.0, 0.9130434782608695, 0.5185185185185185, 0.9400000000000002, 1.0, 1.0, 0.6645241335603082, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29234150555542016, 0.29234150555542016, 0.34542349730652155], 
reward next is 0.6546, 
noisyNet noise sample is [array([-1.2554168], dtype=float32), 2.4550748]. 
=============================================
[2019-03-24 01:17:38,660] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.6280130e-15 1.0000000e+00 3.3334946e-23 4.2911474e-23 2.3435962e-26], sum to 1.0000
[2019-03-24 01:17:38,668] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6634
[2019-03-24 01:17:38,672] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.58333333333333, 94.83333333333333, 1.0, 2.0, 0.6142043364461687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 714152.3782266389, 714152.3782266389, 161216.0516951028], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4683000.0000, 
sim time next is 4683600.0000, 
raw observation next is [23.7, 95.0, 1.0, 2.0, 0.6177783609722018, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 716224.4410683787, 716224.4410683787, 161749.789697329], 
processed observation next is [1.0, 0.21739130434782608, 0.4333333333333333, 0.95, 1.0, 1.0, 0.5449742392526212, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2557944432387067, 0.2557944432387067, 0.31105728787947884], 
reward next is 0.6889, 
noisyNet noise sample is [array([-1.2773153], dtype=float32), 1.9708565]. 
=============================================
[2019-03-24 01:17:41,045] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8187524e-14 1.0000000e+00 3.1248443e-24 4.2157854e-21 1.7483493e-26], sum to 1.0000
[2019-03-24 01:17:41,053] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1534
[2019-03-24 01:17:41,059] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 98.0, 1.0, 2.0, 0.5606058199359261, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 654441.2039997344, 654441.2039997339, 152163.9721166637], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5024400.0000, 
sim time next is 5025000.0000, 
raw observation next is [23.0, 99.0, 1.0, 2.0, 0.5676255454196598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 660950.1913278571, 660950.1913278571, 153263.5360958782], 
processed observation next is [0.0, 0.13043478260869565, 0.4074074074074074, 0.99, 1.0, 1.0, 0.48526850645197595, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23605363975994895, 0.23605363975994895, 0.2947375694151504], 
reward next is 0.7053, 
noisyNet noise sample is [array([-1.3455502], dtype=float32), -0.3880085]. 
=============================================
[2019-03-24 01:17:41,083] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[65.77762]
 [65.77762]
 [65.77762]
 [65.77762]
 [65.77762]], R is [[65.82511139]
 [65.87423706]
 [65.92508698]
 [65.97731781]
 [66.03036499]].
[2019-03-24 01:17:46,606] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.4447326e-14 1.0000000e+00 1.5114919e-23 2.0671559e-22 4.4829123e-26], sum to 1.0000
[2019-03-24 01:17:46,620] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5420
[2019-03-24 01:17:46,625] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.7395412997688047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 842892.6534828595, 842892.6534828595, 183761.2893100389], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4851600.0000, 
sim time next is 4852200.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.7382246701011221, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 841391.2003129077, 841391.2003129077, 183503.2058265035], 
processed observation next is [1.0, 0.13043478260869565, 0.48148148148148145, 0.94, 1.0, 1.0, 0.6883627025013359, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3004968572546099, 0.3004968572546099, 0.35289078043558364], 
reward next is 0.6471, 
noisyNet noise sample is [array([0.17476395], dtype=float32), -0.45117688]. 
=============================================
[2019-03-24 01:17:49,678] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.1261316e-14 1.0000000e+00 6.3542582e-22 1.2139685e-20 1.3835879e-23], sum to 1.0000
[2019-03-24 01:17:49,687] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6843
[2019-03-24 01:17:49,690] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 89.0, 1.0, 2.0, 0.8342625590314091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 950918.2441891799, 950918.2441891799, 203134.7543221203], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4904400.0000, 
sim time next is 4905000.0000, 
raw observation next is [29.0, 89.0, 1.0, 2.0, 0.8385345432811339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 955790.620458339, 955790.620458339, 204044.3205019969], 
processed observation next is [1.0, 0.782608695652174, 0.6296296296296297, 0.89, 1.0, 1.0, 0.807779218191826, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.34135379302083535, 0.34135379302083535, 0.39239292404230175], 
reward next is 0.6076, 
noisyNet noise sample is [array([0.9565386], dtype=float32), -0.32814077]. 
=============================================
[2019-03-24 01:17:49,709] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[56.255375]
 [56.255375]
 [56.255375]
 [56.255375]
 [56.255375]], R is [[56.30042648]
 [56.34677887]
 [56.39870453]
 [56.4565773 ]
 [56.52455902]].
[2019-03-24 01:17:50,484] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.3459339e-14 1.0000000e+00 1.3817327e-21 1.2183207e-19 1.6338635e-23], sum to 1.0000
[2019-03-24 01:17:50,492] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9437
[2019-03-24 01:17:50,503] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2576882.572791141 W.
[2019-03-24 01:17:50,507] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.8, 77.5, 1.0, 2.0, 0.8789852695404866, 1.0, 2.0, 0.7528572967466779, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2576882.572791141, 2576882.572791141, 480799.3694229428], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4897800.0000, 
sim time next is 4898400.0000, 
raw observation next is [31.06666666666667, 73.66666666666667, 1.0, 2.0, 0.8765090906555935, 1.0, 2.0, 0.7516192073042316, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2572638.729040681, 2572638.729040681, 480038.8251841132], 
processed observation next is [1.0, 0.6956521739130435, 0.7061728395061729, 0.7366666666666667, 1.0, 1.0, 0.8529870126852303, 1.0, 1.0, 0.7043085801240853, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8096049824067558, 0.9187995460859575, 0.9187995460859575, 0.9231515868925253], 
reward next is 0.0768, 
noisyNet noise sample is [array([0.16787674], dtype=float32), 0.872223]. 
=============================================
[2019-03-24 01:17:51,392] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6980239e-14 1.0000000e+00 4.8307944e-25 1.1222822e-22 5.4427920e-26], sum to 1.0000
[2019-03-24 01:17:51,399] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8038
[2019-03-24 01:17:51,407] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 80.66666666666667, 1.0, 2.0, 0.681548167802011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 776761.4528388012, 776761.4528388007, 172678.8438552424], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4927200.0000, 
sim time next is 4927800.0000, 
raw observation next is [27.0, 79.83333333333334, 1.0, 2.0, 0.6743494778462507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 768552.9821383444, 768552.9821383444, 171343.1656520675], 
processed observation next is [1.0, 0.0, 0.5555555555555556, 0.7983333333333335, 1.0, 1.0, 0.6123208069598222, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27448320790655156, 0.27448320790655156, 0.32950608779243745], 
reward next is 0.6705, 
noisyNet noise sample is [array([0.52132744], dtype=float32), -0.35112828]. 
=============================================
[2019-03-24 01:17:51,441] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4871571e-14 1.0000000e+00 3.8117077e-23 4.8034612e-21 8.4587642e-25], sum to 1.0000
[2019-03-24 01:17:51,444] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0742
[2019-03-24 01:17:51,445] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2015344.009252091 W.
[2019-03-24 01:17:51,451] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.96666666666667, 77.0, 1.0, 2.0, 0.8834760599583723, 1.0, 2.0, 0.8834760599583723, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2015344.009252091, 2015344.009252091, 379455.4750782775], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5226000.0000, 
sim time next is 5226600.0000, 
raw observation next is [27.98333333333333, 78.0, 1.0, 2.0, 0.598088116362112, 1.0, 2.0, 0.598088116362112, 1.0, 1.0, 0.9521757596185764, 6.9112, 6.9112, 121.94756008, 2046530.977431232, 2046530.977431232, 394334.8854923139], 
processed observation next is [1.0, 0.4782608695652174, 0.5919753086419752, 0.78, 1.0, 1.0, 0.5215334718596571, 1.0, 1.0, 0.5215334718596571, 1.0, 0.5, 0.9402196995232204, 0.0, 0.0, 0.8096049824067558, 0.7309039205111543, 0.7309039205111543, 0.7583363182544498], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.7207146], dtype=float32), -0.53090036]. 
=============================================
[2019-03-24 01:17:57,090] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.0458721e-15 1.0000000e+00 2.6377343e-24 2.9717107e-23 6.6419115e-27], sum to 1.0000
[2019-03-24 01:17:57,101] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9480
[2019-03-24 01:17:57,106] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 91.5, 1.0, 2.0, 0.8160938239423414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 930196.3898393563, 930196.3898393563, 199295.1949396227], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5088600.0000, 
sim time next is 5089200.0000, 
raw observation next is [27.33333333333334, 92.33333333333334, 1.0, 2.0, 0.8147154222686697, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 928624.3143419351, 928624.3143419351, 199006.4425251452], 
processed observation next is [0.0, 0.9130434782608695, 0.5679012345679014, 0.9233333333333335, 1.0, 1.0, 0.7794231217484162, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3316515408364054, 0.3316515408364054, 0.3827046971637407], 
reward next is 0.6173, 
noisyNet noise sample is [array([-0.7196267], dtype=float32), -0.50121593]. 
=============================================
[2019-03-24 01:18:02,285] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.4685553e-15 1.0000000e+00 2.2073941e-23 2.8183085e-22 2.3988252e-26], sum to 1.0000
[2019-03-24 01:18:02,295] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0512
[2019-03-24 01:18:02,303] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 70.5, 1.0, 2.0, 0.8202268341588989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 934910.1324755118, 934910.1324755118, 200162.8231536591], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5146200.0000, 
sim time next is 5146800.0000, 
raw observation next is [31.0, 69.0, 1.0, 2.0, 0.8117256801840731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 925214.5063828866, 925214.5063828861, 198381.4075003505], 
processed observation next is [0.0, 0.5652173913043478, 0.7037037037037037, 0.69, 1.0, 1.0, 0.7758639049810394, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.33043375227960237, 0.3304337522796022, 0.38150270673144326], 
reward next is 0.6185, 
noisyNet noise sample is [array([0.00594925], dtype=float32), -0.13295318]. 
=============================================
[2019-03-24 01:18:02,958] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0795521e-14 1.0000000e+00 4.5653045e-24 8.8499522e-23 2.6669822e-26], sum to 1.0000
[2019-03-24 01:18:02,966] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6804
[2019-03-24 01:18:02,972] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.13333333333333, 89.66666666666667, 1.0, 2.0, 0.7576138436552293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 863502.4501436652, 863502.4501436652, 187342.4055900972], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5442000.0000, 
sim time next is 5442600.0000, 
raw observation next is [27.06666666666667, 89.83333333333333, 1.0, 2.0, 0.7538954525869866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 859261.978923863, 859261.978923863, 186602.4180101689], 
processed observation next is [1.0, 1.0, 0.5580246913580248, 0.8983333333333333, 1.0, 1.0, 0.7070183959368889, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.30687927818709393, 0.30687927818709393, 0.35885080386570944], 
reward next is 0.6411, 
noisyNet noise sample is [array([1.6503679], dtype=float32), -1.3857018]. 
=============================================
[2019-03-24 01:18:04,259] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.872699e-16 1.000000e+00 4.561055e-25 9.479082e-24 5.511910e-26], sum to 1.0000
[2019-03-24 01:18:04,265] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6113
[2019-03-24 01:18:04,273] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1667131.466937818 W.
[2019-03-24 01:18:04,277] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.5, 86.5, 1.0, 2.0, 0.487313930990403, 1.0, 2.0, 0.487313930990403, 1.0, 2.0, 0.7758196488434623, 6.911199999999999, 6.9112, 121.94756008, 1667131.466937818, 1667131.466937819, 337406.2005339189], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5218200.0000, 
sim time next is 5218800.0000, 
raw observation next is [26.66666666666667, 85.66666666666667, 1.0, 2.0, 0.4825360210555569, 1.0, 2.0, 0.4825360210555569, 1.0, 2.0, 0.768213060621524, 6.9112, 6.9112, 121.94756008, 1650770.838907968, 1650770.838907968, 335100.2252616843], 
processed observation next is [1.0, 0.391304347826087, 0.5432098765432101, 0.8566666666666667, 1.0, 1.0, 0.38397145363756774, 1.0, 1.0, 0.38397145363756774, 1.0, 1.0, 0.7102663257769048, 0.0, 0.0, 0.8096049824067558, 0.5895610138957028, 0.5895610138957028, 0.6444235101186236], 
reward next is 0.3556, 
noisyNet noise sample is [array([0.03530734], dtype=float32), -0.24153191]. 
=============================================
[2019-03-24 01:18:07,203] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.5278691e-13 1.0000000e+00 1.4882812e-21 2.4357468e-18 5.9401491e-23], sum to 1.0000
[2019-03-24 01:18:07,210] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7427
[2019-03-24 01:18:07,212] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.2, 84.33333333333334, 1.0, 2.0, 0.8428409305030005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156212, 973976.3639935497, 973976.3639935502, 205646.8347293825], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5280000.0000, 
sim time next is 5280600.0000, 
raw observation next is [25.15, 84.16666666666666, 1.0, 2.0, 0.8077041934160294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 934960.0651514404, 934960.0651514404, 198275.5552417817], 
processed observation next is [1.0, 0.08695652173913043, 0.487037037037037, 0.8416666666666666, 1.0, 1.0, 0.7710764207333684, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3339143089826573, 0.3339143089826573, 0.381299144695734], 
reward next is 0.6187, 
noisyNet noise sample is [array([1.0262289], dtype=float32), 0.5791932]. 
=============================================
[2019-03-24 01:18:09,995] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.4196261e-16 1.0000000e+00 6.2702372e-25 1.4508737e-22 1.6413199e-26], sum to 1.0000
[2019-03-24 01:18:10,007] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8182
[2019-03-24 01:18:10,010] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.3, 68.0, 1.0, 2.0, 0.5989265094704425, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 685650.4091171605, 685650.4091171605, 158046.2051038964], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5335200.0000, 
sim time next is 5335800.0000, 
raw observation next is [28.26666666666667, 68.33333333333334, 1.0, 2.0, 0.6007137947770375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 687436.2929672345, 687436.2929672345, 158341.2458930058], 
processed observation next is [1.0, 0.782608695652174, 0.6024691358024692, 0.6833333333333335, 1.0, 1.0, 0.5246592794964732, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24551296177401233, 0.24551296177401233, 0.3045023959480881], 
reward next is 0.6955, 
noisyNet noise sample is [array([-0.88022923], dtype=float32), -1.082151]. 
=============================================
[2019-03-24 01:18:10,342] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.8473036e-15 1.0000000e+00 1.4856689e-25 8.5488888e-23 3.2382583e-26], sum to 1.0000
[2019-03-24 01:18:10,345] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8411
[2019-03-24 01:18:10,350] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.9, 72.0, 1.0, 2.0, 0.628064610334469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 715777.7038419133, 715777.7038419133, 162971.8800049903], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5342400.0000, 
sim time next is 5343000.0000, 
raw observation next is [27.81666666666667, 72.33333333333333, 1.0, 2.0, 0.6305724586429464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 718637.1283224084, 718637.128322408, 163415.7363284892], 
processed observation next is [1.0, 0.8695652173913043, 0.5858024691358026, 0.7233333333333333, 1.0, 1.0, 0.5602053079082695, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.256656117258003, 0.25665611725800286, 0.3142610314009408], 
reward next is 0.6857, 
noisyNet noise sample is [array([-0.23209853], dtype=float32), -1.0458077]. 
=============================================
[2019-03-24 01:18:10,371] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[64.62655]
 [64.62655]
 [64.62655]
 [64.62655]
 [64.62655]], R is [[64.66603088]
 [64.70596313]
 [64.74459839]
 [64.78312683]
 [64.82167816]].
[2019-03-24 01:18:10,386] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.0923177e-14 1.0000000e+00 2.4155229e-23 1.7202962e-21 7.0641083e-26], sum to 1.0000
[2019-03-24 01:18:10,393] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5322
[2019-03-24 01:18:10,395] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.36666666666667, 91.66666666666667, 1.0, 2.0, 0.625874461054364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 749756.2849295713, 749756.2849295713, 164188.3733727979], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5296800.0000, 
sim time next is 5297400.0000, 
raw observation next is [22.25, 92.0, 1.0, 2.0, 0.6150193359495258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 737749.6711934138, 737749.6711934138, 162286.5975441872], 
processed observation next is [1.0, 0.30434782608695654, 0.37962962962962965, 0.92, 1.0, 1.0, 0.5416896856541974, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26348202542621924, 0.26348202542621924, 0.3120896106618985], 
reward next is 0.6879, 
noisyNet noise sample is [array([-1.2189705], dtype=float32), -0.34647796]. 
=============================================
[2019-03-24 01:18:11,448] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-24 01:18:11,450] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:18:11,451] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:18:11,452] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:18:11,453] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:18:11,453] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:18:11,456] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:18:11,455] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:18:11,457] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:18:11,459] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:18:11,461] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:18:11,481] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run100
[2019-03-24 01:18:11,505] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run100
[2019-03-24 01:18:11,531] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run100
[2019-03-24 01:18:11,532] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run100
[2019-03-24 01:18:11,596] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run100
[2019-03-24 01:18:22,972] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), -0.010541789]
[2019-03-24 01:18:22,974] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.0, 58.0, 1.0, 2.0, 0.3140743296346765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 398914.7459901513, 398914.7459901508, 117322.8927520336]
[2019-03-24 01:18:22,976] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 01:18:22,983] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0591241e-14 1.0000000e+00 2.0372424e-23 1.1597646e-21 2.3696585e-25], sampled 0.7993088295683579
[2019-03-24 01:18:56,612] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), -0.010541789]
[2019-03-24 01:18:56,614] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [20.33333333333334, 90.0, 1.0, 2.0, 0.3854891609070465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 478774.3087419723, 478774.3087419723, 126618.5357456057]
[2019-03-24 01:18:56,614] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:18:56,617] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0591241e-14 1.0000000e+00 2.0372424e-23 1.1597646e-21 2.3696585e-25], sampled 0.30753760601556535
[2019-03-24 01:19:59,415] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 01:19:59,775] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 01:19:59,947] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 01:20:00,044] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 01:20:00,121] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 01:20:01,136] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 2475000, evaluation results [2475000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-03-24 01:20:07,708] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0899752e-15 1.0000000e+00 2.5198727e-25 1.2565568e-21 9.1429256e-26], sum to 1.0000
[2019-03-24 01:20:07,723] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8377
[2019-03-24 01:20:07,733] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2048307.234706455 W.
[2019-03-24 01:20:07,740] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.3, 88.0, 1.0, 2.0, 0.8979097542224753, 1.0, 2.0, 0.8979097542224753, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260425394825, 2048307.234706455, 2048307.234706455, 385875.092456246], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5475600.0000, 
sim time next is 5476200.0000, 
raw observation next is [28.43333333333334, 87.50000000000001, 1.0, 2.0, 0.9427094803999937, 1.0, 2.0, 0.9427094803999937, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156386, 2150627.216990496, 2150627.216990496, 406254.7935954211], 
processed observation next is [1.0, 0.391304347826087, 0.6086419753086423, 0.8750000000000001, 1.0, 1.0, 0.931797000476183, 1.0, 1.0, 0.931797000476183, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288199819, 0.7680811489251772, 0.7680811489251772, 0.7812592184527329], 
reward next is 0.2187, 
noisyNet noise sample is [array([-0.17792611], dtype=float32), 1.2243865]. 
=============================================
[2019-03-24 01:20:08,037] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.9451695e-14 1.0000000e+00 3.4610139e-23 9.6121457e-22 4.8470385e-25], sum to 1.0000
[2019-03-24 01:20:08,046] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6662
[2019-03-24 01:20:08,055] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1458753.568360311 W.
[2019-03-24 01:20:08,059] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.23333333333333, 46.0, 1.0, 2.0, 0.4141549952180746, 1.0, 1.0, 0.4141549952180746, 1.0, 2.0, 0.6624808783109897, 6.9112, 6.9112, 121.94756008, 1458753.568360311, 1458753.568360311, 303355.4382955148], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5930400.0000, 
sim time next is 5931000.0000, 
raw observation next is [29.2, 46.5, 1.0, 2.0, 0.422502778660339, 1.0, 2.0, 0.422502778660339, 1.0, 2.0, 0.6749468463120372, 6.911200000000001, 6.9112, 121.94756008, 1480991.36811849, 1480991.368118489, 307145.7827559626], 
processed observation next is [1.0, 0.6521739130434783, 0.637037037037037, 0.465, 1.0, 1.0, 0.312503307928975, 1.0, 1.0, 0.312503307928975, 1.0, 1.0, 0.5936835578900465, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5289254886137464, 0.528925488613746, 0.5906649668383895], 
reward next is 0.4093, 
noisyNet noise sample is [array([-0.18964891], dtype=float32), -1.8184148]. 
=============================================
[2019-03-24 01:20:08,072] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[62.09611]
 [62.09611]
 [62.09611]
 [62.09611]
 [62.09611]], R is [[61.88449097]
 [61.26564789]
 [61.08798599]
 [60.92137909]
 [60.75439453]].
[2019-03-24 01:20:09,389] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1300884e-14 1.0000000e+00 4.1938905e-21 1.3055169e-20 1.4647702e-23], sum to 1.0000
[2019-03-24 01:20:09,401] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0206
[2019-03-24 01:20:09,409] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1772424.369163537 W.
[2019-03-24 01:20:09,416] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.09999999999999, 70.0, 1.0, 2.0, 0.5180612687779186, 1.0, 2.0, 0.5180612687779186, 1.0, 1.0, 0.8247704119720695, 6.9112, 6.9112, 121.94756008, 1772424.369163537, 1772424.369163537, 352542.1704768959], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5489400.0000, 
sim time next is 5490000.0000, 
raw observation next is [32.3, 69.0, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 8.830304001303418, 6.9112, 121.9184789189057, 2861802.286580424, 1879110.475530811, 377217.9620430924], 
processed observation next is [1.0, 0.5652173913043478, 0.7518518518518518, 0.69, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 0.19191040013034177, 0.0, 0.8094119137393657, 1.0220722452072941, 0.6711108841181468, 0.7254191577751777], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8001479], dtype=float32), 0.3708744]. 
=============================================
[2019-03-24 01:20:09,429] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[54.69441]
 [54.69441]
 [54.69441]
 [54.69441]
 [54.69441]], R is [[54.14746857]
 [53.60599518]
 [53.37807846]
 [52.96316528]
 [52.5847702 ]].
[2019-03-24 01:20:13,994] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.4491371e-15 1.0000000e+00 1.4374366e-23 4.8278701e-23 3.3919571e-26], sum to 1.0000
[2019-03-24 01:20:14,001] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8020
[2019-03-24 01:20:14,009] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1603251.622501125 W.
[2019-03-24 01:20:14,013] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.23333333333333, 81.33333333333333, 1.0, 2.0, 0.702987116936748, 1.0, 2.0, 0.702987116936748, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1603251.622501125, 1603251.622501125, 305296.9819513923], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5565000.0000, 
sim time next is 5565600.0000, 
raw observation next is [26.3, 81.0, 1.0, 2.0, 0.6904276144792068, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1501875.737529426, 1501875.737529426, 315499.3793022536], 
processed observation next is [1.0, 0.43478260869565216, 0.5296296296296297, 0.81, 1.0, 1.0, 0.6314614458085794, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, 0.0, 0.0, 0.8094621288201359, 0.536384191974795, 0.536384191974795, 0.606729575581257], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.04417129], dtype=float32), -0.54317003]. 
=============================================
[2019-03-24 01:20:16,007] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.8657712e-16 1.0000000e+00 2.7188384e-25 4.5842395e-24 1.2227621e-27], sum to 1.0000
[2019-03-24 01:20:16,013] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0591
[2019-03-24 01:20:16,022] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666666, 87.33333333333333, 1.0, 2.0, 0.6696131503582464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 763152.3244464057, 763152.3244464057, 170470.9689689021], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5650800.0000, 
sim time next is 5651400.0000, 
raw observation next is [26.33333333333334, 86.66666666666667, 1.0, 2.0, 0.6747396094327255, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 768997.8363408272, 768997.8363408272, 171416.9448944264], 
processed observation next is [0.0, 0.391304347826087, 0.5308641975308644, 0.8666666666666667, 1.0, 1.0, 0.6127852493246732, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27464208440743826, 0.27464208440743826, 0.32964797095082], 
reward next is 0.6704, 
noisyNet noise sample is [array([-1.3483956], dtype=float32), -0.41627476]. 
=============================================
[2019-03-24 01:20:17,224] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.5224122e-17 1.0000000e+00 8.4427006e-27 2.5323914e-24 1.3684775e-28], sum to 1.0000
[2019-03-24 01:20:17,234] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4289
[2019-03-24 01:20:17,240] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.9, 93.33333333333334, 1.0, 2.0, 0.6445444240558242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 734568.0239318167, 734568.0239318167, 165910.1733795003], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5646000.0000, 
sim time next is 5646600.0000, 
raw observation next is [25.05, 92.5, 1.0, 2.0, 0.6472536830020887, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 737657.1710666067, 737657.1710666062, 166397.7861038654], 
processed observation next is [0.0, 0.34782608695652173, 0.48333333333333334, 0.925, 1.0, 1.0, 0.5800639083358199, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2634489896666452, 0.26344898966664504, 0.31999574250743346], 
reward next is 0.6800, 
noisyNet noise sample is [array([0.9346375], dtype=float32), 1.160588]. 
=============================================
[2019-03-24 01:20:26,135] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1012428e-15 1.0000000e+00 1.6600736e-24 5.1747496e-23 6.1744125e-26], sum to 1.0000
[2019-03-24 01:20:26,144] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5125
[2019-03-24 01:20:26,150] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.88333333333334, 46.16666666666667, 1.0, 2.0, 0.7587618860753736, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260425513842, 942833.7494823551, 942833.7494823551, 190664.5529329739], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5832600.0000, 
sim time next is 5833200.0000, 
raw observation next is [26.96666666666667, 46.33333333333334, 1.0, 2.0, 0.6653946950476878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156422, 829370.0498986811, 829370.0498986811, 172378.3000945349], 
processed observation next is [1.0, 0.5217391304347826, 0.554320987654321, 0.46333333333333343, 1.0, 1.0, 0.6016603512472474, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288200058, 0.29620358924952894, 0.29620358924952894, 0.33149673095102866], 
reward next is 0.6685, 
noisyNet noise sample is [array([0.10453694], dtype=float32), -0.606727]. 
=============================================
[2019-03-24 01:20:30,320] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1430813e-16 1.0000000e+00 3.3455283e-26 1.0720945e-23 4.2804584e-29], sum to 1.0000
[2019-03-24 01:20:30,325] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8686
[2019-03-24 01:20:30,327] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 85.0, 1.0, 2.0, 0.5722804451056006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 674183.4465577886, 674183.4465577886, 154380.5151350378], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6163200.0000, 
sim time next is 6163800.0000, 
raw observation next is [24.38333333333333, 83.83333333333334, 1.0, 2.0, 0.7374864327764032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 868197.6461563682, 868197.6461563677, 184692.1576177024], 
processed observation next is [1.0, 0.34782608695652173, 0.4586419753086418, 0.8383333333333334, 1.0, 1.0, 0.6874838485433372, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.31007058791298864, 0.31007058791298847, 0.3551772261878893], 
reward next is 0.6448, 
noisyNet noise sample is [array([0.17707366], dtype=float32), -0.3145672]. 
=============================================
[2019-03-24 01:20:37,002] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.1584143e-17 1.0000000e+00 3.5592572e-27 1.8522284e-24 1.1479460e-29], sum to 1.0000
[2019-03-24 01:20:37,011] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4129
[2019-03-24 01:20:37,018] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.33333333333334, 64.66666666666667, 1.0, 2.0, 0.3737899854919271, 1.0, 1.0, 0.3737899854919271, 1.0, 2.0, 0.5950858303930998, 6.9112, 6.9112, 121.94756008, 1278444.972338376, 1278444.972338376, 285791.1394045255], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6006000.0000, 
sim time next is 6006600.0000, 
raw observation next is [28.5, 64.0, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.651094520571137, 6.9112, 121.923101756877, 1548037.876062094, 1169154.889394102, 245932.1269224974], 
processed observation next is [1.0, 0.5217391304347826, 0.6111111111111112, 0.64, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.07398945205711369, 0.0, 0.8094426045760825, 0.5528706700221764, 0.4175553176407507, 0.4729463979278796], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.54980725], dtype=float32), -0.52582926]. 
=============================================
[2019-03-24 01:20:40,337] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.9808851e-15 1.0000000e+00 1.5268831e-24 1.5718235e-22 3.0113271e-26], sum to 1.0000
[2019-03-24 01:20:40,343] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1101
[2019-03-24 01:20:40,348] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.13333333333333, 82.33333333333334, 1.0, 2.0, 0.6052981757217534, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 718762.138545017, 718762.138545017, 160291.4443373738], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6072600.0000, 
sim time next is 6073200.0000, 
raw observation next is [24.2, 82.0, 1.0, 2.0, 0.5341099516856982, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 634009.3364841038, 634009.3364841038, 148241.7047620619], 
processed observation next is [1.0, 0.30434782608695654, 0.45185185185185184, 0.82, 1.0, 1.0, 0.44536899010202163, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22643190588717993, 0.22643190588717993, 0.28508020146550367], 
reward next is 0.7149, 
noisyNet noise sample is [array([1.4560661], dtype=float32), 1.6114324]. 
=============================================
[2019-03-24 01:20:43,860] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.1659658e-15 1.0000000e+00 2.9951865e-25 8.2742749e-23 9.4767492e-28], sum to 1.0000
[2019-03-24 01:20:43,874] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7130
[2019-03-24 01:20:43,881] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1466444.20070856 W.
[2019-03-24 01:20:43,885] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.3, 72.0, 1.0, 2.0, 0.4287043800502919, 1.0, 2.0, 0.4287043800502919, 1.0, 2.0, 0.68251133496699, 6.9112, 6.9112, 121.94756008, 1466444.20070856, 1466444.20070856, 309884.4324776059], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6170400.0000, 
sim time next is 6171000.0000, 
raw observation next is [26.48333333333333, 71.16666666666667, 1.0, 2.0, 0.6413872290416617, 1.0, 2.0, 0.6413872290416617, 0.0, 1.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 1465032.753473037, 1465032.753473036, 282692.0388164977], 
processed observation next is [1.0, 0.43478260869565216, 0.5364197530864196, 0.7116666666666667, 1.0, 1.0, 0.5730800345734067, 1.0, 1.0, 0.5730800345734067, 0.0, 0.5, -0.25, 1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.5232259833832275, 0.5232259833832271, 0.5436385361855726], 
reward next is 0.4564, 
noisyNet noise sample is [array([-1.0375544], dtype=float32), -0.14801323]. 
=============================================
[2019-03-24 01:20:43,896] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[67.88494]
 [67.88494]
 [67.88494]
 [67.88494]
 [67.88494]], R is [[67.66244507]
 [67.38989258]
 [66.71599579]
 [66.51078796]
 [66.24757385]].
[2019-03-24 01:20:44,350] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.2914589e-13 1.0000000e+00 5.9298927e-23 6.8214976e-21 3.1752024e-25], sum to 1.0000
[2019-03-24 01:20:44,360] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1259
[2019-03-24 01:20:44,368] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.93333333333333, 90.0, 1.0, 2.0, 0.564351323559941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 671889.6252172573, 671889.6252172573, 153323.8051847325], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6147600.0000, 
sim time next is 6148200.0000, 
raw observation next is [22.86666666666667, 90.0, 1.0, 2.0, 0.559624483373567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 667076.1333464056, 667076.1333464056, 152560.8291999832], 
processed observation next is [1.0, 0.13043478260869565, 0.4024691358024693, 0.9, 1.0, 1.0, 0.4757434325875797, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23824147619514485, 0.23824147619514485, 0.29338620999996773], 
reward next is 0.7066, 
noisyNet noise sample is [array([0.30262774], dtype=float32), -0.028836282]. 
=============================================
[2019-03-24 01:20:47,676] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3954555e-16 1.0000000e+00 8.1682923e-26 2.9835805e-23 2.9742791e-27], sum to 1.0000
[2019-03-24 01:20:47,682] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8680
[2019-03-24 01:20:47,687] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.73333333333333, 74.66666666666667, 1.0, 2.0, 0.4938597158079047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 591780.7023833265, 591780.7023833265, 142033.0849310197], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6222000.0000, 
sim time next is 6222600.0000, 
raw observation next is [24.65, 75.0, 1.0, 2.0, 0.4921361758388176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 590036.3017642167, 590036.3017642167, 141775.3793728581], 
processed observation next is [0.0, 0.0, 0.46851851851851845, 0.75, 1.0, 1.0, 0.3954002093319257, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2107272506300774, 0.2107272506300774, 0.2726449603324194], 
reward next is 0.7274, 
noisyNet noise sample is [array([1.6819012], dtype=float32), 0.5169118]. 
=============================================
[2019-03-24 01:20:50,170] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.9950135e-16 1.0000000e+00 3.4269987e-24 5.2116139e-24 3.8544691e-27], sum to 1.0000
[2019-03-24 01:20:50,179] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4074
[2019-03-24 01:20:50,183] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.8, 64.0, 1.0, 2.0, 0.615777836242106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 707834.3874762824, 707834.3874762824, 161110.9799619705], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6289200.0000, 
sim time next is 6289800.0000, 
raw observation next is [28.68333333333333, 64.33333333333334, 1.0, 2.0, 0.610273460766347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 702326.1805748454, 702326.1805748454, 160188.3656797025], 
processed observation next is [0.0, 0.8260869565217391, 0.6179012345679011, 0.6433333333333334, 1.0, 1.0, 0.5360398342456512, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2508307787767305, 0.2508307787767305, 0.30805454938404325], 
reward next is 0.6919, 
noisyNet noise sample is [array([0.05021228], dtype=float32), 0.5380635]. 
=============================================
[2019-03-24 01:20:50,215] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-24 01:20:50,216] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 01:20:50,217] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 01:20:50,217] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:20:50,218] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:20:50,221] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 01:20:50,222] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 01:20:50,224] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:20:50,224] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:20:50,223] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 01:20:50,226] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 01:20:50,249] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run101
[2019-03-24 01:20:50,275] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run101
[2019-03-24 01:20:50,276] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run101
[2019-03-24 01:20:50,322] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run101
[2019-03-24 01:20:50,323] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/38/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run101
[2019-03-24 01:21:13,187] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.013395216]
[2019-03-24 01:21:13,188] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.5, 65.0, 1.0, 2.0, 0.4713234423750635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 571508.3464429645, 571508.3464429645, 138780.7179974625]
[2019-03-24 01:21:13,189] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:21:13,193] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.0592156e-16 1.0000000e+00 1.3009746e-25 1.0653066e-23 1.0400037e-27], sampled 0.7030253107765783
[2019-03-24 01:21:23,155] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.013395216]
[2019-03-24 01:21:23,156] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.0, 78.0, 1.0, 2.0, 0.4111117707529992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 502706.0959028243, 502706.0959028243, 130026.568854156]
[2019-03-24 01:21:23,156] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:21:23,160] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.0592156e-16 1.0000000e+00 1.3009746e-25 1.0653066e-23 1.0400037e-27], sampled 0.1856056316226775
[2019-03-24 01:21:36,414] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.013395216]
[2019-03-24 01:21:36,416] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [32.0, 59.0, 1.0, 2.0, 0.705389546005352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 803947.7567597034, 803947.7567597034, 177169.8053975365]
[2019-03-24 01:21:36,418] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:21:36,421] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.0592156e-16 1.0000000e+00 1.3009746e-25 1.0653066e-23 1.0400037e-27], sampled 0.6863564690723495
[2019-03-24 01:21:53,226] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.013395216]
[2019-03-24 01:21:53,228] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.0, 70.66666666666667, 1.0, 2.0, 0.562346564143964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 654122.6112455694, 654122.6112455694, 152350.3147799213]
[2019-03-24 01:21:53,229] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 01:21:53,233] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.0592156e-16 1.0000000e+00 1.3009746e-25 1.0653066e-23 1.0400037e-27], sampled 0.8547836858730825
[2019-03-24 01:22:34,957] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.08627688], dtype=float32), 0.013395216]
[2019-03-24 01:22:34,958] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [17.0, 94.0, 1.0, 2.0, 0.2803298282857978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 359826.7103298811, 359826.7103298811, 113178.6445792817]
[2019-03-24 01:22:34,958] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 01:22:34,960] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.0592156e-16 1.0000000e+00 1.3009746e-25 1.0653066e-23 1.0400037e-27], sampled 0.14848654488444712
[2019-03-24 01:22:39,160] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-03-24 01:22:39,266] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-03-24 01:22:39,464] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-03-24 01:22:39,478] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-03-24 01:22:39,533] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-03-24 01:22:40,548] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 2500000, evaluation results [2500000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
