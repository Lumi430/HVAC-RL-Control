Using TensorFlow backend.
[2019-04-27 17:51:17,273] A3C_AGENT_MAIN INFO:Namespace(action_repeat_n=1, action_space='part3_v1', activation='relu', agent_num=5, check_args_only=False, clip_norm=5.0, debug_log_prob=0.0005, decay_steps=1000000, dropout_prob=0.0, end_e=0.0, env='Part3-NA-Bej-Train-v1', eval_act_func='part3_bej_det_v1', eval_env_res_max_keep=100, eval_epi_num=1, eval_freq=25000, forecast_dim=0, gamma=0.99, h_decay_bounds=[], h_regu_frac=[0.0], init_e=0.0, isNoisyNet=True, isNoisyNetEval_rmNoise=True, is_add_time_to_state=True, is_greedy_policy=False, is_learning_rate_decay_staircase=False, is_r_term_zero=True, is_warm_start=False, job_mode='Train', learning_rate=5e-05, learning_rate_decay_rate=1.0, learning_rate_decay_steps=100000, max_interactions=2500000, metric_func='part3_v1', model_dir='None', model_param=[256, 4], model_type='nn', num_threads=16, output='./Part3-NA-Bej-Train-v1-res1', p_loss_frac=1.0, raw_state_prcs_func='cslDx_1', reward_func='part3_v3', rmsprop_decay=0.99, rmsprop_epsil=1e-10, rmsprop_momet=0.0, rwd_e_para=1.0, rwd_p_para=1.0, save_freq=500000, save_max_to_keep=5, save_scope='all', sharedNet_type='Dense', state_dim=17, test_env=['Part3-NA-Bej-Test-v1', 'Part3-NA-Bej-Test-v2', 'Part3-NA-Bej-Test-v3', 'Part3-NA-Bej-Test-v4'], test_mode='Multiple', train_act_func='part3_bej_sto_v1', train_freq=5, v_loss_frac=0.5, violation_penalty_scl=50.0, weight_initer='glorot_uniform', window_len=26)
[2019-04-27 17:51:17,274] A3C_AGENT_MAIN INFO:Start compiling...
2019-04-27 17:51:17.329586: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[2019-04-27 17:51:39,615] A3C_AGENT_MAIN INFO:Start the learning...
[2019-04-27 17:51:39,615] A3C_AGENT_MAIN INFO:Prepare the evaluation environments ['Part3-NA-Bej-Train-v1', 'Part3-NA-Bej-Test-v1', 'Part3-NA-Bej-Test-v2', 'Part3-NA-Bej-Test-v3', 'Part3-NA-Bej-Test-v4'] ...
[2019-04-27 17:51:39,627] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation worker starts!
[2019-04-27 17:51:39,630] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation worker starts!
[2019-04-27 17:51:39,633] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation worker starts!
[2019-04-27 17:51:39,637] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation worker starts!
[2019-04-27 17:51:39,643] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation worker starts!
[2019-04-27 17:51:39,644] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-27 17:51:39,644] A3C_AGENT_WORKER-Thread-2 INFO:Local worker starts!
[2019-04-27 17:51:39,713] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 17:51:39,714] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run1
[2019-04-27 17:51:40,645] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-27 17:51:40,648] A3C_AGENT_WORKER-Thread-3 INFO:Local worker starts!
[2019-04-27 17:51:40,757] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 17:51:40,757] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run1
[2019-04-27 17:51:41,059] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-27 17:51:41,060] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 17:51:41,060] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 17:51:41,060] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 17:51:41,061] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 17:51:41,061] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 17:51:41,061] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 17:51:41,062] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 17:51:41,061] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 17:51:41,062] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 17:51:41,062] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 17:51:41,066] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run1
[2019-04-27 17:51:41,073] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run1
[2019-04-27 17:51:41,074] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run1
[2019-04-27 17:51:41,095] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run1
[2019-04-27 17:51:41,095] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run1
[2019-04-27 17:51:41,649] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-27 17:51:41,650] A3C_AGENT_WORKER-Thread-9 INFO:Local worker starts!
[2019-04-27 17:51:41,733] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 17:51:41,734] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run1
[2019-04-27 17:51:42,651] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-27 17:51:42,652] A3C_AGENT_WORKER-Thread-10 INFO:Local worker starts!
[2019-04-27 17:51:42,818] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 17:51:42,819] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run1
[2019-04-27 17:51:43,555] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-04-27 17:51:43,556] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.143584495, 53.79335217666667, 1.0, 2.0, 0.2943322670977833, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 372892.5182490955, 372892.5182490955, 114861.8500459525]
[2019-04-27 17:51:43,557] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 17:51:43,559] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0.21921793 0.21475057 0.19571576 0.210668   0.15964775], sampled 0.9948990340240197
[2019-04-27 17:51:43,652] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-27 17:51:43,658] A3C_AGENT_WORKER-Thread-11 INFO:Local worker starts!
[2019-04-27 17:51:43,760] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 17:51:43,775] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run1
[2019-04-27 17:51:44,657] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-27 17:51:44,660] A3C_AGENT_WORKER-Thread-12 INFO:Local worker starts!
[2019-04-27 17:51:44,758] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 17:51:44,769] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run1
[2019-04-27 17:51:45,661] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-27 17:51:45,665] A3C_AGENT_WORKER-Thread-13 INFO:Local worker starts!
[2019-04-27 17:51:45,768] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 17:51:45,780] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run1
[2019-04-27 17:51:46,665] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-27 17:51:46,670] A3C_AGENT_WORKER-Thread-14 INFO:Local worker starts!
[2019-04-27 17:51:46,764] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 17:51:46,777] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run1
[2019-04-27 17:51:47,669] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-27 17:51:47,674] A3C_AGENT_WORKER-Thread-15 INFO:Local worker starts!
[2019-04-27 17:51:47,750] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 17:51:47,750] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run1
[2019-04-27 17:51:48,675] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-27 17:51:48,679] A3C_AGENT_WORKER-Thread-16 INFO:Local worker starts!
[2019-04-27 17:51:48,763] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 17:51:48,764] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run1
[2019-04-27 17:51:49,679] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-27 17:51:49,685] A3C_AGENT_WORKER-Thread-17 INFO:Local worker starts!
[2019-04-27 17:51:49,758] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 17:51:49,759] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run1
[2019-04-27 17:51:50,684] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-27 17:51:50,689] A3C_AGENT_WORKER-Thread-18 INFO:Local worker starts!
[2019-04-27 17:51:50,766] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 17:51:50,767] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run1
[2019-04-27 17:51:51,241] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-04-27 17:51:51,241] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.65, 39.66666666666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2, 6.911199999999999, 6.9112, 121.94756008, 392290.7831175529, 392290.7831175534, 174914.8027287489]
[2019-04-27 17:51:51,242] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 17:51:51,244] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0.20896807 0.23166116 0.2044345  0.20459095 0.1503453 ], sampled 0.8721032533592161
[2019-04-27 17:51:51,690] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-27 17:51:51,694] A3C_AGENT_WORKER-Thread-19 INFO:Local worker starts!
[2019-04-27 17:51:51,767] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 17:51:51,769] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run1
[2019-04-27 17:51:52,694] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-27 17:51:52,696] A3C_AGENT_WORKER-Thread-20 INFO:Local worker starts!
[2019-04-27 17:51:52,777] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 17:51:52,778] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run1
[2019-04-27 17:51:53,697] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-27 17:51:53,701] A3C_AGENT_WORKER-Thread-21 INFO:Local worker starts!
[2019-04-27 17:51:53,773] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 17:51:53,774] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run1
[2019-04-27 17:51:54,703] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-04-27 17:51:54,708] A3C_AGENT_WORKER-Thread-22 INFO:Local worker starts!
[2019-04-27 17:51:54,783] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 17:51:54,783] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run1
[2019-04-27 17:52:01,599] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-04-27 17:52:01,601] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.0, 56.33333333333333, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 1.0, 1.0, 0.2500898998282146, 6.911199999999999, 6.9112, 121.9260426156618, 363089.3140510571, 363089.3140510576, 150331.3170188417]
[2019-04-27 17:52:01,604] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 17:52:01,605] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [0.22513308 0.22215116 0.19545525 0.20124555 0.15601493], sampled 0.3668933406469127
[2019-04-27 17:52:13,623] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-04-27 17:52:13,624] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [18.58333333333334, 93.16666666666666, 1.0, 2.0, 0.16, 1.0, 1.0, 0.16, 1.0, 1.0, 0.2, 6.911199999999999, 6.9112, 121.94756008, 410569.2441999061, 410569.2441999065, 179458.4422897123]
[2019-04-27 17:52:13,625] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 17:52:13,628] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [0.22240517 0.23912005 0.18199532 0.20268983 0.15378967], sampled 0.2731634770786493
[2019-04-27 17:52:42,073] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-04-27 17:52:42,074] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [18.208769095, 90.25126212666666, 1.0, 2.0, 0.3115800370180586, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 396383.3926604641, 396383.3926604645, 117012.673342753]
[2019-04-27 17:52:42,075] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 17:52:42,078] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0.20527245 0.23711377 0.19275883 0.21998464 0.14487033], sampled 0.36760235451598167
[2019-04-27 17:53:03,663] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-04-27 17:53:03,664] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.1, 65.0, 1.0, 1.0, 0.2893204723675715, 1.0, 1.0, 0.2893204723675715, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 664339.8335772344, 664339.8335772349, 178163.4283050548]
[2019-04-27 17:53:03,666] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 17:53:03,669] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0.20092109 0.21363142 0.20496862 0.23701853 0.14346036], sampled 0.9623025359664159
[2019-04-27 17:53:27,762] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-04-27 17:53:27,762] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [17.13333333333333, 97.33333333333333, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 361687.2558973997, 361687.2558974002, 145204.5063027223]
[2019-04-27 17:53:27,764] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 17:53:27,768] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [0.23617467 0.21151972 0.20002824 0.19648497 0.15579239], sampled 0.3969429993369502
[2019-04-27 17:53:32,140] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 4093.0168 2437362673.6868 290.0000
[2019-04-27 17:53:32,174] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 4076.9338 2465207930.1937 339.0000
[2019-04-27 17:53:32,326] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 4037.9234 2681347565.0891 441.0000
[2019-04-27 17:53:32,398] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 4059.9709 2502397205.1002 344.0000
[2019-04-27 17:53:32,421] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 4253.5826 2402849541.0320 258.0000
[2019-04-27 17:53:33,437] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 0, evaluation results [0.0, 4037.923441729062, 2681347565.0891104, 441.0, 4093.016772381131, 2437362673.6868334, 290.0, 4253.582621037442, 2402849541.0319986, 258.0, 4059.9709295219477, 2502397205.1002307, 344.0, 4076.9337734993187, 2465207930.193655, 339.0]
[2019-04-27 17:53:38,177] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.21694148 0.25391158 0.19280957 0.1822265  0.15411092], sum to 1.0000
[2019-04-27 17:53:38,187] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1089
[2019-04-27 17:53:38,195] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1136597.111921567 W.
[2019-04-27 17:53:38,327] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.08333333333334, 40.66666666666667, 1.0, 2.0, 0.8801119221547119, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.968329672486284, 6.9112, 121.9258058303474, 1136597.111921567, 1107341.670231768, 217106.0557144253], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 40200.0000, 
sim time next is 40800.0000, 
raw observation next is [27.26666666666667, 40.33333333333334, 1.0, 2.0, 0.3064348359705046, 1.0, 1.0, 0.3064348359705046, 1.0, 1.0, 0.5063010118005357, 6.911200000000001, 6.9112, 121.94756008, 1135280.26466068, 1135280.26466068, 256632.0017331773], 
processed observation next is [1.0, 0.4782608695652174, 0.5654320987654322, 0.40333333333333343, 1.0, 1.0, 0.17432718567917213, 1.0, 0.5, 0.17432718567917213, 1.0, 0.5, 0.38287626475066955, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.4054572373788143, 0.4054572373788143, 0.4935230802561102], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0482626], dtype=float32), 0.9430591]. 
=============================================
[2019-04-27 17:53:38,871] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [0.21866277 0.2640261  0.16875532 0.20413628 0.14441954], sum to 1.0000
[2019-04-27 17:53:38,881] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3925
[2019-04-27 17:53:38,885] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1465399.245768578 W.
[2019-04-27 17:53:39,008] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.03333333333333, 36.83333333333334, 1.0, 2.0, 0.6175682860799357, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9570459889606326, 6.9112, 6.9112, 121.9260426156618, 1465399.245768578, 1465399.245768578, 291448.4660221664], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 53400.0000, 
sim time next is 54000.0000, 
raw observation next is [30.0, 37.0, 1.0, 2.0, 0.614270512700655, 1.0, 1.0, 0.614270512700655, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1486019.685193537, 1486019.685193537, 276624.0722592935], 
processed observation next is [1.0, 0.6521739130434783, 0.6666666666666666, 0.37, 1.0, 1.0, 0.5407982294055417, 1.0, 0.5, 0.5407982294055417, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.530721316140549, 0.530721316140549, 0.5319693697294107], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.601335], dtype=float32), -0.82943]. 
=============================================
[2019-04-27 17:53:39,036] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[0.1754182 ]
 [0.2823689 ]
 [0.16999064]
 [0.21451114]
 [0.23277955]], R is [[0.28520891]
 [0.28235683]
 [0.76265848]
 [1.21575367]
 [1.20359612]].
[2019-04-27 17:53:46,818] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.0162667  0.1011494  0.05625712 0.79574436 0.03058239], sum to 1.0000
[2019-04-27 17:53:46,827] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3550
[2019-04-27 17:53:46,842] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.06666666666667, 56.00000000000001, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 317541.3434937785, 317541.3434937785, 126251.9989467308], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 192000.0000, 
sim time next is 192600.0000, 
raw observation next is [20.25, 57.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 319345.2341425883, 319345.2341425883, 130120.6917891227], 
processed observation next is [0.0, 0.21739130434782608, 0.3055555555555556, 0.57, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.11405186933663868, 0.11405186933663868, 0.25023209959446674], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.03738274], dtype=float32), -0.47839844]. 
=============================================
[2019-04-27 17:53:52,444] A3C_AGENT_WORKER-Thread-3 INFO:Local step 500, global step 7912: loss 0.6698
[2019-04-27 17:53:52,511] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 500, global step 7913: learning rate 0.0000
[2019-04-27 17:53:52,573] A3C_AGENT_WORKER-Thread-15 INFO:Local step 500, global step 7951: loss 0.3181
[2019-04-27 17:53:52,581] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 500, global step 7954: learning rate 0.0000
[2019-04-27 17:53:52,601] A3C_AGENT_WORKER-Thread-13 INFO:Local step 500, global step 7967: loss 0.2876
[2019-04-27 17:53:52,602] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 500, global step 7968: learning rate 0.0000
[2019-04-27 17:53:52,604] A3C_AGENT_WORKER-Thread-11 INFO:Local step 500, global step 7968: loss 0.4114
[2019-04-27 17:53:52,606] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 500, global step 7968: learning rate 0.0000
[2019-04-27 17:53:52,630] A3C_AGENT_WORKER-Thread-21 INFO:Local step 500, global step 7981: loss 0.1833
[2019-04-27 17:53:52,632] A3C_AGENT_WORKER-Thread-14 INFO:Local step 500, global step 7982: loss 0.1295
[2019-04-27 17:53:52,633] A3C_AGENT_WORKER-Thread-22 INFO:Local step 500, global step 7982: loss 0.0591
[2019-04-27 17:53:52,634] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 500, global step 7982: learning rate 0.0000
[2019-04-27 17:53:52,637] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 500, global step 7983: learning rate 0.0000
[2019-04-27 17:53:52,640] A3C_AGENT_WORKER-Thread-19 INFO:Local step 500, global step 7984: loss 0.1253
[2019-04-27 17:53:52,641] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 500, global step 7984: learning rate 0.0000
[2019-04-27 17:53:52,644] A3C_AGENT_WORKER-Thread-10 INFO:Local step 500, global step 7986: loss 0.1017
[2019-04-27 17:53:52,647] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 500, global step 7986: learning rate 0.0000
[2019-04-27 17:53:52,648] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 500, global step 7986: learning rate 0.0000
[2019-04-27 17:53:52,657] A3C_AGENT_WORKER-Thread-18 INFO:Local step 500, global step 7991: loss 0.0350
[2019-04-27 17:53:52,659] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 500, global step 7991: learning rate 0.0000
[2019-04-27 17:53:52,675] A3C_AGENT_WORKER-Thread-2 INFO:Local step 500, global step 8000: loss 0.0840
[2019-04-27 17:53:52,677] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 500, global step 8000: learning rate 0.0000
[2019-04-27 17:53:52,682] A3C_AGENT_WORKER-Thread-12 INFO:Local step 500, global step 8000: loss 0.0093
[2019-04-27 17:53:52,685] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 500, global step 8001: learning rate 0.0000
[2019-04-27 17:53:52,699] A3C_AGENT_WORKER-Thread-20 INFO:Local step 500, global step 8007: loss 0.0007
[2019-04-27 17:53:52,701] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 500, global step 8008: learning rate 0.0000
[2019-04-27 17:53:52,707] A3C_AGENT_WORKER-Thread-17 INFO:Local step 500, global step 8009: loss 0.0006
[2019-04-27 17:53:52,710] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 500, global step 8012: learning rate 0.0000
[2019-04-27 17:53:52,728] A3C_AGENT_WORKER-Thread-16 INFO:Local step 500, global step 8020: loss 0.0036
[2019-04-27 17:53:52,731] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 500, global step 8021: learning rate 0.0000
[2019-04-27 17:53:52,784] A3C_AGENT_WORKER-Thread-9 INFO:Local step 500, global step 8048: loss 0.0680
[2019-04-27 17:53:52,788] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 500, global step 8048: learning rate 0.0000
[2019-04-27 17:53:59,959] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.1542853e-16 1.0000000e+00 2.0855300e-16 1.1809824e-13 5.6524737e-16], sum to 1.0000
[2019-04-27 17:53:59,967] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2618
[2019-04-27 17:54:00,087] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.7, 43.5, 1.0, 2.0, 0.2950064419536046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 378030.3166560044, 378030.3166560044, 114961.6315932462], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 430200.0000, 
sim time next is 430800.0000, 
raw observation next is [24.43333333333333, 44.66666666666667, 1.0, 2.0, 0.2922182588713689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 374512.6402303048, 374512.6402303048, 114620.1689070849], 
processed observation next is [1.0, 1.0, 0.4604938271604937, 0.4466666666666667, 1.0, 1.0, 0.15740268913258199, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.133754514367966, 0.133754514367966, 0.22042340174439404], 
reward next is 0.7796, 
noisyNet noise sample is [array([0.05571623], dtype=float32), 0.57973766]. 
=============================================
[2019-04-27 17:54:04,539] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.9652888e-13 1.0000000e+00 2.1714063e-12 2.1377765e-10 8.3103625e-13], sum to 1.0000
[2019-04-27 17:54:04,551] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4700
[2019-04-27 17:54:04,681] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.43333333333333, 54.0, 1.0, 2.0, 0.3130455575148792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 398469.8502616474, 398469.8502616469, 117198.5845507922], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 515400.0000, 
sim time next is 516000.0000, 
raw observation next is [23.26666666666667, 55.0, 1.0, 2.0, 0.3134703522328737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 398967.7801920803, 398967.7801920803, 117251.8501396549], 
processed observation next is [1.0, 1.0, 0.41728395061728407, 0.55, 1.0, 1.0, 0.18270280027723057, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14248849292574298, 0.14248849292574298, 0.22548432719164402], 
reward next is 0.7745, 
noisyNet noise sample is [array([-2.1785603], dtype=float32), -1.3497314]. 
=============================================
[2019-04-27 17:54:04,696] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[52.551964]
 [52.50581 ]
 [52.4542  ]
 [52.435818]
 [52.416042]], R is [[52.83755875]
 [53.08380127]
 [53.32743454]
 [53.56782913]
 [53.80507278]].
[2019-04-27 17:54:08,708] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.4977817e-12 1.0000000e+00 1.8984451e-11 7.0112276e-09 2.7849957e-11], sum to 1.0000
[2019-04-27 17:54:08,722] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8907
[2019-04-27 17:54:08,847] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.73333333333333, 34.0, 1.0, 2.0, 0.3890994159111945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 482216.2654563684, 482216.2654563684, 127096.4434108144], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 585600.0000, 
sim time next is 586200.0000, 
raw observation next is [30.56666666666666, 34.5, 1.0, 2.0, 0.3885006365108193, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 481574.8600070205, 481574.8600070205, 127015.5183077476], 
processed observation next is [1.0, 0.782608695652174, 0.687654320987654, 0.345, 1.0, 1.0, 0.27202456727478486, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17199102143107875, 0.17199102143107875, 0.24426061213028383], 
reward next is 0.7557, 
noisyNet noise sample is [array([1.5224862], dtype=float32), 0.65931535]. 
=============================================
[2019-04-27 17:54:09,444] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1000, global step 15912: loss 2.8458
[2019-04-27 17:54:09,448] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1000, global step 15912: learning rate 0.0000
[2019-04-27 17:54:09,491] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1000, global step 15932: loss 3.0708
[2019-04-27 17:54:09,495] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1000, global step 15932: learning rate 0.0000
[2019-04-27 17:54:09,497] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1000, global step 15932: loss 2.9640
[2019-04-27 17:54:09,498] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1000, global step 15932: learning rate 0.0000
[2019-04-27 17:54:09,499] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1000, global step 15932: loss 2.9457
[2019-04-27 17:54:09,502] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1000, global step 15934: learning rate 0.0000
[2019-04-27 17:54:09,527] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1000, global step 15944: loss 3.0445
[2019-04-27 17:54:09,532] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1000, global step 15945: learning rate 0.0000
[2019-04-27 17:54:09,585] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1000, global step 15975: loss 2.8121
[2019-04-27 17:54:09,588] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1000, global step 15975: learning rate 0.0000
[2019-04-27 17:54:09,609] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1000, global step 15986: loss 2.7052
[2019-04-27 17:54:09,613] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1000, global step 15990: learning rate 0.0000
[2019-04-27 17:54:09,619] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1000, global step 15992: loss 2.4772
[2019-04-27 17:54:09,623] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1000, global step 15993: learning rate 0.0000
[2019-04-27 17:54:09,624] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1000, global step 15993: loss 2.3934
[2019-04-27 17:54:09,627] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1000, global step 15993: learning rate 0.0000
[2019-04-27 17:54:09,657] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1000, global step 16009: loss 2.3430
[2019-04-27 17:54:09,661] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1000, global step 16010: learning rate 0.0000
[2019-04-27 17:54:09,662] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1000, global step 16010: loss 2.1874
[2019-04-27 17:54:09,666] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1000, global step 16011: learning rate 0.0000
[2019-04-27 17:54:09,693] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1000, global step 16024: loss 1.9547
[2019-04-27 17:54:09,694] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1000, global step 16024: learning rate 0.0000
[2019-04-27 17:54:09,704] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1000, global step 16026: loss 1.7346
[2019-04-27 17:54:09,706] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1000, global step 16027: learning rate 0.0000
[2019-04-27 17:54:09,715] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1000, global step 16032: loss 1.7772
[2019-04-27 17:54:09,716] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1000, global step 16033: loss 1.5310
[2019-04-27 17:54:09,717] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1000, global step 16033: learning rate 0.0000
[2019-04-27 17:54:09,718] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1000, global step 16033: learning rate 0.0000
[2019-04-27 17:54:09,815] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1000, global step 16084: loss 1.3550
[2019-04-27 17:54:09,821] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1000, global step 16084: learning rate 0.0000
[2019-04-27 17:54:10,184] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.1883556e-15 1.0000000e+00 2.0449357e-15 3.0523713e-12 1.0764515e-14], sum to 1.0000
[2019-04-27 17:54:10,191] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9867
[2019-04-27 17:54:10,195] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 52.0, 1.0, 2.0, 0.3323608842213289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 420686.8856284275, 420686.8856284275, 119645.1242788688], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 608400.0000, 
sim time next is 609000.0000, 
raw observation next is [24.26666666666667, 52.5, 1.0, 2.0, 0.3319300213600501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 420313.7106192245, 420313.7106192249, 119591.1277959754], 
processed observation next is [1.0, 0.043478260869565216, 0.4543209876543211, 0.525, 1.0, 1.0, 0.20467859685720252, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1501120395068659, 0.15011203950686602, 0.22998293806918346], 
reward next is 0.7700, 
noisyNet noise sample is [array([1.1843166], dtype=float32), -0.20581575]. 
=============================================
[2019-04-27 17:54:10,215] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[65.77924 ]
 [65.93828 ]
 [66.12282 ]
 [66.25951 ]
 [66.550224]], R is [[65.83958435]
 [65.95110321]
 [66.06105804]
 [66.16944885]
 [66.27631378]].
[2019-04-27 17:54:11,872] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.6346301e-12 1.0000000e+00 1.2391223e-11 2.4144622e-09 4.1198625e-10], sum to 1.0000
[2019-04-27 17:54:11,877] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8589
[2019-04-27 17:54:11,884] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1357806.123586281 W.
[2019-04-27 17:54:12,004] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.76666666666667, 45.16666666666667, 1.0, 2.0, 0.554690209419101, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9082300461411075, 6.9112, 6.9112, 121.9258293193749, 1357806.123586281, 1357806.123586281, 273489.020184235], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 637800.0000, 
sim time next is 638400.0000, 
raw observation next is [28.13333333333334, 44.33333333333334, 1.0, 2.0, 0.3718974267310613, 1.0, 1.0, 0.3718974267310613, 1.0, 2.0, 0.6010706735460917, 6.911200000000001, 6.9112, 121.94756008, 1341491.854695691, 1341491.85469569, 284445.5222827127], 
processed observation next is [1.0, 0.391304347826087, 0.5975308641975311, 0.4433333333333334, 1.0, 1.0, 0.25225884134650156, 1.0, 0.5, 0.25225884134650156, 1.0, 1.0, 0.5013383419326145, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.47910423381988965, 0.4791042338198893, 0.5470106197744474], 
reward next is 0.4530, 
noisyNet noise sample is [array([-0.2589368], dtype=float32), -0.85068005]. 
=============================================
[2019-04-27 17:54:14,605] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.2141461e-14 1.0000000e+00 6.1611393e-12 1.6384438e-09 3.8440781e-13], sum to 1.0000
[2019-04-27 17:54:14,618] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5488
[2019-04-27 17:54:14,735] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.93333333333333, 35.33333333333334, 1.0, 2.0, 0.3333551984994206, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 422721.3811450418, 422721.3811450414, 119780.8229125952], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 688800.0000, 
sim time next is 689400.0000, 
raw observation next is [27.8, 35.5, 1.0, 2.0, 0.3315409882164033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 420734.7684051611, 420734.7684051611, 119548.7886606814], 
processed observation next is [1.0, 1.0, 0.5851851851851853, 0.355, 1.0, 1.0, 0.2042154621623849, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15026241728755754, 0.15026241728755754, 0.22990151665515654], 
reward next is 0.7701, 
noisyNet noise sample is [array([0.17321406], dtype=float32), 0.038265537]. 
=============================================
[2019-04-27 17:54:21,248] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.8737371e-22 1.0000000e+00 3.2558695e-20 1.0949823e-19 7.8420587e-23], sum to 1.0000
[2019-04-27 17:54:21,255] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5471
[2019-04-27 17:54:21,259] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.65, 56.5, 1.0, 2.0, 0.3619235036006636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 453226.1413370713, 453226.1413370713, 123478.7137969146], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 808200.0000, 
sim time next is 808800.0000, 
raw observation next is [24.93333333333333, 55.66666666666667, 1.0, 2.0, 0.3661683490217849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 457874.0269773283, 457874.0269773283, 124039.0920145435], 
processed observation next is [0.0, 0.34782608695652173, 0.47901234567901224, 0.5566666666666668, 1.0, 1.0, 0.24543851074022013, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16352643820618867, 0.16352643820618867, 0.23853671541258364], 
reward next is 0.7615, 
noisyNet noise sample is [array([-0.2548975], dtype=float32), -1.6158886]. 
=============================================
[2019-04-27 17:54:26,070] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1500, global step 23848: loss 0.0918
[2019-04-27 17:54:26,072] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1500, global step 23850: learning rate 0.0000
[2019-04-27 17:54:26,143] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1500, global step 23883: loss 0.1334
[2019-04-27 17:54:26,147] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1500, global step 23883: learning rate 0.0000
[2019-04-27 17:54:26,185] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1500, global step 23906: loss 0.1890
[2019-04-27 17:54:26,186] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1500, global step 23906: learning rate 0.0000
[2019-04-27 17:54:26,278] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1500, global step 23948: loss 0.0003
[2019-04-27 17:54:26,279] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1500, global step 23948: loss 0.0003
[2019-04-27 17:54:26,280] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1500, global step 23948: learning rate 0.0000
[2019-04-27 17:54:26,284] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1500, global step 23951: learning rate 0.0000
[2019-04-27 17:54:26,307] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1500, global step 23965: loss 0.0052
[2019-04-27 17:54:26,308] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1500, global step 23965: learning rate 0.0000
[2019-04-27 17:54:26,314] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1500, global step 23967: loss 0.0061
[2019-04-27 17:54:26,316] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1500, global step 23967: learning rate 0.0000
[2019-04-27 17:54:26,341] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1500, global step 23980: loss 0.0016
[2019-04-27 17:54:26,345] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1500, global step 23980: learning rate 0.0000
[2019-04-27 17:54:26,388] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1500, global step 24002: loss 0.1260
[2019-04-27 17:54:26,390] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1500, global step 24002: learning rate 0.0000
[2019-04-27 17:54:26,411] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1500, global step 24010: loss 0.0613
[2019-04-27 17:54:26,414] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1500, global step 24011: learning rate 0.0000
[2019-04-27 17:54:26,423] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1500, global step 24016: loss 0.1423
[2019-04-27 17:54:26,428] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1500, global step 24016: learning rate 0.0000
[2019-04-27 17:54:26,444] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1500, global step 24028: loss 0.1909
[2019-04-27 17:54:26,445] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1500, global step 24028: learning rate 0.0000
[2019-04-27 17:54:26,515] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1500, global step 24061: loss 0.0942
[2019-04-27 17:54:26,527] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1500, global step 24064: learning rate 0.0000
[2019-04-27 17:54:26,537] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1500, global step 24071: loss 0.0279
[2019-04-27 17:54:26,542] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1500, global step 24071: learning rate 0.0000
[2019-04-27 17:54:26,544] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1500, global step 24071: loss 0.0956
[2019-04-27 17:54:26,549] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1500, global step 24076: learning rate 0.0000
[2019-04-27 17:54:26,558] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1500, global step 24081: loss 0.0297
[2019-04-27 17:54:26,559] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1500, global step 24081: learning rate 0.0000
[2019-04-27 17:54:28,020] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.2718395e-15 1.0000000e+00 4.2286350e-15 3.0869469e-14 4.8674190e-18], sum to 1.0000
[2019-04-27 17:54:28,034] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1246
[2019-04-27 17:54:28,037] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.96666666666667, 46.33333333333334, 1.0, 2.0, 0.3825008799429552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 477215.2071600215, 477215.207160021, 126249.1967258868], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 930000.0000, 
sim time next is 930600.0000, 
raw observation next is [26.8, 47.0, 1.0, 2.0, 0.3811214651478214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 475594.6298961016, 475594.6298961016, 126060.9792502758], 
processed observation next is [0.0, 0.782608695652174, 0.5481481481481482, 0.47, 1.0, 1.0, 0.26323983946169216, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16985522496289343, 0.16985522496289343, 0.24242496009668424], 
reward next is 0.7576, 
noisyNet noise sample is [array([-1.2393005], dtype=float32), 0.060102522]. 
=============================================
[2019-04-27 17:54:28,465] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-04-27 17:54:28,465] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 17:54:28,467] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 17:54:28,467] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 17:54:28,469] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 17:54:28,469] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 17:54:28,469] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 17:54:28,470] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 17:54:28,471] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 17:54:28,472] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 17:54:28,473] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 17:54:28,491] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run2
[2019-04-27 17:54:28,514] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run2
[2019-04-27 17:54:28,515] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run2
[2019-04-27 17:54:28,515] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run2
[2019-04-27 17:54:28,551] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run2
[2019-04-27 17:54:29,949] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.012830028]
[2019-04-27 17:54:29,950] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.62601598833333, 51.02360122833333, 1.0, 2.0, 0.3686147599962387, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 461814.7030465424, 461814.7030465424, 124385.1764930338]
[2019-04-27 17:54:29,952] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 17:54:29,955] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.1652718e-19 1.0000000e+00 3.3945857e-18 1.6494188e-16 5.9120809e-20], sampled 0.8385960110355097
[2019-04-27 17:54:38,031] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.012830028]
[2019-04-27 17:54:38,032] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.62691061, 36.02578893499999, 1.0, 2.0, 0.3020084520083333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 389282.2372481388, 389282.2372481384, 115812.684973454]
[2019-04-27 17:54:38,035] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 17:54:38,037] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.2659946e-20 1.0000000e+00 2.7954739e-19 1.7503860e-17 3.8615008e-21], sampled 0.20293911012192034
[2019-04-27 17:54:45,694] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.012830028]
[2019-04-27 17:54:45,695] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [16.33262532, 67.86063607, 1.0, 2.0, 0.1931284711864671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 249107.198599252, 249107.198599252, 78098.90913429893]
[2019-04-27 17:54:45,698] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 17:54:45,701] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.1353579e-19 1.0000000e+00 3.5074352e-18 1.6532866e-16 5.6477850e-20], sampled 0.9752561475595931
[2019-04-27 17:55:07,571] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.012830028]
[2019-04-27 17:55:07,573] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.866127095, 35.21730714666667, 1.0, 2.0, 0.3979954015849138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 490892.4902036865, 490892.4902036865, 128284.548166708]
[2019-04-27 17:55:07,573] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 17:55:07,576] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.2499653e-19 1.0000000e+00 4.8781974e-19 2.8502212e-17 7.1526873e-21], sampled 0.14478747899416988
[2019-04-27 17:55:14,964] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.012830028]
[2019-04-27 17:55:14,965] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.6, 81.66666666666667, 1.0, 2.0, 0.5891712127353592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 682331.7982187818, 682331.7982187818, 156748.801354126]
[2019-04-27 17:55:14,967] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 17:55:14,968] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.4050474e-20 1.0000000e+00 3.7983906e-19 2.2453206e-17 5.1069222e-21], sampled 0.5603216004546233
[2019-04-27 17:55:20,630] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.012830028]
[2019-04-27 17:55:20,631] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [34.83333333333334, 42.83333333333333, 1.0, 2.0, 0.9799968232180208, 1.0, 2.0, 0.9799968232180208, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2235798.292213534, 2235798.292213535, 423745.2669410338]
[2019-04-27 17:55:20,633] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 17:55:20,635] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.7443719e-22 1.0000000e+00 9.9283959e-22 1.3519524e-19 8.6977981e-24], sampled 0.5426991568644898
[2019-04-27 17:55:20,636] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2235798.292213534 W.
[2019-04-27 17:55:29,793] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.012830028]
[2019-04-27 17:55:29,795] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.26666666666667, 88.66666666666667, 1.0, 2.0, 0.646478020306377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 737518.0617240599, 737518.0617240599, 166294.6421575098]
[2019-04-27 17:55:29,796] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 17:55:29,799] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.8520022e-21 1.0000000e+00 4.0806920e-20 3.0713537e-18 4.5028196e-22], sampled 0.9603891501673544
[2019-04-27 17:56:14,879] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2184 2120437061.2969 430.0000
[2019-04-27 17:56:14,972] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.6901 2195047582.3563 572.0000
[2019-04-27 17:56:14,983] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8099.2011 2445377682.4312 746.0000
[2019-04-27 17:56:15,019] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-04-27 17:56:15,092] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-04-27 17:56:16,107] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 25000, evaluation results [25000.0, 8099.201055540698, 2445377682.4311814, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.218435439243, 2120437061.2969296, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.690060682284, 2195047582.3563175, 572.0]
[2019-04-27 17:56:18,832] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.7217355e-16 1.0000000e+00 5.1725380e-16 6.4056724e-14 3.8650014e-17], sum to 1.0000
[2019-04-27 17:56:18,840] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8697
[2019-04-27 17:56:18,970] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 56.0, 1.0, 2.0, 0.8958657286721151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.01724405681347, 6.9112, 121.9251769931856, 1170722.798878969, 1116419.149215527, 220486.085477412], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 990000.0000, 
sim time next is 990600.0000, 
raw observation next is [25.03333333333333, 55.83333333333334, 1.0, 2.0, 0.7928275183383027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9259787067847, 987695.0072859253, 987695.0072859253, 197802.0552381644], 
processed observation next is [1.0, 0.4782608695652174, 0.482716049382716, 0.5583333333333335, 1.0, 1.0, 0.7533660932598841, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094617045316526, 0.3527482168878305, 0.3527482168878305, 0.3803885677657008], 
reward next is 0.6196, 
noisyNet noise sample is [array([-0.44821063], dtype=float32), -1.6521397]. 
=============================================
[2019-04-27 17:56:21,499] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.7329868e-21 1.0000000e+00 2.7227749e-23 3.0205254e-22 1.3086661e-23], sum to 1.0000
[2019-04-27 17:56:21,507] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9035
[2019-04-27 17:56:21,639] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.4, 55.0, 1.0, 2.0, 0.2801200936320363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 359264.1537263692, 359264.1537263692, 113154.5201900645], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1037400.0000, 
sim time next is 1038000.0000, 
raw observation next is [22.3, 56.00000000000001, 1.0, 2.0, 0.2824649857660376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 362053.7714594791, 362053.7714594787, 113436.9872218997], 
processed observation next is [1.0, 0.0, 0.38148148148148153, 0.56, 1.0, 1.0, 0.14579164972147338, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1293049183783854, 0.12930491837838526, 0.21814805234980714], 
reward next is 0.7819, 
noisyNet noise sample is [array([0.43500274], dtype=float32), -1.9872279]. 
=============================================
[2019-04-27 17:56:21,657] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[88.69246]
 [89.09974]
 [89.92461]
 [89.91575]
 [89.90713]], R is [[88.48003387]
 [88.37763214]
 [88.27689362]
 [88.17796326]
 [88.08006287]].
[2019-04-27 17:56:25,056] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.0954295e-13 1.0000000e+00 4.0613387e-14 2.9036736e-12 2.4121533e-15], sum to 1.0000
[2019-04-27 17:56:25,062] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6361
[2019-04-27 17:56:25,065] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.05, 47.0, 1.0, 2.0, 0.4474072465165388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 562044.0683113137, 562044.0683113137, 135643.3200456691], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1098600.0000, 
sim time next is 1099200.0000, 
raw observation next is [25.8, 48.0, 1.0, 2.0, 0.3377488937709054, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 424799.4226510472, 424799.4226510472, 120311.3034324183], 
processed observation next is [1.0, 0.7391304347826086, 0.5111111111111112, 0.48, 1.0, 1.0, 0.21160582591774452, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15171407951823113, 0.15171407951823113, 0.23136789121618903], 
reward next is 0.7686, 
noisyNet noise sample is [array([1.0740037], dtype=float32), -1.0123074]. 
=============================================
[2019-04-27 17:56:25,172] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.6175455e-12 1.0000000e+00 2.3017799e-12 4.7235334e-11 2.0754242e-11], sum to 1.0000
[2019-04-27 17:56:25,181] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6338
[2019-04-27 17:56:25,310] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.53333333333333, 43.66666666666667, 1.0, 2.0, 0.5102141387242976, 1.0, 1.0, 0.5102141387242976, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9258043020124, 1260536.619405846, 1260536.619405846, 242272.9954092411], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1093800.0000, 
sim time next is 1094400.0000, 
raw observation next is [26.5, 44.0, 1.0, 2.0, 0.956589308921441, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.45932682021514, 6.9112, 121.9237700178762, 1479131.394658672, 1198446.703510802, 234870.398186342], 
processed observation next is [1.0, 0.6956521739130435, 0.5370370370370371, 0.44, 1.0, 1.0, 0.9483206058588584, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.054812682021514014, 0.0, 0.8094470411341746, 0.5282612123780971, 0.4280166798252864, 0.4516738426660423], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.97968054], dtype=float32), 0.62550753]. 
=============================================
[2019-04-27 17:56:25,605] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.9870918e-16 1.0000000e+00 3.0502899e-18 5.4144726e-15 7.0301840e-18], sum to 1.0000
[2019-04-27 17:56:25,614] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9974
[2019-04-27 17:56:25,739] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 56.66666666666666, 1.0, 2.0, 0.3361432072151349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 424338.2679815418, 424338.2679815418, 120123.0199096897], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1104000.0000, 
sim time next is 1104600.0000, 
raw observation next is [23.55, 57.83333333333334, 1.0, 2.0, 0.3350127987956335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 423093.8315448692, 423093.8315448696, 119978.4113975126], 
processed observation next is [1.0, 0.782608695652174, 0.4277777777777778, 0.5783333333333335, 1.0, 1.0, 0.2083485699948018, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15110493983745327, 0.15110493983745343, 0.23072771422598576], 
reward next is 0.7693, 
noisyNet noise sample is [array([-0.28582844], dtype=float32), -0.26300314]. 
=============================================
[2019-04-27 17:56:28,376] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.2397216e-17 1.0000000e+00 4.8018586e-17 8.2455957e-17 3.3872643e-18], sum to 1.0000
[2019-04-27 17:56:28,383] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0114
[2019-04-27 17:56:28,499] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.46666666666667, 66.83333333333334, 1.0, 2.0, 0.5678287166299141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 727826.5450798428, 727826.5450798428, 155072.1664190622], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1156200.0000, 
sim time next is 1156800.0000, 
raw observation next is [20.53333333333333, 66.66666666666667, 1.0, 2.0, 0.5398338731661454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 691632.0835058815, 691632.0835058815, 150345.0981167547], 
processed observation next is [1.0, 0.391304347826087, 0.3160493827160493, 0.6666666666666667, 1.0, 1.0, 0.45218318234064925, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24701145839495767, 0.24701145839495767, 0.28912518868606674], 
reward next is 0.7109, 
noisyNet noise sample is [array([-0.11471349], dtype=float32), 0.9117863]. 
=============================================
[2019-04-27 17:56:30,793] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2000, global step 31851: loss 0.0984
[2019-04-27 17:56:30,796] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2000, global step 31851: learning rate 0.0000
[2019-04-27 17:56:30,858] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2000, global step 31881: loss 0.1126
[2019-04-27 17:56:30,858] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2000, global step 31881: loss 0.0624
[2019-04-27 17:56:30,861] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2000, global step 31882: learning rate 0.0000
[2019-04-27 17:56:30,862] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2000, global step 31881: learning rate 0.0000
[2019-04-27 17:56:30,907] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2000, global step 31901: loss 0.0299
[2019-04-27 17:56:30,910] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2000, global step 31901: learning rate 0.0000
[2019-04-27 17:56:30,992] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2000, global step 31942: loss 0.0048
[2019-04-27 17:56:30,995] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2000, global step 31942: learning rate 0.0000
[2019-04-27 17:56:31,048] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2000, global step 31965: loss 0.0724
[2019-04-27 17:56:31,050] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2000, global step 31965: learning rate 0.0000
[2019-04-27 17:56:31,063] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2000, global step 31972: loss 0.1158
[2019-04-27 17:56:31,067] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2000, global step 31972: learning rate 0.0000
[2019-04-27 17:56:31,083] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2000, global step 31981: loss 0.1967
[2019-04-27 17:56:31,085] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2000, global step 31981: learning rate 0.0000
[2019-04-27 17:56:31,114] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2000, global step 31998: loss 0.1032
[2019-04-27 17:56:31,117] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2000, global step 31999: learning rate 0.0000
[2019-04-27 17:56:31,119] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2000, global step 32000: loss 0.2216
[2019-04-27 17:56:31,122] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2000, global step 32000: learning rate 0.0000
[2019-04-27 17:56:31,140] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2000, global step 32012: loss 0.2172
[2019-04-27 17:56:31,143] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2000, global step 32013: learning rate 0.0000
[2019-04-27 17:56:31,168] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2000, global step 32029: loss 0.1599
[2019-04-27 17:56:31,170] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2000, global step 32029: learning rate 0.0000
[2019-04-27 17:56:31,195] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2000, global step 32042: loss 0.1805
[2019-04-27 17:56:31,196] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2000, global step 32042: learning rate 0.0000
[2019-04-27 17:56:31,345] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2000, global step 32116: loss 0.0127
[2019-04-27 17:56:31,349] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2000, global step 32118: learning rate 0.0000
[2019-04-27 17:56:31,355] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2000, global step 32121: loss 0.0620
[2019-04-27 17:56:31,357] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2000, global step 32122: learning rate 0.0000
[2019-04-27 17:56:31,394] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2000, global step 32135: loss 0.1131
[2019-04-27 17:56:31,395] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2000, global step 32136: learning rate 0.0000
[2019-04-27 17:56:32,975] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8771485e-21 1.0000000e+00 1.3552078e-23 2.0078264e-21 3.2142273e-23], sum to 1.0000
[2019-04-27 17:56:32,983] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7411
[2019-04-27 17:56:32,991] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.2, 91.0, 1.0, 2.0, 0.3084140856588261, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 392521.0456674654, 392521.0456674654, 116617.2503572089], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1231200.0000, 
sim time next is 1231800.0000, 
raw observation next is [18.28333333333333, 90.66666666666667, 1.0, 2.0, 0.3298307830705286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 419582.1487580687, 419582.1487580687, 119335.2153512309], 
processed observation next is [1.0, 0.2608695652173913, 0.23271604938271598, 0.9066666666666667, 1.0, 1.0, 0.2021795036553912, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14985076741359596, 0.14985076741359596, 0.2294907987523671], 
reward next is 0.7705, 
noisyNet noise sample is [array([0.15934925], dtype=float32), -1.1150396]. 
=============================================
[2019-04-27 17:56:43,422] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.2009921e-18 1.0000000e+00 4.7320424e-20 3.1001220e-18 7.8509605e-20], sum to 1.0000
[2019-04-27 17:56:43,433] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9581
[2019-04-27 17:56:43,439] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.25, 26.83333333333333, 1.0, 2.0, 0.3624490010122657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 456916.8465035775, 456916.8465035775, 123594.4009224252], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1422600.0000, 
sim time next is 1423200.0000, 
raw observation next is [31.40000000000001, 26.66666666666667, 1.0, 2.0, 0.3629684655944183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 457226.832503281, 457226.832503281, 123659.856803491], 
processed observation next is [0.0, 0.4782608695652174, 0.7185185185185189, 0.2666666666666667, 1.0, 1.0, 0.24162912570764086, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16329529732260037, 0.16329529732260037, 0.23780741692979038], 
reward next is 0.7622, 
noisyNet noise sample is [array([-0.7631932], dtype=float32), -0.19797184]. 
=============================================
[2019-04-27 17:56:43,660] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.198525e-18 1.000000e+00 7.738662e-18 9.470184e-18 8.295150e-19], sum to 1.0000
[2019-04-27 17:56:43,673] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9975
[2019-04-27 17:56:43,680] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.7, 26.33333333333334, 1.0, 2.0, 0.3663490734150568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 460774.7643392621, 460774.7643392621, 124106.3328404302], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1424400.0000, 
sim time next is 1425000.0000, 
raw observation next is [31.85, 26.16666666666667, 1.0, 2.0, 0.368407423156959, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 463004.6381789575, 463004.6381789575, 124379.8669052394], 
processed observation next is [0.0, 0.4782608695652174, 0.7351851851851853, 0.2616666666666667, 1.0, 1.0, 0.24810407518685598, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1653587993496277, 0.1653587993496277, 0.23919205174084499], 
reward next is 0.7608, 
noisyNet noise sample is [array([0.43089995], dtype=float32), 0.120827064]. 
=============================================
[2019-04-27 17:56:43,691] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[74.39809 ]
 [74.38746 ]
 [74.347466]
 [74.32024 ]
 [74.27521 ]], R is [[74.43662262]
 [74.45359802]
 [74.47087097]
 [74.48835754]
 [74.50579834]].
[2019-04-27 17:56:46,211] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.2887714e-14 1.0000000e+00 9.8683192e-15 1.2377550e-14 2.3315254e-16], sum to 1.0000
[2019-04-27 17:56:46,220] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7315
[2019-04-27 17:56:46,224] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.31666666666667, 52.16666666666666, 1.0, 2.0, 0.3344719377437321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 423637.9964626726, 423637.9964626721, 119921.0885101011], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1473000.0000, 
sim time next is 1473600.0000, 
raw observation next is [24.03333333333333, 53.33333333333334, 1.0, 2.0, 0.332243242708498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 421065.4186234567, 421065.4186234563, 119634.8569318191], 
processed observation next is [0.0, 0.043478260869565216, 0.4456790123456789, 0.5333333333333334, 1.0, 1.0, 0.20505147941487856, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15038050665123454, 0.1503805066512344, 0.23006703256119057], 
reward next is 0.7699, 
noisyNet noise sample is [array([-0.32487217], dtype=float32), -0.0012210325]. 
=============================================
[2019-04-27 17:56:47,276] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2500, global step 39820: loss 0.1635
[2019-04-27 17:56:47,278] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2500, global step 39820: learning rate 0.0000
[2019-04-27 17:56:47,406] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2500, global step 39883: loss 0.0799
[2019-04-27 17:56:47,414] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2500, global step 39886: learning rate 0.0000
[2019-04-27 17:56:47,424] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2500, global step 39890: loss 0.1968
[2019-04-27 17:56:47,428] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2500, global step 39892: learning rate 0.0000
[2019-04-27 17:56:47,497] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2500, global step 39924: loss 0.0246
[2019-04-27 17:56:47,499] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2500, global step 39925: learning rate 0.0000
[2019-04-27 17:56:47,513] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2500, global step 39933: loss 0.0006
[2019-04-27 17:56:47,517] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2500, global step 39935: learning rate 0.0000
[2019-04-27 17:56:47,604] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2500, global step 39979: loss 0.0140
[2019-04-27 17:56:47,607] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2500, global step 39980: learning rate 0.0000
[2019-04-27 17:56:47,620] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2500, global step 39986: loss 0.1092
[2019-04-27 17:56:47,622] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2500, global step 39986: loss 0.0668
[2019-04-27 17:56:47,624] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2500, global step 39986: learning rate 0.0000
[2019-04-27 17:56:47,625] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2500, global step 39988: loss 0.1193
[2019-04-27 17:56:47,626] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2500, global step 39988: learning rate 0.0000
[2019-04-27 17:56:47,628] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2500, global step 39988: learning rate 0.0000
[2019-04-27 17:56:47,672] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2500, global step 40008: loss 0.0901
[2019-04-27 17:56:47,678] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2500, global step 40011: learning rate 0.0000
[2019-04-27 17:56:47,692] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2500, global step 40018: loss 0.0623
[2019-04-27 17:56:47,694] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2500, global step 40020: learning rate 0.0000
[2019-04-27 17:56:47,709] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2500, global step 40028: loss 0.2242
[2019-04-27 17:56:47,714] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2500, global step 40030: learning rate 0.0000
[2019-04-27 17:56:47,744] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2500, global step 40045: loss 0.1096
[2019-04-27 17:56:47,745] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2500, global step 40045: learning rate 0.0000
[2019-04-27 17:56:47,748] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2500, global step 40046: loss 0.0740
[2019-04-27 17:56:47,752] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2500, global step 40048: learning rate 0.0000
[2019-04-27 17:56:47,894] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2500, global step 40117: loss 0.0174
[2019-04-27 17:56:47,895] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2500, global step 40117: learning rate 0.0000
[2019-04-27 17:56:47,943] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2500, global step 40141: loss 0.1124
[2019-04-27 17:56:47,946] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2500, global step 40142: learning rate 0.0000
[2019-04-27 17:56:52,161] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.7974528e-18 1.0000000e+00 1.2923540e-16 4.1666308e-17 1.1187374e-17], sum to 1.0000
[2019-04-27 17:56:52,173] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4208
[2019-04-27 17:56:52,177] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.41666666666667, 65.5, 1.0, 2.0, 0.4260652149790158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 537272.7089941041, 537272.7089941036, 132518.2774377753], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1581000.0000, 
sim time next is 1581600.0000, 
raw observation next is [22.63333333333333, 64.0, 1.0, 2.0, 0.3881047563349218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 489495.7460383771, 489495.7460383771, 127108.6077645705], 
processed observation next is [1.0, 0.30434782608695654, 0.393827160493827, 0.64, 1.0, 1.0, 0.2715532813510974, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1748199092994204, 0.1748199092994204, 0.24443963031648172], 
reward next is 0.7556, 
noisyNet noise sample is [array([-0.72596353], dtype=float32), 0.17131394]. 
=============================================
[2019-04-27 17:56:53,788] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.9710021e-06 9.9999356e-01 2.5448328e-06 1.8108007e-06 1.2483875e-07], sum to 1.0000
[2019-04-27 17:56:53,794] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6952
[2019-04-27 17:56:53,798] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.83333333333334, 41.83333333333334, 1.0, 2.0, 0.313055262452515, 1.0, 1.0, 0.313055262452515, 1.0, 1.0, 0.5110622507935934, 6.9112, 6.9112, 121.94756008, 1145342.21054159, 1145342.21054159, 259908.6534960542], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1613400.0000, 
sim time next is 1614000.0000, 
raw observation next is [27.86666666666667, 41.66666666666667, 1.0, 2.0, 0.8845697423765628, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.912604926550821, 6.9112, 121.9259128368886, 1097721.806682754, 1097002.359483608, 217776.8888076727], 
processed observation next is [1.0, 0.6956521739130435, 0.5876543209876545, 0.41666666666666674, 1.0, 1.0, 0.8625830266387653, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.00014049265508209174, 0.0, 0.8094612672240423, 0.3920435023866979, 0.39178655695843145, 0.4188017092455244], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.38654014], dtype=float32), -0.527105]. 
=============================================
[2019-04-27 17:56:53,814] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[21.697018]
 [21.919954]
 [21.878613]
 [21.601753]
 [21.574512]], R is [[21.94202995]
 [21.72261047]
 [21.50538445]
 [21.82693291]
 [21.60866356]].
[2019-04-27 17:56:54,688] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.6210058e-15 1.0000000e+00 6.3903574e-14 2.5191093e-13 1.0373469e-16], sum to 1.0000
[2019-04-27 17:56:54,696] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6042
[2019-04-27 17:56:54,700] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.83333333333334, 48.5, 1.0, 2.0, 0.3521072726216549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 442474.4928361183, 442474.4928361183, 122192.7124491864], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1626600.0000, 
sim time next is 1627200.0000, 
raw observation next is [25.7, 49.0, 1.0, 2.0, 0.3495136156313136, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 439350.7593225829, 439350.7593225824, 121851.1801267708], 
processed observation next is [1.0, 0.8695652173913043, 0.5074074074074074, 0.49, 1.0, 1.0, 0.22561144718013526, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15691098547235105, 0.15691098547235086, 0.23432919255148232], 
reward next is 0.7657, 
noisyNet noise sample is [array([-0.07356022], dtype=float32), -1.4017458]. 
=============================================
[2019-04-27 17:56:55,870] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.8254564e-12 1.0000000e+00 4.1121845e-10 1.5176731e-09 1.4981187e-13], sum to 1.0000
[2019-04-27 17:56:55,877] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5990
[2019-04-27 17:56:56,010] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.86666666666667, 65.0, 1.0, 2.0, 0.3203261706314846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 406688.9905649445, 406688.990564944, 118113.0995051569], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1647600.0000, 
sim time next is 1648200.0000, 
raw observation next is [21.78333333333333, 65.5, 1.0, 2.0, 0.3157075796230025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 400852.4696627439, 400852.4696627439, 117527.9327946904], 
processed observation next is [1.0, 0.043478260869565216, 0.3623456790123456, 0.655, 1.0, 1.0, 0.18536616621786012, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14316159630812283, 0.14316159630812283, 0.22601525537440462], 
reward next is 0.7740, 
noisyNet noise sample is [array([1.1517549], dtype=float32), -1.3835802]. 
=============================================
[2019-04-27 17:56:57,919] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.6263191e-16 1.0000000e+00 8.4074037e-14 3.0302769e-15 1.3055722e-19], sum to 1.0000
[2019-04-27 17:56:57,931] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2050
[2019-04-27 17:56:58,001] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.7244440e-18 1.0000000e+00 3.4960560e-17 3.4882612e-18 1.2350864e-20], sum to 1.0000
[2019-04-27 17:56:58,004] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8228
[2019-04-27 17:56:58,060] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.7, 81.0, 1.0, 2.0, 0.6943178688492355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 879710.0721332314, 879710.0721332314, 178125.2616745973], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1679400.0000, 
sim time next is 1680000.0000, 
raw observation next is [19.76666666666667, 80.66666666666666, 1.0, 2.0, 0.6327327726035314, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 801544.2244172244, 801544.224417224, 166524.9951579104], 
processed observation next is [1.0, 0.43478260869565216, 0.2876543209876544, 0.8066666666666665, 1.0, 1.0, 0.5627771102422994, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.286265794434723, 0.28626579443472283, 0.32024037530367383], 
reward next is 0.6798, 
noisyNet noise sample is [array([-0.75449324], dtype=float32), -1.050793]. 
=============================================
[2019-04-27 17:56:58,193] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.81666666666667, 76.66666666666667, 1.0, 2.0, 0.7499221031455706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 944672.6232351062, 944672.6232351062, 189109.110897298], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1684200.0000, 
sim time next is 1684800.0000, 
raw observation next is [21.0, 76.0, 1.0, 2.0, 0.7606415708105178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 957157.3111227534, 957157.3111227534, 191286.4759537776], 
processed observation next is [1.0, 0.5217391304347826, 0.3333333333333333, 0.76, 1.0, 1.0, 0.7150494890601402, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3418418968295548, 0.3418418968295548, 0.3678586076034185], 
reward next is 0.6321, 
noisyNet noise sample is [array([0.68860257], dtype=float32), 1.0053738]. 
=============================================
[2019-04-27 17:56:58,194] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[73.96583]
 [73.96623]
 [73.95085]
 [74.00696]
 [73.91835]], R is [[73.97743225]
 [73.89510345]
 [73.81015778]
 [73.72237396]
 [73.68608093]].
[2019-04-27 17:57:04,148] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3000, global step 47849: loss 1.9146
[2019-04-27 17:57:04,149] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3000, global step 47850: learning rate 0.0000
[2019-04-27 17:57:04,180] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3000, global step 47865: loss 1.5014
[2019-04-27 17:57:04,185] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3000, global step 47867: learning rate 0.0000
[2019-04-27 17:57:04,231] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3000, global step 47887: loss 0.8400
[2019-04-27 17:57:04,234] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3000, global step 47888: learning rate 0.0000
[2019-04-27 17:57:04,292] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3000, global step 47915: loss 2.3986
[2019-04-27 17:57:04,295] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3000, global step 47917: learning rate 0.0000
[2019-04-27 17:57:04,335] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3000, global step 47938: loss 1.1969
[2019-04-27 17:57:04,339] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3000, global step 47938: learning rate 0.0000
[2019-04-27 17:57:04,356] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3000, global step 47949: loss 0.6496
[2019-04-27 17:57:04,358] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3000, global step 47949: learning rate 0.0000
[2019-04-27 17:57:04,367] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3000, global step 47952: loss 0.8022
[2019-04-27 17:57:04,370] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3000, global step 47953: learning rate 0.0000
[2019-04-27 17:57:04,400] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3000, global step 47968: loss 2.8253
[2019-04-27 17:57:04,402] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3000, global step 47969: learning rate 0.0000
[2019-04-27 17:57:04,421] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3000, global step 47981: loss 0.3981
[2019-04-27 17:57:04,423] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3000, global step 47981: learning rate 0.0000
[2019-04-27 17:57:04,430] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3000, global step 47984: loss 0.7797
[2019-04-27 17:57:04,431] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3000, global step 47984: learning rate 0.0000
[2019-04-27 17:57:04,545] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3000, global step 48043: loss 0.1215
[2019-04-27 17:57:04,547] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3000, global step 48044: learning rate 0.0000
[2019-04-27 17:57:04,558] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3000, global step 48051: loss 0.0624
[2019-04-27 17:57:04,562] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3000, global step 48052: learning rate 0.0000
[2019-04-27 17:57:04,578] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3000, global step 48060: loss 0.0792
[2019-04-27 17:57:04,582] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3000, global step 48061: learning rate 0.0000
[2019-04-27 17:57:04,584] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3000, global step 48061: loss 0.4140
[2019-04-27 17:57:04,587] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3000, global step 48061: learning rate 0.0000
[2019-04-27 17:57:04,766] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3000, global step 48146: loss 0.0530
[2019-04-27 17:57:04,769] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3000, global step 48147: learning rate 0.0000
[2019-04-27 17:57:04,780] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3000, global step 48150: loss 0.0102
[2019-04-27 17:57:04,783] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3000, global step 48151: learning rate 0.0000
[2019-04-27 17:57:08,623] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-04-27 17:57:08,625] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 17:57:08,627] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 17:57:08,628] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 17:57:08,629] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 17:57:08,630] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 17:57:08,631] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 17:57:08,631] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 17:57:08,632] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 17:57:08,630] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 17:57:08,638] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 17:57:08,648] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run3
[2019-04-27 17:57:08,667] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run3
[2019-04-27 17:57:08,690] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run3
[2019-04-27 17:57:08,691] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run3
[2019-04-27 17:57:08,707] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run3
[2019-04-27 17:57:34,997] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.020159682]
[2019-04-27 17:57:34,998] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.11688138333334, 88.68069331999999, 1.0, 2.0, 0.3611496769666339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 450956.765824686, 450956.765824686, 123351.720644206]
[2019-04-27 17:57:35,000] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 17:57:35,004] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.4460270e-12 1.0000000e+00 1.6408042e-10 1.3121658e-11 1.5434145e-13], sampled 0.7590276587436906
[2019-04-27 17:57:35,935] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.020159682]
[2019-04-27 17:57:35,935] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [20.16666666666667, 99.0, 1.0, 2.0, 0.6354350159853019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 778200.129819299, 778200.129819299, 166473.6408489744]
[2019-04-27 17:57:35,938] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 17:57:35,941] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.1170719e-12 1.0000000e+00 2.3241976e-10 1.9152773e-11 2.3925352e-13], sampled 0.9329892920758429
[2019-04-27 17:58:39,409] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.020159682]
[2019-04-27 17:58:39,409] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.90768871666667, 70.93309473333333, 1.0, 2.0, 0.6051844534932246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 692451.1515644795, 692451.1515644795, 159108.8640733229]
[2019-04-27 17:58:39,412] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 17:58:39,415] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.8453986e-12 1.0000000e+00 1.9809476e-10 1.6322383e-11 2.0440642e-13], sampled 0.47231052676567775
[2019-04-27 17:58:40,849] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.020159682]
[2019-04-27 17:58:40,850] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.62649103166666, 60.00224979166666, 1.0, 2.0, 0.5627798698041436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 657269.8980136942, 657269.8980136937, 152538.5787591734]
[2019-04-27 17:58:40,852] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 17:58:40,854] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.3071490e-12 1.0000000e+00 3.3194125e-10 2.8061161e-11 3.8928274e-13], sampled 0.1349560949343961
[2019-04-27 17:58:44,900] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.020159682]
[2019-04-27 17:58:44,902] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.08333333333334, 72.66666666666667, 1.0, 2.0, 0.7269632478093473, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 896763.4188947653, 896763.4188947653, 184081.4928989716]
[2019-04-27 17:58:44,903] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 17:58:44,906] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.0780161e-12 1.0000000e+00 3.9616024e-10 3.5136213e-11 4.9868334e-13], sampled 0.3059501460860138
[2019-04-27 17:58:50,054] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.020159682]
[2019-04-27 17:58:50,056] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [17.16666666666667, 96.66666666666666, 1.0, 2.0, 0.2846622626375814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 363840.5364266154, 363840.536426615, 113702.5179202685]
[2019-04-27 17:58:50,057] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 17:58:50,061] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.3400170e-12 1.0000000e+00 1.5800541e-10 1.2321697e-11 1.4370162e-13], sampled 0.9418522568790392
[2019-04-27 17:58:54,972] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-04-27 17:58:54,973] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8770.2612 2170674121.3264 493.0000
[2019-04-27 17:58:55,036] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.6901 2195047582.3563 572.0000
[2019-04-27 17:58:55,094] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8099.1409 2445383265.7936 746.0000
[2019-04-27 17:58:55,112] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8921.9027 2120509233.4671 430.0000
[2019-04-27 17:58:56,125] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 50000, evaluation results [50000.0, 8099.1409108992975, 2445383265.7936034, 746.0, 8770.261224165219, 2170674121.3264093, 493.0, 8921.902705613917, 2120509233.4670584, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.690060682284, 2195047582.3563175, 572.0]
[2019-04-27 17:59:03,342] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2263806e-15 1.0000000e+00 6.8627477e-14 8.4777648e-16 6.0450952e-16], sum to 1.0000
[2019-04-27 17:59:03,358] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3098
[2019-04-27 17:59:03,365] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666667, 84.83333333333333, 1.0, 2.0, 0.3716151298074654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 463422.1618892945, 463422.161889294, 124754.0957452766], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2011800.0000, 
sim time next is 2012400.0000, 
raw observation next is [20.8, 84.0, 1.0, 2.0, 0.3722370767566662, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 464033.1602484185, 464033.1602484185, 124835.5308662179], 
processed observation next is [0.0, 0.30434782608695654, 0.32592592592592595, 0.84, 1.0, 1.0, 0.2526631866150788, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16572612866014946, 0.16572612866014946, 0.24006832858888058], 
reward next is 0.7599, 
noisyNet noise sample is [array([0.50478923], dtype=float32), -0.56125724]. 
=============================================
[2019-04-27 17:59:05,506] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.3249042e-20 1.0000000e+00 1.2992000e-16 1.5406783e-18 1.6450921e-20], sum to 1.0000
[2019-04-27 17:59:05,513] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7413
[2019-04-27 17:59:05,649] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 63.0, 1.0, 2.0, 0.5932034718064171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 682340.0506407066, 682340.0506407066, 157221.1496194667], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2047200.0000, 
sim time next is 2047800.0000, 
raw observation next is [29.05, 63.0, 1.0, 2.0, 0.5948281381996406, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 683537.6413546926, 683537.6413546926, 157467.6369226745], 
processed observation next is [0.0, 0.6956521739130435, 0.6314814814814815, 0.63, 1.0, 1.0, 0.5176525454757627, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2441205861981045, 0.2441205861981045, 0.30282237869745093], 
reward next is 0.6972, 
noisyNet noise sample is [array([-0.2555815], dtype=float32), -0.21777123]. 
=============================================
[2019-04-27 17:59:05,931] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.8162150e-17 1.0000000e+00 3.0836455e-14 1.0932483e-15 2.5419629e-17], sum to 1.0000
[2019-04-27 17:59:05,940] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8319
[2019-04-27 17:59:05,950] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.13333333333333, 68.33333333333334, 1.0, 2.0, 0.6042625201487022, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 693246.7419008204, 693246.7419008204, 159039.3160020027], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2053200.0000, 
sim time next is 2053800.0000, 
raw observation next is [28.0, 69.0, 1.0, 2.0, 0.6052967801974493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 694655.151096548, 694655.151096548, 159229.2188596955], 
processed observation next is [0.0, 0.782608695652174, 0.5925925925925926, 0.69, 1.0, 1.0, 0.5301152145207729, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24809112539162426, 0.24809112539162426, 0.30621003626864524], 
reward next is 0.6938, 
noisyNet noise sample is [array([-1.9215379], dtype=float32), 0.65043503]. 
=============================================
[2019-04-27 17:59:06,051] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5331286e-16 1.0000000e+00 8.3782930e-16 1.9012605e-15 3.6472847e-16], sum to 1.0000
[2019-04-27 17:59:06,063] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2826
[2019-04-27 17:59:06,071] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.35, 63.0, 1.0, 2.0, 0.5570105229722229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 648744.0206666612, 648744.0206666607, 151500.2607495496], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2040600.0000, 
sim time next is 2041200.0000, 
raw observation next is [28.4, 63.0, 1.0, 2.0, 0.5604053109397028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 652087.342275512, 652087.3422755116, 152037.1697527372], 
processed observation next is [0.0, 0.6521739130434783, 0.6074074074074074, 0.63, 1.0, 1.0, 0.4766729892139319, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23288833652696858, 0.23288833652696841, 0.29237917260141766], 
reward next is 0.7076, 
noisyNet noise sample is [array([-0.7704835], dtype=float32), 0.27857763]. 
=============================================
[2019-04-27 17:59:08,339] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3500, global step 55784: loss 0.0030
[2019-04-27 17:59:08,343] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3500, global step 55784: learning rate 0.0000
[2019-04-27 17:59:08,512] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3500, global step 55866: loss 0.0363
[2019-04-27 17:59:08,519] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3500, global step 55867: learning rate 0.0000
[2019-04-27 17:59:08,535] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3500, global step 55878: loss 0.0193
[2019-04-27 17:59:08,539] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3500, global step 55879: learning rate 0.0000
[2019-04-27 17:59:08,546] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3500, global step 55881: loss 0.0623
[2019-04-27 17:59:08,547] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3500, global step 55881: learning rate 0.0000
[2019-04-27 17:59:08,574] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3500, global step 55896: loss 0.1143
[2019-04-27 17:59:08,576] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3500, global step 55897: learning rate 0.0000
[2019-04-27 17:59:08,600] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3500, global step 55907: loss 0.1276
[2019-04-27 17:59:08,601] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3500, global step 55907: learning rate 0.0000
[2019-04-27 17:59:08,687] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3500, global step 55949: loss 0.0431
[2019-04-27 17:59:08,690] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3500, global step 55950: learning rate 0.0000
[2019-04-27 17:59:08,708] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3500, global step 55958: loss 0.0287
[2019-04-27 17:59:08,710] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3500, global step 55959: learning rate 0.0000
[2019-04-27 17:59:08,813] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3500, global step 56005: loss 0.0024
[2019-04-27 17:59:08,820] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3500, global step 56008: learning rate 0.0000
[2019-04-27 17:59:08,823] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3500, global step 56010: loss 0.0328
[2019-04-27 17:59:08,826] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3500, global step 56011: learning rate 0.0000
[2019-04-27 17:59:08,920] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3500, global step 56057: loss 0.1295
[2019-04-27 17:59:08,922] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3500, global step 56057: learning rate 0.0000
[2019-04-27 17:59:08,939] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3500, global step 56067: loss 0.1860
[2019-04-27 17:59:08,942] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3500, global step 56068: learning rate 0.0000
[2019-04-27 17:59:08,954] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3500, global step 56073: loss 0.2632
[2019-04-27 17:59:08,956] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3500, global step 56074: learning rate 0.0000
[2019-04-27 17:59:09,009] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3500, global step 56101: loss 0.0376
[2019-04-27 17:59:09,011] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3500, global step 56101: learning rate 0.0000
[2019-04-27 17:59:09,060] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3500, global step 56121: loss 0.0209
[2019-04-27 17:59:09,063] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3500, global step 56121: learning rate 0.0000
[2019-04-27 17:59:09,287] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3500, global step 56237: loss 0.1476
[2019-04-27 17:59:09,290] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3500, global step 56237: learning rate 0.0000
[2019-04-27 17:59:11,173] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.0009262e-19 1.0000000e+00 1.5028624e-15 1.8113713e-18 3.4299109e-19], sum to 1.0000
[2019-04-27 17:59:11,178] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1355
[2019-04-27 17:59:11,185] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.83333333333334, 46.0, 1.0, 2.0, 0.5493345185780555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 641942.7650608333, 641942.7650608328, 150325.7017229918], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2133600.0000, 
sim time next is 2134200.0000, 
raw observation next is [31.91666666666667, 45.5, 1.0, 2.0, 0.5471608350031429, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 639865.7078387914, 639865.7078387914, 149988.087055216], 
processed observation next is [0.0, 0.6956521739130435, 0.7376543209876545, 0.455, 1.0, 1.0, 0.46090575595612254, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22852346708528265, 0.22852346708528265, 0.28843862895233846], 
reward next is 0.7116, 
noisyNet noise sample is [array([-0.18539503], dtype=float32), 0.48376524]. 
=============================================
[2019-04-27 17:59:12,085] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.3487959e-17 1.0000000e+00 9.2165138e-15 3.3260995e-17 3.1524364e-20], sum to 1.0000
[2019-04-27 17:59:12,091] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8119
[2019-04-27 17:59:12,095] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 86.0, 1.0, 2.0, 0.5760052368716099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 668736.1097098041, 668736.1097098041, 154586.1788145438], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2163600.0000, 
sim time next is 2164200.0000, 
raw observation next is [24.71666666666667, 86.5, 1.0, 2.0, 0.5769438664895896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 669866.5089392207, 669866.5089392207, 154746.6288275546], 
processed observation next is [1.0, 0.043478260869565216, 0.4709876543209877, 0.865, 1.0, 1.0, 0.49636174582094, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23923803890686454, 0.23923803890686454, 0.29758967082222043], 
reward next is 0.7024, 
noisyNet noise sample is [array([1.0176625], dtype=float32), 0.44939694]. 
=============================================
[2019-04-27 17:59:14,143] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.5982168e-16 1.0000000e+00 1.1372283e-14 9.1467349e-17 1.8854836e-18], sum to 1.0000
[2019-04-27 17:59:14,148] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2671
[2019-04-27 17:59:14,156] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1385499.556377391 W.
[2019-04-27 17:59:14,160] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.4, 90.5, 1.0, 2.0, 0.4050621790803335, 1.0, 2.0, 0.4050621790803335, 1.0, 1.0, 0.6448721810500854, 6.9112, 6.9112, 121.94756008, 1385499.556377391, 1385499.556377391, 299306.7496392906], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2194200.0000, 
sim time next is 2194800.0000, 
raw observation next is [24.4, 90.66666666666667, 1.0, 2.0, 0.4135601152091397, 1.0, 2.0, 0.4135601152091397, 1.0, 2.0, 0.6584011721256029, 6.911200000000001, 6.9112, 121.94756008, 1414593.257844502, 1414593.257844502, 303073.1558544393], 
processed observation next is [1.0, 0.391304347826087, 0.4592592592592592, 0.9066666666666667, 1.0, 1.0, 0.3018572800108806, 1.0, 1.0, 0.3018572800108806, 1.0, 1.0, 0.5730014651570036, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5052118778016079, 0.5052118778016079, 0.582832992027768], 
reward next is 0.4172, 
noisyNet noise sample is [array([-0.09047268], dtype=float32), -0.4234516]. 
=============================================
[2019-04-27 17:59:21,850] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2630609e-18 1.0000000e+00 7.3405222e-19 2.8318593e-19 2.7204015e-20], sum to 1.0000
[2019-04-27 17:59:21,863] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3905
[2019-04-27 17:59:21,871] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.4829733628801072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 579985.4650784361, 579985.4650784356, 140386.3762359109], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2338200.0000, 
sim time next is 2338800.0000, 
raw observation next is [22.0, 94.33333333333333, 1.0, 2.0, 0.484766413594218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 581716.8443082741, 581716.8443082741, 140648.8810244325], 
processed observation next is [1.0, 0.043478260869565216, 0.37037037037037035, 0.9433333333333332, 1.0, 1.0, 0.38662668285025953, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2077560158243836, 0.2077560158243836, 0.27047861735467793], 
reward next is 0.7295, 
noisyNet noise sample is [array([0.21500407], dtype=float32), 1.4927044]. 
=============================================
[2019-04-27 17:59:23,805] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.6182504e-13 1.0000000e+00 1.1087222e-12 5.5985013e-13 1.9584784e-13], sum to 1.0000
[2019-04-27 17:59:23,813] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0224
[2019-04-27 17:59:23,817] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 41.0, 1.0, 2.0, 0.7826545170374795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000003, 6.9112, 121.9260426156618, 978447.7597401028, 978447.7597401014, 195738.0497462761], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2365200.0000, 
sim time next is 2365800.0000, 
raw observation next is [28.11666666666667, 40.83333333333334, 1.0, 2.0, 0.8427828075661761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1052717.621565978, 1052717.621565978, 208621.5574745284], 
processed observation next is [1.0, 0.391304347826087, 0.5969135802469138, 0.40833333333333344, 1.0, 1.0, 0.8128366756740192, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3759705791307064, 0.3759705791307064, 0.40119530283563154], 
reward next is 0.5988, 
noisyNet noise sample is [array([-0.30389208], dtype=float32), -0.43074805]. 
=============================================
[2019-04-27 17:59:24,294] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.3049485e-08 9.9999988e-01 3.7549032e-08 5.2582121e-09 2.5714233e-08], sum to 1.0000
[2019-04-27 17:59:24,305] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1648
[2019-04-27 17:59:24,312] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1682483.77520937 W.
[2019-04-27 17:59:24,319] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.0, 37.83333333333334, 1.0, 2.0, 1.018210925030032, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.750822138229654, 6.9112, 121.9226306235234, 1682483.77520937, 1252534.227954, 249395.7416974198], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2376600.0000, 
sim time next is 2377200.0000, 
raw observation next is [30.1, 37.66666666666667, 1.0, 2.0, 0.3239768709041217, 1.0, 1.0, 0.3239768709041217, 1.0, 1.0, 0.5233281720038548, 6.9112, 6.9112, 121.94756008, 1167379.497895237, 1167379.497895237, 264817.7909607583], 
processed observation next is [1.0, 0.5217391304347826, 0.6703703703703704, 0.3766666666666667, 1.0, 1.0, 0.19521056060014488, 1.0, 0.5, 0.19521056060014488, 1.0, 0.5, 0.4041602150048185, 0.0, 0.0, 0.8096049824067558, 0.41692124924829893, 0.41692124924829893, 0.5092649826168428], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.24141008], dtype=float32), -2.1671567]. 
=============================================
[2019-04-27 17:59:25,009] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4000, global step 63758: loss 0.0188
[2019-04-27 17:59:25,012] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4000, global step 63759: learning rate 0.0000
[2019-04-27 17:59:25,077] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.0204310e-14 1.0000000e+00 1.4510929e-10 2.1416870e-13 3.4378219e-12], sum to 1.0000
[2019-04-27 17:59:25,087] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1062
[2019-04-27 17:59:25,095] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1580568.764985231 W.
[2019-04-27 17:59:25,099] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.8, 37.0, 1.0, 2.0, 0.7195404575700072, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9602072750233863, 6.911199999999999, 6.9112, 121.9260426156618, 1580568.764985231, 1580568.764985231, 311790.2713062281], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2390400.0000, 
sim time next is 2391000.0000, 
raw observation next is [30.78333333333333, 37.16666666666667, 1.0, 2.0, 0.5815461091288481, 0.0, 2.0, 0.0, 1.0, 2.0, 0.941473768227858, 6.911199999999999, 6.9112, 121.9260426156618, 1402371.148029092, 1402371.148029093, 284616.4376329051], 
processed observation next is [1.0, 0.6956521739130435, 0.695679012345679, 0.3716666666666667, 1.0, 1.0, 0.5018406061057715, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9268422102848225, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5008468385818186, 0.5008468385818189, 0.5473393031402021], 
reward next is 0.4527, 
noisyNet noise sample is [array([-1.5691903], dtype=float32), -1.1300129]. 
=============================================
[2019-04-27 17:59:25,112] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[51.44425 ]
 [51.66254 ]
 [51.962276]
 [51.302822]
 [51.161907]], R is [[51.99340057]
 [51.47346878]
 [51.39477158]
 [51.29413986]
 [51.24347305]].
[2019-04-27 17:59:25,208] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4000, global step 63851: loss 0.0406
[2019-04-27 17:59:25,214] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4000, global step 63852: learning rate 0.0000
[2019-04-27 17:59:25,318] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4000, global step 63900: loss 4.2144
[2019-04-27 17:59:25,319] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4000, global step 63900: learning rate 0.0000
[2019-04-27 17:59:25,352] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4000, global step 63918: loss 0.5816
[2019-04-27 17:59:25,355] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4000, global step 63918: learning rate 0.0000
[2019-04-27 17:59:25,373] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4000, global step 63928: loss 1.5370
[2019-04-27 17:59:25,377] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4000, global step 63928: learning rate 0.0000
[2019-04-27 17:59:25,392] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4000, global step 63936: loss 0.2590
[2019-04-27 17:59:25,395] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4000, global step 63936: learning rate 0.0000
[2019-04-27 17:59:25,406] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4000, global step 63942: loss 1.7892
[2019-04-27 17:59:25,408] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4000, global step 63942: learning rate 0.0000
[2019-04-27 17:59:25,417] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4000, global step 63947: loss 0.8152
[2019-04-27 17:59:25,418] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4000, global step 63947: learning rate 0.0000
[2019-04-27 17:59:25,548] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4000, global step 64009: loss 0.5921
[2019-04-27 17:59:25,552] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4000, global step 64009: learning rate 0.0000
[2019-04-27 17:59:25,578] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4000, global step 64022: loss 0.0351
[2019-04-27 17:59:25,580] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4000, global step 64023: learning rate 0.0000
[2019-04-27 17:59:25,604] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4000, global step 64033: loss 1.0987
[2019-04-27 17:59:25,608] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4000, global step 64033: learning rate 0.0000
[2019-04-27 17:59:25,620] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4000, global step 64042: loss 0.0091
[2019-04-27 17:59:25,623] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4000, global step 64043: learning rate 0.0000
[2019-04-27 17:59:25,701] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4000, global step 64078: loss 0.1292
[2019-04-27 17:59:25,703] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4000, global step 64079: learning rate 0.0000
[2019-04-27 17:59:25,770] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4000, global step 64111: loss 0.5309
[2019-04-27 17:59:25,771] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4000, global step 64111: learning rate 0.0000
[2019-04-27 17:59:25,816] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4000, global step 64135: loss 0.9775
[2019-04-27 17:59:25,817] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4000, global step 64135: learning rate 0.0000
[2019-04-27 17:59:26,018] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4000, global step 64226: loss 0.2370
[2019-04-27 17:59:26,020] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4000, global step 64227: learning rate 0.0000
[2019-04-27 17:59:26,620] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6085308e-18 1.0000000e+00 1.4924858e-17 1.1556183e-20 5.8140954e-21], sum to 1.0000
[2019-04-27 17:59:26,632] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0017
[2019-04-27 17:59:26,642] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.43333333333334, 66.0, 1.0, 2.0, 0.3052624444066655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 392104.7157347788, 392104.7157347788, 116226.2760374209], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2428800.0000, 
sim time next is 2429400.0000, 
raw observation next is [20.26666666666667, 67.0, 1.0, 2.0, 0.3001359206761735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 385601.4996371531, 385601.4996371531, 115589.9615253382], 
processed observation next is [1.0, 0.08695652173913043, 0.3061728395061729, 0.67, 1.0, 1.0, 0.16682847699544465, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13771482129898324, 0.13771482129898324, 0.22228838754872732], 
reward next is 0.7777, 
noisyNet noise sample is [array([-0.6812292], dtype=float32), 1.4888139]. 
=============================================
[2019-04-27 17:59:28,821] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1783617e-12 1.0000000e+00 9.9102031e-13 3.3256350e-14 5.4377825e-14], sum to 1.0000
[2019-04-27 17:59:28,829] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2667
[2019-04-27 17:59:28,836] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1453559.680364934 W.
[2019-04-27 17:59:28,839] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.36666666666667, 24.0, 1.0, 2.0, 0.9619334190253963, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.422671320215823, 6.9112, 121.9239177339492, 1453559.680364934, 1191645.214254007, 235833.2077915412], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2461200.0000, 
sim time next is 2461800.0000, 
raw observation next is [33.48333333333333, 24.0, 1.0, 2.0, 0.5462037839924978, 1.0, 1.0, 0.5462037839924978, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9257346163377, 1336905.18442252, 1336905.18442252, 253707.0209566355], 
processed observation next is [1.0, 0.4782608695652174, 0.7956790123456788, 0.24, 1.0, 1.0, 0.4597664095148783, 1.0, 0.5, 0.4597664095148783, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094600840249206, 0.47746613729375714, 0.47746613729375714, 0.48789811722429904], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.16712493], dtype=float32), 0.22927012]. 
=============================================
[2019-04-27 17:59:29,342] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.8675948e-09 1.0000000e+00 2.3609932e-09 5.6353533e-10 1.2795943e-09], sum to 1.0000
[2019-04-27 17:59:29,347] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7093
[2019-04-27 17:59:29,355] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1957686.194120928 W.
[2019-04-27 17:59:29,362] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [34.53333333333333, 23.0, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 8.266076119201955, 6.9112, 121.9208370458806, 1957686.194120928, 1263898.145825307, 250113.5276714274], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2467200.0000, 
sim time next is 2467800.0000, 
raw observation next is [34.65, 23.0, 1.0, 2.0, 0.4820226801820197, 1.0, 1.0, 0.4820226801820197, 1.0, 1.0, 0.7769710109972352, 6.9112, 6.9112, 121.94756008, 1730727.654631416, 1730727.654631416, 334540.0129088434], 
processed observation next is [1.0, 0.5652173913043478, 0.8388888888888888, 0.23, 1.0, 1.0, 0.3833603335500235, 1.0, 0.5, 0.3833603335500235, 1.0, 0.5, 0.721213763746544, 0.0, 0.0, 0.8096049824067558, 0.61811701951122, 0.61811701951122, 0.6433461786708528], 
reward next is 0.3567, 
noisyNet noise sample is [array([-0.3366261], dtype=float32), -0.3009051]. 
=============================================
[2019-04-27 17:59:35,194] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.26980475e-11 1.00000000e+00 2.36378452e-11 1.66635531e-12
 4.89426832e-10], sum to 1.0000
[2019-04-27 17:59:35,200] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9388
[2019-04-27 17:59:35,206] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.13333333333333, 47.66666666666667, 1.0, 2.0, 0.4970458557392125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 593020.7240370013, 593020.7240370013, 142438.7128438473], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2575200.0000, 
sim time next is 2575800.0000, 
raw observation next is [29.95, 48.5, 1.0, 2.0, 0.4988310243676091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 595027.4291742184, 595027.4291742188, 142714.0227687857], 
processed observation next is [1.0, 0.8260869565217391, 0.6648148148148147, 0.485, 1.0, 1.0, 0.40337026710429663, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21250979613364945, 0.21250979613364956, 0.27445004378612636], 
reward next is 0.7255, 
noisyNet noise sample is [array([2.7203202], dtype=float32), 0.32298177]. 
=============================================
[2019-04-27 17:59:36,679] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.1560102e-12 1.0000000e+00 5.5434633e-12 1.3969650e-13 2.0330676e-10], sum to 1.0000
[2019-04-27 17:59:36,688] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6660
[2019-04-27 17:59:36,693] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.45, 92.5, 1.0, 2.0, 0.4588090503444096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 557636.4679539811, 557636.4679539816, 136922.9614248217], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2601000.0000, 
sim time next is 2601600.0000, 
raw observation next is [21.36666666666667, 93.0, 1.0, 2.0, 0.4575328598129764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 556288.0730518443, 556288.0730518443, 136736.9729126286], 
processed observation next is [0.0, 0.08695652173913043, 0.3469135802469137, 0.93, 1.0, 1.0, 0.35420578549163856, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1986743118042301, 0.1986743118042301, 0.2629557171396704], 
reward next is 0.7370, 
noisyNet noise sample is [array([0.5813968], dtype=float32), -0.93901545]. 
=============================================
[2019-04-27 17:59:39,690] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.3509512e-15 1.0000000e+00 1.7952084e-15 7.9802717e-16 1.0673616e-14], sum to 1.0000
[2019-04-27 17:59:39,696] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1060
[2019-04-27 17:59:39,701] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 78.0, 1.0, 2.0, 0.588037537444193, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 681882.8798644984, 681882.8798644984, 156594.1470340539], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2660400.0000, 
sim time next is 2661000.0000, 
raw observation next is [25.85, 78.66666666666667, 1.0, 2.0, 0.5850620400428178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 679150.2033617734, 679150.2033617734, 156118.8482566037], 
processed observation next is [0.0, 0.8260869565217391, 0.5129629629629631, 0.7866666666666667, 1.0, 1.0, 0.5060262381462116, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2425536440577762, 0.2425536440577762, 0.3002285543396225], 
reward next is 0.6998, 
noisyNet noise sample is [array([0.13876575], dtype=float32), 1.635115]. 
=============================================
[2019-04-27 17:59:39,723] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[64.06985 ]
 [63.98605 ]
 [63.939304]
 [63.903225]
 [63.859016]], R is [[64.19928741]
 [64.25615692]
 [64.31136322]
 [64.36476898]
 [64.41627502]].
[2019-04-27 17:59:41,470] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4500, global step 71687: loss 0.0962
[2019-04-27 17:59:41,472] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4500, global step 71687: learning rate 0.0000
[2019-04-27 17:59:41,788] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4500, global step 71840: loss 0.4243
[2019-04-27 17:59:41,791] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4500, global step 71841: learning rate 0.0000
[2019-04-27 17:59:41,863] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4500, global step 71875: loss 0.1707
[2019-04-27 17:59:41,865] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4500, global step 71875: learning rate 0.0000
[2019-04-27 17:59:41,899] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4500, global step 71890: loss 0.3086
[2019-04-27 17:59:41,902] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4500, global step 71892: learning rate 0.0000
[2019-04-27 17:59:41,932] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4500, global step 71906: loss 0.2267
[2019-04-27 17:59:41,934] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4500, global step 71907: learning rate 0.0000
[2019-04-27 17:59:41,993] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4500, global step 71936: loss 0.1030
[2019-04-27 17:59:41,995] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4500, global step 71936: learning rate 0.0000
[2019-04-27 17:59:42,016] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4500, global step 71946: loss 0.0813
[2019-04-27 17:59:42,020] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4500, global step 71946: learning rate 0.0000
[2019-04-27 17:59:42,120] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4500, global step 71996: loss 0.0165
[2019-04-27 17:59:42,122] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4500, global step 71996: learning rate 0.0000
[2019-04-27 17:59:42,132] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4500, global step 72000: loss 0.0138
[2019-04-27 17:59:42,133] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4500, global step 72000: learning rate 0.0000
[2019-04-27 17:59:42,170] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4500, global step 72019: loss 0.0364
[2019-04-27 17:59:42,172] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4500, global step 72020: learning rate 0.0000
[2019-04-27 17:59:42,255] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4500, global step 72061: loss 0.0321
[2019-04-27 17:59:42,257] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4500, global step 72061: learning rate 0.0000
[2019-04-27 17:59:42,269] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4500, global step 72069: loss 0.0089
[2019-04-27 17:59:42,270] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4500, global step 72069: learning rate 0.0000
[2019-04-27 17:59:42,335] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4500, global step 72096: loss 0.0074
[2019-04-27 17:59:42,337] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4500, global step 72097: learning rate 0.0000
[2019-04-27 17:59:42,431] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4500, global step 72142: loss 0.0635
[2019-04-27 17:59:42,435] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4500, global step 72144: learning rate 0.0000
[2019-04-27 17:59:42,443] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4500, global step 72150: loss 0.0454
[2019-04-27 17:59:42,445] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4500, global step 72150: learning rate 0.0000
[2019-04-27 17:59:42,594] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4500, global step 72221: loss 0.1747
[2019-04-27 17:59:42,595] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4500, global step 72221: learning rate 0.0000
[2019-04-27 17:59:43,984] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.4722179e-16 1.0000000e+00 3.0028053e-14 3.0354717e-15 1.9764045e-13], sum to 1.0000
[2019-04-27 17:59:43,991] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9835
[2019-04-27 17:59:44,000] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.55, 52.5, 1.0, 2.0, 0.6174136587498048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 705491.0459390059, 705491.0459390059, 161191.1247404644], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2737800.0000, 
sim time next is 2738400.0000, 
raw observation next is [31.4, 53.66666666666666, 1.0, 2.0, 0.6252470060378993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 712822.3822146391, 712822.3822146391, 162487.1054610476], 
processed observation next is [0.0, 0.6956521739130435, 0.7185185185185184, 0.5366666666666666, 1.0, 1.0, 0.5538654833784515, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25457942221951396, 0.25457942221951396, 0.312475202809707], 
reward next is 0.6875, 
noisyNet noise sample is [array([1.2731425], dtype=float32), -0.06275312]. 
=============================================
[2019-04-27 17:59:47,896] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.6710232e-11 1.0000000e+00 5.3451167e-12 1.3031892e-11 4.0373269e-10], sum to 1.0000
[2019-04-27 17:59:47,899] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8381
[2019-04-27 17:59:47,902] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2463289.55609304 W.
[2019-04-27 17:59:47,906] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.0, 63.0, 1.0, 2.0, 0.8127024667675873, 1.0, 2.0, 0.7197158953602282, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2463289.55609304, 2463289.55609304, 460898.1502685067], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2808000.0000, 
sim time next is 2808600.0000, 
raw observation next is [32.0, 63.0, 1.0, 2.0, 0.8699718285280585, 1.0, 2.0, 0.7483505762404639, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 122.090524452103, 2561430.518218567, 2561430.518218568, 478078.9813895503], 
processed observation next is [1.0, 0.5217391304347826, 0.7407407407407407, 0.63, 1.0, 1.0, 0.8452045577714983, 1.0, 1.0, 0.7004173526672188, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8105541171650511, 0.9147966136494883, 0.9147966136494886, 0.919382656518366], 
reward next is 0.0806, 
noisyNet noise sample is [array([0.91247565], dtype=float32), 0.10085452]. 
=============================================
[2019-04-27 17:59:48,386] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-04-27 17:59:48,389] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 17:59:48,390] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 17:59:48,390] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 17:59:48,391] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 17:59:48,391] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 17:59:48,392] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 17:59:48,393] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 17:59:48,392] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 17:59:48,395] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 17:59:48,397] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 17:59:48,407] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run4
[2019-04-27 17:59:48,407] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run4
[2019-04-27 17:59:48,448] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run4
[2019-04-27 17:59:48,450] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run4
[2019-04-27 17:59:48,485] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run4
[2019-04-27 18:00:02,411] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.023651594]
[2019-04-27 18:00:02,413] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.92396358166667, 42.38154307333333, 1.0, 2.0, 0.2948791982098959, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 378086.7015399165, 378086.7015399165, 114945.7081732803]
[2019-04-27 18:00:02,414] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 18:00:02,418] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.2981161e-09 9.9999988e-01 2.5083362e-09 1.8747266e-09 8.4114710e-08], sampled 0.7440982829731065
[2019-04-27 18:00:32,426] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.023651594]
[2019-04-27 18:00:32,429] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [34.50208, 40.01715136833334, 1.0, 2.0, 1.005251247185527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.237501992066705, 6.9112, 121.9245236842104, 1324381.012559733, 1157287.309727977, 242631.1303900557]
[2019-04-27 18:00:32,430] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 18:00:32,435] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.9170181e-08 9.9999976e-01 8.4846521e-09 6.5559305e-09 2.3955010e-07], sampled 0.6939116321015101
[2019-04-27 18:00:32,437] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1324381.012559733 W.
[2019-04-27 18:00:43,322] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.023651594]
[2019-04-27 18:00:43,322] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.31666666666667, 64.16666666666666, 1.0, 2.0, 0.7156037808541286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 815595.3354019308, 815595.3354019308, 179123.8135849444]
[2019-04-27 18:00:43,323] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 18:00:43,327] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.1300217e-09 1.0000000e+00 9.7999375e-10 8.4622975e-10 3.9424979e-08], sampled 0.046669679186803203
[2019-04-27 18:01:03,623] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.023651594]
[2019-04-27 18:01:03,624] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.0, 78.5, 1.0, 2.0, 0.5272393067609181, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 623095.5093312562, 623095.5093312562, 147018.7533753213]
[2019-04-27 18:01:03,625] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 18:01:03,629] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.5556691e-09 9.9999988e-01 2.3960016e-09 1.7376592e-09 7.4478869e-08], sampled 0.13430343651803778
[2019-04-27 18:01:31,873] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.023651594]
[2019-04-27 18:01:31,873] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.66666666666666, 27.33333333333334, 1.0, 2.0, 0.3524040541903832, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 454610.0619879876, 454610.0619879876, 121917.3560485287]
[2019-04-27 18:01:31,878] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 18:01:31,881] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.5339623e-08 9.9999988e-01 4.3476276e-09 3.2192686e-09 1.2898505e-07], sampled 0.6579775658082377
[2019-04-27 18:01:32,447] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.023651594]
[2019-04-27 18:01:32,449] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.07195404, 50.476837745, 1.0, 2.0, 0.3504340616071723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 437771.6565933028, 437771.6565933028, 121928.0038119135]
[2019-04-27 18:01:32,450] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 18:01:32,453] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.11220215e-08 9.99999881e-01 3.20283022e-09 2.28416663e-09
 9.67703855e-08], sampled 0.5621158263450197
[2019-04-27 18:01:34,460] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8700.8853 2195111564.5987 572.0000
[2019-04-27 18:01:34,814] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8098.1982 2445474065.1982 746.0000
[2019-04-27 18:01:34,826] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8583.7010 2248665784.9182 553.0000
[2019-04-27 18:01:34,878] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.1744 2120459934.0312 430.0000
[2019-04-27 18:01:34,930] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8768.6234 2170750632.1576 493.0000
[2019-04-27 18:01:35,944] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 75000, evaluation results [75000.0, 8098.198157630031, 2445474065.1982007, 746.0, 8768.623414302618, 2170750632.157631, 493.0, 8924.174449411888, 2120459934.031154, 430.0, 8583.700958564144, 2248665784.918216, 553.0, 8700.885259520708, 2195111564.598743, 572.0]
[2019-04-27 18:01:39,989] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.6328351e-16 1.0000000e+00 6.6721108e-18 3.1399185e-20 3.8408402e-16], sum to 1.0000
[2019-04-27 18:01:40,000] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7430
[2019-04-27 18:01:40,008] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1405795.440470306 W.
[2019-04-27 18:01:40,017] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.43333333333334, 90.66666666666667, 1.0, 2.0, 0.4109904078186831, 1.0, 1.0, 0.4109904078186831, 1.0, 1.0, 0.654310114270469, 6.911200000000001, 6.9112, 121.94756008, 1405795.440470306, 1405795.440470306, 301930.0061281247], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2888400.0000, 
sim time next is 2889000.0000, 
raw observation next is [23.65, 89.0, 1.0, 2.0, 0.6071290686162264, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9674809581433723, 6.9112, 6.9112, 121.9260425145727, 1399954.224809068, 1399954.224809068, 296414.9758628168], 
processed observation next is [1.0, 0.43478260869565216, 0.4314814814814814, 0.89, 1.0, 1.0, 0.5322965102574123, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9593511976792154, 0.0, 0.0, 0.8094621281490094, 0.4999836517175243, 0.4999836517175243, 0.5700287997361861], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.04437812], dtype=float32), 2.1290312]. 
=============================================
[2019-04-27 18:01:40,033] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[57.141315]
 [57.601665]
 [57.390995]
 [57.056526]
 [56.80856 ]], R is [[56.7117691 ]
 [56.14465332]
 [55.58320618]
 [55.53911591]
 [55.46507263]].
[2019-04-27 18:01:42,562] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.8529411e-19 1.0000000e+00 2.5425021e-20 2.7017227e-21 5.4788579e-16], sum to 1.0000
[2019-04-27 18:01:42,572] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4263
[2019-04-27 18:01:42,578] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.16666666666667, 90.33333333333334, 1.0, 2.0, 0.6465684997179202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 736875.9112433739, 736875.9112433739, 166273.5592879111], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2936400.0000, 
sim time next is 2937000.0000, 
raw observation next is [25.13333333333333, 90.66666666666667, 1.0, 2.0, 0.6463624314512312, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 736640.9481982864, 736640.9481982864, 166236.5225041343], 
processed observation next is [1.0, 1.0, 0.4864197530864196, 0.9066666666666667, 1.0, 1.0, 0.579002894584799, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2630860529279594, 0.2630860529279594, 0.31968562020025826], 
reward next is 0.6803, 
noisyNet noise sample is [array([0.2283577], dtype=float32), 0.21318206]. 
=============================================
[2019-04-27 18:01:42,596] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[64.8567  ]
 [64.82002 ]
 [64.76994 ]
 [64.718605]
 [64.65113 ]], R is [[64.93453217]
 [64.96543121]
 [64.99619293]
 [65.02667236]
 [65.05648804]].
[2019-04-27 18:01:45,773] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5000, global step 79737: loss 85.7536
[2019-04-27 18:01:45,775] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5000, global step 79738: learning rate 0.0000
[2019-04-27 18:01:45,914] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.7504580e-11 1.0000000e+00 6.5156908e-13 9.6550394e-13 1.9139499e-09], sum to 1.0000
[2019-04-27 18:01:45,919] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6528
[2019-04-27 18:01:45,927] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1670955.238500558 W.
[2019-04-27 18:01:45,937] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.46666666666667, 76.66666666666667, 1.0, 2.0, 0.7326457813675176, 1.0, 2.0, 0.7326457813675176, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1670955.238500558, 1670955.238500558, 316709.0857495256], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2989200.0000, 
sim time next is 2989800.0000, 
raw observation next is [27.6, 81.0, 1.0, 2.0, 0.8492227161083631, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1683123.438620629, 1683123.438620629, 346223.3898436358], 
processed observation next is [1.0, 0.6086956521739131, 0.5777777777777778, 0.81, 1.0, 1.0, 0.820503233462337, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6011155137930818, 0.6011155137930818, 0.6658142112377611], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.6940768], dtype=float32), -1.2382084]. 
=============================================
[2019-04-27 18:01:46,156] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5000, global step 79881: loss 23.7546
[2019-04-27 18:01:46,159] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5000, global step 79881: loss 58.5729
[2019-04-27 18:01:46,163] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5000, global step 79881: learning rate 0.0000
[2019-04-27 18:01:46,166] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5000, global step 79881: learning rate 0.0000
[2019-04-27 18:01:46,394] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5000, global step 79907: loss 28.9696
[2019-04-27 18:01:46,394] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5000, global step 79907: loss -14.9025
[2019-04-27 18:01:46,396] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5000, global step 79907: learning rate 0.0000
[2019-04-27 18:01:46,398] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5000, global step 79908: learning rate 0.0000
[2019-04-27 18:01:46,403] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5000, global step 79911: loss 143.0134
[2019-04-27 18:01:46,588] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5000, global step 79912: learning rate 0.0000
[2019-04-27 18:01:46,717] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5000, global step 79938: loss 25.9109
[2019-04-27 18:01:46,719] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5000, global step 79938: learning rate 0.0000
[2019-04-27 18:01:46,956] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5000, global step 80017: loss 14.3020
[2019-04-27 18:01:46,960] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5000, global step 80018: learning rate 0.0000
[2019-04-27 18:01:47,084] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5000, global step 80032: loss 5.9404
[2019-04-27 18:01:47,088] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5000, global step 80034: learning rate 0.0000
[2019-04-27 18:01:47,092] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5000, global step 80038: loss 123.8562
[2019-04-27 18:01:47,182] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5000, global step 80039: learning rate 0.0000
[2019-04-27 18:01:47,287] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5000, global step 80046: loss 20.3174
[2019-04-27 18:01:47,292] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5000, global step 80046: learning rate 0.0000
[2019-04-27 18:01:47,293] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5000, global step 80046: loss 1.5854
[2019-04-27 18:01:47,296] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5000, global step 80046: loss 70.8404
[2019-04-27 18:01:47,385] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5000, global step 80046: learning rate 0.0000
[2019-04-27 18:01:47,386] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5000, global step 80047: learning rate 0.0000
[2019-04-27 18:01:47,645] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5000, global step 80090: loss 94.7101
[2019-04-27 18:01:47,648] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5000, global step 80092: learning rate 0.0000
[2019-04-27 18:01:47,757] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5000, global step 80104: loss 28.7777
[2019-04-27 18:01:47,759] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5000, global step 80104: learning rate 0.0000
[2019-04-27 18:01:48,124] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5000, global step 80240: loss 159.9842
[2019-04-27 18:01:48,133] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5000, global step 80243: learning rate 0.0000
[2019-04-27 18:01:55,202] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3183788e-20 1.0000000e+00 1.2592186e-23 2.2738703e-23 2.2887375e-20], sum to 1.0000
[2019-04-27 18:01:55,210] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2469
[2019-04-27 18:01:55,219] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.33333333333334, 53.83333333333334, 1.0, 2.0, 0.7481737970442174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 885268.9045452969, 885268.9045452964, 187013.6533374556], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3138600.0000, 
sim time next is 3139200.0000, 
raw observation next is [29.8, 53.0, 1.0, 2.0, 0.7683047974111977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 904770.4721861077, 904770.4721861081, 190892.8004210711], 
processed observation next is [1.0, 0.34782608695652173, 0.6592592592592593, 0.53, 1.0, 1.0, 0.7241723778704735, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.32313231149503846, 0.3231323114950386, 0.3671015392712906], 
reward next is 0.6329, 
noisyNet noise sample is [array([0.3843853], dtype=float32), 0.7508591]. 
=============================================
[2019-04-27 18:01:55,761] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.4463021e-14 1.0000000e+00 3.5843613e-16 1.2255282e-17 5.7706857e-14], sum to 1.0000
[2019-04-27 18:01:55,769] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3566
[2019-04-27 18:01:55,774] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.93333333333334, 56.33333333333334, 1.0, 2.0, 0.7014058117158612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 841758.430332202, 841758.430332202, 178306.5183256296], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3136800.0000, 
sim time next is 3137400.0000, 
raw observation next is [28.4, 55.5, 1.0, 2.0, 0.7468515934358746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 892059.2560711806, 892059.2560711806, 187091.6585365566], 
processed observation next is [1.0, 0.30434782608695654, 0.6074074074074074, 0.555, 1.0, 1.0, 0.6986328493284222, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31859259145399305, 0.31859259145399305, 0.35979165103183963], 
reward next is 0.6402, 
noisyNet noise sample is [array([0.53721005], dtype=float32), -2.3790889]. 
=============================================
[2019-04-27 18:02:02,008] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.4221215e-22 1.0000000e+00 2.6745432e-25 2.4545224e-26 2.8440043e-20], sum to 1.0000
[2019-04-27 18:02:02,017] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9319
[2019-04-27 18:02:02,020] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 48.0, 1.0, 2.0, 0.5397305505965874, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 634558.8154451692, 634558.8154451692, 148914.5602729984], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3247200.0000, 
sim time next is 3247800.0000, 
raw observation next is [31.16666666666667, 46.83333333333334, 1.0, 2.0, 0.5383832181340369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 633627.7652831445, 633627.7652831441, 148721.394119855], 
processed observation next is [0.0, 0.6086956521739131, 0.7098765432098767, 0.46833333333333343, 1.0, 1.0, 0.4504562120643296, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2262956304582659, 0.22629563045826576, 0.28600268099972115], 
reward next is 0.7140, 
noisyNet noise sample is [array([-0.7711297], dtype=float32), -2.373734]. 
=============================================
[2019-04-27 18:02:02,266] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.02995993e-19 1.00000000e+00 2.44230125e-22 1.79363367e-23
 4.69335714e-19], sum to 1.0000
[2019-04-27 18:02:02,278] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9001
[2019-04-27 18:02:02,284] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.25, 56.0, 1.0, 2.0, 0.6064319214239654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 698631.9362909428, 698631.9362909428, 159554.2818894814], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3259800.0000, 
sim time next is 3260400.0000, 
raw observation next is [30.5, 53.66666666666667, 1.0, 2.0, 0.5937805153411106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 687273.9017181771, 687273.9017181771, 157520.3974308437], 
processed observation next is [0.0, 0.7391304347826086, 0.6851851851851852, 0.5366666666666667, 1.0, 1.0, 0.5164053754060841, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24545496489934898, 0.24545496489934898, 0.30292384121316096], 
reward next is 0.6971, 
noisyNet noise sample is [array([-0.7927005], dtype=float32), 2.8181775]. 
=============================================
[2019-04-27 18:02:03,710] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5500, global step 87711: loss 0.0190
[2019-04-27 18:02:03,713] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5500, global step 87711: learning rate 0.0000
[2019-04-27 18:02:03,961] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5500, global step 87824: loss 0.0461
[2019-04-27 18:02:03,963] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5500, global step 87825: learning rate 0.0000
[2019-04-27 18:02:04,010] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5500, global step 87851: loss 0.0656
[2019-04-27 18:02:04,016] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5500, global step 87851: learning rate 0.0000
[2019-04-27 18:02:04,047] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5500, global step 87869: loss 0.0872
[2019-04-27 18:02:04,048] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5500, global step 87869: loss 0.0963
[2019-04-27 18:02:04,053] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5500, global step 87869: learning rate 0.0000
[2019-04-27 18:02:04,053] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5500, global step 87870: learning rate 0.0000
[2019-04-27 18:02:04,097] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5500, global step 87896: loss 0.1014
[2019-04-27 18:02:04,098] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5500, global step 87896: learning rate 0.0000
[2019-04-27 18:02:04,142] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5500, global step 87914: loss 0.0378
[2019-04-27 18:02:04,144] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5500, global step 87915: learning rate 0.0000
[2019-04-27 18:02:04,271] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5500, global step 87982: loss 0.0166
[2019-04-27 18:02:04,275] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5500, global step 87982: learning rate 0.0000
[2019-04-27 18:02:04,353] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5500, global step 88023: loss 0.0541
[2019-04-27 18:02:04,355] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5500, global step 88023: learning rate 0.0000
[2019-04-27 18:02:04,398] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5500, global step 88044: loss 0.0592
[2019-04-27 18:02:04,399] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5500, global step 88044: learning rate 0.0000
[2019-04-27 18:02:04,428] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5500, global step 88058: loss 0.0239
[2019-04-27 18:02:04,430] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5500, global step 88059: learning rate 0.0000
[2019-04-27 18:02:04,472] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5500, global step 88077: loss 0.0190
[2019-04-27 18:02:04,474] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5500, global step 88077: learning rate 0.0000
[2019-04-27 18:02:04,519] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5500, global step 88099: loss 0.0420
[2019-04-27 18:02:04,521] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5500, global step 88100: learning rate 0.0000
[2019-04-27 18:02:04,595] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5500, global step 88139: loss 0.0150
[2019-04-27 18:02:04,600] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5500, global step 88140: learning rate 0.0000
[2019-04-27 18:02:04,618] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5500, global step 88150: loss 0.0144
[2019-04-27 18:02:04,621] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5500, global step 88150: learning rate 0.0000
[2019-04-27 18:02:04,911] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5500, global step 88283: loss 0.1336
[2019-04-27 18:02:04,916] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5500, global step 88286: learning rate 0.0000
[2019-04-27 18:02:08,698] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.3096432e-18 1.0000000e+00 8.7101634e-21 4.9874003e-22 5.0760095e-18], sum to 1.0000
[2019-04-27 18:02:08,700] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.4967894e-19 1.0000000e+00 4.7951833e-22 6.9515796e-22 6.2761667e-19], sum to 1.0000
[2019-04-27 18:02:08,705] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4044
[2019-04-27 18:02:08,707] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7642
[2019-04-27 18:02:08,712] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.95, 97.0, 1.0, 2.0, 0.6282935442603312, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 736016.1108567854, 736016.1108567854, 163953.2148142153], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3389400.0000, 
sim time next is 3390000.0000, 
raw observation next is [22.96666666666667, 98.0, 1.0, 2.0, 0.6241011868130646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 729036.1236619884, 729036.1236619884, 163115.0820722265], 
processed observation next is [1.0, 0.21739130434782608, 0.4061728395061729, 0.98, 1.0, 1.0, 0.5525014128726959, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2603700441649959, 0.2603700441649959, 0.31368285013889713], 
reward next is 0.6863, 
noisyNet noise sample is [array([-0.07962524], dtype=float32), -0.3324681]. 
=============================================
[2019-04-27 18:02:08,720] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.95, 92.0, 1.0, 2.0, 0.593284805898886, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 688603.4315310649, 688603.4315310644, 157522.5933361594], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3375000.0000, 
sim time next is 3375600.0000, 
raw observation next is [23.83333333333334, 91.66666666666667, 1.0, 2.0, 0.5867458169640085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 683288.7418216369, 683288.7418216369, 156504.2895804916], 
processed observation next is [1.0, 0.043478260869565216, 0.43827160493827183, 0.9166666666666667, 1.0, 1.0, 0.5080307344809625, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24403169350772747, 0.24403169350772747, 0.30096978765479154], 
reward next is 0.6990, 
noisyNet noise sample is [array([0.74105984], dtype=float32), -0.109745]. 
=============================================
[2019-04-27 18:02:08,730] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[64.052666]
 [64.00474 ]
 [64.167076]
 [63.990147]
 [64.13128 ]], R is [[64.18210602]
 [64.22499084]
 [64.2684021 ]
 [64.30246735]
 [64.35543823]].
[2019-04-27 18:02:14,024] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.3513517e-18 1.0000000e+00 1.7174055e-20 2.2321207e-22 5.4704517e-20], sum to 1.0000
[2019-04-27 18:02:14,031] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0413
[2019-04-27 18:02:14,041] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 100.0, 1.0, 2.0, 0.7888799241524445, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 899159.3681747539, 899159.3681747539, 193647.903895979], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3466800.0000, 
sim time next is 3467400.0000, 
raw observation next is [24.0, 100.0, 1.0, 2.0, 0.8801784473669527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1003288.853514358, 1003288.853514358, 213057.0886307593], 
processed observation next is [1.0, 0.13043478260869565, 0.4444444444444444, 1.0, 1.0, 1.0, 0.8573552944844676, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.35831744768369933, 0.35831744768369933, 0.4097251704437679], 
reward next is 0.5903, 
noisyNet noise sample is [array([-1.6466553], dtype=float32), -0.6119]. 
=============================================
[2019-04-27 18:02:14,194] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.1178303e-17 1.0000000e+00 1.9210427e-19 3.1415942e-21 1.7887185e-18], sum to 1.0000
[2019-04-27 18:02:14,203] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7372
[2019-04-27 18:02:14,207] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 100.0, 1.0, 2.0, 0.7888799241524445, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 899159.3681747539, 899159.3681747539, 193647.903895979], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3466800.0000, 
sim time next is 3467400.0000, 
raw observation next is [24.0, 100.0, 1.0, 2.0, 0.8801784473669527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1003288.853514358, 1003288.853514358, 213057.0886307593], 
processed observation next is [1.0, 0.13043478260869565, 0.4444444444444444, 1.0, 1.0, 1.0, 0.8573552944844676, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.35831744768369933, 0.35831744768369933, 0.4097251704437679], 
reward next is 0.5903, 
noisyNet noise sample is [array([-0.24800664], dtype=float32), -1.451851]. 
=============================================
[2019-04-27 18:02:18,332] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.3455281e-18 1.0000000e+00 7.6619879e-20 1.6505239e-19 2.4624007e-18], sum to 1.0000
[2019-04-27 18:02:18,346] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9258
[2019-04-27 18:02:18,352] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 85.5, 1.0, 2.0, 0.4779677947699353, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 576311.7512919304, 576311.7512919304, 139694.800353021], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3547800.0000, 
sim time next is 3548400.0000, 
raw observation next is [23.06666666666667, 82.66666666666666, 1.0, 2.0, 0.4734158445142892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 571902.7455483205, 571902.7455483209, 139032.4385529073], 
processed observation next is [1.0, 0.043478260869565216, 0.40987654320987665, 0.8266666666666665, 1.0, 1.0, 0.37311410061224903, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20425098055297158, 0.20425098055297175, 0.2673700741402063], 
reward next is 0.7326, 
noisyNet noise sample is [array([-1.2954102], dtype=float32), 0.78871685]. 
=============================================
[2019-04-27 18:02:19,332] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3483405e-21 1.0000000e+00 2.6077683e-25 4.9440871e-26 7.9508596e-23], sum to 1.0000
[2019-04-27 18:02:19,345] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2413
[2019-04-27 18:02:19,359] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 93.0, 1.0, 2.0, 0.556313289623825, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 669688.0421263474, 669688.0421263479, 152243.1386610222], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3571200.0000, 
sim time next is 3571800.0000, 
raw observation next is [21.98333333333333, 92.66666666666667, 1.0, 2.0, 0.5866294214337523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 706410.564381865, 706410.564381865, 157409.8621059544], 
processed observation next is [1.0, 0.34782608695652173, 0.36975308641975296, 0.9266666666666667, 1.0, 1.0, 0.5078921683735146, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2522894872792375, 0.2522894872792375, 0.30271127328068154], 
reward next is 0.6973, 
noisyNet noise sample is [array([1.6454875], dtype=float32), 0.7231124]. 
=============================================
[2019-04-27 18:02:20,394] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6000, global step 95697: loss -36.7067
[2019-04-27 18:02:20,398] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6000, global step 95699: learning rate 0.0000
[2019-04-27 18:02:20,582] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.6275270e-09 1.0000000e+00 8.0727864e-12 2.0532333e-11 3.3740594e-10], sum to 1.0000
[2019-04-27 18:02:20,589] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4745
[2019-04-27 18:02:20,599] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1294547.800143076 W.
[2019-04-27 18:02:20,605] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6000, global step 95796: loss 101.4471
[2019-04-27 18:02:20,608] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6000, global step 95796: learning rate 0.0000
[2019-04-27 18:02:20,609] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.2, 75.66666666666667, 1.0, 2.0, 0.5528622011510835, 0.0, 2.0, 0.0, 1.0, 1.0, 0.883679349011997, 6.911200000000001, 6.9112, 121.9258431377282, 1294547.800143076, 1294547.800143076, 275314.3129253105], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3594000.0000, 
sim time next is 3594600.0000, 
raw observation next is [25.15, 77.5, 1.0, 2.0, 0.3806038872784498, 1.0, 1.0, 0.3806038872784498, 1.0, 2.0, 0.606096611159523, 6.911199999999999, 6.9112, 121.94756008, 1307709.17420788, 1307709.174207881, 288725.8401631202], 
processed observation next is [1.0, 0.6086956521739131, 0.487037037037037, 0.775, 1.0, 1.0, 0.26262367533148784, 1.0, 0.5, 0.26262367533148784, 1.0, 1.0, 0.5076207639494037, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.46703899078852856, 0.46703899078852895, 0.5552420003136926], 
reward next is 0.4448, 
noisyNet noise sample is [array([0.85060436], dtype=float32), -0.66668534]. 
=============================================
[2019-04-27 18:02:20,758] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6000, global step 95874: loss 33.5305
[2019-04-27 18:02:20,760] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6000, global step 95874: learning rate 0.0000
[2019-04-27 18:02:20,782] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6000, global step 95883: loss 59.5323
[2019-04-27 18:02:20,784] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6000, global step 95883: learning rate 0.0000
[2019-04-27 18:02:20,827] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6000, global step 95903: loss 4.6987
[2019-04-27 18:02:20,828] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6000, global step 95903: learning rate 0.0000
[2019-04-27 18:02:20,897] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6000, global step 95937: loss -26.3832
[2019-04-27 18:02:20,898] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6000, global step 95937: learning rate 0.0000
[2019-04-27 18:02:20,919] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6000, global step 95947: loss -82.7924
[2019-04-27 18:02:20,923] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6000, global step 95949: learning rate 0.0000
[2019-04-27 18:02:20,941] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6000, global step 95957: loss 13.9572
[2019-04-27 18:02:20,950] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6000, global step 95957: learning rate 0.0000
[2019-04-27 18:02:21,023] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6000, global step 95993: loss -62.5699
[2019-04-27 18:02:21,027] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6000, global step 95993: learning rate 0.0000
[2019-04-27 18:02:21,117] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6000, global step 96037: loss 38.1177
[2019-04-27 18:02:21,119] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6000, global step 96040: learning rate 0.0000
[2019-04-27 18:02:21,136] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6000, global step 96049: loss -95.3682
[2019-04-27 18:02:21,138] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6000, global step 96049: learning rate 0.0000
[2019-04-27 18:02:21,218] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6000, global step 96087: loss -14.5116
[2019-04-27 18:02:21,224] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6000, global step 96088: learning rate 0.0000
[2019-04-27 18:02:21,245] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6000, global step 96099: loss 5.3277
[2019-04-27 18:02:21,246] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6000, global step 96099: learning rate 0.0000
[2019-04-27 18:02:21,368] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6000, global step 96159: loss 4.3457
[2019-04-27 18:02:21,370] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6000, global step 96159: learning rate 0.0000
[2019-04-27 18:02:21,372] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6000, global step 96159: loss -83.5104
[2019-04-27 18:02:21,375] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6000, global step 96159: learning rate 0.0000
[2019-04-27 18:02:21,707] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6000, global step 96322: loss -77.1063
[2019-04-27 18:02:21,710] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6000, global step 96322: learning rate 0.0000
[2019-04-27 18:02:23,019] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.9064970e-19 1.0000000e+00 6.8008157e-21 8.4500086e-21 6.5253595e-19], sum to 1.0000
[2019-04-27 18:02:23,027] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2510
[2019-04-27 18:02:23,034] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 100.0, 1.0, 2.0, 0.5679639097849131, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 659829.4010331787, 659829.4010331787, 153252.7132897004], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3628800.0000, 
sim time next is 3629400.0000, 
raw observation next is [23.0, 100.0, 1.0, 2.0, 0.5722450828270497, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 664169.2329286152, 664169.2329286152, 153942.990958857], 
processed observation next is [1.0, 0.0, 0.4074074074074074, 1.0, 1.0, 1.0, 0.4907679557464877, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23720329747450541, 0.23720329747450541, 0.2960442133824173], 
reward next is 0.7040, 
noisyNet noise sample is [array([-0.88433], dtype=float32), -0.2789395]. 
=============================================
[2019-04-27 18:02:28,934] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.8439111e-17 1.0000000e+00 5.1274994e-20 7.7210499e-20 1.9655565e-19], sum to 1.0000
[2019-04-27 18:02:28,941] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6722
[2019-04-27 18:02:28,949] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2040700.196975747 W.
[2019-04-27 18:02:28,952] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.41666666666667, 77.33333333333334, 1.0, 2.0, 0.8945788878857105, 1.0, 2.0, 0.8945788878857105, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2040700.196975747, 2040700.196975747, 384387.1491041519], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3755400.0000, 
sim time next is 3756000.0000, 
raw observation next is [29.53333333333333, 77.66666666666667, 1.0, 2.0, 0.623975868841098, 1.0, 2.0, 0.623975868841098, 1.0, 1.0, 0.9933899046703603, 6.9112, 6.9112, 121.94756008, 2135219.280423039, 2135219.280423039, 408593.5476483955], 
processed observation next is [1.0, 0.4782608695652174, 0.6493827160493827, 0.7766666666666667, 1.0, 1.0, 0.5523522248108309, 1.0, 1.0, 0.5523522248108309, 1.0, 0.5, 0.9917373808379504, 0.0, 0.0, 0.8096049824067558, 0.7625783144367997, 0.7625783144367997, 0.7857568224007606], 
reward next is 0.2142, 
noisyNet noise sample is [array([-0.89548755], dtype=float32), -1.1080936]. 
=============================================
[2019-04-27 18:02:28,963] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[62.84283 ]
 [62.28213 ]
 [62.171673]
 [61.8209  ]
 [61.117374]], R is [[61.87882996]
 [61.52083969]
 [61.14459229]
 [60.79192734]
 [60.44144821]].
[2019-04-27 18:02:29,208] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.2525012e-17 1.0000000e+00 7.1919635e-17 6.9876190e-18 2.7769300e-17], sum to 1.0000
[2019-04-27 18:02:29,211] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2516
[2019-04-27 18:02:29,218] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1718520.983329991 W.
[2019-04-27 18:02:29,223] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.9, 94.0, 1.0, 2.0, 0.753481381261914, 1.0, 2.0, 0.753481381261914, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1718520.983329991, 1718520.983329992, 324907.5733310188], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3747000.0000, 
sim time next is 3747600.0000, 
raw observation next is [26.0, 94.0, 1.0, 2.0, 0.5465222587871735, 1.0, 2.0, 0.5465222587871735, 1.0, 1.0, 0.8700812349765369, 6.9112, 6.9112, 121.94756008, 1869898.834922981, 1869898.834922981, 367009.0418117598], 
processed observation next is [1.0, 0.391304347826087, 0.5185185185185185, 0.94, 1.0, 1.0, 0.4601455461752066, 1.0, 1.0, 0.4601455461752066, 1.0, 0.5, 0.837601543720671, 0.0, 0.0, 0.8096049824067558, 0.6678210124724933, 0.6678210124724933, 0.7057866188687689], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.164384], dtype=float32), 1.7765994]. 
=============================================
[2019-04-27 18:02:29,394] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-04-27 18:02:29,394] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 18:02:29,395] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 18:02:29,396] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:02:29,395] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 18:02:29,397] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:02:29,399] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:02:29,400] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 18:02:29,398] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 18:02:29,402] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:02:29,403] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:02:29,419] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run5
[2019-04-27 18:02:29,440] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run5
[2019-04-27 18:02:29,458] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run5
[2019-04-27 18:02:29,487] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run5
[2019-04-27 18:02:29,507] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run5
[2019-04-27 18:02:36,871] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.025366688]
[2019-04-27 18:02:36,875] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [17.01666666666667, 88.00000000000001, 1.0, 2.0, 0.2530409259044168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 326401.8581403114, 326401.8581403114, 108359.1863948074]
[2019-04-27 18:02:36,878] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 18:02:36,882] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.8094739e-16 1.0000000e+00 4.1868156e-18 3.2432288e-18 2.5112846e-17], sampled 0.6727247960044371
[2019-04-27 18:02:56,931] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.025366688]
[2019-04-27 18:02:56,934] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [19.0, 94.66666666666667, 1.0, 2.0, 0.3637166205484026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 456296.7696179648, 456296.7696179643, 123733.3053480943]
[2019-04-27 18:02:56,935] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 18:02:56,937] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.7147026e-17 1.0000000e+00 1.5156297e-18 1.2283030e-18 1.0036640e-17], sampled 0.7796263164957259
[2019-04-27 18:03:14,756] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.025366688]
[2019-04-27 18:03:14,760] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.08333333333334, 79.83333333333334, 1.0, 2.0, 0.7669317872403051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 874128.781292273, 874128.781292273, 189209.2167179118]
[2019-04-27 18:03:14,760] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 18:03:14,763] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.6092738e-17 1.0000000e+00 1.8079885e-18 1.5383115e-18 1.2934088e-17], sampled 0.6416852530924338
[2019-04-27 18:03:35,977] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.025366688]
[2019-04-27 18:03:35,978] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.81115904, 87.92851601000001, 1.0, 2.0, 0.9027021109312401, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1028980.136243325, 1028980.136243325, 218068.6288923519]
[2019-04-27 18:03:35,980] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 18:03:35,982] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.8202264e-15 1.0000000e+00 5.0222172e-17 4.1523504e-17 2.9965143e-16], sampled 0.6915659797564309
[2019-04-27 18:03:49,602] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.025366688]
[2019-04-27 18:03:49,604] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.03333333333333, 88.16666666666667, 1.0, 2.0, 0.5236645386194537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 625423.0839272033, 625423.0839272033, 146693.5507313362]
[2019-04-27 18:03:49,605] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 18:03:49,608] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.7419214e-16 1.0000000e+00 6.3715047e-18 5.0092040e-18 3.9442698e-17], sampled 0.040173310036784926
[2019-04-27 18:04:02,218] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.025366688]
[2019-04-27 18:04:02,218] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.0, 87.33333333333334, 1.0, 2.0, 0.6735405702627412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 775405.801936256, 775405.801936256, 171580.9250769065]
[2019-04-27 18:04:02,220] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 18:04:02,223] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.1637327e-16 1.0000000e+00 4.6662958e-18 3.7819533e-18 3.0323323e-17], sampled 0.5957680914986303
[2019-04-27 18:04:15,568] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.0838 2170637693.1962 493.0000
[2019-04-27 18:04:16,021] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-04-27 18:04:16,037] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-04-27 18:04:16,058] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-04-27 18:04:16,058] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-04-27 18:04:17,073] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 100000, evaluation results [100000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.08379319977, 2170637693.1962304, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-04-27 18:04:21,688] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.2188509e-15 1.0000000e+00 1.2481506e-18 6.7934069e-19 1.5421667e-17], sum to 1.0000
[2019-04-27 18:04:21,698] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2821
[2019-04-27 18:04:21,702] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.16666666666666, 59.66666666666667, 1.0, 2.0, 0.6263506300250398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 714206.8510819931, 714206.8510819931, 162688.3900677504], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3834600.0000, 
sim time next is 3835200.0000, 
raw observation next is [30.33333333333334, 60.33333333333334, 1.0, 2.0, 0.6361725441720472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 725022.3303932924, 725022.3303932924, 164412.3876616361], 
processed observation next is [0.0, 0.391304347826087, 0.6790123456790126, 0.6033333333333334, 1.0, 1.0, 0.5668720763952942, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.258936546569033, 0.258936546569033, 0.31617766858006946], 
reward next is 0.6838, 
noisyNet noise sample is [array([-0.6603537], dtype=float32), -0.8104271]. 
=============================================
[2019-04-27 18:04:22,370] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.7974463e-19 1.0000000e+00 1.1810660e-20 3.0829700e-21 2.7590312e-18], sum to 1.0000
[2019-04-27 18:04:22,377] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0652
[2019-04-27 18:04:22,384] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.0, 57.5, 1.0, 2.0, 0.7350849463596973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 837810.7458758174, 837810.7458758178, 182898.1780494148], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3846600.0000, 
sim time next is 3847200.0000, 
raw observation next is [33.0, 57.0, 1.0, 2.0, 0.7467232737189728, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 851082.8576060015, 851082.8576060015, 185183.0156712345], 
processed observation next is [0.0, 0.5217391304347826, 0.7777777777777778, 0.57, 1.0, 1.0, 0.6984800877606819, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.30395816343071486, 0.30395816343071486, 0.35612118398314324], 
reward next is 0.6439, 
noisyNet noise sample is [array([-0.05882851], dtype=float32), -1.271365]. 
=============================================
[2019-04-27 18:04:22,494] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.7808058e-20 1.0000000e+00 2.0549436e-24 4.7782565e-22 6.0457948e-21], sum to 1.0000
[2019-04-27 18:04:22,500] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5924
[2019-04-27 18:04:22,506] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.03333333333334, 54.33333333333334, 1.0, 2.0, 0.7205202628059695, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 821201.8008476354, 821201.8008476349, 180067.7562480613], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3849600.0000, 
sim time next is 3850200.0000, 
raw observation next is [33.05, 53.5, 1.0, 2.0, 0.7168488894001809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 817015.1797220919, 817015.1797220919, 179360.0695343838], 
processed observation next is [0.0, 0.5652173913043478, 0.7796296296296296, 0.535, 1.0, 1.0, 0.6629153445240249, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29179113561503284, 0.29179113561503284, 0.34492321064304576], 
reward next is 0.6551, 
noisyNet noise sample is [array([0.3399998], dtype=float32), 1.2133173]. 
=============================================
[2019-04-27 18:04:24,763] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6500, global step 103673: loss 0.2977
[2019-04-27 18:04:24,765] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6500, global step 103673: learning rate 0.0000
[2019-04-27 18:04:25,042] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6500, global step 103816: loss 0.0248
[2019-04-27 18:04:25,044] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6500, global step 103816: learning rate 0.0000
[2019-04-27 18:04:25,111] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.1954603e-16 1.0000000e+00 4.4502989e-19 1.5463830e-19 2.1463282e-17], sum to 1.0000
[2019-04-27 18:04:25,118] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4977
[2019-04-27 18:04:25,126] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 94.0, 1.0, 2.0, 0.7386361345258864, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 841860.4242443058, 841860.4242443058, 183588.9721726016], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3891600.0000, 
sim time next is 3892200.0000, 
raw observation next is [26.0, 93.50000000000001, 1.0, 2.0, 0.7364653736848121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 839384.9450982494, 839384.9450982494, 183163.5805963995], 
processed observation next is [0.0, 0.043478260869565216, 0.5185185185185185, 0.9350000000000002, 1.0, 1.0, 0.6862683020057287, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29978033753508904, 0.29978033753508904, 0.35223765499307597], 
reward next is 0.6478, 
noisyNet noise sample is [array([-0.40637946], dtype=float32), 1.3654606]. 
=============================================
[2019-04-27 18:04:25,134] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6500, global step 103856: loss 0.0064
[2019-04-27 18:04:25,136] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6500, global step 103856: learning rate 0.0000
[2019-04-27 18:04:25,165] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6500, global step 103872: loss 0.0380
[2019-04-27 18:04:25,167] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6500, global step 103873: learning rate 0.0000
[2019-04-27 18:04:25,249] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6500, global step 103910: loss 0.0042
[2019-04-27 18:04:25,250] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6500, global step 103910: learning rate 0.0000
[2019-04-27 18:04:25,279] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6500, global step 103924: loss 0.0108
[2019-04-27 18:04:25,281] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6500, global step 103925: learning rate 0.0000
[2019-04-27 18:04:25,282] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6500, global step 103926: loss 0.0147
[2019-04-27 18:04:25,287] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6500, global step 103928: learning rate 0.0000
[2019-04-27 18:04:25,342] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6500, global step 103952: loss 0.0105
[2019-04-27 18:04:25,346] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6500, global step 103953: learning rate 0.0000
[2019-04-27 18:04:25,355] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6500, global step 103960: loss 0.0440
[2019-04-27 18:04:25,357] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6500, global step 103960: learning rate 0.0000
[2019-04-27 18:04:25,469] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6500, global step 104010: loss 0.0281
[2019-04-27 18:04:25,470] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6500, global step 104011: learning rate 0.0000
[2019-04-27 18:04:25,527] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6500, global step 104040: loss 0.0055
[2019-04-27 18:04:25,532] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6500, global step 104041: learning rate 0.0000
[2019-04-27 18:04:25,561] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6500, global step 104055: loss 0.0404
[2019-04-27 18:04:25,563] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6500, global step 104055: learning rate 0.0000
[2019-04-27 18:04:25,586] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6500, global step 104067: loss 0.0383
[2019-04-27 18:04:25,589] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6500, global step 104067: learning rate 0.0000
[2019-04-27 18:04:25,814] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6500, global step 104180: loss 0.0374
[2019-04-27 18:04:25,816] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6500, global step 104180: learning rate 0.0000
[2019-04-27 18:04:25,842] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6500, global step 104193: loss 0.1161
[2019-04-27 18:04:25,845] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6500, global step 104193: learning rate 0.0000
[2019-04-27 18:04:26,206] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6500, global step 104371: loss 0.3427
[2019-04-27 18:04:26,208] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6500, global step 104372: learning rate 0.0000
[2019-04-27 18:04:32,057] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.9047238e-12 1.0000000e+00 8.1122966e-13 4.8145792e-13 7.4556897e-12], sum to 1.0000
[2019-04-27 18:04:32,062] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2164
[2019-04-27 18:04:32,067] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1926386.662187629 W.
[2019-04-27 18:04:32,074] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.03333333333333, 88.16666666666667, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 7.005440498237938, 6.9112, 121.925584236632, 1926386.662187629, 1878127.285400699, 383794.3235593336], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4017000.0000, 
sim time next is 4017600.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.5602139849685935, 1.0, 1.0, 0.5602139849685935, 1.0, 2.0, 0.891878908965749, 6.911199999999999, 6.9112, 121.94756008, 1916794.657602789, 1916794.65760279, 374124.6544820407], 
processed observation next is [1.0, 0.5217391304347826, 0.5185185185185185, 0.89, 1.0, 1.0, 0.47644522020070657, 1.0, 0.5, 0.47644522020070657, 1.0, 1.0, 0.8648486362071861, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6845695205724247, 0.684569520572425, 0.7194704893885399], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.13687629], dtype=float32), 0.06714892]. 
=============================================
[2019-04-27 18:04:32,606] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.3613154e-10 1.0000000e+00 7.7020820e-11 1.7970622e-11 1.4273313e-11], sum to 1.0000
[2019-04-27 18:04:32,616] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8303
[2019-04-27 18:04:32,620] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1745488.960303798 W.
[2019-04-27 18:04:32,626] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.33333333333334, 87.33333333333334, 1.0, 2.0, 0.5101960111903111, 1.0, 2.0, 0.5101960111903111, 1.0, 1.0, 0.8122486657390416, 6.9112, 6.9112, 121.94756008, 1745488.960303798, 1745488.960303798, 348621.5586190701], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4029600.0000, 
sim time next is 4030200.0000, 
raw observation next is [26.5, 86.5, 1.0, 2.0, 0.7757455338209883, 1.0, 2.0, 0.7757455338209883, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1769350.780893545, 1769350.780893545, 333834.0691937095], 
processed observation next is [1.0, 0.6521739130434783, 0.5370370370370371, 0.865, 1.0, 1.0, 0.7330303974059384, 1.0, 1.0, 0.7330303974059384, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6319109931762661, 0.6319109931762661, 0.6419885946032875], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.6286349], dtype=float32), 0.7321992]. 
=============================================
[2019-04-27 18:04:33,067] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.5096341e-13 1.0000000e+00 1.5542258e-14 1.7851538e-14 4.9073989e-15], sum to 1.0000
[2019-04-27 18:04:33,076] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4488
[2019-04-27 18:04:33,080] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.685569989467872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 781347.4651601475, 781347.4651601475, 173429.6625745981], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4042200.0000, 
sim time next is 4042800.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.6864492280959202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 782350.0491174161, 782350.0491174161, 173593.9550905963], 
processed observation next is [1.0, 0.8260869565217391, 0.5185185185185185, 0.89, 1.0, 1.0, 0.6267252715427621, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27941073182764864, 0.27941073182764864, 0.3338345290203775], 
reward next is 0.6662, 
noisyNet noise sample is [array([0.13810466], dtype=float32), -0.3352221]. 
=============================================
[2019-04-27 18:04:37,665] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.4545383e-08 9.9999988e-01 1.8063904e-09 2.2233735e-09 4.9866906e-09], sum to 1.0000
[2019-04-27 18:04:37,674] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6867
[2019-04-27 18:04:37,681] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2120874.333566653 W.
[2019-04-27 18:04:37,685] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.13333333333333, 67.33333333333334, 1.0, 2.0, 0.6197888118717103, 1.0, 2.0, 0.6197888118717103, 1.0, 1.0, 0.9867239736121695, 6.911200000000001, 6.9112, 121.94756008, 2120874.333566653, 2120874.333566653, 406262.932106893], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4120800.0000, 
sim time next is 4121400.0000, 
raw observation next is [29.16666666666666, 66.66666666666666, 1.0, 2.0, 0.6137155964570457, 1.0, 2.0, 0.6137155964570457, 1.0, 2.0, 0.9770552168812058, 6.9112, 6.9112, 121.94756008, 2100067.776960796, 2100067.776960796, 402899.1868821862], 
processed observation next is [1.0, 0.6956521739130435, 0.6358024691358023, 0.6666666666666665, 1.0, 1.0, 0.5401376148298163, 1.0, 1.0, 0.5401376148298163, 1.0, 1.0, 0.9713190211015071, 0.0, 0.0, 0.8096049824067558, 0.7500242060574273, 0.7500242060574273, 0.7748061286195889], 
reward next is 0.2252, 
noisyNet noise sample is [array([1.2009], dtype=float32), 0.47830117]. 
=============================================
[2019-04-27 18:04:41,531] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7000, global step 111703: loss -19.6124
[2019-04-27 18:04:41,533] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7000, global step 111704: learning rate 0.0000
[2019-04-27 18:04:41,720] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7000, global step 111805: loss -74.3941
[2019-04-27 18:04:41,721] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7000, global step 111805: learning rate 0.0000
[2019-04-27 18:04:41,780] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7000, global step 111841: loss 56.4079
[2019-04-27 18:04:41,784] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7000, global step 111842: learning rate 0.0000
[2019-04-27 18:04:41,808] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7000, global step 111861: loss 3.1089
[2019-04-27 18:04:41,812] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7000, global step 111863: learning rate 0.0000
[2019-04-27 18:04:41,909] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7000, global step 111913: loss -41.0117
[2019-04-27 18:04:41,911] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7000, global step 111913: learning rate 0.0000
[2019-04-27 18:04:41,977] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7000, global step 111956: loss -93.2445
[2019-04-27 18:04:41,979] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7000, global step 111956: learning rate 0.0000
[2019-04-27 18:04:41,983] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7000, global step 111958: loss -114.3382
[2019-04-27 18:04:41,986] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7000, global step 111958: learning rate 0.0000
[2019-04-27 18:04:42,001] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7000, global step 111966: loss -124.1703
[2019-04-27 18:04:42,002] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7000, global step 111966: learning rate 0.0000
[2019-04-27 18:04:42,013] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7000, global step 111971: loss -66.0265
[2019-04-27 18:04:42,016] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7000, global step 111971: learning rate 0.0000
[2019-04-27 18:04:42,112] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7000, global step 112033: loss 20.1814
[2019-04-27 18:04:42,117] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7000, global step 112036: learning rate 0.0000
[2019-04-27 18:04:42,123] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7000, global step 112040: loss -1.4746
[2019-04-27 18:04:42,124] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7000, global step 112041: learning rate 0.0000
[2019-04-27 18:04:42,127] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7000, global step 112041: loss -7.5879
[2019-04-27 18:04:42,129] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7000, global step 112041: learning rate 0.0000
[2019-04-27 18:04:42,174] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7000, global step 112059: loss -4.4380
[2019-04-27 18:04:42,178] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7000, global step 112059: learning rate 0.0000
[2019-04-27 18:04:42,452] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7000, global step 112217: loss 36.2333
[2019-04-27 18:04:42,452] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7000, global step 112217: loss 6.4545
[2019-04-27 18:04:42,454] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7000, global step 112217: learning rate 0.0000
[2019-04-27 18:04:42,455] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7000, global step 112217: learning rate 0.0000
[2019-04-27 18:04:42,603] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7000, global step 112291: loss -89.7373
[2019-04-27 18:04:42,610] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7000, global step 112291: learning rate 0.0000
[2019-04-27 18:04:48,953] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.07312426e-16 1.00000000e+00 3.55550103e-18 1.29851565e-17
 1.91576833e-17], sum to 1.0000
[2019-04-27 18:04:48,959] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6148
[2019-04-27 18:04:48,965] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 94.00000000000001, 1.0, 2.0, 0.9597197647220109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.984473841780147, 6.9112, 121.9257823224725, 1147859.752896813, 1110337.07686898, 232045.8052751591], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4331400.0000, 
sim time next is 4332000.0000, 
raw observation next is [23.66666666666666, 94.0, 1.0, 2.0, 0.8555025522257342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9259984914974, 992974.2783576988, 992974.2783576988, 208606.1592582218], 
processed observation next is [1.0, 0.13043478260869565, 0.4320987654320985, 0.94, 1.0, 1.0, 0.8279792288401598, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094618358815702, 0.3546336708420353, 0.3546336708420353, 0.40116569088119575], 
reward next is 0.5988, 
noisyNet noise sample is [array([0.64595485], dtype=float32), -0.69193614]. 
=============================================
[2019-04-27 18:04:48,999] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[51.332245]
 [51.898224]
 [52.094322]
 [52.287434]
 [52.23759 ]], R is [[51.32767105]
 [51.00178528]
 [51.10421753]
 [51.23081207]
 [51.34931564]].
[2019-04-27 18:04:57,874] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7500, global step 119622: loss 0.0343
[2019-04-27 18:04:57,878] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7500, global step 119623: learning rate 0.0000
[2019-04-27 18:04:58,128] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7500, global step 119744: loss 0.0096
[2019-04-27 18:04:58,133] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7500, global step 119744: learning rate 0.0000
[2019-04-27 18:04:58,220] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7500, global step 119793: loss 0.1049
[2019-04-27 18:04:58,222] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7500, global step 119794: learning rate 0.0000
[2019-04-27 18:04:58,295] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7500, global step 119828: loss 0.0673
[2019-04-27 18:04:58,300] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7500, global step 119828: learning rate 0.0000
[2019-04-27 18:04:58,358] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7500, global step 119859: loss 0.0687
[2019-04-27 18:04:58,360] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7500, global step 119859: learning rate 0.0000
[2019-04-27 18:04:58,446] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7500, global step 119904: loss 0.0545
[2019-04-27 18:04:58,449] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7500, global step 119904: learning rate 0.0000
[2019-04-27 18:04:58,546] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7500, global step 119954: loss 0.0415
[2019-04-27 18:04:58,549] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7500, global step 119955: learning rate 0.0000
[2019-04-27 18:04:58,557] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7500, global step 119958: loss 0.0576
[2019-04-27 18:04:58,558] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7500, global step 119958: learning rate 0.0000
[2019-04-27 18:04:58,574] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7500, global step 119964: loss 0.0459
[2019-04-27 18:04:58,576] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7500, global step 119964: learning rate 0.0000
[2019-04-27 18:04:58,594] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7500, global step 119974: loss 0.0822
[2019-04-27 18:04:58,599] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7500, global step 119974: learning rate 0.0000
[2019-04-27 18:04:58,723] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7500, global step 120040: loss 0.0095
[2019-04-27 18:04:58,729] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7500, global step 120041: learning rate 0.0000
[2019-04-27 18:04:58,745] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7500, global step 120049: loss 0.0149
[2019-04-27 18:04:58,746] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7500, global step 120050: learning rate 0.0000
[2019-04-27 18:04:58,950] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7500, global step 120143: loss 0.0069
[2019-04-27 18:04:58,952] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7500, global step 120143: learning rate 0.0000
[2019-04-27 18:04:59,180] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7500, global step 120258: loss 0.0085
[2019-04-27 18:04:59,182] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7500, global step 120258: learning rate 0.0000
[2019-04-27 18:04:59,299] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7500, global step 120317: loss 0.0050
[2019-04-27 18:04:59,300] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7500, global step 120318: learning rate 0.0000
[2019-04-27 18:04:59,435] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7500, global step 120383: loss 0.0581
[2019-04-27 18:04:59,437] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7500, global step 120383: learning rate 0.0000
[2019-04-27 18:05:09,017] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-04-27 18:05:09,020] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 18:05:09,022] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:05:09,022] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 18:05:09,025] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 18:05:09,026] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 18:05:09,027] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:05:09,029] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:05:09,028] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 18:05:09,029] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:05:09,031] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:05:09,045] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run6
[2019-04-27 18:05:09,046] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run6
[2019-04-27 18:05:09,046] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run6
[2019-04-27 18:05:09,066] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run6
[2019-04-27 18:05:09,131] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run6
[2019-04-27 18:05:42,375] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.026874334]
[2019-04-27 18:05:42,376] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.3, 68.0, 1.0, 2.0, 0.4621577468201987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 558532.1195804036, 558532.1195804036, 137328.7689577928]
[2019-04-27 18:05:42,377] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 18:05:42,379] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.2841067e-19 1.0000000e+00 3.1911506e-22 8.4305337e-20 1.1243488e-20], sampled 0.6066725428797685
[2019-04-27 18:05:48,363] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.026874334]
[2019-04-27 18:05:48,364] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [32.8, 52.0, 1.0, 2.0, 1.004871827693994, 1.0, 2.0, 1.004871827693994, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156095, 2292621.846863361, 2292621.846863361, 435683.022387618]
[2019-04-27 18:05:48,366] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 18:05:48,368] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.2748078e-15 1.0000000e+00 6.2665053e-18 6.5319941e-16 1.2144434e-16], sampled 0.3937241846312802
[2019-04-27 18:05:48,369] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2292621.846863361 W.
[2019-04-27 18:05:48,849] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.026874334]
[2019-04-27 18:05:48,850] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.858035945, 99.28814393333333, 1.0, 2.0, 0.6714435559093209, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 765239.4631582741, 765239.4631582736, 170809.4745780658]
[2019-04-27 18:05:48,853] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 18:05:48,855] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.2369572e-19 1.0000000e+00 1.5788305e-22 4.2983953e-20 5.4138365e-21], sampled 0.17824163241404
[2019-04-27 18:06:39,039] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.026874334]
[2019-04-27 18:06:39,041] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.92440132, 61.50070072666666, 1.0, 2.0, 0.3534155400403886, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 442254.7710344733, 442254.7710344733, 122336.8777419826]
[2019-04-27 18:06:39,043] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 18:06:39,046] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.5175022e-19 1.0000000e+00 3.5556021e-22 8.8665910e-20 1.1600882e-20], sampled 0.34096995114583795
[2019-04-27 18:06:44,466] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.026874334]
[2019-04-27 18:06:44,467] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.8, 84.0, 1.0, 2.0, 0.3871009758289101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 482378.8373506521, 482378.8373506521, 126874.5172958844]
[2019-04-27 18:06:44,468] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 18:06:44,472] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.7996684e-19 1.0000000e+00 1.2462544e-22 3.4365099e-20 4.2976552e-21], sampled 0.632946501940666
[2019-04-27 18:06:48,387] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.026874334]
[2019-04-27 18:06:48,388] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [18.66666666666667, 74.66666666666667, 1.0, 2.0, 0.2679060594239432, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 345525.4514928236, 345525.4514928241, 111082.8256454346]
[2019-04-27 18:06:48,391] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 18:06:48,394] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.7093344e-19 1.0000000e+00 1.1416223e-22 3.1544571e-20 3.9777908e-21], sampled 0.1931419630903366
[2019-04-27 18:06:55,512] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-04-27 18:06:55,591] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-04-27 18:06:55,837] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8923.4132 2120429144.2209 430.0000
[2019-04-27 18:06:55,913] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-04-27 18:06:55,955] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-04-27 18:06:56,970] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 125000, evaluation results [125000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8923.413159724274, 2120429144.2209237, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-04-27 18:06:58,090] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.103670e-11 1.000000e+00 6.495478e-13 2.504998e-10 2.021694e-11], sum to 1.0000
[2019-04-27 18:06:58,095] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0364
[2019-04-27 18:06:58,102] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1632766.537706233 W.
[2019-04-27 18:06:58,108] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.16666666666667, 89.0, 1.0, 2.0, 0.4772779965077265, 1.0, 1.0, 0.4772779965077265, 1.0, 2.0, 0.7598421142994736, 6.9112, 6.9112, 121.94756008, 1632766.537706233, 1632766.537706233, 332576.8594542108], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4709400.0000, 
sim time next is 4710000.0000, 
raw observation next is [26.33333333333334, 89.0, 1.0, 2.0, 0.5750780202367359, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9155429372004643, 6.911199999999999, 6.9112, 121.9260426156618, 1311291.528395858, 1311291.528395858, 284292.2716866937], 
processed observation next is [1.0, 0.5217391304347826, 0.5308641975308644, 0.89, 1.0, 1.0, 0.4941405002818285, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.8944286715005803, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4683184029985207, 0.4683184029985207, 0.5467159070897956], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.31678703], dtype=float32), -0.5129877]. 
=============================================
[2019-04-27 18:06:58,130] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[36.082943]
 [35.770992]
 [35.9021  ]
 [34.83408 ]
 [34.164326]], R is [[36.1687355 ]
 [36.16747665]
 [36.09643173]
 [36.09786224]
 [36.0888443 ]].
[2019-04-27 18:07:02,583] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8000, global step 127700: loss -57.6048
[2019-04-27 18:07:02,586] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8000, global step 127700: learning rate 0.0000
[2019-04-27 18:07:02,715] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8000, global step 127766: loss 34.7757
[2019-04-27 18:07:02,717] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8000, global step 127766: learning rate 0.0000
[2019-04-27 18:07:02,902] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8000, global step 127853: loss -69.0906
[2019-04-27 18:07:02,904] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8000, global step 127853: learning rate 0.0000
[2019-04-27 18:07:02,975] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8000, global step 127884: loss -95.1258
[2019-04-27 18:07:02,977] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8000, global step 127885: learning rate 0.0000
[2019-04-27 18:07:02,993] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8000, global step 127896: loss -63.5059
[2019-04-27 18:07:02,994] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8000, global step 127896: learning rate 0.0000
[2019-04-27 18:07:03,091] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8000, global step 127939: loss -79.8096
[2019-04-27 18:07:03,093] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8000, global step 127939: learning rate 0.0000
[2019-04-27 18:07:03,135] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8000, global step 127955: loss -75.2187
[2019-04-27 18:07:03,138] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8000, global step 127955: learning rate 0.0000
[2019-04-27 18:07:03,148] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8000, global step 127962: loss -16.2040
[2019-04-27 18:07:03,151] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8000, global step 127963: learning rate 0.0000
[2019-04-27 18:07:03,219] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8000, global step 127997: loss -94.0431
[2019-04-27 18:07:03,221] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8000, global step 127997: learning rate 0.0000
[2019-04-27 18:07:03,245] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8000, global step 128010: loss -4.3637
[2019-04-27 18:07:03,247] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8000, global step 128010: learning rate 0.0000
[2019-04-27 18:07:03,278] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8000, global step 128020: loss 66.8706
[2019-04-27 18:07:03,279] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8000, global step 128020: learning rate 0.0000
[2019-04-27 18:07:03,466] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8000, global step 128105: loss 13.0194
[2019-04-27 18:07:03,469] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8000, global step 128106: learning rate 0.0000
[2019-04-27 18:07:03,522] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8000, global step 128136: loss -27.4690
[2019-04-27 18:07:03,523] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8000, global step 128136: learning rate 0.0000
[2019-04-27 18:07:03,569] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8000, global step 128159: loss -41.2782
[2019-04-27 18:07:03,571] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8000, global step 128160: learning rate 0.0000
[2019-04-27 18:07:03,619] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8000, global step 128178: loss -69.1340
[2019-04-27 18:07:03,620] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8000, global step 128178: learning rate 0.0000
[2019-04-27 18:07:03,732] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.2275218e-08 9.9999988e-01 1.5846392e-09 9.5072600e-08 3.9068486e-09], sum to 1.0000
[2019-04-27 18:07:03,740] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0852
[2019-04-27 18:07:03,747] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1878205.792422418 W.
[2019-04-27 18:07:03,753] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.33333333333334, 86.33333333333334, 1.0, 2.0, 0.8234212689088609, 1.0, 2.0, 0.8234212689088609, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156275, 1878205.792422418, 1878205.792422418, 353528.297138626], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4803600.0000, 
sim time next is 4804200.0000, 
raw observation next is [27.25, 87.0, 1.0, 2.0, 0.8448477699545519, 1.0, 2.0, 0.8448477699545519, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1927131.897823474, 1927131.897823474, 362635.5133735515], 
processed observation next is [1.0, 0.6086956521739131, 0.5648148148148148, 0.87, 1.0, 1.0, 0.8152949642316094, 1.0, 1.0, 0.8152949642316094, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.6882613920798121, 0.6882613920798121, 0.6973759872568298], 
reward next is 0.3026, 
noisyNet noise sample is [array([0.14339016], dtype=float32), -1.3909044]. 
=============================================
[2019-04-27 18:07:03,754] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8000, global step 128244: loss -32.0016
[2019-04-27 18:07:03,756] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8000, global step 128244: learning rate 0.0000
[2019-04-27 18:07:11,975] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.19261002e-15 1.00000000e+00 8.39524050e-18 2.83479549e-14
 1.24182045e-17], sum to 1.0000
[2019-04-27 18:07:11,980] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0952
[2019-04-27 18:07:11,985] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.25, 83.5, 1.0, 2.0, 0.7736634883818039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 912873.5071061539, 912873.5071061539, 192064.3039069992], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4951800.0000, 
sim time next is 4952400.0000, 
raw observation next is [24.33333333333333, 81.66666666666667, 1.0, 2.0, 0.6172945005980207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 730770.9486074543, 730770.9486074543, 162318.6780955882], 
processed observation next is [1.0, 0.30434782608695654, 0.45679012345678993, 0.8166666666666668, 1.0, 1.0, 0.5443982149976437, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2609896245026623, 0.2609896245026623, 0.3121513040299773], 
reward next is 0.6878, 
noisyNet noise sample is [array([-0.08404458], dtype=float32), 0.4219895]. 
=============================================
[2019-04-27 18:07:16,951] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.8483204e-18 1.0000000e+00 1.1980245e-18 1.0397953e-16 1.7761252e-19], sum to 1.0000
[2019-04-27 18:07:16,959] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2452
[2019-04-27 18:07:16,963] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.91666666666667, 74.0, 1.0, 2.0, 0.7089086992626079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 807960.7259915761, 807960.7259915756, 177839.1617807504], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5050200.0000, 
sim time next is 5050800.0000, 
raw observation next is [29.1, 73.0, 1.0, 2.0, 0.7088494455202153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 807893.157448888, 807893.157448888, 177827.9214548496], 
processed observation next is [0.0, 0.4782608695652174, 0.6333333333333334, 0.73, 1.0, 1.0, 0.6533921970478754, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28853327051746, 0.28853327051746, 0.3419767720285569], 
reward next is 0.6580, 
noisyNet noise sample is [array([-1.1124593], dtype=float32), 0.35126474]. 
=============================================
[2019-04-27 18:07:19,048] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8500, global step 135627: loss 6.2423
[2019-04-27 18:07:19,051] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8500, global step 135627: learning rate 0.0000
[2019-04-27 18:07:19,223] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8500, global step 135711: loss 4.8831
[2019-04-27 18:07:19,224] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8500, global step 135711: learning rate 0.0000
[2019-04-27 18:07:19,420] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8500, global step 135809: loss 3.0517
[2019-04-27 18:07:19,423] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8500, global step 135810: learning rate 0.0000
[2019-04-27 18:07:19,585] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8500, global step 135887: loss 4.9605
[2019-04-27 18:07:19,587] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8500, global step 135887: learning rate 0.0000
[2019-04-27 18:07:19,639] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8500, global step 135910: loss 5.3762
[2019-04-27 18:07:19,640] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8500, global step 135910: learning rate 0.0000
[2019-04-27 18:07:19,696] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8500, global step 135942: loss 5.1447
[2019-04-27 18:07:19,701] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8500, global step 135944: learning rate 0.0000
[2019-04-27 18:07:19,719] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8500, global step 135955: loss 5.1296
[2019-04-27 18:07:19,725] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8500, global step 135958: loss 5.3827
[2019-04-27 18:07:19,726] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8500, global step 135957: learning rate 0.0000
[2019-04-27 18:07:19,729] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8500, global step 135959: learning rate 0.0000
[2019-04-27 18:07:19,753] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8500, global step 135970: loss 4.2379
[2019-04-27 18:07:19,755] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8500, global step 135970: learning rate 0.0000
[2019-04-27 18:07:19,758] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8500, global step 135970: loss 5.1403
[2019-04-27 18:07:19,760] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8500, global step 135970: learning rate 0.0000
[2019-04-27 18:07:19,829] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8500, global step 136001: loss 3.9051
[2019-04-27 18:07:19,835] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8500, global step 136001: learning rate 0.0000
[2019-04-27 18:07:20,116] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8500, global step 136140: loss 2.6435
[2019-04-27 18:07:20,119] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8500, global step 136140: learning rate 0.0000
[2019-04-27 18:07:20,168] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8500, global step 136160: loss 3.7307
[2019-04-27 18:07:20,169] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8500, global step 136160: learning rate 0.0000
[2019-04-27 18:07:20,318] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8500, global step 136234: loss 5.3591
[2019-04-27 18:07:20,320] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8500, global step 136234: learning rate 0.0000
[2019-04-27 18:07:20,357] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8500, global step 136250: loss 4.7171
[2019-04-27 18:07:20,360] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8500, global step 136250: learning rate 0.0000
[2019-04-27 18:07:20,403] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8500, global step 136269: loss 5.3269
[2019-04-27 18:07:20,405] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8500, global step 136269: learning rate 0.0000
[2019-04-27 18:07:35,741] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9000, global step 143622: loss -15.2254
[2019-04-27 18:07:35,742] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9000, global step 143622: learning rate 0.0000
[2019-04-27 18:07:36,072] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9000, global step 143778: loss 120.3490
[2019-04-27 18:07:36,074] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9000, global step 143778: learning rate 0.0000
[2019-04-27 18:07:36,249] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9000, global step 143861: loss -30.6351
[2019-04-27 18:07:36,251] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9000, global step 143861: learning rate 0.0000
[2019-04-27 18:07:36,259] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9000, global step 143866: loss 0.8620
[2019-04-27 18:07:36,263] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9000, global step 143868: learning rate 0.0000
[2019-04-27 18:07:36,340] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9000, global step 143904: loss -68.0958
[2019-04-27 18:07:36,345] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9000, global step 143906: learning rate 0.0000
[2019-04-27 18:07:36,398] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9000, global step 143932: loss -30.2769
[2019-04-27 18:07:36,400] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9000, global step 143932: learning rate 0.0000
[2019-04-27 18:07:36,464] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9000, global step 143962: loss 130.4635
[2019-04-27 18:07:36,465] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9000, global step 143962: learning rate 0.0000
[2019-04-27 18:07:36,470] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9000, global step 143964: loss 31.3252
[2019-04-27 18:07:36,472] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9000, global step 143965: learning rate 0.0000
[2019-04-27 18:07:36,540] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9000, global step 144000: loss -39.5936
[2019-04-27 18:07:36,541] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9000, global step 144000: loss 148.2530
[2019-04-27 18:07:36,542] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9000, global step 144000: learning rate 0.0000
[2019-04-27 18:07:36,542] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9000, global step 144000: learning rate 0.0000
[2019-04-27 18:07:36,549] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9000, global step 144002: loss 55.4507
[2019-04-27 18:07:36,551] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9000, global step 144003: learning rate 0.0000
[2019-04-27 18:07:36,873] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9000, global step 144157: loss -47.0849
[2019-04-27 18:07:36,875] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9000, global step 144159: learning rate 0.0000
[2019-04-27 18:07:36,909] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9000, global step 144173: loss -79.2443
[2019-04-27 18:07:36,910] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9000, global step 144173: learning rate 0.0000
[2019-04-27 18:07:36,956] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9000, global step 144194: loss -18.1115
[2019-04-27 18:07:36,958] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9000, global step 144194: learning rate 0.0000
[2019-04-27 18:07:36,980] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9000, global step 144204: loss -50.7822
[2019-04-27 18:07:36,983] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9000, global step 144204: learning rate 0.0000
[2019-04-27 18:07:37,030] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9000, global step 144230: loss 56.8163
[2019-04-27 18:07:37,032] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9000, global step 144230: learning rate 0.0000
[2019-04-27 18:07:41,222] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.3952849e-12 1.0000000e+00 1.4994379e-15 5.0635874e-13 5.0619405e-15], sum to 1.0000
[2019-04-27 18:07:41,229] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5492
[2019-04-27 18:07:41,238] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2302540.345548658 W.
[2019-04-27 18:07:41,245] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.21666666666666, 64.0, 1.0, 2.0, 0.7188890809455075, 1.0, 2.0, 0.6728092024491884, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2302540.345548658, 2302540.345548658, 434354.4578164644], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5493000.0000, 
sim time next is 5493600.0000, 
raw observation next is [33.4, 63.0, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 8.484801081678764, 6.9112, 121.9199867346289, 3134017.217214476, 2328232.840598211, 443050.4698351264], 
processed observation next is [1.0, 0.6086956521739131, 0.7925925925925925, 0.63, 1.0, 1.0, 1.0238095238095237, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.25, 0.15736010816787643, 0.0, 0.8094219240677499, 1.1192918632908841, 0.8315117287850754, 0.85202013429832], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.21724951], dtype=float32), -0.5895508]. 
=============================================
[2019-04-27 18:07:49,091] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-04-27 18:07:49,094] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 18:07:49,095] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:07:49,095] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 18:07:49,097] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 18:07:49,098] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 18:07:49,101] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:07:49,101] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:07:49,104] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:07:49,100] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 18:07:49,107] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:07:49,117] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run7
[2019-04-27 18:07:49,118] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run7
[2019-04-27 18:07:49,160] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run7
[2019-04-27 18:07:49,163] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run7
[2019-04-27 18:07:49,185] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run7
[2019-04-27 18:07:51,246] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.02731008]
[2019-04-27 18:07:51,248] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.595988315, 42.62826181833334, 1.0, 2.0, 0.3603517703306276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 450589.345821519, 450589.345821519, 123255.9064533558]
[2019-04-27 18:07:51,249] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 18:07:51,252] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0445752e-21 1.0000000e+00 2.4430605e-26 7.5795101e-21 3.3099859e-25], sampled 0.08646112507343295
[2019-04-27 18:08:00,256] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.02731008]
[2019-04-27 18:08:00,260] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.77980272, 47.36152145, 1.0, 2.0, 0.318634873817453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 405309.3395343045, 405309.3395343045, 117903.3428507336]
[2019-04-27 18:08:00,261] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 18:08:00,263] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [5.8950751e-21 1.0000000e+00 2.3581074e-25 4.1577965e-20 2.5600053e-24], sampled 0.9177104534933769
[2019-04-27 18:08:42,645] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.02731008]
[2019-04-27 18:08:42,646] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.83333333333333, 85.66666666666666, 1.0, 2.0, 0.6060014005563038, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9647739657734038, 6.911199999999999, 6.9112, 121.9260426156618, 1381866.5533855, 1381866.5533855, 296205.2773038496]
[2019-04-27 18:08:42,647] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 18:08:42,649] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.5317174e-19 1.0000000e+00 1.1570766e-23 1.0794593e-18 1.1571435e-22], sampled 0.8079641903668671
[2019-04-27 18:08:42,650] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1381866.5533855 W.
[2019-04-27 18:08:58,094] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.02731008]
[2019-04-27 18:08:58,095] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [33.78108257, 71.6608543, 1.0, 2.0, 1.003388741181346, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.165545488764669, 6.9112, 121.9251390298797, 1274181.283445122, 1143934.625312251, 241569.8801969451]
[2019-04-27 18:08:58,096] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 18:08:58,098] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [5.5062105e-20 1.0000000e+00 3.6227262e-24 3.4933063e-19 3.5981164e-23], sampled 0.4745855184697705
[2019-04-27 18:08:58,258] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.02731008]
[2019-04-27 18:08:58,260] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.13906252, 79.34822395, 1.0, 2.0, 0.7473035416268395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 851744.5893373243, 851744.5893373243, 185299.6100835244]
[2019-04-27 18:08:58,261] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 18:08:58,264] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.5632730e-21 1.0000000e+00 8.4883683e-26 1.8399505e-20 9.8610059e-25], sampled 0.4520785181652648
[2019-04-27 18:09:26,821] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.02731008]
[2019-04-27 18:09:26,822] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.46666666666667, 34.0, 1.0, 2.0, 0.3145220851996356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 404755.0408409365, 404755.0408409365, 117382.7944435023]
[2019-04-27 18:09:26,824] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 18:09:26,828] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.7648465e-22 1.0000000e+00 1.3609407e-26 4.8876551e-21 1.9405920e-25], sampled 0.9110047139772806
[2019-04-27 18:09:33,843] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.02731008]
[2019-04-27 18:09:33,845] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.87016449333333, 66.38584486333333, 1.0, 2.0, 0.5026990874137958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 614653.5914851837, 614653.5914851832, 143815.0698524506]
[2019-04-27 18:09:33,848] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 18:09:33,851] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.8233997e-21 1.0000000e+00 9.3664944e-26 2.0090149e-20 1.0678246e-24], sampled 0.17017090654640044
[2019-04-27 18:09:35,302] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-04-27 18:09:35,478] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.0852 2170656631.3663 493.0000
[2019-04-27 18:09:35,834] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-04-27 18:09:35,872] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-04-27 18:09:36,054] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-04-27 18:09:37,069] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 150000, evaluation results [150000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.085197215923, 2170656631.3662677, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-04-27 18:09:40,252] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9500, global step 151533: loss 0.0522
[2019-04-27 18:09:40,254] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9500, global step 151533: learning rate 0.0000
[2019-04-27 18:09:40,558] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9500, global step 151689: loss 0.0123
[2019-04-27 18:09:40,561] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9500, global step 151689: learning rate 0.0000
[2019-04-27 18:09:40,728] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9500, global step 151773: loss 0.2246
[2019-04-27 18:09:40,731] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9500, global step 151773: learning rate 0.0000
[2019-04-27 18:09:40,827] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9500, global step 151820: loss 0.1106
[2019-04-27 18:09:40,833] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9500, global step 151821: learning rate 0.0000
[2019-04-27 18:09:40,960] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9500, global step 151882: loss 0.0033
[2019-04-27 18:09:40,963] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9500, global step 151884: loss 0.0047
[2019-04-27 18:09:40,965] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9500, global step 151884: learning rate 0.0000
[2019-04-27 18:09:40,968] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9500, global step 151884: learning rate 0.0000
[2019-04-27 18:09:40,995] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9500, global step 151899: loss 0.0016
[2019-04-27 18:09:40,997] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9500, global step 151899: learning rate 0.0000
[2019-04-27 18:09:41,163] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9500, global step 151980: loss 0.0091
[2019-04-27 18:09:41,164] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9500, global step 151980: learning rate 0.0000
[2019-04-27 18:09:41,234] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9500, global step 152012: loss 0.0017
[2019-04-27 18:09:41,236] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9500, global step 152012: learning rate 0.0000
[2019-04-27 18:09:41,315] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9500, global step 152053: loss 0.0439
[2019-04-27 18:09:41,317] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9500, global step 152053: learning rate 0.0000
[2019-04-27 18:09:41,347] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9500, global step 152067: loss 0.0865
[2019-04-27 18:09:41,350] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9500, global step 152067: learning rate 0.0000
[2019-04-27 18:09:41,454] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.0588039e-19 1.0000000e+00 5.7068324e-24 1.2386459e-17 2.1759765e-22], sum to 1.0000
[2019-04-27 18:09:41,463] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1148
[2019-04-27 18:09:41,467] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.25, 96.5, 1.0, 2.0, 0.524146491783805, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 622642.1795335695, 622642.179533569, 146645.2290644922], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5707800.0000, 
sim time next is 5708400.0000, 
raw observation next is [22.16666666666667, 96.66666666666666, 1.0, 2.0, 0.5195752095997188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 617950.4668162714, 617950.4668162714, 145938.5138395125], 
processed observation next is [0.0, 0.043478260869565216, 0.3765432098765434, 0.9666666666666666, 1.0, 1.0, 0.42806572571395096, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22069659529152552, 0.22069659529152552, 0.2806509881529087], 
reward next is 0.7193, 
noisyNet noise sample is [array([-1.3519748], dtype=float32), -0.44222447]. 
=============================================
[2019-04-27 18:09:41,611] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9500, global step 152198: loss 0.0353
[2019-04-27 18:09:41,616] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9500, global step 152198: learning rate 0.0000
[2019-04-27 18:09:41,701] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9500, global step 152242: loss 0.0498
[2019-04-27 18:09:41,703] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9500, global step 152243: learning rate 0.0000
[2019-04-27 18:09:41,746] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9500, global step 152264: loss 0.0499
[2019-04-27 18:09:41,747] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9500, global step 152264: learning rate 0.0000
[2019-04-27 18:09:41,764] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9500, global step 152272: loss 0.0740
[2019-04-27 18:09:41,766] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9500, global step 152272: learning rate 0.0000
[2019-04-27 18:09:41,771] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9500, global step 152274: loss 0.0204
[2019-04-27 18:09:41,773] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9500, global step 152274: learning rate 0.0000
[2019-04-27 18:09:48,658] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.4206328e-16 1.0000000e+00 3.2704118e-18 2.9778053e-15 9.5598680e-19], sum to 1.0000
[2019-04-27 18:09:48,661] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6057
[2019-04-27 18:09:48,666] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1456207.322861554 W.
[2019-04-27 18:09:48,672] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.5, 47.0, 1.0, 2.0, 0.6002792603254475, 1.0, 1.0, 0.6002792603254475, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9256591948127, 1456207.322861554, 1456207.322861554, 271814.553556415], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5837400.0000, 
sim time next is 5838000.0000, 
raw observation next is [27.56666666666667, 47.0, 1.0, 2.0, 0.5293514762283309, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8620816929535835, 6.911199999999999, 6.9112, 121.9260424987449, 1287337.119764692, 1287337.119764693, 264793.4067937676], 
processed observation next is [1.0, 0.5652173913043478, 0.5765432098765433, 0.47, 1.0, 1.0, 0.43970413836706057, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.8276021161919794, -8.881784197001253e-17, 0.0, 0.8094621280439294, 0.45976325705881854, 0.45976325705881893, 0.5092180899880145], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.31581444], dtype=float32), -0.50454146]. 
=============================================
[2019-04-27 18:09:48,690] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[51.59601 ]
 [53.897305]
 [55.18773 ]
 [55.467056]
 [55.401245]], R is [[50.04502869]
 [50.02185822]
 [49.52164078]
 [49.6321373 ]
 [49.81056976]].
[2019-04-27 18:09:49,167] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.8886945e-10 1.0000000e+00 3.6504499e-13 1.5539030e-10 8.2323802e-13], sum to 1.0000
[2019-04-27 18:09:49,173] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1201
[2019-04-27 18:09:49,182] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1455706.89022115 W.
[2019-04-27 18:09:49,191] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.06666666666667, 42.33333333333334, 1.0, 2.0, 0.9658539710620138, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.425749191314619, 6.9112, 121.9238943768276, 1455706.89022115, 1192216.356956342, 236656.9836814656], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5847600.0000, 
sim time next is 5848200.0000, 
raw observation next is [28.1, 42.0, 1.0, 2.0, 0.5378431066471123, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8836072339582682, 6.911199999999999, 6.9112, 121.9257327629088, 1321287.26124188, 1321287.261241881, 267053.0454874411], 
processed observation next is [1.0, 0.6956521739130435, 0.5962962962962963, 0.42, 1.0, 1.0, 0.4498132221989432, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.8545090424478352, -8.881784197001253e-17, 0.0, 0.8094600717200802, 0.4718883075863857, 0.47188830758638606, 0.5135635490143099], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6622311], dtype=float32), -0.28703836]. 
=============================================
[2019-04-27 18:09:50,209] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.8347897e-18 1.0000000e+00 3.0674381e-21 5.8085459e-16 2.5738945e-21], sum to 1.0000
[2019-04-27 18:09:50,218] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9547
[2019-04-27 18:09:50,222] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.46666666666667, 66.33333333333333, 1.0, 2.0, 0.4254023869950382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 522230.71910908, 522230.71910908, 132135.985608184], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5863200.0000, 
sim time next is 5863800.0000, 
raw observation next is [24.28333333333333, 67.16666666666667, 1.0, 2.0, 0.4231987419491907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 519863.0729555229, 519863.0729555234, 131825.5131220128], 
processed observation next is [1.0, 0.8695652173913043, 0.4549382716049382, 0.6716666666666667, 1.0, 1.0, 0.31333183565379846, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18566538319840103, 0.1856653831984012, 0.2535106021577169], 
reward next is 0.7465, 
noisyNet noise sample is [array([-1.1508795], dtype=float32), -1.1814204]. 
=============================================
[2019-04-27 18:09:52,818] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.8174633e-19 1.0000000e+00 7.2016052e-23 2.6102444e-19 3.8540503e-23], sum to 1.0000
[2019-04-27 18:09:52,829] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9748
[2019-04-27 18:09:52,832] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.1, 66.0, 1.0, 2.0, 0.9134933140203046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.074540755235944, 6.9112, 121.9253655600135, 1210693.75510823, 1127049.153677667, 224258.6799499373], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5908800.0000, 
sim time next is 5909400.0000, 
raw observation next is [24.35, 65.0, 1.0, 2.0, 0.9413476595919941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.252285634251525, 6.9112, 121.9244880806547, 1334694.44851108, 1160030.344850394, 230745.1570126223], 
processed observation next is [1.0, 0.391304347826087, 0.4574074074074075, 0.65, 1.0, 1.0, 0.9301757852285644, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.03410856342515247, 0.0, 0.8094518083242912, 0.4766765887539571, 0.4142965517322835, 0.4437406865627352], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.844762], dtype=float32), -0.38237187]. 
=============================================
[2019-04-27 18:09:55,456] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.1178806e-19 1.0000000e+00 5.4418844e-24 1.2140114e-18 5.2921936e-23], sum to 1.0000
[2019-04-27 18:09:55,467] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8128
[2019-04-27 18:09:55,472] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.55, 74.5, 1.0, 2.0, 0.485579866758287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 583868.0260103213, 583868.0260103213, 140815.3472373937], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5952600.0000, 
sim time next is 5953200.0000, 
raw observation next is [24.33333333333333, 75.66666666666667, 1.0, 2.0, 0.4838867661827436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 582208.0135118129, 582208.0135118129, 140566.0875576438], 
processed observation next is [1.0, 0.9130434782608695, 0.45679012345678993, 0.7566666666666667, 1.0, 1.0, 0.3855794835508852, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20793143339707604, 0.20793143339707604, 0.270319399149315], 
reward next is 0.7297, 
noisyNet noise sample is [array([0.783934], dtype=float32), 1.7365568]. 
=============================================
[2019-04-27 18:09:55,901] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.677997e-20 1.000000e+00 6.149174e-24 5.081684e-19 5.925913e-23], sum to 1.0000
[2019-04-27 18:09:55,910] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1077
[2019-04-27 18:09:55,915] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.7, 79.5, 1.0, 2.0, 0.4808505093004398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 579384.3603805392, 579384.3603805392, 140125.3556623392], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5955000.0000, 
sim time next is 5955600.0000, 
raw observation next is [23.5, 81.0, 1.0, 2.0, 0.4825822734056537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 581344.6071777345, 581344.607177734, 140388.4203342463], 
processed observation next is [1.0, 0.9565217391304348, 0.42592592592592593, 0.81, 1.0, 1.0, 0.3840265159591116, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20762307399204805, 0.20762307399204788, 0.2699777314120121], 
reward next is 0.7300, 
noisyNet noise sample is [array([0.3303554], dtype=float32), -0.28127798]. 
=============================================
[2019-04-27 18:09:57,051] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10000, global step 159587: loss -213.7691
[2019-04-27 18:09:57,054] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10000, global step 159587: learning rate 0.0000
[2019-04-27 18:09:57,325] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10000, global step 159720: loss -190.7866
[2019-04-27 18:09:57,328] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10000, global step 159720: learning rate 0.0000
[2019-04-27 18:09:57,356] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10000, global step 159731: loss -198.9967
[2019-04-27 18:09:57,357] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10000, global step 159731: learning rate 0.0000
[2019-04-27 18:09:57,613] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10000, global step 159856: loss -185.2504
[2019-04-27 18:09:57,615] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10000, global step 159857: learning rate 0.0000
[2019-04-27 18:09:57,628] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10000, global step 159864: loss -171.1672
[2019-04-27 18:09:57,635] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10000, global step 159864: learning rate 0.0000
[2019-04-27 18:09:57,723] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10000, global step 159908: loss -103.9989
[2019-04-27 18:09:57,726] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10000, global step 159908: learning rate 0.0000
[2019-04-27 18:09:57,800] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10000, global step 159947: loss -187.0718
[2019-04-27 18:09:57,802] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10000, global step 159947: learning rate 0.0000
[2019-04-27 18:09:57,887] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10000, global step 159983: loss -93.4660
[2019-04-27 18:09:57,889] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10000, global step 159983: learning rate 0.0000
[2019-04-27 18:09:57,927] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10000, global step 160008: loss -99.5223
[2019-04-27 18:09:57,930] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10000, global step 160009: learning rate 0.0000
[2019-04-27 18:09:57,948] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.0597465e-14 1.0000000e+00 6.7518738e-16 4.0236850e-12 1.7723995e-15], sum to 1.0000
[2019-04-27 18:09:57,960] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0186
[2019-04-27 18:09:57,967] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10000, global step 160026: loss -170.9166
[2019-04-27 18:09:57,968] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1502262.452417148 W.
[2019-04-27 18:09:57,969] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10000, global step 160026: learning rate 0.0000
[2019-04-27 18:09:57,976] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.86666666666667, 68.66666666666667, 1.0, 2.0, 0.6546665890556241, 1.0, 1.0, 0.6546665890556241, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1502262.452417148, 1502262.452417148, 287828.1729230391], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6002400.0000, 
sim time next is 6003000.0000, 
raw observation next is [27.15, 68.0, 1.0, 2.0, 0.7109482990665896, 1.0, 2.0, 0.7109482990665896, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1621851.596862126, 1621851.596862126, 308351.4120729544], 
processed observation next is [1.0, 0.4782608695652174, 0.561111111111111, 0.68, 1.0, 1.0, 0.6558908322221305, 1.0, 1.0, 0.6558908322221305, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.579232713165045, 0.579232713165045, 0.5929834847556815], 
reward next is 0.4070, 
noisyNet noise sample is [array([0.4161314], dtype=float32), -1.2636274]. 
=============================================
[2019-04-27 18:09:57,993] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[45.14569 ]
 [45.526302]
 [45.086514]
 [44.481033]
 [44.685062]], R is [[45.59247971]
 [45.13655472]
 [44.68518829]
 [44.74607849]
 [44.70692062]].
[2019-04-27 18:09:57,997] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10000, global step 160036: loss -140.8904
[2019-04-27 18:09:57,998] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10000, global step 160036: learning rate 0.0000
[2019-04-27 18:09:58,260] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10000, global step 160164: loss -139.6438
[2019-04-27 18:09:58,267] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10000, global step 160167: learning rate 0.0000
[2019-04-27 18:09:58,293] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10000, global step 160181: loss -122.6844
[2019-04-27 18:09:58,294] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10000, global step 160181: loss -114.2167
[2019-04-27 18:09:58,294] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10000, global step 160181: learning rate 0.0000
[2019-04-27 18:09:58,296] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10000, global step 160181: learning rate 0.0000
[2019-04-27 18:09:58,329] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10000, global step 160193: loss -88.7893
[2019-04-27 18:09:58,332] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10000, global step 160194: learning rate 0.0000
[2019-04-27 18:09:58,443] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10000, global step 160251: loss -99.2811
[2019-04-27 18:09:58,445] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10000, global step 160251: learning rate 0.0000
[2019-04-27 18:10:00,744] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.2976967e-18 1.0000000e+00 7.1025766e-21 2.6482899e-17 1.0073644e-19], sum to 1.0000
[2019-04-27 18:10:00,751] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8706
[2019-04-27 18:10:00,755] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.96666666666667, 88.33333333333334, 1.0, 2.0, 0.5241998220515287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 626560.0570535586, 626560.0570535591, 146798.1455468492], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6061200.0000, 
sim time next is 6061800.0000, 
raw observation next is [23.03333333333333, 88.16666666666667, 1.0, 2.0, 0.5236645386194537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 625423.0839272033, 625423.0839272033, 146693.5507313362], 
processed observation next is [1.0, 0.13043478260869565, 0.4086419753086419, 0.8816666666666667, 1.0, 1.0, 0.4329339745469687, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22336538711685833, 0.22336538711685833, 0.28210298217564655], 
reward next is 0.7179, 
noisyNet noise sample is [array([0.438881], dtype=float32), -0.4410185]. 
=============================================
[2019-04-27 18:10:00,868] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.3854904e-19 1.0000000e+00 3.6721074e-23 6.7128592e-17 4.9225304e-22], sum to 1.0000
[2019-04-27 18:10:00,878] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8811
[2019-04-27 18:10:00,881] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666666, 83.66666666666667, 1.0, 2.0, 0.5042087014496544, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 601778.7100497469, 601778.7100497469, 143572.777178622], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6049200.0000, 
sim time next is 6049800.0000, 
raw observation next is [23.55, 84.5, 1.0, 2.0, 0.5039256835766857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 601462.792358101, 601462.7923581005, 143528.9020614045], 
processed observation next is [1.0, 0.0, 0.4277777777777778, 0.845, 1.0, 1.0, 0.4094353375912924, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2148081401278932, 0.21480814012789304, 0.27601711934885476], 
reward next is 0.7240, 
noisyNet noise sample is [array([0.9274488], dtype=float32), -2.2778215]. 
=============================================
[2019-04-27 18:10:08,832] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.9090752e-11 1.0000000e+00 1.5294157e-13 1.3340101e-10 5.1142342e-13], sum to 1.0000
[2019-04-27 18:10:08,839] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0926
[2019-04-27 18:10:08,846] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.36666666666667, 61.66666666666667, 1.0, 2.0, 0.5531692173879558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 646867.5600563493, 646867.5600563493, 150977.7356724003], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6204000.0000, 
sim time next is 6204600.0000, 
raw observation next is [28.25, 62.5, 1.0, 2.0, 0.5566769834913916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 650476.0634750358, 650476.0634750358, 151537.6611411434], 
processed observation next is [1.0, 0.8260869565217391, 0.6018518518518519, 0.625, 1.0, 1.0, 0.47223450415641854, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2323128798125128, 0.2323128798125128, 0.2914185791175835], 
reward next is 0.7086, 
noisyNet noise sample is [array([-0.04881338], dtype=float32), -0.04675899]. 
=============================================
[2019-04-27 18:10:12,427] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.2458777e-17 1.0000000e+00 8.7283529e-22 1.6014975e-16 5.6101864e-20], sum to 1.0000
[2019-04-27 18:10:12,437] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3089
[2019-04-27 18:10:12,441] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.13333333333333, 65.0, 1.0, 2.0, 0.6383574784904393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 727513.6008994087, 727513.6008994087, 164801.0142750754], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6270000.0000, 
sim time next is 6270600.0000, 
raw observation next is [29.26666666666667, 64.5, 1.0, 2.0, 0.642414137452463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 732139.0405082707, 732139.0405082707, 165527.1390405319], 
processed observation next is [0.0, 0.5652173913043478, 0.6395061728395063, 0.645, 1.0, 1.0, 0.5743025445862655, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26147822875295385, 0.26147822875295385, 0.31832142123179213], 
reward next is 0.6817, 
noisyNet noise sample is [array([-0.09355923], dtype=float32), 0.047926676]. 
=============================================
[2019-04-27 18:10:13,850] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10500, global step 167577: loss 0.0130
[2019-04-27 18:10:13,852] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10500, global step 167578: learning rate 0.0000
[2019-04-27 18:10:14,046] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10500, global step 167670: loss 0.1372
[2019-04-27 18:10:14,047] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10500, global step 167670: learning rate 0.0000
[2019-04-27 18:10:14,155] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10500, global step 167723: loss 0.0862
[2019-04-27 18:10:14,156] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10500, global step 167723: learning rate 0.0000
[2019-04-27 18:10:14,285] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10500, global step 167789: loss 0.0136
[2019-04-27 18:10:14,293] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10500, global step 167790: learning rate 0.0000
[2019-04-27 18:10:14,471] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10500, global step 167873: loss 0.0530
[2019-04-27 18:10:14,472] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10500, global step 167873: learning rate 0.0000
[2019-04-27 18:10:14,515] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10500, global step 167893: loss 0.0103
[2019-04-27 18:10:14,517] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10500, global step 167893: learning rate 0.0000
[2019-04-27 18:10:14,585] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10500, global step 167924: loss 0.0015
[2019-04-27 18:10:14,588] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10500, global step 167924: learning rate 0.0000
[2019-04-27 18:10:14,685] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10500, global step 167970: loss 0.0342
[2019-04-27 18:10:14,691] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10500, global step 167971: learning rate 0.0000
[2019-04-27 18:10:14,737] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10500, global step 167994: loss 0.0611
[2019-04-27 18:10:14,740] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10500, global step 167994: learning rate 0.0000
[2019-04-27 18:10:14,807] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10500, global step 168030: loss 0.0582
[2019-04-27 18:10:14,810] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10500, global step 168030: learning rate 0.0000
[2019-04-27 18:10:14,832] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10500, global step 168044: loss 0.0196
[2019-04-27 18:10:14,836] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10500, global step 168045: learning rate 0.0000
[2019-04-27 18:10:15,200] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10500, global step 168202: loss 0.0245
[2019-04-27 18:10:15,202] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10500, global step 168204: learning rate 0.0000
[2019-04-27 18:10:15,221] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10500, global step 168210: loss 0.0120
[2019-04-27 18:10:15,225] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10500, global step 168211: learning rate 0.0000
[2019-04-27 18:10:15,303] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10500, global step 168247: loss 0.0025
[2019-04-27 18:10:15,308] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10500, global step 168249: learning rate 0.0000
[2019-04-27 18:10:15,321] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10500, global step 168257: loss 0.0031
[2019-04-27 18:10:15,323] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10500, global step 168258: learning rate 0.0000
[2019-04-27 18:10:15,593] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10500, global step 168386: loss 0.0261
[2019-04-27 18:10:15,595] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10500, global step 168386: learning rate 0.0000
[2019-04-27 18:10:29,410] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-04-27 18:10:29,412] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 18:10:29,413] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 18:10:29,413] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:10:29,413] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 18:10:29,414] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 18:10:29,414] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 18:10:29,415] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:10:29,417] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:10:29,418] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:10:29,419] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:10:29,432] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run8
[2019-04-27 18:10:29,451] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run8
[2019-04-27 18:10:29,452] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run8
[2019-04-27 18:10:29,473] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run8
[2019-04-27 18:10:29,510] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run8
[2019-04-27 18:11:27,273] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.031252492]
[2019-04-27 18:11:27,275] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.09476476, 90.79838564, 1.0, 2.0, 0.5845214355420065, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 678246.8523776378, 678246.8523776374, 156013.8707248452]
[2019-04-27 18:11:27,276] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 18:11:27,279] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.8429577e-20 1.0000000e+00 7.8342768e-25 3.4009107e-18 1.4932728e-23], sampled 0.47839915165543334
[2019-04-27 18:11:33,726] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.031252492]
[2019-04-27 18:11:33,727] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.4, 87.66666666666667, 1.0, 2.0, 0.405698239065776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 498662.6890462009, 498662.6890462009, 129327.6861340098]
[2019-04-27 18:11:33,728] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 18:11:33,730] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.5452277e-21 1.0000000e+00 2.1592691e-26 2.8611226e-19 5.7454046e-25], sampled 0.7338791525686662
[2019-04-27 18:11:37,037] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.031252492]
[2019-04-27 18:11:37,038] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.09849443, 100.8313614, 1.0, 2.0, 0.7696819848585789, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 877265.1785830953, 877265.1785830953, 189761.8290082617]
[2019-04-27 18:11:37,040] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 18:11:37,042] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.6766613e-20 1.0000000e+00 1.4289235e-24 5.2397371e-18 2.7322847e-23], sampled 0.802262133264571
[2019-04-27 18:12:02,897] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.031252492]
[2019-04-27 18:12:02,898] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.14714931333334, 83.70591789, 1.0, 2.0, 0.4577011500355392, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 558357.152079918, 558357.152079918, 136816.7535511852]
[2019-04-27 18:12:02,898] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 18:12:02,901] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.4107991e-20 1.0000000e+00 8.1848594e-25 3.6976578e-18 1.7150787e-23], sampled 0.9691290252385437
[2019-04-27 18:12:07,260] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.031252492]
[2019-04-27 18:12:07,262] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.177675, 68.31780601, 1.0, 2.0, 0.4781679453723996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 577789.6365409086, 577789.6365409086, 139766.1599604493]
[2019-04-27 18:12:07,263] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 18:12:07,266] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.7456089e-20 1.0000000e+00 2.4309299e-25 1.6917361e-18 5.8170812e-24], sampled 0.8812865177886007
[2019-04-27 18:12:16,003] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8770.2665 2170632327.5226 493.0000
[2019-04-27 18:12:16,083] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8923.5143 2120416988.3376 430.0000
[2019-04-27 18:12:16,137] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-04-27 18:12:16,199] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-04-27 18:12:16,285] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8583.7010 2248665784.9182 553.0000
[2019-04-27 18:12:17,301] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 175000, evaluation results [175000.0, 8100.722247181571, 2445312557.402538, 746.0, 8770.266515857684, 2170632327.522563, 493.0, 8923.514325042122, 2120416988.33764, 430.0, 8583.700958564144, 2248665784.918216, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-04-27 18:12:18,407] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11000, global step 175526: loss 1.1150
[2019-04-27 18:12:18,412] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11000, global step 175528: learning rate 0.0000
[2019-04-27 18:12:18,537] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.9750915e-21 1.0000000e+00 9.0699706e-27 4.0348891e-20 7.3145920e-24], sum to 1.0000
[2019-04-27 18:12:18,543] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5810
[2019-04-27 18:12:18,549] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.6, 50.33333333333334, 1.0, 2.0, 0.4236969600666726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 531418.7537157475, 531418.753715747, 132132.1145990264], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6576600.0000, 
sim time next is 6577200.0000, 
raw observation next is [25.6, 50.0, 1.0, 2.0, 0.4312195448290055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 541245.1533212306, 541245.1533212306, 133237.0977492863], 
processed observation next is [1.0, 0.13043478260869565, 0.5037037037037038, 0.5, 1.0, 1.0, 0.3228804105107208, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19330184047186805, 0.19330184047186805, 0.25622518797939675], 
reward next is 0.7438, 
noisyNet noise sample is [array([0.48159268], dtype=float32), -0.15794109]. 
=============================================
[2019-04-27 18:12:18,632] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11000, global step 175638: loss 1.5352
[2019-04-27 18:12:18,634] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11000, global step 175638: learning rate 0.0000
[2019-04-27 18:12:18,999] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11000, global step 175813: loss 1.3508
[2019-04-27 18:12:19,001] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11000, global step 175814: loss 1.4819
[2019-04-27 18:12:19,002] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11000, global step 175814: learning rate 0.0000
[2019-04-27 18:12:19,005] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11000, global step 175814: learning rate 0.0000
[2019-04-27 18:12:19,024] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11000, global step 175819: loss 1.2638
[2019-04-27 18:12:19,026] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11000, global step 175820: learning rate 0.0000
[2019-04-27 18:12:19,043] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11000, global step 175829: loss 1.1883
[2019-04-27 18:12:19,045] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11000, global step 175829: learning rate 0.0000
[2019-04-27 18:12:19,168] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11000, global step 175888: loss 1.5107
[2019-04-27 18:12:19,173] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11000, global step 175890: learning rate 0.0000
[2019-04-27 18:12:19,303] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11000, global step 175956: loss 1.3396
[2019-04-27 18:12:19,305] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11000, global step 175957: learning rate 0.0000
[2019-04-27 18:12:19,481] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11000, global step 176035: loss 1.6265
[2019-04-27 18:12:19,485] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11000, global step 176035: loss 1.4057
[2019-04-27 18:12:19,487] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11000, global step 176036: learning rate 0.0000
[2019-04-27 18:12:19,488] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11000, global step 176035: learning rate 0.0000
[2019-04-27 18:12:19,557] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11000, global step 176072: loss 1.1637
[2019-04-27 18:12:19,558] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11000, global step 176072: learning rate 0.0000
[2019-04-27 18:12:19,769] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11000, global step 176170: loss 0.9926
[2019-04-27 18:12:19,772] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11000, global step 176171: learning rate 0.0000
[2019-04-27 18:12:19,847] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11000, global step 176208: loss 0.9184
[2019-04-27 18:12:19,848] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11000, global step 176208: learning rate 0.0000
[2019-04-27 18:12:19,940] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11000, global step 176251: loss 0.9235
[2019-04-27 18:12:19,944] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11000, global step 176251: learning rate 0.0000
[2019-04-27 18:12:20,081] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11000, global step 176313: loss 0.5414
[2019-04-27 18:12:20,083] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11000, global step 176313: learning rate 0.0000
[2019-04-27 18:12:20,192] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11000, global step 176367: loss 0.3222
[2019-04-27 18:12:20,193] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11000, global step 176367: learning rate 0.0000
[2019-04-27 18:12:23,624] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.0447221e-24 1.0000000e+00 3.3131373e-29 6.9157398e-22 1.5321210e-26], sum to 1.0000
[2019-04-27 18:12:23,633] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2444
[2019-04-27 18:12:23,638] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 50.0, 1.0, 2.0, 0.3070942449783921, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 394748.5963924245, 394748.5963924245, 116453.2585880276], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6679200.0000, 
sim time next is 6679800.0000, 
raw observation next is [23.0, 50.5, 1.0, 2.0, 0.3003444751754684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 385824.5072976518, 385824.5072976522, 115616.048913862], 
processed observation next is [1.0, 0.30434782608695654, 0.4074074074074074, 0.505, 1.0, 1.0, 0.16707675616127193, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1377944668920185, 0.13779446689201863, 0.22233855560358076], 
reward next is 0.7777, 
noisyNet noise sample is [array([-1.1457494], dtype=float32), 0.19753234]. 
=============================================
[2019-04-27 18:12:25,693] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.6452790e-14 1.0000000e+00 1.9216227e-18 3.1518221e-13 1.5119520e-17], sum to 1.0000
[2019-04-27 18:12:25,700] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4844
[2019-04-27 18:12:25,704] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.25, 35.0, 1.0, 2.0, 0.3345998192242703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 423519.8440091484, 423519.8440091479, 119935.0439487276], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6719400.0000, 
sim time next is 6720000.0000, 
raw observation next is [28.0, 36.0, 1.0, 2.0, 0.3307463195927755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 418583.0269753035, 418583.0269753035, 119436.1038864712], 
processed observation next is [1.0, 0.782608695652174, 0.5925925925925926, 0.36, 1.0, 1.0, 0.2032694280866375, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14949393820546553, 0.14949393820546553, 0.22968481516629077], 
reward next is 0.7703, 
noisyNet noise sample is [array([0.17719413], dtype=float32), 0.60379326]. 
=============================================
[2019-04-27 18:12:25,723] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[55.85182 ]
 [55.98558 ]
 [55.649662]
 [55.64695 ]
 [55.326553]], R is [[56.13478851]
 [56.34279633]
 [56.54767609]
 [56.74965668]
 [56.94881439]].
[2019-04-27 18:12:32,918] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.3050413e-17 1.0000000e+00 1.9274627e-22 1.0871722e-15 4.1553842e-21], sum to 1.0000
[2019-04-27 18:12:32,926] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8227
[2019-04-27 18:12:32,930] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.73333333333333, 77.66666666666667, 1.0, 2.0, 0.4251653955326882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 521845.609228336, 521845.6092283356, 132099.0224457206], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6829800.0000, 
sim time next is 6830400.0000, 
raw observation next is [22.66666666666667, 77.33333333333334, 1.0, 2.0, 0.4213464214205481, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 518003.9872521915, 518003.987252191, 131568.4883833897], 
processed observation next is [0.0, 0.043478260869565216, 0.39506172839506193, 0.7733333333333334, 1.0, 1.0, 0.31112669216731914, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18500142401863984, 0.18500142401863964, 0.25301632381421096], 
reward next is 0.7470, 
noisyNet noise sample is [array([0.28303096], dtype=float32), 1.0417528]. 
=============================================
[2019-04-27 18:12:35,043] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11500, global step 183476: loss 0.0510
[2019-04-27 18:12:35,046] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11500, global step 183477: learning rate 0.0000
[2019-04-27 18:12:35,306] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11500, global step 183603: loss 0.1685
[2019-04-27 18:12:35,310] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11500, global step 183603: learning rate 0.0000
[2019-04-27 18:12:35,734] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11500, global step 183812: loss 0.0708
[2019-04-27 18:12:35,736] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11500, global step 183813: learning rate 0.0000
[2019-04-27 18:12:35,792] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11500, global step 183839: loss 0.1522
[2019-04-27 18:12:35,794] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11500, global step 183840: learning rate 0.0000
[2019-04-27 18:12:35,833] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11500, global step 183855: loss 0.1960
[2019-04-27 18:12:35,835] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11500, global step 183855: learning rate 0.0000
[2019-04-27 18:12:35,893] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11500, global step 183884: loss 0.1239
[2019-04-27 18:12:35,896] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11500, global step 183887: learning rate 0.0000
[2019-04-27 18:12:35,912] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11500, global step 183893: loss 0.1399
[2019-04-27 18:12:35,913] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11500, global step 183893: learning rate 0.0000
[2019-04-27 18:12:36,155] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11500, global step 184006: loss 0.0014
[2019-04-27 18:12:36,156] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11500, global step 184006: learning rate 0.0000
[2019-04-27 18:12:36,156] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11500, global step 184006: loss 0.0093
[2019-04-27 18:12:36,160] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11500, global step 184007: learning rate 0.0000
[2019-04-27 18:12:36,206] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11500, global step 184030: loss 0.0197
[2019-04-27 18:12:36,209] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11500, global step 184030: learning rate 0.0000
[2019-04-27 18:12:36,310] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11500, global step 184080: loss 0.0021
[2019-04-27 18:12:36,315] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11500, global step 184080: learning rate 0.0000
[2019-04-27 18:12:36,567] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11500, global step 184200: loss 0.0070
[2019-04-27 18:12:36,570] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11500, global step 184201: learning rate 0.0000
[2019-04-27 18:12:36,626] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11500, global step 184230: loss 0.0068
[2019-04-27 18:12:36,630] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11500, global step 184234: learning rate 0.0000
[2019-04-27 18:12:36,662] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11500, global step 184250: loss 0.0252
[2019-04-27 18:12:36,664] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11500, global step 184250: learning rate 0.0000
[2019-04-27 18:12:36,773] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11500, global step 184306: loss 0.1328
[2019-04-27 18:12:36,778] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11500, global step 184307: learning rate 0.0000
[2019-04-27 18:12:36,816] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11500, global step 184324: loss 0.0639
[2019-04-27 18:12:36,819] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11500, global step 184324: learning rate 0.0000
[2019-04-27 18:12:51,767] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12000, global step 191495: loss 0.0480
[2019-04-27 18:12:51,769] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12000, global step 191495: learning rate 0.0000
[2019-04-27 18:12:52,102] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12000, global step 191656: loss 0.0010
[2019-04-27 18:12:52,103] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12000, global step 191656: learning rate 0.0000
[2019-04-27 18:12:52,137] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.5578537e-18 1.0000000e+00 4.8210217e-24 1.7405864e-15 8.2804091e-21], sum to 1.0000
[2019-04-27 18:12:52,147] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3088
[2019-04-27 18:12:52,154] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.8, 94.66666666666667, 1.0, 2.0, 0.3856493201842415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 478838.4914127259, 478838.4914127259, 126637.8301794826], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7177800.0000, 
sim time next is 7178400.0000, 
raw observation next is [19.8, 95.0, 1.0, 2.0, 0.3866188356758198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 479785.0833465317, 479785.0833465313, 126766.5325592238], 
processed observation next is [1.0, 0.08695652173913043, 0.2888888888888889, 0.95, 1.0, 1.0, 0.26978432818549974, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1713518154809042, 0.17135181548090403, 0.24378179338312267], 
reward next is 0.7562, 
noisyNet noise sample is [array([0.8354117], dtype=float32), -0.43594003]. 
=============================================
[2019-04-27 18:12:52,402] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12000, global step 191795: loss 0.0658
[2019-04-27 18:12:52,404] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12000, global step 191795: learning rate 0.0000
[2019-04-27 18:12:52,410] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12000, global step 191797: loss 0.0675
[2019-04-27 18:12:52,413] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12000, global step 191799: learning rate 0.0000
[2019-04-27 18:12:52,484] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12000, global step 191835: loss 0.0025
[2019-04-27 18:12:52,486] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12000, global step 191835: learning rate 0.0000
[2019-04-27 18:12:52,614] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12000, global step 191894: loss 0.0056
[2019-04-27 18:12:52,621] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12000, global step 191895: learning rate 0.0000
[2019-04-27 18:12:52,694] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12000, global step 191930: loss 0.0282
[2019-04-27 18:12:52,698] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12000, global step 191930: learning rate 0.0000
[2019-04-27 18:12:52,828] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12000, global step 191999: loss 0.0011
[2019-04-27 18:12:52,830] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12000, global step 192000: loss 0.0003
[2019-04-27 18:12:52,833] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12000, global step 192000: learning rate 0.0000
[2019-04-27 18:12:52,833] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12000, global step 192000: learning rate 0.0000
[2019-04-27 18:12:52,890] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12000, global step 192028: loss 0.0206
[2019-04-27 18:12:52,892] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12000, global step 192029: learning rate 0.0000
[2019-04-27 18:12:52,968] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12000, global step 192072: loss 0.0334
[2019-04-27 18:12:52,973] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12000, global step 192072: learning rate 0.0000
[2019-04-27 18:12:53,285] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12000, global step 192226: loss 0.0061
[2019-04-27 18:12:53,290] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12000, global step 192227: learning rate 0.0000
[2019-04-27 18:12:53,332] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12000, global step 192247: loss 0.0233
[2019-04-27 18:12:53,335] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12000, global step 192248: learning rate 0.0000
[2019-04-27 18:12:53,342] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12000, global step 192250: loss 0.0479
[2019-04-27 18:12:53,344] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12000, global step 192250: learning rate 0.0000
[2019-04-27 18:12:53,392] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12000, global step 192273: loss 0.0181
[2019-04-27 18:12:53,393] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12000, global step 192273: learning rate 0.0000
[2019-04-27 18:12:53,515] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12000, global step 192331: loss 0.0022
[2019-04-27 18:12:53,518] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12000, global step 192331: learning rate 0.0000
[2019-04-27 18:13:04,131] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.9684587e-18 1.0000000e+00 5.0234855e-23 4.0229576e-15 7.3693569e-21], sum to 1.0000
[2019-04-27 18:13:04,138] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0180
[2019-04-27 18:13:04,143] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.06666666666667, 89.33333333333334, 1.0, 2.0, 0.4119979008620698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426033011, 506615.003979319, 506615.003979319, 130228.6650684294], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7406400.0000, 
sim time next is 7407000.0000, 
raw observation next is [21.0, 89.5, 1.0, 2.0, 0.408542345570785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.926042615658, 502838.4696281383, 502838.4696281383, 129748.480791665], 
processed observation next is [1.0, 0.7391304347826086, 0.3333333333333333, 0.895, 1.0, 1.0, 0.29588374472712503, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201107, 0.1795851677243351, 0.1795851677243351, 0.24951630921474038], 
reward next is 0.7505, 
noisyNet noise sample is [array([-1.4483188], dtype=float32), -0.40238076]. 
=============================================
[2019-04-27 18:13:04,164] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[68.86949]
 [67.94732]
 [66.37958]
 [66.02475]
 [66.10532]], R is [[69.41835785]
 [69.47373199]
 [69.49938965]
 [69.04149628]
 [68.35108185]].
[2019-04-27 18:13:07,620] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5275119e-17 1.0000000e+00 1.5997463e-22 9.6248015e-15 9.1209374e-20], sum to 1.0000
[2019-04-27 18:13:07,624] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5703
[2019-04-27 18:13:07,630] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.23333333333333, 74.83333333333333, 1.0, 2.0, 0.5093006703801265, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 604955.7851775624, 604955.7851775624, 144270.1784633331], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7483800.0000, 
sim time next is 7484400.0000, 
raw observation next is [25.2, 75.0, 1.0, 2.0, 0.5106360011877689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 606620.8986780187, 606620.8986780182, 144485.0670107457], 
processed observation next is [0.0, 0.6521739130434783, 0.4888888888888889, 0.75, 1.0, 1.0, 0.41742381093782005, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21665032095643524, 0.21665032095643508, 0.2778558980975879], 
reward next is 0.7221, 
noisyNet noise sample is [array([1.3208678], dtype=float32), 0.04706847]. 
=============================================
[2019-04-27 18:13:08,528] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12500, global step 199543: loss 0.0600
[2019-04-27 18:13:08,531] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12500, global step 199543: learning rate 0.0000
[2019-04-27 18:13:08,760] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12500, global step 199657: loss 0.0974
[2019-04-27 18:13:08,762] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12500, global step 199657: learning rate 0.0000
[2019-04-27 18:13:08,937] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12500, global step 199739: loss 0.0450
[2019-04-27 18:13:08,939] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12500, global step 199739: learning rate 0.0000
[2019-04-27 18:13:08,963] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12500, global step 199753: loss 0.0696
[2019-04-27 18:13:08,965] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12500, global step 199753: learning rate 0.0000
[2019-04-27 18:13:08,987] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12500, global step 199764: loss 0.0769
[2019-04-27 18:13:08,990] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12500, global step 199765: learning rate 0.0000
[2019-04-27 18:13:09,142] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12500, global step 199844: loss 0.0031
[2019-04-27 18:13:09,143] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12500, global step 199844: learning rate 0.0000
[2019-04-27 18:13:09,234] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.2712112e-21 1.0000000e+00 2.2234308e-26 4.4462290e-18 3.6921653e-23], sum to 1.0000
[2019-04-27 18:13:09,244] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9561
[2019-04-27 18:13:09,253] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.03333333333333, 88.66666666666667, 1.0, 2.0, 0.500348540434851, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 596732.3222065434, 596732.3222065434, 142948.4035233821], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7501200.0000, 
sim time next is 7501800.0000, 
raw observation next is [22.91666666666666, 89.33333333333333, 1.0, 2.0, 0.4991357955127477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 595606.144274983, 595606.1442749825, 142769.7268779289], 
processed observation next is [0.0, 0.8260869565217391, 0.4043209876543208, 0.8933333333333333, 1.0, 1.0, 0.40373308989612827, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2127164800982082, 0.21271648009820804, 0.27455716707294014], 
reward next is 0.7254, 
noisyNet noise sample is [array([0.12863216], dtype=float32), -0.8989109]. 
=============================================
[2019-04-27 18:13:09,373] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12500, global step 199957: loss 0.0063
[2019-04-27 18:13:09,377] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12500, global step 199957: learning rate 0.0000
[2019-04-27 18:13:09,397] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12500, global step 199966: loss 0.0060
[2019-04-27 18:13:09,403] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12500, global step 199967: learning rate 0.0000
[2019-04-27 18:13:09,405] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12500, global step 199971: loss 0.0012
[2019-04-27 18:13:09,409] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12500, global step 199971: learning rate 0.0000
[2019-04-27 18:13:09,473] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-04-27 18:13:09,477] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 18:13:09,477] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 18:13:09,478] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:13:09,479] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:13:09,479] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 18:13:09,482] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:13:09,482] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 18:13:09,483] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 18:13:09,485] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:13:09,486] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:13:09,499] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run9
[2019-04-27 18:13:09,500] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run9
[2019-04-27 18:13:09,500] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run9
[2019-04-27 18:13:09,500] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run9
[2019-04-27 18:13:09,575] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run9
[2019-04-27 18:13:16,589] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.03538314]
[2019-04-27 18:13:16,590] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.5, 56.33333333333334, 1.0, 2.0, 0.254665304835226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 328341.0763721561, 328341.0763721561, 110145.7480722]
[2019-04-27 18:13:16,591] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 18:13:16,593] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.5844111e-18 1.0000000e+00 1.8392960e-22 2.8379318e-15 1.0835880e-20], sampled 0.8237836352466892
[2019-04-27 18:13:49,801] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.03538314]
[2019-04-27 18:13:49,804] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.121383545, 81.26106711, 1.0, 2.0, 0.6771050943234463, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1486670.114420643, 1486670.114420643, 313128.5674527995]
[2019-04-27 18:13:49,805] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 18:13:49,809] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.7801961e-19 1.0000000e+00 3.6600085e-24 2.3597827e-16 3.4034476e-22], sampled 0.7359854637563735
[2019-04-27 18:13:49,813] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1486670.114420643 W.
[2019-04-27 18:14:23,966] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.03538314]
[2019-04-27 18:14:23,970] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [37.16666666666667, 31.83333333333334, 1.0, 2.0, 0.5939088608640379, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9455222487567932, 6.911199999999999, 6.9112, 121.9260426156618, 1354267.525543903, 1354267.525543904, 291496.8918743188]
[2019-04-27 18:14:23,971] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 18:14:23,974] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.7088786e-18 1.0000000e+00 3.4482442e-23 1.0206222e-15 2.5412307e-21], sampled 0.2559507851177554
[2019-04-27 18:14:23,975] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1354267.525543903 W.
[2019-04-27 18:14:26,808] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.03538314]
[2019-04-27 18:14:26,809] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [34.4, 32.0, 1.0, 2.0, 0.4891728869417735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 584582.0239559703, 584582.02395597, 141245.8310174831]
[2019-04-27 18:14:26,812] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 18:14:26,815] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.74496206e-19 1.00000000e+00 1.05760925e-23 4.14050510e-16
 7.74186477e-22], sampled 0.11081282472861309
[2019-04-27 18:14:34,780] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.03538314]
[2019-04-27 18:14:34,782] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [31.60694669666667, 58.85658294500001, 1.0, 2.0, 0.7302998591201268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 832353.9964154509, 832353.9964154509, 181959.8908507175]
[2019-04-27 18:14:34,783] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 18:14:34,786] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.2409721e-18 1.0000000e+00 1.4699647e-23 5.1783423e-16 1.0545566e-21], sampled 0.5714835355188078
[2019-04-27 18:14:56,613] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8099.2011 2445344792.3129 746.0000
[2019-04-27 18:14:56,914] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-04-27 18:14:56,942] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-04-27 18:14:57,011] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-04-27 18:14:57,085] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-04-27 18:14:58,105] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 200000, evaluation results [200000.0, 8099.201058977578, 2445344792.312898, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-04-27 18:14:58,241] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12500, global step 200068: loss 0.0550
[2019-04-27 18:14:58,245] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12500, global step 200069: learning rate 0.0000
[2019-04-27 18:14:58,267] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12500, global step 200077: loss 0.0705
[2019-04-27 18:14:58,268] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12500, global step 200077: learning rate 0.0000
[2019-04-27 18:14:58,562] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12500, global step 200219: loss 0.0395
[2019-04-27 18:14:58,565] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12500, global step 200219: learning rate 0.0000
[2019-04-27 18:14:58,648] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12500, global step 200258: loss 0.0006
[2019-04-27 18:14:58,651] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12500, global step 200258: learning rate 0.0000
[2019-04-27 18:14:58,683] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12500, global step 200277: loss 0.0023
[2019-04-27 18:14:58,684] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12500, global step 200277: learning rate 0.0000
[2019-04-27 18:14:58,846] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12500, global step 200353: loss 0.0755
[2019-04-27 18:14:58,849] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12500, global step 200354: learning rate 0.0000
[2019-04-27 18:14:58,928] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12500, global step 200390: loss 0.0379
[2019-04-27 18:14:58,932] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12500, global step 200391: learning rate 0.0000
[2019-04-27 18:14:58,986] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.5664664e-19 1.0000000e+00 1.4492728e-25 3.5414943e-16 2.8358995e-21], sum to 1.0000
[2019-04-27 18:14:58,996] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1457
[2019-04-27 18:14:59,001] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.9, 96.0, 1.0, 2.0, 0.4385645393199104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 534246.1993203267, 534246.1993203267, 133945.4019786304], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7528800.0000, 
sim time next is 7529400.0000, 
raw observation next is [20.9, 96.0, 1.0, 2.0, 0.4383543396778114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 533990.1053613863, 533990.1053613863, 133914.4693002797], 
processed observation next is [0.0, 0.13043478260869565, 0.32962962962962955, 0.96, 1.0, 1.0, 0.3313742139021565, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19071075191478082, 0.19071075191478082, 0.257527825577461], 
reward next is 0.7425, 
noisyNet noise sample is [array([0.90054584], dtype=float32), 0.84460306]. 
=============================================
[2019-04-27 18:15:03,706] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.6719933e-20 1.0000000e+00 5.9085516e-24 6.3776115e-17 4.9677452e-23], sum to 1.0000
[2019-04-27 18:15:03,714] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5031
[2019-04-27 18:15:03,719] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.61666666666667, 87.16666666666666, 1.0, 2.0, 0.4774496974287495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 575262.859258572, 575262.859258572, 139600.9572398514], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7602600.0000, 
sim time next is 7603200.0000, 
raw observation next is [22.5, 87.0, 1.0, 2.0, 0.4711531558790052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 569001.5717244351, 569001.5717244346, 138681.1790751647], 
processed observation next is [1.0, 0.0, 0.3888888888888889, 0.87, 1.0, 1.0, 0.37042042366548233, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2032148470444411, 0.20321484704444093, 0.2666945751445475], 
reward next is 0.7333, 
noisyNet noise sample is [array([0.016032], dtype=float32), -0.18837358]. 
=============================================
[2019-04-27 18:15:06,580] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.0938930e-11 1.0000000e+00 2.1717986e-13 4.1819481e-10 9.6290665e-14], sum to 1.0000
[2019-04-27 18:15:06,588] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9482
[2019-04-27 18:15:06,593] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.43333333333334, 70.33333333333334, 1.0, 2.0, 0.9505462929616705, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.02891910340002, 6.9112, 121.9255515160558, 1178866.512778152, 1118584.053032855, 230846.5745414202], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7648800.0000, 
sim time next is 7649400.0000, 
raw observation next is [26.51666666666667, 69.66666666666666, 1.0, 2.0, 0.9706993029876223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.160220153822362, 6.9112, 121.9248768744023, 1270466.827617376, 1142947.470922424, 235654.3544450584], 
processed observation next is [1.0, 0.5217391304347826, 0.5376543209876544, 0.6966666666666665, 1.0, 1.0, 0.9651182178424075, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.024902015382236176, 0.0, 0.8094543895104583, 0.45373815272049145, 0.40819552532943715, 0.4531814508558815], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.634196], dtype=float32), 0.54356843]. 
=============================================
[2019-04-27 18:15:12,263] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.1470718e-22 1.0000000e+00 1.7597106e-26 2.6331969e-19 7.3942102e-24], sum to 1.0000
[2019-04-27 18:15:12,275] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7316
[2019-04-27 18:15:12,287] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.7, 61.0, 1.0, 2.0, 0.4332721892207285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 529514.8913242135, 529514.8913242135, 133218.3590031494], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7758000.0000, 
sim time next is 7758600.0000, 
raw observation next is [25.41666666666667, 61.83333333333334, 1.0, 2.0, 0.4285376007997698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 524728.4590188278, 524728.4590188278, 132555.2912961425], 
processed observation next is [1.0, 0.8260869565217391, 0.49691358024691373, 0.6183333333333334, 1.0, 1.0, 0.319687619999726, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18740302107815276, 0.18740302107815276, 0.254914021723351], 
reward next is 0.7451, 
noisyNet noise sample is [array([0.6328888], dtype=float32), 0.21244372]. 
=============================================
[2019-04-27 18:15:13,691] A3C_AGENT_WORKER-Thread-13 INFO:Local step 13000, global step 207510: loss 0.0800
[2019-04-27 18:15:13,692] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 13000, global step 207510: learning rate 0.0000
[2019-04-27 18:15:13,836] A3C_AGENT_WORKER-Thread-17 INFO:Local step 13000, global step 207581: loss 0.1054
[2019-04-27 18:15:13,837] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 13000, global step 207581: learning rate 0.0000
[2019-04-27 18:15:13,911] A3C_AGENT_WORKER-Thread-20 INFO:Local step 13000, global step 207614: loss 0.1812
[2019-04-27 18:15:13,916] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 13000, global step 207617: learning rate 0.0000
[2019-04-27 18:15:13,988] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.6778484e-17 1.0000000e+00 2.8104282e-22 2.1695193e-15 2.8750519e-18], sum to 1.0000
[2019-04-27 18:15:13,996] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9497
[2019-04-27 18:15:14,002] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.4, 68.0, 1.0, 2.0, 0.3315389003896583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 420922.128984884, 420922.128984884, 119550.0104851678], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7789200.0000, 
sim time next is 7789800.0000, 
raw observation next is [21.45, 67.5, 1.0, 2.0, 0.3276073425733826, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 416043.7294181839, 416043.7294181834, 119044.4457417687], 
processed observation next is [1.0, 0.13043478260869565, 0.35, 0.675, 1.0, 1.0, 0.19953255068259831, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14858704622077998, 0.14858704622077978, 0.22893162642647827], 
reward next is 0.7711, 
noisyNet noise sample is [array([-0.57380915], dtype=float32), -0.26363528]. 
=============================================
[2019-04-27 18:15:14,225] A3C_AGENT_WORKER-Thread-22 INFO:Local step 13000, global step 207761: loss 0.0599
[2019-04-27 18:15:14,229] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 13000, global step 207763: learning rate 0.0000
[2019-04-27 18:15:14,340] A3C_AGENT_WORKER-Thread-21 INFO:Local step 13000, global step 207822: loss 0.0388
[2019-04-27 18:15:14,342] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 13000, global step 207822: learning rate 0.0000
[2019-04-27 18:15:14,488] A3C_AGENT_WORKER-Thread-14 INFO:Local step 13000, global step 207889: loss 0.0696
[2019-04-27 18:15:14,491] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 13000, global step 207890: learning rate 0.0000
[2019-04-27 18:15:14,584] A3C_AGENT_WORKER-Thread-11 INFO:Local step 13000, global step 207935: loss 0.1484
[2019-04-27 18:15:14,586] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 13000, global step 207936: learning rate 0.0000
[2019-04-27 18:15:14,604] A3C_AGENT_WORKER-Thread-10 INFO:Local step 13000, global step 207942: loss 0.1913
[2019-04-27 18:15:14,608] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 13000, global step 207943: learning rate 0.0000
[2019-04-27 18:15:14,780] A3C_AGENT_WORKER-Thread-2 INFO:Local step 13000, global step 208027: loss 0.1186
[2019-04-27 18:15:14,784] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 13000, global step 208029: learning rate 0.0000
[2019-04-27 18:15:14,893] A3C_AGENT_WORKER-Thread-9 INFO:Local step 13000, global step 208082: loss 0.0744
[2019-04-27 18:15:14,898] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 13000, global step 208082: learning rate 0.0000
[2019-04-27 18:15:15,040] A3C_AGENT_WORKER-Thread-18 INFO:Local step 13000, global step 208152: loss 0.0988
[2019-04-27 18:15:15,043] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 13000, global step 208153: learning rate 0.0000
[2019-04-27 18:15:15,067] A3C_AGENT_WORKER-Thread-19 INFO:Local step 13000, global step 208165: loss 0.0840
[2019-04-27 18:15:15,070] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 13000, global step 208165: learning rate 0.0000
[2019-04-27 18:15:15,149] A3C_AGENT_WORKER-Thread-12 INFO:Local step 13000, global step 208202: loss 0.1565
[2019-04-27 18:15:15,152] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 13000, global step 208203: learning rate 0.0000
[2019-04-27 18:15:15,359] A3C_AGENT_WORKER-Thread-15 INFO:Local step 13000, global step 208302: loss 0.2781
[2019-04-27 18:15:15,362] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 13000, global step 208303: learning rate 0.0000
[2019-04-27 18:15:15,418] A3C_AGENT_WORKER-Thread-16 INFO:Local step 13000, global step 208334: loss 0.3696
[2019-04-27 18:15:15,420] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 13000, global step 208334: learning rate 0.0000
[2019-04-27 18:15:15,621] A3C_AGENT_WORKER-Thread-3 INFO:Local step 13000, global step 208429: loss 0.6018
[2019-04-27 18:15:15,623] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 13000, global step 208429: learning rate 0.0000
[2019-04-27 18:15:17,416] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.1842237e-17 1.0000000e+00 7.6897676e-22 4.5799952e-15 9.6417497e-21], sum to 1.0000
[2019-04-27 18:15:17,426] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5392
[2019-04-27 18:15:17,435] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.21666666666667, 73.5, 1.0, 2.0, 0.4204861808399036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 517250.1240211863, 517250.1240211863, 131452.2480742829], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7863000.0000, 
sim time next is 7863600.0000, 
raw observation next is [23.13333333333333, 74.0, 1.0, 2.0, 0.4194132392338866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 515992.4159968887, 515992.4159968887, 131299.1132037926], 
processed observation next is [1.0, 0.0, 0.41234567901234553, 0.74, 1.0, 1.0, 0.30882528480224597, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18428300571317455, 0.18428300571317455, 0.2524982946226781], 
reward next is 0.7475, 
noisyNet noise sample is [array([0.8474854], dtype=float32), 0.5430603]. 
=============================================
[2019-04-27 18:15:21,149] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.0951389e-16 1.0000000e+00 2.1337681e-21 3.5322287e-14 2.3385843e-20], sum to 1.0000
[2019-04-27 18:15:21,157] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7690
[2019-04-27 18:15:21,163] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.46666666666667, 59.0, 1.0, 2.0, 0.4918132256901845, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 588793.9704587748, 588793.9704587748, 141694.6351452472], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7932000.0000, 
sim time next is 7932600.0000, 
raw observation next is [27.3, 59.5, 1.0, 2.0, 0.4917265328938372, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 589346.4652164247, 589346.4652164247, 141704.4443693891], 
processed observation next is [1.0, 0.8260869565217391, 0.5666666666666667, 0.595, 1.0, 1.0, 0.39491253915933006, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21048088043443738, 0.21048088043443738, 0.2725085468642098], 
reward next is 0.7275, 
noisyNet noise sample is [array([-0.5721819], dtype=float32), -2.3615587]. 
=============================================
[2019-04-27 18:15:23,005] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 18:15:23,005] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:15:23,006] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run2
[2019-04-27 18:15:23,162] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 18:15:23,163] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:15:23,165] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run2
[2019-04-27 18:15:23,195] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 18:15:23,196] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:15:23,198] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run2
[2019-04-27 18:15:23,409] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 18:15:23,410] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:15:23,411] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run2
[2019-04-27 18:15:23,536] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 18:15:23,537] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:15:23,538] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run2
[2019-04-27 18:15:23,700] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 18:15:23,701] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:15:23,702] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run2
[2019-04-27 18:15:23,733] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 18:15:23,733] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:15:23,735] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run2
[2019-04-27 18:15:23,757] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 18:15:23,758] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:15:23,760] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run2
[2019-04-27 18:15:23,778] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 18:15:23,779] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:15:23,782] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run2
[2019-04-27 18:15:23,877] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 18:15:23,877] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:15:23,878] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run2
[2019-04-27 18:15:23,897] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 18:15:23,897] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:15:23,899] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run2
[2019-04-27 18:15:23,922] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 18:15:23,922] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:15:23,924] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run2
[2019-04-27 18:15:23,944] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 18:15:23,944] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:15:23,946] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run2
[2019-04-27 18:15:23,972] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 18:15:23,972] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:15:23,974] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run2
[2019-04-27 18:15:23,995] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 18:15:23,995] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:15:23,997] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run2
[2019-04-27 18:15:24,018] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 18:15:24,018] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:15:24,020] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run2
[2019-04-27 18:15:30,157] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3809596e-19 1.0000000e+00 5.5087778e-26 3.3858177e-14 1.2064520e-21], sum to 1.0000
[2019-04-27 18:15:30,163] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7924
[2019-04-27 18:15:30,168] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.96666666666667, 64.0, 1.0, 2.0, 0.4244870178744375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 520604.6018310955, 520604.601831095, 131989.9174110973], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 82200.0000, 
sim time next is 82800.0000, 
raw observation next is [24.8, 65.0, 1.0, 2.0, 0.4260724219117081, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 522518.6557235957, 522518.6557235957, 132219.0752668787], 
processed observation next is [1.0, 1.0, 0.4740740740740741, 0.65, 1.0, 1.0, 0.3167528832282239, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1866138056155699, 0.1866138056155699, 0.2542674524363052], 
reward next is 0.7457, 
noisyNet noise sample is [array([-0.42650148], dtype=float32), 0.5518035]. 
=============================================
[2019-04-27 18:15:36,114] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.31693115e-20 1.00000000e+00 1.82555256e-23 9.57298849e-15
 8.59211445e-22], sum to 1.0000
[2019-04-27 18:15:36,123] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1680
[2019-04-27 18:15:36,136] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666667, 44.0, 1.0, 2.0, 0.2594843098906052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 334715.104021851, 334715.104021851, 91782.12701774288], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 188400.0000, 
sim time next is 189000.0000, 
raw observation next is [20.8, 46.5, 1.0, 2.0, 0.2558082860819988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 329972.2917067006, 329972.2917067006, 91594.7366167911], 
processed observation next is [0.0, 0.17391304347826086, 0.32592592592592595, 0.465, 1.0, 1.0, 0.11405748343095094, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.11784724703810735, 0.11784724703810735, 0.1761437242630598], 
reward next is 0.8239, 
noisyNet noise sample is [array([0.67182386], dtype=float32), 0.061241273]. 
=============================================
[2019-04-27 18:15:36,159] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[76.8941 ]
 [76.91663]
 [77.01234]
 [77.17071]
 [77.10219]], R is [[76.93714905]
 [76.99127197]
 [77.04458618]
 [77.09719086]
 [77.14865875]].
[2019-04-27 18:15:37,086] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.4517973e-19 1.0000000e+00 8.5642905e-24 2.9127901e-14 4.3215234e-22], sum to 1.0000
[2019-04-27 18:15:37,096] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3366
[2019-04-27 18:15:37,101] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.1, 13.83333333333333, 1.0, 2.0, 0.3733559869705815, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 481007.7906979043, 481007.7906979039, 125108.8648741274], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 222600.0000, 
sim time next is 223200.0000, 
raw observation next is [33.3, 13.0, 1.0, 2.0, 0.3746885712699762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 483225.5931543391, 483225.5931543387, 125286.5570740391], 
processed observation next is [0.0, 0.6086956521739131, 0.7888888888888888, 0.13, 1.0, 1.0, 0.25558163246425736, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17258056898369253, 0.1725805689836924, 0.24093568668084442], 
reward next is 0.7591, 
noisyNet noise sample is [array([-0.02987895], dtype=float32), 1.1681918]. 
=============================================
[2019-04-27 18:15:42,650] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.3599678e-22 1.0000000e+00 3.1253181e-26 3.4356683e-14 1.1110870e-23], sum to 1.0000
[2019-04-27 18:15:42,654] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9858
[2019-04-27 18:15:42,660] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.73333333333333, 44.5, 1.0, 2.0, 0.2909835684954484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 374909.372492536, 374909.372492536, 114458.8833006356], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 341400.0000, 
sim time next is 342000.0000, 
raw observation next is [23.6, 45.0, 1.0, 2.0, 0.2912203712318286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 375294.9561756047, 375294.9561756047, 114487.0245443953], 
processed observation next is [0.0, 1.0, 0.4296296296296297, 0.45, 1.0, 1.0, 0.1562147276569388, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13403391291985883, 0.13403391291985883, 0.22016735489306788], 
reward next is 0.7798, 
noisyNet noise sample is [array([0.9884471], dtype=float32), 0.15224233]. 
=============================================
[2019-04-27 18:15:42,678] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[84.471924]
 [84.510666]
 [84.5444  ]
 [84.57453 ]
 [84.61174 ]], R is [[84.43100739]
 [84.36658478]
 [84.30287933]
 [84.23952484]
 [84.17648315]].
[2019-04-27 18:15:43,971] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.2296633e-17 1.0000000e+00 6.3949897e-22 4.6147731e-11 5.5943533e-19], sum to 1.0000
[2019-04-27 18:15:43,981] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6474
[2019-04-27 18:15:43,986] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.83333333333334, 37.0, 1.0, 2.0, 0.3121413434248507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 400957.6235211717, 400957.6235211717, 117086.8908760632], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 332400.0000, 
sim time next is 333000.0000, 
raw observation next is [25.7, 37.5, 1.0, 2.0, 0.3105613204554739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 398965.7200231063, 398965.7200231063, 116888.276446878], 
processed observation next is [0.0, 0.8695652173913043, 0.5074074074074074, 0.375, 1.0, 1.0, 0.1792396672088975, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1424877571511094, 0.1424877571511094, 0.2247851470132269], 
reward next is 0.7752, 
noisyNet noise sample is [array([-0.41257864], dtype=float32), -1.7187262]. 
=============================================
[2019-04-27 18:15:44,003] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[73.01108]
 [73.02339]
 [73.00919]
 [72.95775]
 [72.95464]], R is [[73.04329681]
 [73.08769989]
 [73.13127136]
 [73.17417145]
 [73.21633148]].
[2019-04-27 18:15:46,400] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.6341130e-11 9.9999988e-01 2.3808950e-13 9.8107179e-08 2.4555932e-12], sum to 1.0000
[2019-04-27 18:15:46,406] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6456
[2019-04-27 18:15:46,410] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.8, 33.5, 1.0, 2.0, 0.870702272697101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.014367677136711, 6.9112, 121.9254632867497, 1168715.346787564, 1115884.526096896, 215158.7570369703], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 379800.0000, 
sim time next is 380400.0000, 
raw observation next is [27.0, 33.0, 1.0, 2.0, 0.8785276766560056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.065579698004341, 6.9112, 121.9252469810476, 1204442.6346488, 1125386.946855037, 216928.3481791435], 
processed observation next is [1.0, 0.391304347826087, 0.5555555555555556, 0.33, 1.0, 1.0, 0.8553900912571495, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.015437969800434104, 0.0, 0.8094568466336993, 0.4301580838031428, 0.40192390959108465, 0.41716990034450674], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.698214], dtype=float32), -0.95213187]. 
=============================================
[2019-04-27 18:15:48,876] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2459452e-15 1.0000000e+00 6.2940562e-18 1.8210757e-09 3.4482023e-17], sum to 1.0000
[2019-04-27 18:15:48,885] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1995
[2019-04-27 18:15:48,890] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 67.5, 1.0, 2.0, 0.3401558826894251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 437747.5854680617, 437747.5854680617, 120674.7863844145], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 454200.0000, 
sim time next is 454800.0000, 
raw observation next is [20.3, 66.0, 1.0, 2.0, 0.3020816470514685, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 388455.2767675213, 388455.2767675213, 115828.9057334496], 
processed observation next is [1.0, 0.2608695652173913, 0.3074074074074074, 0.66, 1.0, 1.0, 0.1691448179184149, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13873402741697188, 0.13873402741697188, 0.22274789564124925], 
reward next is 0.7773, 
noisyNet noise sample is [array([0.71853924], dtype=float32), 0.023130424]. 
=============================================
[2019-04-27 18:15:52,165] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-04-27 18:15:52,169] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 18:15:52,171] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 18:15:52,172] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:15:52,172] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 18:15:52,173] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:15:52,174] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:15:52,173] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 18:15:52,174] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 18:15:52,176] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:15:52,179] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:15:52,196] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run10
[2019-04-27 18:15:52,196] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run10
[2019-04-27 18:15:52,197] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run10
[2019-04-27 18:15:52,255] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run10
[2019-04-27 18:15:52,283] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run10
[2019-04-27 18:16:09,083] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.04023718]
[2019-04-27 18:16:09,085] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [19.30194939666667, 64.10457080666667, 1.0, 2.0, 0.232126516026329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 299418.7338351255, 299418.7338351255, 95973.62306058346]
[2019-04-27 18:16:09,086] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 18:16:09,089] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.39728681e-10 9.99893904e-01 1.54881598e-12 1.06120686e-04
 1.96613684e-10], sampled 0.47186649408673664
[2019-04-27 18:16:12,341] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.04023718]
[2019-04-27 18:16:12,341] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [35.35388322166667, 26.10032968966667, 1.0, 2.0, 0.404898065643597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 489585.8988895047, 489585.8988895052, 128977.4412987202]
[2019-04-27 18:16:12,342] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 18:16:12,344] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.4155310e-11 9.9996102e-01 8.8138013e-14 3.8980146e-05 1.9732710e-11], sampled 0.9188475608921919
[2019-04-27 18:16:28,375] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.04023718]
[2019-04-27 18:16:28,376] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.0, 76.5, 1.0, 2.0, 0.5729365497962604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 667253.0365359056, 667253.0365359056, 154161.4340260064]
[2019-04-27 18:16:28,377] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 18:16:28,380] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.4993372e-11 9.9993503e-01 3.3396140e-13 6.5024389e-05 5.6089276e-11], sampled 0.4313213965496475
[2019-04-27 18:16:30,356] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.04023718]
[2019-04-27 18:16:30,357] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [32.2, 60.33333333333334, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 8.049621895369725, 6.9112, 121.9218573612501, 2461643.482392149, 1878689.732226544, 380043.5724283737]
[2019-04-27 18:16:30,358] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 18:16:30,364] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.08530413e-12 9.99977231e-01 1.17270145e-14 2.28006720e-05
 4.83322323e-12], sampled 0.35071114048703644
[2019-04-27 18:16:30,365] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2461643.482392149 W.
[2019-04-27 18:16:40,442] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.04023718]
[2019-04-27 18:16:40,444] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.55172405666666, 94.80991925833334, 1.0, 2.0, 0.6636645036575317, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 756369.3582515692, 756369.3582515689, 169376.4800200261]
[2019-04-27 18:16:40,445] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 18:16:40,448] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [8.5584748e-11 9.9992442e-01 3.8095059e-13 7.5613265e-05 6.8660494e-11], sampled 0.4310011850044707
[2019-04-27 18:16:47,856] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.04023718]
[2019-04-27 18:16:47,857] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [36.543647585, 44.89859923500001, 1.0, 2.0, 0.9103822721946752, 1.0, 2.0, 0.9103822721946752, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260424978416, 2076792.566340794, 2076792.566340794, 391478.6629381563]
[2019-04-27 18:16:47,858] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 18:16:47,860] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.2567690e-10 9.9982578e-01 4.6646072e-12 1.7421760e-04 5.3967592e-10], sampled 0.2072769178658479
[2019-04-27 18:16:47,864] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2076792.566340794 W.
[2019-04-27 18:16:50,890] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.04023718]
[2019-04-27 18:16:50,891] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.66666666666667, 85.50000000000001, 1.0, 2.0, 0.4206455224566588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 516848.7648083018, 516848.7648083018, 131459.9218185627]
[2019-04-27 18:16:50,891] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 18:16:50,895] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.09541314e-10 9.99919653e-01 5.04147884e-13 8.03738367e-05
 8.78840403e-11], sampled 0.18633255489201017
[2019-04-27 18:16:57,461] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.04023718]
[2019-04-27 18:16:57,463] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.36666666666667, 91.33333333333334, 1.0, 2.0, 0.8772549979567837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 999954.3274664787, 999954.3274664787, 212430.993091008]
[2019-04-27 18:16:57,464] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 18:16:57,466] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.8350601e-11 9.9995637e-01 1.0606107e-13 4.3677064e-05 2.1053794e-11], sampled 0.9181909562501909
[2019-04-27 18:17:05,299] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.04023718]
[2019-04-27 18:17:05,302] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.36457737, 77.64277426, 1.0, 2.0, 0.5469539109778658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 643785.307466306, 643785.307466306, 150129.5655561109]
[2019-04-27 18:17:05,303] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 18:17:05,306] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.1978774e-11 9.9996901e-01 3.0137802e-14 3.0953965e-05 8.5593746e-12], sampled 0.5855839261172336
[2019-04-27 18:17:17,299] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.04023718]
[2019-04-27 18:17:17,302] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.64114813333333, 73.39760896666667, 1.0, 2.0, 0.7432338288000686, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 847103.5414917815, 847103.5414917815, 184494.697023159]
[2019-04-27 18:17:17,304] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 18:17:17,308] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.81139400e-11 9.99954581e-01 1.01322976e-13 4.53844441e-05
 2.28020849e-11], sampled 0.5191243145325961
[2019-04-27 18:17:20,598] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.04023718]
[2019-04-27 18:17:20,601] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.5, 91.5, 1.0, 2.0, 0.5926184954258541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 695456.1227545835, 695456.1227545835, 157744.103276596]
[2019-04-27 18:17:20,601] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 18:17:20,606] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.24281524e-10 9.99887109e-01 1.48731125e-12 1.12860536e-04
 1.93969951e-10], sampled 0.5105749981950265
[2019-04-27 18:17:30,835] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.04023718]
[2019-04-27 18:17:30,836] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.02351589, 87.204662555, 1.0, 2.0, 0.4789220928908987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 572404.08849472, 572404.08849472, 139665.5111912694]
[2019-04-27 18:17:30,838] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 18:17:30,840] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.5412086e-10 9.9988651e-01 1.6849192e-12 1.1352153e-04 2.1157924e-10], sampled 0.8711913474341932
[2019-04-27 18:17:31,368] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.04023718]
[2019-04-27 18:17:31,370] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.7, 74.5, 1.0, 2.0, 0.4059634821454339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 501899.3532041663, 501899.3532041658, 129437.0878006422]
[2019-04-27 18:17:31,371] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 18:17:31,373] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.0939656e-11 9.9993920e-01 2.4815027e-13 6.0839440e-05 4.7149114e-11], sampled 0.7684342680349168
[2019-04-27 18:17:40,516] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8922.7937 2120428421.6109 430.0000
[2019-04-27 18:17:40,662] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8698.8698 2195077306.5691 572.0000
[2019-04-27 18:17:40,885] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-04-27 18:17:41,000] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8097.8711 2445369864.4281 746.0000
[2019-04-27 18:17:41,132] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8582.8795 2248773970.1662 553.0000
[2019-04-27 18:17:42,148] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 225000, evaluation results [225000.0, 8097.871082328516, 2445369864.428084, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8922.793657586852, 2120428421.6108897, 430.0, 8582.879467926026, 2248773970.1662407, 553.0, 8698.869825232914, 2195077306.569128, 572.0]
[2019-04-27 18:17:43,847] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.3390652e-15 9.9999988e-01 1.1237036e-16 1.6522269e-07 1.4571463e-15], sum to 1.0000
[2019-04-27 18:17:43,858] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8096
[2019-04-27 18:17:43,862] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.73333333333333, 46.33333333333334, 1.0, 2.0, 0.335719987016585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 424082.740722004, 424082.740722004, 120071.2486589477], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 510000.0000, 
sim time next is 510600.0000, 
raw observation next is [25.46666666666667, 47.16666666666666, 1.0, 2.0, 0.3335143476090035, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 421654.4595051919, 421654.4595051919, 119789.2496177124], 
processed observation next is [1.0, 0.9130434782608695, 0.4987654320987655, 0.47166666666666657, 1.0, 1.0, 0.206564699534528, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15059087839471139, 0.15059087839471139, 0.23036394157252385], 
reward next is 0.7696, 
noisyNet noise sample is [array([-1.5869147], dtype=float32), -0.5501677]. 
=============================================
[2019-04-27 18:17:45,219] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.0167743e-12 9.9940491e-01 1.7491641e-17 5.9505476e-04 2.0059674e-12], sum to 1.0000
[2019-04-27 18:17:45,225] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5979
[2019-04-27 18:17:45,229] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.36666666666667, 77.66666666666666, 1.0, 2.0, 0.3050418598756934, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 389873.3271422607, 389873.3271422607, 116201.9659003842], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 535800.0000, 
sim time next is 536400.0000, 
raw observation next is [19.3, 78.0, 1.0, 2.0, 0.3032750116959846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 387705.05735794, 387705.05735794, 115982.4278117022], 
processed observation next is [1.0, 0.21739130434782608, 0.27037037037037037, 0.78, 1.0, 1.0, 0.17056549011426736, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13846609191355, 0.13846609191355, 0.22304313040711962], 
reward next is 0.7770, 
noisyNet noise sample is [array([2.0285828], dtype=float32), 0.9568426]. 
=============================================
[2019-04-27 18:17:45,442] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.6125738e-12 9.9991488e-01 9.2696033e-15 8.5061234e-05 2.0451713e-11], sum to 1.0000
[2019-04-27 18:17:45,449] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8582
[2019-04-27 18:17:45,455] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.23333333333333, 68.0, 1.0, 2.0, 0.3441840716333947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 437700.01137077, 437700.0113707695, 121202.3824591959], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 542400.0000, 
sim time next is 543000.0000, 
raw observation next is [21.41666666666667, 67.0, 1.0, 2.0, 0.3437864480133992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 437053.6151384575, 437053.6151384575, 121149.2683511697], 
processed observation next is [1.0, 0.2608695652173913, 0.3487654320987656, 0.67, 1.0, 1.0, 0.2187933904921419, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1560905768351634, 0.1560905768351634, 0.23297936221378787], 
reward next is 0.7670, 
noisyNet noise sample is [array([-1.6337789], dtype=float32), -0.75920147]. 
=============================================
[2019-04-27 18:17:45,466] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[56.36971 ]
 [56.44907 ]
 [56.530113]
 [56.733547]
 [57.128147]], R is [[56.49710464]
 [56.6990509 ]
 [56.89726257]
 [57.09338379]
 [57.28305817]].
[2019-04-27 18:17:47,634] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.6968402e-13 1.2438418e-04 3.7444804e-16 9.9987555e-01 4.8642597e-11], sum to 1.0000
[2019-04-27 18:17:47,640] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9895
[2019-04-27 18:17:47,646] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.0, 53.5, 1.0, 2.0, 0.1662752191309991, 1.0, 2.0, 0.1662752191309991, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 418723.6066734471, 418723.6066734475, 153095.7840693814], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 610200.0000, 
sim time next is 610800.0000, 
raw observation next is [23.86666666666667, 54.0, 1.0, 2.0, 0.1650490643317691, 1.0, 2.0, 0.1650490643317691, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 415817.6351890377, 415817.6351890381, 152850.3989603259], 
processed observation next is [1.0, 0.043478260869565216, 0.4395061728395063, 0.54, 1.0, 1.0, 0.006010790871153695, 1.0, 1.0, 0.006010790871153695, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14850629828179918, 0.14850629828179931, 0.29394307492370364], 
reward next is 0.7061, 
noisyNet noise sample is [array([0.23859389], dtype=float32), -1.4014454]. 
=============================================
[2019-04-27 18:17:56,751] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.1022619e-13 1.2959829e-05 1.9535301e-15 9.9998701e-01 8.3086302e-11], sum to 1.0000
[2019-04-27 18:17:56,761] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3961
[2019-04-27 18:17:56,769] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 28.33333333333334, 1.0, 2.0, 0.4969555532144669, 1.0, 2.0, 0.4969555532144669, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1226590.730579952, 1226590.730579952, 238022.7415499956], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 739200.0000, 
sim time next is 739800.0000, 
raw observation next is [31.3, 27.0, 1.0, 2.0, 0.519933224134798, 1.0, 2.0, 0.519933224134798, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1282951.569962423, 1282951.569962423, 245366.6994805643], 
processed observation next is [1.0, 0.5652173913043478, 0.7148148148148148, 0.27, 1.0, 1.0, 0.42849193349380715, 1.0, 1.0, 0.42849193349380715, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.45819698927229396, 0.45819698927229396, 0.47185903746262364], 
reward next is 0.5281, 
noisyNet noise sample is [array([0.5983344], dtype=float32), -0.053698823]. 
=============================================
[2019-04-27 18:18:04,450] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0602034e-12 2.0029065e-05 4.5819942e-14 9.9997997e-01 5.2544352e-10], sum to 1.0000
[2019-04-27 18:18:04,458] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1216
[2019-04-27 18:18:04,463] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.85, 50.0, 1.0, 2.0, 0.2193327341794189, 1.0, 2.0, 0.2193327341794189, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 531559.5881168752, 531559.5881168756, 163686.7463562043], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 912600.0000, 
sim time next is 913200.0000, 
raw observation next is [28.06666666666667, 49.33333333333334, 1.0, 2.0, 0.2204131625681933, 1.0, 2.0, 0.2204131625681933, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 533640.9973170536, 533640.9973170536, 163901.4578915421], 
processed observation next is [0.0, 0.5652173913043478, 0.5950617283950619, 0.4933333333333334, 1.0, 1.0, 0.07192043162880155, 1.0, 1.0, 0.07192043162880155, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1905860704703763, 0.1905860704703763, 0.31519511132988864], 
reward next is 0.6848, 
noisyNet noise sample is [array([-1.4534632], dtype=float32), 0.78709745]. 
=============================================
[2019-04-27 18:18:11,859] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.4267823e-07 6.1128087e-02 2.9160011e-11 9.3877876e-01 9.2910333e-05], sum to 1.0000
[2019-04-27 18:18:11,868] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9040
[2019-04-27 18:18:11,875] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.65, 46.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 364564.3301331807, 364564.3301331811, 145302.3984747997], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1027800.0000, 
sim time next is 1028400.0000, 
raw observation next is [23.6, 46.66666666666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 363916.1781013474, 363916.1781013479, 145199.8125236638], 
processed observation next is [1.0, 0.9130434782608695, 0.4296296296296297, 0.46666666666666673, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1299700636076241, 0.12997006360762425, 0.27923040869935345], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.345243], dtype=float32), 0.4403925]. 
=============================================
[2019-04-27 18:18:13,487] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.6933813e-08 9.9310583e-01 3.5167370e-12 6.8939012e-03 2.7011544e-07], sum to 1.0000
[2019-04-27 18:18:13,500] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9680
[2019-04-27 18:18:13,504] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.03333333333333, 67.0, 1.0, 2.0, 0.3055278783948039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 389829.385167547, 389829.3851675475, 116261.1198763341], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1046400.0000, 
sim time next is 1047000.0000, 
raw observation next is [20.96666666666667, 67.5, 1.0, 2.0, 0.3020588726722637, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 385395.3665520631, 385395.3665520636, 115830.1218729356], 
processed observation next is [1.0, 0.08695652173913043, 0.3320987654320988, 0.675, 1.0, 1.0, 0.16911770556221872, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13764120234002253, 0.13764120234002272, 0.22275023437103], 
reward next is 0.7772, 
noisyNet noise sample is [array([0.22508076], dtype=float32), 0.9004847]. 
=============================================
[2019-04-27 18:18:13,516] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[48.00451 ]
 [48.12004 ]
 [48.13926 ]
 [47.399925]
 [47.768013]], R is [[48.5616188 ]
 [48.85242462]
 [49.1370163 ]
 [49.4093399 ]
 [49.64923859]].
[2019-04-27 18:18:14,564] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.5871266e-13 9.9996817e-01 3.9226873e-17 3.1794880e-05 8.4352507e-09], sum to 1.0000
[2019-04-27 18:18:14,573] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3989
[2019-04-27 18:18:14,578] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.21666666666667, 51.5, 1.0, 2.0, 0.7326333767667431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 928439.8737705643, 928439.8737705643, 185684.7327645493], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1075800.0000, 
sim time next is 1076400.0000, 
raw observation next is [24.3, 51.0, 1.0, 2.0, 0.7744291057594215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 981511.713570805, 981511.713570805, 194228.6310680226], 
processed observation next is [1.0, 0.4782608695652174, 0.4555555555555556, 0.51, 1.0, 1.0, 0.7314632211421684, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.35053989770385896, 0.35053989770385896, 0.37351659820773575], 
reward next is 0.6265, 
noisyNet noise sample is [array([-1.3715982], dtype=float32), 0.6138043]. 
=============================================
[2019-04-27 18:18:31,105] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.6194169e-13 1.0000000e+00 1.1400797e-18 2.7078164e-09 2.6868617e-13], sum to 1.0000
[2019-04-27 18:18:31,116] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6038
[2019-04-27 18:18:31,120] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.75, 41.33333333333334, 1.0, 2.0, 0.3531393700891461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 442622.0719331374, 442622.0719331374, 122311.8725567118], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1365000.0000, 
sim time next is 1365600.0000, 
raw observation next is [27.5, 42.66666666666667, 1.0, 2.0, 0.3551979409085979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 444885.2974389549, 444885.2974389544, 122580.3909784085], 
processed observation next is [1.0, 0.8260869565217391, 0.5740740740740741, 0.4266666666666667, 1.0, 1.0, 0.2323785010816642, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15888760622819817, 0.158887606228198, 0.23573152111232404], 
reward next is 0.7643, 
noisyNet noise sample is [array([1.4754223], dtype=float32), 0.49037173]. 
=============================================
[2019-04-27 18:18:34,324] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-04-27 18:18:34,327] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 18:18:34,329] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:18:34,329] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 18:18:34,332] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 18:18:34,333] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:18:34,331] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 18:18:34,334] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 18:18:34,333] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:18:34,336] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:18:34,336] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:18:34,353] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run11
[2019-04-27 18:18:34,371] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run11
[2019-04-27 18:18:34,398] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run11
[2019-04-27 18:18:34,417] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run11
[2019-04-27 18:18:34,417] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run11
[2019-04-27 18:18:58,669] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.044211835]
[2019-04-27 18:18:58,670] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.22870238666667, 61.85729300166667, 1.0, 2.0, 0.5497077406493557, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 670794.4887325342, 670794.4887325342, 151428.7988711316]
[2019-04-27 18:18:58,671] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 18:18:58,675] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.5626974e-18 1.0000000e+00 1.2069611e-24 5.6221076e-13 1.5384415e-17], sampled 0.5515937081427207
[2019-04-27 18:19:19,056] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.044211835]
[2019-04-27 18:19:19,057] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.18333333333333, 92.66666666666667, 1.0, 2.0, 0.6133088373476403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 706990.7820918395, 706990.7820918395, 160774.188148523]
[2019-04-27 18:19:19,058] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 18:19:19,061] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.3965938e-18 1.0000000e+00 1.1407592e-24 5.2182081e-13 1.3870588e-17], sampled 0.6353675292396639
[2019-04-27 18:19:19,779] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.044211835]
[2019-04-27 18:19:19,781] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.922322795, 71.11956438333334, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.302968590245115, 6.9112, 121.9244140784417, 1363558.293741327, 1162940.439297441, 245584.7446211656]
[2019-04-27 18:19:19,783] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 18:19:19,786] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.8262607e-18 1.0000000e+00 1.5517801e-24 5.8817561e-13 1.6761020e-17], sampled 0.22259059333704345
[2019-04-27 18:19:19,788] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1363558.293741327 W.
[2019-04-27 18:19:26,203] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.044211835]
[2019-04-27 18:19:26,203] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [32.85, 59.0, 1.0, 2.0, 0.7600436837766384, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 866273.464285439, 866273.464285439, 187829.0860795367]
[2019-04-27 18:19:26,203] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 18:19:26,205] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.5427307e-18 1.0000000e+00 1.3056238e-24 5.6218929e-13 1.4929755e-17], sampled 0.2856943657405795
[2019-04-27 18:20:02,042] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.044211835]
[2019-04-27 18:20:02,044] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.86876331, 46.11956302, 1.0, 2.0, 0.3148860150473156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 400375.821806876, 400375.821806876, 117427.4470891853]
[2019-04-27 18:20:02,046] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 18:20:02,051] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.7789970e-18 1.0000000e+00 4.7789075e-24 1.0896339e-12 3.5174595e-17], sampled 0.76555597587215
[2019-04-27 18:20:21,343] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-04-27 18:20:21,440] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8583.7021 2248718286.8236 553.0000
[2019-04-27 18:20:21,444] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.044211835]
[2019-04-27 18:20:21,444] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.63333333333333, 69.33333333333334, 1.0, 2.0, 0.4556057927784745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 554166.8207135566, 554166.8207135566, 136454.0552582926]
[2019-04-27 18:20:21,445] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 18:20:21,446] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-04-27 18:20:21,447] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0095769e-18 1.0000000e+00 6.8076542e-25 3.7468314e-13 9.4630703e-18], sampled 0.6443623218026076
[2019-04-27 18:20:21,475] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-04-27 18:20:21,521] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2399 2120425912.2928 430.0000
[2019-04-27 18:20:22,533] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 250000, evaluation results [250000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.239875831723, 2120425912.2928398, 430.0, 8583.702050975664, 2248718286.823596, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-04-27 18:20:27,335] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.9312200e-18 1.0000000e+00 6.3294306e-24 5.2065886e-12 1.8629990e-17], sum to 1.0000
[2019-04-27 18:20:27,344] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5245
[2019-04-27 18:20:27,350] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.2, 66.5, 1.0, 2.0, 0.5105627510353288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 610379.2742631013, 610379.2742631013, 144616.6385040554], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1537800.0000, 
sim time next is 1538400.0000, 
raw observation next is [25.7, 69.0, 1.0, 2.0, 0.5081287035775254, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 608206.1064550175, 608206.106455017, 144256.5027971114], 
processed observation next is [0.0, 0.8260869565217391, 0.5074074074074074, 0.69, 1.0, 1.0, 0.41443893283038735, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21721646659107766, 0.2172164665910775, 0.27741635153290656], 
reward next is 0.7226, 
noisyNet noise sample is [array([-2.1883402], dtype=float32), 0.653168]. 
=============================================
[2019-04-27 18:20:35,194] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.0066148e-15 1.0000000e+00 6.6511319e-22 1.9455617e-14 1.5025291e-16], sum to 1.0000
[2019-04-27 18:20:35,201] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4439
[2019-04-27 18:20:35,206] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.03333333333333, 64.0, 1.0, 2.0, 0.3216789426718244, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 408365.329599056, 408365.329599056, 118284.9660086863], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1646400.0000, 
sim time next is 1647000.0000, 
raw observation next is [21.95, 64.5, 1.0, 2.0, 0.3214411428918963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 408082.1401107764, 408082.1401107764, 118254.8163625456], 
processed observation next is [1.0, 0.043478260869565216, 0.36851851851851847, 0.645, 1.0, 1.0, 0.19219183677606702, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14574362146813444, 0.14574362146813444, 0.2274131083895108], 
reward next is 0.7726, 
noisyNet noise sample is [array([0.09329955], dtype=float32), 0.5018813]. 
=============================================
[2019-04-27 18:20:35,218] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[77.859505]
 [77.84055 ]
 [77.92828 ]
 [77.93833 ]
 [77.850876]], R is [[77.73488617]
 [77.73006439]
 [77.72549438]
 [77.72114563]
 [77.71689606]].
[2019-04-27 18:20:35,469] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.4442499e-14 1.0000000e+00 8.2074937e-18 5.1036597e-10 3.8724620e-13], sum to 1.0000
[2019-04-27 18:20:35,476] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5090
[2019-04-27 18:20:35,481] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.8, 77.0, 1.0, 2.0, 0.3654002080101624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 465393.8590127878, 465393.8590127878, 124034.6281759137], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1654200.0000, 
sim time next is 1654800.0000, 
raw observation next is [19.6, 78.33333333333334, 1.0, 2.0, 0.3438177929621198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 438030.4692188016, 438030.4692188016, 121158.3677777015], 
processed observation next is [1.0, 0.13043478260869565, 0.28148148148148155, 0.7833333333333334, 1.0, 1.0, 0.21883070590728546, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15643945329242914, 0.15643945329242914, 0.2329968611109644], 
reward next is 0.7670, 
noisyNet noise sample is [array([0.76107997], dtype=float32), 0.07819242]. 
=============================================
[2019-04-27 18:20:37,653] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.0877797e-16 1.0000000e+00 5.4395500e-20 5.7015252e-12 1.9720692e-14], sum to 1.0000
[2019-04-27 18:20:37,660] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8499
[2019-04-27 18:20:37,665] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.2, 69.0, 1.0, 2.0, 0.8496360924584618, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1053883.829531513, 1053883.829531513, 209960.9044707321], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1693200.0000, 
sim time next is 1693800.0000, 
raw observation next is [23.25, 69.0, 1.0, 2.0, 0.8563337423824632, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1061543.341837555, 1061543.341837555, 211427.525551832], 
processed observation next is [1.0, 0.6086956521739131, 0.4166666666666667, 0.69, 1.0, 1.0, 0.8289687409315037, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.37912262208484104, 0.37912262208484104, 0.40659139529198457], 
reward next is 0.5934, 
noisyNet noise sample is [array([-0.02456056], dtype=float32), -0.8215011]. 
=============================================
[2019-04-27 18:20:39,034] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0365043e-16 1.0000000e+00 2.7606300e-19 1.1579883e-12 7.0320451e-15], sum to 1.0000
[2019-04-27 18:20:39,043] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5250
[2019-04-27 18:20:39,048] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.8, 89.0, 1.0, 2.0, 0.3603857028667307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 451356.6497012962, 451356.6497012962, 123273.1118447614], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1746000.0000, 
sim time next is 1746600.0000, 
raw observation next is [19.96666666666667, 88.16666666666667, 1.0, 2.0, 0.3899656431317965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 488138.3618033805, 488138.3618033801, 127313.0346826939], 
processed observation next is [1.0, 0.21739130434782608, 0.2950617283950618, 0.8816666666666667, 1.0, 1.0, 0.2737686227759482, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17433512921549302, 0.17433512921549288, 0.2448327590051806], 
reward next is 0.7552, 
noisyNet noise sample is [array([-0.29154244], dtype=float32), 0.37011865]. 
=============================================
[2019-04-27 18:20:42,852] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.7023240e-09 9.9995196e-01 9.5897530e-13 4.8029946e-05 3.3003239e-08], sum to 1.0000
[2019-04-27 18:20:42,859] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1469
[2019-04-27 18:20:42,864] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1414792.24542596 W.
[2019-04-27 18:20:42,870] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.8, 65.0, 1.0, 2.0, 0.6077244023467561, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9700024704891859, 6.911199999999999, 6.9112, 121.9260426156618, 1414792.24542596, 1414792.245425961, 296379.7012418465], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1786800.0000, 
sim time next is 1787400.0000, 
raw observation next is [26.7, 64.5, 1.0, 2.0, 0.599212070649573, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9580240719453904, 6.9112, 6.9112, 121.9260426156618, 1404575.336538906, 1404575.336538906, 292825.0005275923], 
processed observation next is [1.0, 0.6956521739130435, 0.5444444444444444, 0.645, 1.0, 1.0, 0.5228715126780631, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9475300899317379, 0.0, 0.0, 0.8094621288201359, 0.501634048763895, 0.501634048763895, 0.5631250010146006], 
reward next is 0.4369, 
noisyNet noise sample is [array([-0.62731767], dtype=float32), -0.34558007]. 
=============================================
[2019-04-27 18:20:56,144] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.0450025e-13 3.0437653e-04 7.0118526e-16 9.9967313e-01 2.2530932e-05], sum to 1.0000
[2019-04-27 18:20:56,152] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2712
[2019-04-27 18:20:56,156] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.4, 66.0, 1.0, 2.0, 0.2450945609141853, 1.0, 2.0, 0.2450945609141853, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 579452.9529284044, 579452.9529284049, 168812.4907424896], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2030400.0000, 
sim time next is 2031000.0000, 
raw observation next is [26.53333333333333, 65.83333333333333, 1.0, 2.0, 0.2478401190704347, 1.0, 2.0, 0.2478401190704347, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 584752.217192639, 584752.217192639, 169376.884818386], 
processed observation next is [0.0, 0.5217391304347826, 0.5382716049382715, 0.6583333333333333, 1.0, 1.0, 0.10457157032194608, 1.0, 1.0, 0.10457157032194608, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20884007756879966, 0.20884007756879966, 0.32572477849689613], 
reward next is 0.6743, 
noisyNet noise sample is [array([0.35931155], dtype=float32), -1.5346128]. 
=============================================
[2019-04-27 18:20:56,173] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[84.47613]
 [84.31083]
 [84.2028 ]
 [84.10466]
 [84.01592]], R is [[84.43838501]
 [84.2693634 ]
 [84.10330963]
 [83.94012451]
 [83.77976227]].
[2019-04-27 18:21:01,572] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.4547003e-10 6.7183195e-05 1.2225331e-13 9.9991620e-01 1.6603715e-05], sum to 1.0000
[2019-04-27 18:21:01,583] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0751
[2019-04-27 18:21:01,590] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.1, 56.66666666666667, 1.0, 2.0, 0.2960071246681758, 1.0, 2.0, 0.2960071246681758, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 674712.5973263849, 674712.5973263853, 179507.2005106545], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2122800.0000, 
sim time next is 2123400.0000, 
raw observation next is [30.3, 55.83333333333334, 1.0, 2.0, 0.2963421839271059, 1.0, 2.0, 0.2963421839271059, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 675438.6288479753, 675438.6288479757, 179585.2467875286], 
processed observation next is [0.0, 0.5652173913043478, 0.6777777777777778, 0.5583333333333335, 1.0, 1.0, 0.1623121237227451, 1.0, 1.0, 0.1623121237227451, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24122808173141974, 0.2412280817314199, 0.3453562438221704], 
reward next is 0.6546, 
noisyNet noise sample is [array([-1.076904], dtype=float32), 0.7113158]. 
=============================================
[2019-04-27 18:21:07,013] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.8462685e-10 6.3331630e-05 8.7392421e-14 9.9993432e-01 2.3670752e-06], sum to 1.0000
[2019-04-27 18:21:07,024] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0226
[2019-04-27 18:21:07,028] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.8, 94.5, 1.0, 2.0, 0.2721531754327951, 1.0, 2.0, 0.2721531754327951, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 635663.611515231, 635663.6115152314, 174658.8943716356], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2230200.0000, 
sim time next is 2230800.0000, 
raw observation next is [22.76666666666667, 94.33333333333334, 1.0, 2.0, 0.2716035578896301, 1.0, 2.0, 0.2716035578896301, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 635039.3152521584, 635039.3152521589, 174561.0405727191], 
processed observation next is [1.0, 0.8260869565217391, 0.3987654320987655, 0.9433333333333335, 1.0, 1.0, 0.13286137844003582, 1.0, 1.0, 0.13286137844003582, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22679975544719944, 0.2267997554471996, 0.33569430879369055], 
reward next is 0.6643, 
noisyNet noise sample is [array([0.39944386], dtype=float32), 0.4249835]. 
=============================================
[2019-04-27 18:21:10,816] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.5440488e-11 9.1735717e-07 3.4955087e-13 9.9999785e-01 1.2171090e-06], sum to 1.0000
[2019-04-27 18:21:10,829] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2591
[2019-04-27 18:21:10,832] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.35, 82.5, 1.0, 2.0, 0.4505389788765055, 1.0, 2.0, 0.4505389788765055, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1045840.868612446, 1045840.868612446, 221385.0128692827], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2291400.0000, 
sim time next is 2292000.0000, 
raw observation next is [24.46666666666667, 82.0, 1.0, 2.0, 0.4292110115163041, 1.0, 2.0, 0.4292110115163041, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 996636.8669971775, 996636.8669971771, 215206.5321040557], 
processed observation next is [1.0, 0.5217391304347826, 0.46172839506172847, 0.82, 1.0, 1.0, 0.3204892994241716, 1.0, 1.0, 0.3204892994241716, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3559417382132777, 0.35594173821327757, 0.4138587155847225], 
reward next is 0.5861, 
noisyNet noise sample is [array([1.1069009], dtype=float32), -0.06442416]. 
=============================================
[2019-04-27 18:21:10,853] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[58.184433]
 [58.037876]
 [57.572556]
 [58.017937]
 [57.989532]], R is [[58.31345749]
 [58.3045845 ]
 [58.27162933]
 [58.14211655]
 [58.09722519]].
[2019-04-27 18:21:10,914] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.5627646e-10 2.3365699e-06 3.0912152e-14 9.9999702e-01 5.9865067e-07], sum to 1.0000
[2019-04-27 18:21:10,924] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6152
[2019-04-27 18:21:10,928] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.6, 74.0, 1.0, 2.0, 0.5963261421535417, 1.0, 2.0, 0.5963261421535417, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1378561.040362342, 1378561.040362342, 267692.0653616084], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2300400.0000, 
sim time next is 2301000.0000, 
raw observation next is [25.66666666666667, 73.5, 1.0, 2.0, 0.6298081142706975, 1.0, 2.0, 0.6298081142706975, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1455211.072606292, 1455211.072606292, 279380.3097194274], 
processed observation next is [1.0, 0.6521739130434783, 0.506172839506173, 0.735, 1.0, 1.0, 0.5592953741317828, 1.0, 1.0, 0.5592953741317828, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5197182402165329, 0.5197182402165329, 0.5372698263835142], 
reward next is 0.4627, 
noisyNet noise sample is [array([1.0713476], dtype=float32), -0.53259677]. 
=============================================
[2019-04-27 18:21:10,938] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[57.846924]
 [57.845238]
 [57.869095]
 [57.970573]
 [57.869514]], R is [[57.59889603]
 [57.50811386]
 [57.43338776]
 [57.36428833]
 [57.31574631]].
[2019-04-27 18:21:14,625] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-27 18:21:14,627] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 18:21:14,628] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 18:21:14,629] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:21:14,629] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:21:14,630] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 18:21:14,631] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 18:21:14,631] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 18:21:14,635] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:21:14,632] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:21:14,635] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:21:14,651] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run12
[2019-04-27 18:21:14,652] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run12
[2019-04-27 18:21:14,652] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run12
[2019-04-27 18:21:14,672] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run12
[2019-04-27 18:21:14,713] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run12
[2019-04-27 18:21:17,701] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.047065537]
[2019-04-27 18:21:17,703] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.2, 42.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 327675.2885195587, 327675.2885195591, 117027.7995767739]
[2019-04-27 18:21:17,703] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 18:21:17,705] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.2612981e-10 3.3368226e-05 4.6906316e-13 9.9996531e-01 1.3053365e-06], sampled 0.21554206321343905
[2019-04-27 18:22:06,986] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.047065537]
[2019-04-27 18:22:06,987] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.81159648333333, 92.69821332333333, 1.0, 2.0, 0.384970326743887, 1.0, 2.0, 0.384970326743887, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 877560.1717132677, 877560.1717132677, 202102.9393725899]
[2019-04-27 18:22:06,987] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 18:22:06,990] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.37110373e-11 1.19045535e-05 3.57746330e-14 9.99987721e-01
 3.67490884e-07], sampled 0.6598950635317999
[2019-04-27 18:22:10,262] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.047065537]
[2019-04-27 18:22:10,264] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.66666666666667, 74.83333333333334, 1.0, 2.0, 0.3785533394406557, 1.0, 2.0, 0.3785533394406557, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 862924.0755923929, 862924.0755923934, 200381.4492219099]
[2019-04-27 18:22:10,265] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 18:22:10,268] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.7145713e-11 1.2149204e-05 3.6485785e-14 9.9998748e-01 3.7310784e-07], sampled 0.24590636738372973
[2019-04-27 18:22:40,318] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.047065537]
[2019-04-27 18:22:40,319] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.81115971333333, 78.79258125666667, 1.0, 2.0, 0.3372074795107613, 1.0, 2.0, 0.3372074795107613, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 768627.6481484266, 768627.648148427, 189629.9616818485]
[2019-04-27 18:22:40,320] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 18:22:40,324] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.3672273e-10 1.6604108e-05 8.3193658e-14 9.9998283e-01 5.3819070e-07], sampled 0.2856636711658096
[2019-04-27 18:23:01,428] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7522.4446 2668443324.6334 68.0000
[2019-04-27 18:23:01,572] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6907.5541 2495358454.3914 47.0000
[2019-04-27 18:23:01,697] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7122.2606 2438816242.1516 34.0000
[2019-04-27 18:23:01,739] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7478.3358 2465993538.8737 46.0000
[2019-04-27 18:23:01,793] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7797.6461 2410746474.6630 22.0000
[2019-04-27 18:23:02,808] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 275000, evaluation results [275000.0, 7522.4445541311425, 2668443324.6334205, 68.0, 7122.260633411203, 2438816242.1516013, 34.0, 7797.646136169532, 2410746474.6630116, 22.0, 6907.554075565959, 2495358454.391429, 47.0, 7478.33583409855, 2465993538.873662, 46.0]
[2019-04-27 18:23:03,644] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.8951300e-10 2.2013926e-04 5.7287779e-14 9.9977988e-01 2.9995434e-08], sum to 1.0000
[2019-04-27 18:23:03,658] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9349
[2019-04-27 18:23:03,662] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.6, 38.5, 1.0, 2.0, 0.469022122550272, 1.0, 2.0, 0.469022122550272, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1140229.792427971, 1140229.792427971, 228847.6466573699], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2374200.0000, 
sim time next is 2374800.0000, 
raw observation next is [29.7, 38.33333333333334, 1.0, 2.0, 0.4712740774367583, 1.0, 2.0, 0.4712740774367583, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1144927.647313752, 1144927.647313753, 229510.9859520065], 
processed observation next is [1.0, 0.4782608695652174, 0.6555555555555556, 0.3833333333333334, 1.0, 1.0, 0.37056437790090274, 1.0, 1.0, 0.37056437790090274, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.40890273118348286, 0.4089027311834832, 0.4413672806769356], 
reward next is 0.5586, 
noisyNet noise sample is [array([-0.12748937], dtype=float32), 0.48757252]. 
=============================================
[2019-04-27 18:23:04,057] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3191320e-11 1.6066642e-06 1.5384117e-14 9.9999821e-01 2.1143859e-07], sum to 1.0000
[2019-04-27 18:23:04,068] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5489
[2019-04-27 18:23:04,073] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.1, 37.0, 1.0, 2.0, 0.573506926752879, 1.0, 2.0, 0.573506926752879, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1371821.359486189, 1371821.35948619, 261862.4165032555], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2383200.0000, 
sim time next is 2383800.0000, 
raw observation next is [31.08333333333334, 37.0, 1.0, 2.0, 0.5819258692295515, 1.0, 2.0, 0.5819258692295515, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1391218.878620255, 1391218.878620255, 264712.1408875854], 
processed observation next is [1.0, 0.6086956521739131, 0.7067901234567904, 0.37, 1.0, 1.0, 0.5022927014637517, 1.0, 1.0, 0.5022927014637517, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.49686388522151964, 0.49686388522151964, 0.5090618093992028], 
reward next is 0.4909, 
noisyNet noise sample is [array([-0.866363], dtype=float32), 1.3508927]. 
=============================================
[2019-04-27 18:23:14,279] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.0608605e-09 8.0440870e-05 3.0964158e-11 9.9991596e-01 3.6342130e-06], sum to 1.0000
[2019-04-27 18:23:14,290] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9610
[2019-04-27 18:23:14,295] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.03333333333333, 43.66666666666666, 1.0, 2.0, 0.2456855654285995, 1.0, 2.0, 0.2456855654285995, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 580876.0729309216, 580876.072930922, 168945.932033655], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2572800.0000, 
sim time next is 2573400.0000, 
raw observation next is [30.76666666666667, 44.83333333333334, 1.0, 2.0, 0.2476586736368008, 1.0, 2.0, 0.2476586736368008, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 585242.0924779715, 585242.0924779715, 169375.8287428032], 
processed observation next is [1.0, 0.782608695652174, 0.6950617283950619, 0.4483333333333334, 1.0, 1.0, 0.10435556385333429, 1.0, 1.0, 0.10435556385333429, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20901503302784694, 0.20901503302784694, 0.32572274758231384], 
reward next is 0.6743, 
noisyNet noise sample is [array([-1.4857681], dtype=float32), -0.3070752]. 
=============================================
[2019-04-27 18:23:25,474] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.0377020e-10 4.0322182e-05 9.1466229e-14 9.9995959e-01 1.1403749e-07], sum to 1.0000
[2019-04-27 18:23:25,481] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7169
[2019-04-27 18:23:25,485] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.75, 86.5, 1.0, 2.0, 0.3277908428769483, 1.0, 2.0, 0.3277908428769483, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 747152.9917088102, 747152.9917088107, 187263.5556531338], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2759400.0000, 
sim time next is 2760000.0000, 
raw observation next is [25.66666666666667, 87.33333333333333, 1.0, 2.0, 0.3282688407925297, 1.0, 2.0, 0.3282688407925297, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 748243.0523033865, 748243.0523033865, 187382.923933375], 
processed observation next is [0.0, 0.9565217391304348, 0.506172839506173, 0.8733333333333333, 1.0, 1.0, 0.20032004856253538, 1.0, 1.0, 0.20032004856253538, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26722966153692373, 0.26722966153692373, 0.3603517767949519], 
reward next is 0.6396, 
noisyNet noise sample is [array([1.4191383], dtype=float32), 0.6421714]. 
=============================================
[2019-04-27 18:23:25,503] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[58.44707 ]
 [58.5057  ]
 [58.57394 ]
 [58.608097]
 [58.62511 ]], R is [[58.44403076]
 [58.49946976]
 [58.55513763]
 [58.61201859]
 [58.66667557]].
[2019-04-27 18:23:31,435] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.1591123e-12 1.3900381e-05 2.6550504e-17 9.9998224e-01 3.8374415e-06], sum to 1.0000
[2019-04-27 18:23:31,447] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9414
[2019-04-27 18:23:31,453] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.13333333333334, 93.33333333333334, 1.0, 2.0, 0.2901029731030326, 1.0, 2.0, 0.2901029731030326, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 688030.6495149565, 688030.6495149565, 179330.6673182531], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2877000.0000, 
sim time next is 2877600.0000, 
raw observation next is [22.26666666666667, 92.66666666666667, 1.0, 2.0, 0.285435183999411, 1.0, 2.0, 0.285435183999411, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 676104.622080692, 676104.6220806924, 178180.0187684657], 
processed observation next is [1.0, 0.30434782608695654, 0.38024691358024704, 0.9266666666666667, 1.0, 1.0, 0.1493275999992988, 1.0, 1.0, 0.1493275999992988, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24146593645738998, 0.24146593645739015, 0.3426538822470494], 
reward next is 0.6573, 
noisyNet noise sample is [array([-2.679133], dtype=float32), 0.15722738]. 
=============================================
[2019-04-27 18:23:38,562] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.5867117e-11 1.5111214e-05 8.5427806e-17 9.9998415e-01 7.3138273e-07], sum to 1.0000
[2019-04-27 18:23:38,574] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4226
[2019-04-27 18:23:38,578] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.83333333333333, 95.0, 1.0, 2.0, 0.3019450611687849, 1.0, 2.0, 0.3019450611687849, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 689189.4835624414, 689189.4835624419, 180977.0160404787], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3027000.0000, 
sim time next is 3027600.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.3037359950053843, 1.0, 2.0, 0.3037359950053843, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 692646.7188702509, 692646.7188702513, 181377.0260437542], 
processed observation next is [1.0, 0.043478260869565216, 0.4444444444444444, 0.94, 1.0, 1.0, 0.17111427976831461, 1.0, 1.0, 0.17111427976831461, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24737382816794673, 0.2473738281679469, 0.34880197316106576], 
reward next is 0.6512, 
noisyNet noise sample is [array([1.1132104], dtype=float32), 0.7642351]. 
=============================================
[2019-04-27 18:23:41,769] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.2792507e-07 2.7649431e-04 1.4488746e-10 9.9931729e-01 4.0572361e-04], sum to 1.0000
[2019-04-27 18:23:41,780] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3611
[2019-04-27 18:23:41,786] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.33333333333334, 77.0, 1.0, 2.0, 0.9420459784040724, 1.0, 2.0, 0.9420459784040724, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260424659847, 2149111.731284839, 2149111.731284839, 405948.0848337004], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3064800.0000, 
sim time next is 3065400.0000, 
raw observation next is [30.5, 77.5, 1.0, 2.0, 1.007384000177577, 1.0, 2.0, 1.007384000177577, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156162, 2298360.763313269, 2298360.76331327, 436902.7404182603], 
processed observation next is [1.0, 0.4782608695652174, 0.6851851851851852, 0.775, 1.0, 1.0, 1.0087904764018774, 1.0, 1.0, 1.0087904764018774, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288198331, 0.8208431297547388, 0.8208431297547394, 0.8401975777274237], 
reward next is 0.1598, 
noisyNet noise sample is [array([-0.0868278], dtype=float32), -0.02397922]. 
=============================================
[2019-04-27 18:23:43,869] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.7283351e-10 1.4836623e-05 2.3172379e-19 2.9902984e-03 9.9699485e-01], sum to 1.0000
[2019-04-27 18:23:43,880] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5526
[2019-04-27 18:23:43,885] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.0, 58.0, 1.0, 2.0, 0.1916425554942623, 1.0, 2.0, 0.1916425554942623, 1.0, 2.0, 0.3052270177641132, 6.911200000000001, 6.9112, 121.94756008, 659321.4168513156, 659321.4168513152, 217892.5398833996], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3103200.0000, 
sim time next is 3103800.0000, 
raw observation next is [28.91666666666667, 58.83333333333334, 1.0, 2.0, 0.1908896204022313, 1.0, 2.0, 0.1908896204022313, 1.0, 2.0, 0.3040366902336372, 6.911199999999999, 6.9112, 121.94756008, 656940.2455604809, 656940.2455604813, 217650.0263648852], 
processed observation next is [1.0, 0.9565217391304348, 0.6265432098765434, 0.5883333333333334, 1.0, 1.0, 0.036773357621703945, 1.0, 1.0, 0.036773357621703945, 1.0, 1.0, 0.1300458627920465, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2346215162716003, 0.23462151627160047, 0.41855774300939463], 
reward next is 0.5814, 
noisyNet noise sample is [array([0.09086755], dtype=float32), -0.38918415]. 
=============================================
[2019-04-27 18:23:44,460] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.8045544e-08 5.5145903e-04 4.8017698e-14 7.2523844e-03 9.9219620e-01], sum to 1.0000
[2019-04-27 18:23:44,464] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7044
[2019-04-27 18:23:44,472] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.03333333333333, 56.66666666666667, 1.0, 2.0, 0.1915221922361919, 1.0, 2.0, 0.1915221922361919, 1.0, 2.0, 0.3081016180541604, 6.9112, 6.9112, 121.94756008, 684445.3313277843, 684445.3313277843, 217407.2373641664], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3134400.0000, 
sim time next is 3135000.0000, 
raw observation next is [27.01666666666667, 57.33333333333334, 1.0, 2.0, 0.1891580179169396, 1.0, 2.0, 0.1891580179169396, 1.0, 2.0, 0.3041523012968326, 6.9112, 6.9112, 121.94756008, 675286.9133909469, 675286.9133909469, 216671.897522634], 
processed observation next is [1.0, 0.2608695652173913, 0.5561728395061729, 0.5733333333333335, 1.0, 1.0, 0.03471192609159475, 1.0, 1.0, 0.03471192609159475, 1.0, 1.0, 0.1301903766210407, 0.0, 0.0, 0.8096049824067558, 0.2411738976396239, 0.2411738976396239, 0.4166767260050654], 
reward next is 0.5833, 
noisyNet noise sample is [array([-0.6513052], dtype=float32), 0.48567292]. 
=============================================
[2019-04-27 18:23:44,495] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[49.547947]
 [49.310394]
 [49.50543 ]
 [49.514248]
 [49.944077]], R is [[49.71937943]
 [49.80409622]
 [49.87976074]
 [49.95751953]
 [50.03396606]].
[2019-04-27 18:23:47,600] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.7118442e-07 1.5796730e-03 9.6990809e-12 6.7395135e-04 9.9774593e-01], sum to 1.0000
[2019-04-27 18:23:47,607] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9235
[2019-04-27 18:23:47,611] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [34.2, 32.66666666666666, 1.0, 2.0, 0.5051243735109804, 1.0, 2.0, 0.5051243735109804, 1.0, 2.0, 0.8041758938930972, 6.9112, 6.9112, 121.94756008, 1728194.475024172, 1728194.475024172, 346111.8419751817], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3159600.0000, 
sim time next is 3160200.0000, 
raw observation next is [34.25, 31.83333333333334, 1.0, 2.0, 0.4997775808171142, 1.0, 2.0, 0.4997775808171142, 1.0, 2.0, 0.7958077521242165, 6.911200000000001, 6.9112, 121.94756008, 1715560.305304188, 1715560.305304187, 343520.7494386555], 
processed observation next is [1.0, 0.5652173913043478, 0.8240740740740741, 0.3183333333333334, 1.0, 1.0, 0.404497120020374, 1.0, 1.0, 0.404497120020374, 1.0, 1.0, 0.7447596901552705, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6127001090372101, 0.6127001090372096, 0.6606168258435683], 
reward next is 0.3394, 
noisyNet noise sample is [array([0.92176837], dtype=float32), 0.03808548]. 
=============================================
[2019-04-27 18:23:48,037] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.6121218e-07 7.2328455e-04 5.6480865e-14 8.1729481e-04 9.9845886e-01], sum to 1.0000
[2019-04-27 18:23:48,044] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6017
[2019-04-27 18:23:48,050] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [34.0, 32.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2518771183045846, 6.9112, 6.9112, 121.94756008, 556985.6586024091, 556985.6586024091, 206300.5624835693], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3175200.0000, 
sim time next is 3175800.0000, 
raw observation next is [33.83333333333334, 33.0, 1.0, 2.0, 0.1605917396486212, 1.0, 2.0, 0.1605917396486212, 1.0, 2.0, 0.2573798188972927, 6.911200000000001, 6.9112, 121.94756008, 568674.0904751812, 568674.0904751808, 207897.0719271723], 
processed observation next is [1.0, 0.782608695652174, 0.8086419753086423, 0.33, 1.0, 1.0, 0.0007044519626442766, 1.0, 1.0, 0.0007044519626442766, 1.0, 1.0, 0.07172477362161589, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.20309788945542187, 0.2030978894554217, 0.3998020613984083], 
reward next is 0.6002, 
noisyNet noise sample is [array([0.6834157], dtype=float32), -2.5532641]. 
=============================================
[2019-04-27 18:23:54,817] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.3039175e-10 4.7831600e-06 9.6035100e-17 3.0563959e-05 9.9996459e-01], sum to 1.0000
[2019-04-27 18:23:54,827] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0607
[2019-04-27 18:23:54,833] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.75, 93.16666666666666, 1.0, 2.0, 0.1629782647608919, 1.0, 2.0, 0.1629782647608919, 1.0, 2.0, 0.2618560734544919, 6.9112, 6.9112, 121.94756008, 580782.0681112402, 580782.0681112402, 208499.3936350262], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3300600.0000, 
sim time next is 3301200.0000, 
raw observation next is [21.7, 93.0, 1.0, 2.0, 0.1618332094727797, 1.0, 2.0, 0.1618332094727797, 1.0, 2.0, 0.2601690945045945, 6.911199999999999, 6.9112, 121.94756008, 577470.5691277861, 577470.5691277866, 208118.4928784749], 
processed observation next is [0.0, 0.21739130434782608, 0.3592592592592592, 0.93, 1.0, 1.0, 0.0021823922294996506, 1.0, 1.0, 0.0021823922294996506, 1.0, 1.0, 0.07521136813074314, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.20623948897420932, 0.2062394889742095, 0.40022787092014406], 
reward next is 0.5998, 
noisyNet noise sample is [array([0.1511109], dtype=float32), 1.320733]. 
=============================================
[2019-04-27 18:23:54,914] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-04-27 18:23:54,916] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 18:23:54,916] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 18:23:54,916] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:23:54,917] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:23:54,918] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 18:23:54,917] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 18:23:54,919] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 18:23:54,923] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:23:54,925] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:23:54,923] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:23:54,940] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run13
[2019-04-27 18:23:54,940] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run13
[2019-04-27 18:23:54,940] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run13
[2019-04-27 18:23:54,960] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run13
[2019-04-27 18:23:55,024] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run13
[2019-04-27 18:24:00,367] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.048693888]
[2019-04-27 18:24:00,370] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.46666666666667, 21.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2019813257789105, 6.911199999999999, 6.9112, 121.94756008, 447405.9691383262, 447405.9691383266, 184409.7746612634]
[2019-04-27 18:24:00,370] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 18:24:00,373] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.2128166e-09 1.1459417e-05 8.2616317e-16 5.6459528e-05 9.9993205e-01], sampled 0.9680674210302626
[2019-04-27 18:24:15,376] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.048693888]
[2019-04-27 18:24:15,379] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [31.2, 37.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2415752675249808, 6.9112, 6.9112, 121.94756008, 539105.7612064626, 539105.7612064626, 202180.8453741938]
[2019-04-27 18:24:15,380] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 18:24:15,385] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.7185550e-09 1.3877405e-05 1.6587261e-15 7.4074575e-05 9.9991202e-01], sampled 0.6577567998886286
[2019-04-27 18:24:20,827] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.048693888]
[2019-04-27 18:24:20,827] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.2, 87.00000000000001, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2480836827088369, 6.9112, 6.9112, 121.94756008, 556098.3069740843, 556098.3069740843, 201480.8520177279]
[2019-04-27 18:24:20,828] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 18:24:20,831] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.3415834e-09 1.5529838e-05 2.4671194e-15 6.6601446e-05 9.9991786e-01], sampled 0.01694317752912955
[2019-04-27 18:25:19,697] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.048693888]
[2019-04-27 18:25:19,701] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.99805609166667, 85.72760340166667, 1.0, 2.0, 0.1872451257459523, 1.0, 2.0, 0.1872451257459523, 1.0, 2.0, 0.2984832949956132, 6.9112, 6.9112, 121.94756008, 648912.3319846202, 648912.3319846202, 216463.7369235637]
[2019-04-27 18:25:19,702] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 18:25:19,706] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0659196e-09 1.0501812e-05 7.7974296e-16 5.8390517e-05 9.9993110e-01], sampled 0.0986495900793618
[2019-04-27 18:25:25,617] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.048693888]
[2019-04-27 18:25:25,619] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.0, 94.00000000000001, 1.0, 2.0, 0.1811425160316848, 1.0, 2.0, 0.1811425160316848, 1.0, 2.0, 0.2888242501966359, 6.9112, 6.9112, 121.94756008, 628716.9277873273, 628716.9277873273, 214514.9762599702]
[2019-04-27 18:25:25,620] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 18:25:25,624] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0311647e-09 1.0067018e-05 7.2627421e-16 5.8092290e-05 9.9993181e-01], sampled 0.5222408933070065
[2019-04-27 18:25:39,601] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.048693888]
[2019-04-27 18:25:39,602] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.13333333333333, 56.0, 1.0, 2.0, 0.1625412235759622, 1.0, 2.0, 0.1625412235759622, 1.0, 2.0, 0.2641119261652378, 6.9112, 6.9112, 121.94756008, 590862.7450249556, 590862.7450249556, 207766.2053474063]
[2019-04-27 18:25:39,602] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 18:25:39,604] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.2757007e-09 1.5695578e-05 2.4380475e-15 7.1616829e-05 9.9991262e-01], sampled 0.5377577984384185
[2019-04-27 18:25:41,292] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 4609.9101 2894508116.6154 12.0000
[2019-04-27 18:25:41,697] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 4489.5053 2940613033.4583 28.0000
[2019-04-27 18:25:41,961] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 4512.2738 3107489099.0183 0.0000
[2019-04-27 18:25:42,001] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 4392.9227 2875851121.3645 8.0000
[2019-04-27 18:25:42,080] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 4276.5235 2919915727.9422 33.0000
[2019-04-27 18:25:43,095] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 300000, evaluation results [300000.0, 4512.273842737323, 3107489099.0183177, 0.0, 4609.910050545777, 2894508116.6154127, 12.0, 4392.922679884325, 2875851121.364467, 8.0, 4489.505317925441, 2940613033.4583435, 28.0, 4276.523525893009, 2919915727.942232, 33.0]
[2019-04-27 18:25:51,217] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.0854642e-09 8.0347709e-06 3.9678605e-14 5.7505462e-05 9.9993443e-01], sum to 1.0000
[2019-04-27 18:25:51,225] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6258
[2019-04-27 18:25:51,231] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.9, 78.0, 1.0, 2.0, 0.2178488812477594, 1.0, 2.0, 0.2178488812477594, 1.0, 2.0, 0.3468225137891786, 6.911200000000001, 6.9112, 121.94756008, 744832.5054273864, 744832.5054273859, 226513.7988248316], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3441600.0000, 
sim time next is 3442200.0000, 
raw observation next is [26.75, 79.83333333333333, 1.0, 2.0, 0.2185158907184759, 1.0, 2.0, 0.2185158907184759, 1.0, 2.0, 0.3478844145895411, 6.9112, 6.9112, 121.94756008, 747114.1439735664, 747114.1439735664, 226738.4508804609], 
processed observation next is [1.0, 0.8695652173913043, 0.5462962962962963, 0.7983333333333333, 1.0, 1.0, 0.06966177466485227, 1.0, 1.0, 0.06966177466485227, 1.0, 1.0, 0.18485551823692636, 0.0, 0.0, 0.8096049824067558, 0.2668264799905594, 0.2668264799905594, 0.4360354824624248], 
reward next is 0.5640, 
noisyNet noise sample is [array([0.26966152], dtype=float32), 0.22129603]. 
=============================================
[2019-04-27 18:25:55,038] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.0588035e-08 6.2798322e-06 8.2283480e-13 3.3466273e-05 9.9996018e-01], sum to 1.0000
[2019-04-27 18:25:55,047] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8255
[2019-04-27 18:25:55,050] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.66666666666667, 87.33333333333334, 1.0, 2.0, 0.5901658939526997, 1.0, 2.0, 0.5901658939526997, 1.0, 2.0, 0.9395633235340207, 6.9112, 6.9112, 121.94756008, 2019392.163291074, 2019392.163291074, 390043.5047667309], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3511200.0000, 
sim time next is 3511800.0000, 
raw observation next is [27.5, 86.5, 1.0, 2.0, 0.5885190167380734, 1.0, 2.0, 0.5885190167380734, 1.0, 2.0, 0.9369414413732892, 6.911200000000001, 6.9112, 121.94756008, 2013750.630882282, 2013750.630882281, 389155.6542978973], 
processed observation next is [1.0, 0.6521739130434783, 0.5740740740740741, 0.865, 1.0, 1.0, 0.5101416865929445, 1.0, 1.0, 0.5101416865929445, 1.0, 1.0, 0.9211768017166113, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7191966538865293, 0.719196653886529, 0.7483762582651872], 
reward next is 0.2516, 
noisyNet noise sample is [array([-0.85054505], dtype=float32), 1.352943]. 
=============================================
[2019-04-27 18:25:55,573] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.2814628e-09 3.3729465e-04 2.0664358e-13 1.9482229e-04 9.9946791e-01], sum to 1.0000
[2019-04-27 18:25:55,581] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4122
[2019-04-27 18:25:55,584] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.7, 86.66666666666666, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.256276682187219, 6.9112, 6.9112, 121.94756008, 568562.6771624411, 568562.6771624411, 207325.9773905446], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3541200.0000, 
sim time next is 3541800.0000, 
raw observation next is [22.85, 87.83333333333334, 1.0, 2.0, 0.1637342810974422, 1.0, 2.0, 0.1637342810974422, 1.0, 2.0, 0.2625235784649548, 6.911199999999999, 6.9112, 121.94756008, 580455.9396425617, 580455.9396425622, 208837.7812973228], 
processed observation next is [1.0, 1.0, 0.4018518518518519, 0.8783333333333334, 1.0, 1.0, 0.004445572735050237, 1.0, 1.0, 0.004445572735050237, 1.0, 1.0, 0.07815447308119346, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.20730569272948632, 0.20730569272948648, 0.4016111178794669], 
reward next is 0.5984, 
noisyNet noise sample is [array([0.0388248], dtype=float32), 0.13066]. 
=============================================
[2019-04-27 18:25:56,694] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.4113358e-09 2.1288133e-06 3.7167999e-16 8.1212129e-06 9.9998975e-01], sum to 1.0000
[2019-04-27 18:25:56,703] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7990
[2019-04-27 18:25:56,713] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.55, 80.5, 1.0, 2.0, 0.187182904635419, 1.0, 2.0, 0.187182904635419, 1.0, 2.0, 0.2984392142412478, 6.9112, 6.9112, 121.94756008, 649472.329045368, 649472.329045368, 216438.1160696583], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3537000.0000, 
sim time next is 3537600.0000, 
raw observation next is [23.73333333333333, 81.0, 1.0, 2.0, 0.174768661418558, 1.0, 2.0, 0.174768661418558, 1.0, 2.0, 0.2795691913451192, 6.911200000000001, 6.9112, 121.94756008, 615312.076403163, 615312.0764031626, 212370.775219143], 
processed observation next is [1.0, 0.9565217391304348, 0.4345679012345678, 0.81, 1.0, 1.0, 0.017581739783997633, 1.0, 1.0, 0.017581739783997633, 1.0, 1.0, 0.099461489181399, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.21975431300112966, 0.2197543130011295, 0.40840533695989034], 
reward next is 0.5916, 
noisyNet noise sample is [array([-1.1769551], dtype=float32), 0.6622579]. 
=============================================
[2019-04-27 18:26:01,950] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.4461449e-09 7.7174103e-05 1.7324248e-13 9.3828450e-05 9.9982893e-01], sum to 1.0000
[2019-04-27 18:26:01,959] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1606
[2019-04-27 18:26:01,966] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.0, 100.0, 1.0, 2.0, 0.2094695108309406, 1.0, 2.0, 0.2094695108309406, 1.0, 2.0, 0.3334822831885604, 6.911199999999999, 6.9112, 121.94756008, 716169.7809124913, 716169.7809124917, 223712.7914641154], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3639600.0000, 
sim time next is 3640200.0000, 
raw observation next is [23.0, 99.00000000000001, 1.0, 2.0, 0.2099241812912709, 1.0, 2.0, 0.2099241812912709, 1.0, 2.0, 0.3342061333689892, 6.911200000000001, 6.9112, 121.94756008, 717725.0127638967, 717725.0127638963, 223863.7679722698], 
processed observation next is [1.0, 0.13043478260869565, 0.4074074074074074, 0.9900000000000001, 1.0, 1.0, 0.05943354915627489, 1.0, 1.0, 0.05943354915627489, 1.0, 1.0, 0.16775766671123646, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2563303617013917, 0.2563303617013915, 0.4305072461005188], 
reward next is 0.5695, 
noisyNet noise sample is [array([-1.1397321], dtype=float32), -0.56744444]. 
=============================================
[2019-04-27 18:26:05,961] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.0387618e-09 4.6663623e-05 2.8192501e-14 1.4596834e-04 9.9980742e-01], sum to 1.0000
[2019-04-27 18:26:05,968] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0638
[2019-04-27 18:26:05,973] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.0, 100.0, 1.0, 2.0, 0.2330341042158083, 1.0, 2.0, 0.2330341042158083, 1.0, 2.0, 0.3709978833024982, 6.911199999999999, 6.9112, 121.94756008, 796778.263053562, 796778.2630535625, 231689.9071221697], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3736800.0000, 
sim time next is 3737400.0000, 
raw observation next is [24.0, 100.0, 1.0, 2.0, 0.2576117093080449, 1.0, 2.0, 0.2576117093080449, 1.0, 2.0, 0.4101262310460553, 6.911199999999999, 6.9112, 121.94756008, 880861.0318744272, 880861.0318744277, 240340.6673401257], 
processed observation next is [1.0, 0.2608695652173913, 0.4444444444444444, 1.0, 1.0, 1.0, 0.11620441584291058, 1.0, 1.0, 0.11620441584291058, 1.0, 1.0, 0.26265778880756907, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.3145932256694383, 0.3145932256694385, 0.4621935910387033], 
reward next is 0.5378, 
noisyNet noise sample is [array([1.19464], dtype=float32), 0.23575799]. 
=============================================
[2019-04-27 18:26:15,467] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.7877481e-08 1.1968384e-04 6.0206397e-13 1.8555904e-04 9.9969471e-01], sum to 1.0000
[2019-04-27 18:26:15,473] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5004
[2019-04-27 18:26:15,478] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.95, 68.0, 1.0, 2.0, 0.2614996633327243, 1.0, 2.0, 0.2614996633327243, 1.0, 2.0, 0.4163159804751677, 6.9112, 6.9112, 121.94756008, 894163.0075811453, 894163.0075811453, 241740.0471739228], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3871800.0000, 
sim time next is 3872400.0000, 
raw observation next is [30.6, 68.33333333333334, 1.0, 2.0, 0.2590633587755685, 1.0, 2.0, 0.2590633587755685, 1.0, 2.0, 0.4124373042752754, 6.9112, 6.9112, 121.94756008, 885827.5774764369, 885827.5774764369, 240862.1679725575], 
processed observation next is [0.0, 0.8260869565217391, 0.688888888888889, 0.6833333333333335, 1.0, 1.0, 0.1179325699709149, 1.0, 1.0, 0.1179325699709149, 1.0, 1.0, 0.26554663034409426, 0.0, 0.0, 0.8096049824067558, 0.3163669919558703, 0.3163669919558703, 0.4631964768703029], 
reward next is 0.5368, 
noisyNet noise sample is [array([-0.7368834], dtype=float32), 0.15255742]. 
=============================================
[2019-04-27 18:26:16,762] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.9673021e-07 8.2863968e-05 2.7514208e-12 3.4370244e-04 9.9957329e-01], sum to 1.0000
[2019-04-27 18:26:16,771] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6098
[2019-04-27 18:26:16,779] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 91.0, 1.0, 2.0, 0.2394146732601513, 1.0, 2.0, 0.2394146732601513, 1.0, 2.0, 0.3811559570217187, 6.911199999999999, 6.9112, 121.94756008, 818606.0255984967, 818606.0255984971, 233903.2854684789], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3895200.0000, 
sim time next is 3895800.0000, 
raw observation next is [26.16666666666667, 90.66666666666667, 1.0, 2.0, 0.2399317314299507, 1.0, 2.0, 0.2399317314299507, 1.0, 2.0, 0.3819791304674482, 6.9112, 6.9112, 121.94756008, 820374.8955182543, 820374.8955182543, 234083.6462838673], 
processed observation next is [0.0, 0.08695652173913043, 0.5246913580246916, 0.9066666666666667, 1.0, 1.0, 0.09515682313089369, 1.0, 1.0, 0.09515682313089369, 1.0, 1.0, 0.22747391308431023, 0.0, 0.0, 0.8096049824067558, 0.29299103411366223, 0.29299103411366223, 0.45016085823820634], 
reward next is 0.5498, 
noisyNet noise sample is [array([0.49664748], dtype=float32), -1.3505838]. 
=============================================
[2019-04-27 18:26:23,038] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.5801486e-07 5.4479326e-05 8.5699572e-11 2.2437058e-04 9.9972028e-01], sum to 1.0000
[2019-04-27 18:26:23,048] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5747
[2019-04-27 18:26:23,051] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.8, 94.0, 1.0, 2.0, 0.4745213441010424, 1.0, 2.0, 0.4745213441010424, 1.0, 2.0, 0.7554534338901312, 6.911199999999999, 6.9112, 121.94756008, 1623327.472210884, 1623327.472210884, 331259.9220532357], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4008600.0000, 
sim time next is 4009200.0000, 
raw observation next is [24.86666666666667, 94.0, 1.0, 2.0, 0.5012194421995748, 1.0, 2.0, 0.5012194421995748, 1.0, 2.0, 0.7979576755593473, 6.911200000000001, 6.9112, 121.94756008, 1714748.739895995, 1714748.739895994, 344187.9574359162], 
processed observation next is [1.0, 0.391304347826087, 0.47654320987654336, 0.94, 1.0, 1.0, 0.4062136216661605, 1.0, 1.0, 0.4062136216661605, 1.0, 1.0, 0.747447094449184, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6124102642485696, 0.6124102642485693, 0.6618999181459927], 
reward next is 0.3381, 
noisyNet noise sample is [array([0.0582925], dtype=float32), 0.5334729]. 
=============================================
[2019-04-27 18:26:25,236] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.43172518e-10 1.21194091e-06 1.03895604e-13 8.59974898e-06
 9.99990225e-01], sum to 1.0000
[2019-04-27 18:26:25,244] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7550
[2019-04-27 18:26:25,248] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.1734662181111364, 1.0, 2.0, 0.1734662181111364, 1.0, 2.0, 0.2810086738325633, 6.9112, 6.9112, 121.94756008, 627779.3154185421, 627779.3154185421, 211304.9474939304], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4073400.0000, 
sim time next is 4074000.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.1649591742286764, 1.0, 2.0, 0.1649591742286764, 1.0, 2.0, 0.2673102641331181, 6.911199999999999, 6.9112, 121.94756008, 597265.4162893505, 597265.416289351, 208654.1618501203], 
processed observation next is [1.0, 0.13043478260869565, 0.2962962962962963, 1.0, 1.0, 1.0, 0.005903778843662374, 1.0, 1.0, 0.005903778843662374, 1.0, 1.0, 0.0841378301663976, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2133090772461966, 0.21330907724619677, 0.4012580035579236], 
reward next is 0.5987, 
noisyNet noise sample is [array([-0.50793], dtype=float32), 0.53840685]. 
=============================================
[2019-04-27 18:26:25,263] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[51.76284 ]
 [51.87781 ]
 [51.952106]
 [52.297245]
 [52.353638]], R is [[51.74485779]
 [51.82105255]
 [51.89521408]
 [51.95556641]
 [51.43601227]].
[2019-04-27 18:26:29,993] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.4018371e-02 1.8528540e-01 1.1618789e-04 1.0349638e-02 7.9023033e-01], sum to 1.0000
[2019-04-27 18:26:30,001] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7498
[2019-04-27 18:26:30,004] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.35, 92.0, 1.0, 2.0, 0.4528189390435656, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 550016.1338739244, 550016.1338739244, 136012.2352449724], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4134600.0000, 
sim time next is 4135200.0000, 
raw observation next is [21.56666666666667, 90.66666666666666, 1.0, 2.0, 0.16, 1.0, 1.0, 0.16, 1.0, 1.0, 0.2481072671148588, 6.9112, 6.9112, 121.94756008, 553614.6614042369, 553614.6614042369, 204127.674641187], 
processed observation next is [1.0, 0.8695652173913043, 0.35432098765432113, 0.9066666666666666, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.5, 0.0601340838935735, 0.0, 0.0, 0.8096049824067558, 0.1977195219300846, 0.1977195219300846, 0.3925532204638212], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.36447728], dtype=float32), -1.0860208]. 
=============================================
[2019-04-27 18:26:34,589] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.6465617e-16 1.0000000e+00 3.9480792e-24 2.9511299e-14 6.3960254e-11], sum to 1.0000
[2019-04-27 18:26:34,598] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4284
[2019-04-27 18:26:34,602] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.6, 70.66666666666667, 1.0, 2.0, 0.7714960176512794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 948577.5364146794, 948577.5364146794, 193024.0122256595], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4242000.0000, 
sim time next is 4242600.0000, 
raw observation next is [23.2, 72.5, 1.0, 2.0, 0.6798872608837635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 837406.283050732, 837406.283050732, 174884.6415126255], 
processed observation next is [1.0, 0.08695652173913043, 0.4148148148148148, 0.725, 1.0, 1.0, 0.6189134058140041, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29907367251811856, 0.29907367251811856, 0.33631661829351056], 
reward next is 0.6637, 
noisyNet noise sample is [array([0.69031644], dtype=float32), -1.0916193]. 
=============================================
[2019-04-27 18:26:35,280] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-04-27 18:26:35,290] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 18:26:35,291] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 18:26:35,292] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:26:35,292] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:26:35,294] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 18:26:35,294] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:26:35,295] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 18:26:35,295] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:26:35,296] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 18:26:35,297] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:26:35,315] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run14
[2019-04-27 18:26:35,315] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run14
[2019-04-27 18:26:35,316] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run14
[2019-04-27 18:26:35,337] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run14
[2019-04-27 18:26:35,337] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run14
[2019-04-27 18:26:59,205] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.051029515]
[2019-04-27 18:26:59,207] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.67320974, 66.96244807, 1.0, 2.0, 0.9553462987569584, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.091622239549903, 6.9112, 121.9250981589112, 1222610.887847543, 1130219.290925419, 232260.0413623304]
[2019-04-27 18:26:59,207] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 18:26:59,208] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.3195074e-10 9.9999988e-01 2.7870858e-17 1.0509466e-09 1.3634065e-07], sampled 0.9052030883548365
[2019-04-27 18:27:03,944] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.051029515]
[2019-04-27 18:27:03,945] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.328010785, 80.353756245, 1.0, 2.0, 0.6644093064375446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 757218.6190631406, 757218.6190631406, 169516.3186200328]
[2019-04-27 18:27:03,947] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 18:27:03,948] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.1434179e-11 1.0000000e+00 1.3305665e-18 2.1158993e-10 3.9467412e-08], sampled 0.3966092734500861
[2019-04-27 18:27:06,100] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.051029515]
[2019-04-27 18:27:06,102] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.64966099, 78.98317382, 1.0, 2.0, 0.4637056732729951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 560703.7406959812, 560703.7406959812, 137572.770330912]
[2019-04-27 18:27:06,103] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 18:27:06,105] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.6693080e-11 1.0000000e+00 1.9143429e-18 2.5548821e-10 4.4904411e-08], sampled 0.9312869512223966
[2019-04-27 18:27:16,675] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.051029515]
[2019-04-27 18:27:16,678] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [33.104359595, 44.726414415, 1.0, 2.0, 0.7244960198095154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 832964.2448316817, 832964.2448316817, 181197.8626321035]
[2019-04-27 18:27:16,679] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 18:27:16,681] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.0862556e-11 9.9999988e-01 4.7273016e-18 4.3836634e-10 6.4874826e-08], sampled 0.2694887607794332
[2019-04-27 18:27:22,735] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.051029515]
[2019-04-27 18:27:22,736] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [33.25, 67.83333333333334, 1.0, 2.0, 0.9265935013371398, 1.0, 2.0, 0.9265935013371398, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2113817.903071309, 2113817.903071309, 398844.7302898804]
[2019-04-27 18:27:22,737] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 18:27:22,739] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0721750e-10 9.9999988e-01 1.3698482e-17 5.2877885e-10 1.1854498e-07], sampled 0.6635307399436914
[2019-04-27 18:27:22,740] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2113817.903071309 W.
[2019-04-27 18:27:29,002] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.051029515]
[2019-04-27 18:27:29,004] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.27541986833333, 106.0500924333333, 1.0, 2.0, 0.4546389926427103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 555706.5233535459, 555706.5233535459, 136388.518077909]
[2019-04-27 18:27:29,004] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 18:27:29,006] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.3119330e-11 1.0000000e+00 8.2883182e-19 2.0792965e-10 3.0996766e-08], sampled 0.5502846303091595
[2019-04-27 18:27:32,798] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.051029515]
[2019-04-27 18:27:32,800] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.05979753333333, 76.78694525, 1.0, 2.0, 0.55023714664563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 643228.1869772333, 643228.1869772333, 150485.5805785409]
[2019-04-27 18:27:32,802] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 18:27:32,806] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.0517458e-11 1.0000000e+00 1.6223778e-18 2.8979888e-10 4.2127667e-08], sampled 0.8416031056829797
[2019-04-27 18:28:22,015] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8700.1211 2195078910.3040 572.0000
[2019-04-27 18:28:22,062] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-04-27 18:28:22,074] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-04-27 18:28:22,464] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-04-27 18:28:22,510] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8099.9424 2445324199.3218 746.0000
[2019-04-27 18:28:23,526] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 325000, evaluation results [325000.0, 8099.942407935641, 2445324199.321786, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8700.12110735688, 2195078910.30397, 572.0]
[2019-04-27 18:28:27,256] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.9254459e-13 1.0000000e+00 4.0227347e-19 5.6190415e-13 4.9744248e-10], sum to 1.0000
[2019-04-27 18:28:27,262] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4033
[2019-04-27 18:28:27,264] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.7, 74.0, 1.0, 2.0, 0.5466418392760649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 644830.6159256656, 644830.6159256656, 150135.4261810262], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4316400.0000, 
sim time next is 4317000.0000, 
raw observation next is [25.75, 75.66666666666667, 1.0, 2.0, 0.5520562436333247, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 649187.8237337567, 649187.8237337563, 150947.2108553022], 
processed observation next is [1.0, 1.0, 0.5092592592592593, 0.7566666666666667, 1.0, 1.0, 0.4667336233730056, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23185279419062738, 0.23185279419062726, 0.2902830977986581], 
reward next is 0.7097, 
noisyNet noise sample is [array([-0.5858443], dtype=float32), -0.51206213]. 
=============================================
[2019-04-27 18:28:27,282] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[55.99276 ]
 [55.993797]
 [56.031296]
 [56.07082 ]
 [56.111927]], R is [[56.0665741 ]
 [56.21718597]
 [56.36315155]
 [56.50445557]
 [56.64105988]].
[2019-04-27 18:28:30,433] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.3886376e-08 9.9999893e-01 9.4788769e-12 1.3691113e-08 9.5388430e-07], sum to 1.0000
[2019-04-27 18:28:30,438] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0076
[2019-04-27 18:28:30,445] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1900225.743158706 W.
[2019-04-27 18:28:30,450] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.2, 76.83333333333334, 1.0, 2.0, 0.8330647403084727, 1.0, 1.0, 0.8330647403084727, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9257436622162, 1900225.743158706, 1900225.743158707, 357606.9490723975], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4356600.0000, 
sim time next is 4357200.0000, 
raw observation next is [28.4, 74.66666666666667, 1.0, 2.0, 0.5607183622367498, 1.0, 2.0, 0.5607183622367498, 1.0, 1.0, 0.8926818940030744, 6.9112, 6.9112, 121.94756008, 1918522.257934366, 1918522.257934366, 374388.7139870505], 
processed observation next is [1.0, 0.43478260869565216, 0.6074074074074074, 0.7466666666666667, 1.0, 1.0, 0.47704566932946396, 1.0, 1.0, 0.47704566932946396, 1.0, 0.5, 0.8658523675038429, 0.0, 0.0, 0.8096049824067558, 0.685186520690845, 0.685186520690845, 0.7199782961289433], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.23925251], dtype=float32), -1.6618179]. 
=============================================
[2019-04-27 18:28:36,902] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.47197561e-16 1.00000000e+00 1.08133016e-26 1.00120028e-19
 1.07277792e-15], sum to 1.0000
[2019-04-27 18:28:36,910] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5985
[2019-04-27 18:28:36,913] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.25, 70.0, 1.0, 2.0, 0.6916875109710893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 788323.2196592778, 788323.2196592778, 174576.7692202626], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4469400.0000, 
sim time next is 4470000.0000, 
raw observation next is [29.16666666666666, 71.33333333333333, 1.0, 2.0, 0.7014571361267586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 799463.5666081785, 799463.5666081785, 176420.873190995], 
processed observation next is [0.0, 0.7391304347826086, 0.6358024691358023, 0.7133333333333333, 1.0, 1.0, 0.6445918287223317, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2855227023600638, 0.2855227023600638, 0.33927090998268267], 
reward next is 0.6607, 
noisyNet noise sample is [array([0.7752564], dtype=float32), -0.8841758]. 
=============================================
[2019-04-27 18:28:36,928] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[70.550446]
 [70.52655 ]
 [70.45651 ]
 [70.39521 ]
 [70.2832  ]], R is [[70.53083801]
 [70.48980713]
 [70.45553589]
 [70.41981506]
 [70.38253021]].
[2019-04-27 18:28:39,612] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.6037718e-16 1.0000000e+00 6.1033192e-25 1.1143588e-17 1.1440759e-16], sum to 1.0000
[2019-04-27 18:28:39,622] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6417
[2019-04-27 18:28:39,626] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 100.0, 1.0, 2.0, 0.5888154923415688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 683354.0126905383, 683354.0126905383, 156753.2271978864], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4548600.0000, 
sim time next is 4549200.0000, 
raw observation next is [23.0, 100.0, 1.0, 2.0, 0.5879812101301338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 682387.5840007595, 682387.5840007595, 156610.570231823], 
processed observation next is [0.0, 0.6521739130434783, 0.4074074074074074, 1.0, 1.0, 1.0, 0.5095014406311117, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2437098514288427, 0.2437098514288427, 0.3011741735227365], 
reward next is 0.6988, 
noisyNet noise sample is [array([-0.00759376], dtype=float32), 0.7227829]. 
=============================================
[2019-04-27 18:28:41,998] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.8704523e-16 1.0000000e+00 1.3343340e-24 1.4377261e-17 3.1389651e-17], sum to 1.0000
[2019-04-27 18:28:42,009] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3105
[2019-04-27 18:28:42,014] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.98333333333333, 94.16666666666667, 1.0, 2.0, 0.6025265079406558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 695328.4178260459, 695328.4178260459, 158933.8152540889], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4557000.0000, 
sim time next is 4557600.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.6037350768225784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 696792.9484106915, 696792.9484106915, 159146.5496176367], 
processed observation next is [0.0, 0.782608695652174, 0.4444444444444444, 0.94, 1.0, 1.0, 0.5282560438364029, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24885462443238981, 0.24885462443238981, 0.30605105695699364], 
reward next is 0.6939, 
noisyNet noise sample is [array([0.03230236], dtype=float32), -1.680205]. 
=============================================
[2019-04-27 18:28:44,053] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0959295e-14 1.0000000e+00 1.2306280e-20 3.8016414e-17 8.4008958e-14], sum to 1.0000
[2019-04-27 18:28:44,063] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9527
[2019-04-27 18:28:44,070] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1415407.742047705 W.
[2019-04-27 18:28:44,074] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.66666666666666, 73.0, 1.0, 2.0, 0.4137980120482426, 1.0, 2.0, 0.4137980120482426, 1.0, 2.0, 0.6587799116412139, 6.911199999999999, 6.9112, 121.94756008, 1415407.742047705, 1415407.742047705, 303179.1706311749], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4621200.0000, 
sim time next is 4621800.0000, 
raw observation next is [27.83333333333334, 73.5, 1.0, 2.0, 0.657369020874413, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1464144.954156032, 1464144.954156033, 309653.5480291683], 
processed observation next is [1.0, 0.4782608695652174, 0.58641975308642, 0.735, 1.0, 1.0, 0.592105977231444, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5229089121985829, 0.5229089121985833, 0.5954875923637851], 
reward next is 0.4045, 
noisyNet noise sample is [array([1.455378], dtype=float32), -1.0608058]. 
=============================================
[2019-04-27 18:28:47,137] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.8244580e-17 1.0000000e+00 3.7472605e-24 9.5614462e-17 3.2608088e-17], sum to 1.0000
[2019-04-27 18:28:47,148] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5793
[2019-04-27 18:28:47,151] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 89.83333333333333, 1.0, 2.0, 0.6858576561409813, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 781675.4874460106, 781675.4874460106, 173482.3660140461], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4661400.0000, 
sim time next is 4662000.0000, 
raw observation next is [25.6, 89.0, 1.0, 2.0, 0.6742998717215981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 768496.4179262482, 768496.4179262482, 171333.7039570647], 
processed observation next is [1.0, 1.0, 0.5037037037037038, 0.89, 1.0, 1.0, 0.6122617520495215, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2744630064022315, 0.2744630064022315, 0.3294878922251244], 
reward next is 0.6705, 
noisyNet noise sample is [array([-0.49680886], dtype=float32), 0.123186156]. 
=============================================
[2019-04-27 18:28:47,159] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[58.62651 ]
 [58.616398]
 [58.63159 ]
 [58.642616]
 [58.69961 ]], R is [[58.7597847 ]
 [58.83856964]
 [58.91308594]
 [58.98365784]
 [59.0504837 ]].
[2019-04-27 18:28:47,656] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7794016e-18 1.0000000e+00 4.6491594e-29 9.3641603e-21 5.4787868e-19], sum to 1.0000
[2019-04-27 18:28:47,665] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8359
[2019-04-27 18:28:47,670] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 89.83333333333334, 1.0, 2.0, 0.6689259112879898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 762368.6945120457, 762368.6945120452, 170343.0084551845], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4662600.0000, 
sim time next is 4663200.0000, 
raw observation next is [25.4, 90.66666666666667, 1.0, 2.0, 0.6661350936927317, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 759186.4503031863, 759186.4503031863, 169830.5236998207], 
processed observation next is [1.0, 1.0, 0.49629629629629624, 0.9066666666666667, 1.0, 1.0, 0.6025417782056329, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2711380179654237, 0.2711380179654237, 0.3265971609611937], 
reward next is 0.6734, 
noisyNet noise sample is [array([-0.39169252], dtype=float32), -0.5831422]. 
=============================================
[2019-04-27 18:28:51,196] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.2333187e-17 1.0000000e+00 3.6813484e-24 1.0387719e-17 4.3377537e-17], sum to 1.0000
[2019-04-27 18:28:51,202] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0330
[2019-04-27 18:28:51,209] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.95, 87.83333333333334, 1.0, 2.0, 0.7242483268195306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 825453.092052763, 825453.092052763, 180787.7995839164], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4734600.0000, 
sim time next is 4735200.0000, 
raw observation next is [26.9, 86.66666666666667, 1.0, 2.0, 0.7160197971537601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 816069.7342145427, 816069.7342145427, 179200.3574048096], 
processed observation next is [1.0, 0.8260869565217391, 0.5518518518518518, 0.8666666666666667, 1.0, 1.0, 0.6619283299449524, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2914534765051938, 0.2914534765051938, 0.34461607193232613], 
reward next is 0.6554, 
noisyNet noise sample is [array([-0.5437395], dtype=float32), -0.8285268]. 
=============================================
[2019-04-27 18:28:51,672] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.1734075e-16 1.0000000e+00 1.3065206e-24 7.1290303e-17 2.1933340e-16], sum to 1.0000
[2019-04-27 18:28:51,684] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5922
[2019-04-27 18:28:51,690] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.13333333333333, 92.66666666666666, 1.0, 2.0, 0.5950374659599775, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 687299.306547072, 687299.306547072, 157670.3664961613], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4758000.0000, 
sim time next is 4758600.0000, 
raw observation next is [24.16666666666667, 92.33333333333333, 1.0, 2.0, 0.5938327677525224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 686058.1673202098, 686058.1673202098, 157470.3687214837], 
processed observation next is [1.0, 0.043478260869565216, 0.45061728395061745, 0.9233333333333333, 1.0, 1.0, 0.5164675806577647, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24502077404293207, 0.24502077404293207, 0.30282763215669944], 
reward next is 0.6972, 
noisyNet noise sample is [array([-0.33722416], dtype=float32), -0.5748189]. 
=============================================
[2019-04-27 18:28:52,638] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.1500597e-17 1.0000000e+00 2.7204555e-26 3.1280501e-18 1.2033875e-19], sum to 1.0000
[2019-04-27 18:28:52,644] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3520
[2019-04-27 18:28:52,650] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.25, 89.83333333333334, 1.0, 2.0, 0.6443598767222989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 734357.6001034108, 734357.6001034108, 165876.4429740248], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4749000.0000, 
sim time next is 4749600.0000, 
raw observation next is [25.2, 90.66666666666667, 1.0, 2.0, 0.6459193441137673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 736135.731643313, 736135.731643313, 166157.1038029476], 
processed observation next is [1.0, 1.0, 0.4888888888888889, 0.9066666666666667, 1.0, 1.0, 0.5784754096592467, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26290561844404037, 0.26290561844404037, 0.31953289192874534], 
reward next is 0.6805, 
noisyNet noise sample is [array([-1.8773395], dtype=float32), 0.21501274]. 
=============================================
[2019-04-27 18:28:56,326] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.0821594e-13 1.0000000e+00 9.7246124e-19 5.1225938e-12 1.5218516e-11], sum to 1.0000
[2019-04-27 18:28:56,333] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9824
[2019-04-27 18:28:56,346] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 93.16666666666666, 1.0, 2.0, 0.7142101887600325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 814006.1728010392, 814006.1728010392, 178853.1299363321], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4830600.0000, 
sim time next is 4831200.0000, 
raw observation next is [26.0, 93.0, 1.0, 2.0, 0.712150445047943, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 811657.3798652645, 811657.3798652645, 178458.4258478362], 
processed observation next is [1.0, 0.9565217391304348, 0.5185185185185185, 0.93, 1.0, 1.0, 0.6573219583904083, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2898776356661659, 0.2898776356661659, 0.34318928047660807], 
reward next is 0.6568, 
noisyNet noise sample is [array([-0.44052485], dtype=float32), -0.39810786]. 
=============================================
[2019-04-27 18:29:01,391] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.5491095e-13 1.0000000e+00 1.9556541e-19 1.5449338e-10 7.8381929e-10], sum to 1.0000
[2019-04-27 18:29:01,399] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9671
[2019-04-27 18:29:01,405] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.23333333333333, 92.66666666666667, 1.0, 2.0, 0.8074051819512356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 920286.9946751249, 920286.9946751249, 197481.7697285013], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4918800.0000, 
sim time next is 4919400.0000, 
raw observation next is [27.35, 92.0, 1.0, 2.0, 0.8055452544933036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 918165.7642792154, 918165.7642792154, 197095.543244247], 
processed observation next is [1.0, 0.9565217391304348, 0.5685185185185185, 0.92, 1.0, 1.0, 0.7685062553491709, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.32791634438543404, 0.32791634438543404, 0.37902989085432115], 
reward next is 0.6210, 
noisyNet noise sample is [array([-0.28162387], dtype=float32), -1.4425209]. 
=============================================
[2019-04-27 18:29:03,990] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.7978934e-12 1.0000000e+00 4.9180221e-16 3.8509290e-11 3.5215082e-09], sum to 1.0000
[2019-04-27 18:29:03,995] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6006
[2019-04-27 18:29:04,001] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1329360.609042526 W.
[2019-04-27 18:29:04,005] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.1, 83.0, 1.0, 2.0, 0.5811700441808341, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9253975521992355, 6.911199999999999, 6.9112, 121.9260426156618, 1329360.609042526, 1329360.609042526, 286550.7251483794], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4964400.0000, 
sim time next is 4965000.0000, 
raw observation next is [25.25, 83.16666666666667, 1.0, 2.0, 0.6650927099977646, 1.0, 1.0, 0.6650927099977646, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1516746.052482675, 1516746.052482675, 291160.5616572748], 
processed observation next is [1.0, 0.4782608695652174, 0.49074074074074076, 0.8316666666666667, 1.0, 1.0, 0.601300845235434, 1.0, 0.5, 0.601300845235434, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5416950187438125, 0.5416950187438125, 0.5599241570332207], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.14780076], dtype=float32), -1.1108713]. 
=============================================
[2019-04-27 18:29:04,018] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[49.904842]
 [49.312977]
 [49.883053]
 [49.0622  ]
 [48.610004]], R is [[48.84212875]
 [48.35370636]
 [47.87017059]
 [47.80187988]
 [47.73712158]].
[2019-04-27 18:29:08,130] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2354147e-15 1.0000000e+00 5.6823532e-23 1.3306346e-15 1.0894182e-15], sum to 1.0000
[2019-04-27 18:29:08,140] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7158
[2019-04-27 18:29:08,147] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.95, 99.66666666666667, 1.0, 2.0, 0.5740523582291339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 667192.7543001956, 667192.7543001951, 154289.0270048716], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5026200.0000, 
sim time next is 5026800.0000, 
raw observation next is [22.9, 99.33333333333334, 1.0, 2.0, 0.5716528761345233, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 665642.2873980385, 665642.2873980385, 153940.0467931122], 
processed observation next is [0.0, 0.17391304347826086, 0.4037037037037037, 0.9933333333333334, 1.0, 1.0, 0.4900629477791944, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23772938835644233, 0.23772938835644233, 0.2960385515252158], 
reward next is 0.7040, 
noisyNet noise sample is [array([0.02268543], dtype=float32), 0.28007704]. 
=============================================
[2019-04-27 18:29:08,835] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.0186579e-14 1.0000000e+00 3.7417547e-20 1.8340715e-12 2.7378568e-15], sum to 1.0000
[2019-04-27 18:29:08,840] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8561
[2019-04-27 18:29:08,845] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 87.33333333333334, 1.0, 2.0, 0.6767298345369875, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 771267.2285145555, 771267.2285145555, 171785.7439457316], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5044200.0000, 
sim time next is 5044800.0000, 
raw observation next is [26.66666666666667, 85.66666666666667, 1.0, 2.0, 0.6838817278954192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 779422.3669198233, 779422.3669198233, 173115.5118854976], 
processed observation next is [0.0, 0.391304347826087, 0.5432098765432101, 0.8566666666666667, 1.0, 1.0, 0.6236687236850229, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27836513104279403, 0.27836513104279403, 0.3329144459336492], 
reward next is 0.6671, 
noisyNet noise sample is [array([1.2535546], dtype=float32), 0.5103986]. 
=============================================
[2019-04-27 18:29:13,414] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.4656668e-14 1.0000000e+00 6.2737190e-21 8.8388078e-14 2.7546185e-15], sum to 1.0000
[2019-04-27 18:29:13,427] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0965
[2019-04-27 18:29:13,437] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 91.5, 1.0, 2.0, 0.8377181083907039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 954859.4400086326, 954859.4400086326, 203866.607443901], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5131800.0000, 
sim time next is 5132400.0000, 
raw observation next is [28.33333333333334, 90.66666666666666, 1.0, 2.0, 0.8544893206077296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 973987.9835618855, 973987.9835618855, 207466.8633836267], 
processed observation next is [0.0, 0.391304347826087, 0.6049382716049385, 0.9066666666666666, 1.0, 1.0, 0.8267730007234877, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.34785285127210197, 0.34785285127210197, 0.3989747372762052], 
reward next is 0.6010, 
noisyNet noise sample is [array([-0.31307906], dtype=float32), 0.2901493]. 
=============================================
[2019-04-27 18:29:15,787] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-04-27 18:29:15,789] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 18:29:15,789] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:29:15,790] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 18:29:15,791] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 18:29:15,792] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 18:29:15,792] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:29:15,792] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 18:29:15,794] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:29:15,795] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:29:15,793] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:29:15,814] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run15
[2019-04-27 18:29:15,835] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run15
[2019-04-27 18:29:15,854] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run15
[2019-04-27 18:29:15,874] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run15
[2019-04-27 18:29:15,875] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run15
[2019-04-27 18:29:56,955] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.050852664]
[2019-04-27 18:29:56,956] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.65, 93.5, 1.0, 2.0, 0.4471319328682461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 541028.9154068124, 541028.9154068124, 135100.5688198066]
[2019-04-27 18:29:56,958] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 18:29:56,960] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.9876082e-15 1.0000000e+00 1.5805004e-21 3.4289252e-14 4.0381639e-15], sampled 0.47238071902875034
[2019-04-27 18:30:00,695] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.050852664]
[2019-04-27 18:30:00,697] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.523254595, 57.661878775, 1.0, 2.0, 0.8827373035263618, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156525, 1065411.553339045, 1065411.553339045, 216422.6530012922]
[2019-04-27 18:30:00,701] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 18:30:00,704] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.8656964e-15 1.0000000e+00 2.8179644e-22 6.2072971e-15 1.6401023e-15], sampled 0.4668753816412613
[2019-04-27 18:30:21,955] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.050852664]
[2019-04-27 18:30:21,956] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.69050227, 87.0646112, 1.0, 2.0, 0.7757255922519324, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 884157.5116098273, 884157.5116098273, 190986.509248608]
[2019-04-27 18:30:21,957] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 18:30:21,961] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.8866448e-15 1.0000000e+00 2.9169701e-22 9.8182655e-15 1.5855295e-15], sampled 0.8569489273775777
[2019-04-27 18:31:01,700] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.050852664]
[2019-04-27 18:31:01,701] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.667698165, 39.94052641, 1.0, 2.0, 0.394183704758325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 476346.6866736789, 476346.6866736794, 127471.1819471962]
[2019-04-27 18:31:01,703] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 18:31:01,706] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.6364501e-15 1.0000000e+00 8.6937268e-22 2.2409429e-14 3.1279713e-15], sampled 0.5108100419593145
[2019-04-27 18:31:03,137] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-04-27 18:31:03,184] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-04-27 18:31:03,479] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-04-27 18:31:03,516] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-04-27 18:31:03,642] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-04-27 18:31:04,657] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 350000, evaluation results [350000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-04-27 18:31:10,871] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3486791e-15 1.0000000e+00 1.6337451e-23 1.8959128e-14 2.8761626e-16], sum to 1.0000
[2019-04-27 18:31:10,878] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4177
[2019-04-27 18:31:10,882] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.6, 85.0, 1.0, 2.0, 0.6716486894706646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 784542.5142433527, 784542.5142433527, 171761.3289079002], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5284800.0000, 
sim time next is 5285400.0000, 
raw observation next is [24.48333333333334, 85.33333333333334, 1.0, 2.0, 0.6459977723135669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 755605.9060927734, 755605.9060927734, 167092.3842393419], 
processed observation next is [1.0, 0.17391304347826086, 0.46234567901234597, 0.8533333333333334, 1.0, 1.0, 0.5785687765637701, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2698592521759905, 0.2698592521759905, 0.32133150815258055], 
reward next is 0.6787, 
noisyNet noise sample is [array([-1.2235786], dtype=float32), -0.29710478]. 
=============================================
[2019-04-27 18:31:17,803] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3221969e-08 1.0000000e+00 3.6698016e-13 1.5727284e-08 1.3286814e-08], sum to 1.0000
[2019-04-27 18:31:17,808] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7534
[2019-04-27 18:31:17,814] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1881265.159294262 W.
[2019-04-27 18:31:17,817] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.0, 84.0, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.91742015393921, 6.9112, 121.9258498763075, 1881265.159294262, 1878079.889561583, 384113.1539062074], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5410800.0000, 
sim time next is 5411400.0000, 
raw observation next is [28.16666666666667, 83.16666666666667, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.967349785815313, 6.9112, 121.9256398674494, 1906860.389536082, 1878106.775567483, 383934.698302131], 
processed observation next is [1.0, 0.6521739130434783, 0.5987654320987656, 0.8316666666666667, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 0.005614978581531283, 0.0, 0.8094594549908343, 0.6810215676914578, 0.6707524198455296, 0.7383359582733288], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.3731575], dtype=float32), -0.17741522]. 
=============================================
[2019-04-27 18:31:21,408] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.7516387e-13 1.0000000e+00 5.3438104e-20 4.9858182e-12 5.0875835e-14], sum to 1.0000
[2019-04-27 18:31:21,418] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7237
[2019-04-27 18:31:21,422] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.43333333333334, 94.16666666666667, 1.0, 2.0, 0.9072013902034023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1034112.275624716, 1034112.275624716, 219087.8413213857], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5464200.0000, 
sim time next is 5464800.0000, 
raw observation next is [26.5, 94.0, 1.0, 2.0, 0.9704258377360393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.962458630201536, 6.9112, 121.925817214755, 1132501.293058925, 1106252.341477074, 233671.3685442741], 
processed observation next is [1.0, 0.2608695652173913, 0.5370370370370371, 0.94, 1.0, 1.0, 0.9647926639714753, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.005125863020153609, 0.0, 0.8094606323925152, 0.40446474752104467, 0.39509012195609783, 0.4493680164312963], 
reward next is 0.2943, 
noisyNet noise sample is [array([-0.23378985], dtype=float32), 0.9521252]. 
=============================================
[2019-04-27 18:31:21,896] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.8324124e-10 1.0000000e+00 7.1164063e-14 2.6936711e-09 1.2739780e-10], sum to 1.0000
[2019-04-27 18:31:21,903] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7094
[2019-04-27 18:31:21,903] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2178169.484766457 W.
[2019-04-27 18:31:21,908] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.0, 89.33333333333334, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 7.496612010947193, 6.9112, 121.9237643312909, 2178169.484766457, 1878391.81331684, 382038.8083844098], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5474400.0000, 
sim time next is 5475000.0000, 
raw observation next is [28.15, 88.66666666666667, 1.0, 2.0, 0.6160680647492793, 1.0, 1.0, 0.6160680647492793, 1.0, 2.0, 0.9808004230169853, 6.911200000000001, 6.9112, 121.94756008, 2108127.167584903, 2108127.167584903, 404199.7847621478], 
processed observation next is [1.0, 0.34782608695652173, 0.5981481481481481, 0.8866666666666667, 1.0, 1.0, 0.5429381723205706, 1.0, 0.5, 0.5429381723205706, 1.0, 1.0, 0.9760005287712317, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7529025598517511, 0.7529025598517511, 0.7773072783887458], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7461039], dtype=float32), -0.23302022]. 
=============================================
[2019-04-27 18:31:21,929] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[42.264576]
 [44.49872 ]
 [46.392025]
 [50.974907]
 [51.708176]], R is [[39.92481995]
 [39.52557373]
 [39.13031769]
 [39.0596199 ]
 [38.66902542]].
[2019-04-27 18:31:21,940] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.6336570e-09 1.0000000e+00 4.4835403e-13 8.5375920e-09 7.4702455e-10], sum to 1.0000
[2019-04-27 18:31:21,948] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8334
[2019-04-27 18:31:21,954] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2150675.060538974 W.
[2019-04-27 18:31:21,957] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.43333333333334, 87.50000000000001, 1.0, 2.0, 0.6302448454976268, 1.0, 2.0, 0.6284870847252482, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2150675.060538974, 2150675.060538974, 411021.6505218513], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5476200.0000, 
sim time next is 5476800.0000, 
raw observation next is [28.56666666666667, 87.0, 1.0, 2.0, 0.9490512066454327, 1.0, 2.0, 0.9490512066454327, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2165112.300182424, 2165112.300182424, 409195.9271751224], 
processed observation next is [1.0, 0.391304347826087, 0.6135802469135804, 0.87, 1.0, 1.0, 0.9393466745778961, 1.0, 1.0, 0.9393466745778961, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7732543929222943, 0.7732543929222943, 0.786915244567543], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6310214], dtype=float32), -0.2632341]. 
=============================================
[2019-04-27 18:31:24,798] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0227536e-16 1.0000000e+00 2.2032538e-24 2.7835402e-15 1.3085553e-17], sum to 1.0000
[2019-04-27 18:31:24,810] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9817
[2019-04-27 18:31:24,815] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.03333333333333, 88.0, 1.0, 2.0, 0.6748170602792001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 769086.1510216102, 769086.1510216102, 171430.7294077771], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5523600.0000, 
sim time next is 5524200.0000, 
raw observation next is [26.0, 88.5, 1.0, 2.0, 0.6767768588703053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 771320.8489896905, 771320.848989691, 171793.6432992636], 
processed observation next is [1.0, 0.9565217391304348, 0.5185185185185185, 0.885, 1.0, 1.0, 0.6152105462741729, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2754717317820323, 0.2754717317820325, 0.33037239096012233], 
reward next is 0.6696, 
noisyNet noise sample is [array([0.3515429], dtype=float32), -0.13879934]. 
=============================================
[2019-04-27 18:31:29,552] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.7573516e-19 1.0000000e+00 4.6443476e-25 1.4073388e-17 4.8454632e-19], sum to 1.0000
[2019-04-27 18:31:29,557] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8722
[2019-04-27 18:31:29,562] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.15, 96.0, 1.0, 2.0, 0.6213164524583843, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 710910.0353459646, 710910.0353459646, 161923.4633597896], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5640600.0000, 
sim time next is 5641200.0000, 
raw observation next is [24.2, 96.0, 1.0, 2.0, 0.6249562141305062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 714263.1110789693, 714263.1110789698, 162524.531026068], 
processed observation next is [0.0, 0.30434782608695654, 0.45185185185185184, 0.96, 1.0, 1.0, 0.5535193025363169, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.25509396824248903, 0.2550939682424892, 0.31254717505013074], 
reward next is 0.6875, 
noisyNet noise sample is [array([-0.31724712], dtype=float32), -1.559897]. 
=============================================
[2019-04-27 18:31:38,758] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.9355186e-19 1.0000000e+00 2.2597104e-27 3.0395325e-19 3.6704904e-19], sum to 1.0000
[2019-04-27 18:31:38,768] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5701
[2019-04-27 18:31:38,774] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 83.5, 1.0, 2.0, 0.5137715843900241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 610761.0935532185, 610761.0935532185, 144999.6283919452], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5783400.0000, 
sim time next is 5784000.0000, 
raw observation next is [23.8, 84.0, 1.0, 2.0, 0.5121093124352167, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 609122.8329825962, 609122.8329825958, 144747.7659877211], 
processed observation next is [0.0, 0.9565217391304348, 0.43703703703703706, 0.84, 1.0, 1.0, 0.4191777528990675, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2175438689223558, 0.21754386892235564, 0.2783610884379252], 
reward next is 0.7216, 
noisyNet noise sample is [array([-0.6045249], dtype=float32), 0.31548804]. 
=============================================
[2019-04-27 18:31:38,783] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[76.566505]
 [76.5875  ]
 [76.62893 ]
 [76.65867 ]
 [76.64858 ]], R is [[76.50269318]
 [76.45881653]
 [76.41488647]
 [76.3708725 ]
 [76.32669067]].
[2019-04-27 18:31:39,390] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.7908814e-17 1.0000000e+00 2.5990290e-25 3.7305883e-16 7.0076590e-20], sum to 1.0000
[2019-04-27 18:31:39,399] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9974
[2019-04-27 18:31:39,405] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.05, 87.5, 1.0, 2.0, 0.558578490899124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 678957.295517853, 678957.295517853, 152837.620687582], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5797800.0000, 
sim time next is 5798400.0000, 
raw observation next is [22.0, 88.0, 1.0, 2.0, 0.550348546413134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 668893.4249924582, 668893.4249924582, 151456.4480125662], 
processed observation next is [1.0, 0.08695652173913043, 0.37037037037037035, 0.88, 1.0, 1.0, 0.4647006504918262, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23889050892587793, 0.23889050892587793, 0.29126240002416576], 
reward next is 0.7087, 
noisyNet noise sample is [array([-0.44017762], dtype=float32), -1.6287667]. 
=============================================
[2019-04-27 18:31:39,921] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.7552571e-16 1.0000000e+00 4.6791158e-24 1.4375623e-16 1.5120508e-16], sum to 1.0000
[2019-04-27 18:31:39,930] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0360
[2019-04-27 18:31:39,938] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.2, 95.0, 1.0, 2.0, 0.4471706791041427, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 543100.8865050845, 543100.886505084, 135169.5465890517], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5806800.0000, 
sim time next is 5807400.0000, 
raw observation next is [21.33333333333334, 94.0, 1.0, 2.0, 0.5497375123873501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 667457.4028083998, 667457.4028083998, 151332.9313769092], 
processed observation next is [1.0, 0.21739130434782608, 0.3456790123456792, 0.94, 1.0, 1.0, 0.46397322903255966, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23837764386014276, 0.23837764386014276, 0.2910248680325177], 
reward next is 0.7090, 
noisyNet noise sample is [array([-1.515446], dtype=float32), 0.1651624]. 
=============================================
[2019-04-27 18:31:40,075] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.0636703e-14 1.0000000e+00 1.4244039e-20 1.7722424e-13 2.2721616e-16], sum to 1.0000
[2019-04-27 18:31:40,084] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4197
[2019-04-27 18:31:40,087] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.15, 86.5, 1.0, 2.0, 0.7380901568190914, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 122.0023338734303, 897684.3164881194, 897684.3164881194, 185933.2123159912], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5796600.0000, 
sim time next is 5797200.0000, 
raw observation next is [22.1, 87.0, 1.0, 2.0, 0.6382600076096098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 775884.5248766068, 775884.5248766068, 166814.1259252875], 
processed observation next is [1.0, 0.08695652173913043, 0.3740740740740741, 0.87, 1.0, 1.0, 0.5693571519162021, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27710161602735955, 0.27710161602735955, 0.32079639601016824], 
reward next is 0.6792, 
noisyNet noise sample is [array([-0.60065866], dtype=float32), -1.2131339]. 
=============================================
[2019-04-27 18:31:44,751] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.1403232e-14 1.0000000e+00 7.3911197e-21 1.6573421e-14 1.2285995e-16], sum to 1.0000
[2019-04-27 18:31:44,760] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6050
[2019-04-27 18:31:44,765] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.6, 60.33333333333334, 1.0, 2.0, 0.8681554904664327, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.926024407615, 1063417.98247635, 1063417.98247635, 213697.1864041383], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5912400.0000, 
sim time next is 5913000.0000, 
raw observation next is [25.85, 59.5, 1.0, 2.0, 0.8760406913797264, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426101097, 1071813.622748884, 1071813.622748883, 215424.952113205], 
processed observation next is [1.0, 0.43478260869565216, 0.5129629629629631, 0.595, 1.0, 1.0, 0.8524293944996743, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 1.7763568394002506e-16, 0.0, 0.8094621287832758, 0.3827905795531728, 0.38279057955317247, 0.4142787540638558], 
reward next is 0.5857, 
noisyNet noise sample is [array([0.2159142], dtype=float32), -0.23259863]. 
=============================================
[2019-04-27 18:31:44,777] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[60.648575]
 [59.086056]
 [58.34154 ]
 [59.42246 ]
 [60.473324]], R is [[61.2427063 ]
 [61.2193222 ]
 [60.60712814]
 [60.00105667]
 [59.40104675]].
[2019-04-27 18:31:53,588] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.0550691e-15 1.0000000e+00 6.1431047e-23 6.8038722e-15 6.2744257e-17], sum to 1.0000
[2019-04-27 18:31:53,595] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7622
[2019-04-27 18:31:53,602] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.81666666666666, 77.33333333333333, 1.0, 2.0, 0.5174058493374921, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 614851.3761995293, 614851.3761995297, 145571.2407882451], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6043800.0000, 
sim time next is 6044400.0000, 
raw observation next is [24.7, 78.0, 1.0, 2.0, 0.5158228803317958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 613157.5309905863, 613157.5309905863, 145325.33376749], 
processed observation next is [1.0, 1.0, 0.4703703703703703, 0.78, 1.0, 1.0, 0.42359866706166166, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21898483249663794, 0.21898483249663794, 0.27947179570671155], 
reward next is 0.7205, 
noisyNet noise sample is [array([-0.17758955], dtype=float32), 0.090146326]. 
=============================================
[2019-04-27 18:31:56,923] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-04-27 18:31:56,924] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 18:31:56,924] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 18:31:56,925] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 18:31:56,926] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:31:56,926] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 18:31:56,927] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:31:56,928] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 18:31:56,929] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:31:56,928] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:31:56,931] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:31:56,945] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run16
[2019-04-27 18:31:56,945] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run16
[2019-04-27 18:31:56,946] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run16
[2019-04-27 18:31:57,005] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run16
[2019-04-27 18:31:57,006] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run16
[2019-04-27 18:32:11,987] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.05231522]
[2019-04-27 18:32:11,988] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.53306139166667, 55.98309883666667, 1.0, 2.0, 0.2820178119794094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 361061.2219206708, 361061.2219206708, 113383.9893894936]
[2019-04-27 18:32:11,992] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 18:32:11,996] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.2468171e-17 1.0000000e+00 1.9168507e-24 9.0649665e-17 7.3548170e-19], sampled 0.581204151892397
[2019-04-27 18:32:20,658] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.05231522]
[2019-04-27 18:32:20,659] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.85, 49.0, 1.0, 2.0, 0.8584343500182248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1038479.343197572, 1038479.343197572, 211088.4297303011]
[2019-04-27 18:32:20,660] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 18:32:20,664] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0664739e-15 1.0000000e+00 2.1177275e-22 2.2172011e-15 2.6666386e-17], sampled 0.3891081010252505
[2019-04-27 18:32:43,664] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.05231522]
[2019-04-27 18:32:43,665] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.244592725, 91.307349305, 1.0, 2.0, 0.432787293110203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 533972.6623864347, 533972.6623864347, 133279.4478763679]
[2019-04-27 18:32:43,667] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 18:32:43,673] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0314438e-16 1.0000000e+00 7.4969696e-24 2.4735030e-16 1.9394740e-18], sampled 0.6379963547152587
[2019-04-27 18:32:49,250] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.05231522]
[2019-04-27 18:32:49,253] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.25, 83.16666666666667, 1.0, 2.0, 0.6666257134505104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 759745.8810644371, 759745.8810644371, 169919.5087455197]
[2019-04-27 18:32:49,254] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 18:32:49,256] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.3916491e-17 1.0000000e+00 1.9763029e-24 9.3656797e-17 8.0724189e-19], sampled 0.4226393520795899
[2019-04-27 18:32:55,945] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.05231522]
[2019-04-27 18:32:55,946] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.0, 89.0, 1.0, 2.0, 0.5366063197364429, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 628424.6990213105, 628424.6990213105, 148301.9715698257]
[2019-04-27 18:32:55,946] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 18:32:55,950] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.1597254e-17 1.0000000e+00 2.8497001e-24 1.3166927e-16 9.1539860e-19], sampled 0.5194990556336934
[2019-04-27 18:32:58,479] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.05231522]
[2019-04-27 18:32:58,479] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.23333333333333, 91.83333333333334, 1.0, 2.0, 0.5624287919779954, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 650034.0075716368, 650034.0075716368, 152174.407310027]
[2019-04-27 18:32:58,480] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 18:32:58,486] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.7878535e-17 1.0000000e+00 7.1461308e-24 2.4288183e-16 1.8516337e-18], sampled 0.9020289234917718
[2019-04-27 18:33:12,399] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.05231522]
[2019-04-27 18:33:12,400] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.76666666666667, 52.33333333333334, 1.0, 2.0, 0.6939271751914481, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 790877.104410608, 790877.104410608, 175002.1682854094]
[2019-04-27 18:33:12,401] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 18:33:12,403] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.5349861e-17 1.0000000e+00 3.0013527e-24 1.2678074e-16 1.0480614e-18], sampled 0.24722947501291204
[2019-04-27 18:33:42,701] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.05231522]
[2019-04-27 18:33:42,702] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.21744785333333, 23.03795691166667, 1.0, 2.0, 0.5540979123094714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 714920.8089362091, 714920.8089362091, 144698.1100985096]
[2019-04-27 18:33:42,703] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 18:33:42,706] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.5964105e-16 1.0000000e+00 1.2616034e-23 3.2186929e-16 3.4530444e-18], sampled 0.09935920644370033
[2019-04-27 18:33:44,090] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-04-27 18:33:44,259] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-04-27 18:33:44,364] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-04-27 18:33:44,447] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-04-27 18:33:44,747] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-04-27 18:33:45,765] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 375000, evaluation results [375000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-04-27 18:33:45,819] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.1246757e-15 1.0000000e+00 6.9817164e-22 3.1243237e-14 6.8663905e-17], sum to 1.0000
[2019-04-27 18:33:45,822] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3334
[2019-04-27 18:33:45,827] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2012623.294062065 W.
[2019-04-27 18:33:45,837] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.43333333333333, 52.66666666666667, 1.0, 2.0, 0.8822847094352949, 1.0, 2.0, 0.8822847094352949, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260424583099, 2012623.294062065, 2012623.294062065, 378927.4199782885], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6101400.0000, 
sim time next is 6102000.0000, 
raw observation next is [30.4, 53.0, 1.0, 2.0, 0.5932108309302707, 1.0, 2.0, 0.5932108309302707, 1.0, 1.0, 0.944410962368988, 6.911200000000001, 6.9112, 121.94756008, 2029822.974433794, 2029822.974433793, 391688.9138925101], 
processed observation next is [1.0, 0.6521739130434783, 0.6814814814814815, 0.53, 1.0, 1.0, 0.5157271796788937, 1.0, 1.0, 0.5157271796788937, 1.0, 0.5, 0.930513702961235, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7249367765834979, 0.7249367765834975, 0.7532479113317502], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1797212], dtype=float32), -0.038395926]. 
=============================================
[2019-04-27 18:33:45,874] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[55.084263]
 [54.50356 ]
 [53.790897]
 [54.483772]
 [54.588722]], R is [[55.33765793]
 [55.05557632]
 [54.50502014]
 [53.95996857]
 [53.68281937]].
[2019-04-27 18:33:48,504] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.1277436e-15 1.0000000e+00 6.0697490e-24 7.6994441e-17 4.3059512e-17], sum to 1.0000
[2019-04-27 18:33:48,511] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0190
[2019-04-27 18:33:48,519] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1773971.097235707 W.
[2019-04-27 18:33:48,527] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.2, 63.0, 1.0, 2.0, 0.9272521219032525, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9961815226664418, 6.911199999999999, 6.9112, 121.9260426156618, 1773971.097235707, 1773971.097235708, 362684.1187794853], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6177600.0000, 
sim time next is 6178200.0000, 
raw observation next is [28.33333333333333, 62.33333333333333, 1.0, 2.0, 0.4692356808106969, 1.0, 1.0, 0.4692356808106969, 1.0, 2.0, 0.7470384857898659, 6.911199999999999, 6.9112, 121.94756008, 1605229.088425373, 1605229.088425373, 328737.7281813197], 
processed observation next is [1.0, 0.5217391304347826, 0.6049382716049381, 0.6233333333333333, 1.0, 1.0, 0.3681377152508296, 1.0, 0.5, 0.3681377152508296, 1.0, 1.0, 0.6837981072373323, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5732961030090618, 0.5732961030090618, 0.6321879388102303], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.64518386], dtype=float32), -0.5104769]. 
=============================================
[2019-04-27 18:33:49,352] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.5090119e-12 1.0000000e+00 6.8181259e-18 8.1157325e-13 8.9457142e-13], sum to 1.0000
[2019-04-27 18:33:49,359] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0082
[2019-04-27 18:33:49,367] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1480003.833754446 W.
[2019-04-27 18:33:49,372] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.21666666666667, 67.83333333333333, 1.0, 2.0, 0.6487923609897246, 1.0, 2.0, 0.6487923609897246, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1480003.833754446, 1480003.833754446, 285256.5853452368], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6173400.0000, 
sim time next is 6174000.0000, 
raw observation next is [27.4, 67.0, 1.0, 2.0, 0.4565085876757293, 1.0, 2.0, 0.4565085876757293, 1.0, 1.0, 0.7267765390265111, 6.9112, 6.9112, 121.94756008, 1561649.402144481, 1561649.402144481, 322719.9054978014], 
processed observation next is [1.0, 0.4782608695652174, 0.5703703703703703, 0.67, 1.0, 1.0, 0.3529864138996777, 1.0, 1.0, 0.3529864138996777, 1.0, 0.5, 0.6584706737831388, 0.0, 0.0, 0.8096049824067558, 0.5577319293373146, 0.5577319293373146, 0.6206152028803873], 
reward next is 0.3794, 
noisyNet noise sample is [array([0.4175527], dtype=float32), 1.8036377]. 
=============================================
[2019-04-27 18:33:49,384] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[45.9934  ]
 [46.014442]
 [45.21643 ]
 [45.906307]
 [46.11982 ]], R is [[45.42728424]
 [45.42444229]
 [45.42017365]
 [44.9659729 ]
 [44.91437912]].
[2019-04-27 18:33:59,704] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.4145905e-17 1.0000000e+00 1.2190509e-26 1.8002540e-17 8.3493375e-20], sum to 1.0000
[2019-04-27 18:33:59,713] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5828
[2019-04-27 18:33:59,719] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.71666666666667, 77.33333333333333, 1.0, 2.0, 0.6926780818321623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 789452.7646346765, 789452.7646346765, 174761.6077419126], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6389400.0000, 
sim time next is 6390000.0000, 
raw observation next is [27.6, 78.0, 1.0, 2.0, 0.6918807108490882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 788543.5247687678, 788543.5247687678, 174611.6991952037], 
processed observation next is [0.0, 1.0, 0.5777777777777778, 0.78, 1.0, 1.0, 0.6331913224393907, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2816226874174171, 0.2816226874174171, 0.33579172922154554], 
reward next is 0.6642, 
noisyNet noise sample is [array([0.4238578], dtype=float32), 0.3086516]. 
=============================================
[2019-04-27 18:33:59,742] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[74.36936 ]
 [74.39867 ]
 [74.445656]
 [74.50066 ]
 [74.528824]], R is [[74.30184937]
 [74.2227478 ]
 [74.1442337 ]
 [74.06760406]
 [73.99652863]].
[2019-04-27 18:34:05,744] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.5577758e-12 1.0000000e+00 5.6779635e-20 6.8544573e-13 2.2415938e-13], sum to 1.0000
[2019-04-27 18:34:05,754] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9447
[2019-04-27 18:34:05,761] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.36666666666667, 85.33333333333333, 1.0, 2.0, 0.9670540281964068, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.941679894480588, 6.9112, 121.9254988427184, 1118006.535903873, 1102398.175279153, 232868.9237949222], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6496800.0000, 
sim time next is 6497400.0000, 
raw observation next is [26.33333333333334, 85.66666666666667, 1.0, 2.0, 0.9028431967908275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260242178711, 1029141.066555218, 1029141.066555218, 218101.2543935005], 
processed observation next is [1.0, 0.17391304347826086, 0.5308641975308644, 0.8566666666666667, 1.0, 1.0, 0.8843371390366994, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094620066779381, 0.36755038091257786, 0.36755038091257786, 0.4194254892182702], 
reward next is 0.5806, 
noisyNet noise sample is [array([-1.0619293], dtype=float32), -0.99334455]. 
=============================================
[2019-04-27 18:34:30,801] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.2697230e-10 9.9999940e-01 8.5348942e-18 2.6244967e-07 3.6756529e-07], sum to 1.0000
[2019-04-27 18:34:30,811] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3332
[2019-04-27 18:34:30,816] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.85, 75.5, 1.0, 2.0, 0.4176529276692133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 514351.767464844, 514351.767464844, 131059.0789590144], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6918600.0000, 
sim time next is 6919200.0000, 
raw observation next is [22.8, 76.0, 1.0, 2.0, 0.4179895941317701, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 514604.6991452071, 514604.6991452071, 131103.4258534624], 
processed observation next is [0.0, 0.08695652173913043, 0.4, 0.76, 1.0, 1.0, 0.3071304692044883, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1837873925518597, 0.1837873925518597, 0.25212197279512], 
reward next is 0.7479, 
noisyNet noise sample is [array([1.8461672], dtype=float32), 0.22686523]. 
=============================================
[2019-04-27 18:34:31,745] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3004441e-10 9.9983633e-01 1.4889192e-19 1.5513171e-04 8.4040103e-06], sum to 1.0000
[2019-04-27 18:34:31,753] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1747
[2019-04-27 18:34:31,761] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.15, 83.5, 1.0, 2.0, 0.4328255157560487, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 529925.8610422555, 529925.8610422555, 133179.9208164652], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6935400.0000, 
sim time next is 6936000.0000, 
raw observation next is [22.26666666666667, 83.0, 1.0, 2.0, 0.4352036096058254, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 532434.9523691793, 532434.9523691789, 133517.2825750743], 
processed observation next is [0.0, 0.2608695652173913, 0.38024691358024704, 0.83, 1.0, 1.0, 0.3276233447688397, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19015534013184976, 0.1901553401318496, 0.25676400495206597], 
reward next is 0.7432, 
noisyNet noise sample is [array([-0.78592265], dtype=float32), 0.0048180567]. 
=============================================
[2019-04-27 18:34:31,787] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[78.88331 ]
 [78.95954 ]
 [79.05617 ]
 [79.148315]
 [79.19894 ]], R is [[78.75255585]
 [78.70891571]
 [78.66631317]
 [78.62464905]
 [78.58405304]].
[2019-04-27 18:34:36,073] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.2636494e-09 9.9763751e-01 3.2279423e-14 1.3706930e-03 9.9180755e-04], sum to 1.0000
[2019-04-27 18:34:36,078] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2726
[2019-04-27 18:34:36,080] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1359930.687687057 W.
[2019-04-27 18:34:36,083] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.2, 76.0, 1.0, 2.0, 0.968690838503248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.288460815237249, 6.9112, 121.9246396215145, 1359930.687687057, 1166741.654134352, 236332.4785797235], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7034400.0000, 
sim time next is 7035000.0000, 
raw observation next is [24.38333333333333, 75.33333333333334, 1.0, 2.0, 0.5765284241489095, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9258291687130971, 6.911200000000001, 6.9112, 121.9258154357781, 1368709.897129543, 1368709.897129542, 283592.8344088813], 
processed observation next is [1.0, 0.43478260869565216, 0.4586419753086418, 0.7533333333333334, 1.0, 1.0, 0.4958671716058446, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.9072864608913713, 8.881784197001253e-17, 0.0, 0.8094606205819587, 0.488824963260551, 0.4888249632605507, 0.5453708354016948], 
reward next is 0.4546, 
noisyNet noise sample is [array([-0.03915505], dtype=float32), -1.7211584]. 
=============================================
[2019-04-27 18:34:36,115] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[54.516026]
 [55.29798 ]
 [55.115192]
 [54.34449 ]
 [54.474712]], R is [[54.28305817]
 [53.74022675]
 [53.78886795]
 [53.72960663]
 [53.19231033]].
[2019-04-27 18:34:37,179] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-04-27 18:34:37,182] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 18:34:37,182] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:34:37,182] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 18:34:37,183] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 18:34:37,183] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:34:37,185] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:34:37,187] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 18:34:37,184] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 18:34:37,188] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:34:37,190] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:34:37,205] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run17
[2019-04-27 18:34:37,224] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run17
[2019-04-27 18:34:37,225] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run17
[2019-04-27 18:34:37,225] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run17
[2019-04-27 18:34:37,285] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run17
[2019-04-27 18:34:51,887] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.0541206]
[2019-04-27 18:34:51,888] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.42992665166667, 66.30272265666666, 1.0, 2.0, 0.584367637690929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 716540.5273077697, 716540.5273077697, 157421.3655111856]
[2019-04-27 18:34:51,888] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 18:34:51,890] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.6110638e-07 9.9651438e-01 6.6403545e-13 2.7184802e-04 3.2131390e-03], sampled 0.25625550933600405
[2019-04-27 18:34:55,132] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.0541206]
[2019-04-27 18:34:55,133] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.58421486666667, 45.59873707666667, 1.0, 2.0, 0.3408491409376475, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 434132.3711255009, 434132.3711255009, 120770.143983239]
[2019-04-27 18:34:55,134] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 18:34:55,138] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.1911712e-06 9.9599212e-01 1.6278334e-12 3.5527602e-04 3.6514327e-03], sampled 0.07144929892847307
[2019-04-27 18:35:11,412] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.0541206]
[2019-04-27 18:35:11,413] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.79051621666667, 100.9627222583333, 1.0, 2.0, 0.5184387056161055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 616566.3977966182, 616566.3977966182, 145755.1581832278]
[2019-04-27 18:35:11,415] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 18:35:11,417] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.6718243e-07 9.9654645e-01 6.9478093e-13 3.0916510e-04 3.1437313e-03], sampled 0.533331496027788
[2019-04-27 18:35:12,567] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.0541206]
[2019-04-27 18:35:12,568] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.0, 70.0, 1.0, 2.0, 0.5736494925744757, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 669076.2556520657, 669076.2556520657, 154325.6450120587]
[2019-04-27 18:35:12,569] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 18:35:12,572] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.0886479e-07 9.9706572e-01 3.2377627e-13 2.1673903e-04 2.7171015e-03], sampled 0.8367786636901694
[2019-04-27 18:35:26,157] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.0541206]
[2019-04-27 18:35:26,159] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.05, 94.0, 1.0, 2.0, 0.6664844235449651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 759584.7747520634, 759584.7747520634, 169895.0626634595]
[2019-04-27 18:35:26,161] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 18:35:26,163] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.5263056e-07 9.9610305e-01 1.0135235e-12 3.0003610e-04 3.5959226e-03], sampled 0.23486437735350418
[2019-04-27 18:35:30,204] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.0541206]
[2019-04-27 18:35:30,207] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.2, 89.33333333333334, 1.0, 2.0, 0.8763902799893307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 998968.0212054208, 998968.0212054208, 212227.0109042258]
[2019-04-27 18:35:30,208] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 18:35:30,210] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.8161223e-06 9.9450326e-01 3.8070653e-12 4.6337431e-04 5.0316057e-03], sampled 0.8202491866474724
[2019-04-27 18:35:59,931] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.0541206]
[2019-04-27 18:35:59,933] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.0, 94.0, 1.0, 2.0, 0.5944341127674369, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9463584668932644, 6.911199999999999, 6.9112, 121.9260426156618, 1355466.297054217, 1355466.297054217, 291704.9347771315]
[2019-04-27 18:35:59,934] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 18:35:59,937] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.4311538e-07 9.9601859e-01 4.7854694e-13 1.9557732e-04 3.7850938e-03], sampled 0.8459595178893429
[2019-04-27 18:35:59,938] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1355466.297054217 W.
[2019-04-27 18:36:09,465] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.0541206]
[2019-04-27 18:36:09,466] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.61624618166667, 48.23652947833334, 1.0, 2.0, 0.5442240890209543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 670419.4555523174, 670419.455552317, 150691.7792724672]
[2019-04-27 18:36:09,467] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 18:36:09,469] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.9166303e-07 9.9634093e-01 9.2202873e-13 2.9636879e-04 3.3617031e-03], sampled 0.006102817409960992
[2019-04-27 18:36:24,959] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8729.1249 2173060659.8632 491.0000
[2019-04-27 18:36:25,368] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8655.5181 2197368030.8205 572.0000
[2019-04-27 18:36:25,392] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8060.9227 2447253875.8446 747.0000
[2019-04-27 18:36:25,433] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8879.7104 2122619161.3000 430.0000
[2019-04-27 18:36:25,475] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8531.2973 2251290580.7975 551.0000
[2019-04-27 18:36:26,488] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 400000, evaluation results [400000.0, 8060.922692476441, 2447253875.8445954, 747.0, 8729.124876223477, 2173060659.863212, 491.0, 8879.710387559608, 2122619161.3000205, 430.0, 8531.297293002079, 2251290580.797494, 551.0, 8655.518051308783, 2197368030.8204565, 572.0]
[2019-04-27 18:36:28,399] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.4310742e-10 9.9668664e-01 2.2393742e-18 9.3298586e-06 3.3039595e-03], sum to 1.0000
[2019-04-27 18:36:28,401] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1872
[2019-04-27 18:36:28,406] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.56666666666667, 80.16666666666667, 1.0, 2.0, 0.481194604262053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 580123.5632637322, 580123.5632637318, 140189.2594304248], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7067400.0000, 
sim time next is 7068000.0000, 
raw observation next is [23.53333333333333, 80.33333333333334, 1.0, 2.0, 0.4812273709878159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 580253.4186186891, 580253.4186186891, 140197.3265906108], 
processed observation next is [1.0, 0.8260869565217391, 0.4271604938271604, 0.8033333333333335, 1.0, 1.0, 0.382413536890257, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20723336379238894, 0.20723336379238894, 0.26961024344348233], 
reward next is 0.7304, 
noisyNet noise sample is [array([-0.1691773], dtype=float32), -0.29684073]. 
=============================================
[2019-04-27 18:36:28,444] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[67.07056 ]
 [66.85411 ]
 [67.1097  ]
 [67.222824]
 [67.52608 ]], R is [[66.79423523]
 [66.85670471]
 [66.91864014]
 [66.9800415 ]
 [67.04073334]].
[2019-04-27 18:36:43,766] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.1515767e-10 9.9873549e-01 1.0632036e-18 1.2351862e-06 1.2632774e-03], sum to 1.0000
[2019-04-27 18:36:43,774] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1973
[2019-04-27 18:36:43,781] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.43333333333334, 96.0, 1.0, 2.0, 0.3801747026952166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 473289.9328516799, 473289.9328516804, 125908.7704752989], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7363200.0000, 
sim time next is 7363800.0000, 
raw observation next is [19.4, 96.0, 1.0, 2.0, 0.3789534873130062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 471995.0521062265, 471995.0521062265, 125745.5189083229], 
processed observation next is [1.0, 0.21739130434782608, 0.274074074074074, 0.96, 1.0, 1.0, 0.2606589134678645, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16856966146650945, 0.16856966146650945, 0.24181830559292866], 
reward next is 0.7582, 
noisyNet noise sample is [array([-1.3865685], dtype=float32), 0.45558092]. 
=============================================
[2019-04-27 18:36:45,392] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.4443449e-09 9.9943775e-01 2.6762569e-15 1.3814229e-05 5.4841314e-04], sum to 1.0000
[2019-04-27 18:36:45,400] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9425
[2019-04-27 18:36:45,406] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.6, 93.33333333333334, 1.0, 2.0, 0.5589089152984116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 687343.6685832314, 687343.6685832314, 153122.873278667], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7389600.0000, 
sim time next is 7390200.0000, 
raw observation next is [20.7, 93.16666666666666, 1.0, 2.0, 0.5670656420442081, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 696536.5054359182, 696536.5054359182, 154483.7682293894], 
processed observation next is [1.0, 0.5217391304347826, 0.3222222222222222, 0.9316666666666665, 1.0, 1.0, 0.4846019548145334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24876303765568508, 0.24876303765568508, 0.29708416967190265], 
reward next is 0.7029, 
noisyNet noise sample is [array([0.26332638], dtype=float32), -1.0969712]. 
=============================================
[2019-04-27 18:36:46,653] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.9928743e-10 9.9996781e-01 7.4246584e-19 2.1471942e-08 3.2191965e-05], sum to 1.0000
[2019-04-27 18:36:46,663] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4202
[2019-04-27 18:36:46,667] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.2, 90.0, 1.0, 2.0, 0.836787159252744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9259471227492, 1024645.926452411, 1024645.92645241, 206761.7152974361], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7401600.0000, 
sim time next is 7402200.0000, 
raw observation next is [21.2, 89.83333333333333, 1.0, 2.0, 0.8761845660644688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260425865436, 1073463.822164229, 1073463.822164229, 215504.1866956083], 
processed observation next is [1.0, 0.6956521739130435, 0.34074074074074073, 0.8983333333333333, 1.0, 1.0, 0.8526006738862724, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621286268214, 0.3833799364872246, 0.3833799364872246, 0.4144311282607852], 
reward next is 0.5856, 
noisyNet noise sample is [array([0.908281], dtype=float32), 0.8448292]. 
=============================================
[2019-04-27 18:36:59,375] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1940392e-09 9.9985433e-01 1.7112531e-17 4.4726605e-07 1.4514271e-04], sum to 1.0000
[2019-04-27 18:36:59,386] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7693
[2019-04-27 18:36:59,395] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.6, 91.0, 1.0, 2.0, 0.4342399605711418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 536393.4888470238, 536393.4888470238, 133509.0759719882], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7630200.0000, 
sim time next is 7630800.0000, 
raw observation next is [20.66666666666667, 91.0, 1.0, 2.0, 0.4193767786074326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 517546.3971003103, 517546.3971003103, 131333.8803359274], 
processed observation next is [1.0, 0.30434782608695654, 0.3209876543209878, 0.91, 1.0, 1.0, 0.3087818792945626, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18483799896439654, 0.18483799896439654, 0.25256515449216804], 
reward next is 0.7474, 
noisyNet noise sample is [array([0.7479518], dtype=float32), 0.5480771]. 
=============================================
[2019-04-27 18:37:02,759] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.7021120e-15 1.0000000e+00 7.1462979e-23 2.0526617e-11 2.0422224e-08], sum to 1.0000
[2019-04-27 18:37:02,769] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5409
[2019-04-27 18:37:02,776] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.26666666666667, 90.33333333333334, 1.0, 2.0, 0.30752376547701, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 391551.9362631745, 391551.9362631745, 116506.9253880441], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7706400.0000, 
sim time next is 7707000.0000, 
raw observation next is [18.18333333333334, 92.16666666666667, 1.0, 2.0, 0.3103585014018716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 394639.0130860892, 394639.0130860892, 116858.779770845], 
processed observation next is [1.0, 0.17391304347826086, 0.22901234567901263, 0.9216666666666667, 1.0, 1.0, 0.17899821595460905, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14094250467360328, 0.14094250467360328, 0.22472842263624038], 
reward next is 0.7753, 
noisyNet noise sample is [array([-0.8766291], dtype=float32), -0.6213388]. 
=============================================
[2019-04-27 18:37:02,804] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[73.88078]
 [73.88379]
 [73.87468]
 [73.85538]
 [74.11253]], R is [[73.93946075]
 [73.97601318]
 [74.01209259]
 [74.0486908 ]
 [74.08078766]].
[2019-04-27 18:37:04,892] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.1754313e-10 9.9999964e-01 6.0876269e-16 9.2980779e-09 3.5177615e-07], sum to 1.0000
[2019-04-27 18:37:04,901] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4264
[2019-04-27 18:37:04,907] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1430098.446430949 W.
[2019-04-27 18:37:04,910] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.8, 49.00000000000001, 1.0, 2.0, 0.9796578290106462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.389041717412804, 6.9112, 121.9243302930401, 1430098.446430949, 1185404.214628093, 239191.8871748963], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7737600.0000, 
sim time next is 7738200.0000, 
raw observation next is [29.0, 48.0, 1.0, 2.0, 0.595420427871939, 0.0, 2.0, 0.0, 1.0, 1.0, 0.958679964955578, 6.9112, 6.9112, 121.9257548675734, 1421823.572350914, 1421823.572350914, 290509.1765270021], 
processed observation next is [1.0, 0.5652173913043478, 0.6296296296296297, 0.48, 1.0, 1.0, 0.5183576522284988, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.9483499561944725, 0.0, 0.0, 0.809460218472066, 0.5077941329824692, 0.5077941329824692, 0.558671493321158], 
reward next is 0.4413, 
noisyNet noise sample is [array([0.13070108], dtype=float32), -0.86934847]. 
=============================================
[2019-04-27 18:37:06,678] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.3185880e-10 9.9726653e-01 4.4095201e-16 1.4134650e-08 2.7334576e-03], sum to 1.0000
[2019-04-27 18:37:06,687] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3911
[2019-04-27 18:37:06,693] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.1, 62.33333333333334, 1.0, 2.0, 0.3206714923171368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 407942.9510283774, 407942.9510283774, 118162.4584656018], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7795200.0000, 
sim time next is 7795800.0000, 
raw observation next is [22.3, 61.5, 1.0, 2.0, 0.320832217644189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 407902.0004886099, 407902.0004886099, 118181.4393829911], 
processed observation next is [1.0, 0.21739130434782608, 0.38148148148148153, 0.615, 1.0, 1.0, 0.19146692576689167, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14567928588878926, 0.14567928588878926, 0.22727199881344443], 
reward next is 0.7727, 
noisyNet noise sample is [array([0.22337343], dtype=float32), 0.43761542]. 
=============================================
[2019-04-27 18:37:07,828] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.3950764e-10 9.9970955e-01 2.3547884e-18 1.0241763e-08 2.9046697e-04], sum to 1.0000
[2019-04-27 18:37:07,843] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9298
[2019-04-27 18:37:07,849] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.06666666666667, 72.0, 1.0, 2.0, 0.3880338432937605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 491238.85314851, 491238.8531485095, 127119.0357887715], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7784400.0000, 
sim time next is 7785000.0000, 
raw observation next is [21.1, 71.5, 1.0, 2.0, 0.3617771086920903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 458227.8575588129, 458227.8575588129, 123527.794654248], 
processed observation next is [1.0, 0.08695652173913043, 0.3370370370370371, 0.715, 1.0, 1.0, 0.24021084368105988, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1636528062710046, 0.1636528062710046, 0.23755345125816923], 
reward next is 0.7624, 
noisyNet noise sample is [array([-0.3792669], dtype=float32), 0.75677615]. 
=============================================
[2019-04-27 18:37:07,866] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[62.02718 ]
 [62.042515]
 [62.25439 ]
 [62.323666]
 [62.530056]], R is [[61.9151001 ]
 [62.05148697]
 [62.16964722]
 [62.31899261]
 [62.46644592]].
[2019-04-27 18:37:08,239] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1706200e-09 9.9987292e-01 7.9829375e-17 2.5412914e-09 1.2711102e-04], sum to 1.0000
[2019-04-27 18:37:08,250] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5097
[2019-04-27 18:37:08,258] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1381797.243442284 W.
[2019-04-27 18:37:08,261] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.4, 39.0, 1.0, 2.0, 0.9510711748248154, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.319804508311162, 6.9112, 121.9243252867923, 1381797.243442284, 1172558.161705369, 233070.8110615808], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7819200.0000, 
sim time next is 7819800.0000, 
raw observation next is [29.5, 38.33333333333334, 1.0, 2.0, 0.5531281079051525, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9045022189305603, 6.9112, 6.9112, 121.9257965611009, 1351987.577350613, 1351987.577350613, 273033.751669601], 
processed observation next is [1.0, 0.5217391304347826, 0.6481481481481481, 0.3833333333333334, 1.0, 1.0, 0.4680096522680387, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.8806277736632003, 0.0, 0.0, 0.8094604952737302, 0.4828527061966475, 0.4828527061966475, 0.525064907056925], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.19795324], dtype=float32), -0.29610756]. 
=============================================
[2019-04-27 18:37:09,502] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.3835587e-07 9.9580741e-01 5.5255231e-11 1.6479555e-05 4.1751028e-03], sum to 1.0000
[2019-04-27 18:37:09,509] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8098
[2019-04-27 18:37:09,515] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1458801.415238946 W.
[2019-04-27 18:37:09,520] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.5, 36.66666666666667, 1.0, 2.0, 0.6056911799213904, 1.0, 1.0, 0.6056911799213904, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156056, 1458801.415238946, 1458801.415238946, 273361.2211027736], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7825800.0000, 
sim time next is 7826400.0000, 
raw observation next is [30.6, 37.0, 1.0, 2.0, 0.6672147119404002, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9591723271818855, 6.911199999999999, 6.9112, 121.9260426156618, 1519813.890261817, 1519813.890261818, 301615.4608827934], 
processed observation next is [1.0, 0.6086956521739131, 0.688888888888889, 0.37, 1.0, 1.0, 0.603827038024286, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9489654089773569, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5427906750935061, 0.5427906750935064, 0.5800297324669104], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.31041843], dtype=float32), -0.96159756]. 
=============================================
[2019-04-27 18:37:15,836] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.6601596e-09 4.7926395e-03 6.3807724e-14 8.2087608e-05 9.9512523e-01], sum to 1.0000
[2019-04-27 18:37:15,841] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4023
[2019-04-27 18:37:15,845] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.1, 48.66666666666666, 1.0, 2.0, 0.5050970384087774, 1.0, 2.0, 0.5050970384087774, 1.0, 2.0, 0.80413093500889, 6.9112, 6.9112, 121.94756008, 1728027.421033822, 1728027.421033822, 346097.7744663638], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7921200.0000, 
sim time next is 7921800.0000, 
raw observation next is [30.1, 49.0, 1.0, 2.0, 0.5126867695852123, 1.0, 2.0, 0.5126867695852123, 1.0, 2.0, 0.8162140342220622, 6.9112, 6.9112, 121.94756008, 1754018.738754771, 1754018.738754771, 349859.5057202979], 
processed observation next is [1.0, 0.6956521739130435, 0.6703703703703704, 0.49, 1.0, 1.0, 0.4198652018871575, 1.0, 1.0, 0.4198652018871575, 1.0, 1.0, 0.7702675427775776, 0.0, 0.0, 0.8096049824067558, 0.6264352638409896, 0.6264352638409896, 0.6728067417698037], 
reward next is 0.3272, 
noisyNet noise sample is [array([-1.4683841], dtype=float32), -0.53198546]. 
=============================================
[2019-04-27 18:37:16,286] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 18:37:16,286] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:37:16,288] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run3
[2019-04-27 18:37:16,447] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 18:37:16,447] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:37:16,449] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run3
[2019-04-27 18:37:16,486] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 18:37:16,486] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:37:16,488] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run3
[2019-04-27 18:37:16,877] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 18:37:16,878] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:37:16,879] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run3
[2019-04-27 18:37:16,944] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 18:37:16,945] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:37:16,946] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run3
[2019-04-27 18:37:17,016] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 18:37:17,016] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:37:17,018] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run3
[2019-04-27 18:37:17,036] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 18:37:17,037] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:37:17,038] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run3
[2019-04-27 18:37:17,081] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 18:37:17,081] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:37:17,083] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run3
[2019-04-27 18:37:17,105] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 18:37:17,106] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:37:17,108] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run3
[2019-04-27 18:37:17,130] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 18:37:17,131] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:37:17,133] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run3
[2019-04-27 18:37:17,155] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 18:37:17,155] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:37:17,159] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run3
[2019-04-27 18:37:17,225] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 18:37:17,225] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:37:17,226] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run3
[2019-04-27 18:37:17,315] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 18:37:17,315] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:37:17,317] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run3
[2019-04-27 18:37:17,375] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 18:37:17,375] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:37:17,377] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run3
[2019-04-27 18:37:17,423] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 18:37:17,423] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:37:17,425] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run3
[2019-04-27 18:37:17,453] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 18:37:17,453] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:37:17,455] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run3
[2019-04-27 18:37:19,222] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.18288546e-04 9.06102080e-03 6.53277477e-09 5.14089921e-03
 9.85679746e-01], sum to 1.0000
[2019-04-27 18:37:19,230] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5758
[2019-04-27 18:37:19,234] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [18.3, 76.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 1.0, 0.2, 6.911199999999999, 6.9112, 121.94756008, 362428.1078156051, 362428.1078156055, 168673.6868401773], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 10800.0000, 
sim time next is 11400.0000, 
raw observation next is [18.26666666666667, 76.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2, 6.9112, 6.9112, 121.94756008, 425321.98025482, 425321.98025482, 178992.5786868383], 
processed observation next is [1.0, 0.13043478260869565, 0.23209876543209887, 0.76, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.8096049824067558, 0.15190070723386428, 0.15190070723386428, 0.344216497474689], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2375509], dtype=float32), 2.2034655]. 
=============================================
[2019-04-27 18:37:20,454] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-04-27 18:37:20,456] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 18:37:20,456] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:37:20,457] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 18:37:20,458] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:37:20,459] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 18:37:20,459] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 18:37:20,460] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:37:20,460] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 18:37:20,460] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:37:20,463] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:37:20,477] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run18
[2019-04-27 18:37:20,496] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run18
[2019-04-27 18:37:20,516] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run18
[2019-04-27 18:37:20,536] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run18
[2019-04-27 18:37:20,555] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run18
[2019-04-27 18:37:38,151] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.058465827]
[2019-04-27 18:37:38,151] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [18.978688765, 89.89845282, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2, 6.911199999999999, 6.9112, 121.94756008, 418248.2599685672, 418248.2599685676, 180970.5263336734]
[2019-04-27 18:37:38,153] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 18:37:38,156] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.4796597e-05 4.6981899e-03 1.7382902e-08 1.2227778e-03 9.9400419e-01], sampled 0.29895495268814276
[2019-04-27 18:37:45,933] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.058465827]
[2019-04-27 18:37:45,936] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [19.0, 94.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2, 6.9112, 6.9112, 121.94756008, 429357.3079356989, 429357.3079356989, 183626.1331809491]
[2019-04-27 18:37:45,938] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 18:37:45,940] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [7.5664633e-05 4.6246583e-03 1.7072683e-08 1.1799110e-03 9.9411976e-01], sampled 0.8302811015334661
[2019-04-27 18:37:52,572] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.058465827]
[2019-04-27 18:37:52,573] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [19.59066421166667, 71.48716237166667, 1.0, 2.0, 0.1687054452600327, 1.0, 2.0, 0.1687054452600327, 1.0, 2.0, 0.2912099247102707, 6.9112, 6.9112, 121.94756008, 642534.9329284694, 642534.9329284694, 206529.5348660185]
[2019-04-27 18:37:52,573] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 18:37:52,577] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.8251214e-05 2.8164596e-03 2.5709161e-09 7.4264663e-04 9.9641269e-01], sampled 0.027189894323038755
[2019-04-27 18:37:53,768] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.058465827]
[2019-04-27 18:37:53,770] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.06666666666667, 77.66666666666667, 1.0, 2.0, 0.4908171091512469, 1.0, 2.0, 0.4908171091512469, 1.0, 2.0, 0.7819477877003723, 6.9112, 6.9112, 121.94756008, 1694602.162093682, 1694602.162093682, 339194.4976951792]
[2019-04-27 18:37:53,771] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 18:37:53,774] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.3649705e-06 1.1627600e-03 4.2501816e-10 3.3857467e-04 9.9848926e-01], sampled 0.748440653968752
[2019-04-27 18:38:24,557] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.058465827]
[2019-04-27 18:38:24,560] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.02438829, 89.85489441666667, 1.0, 2.0, 0.4865761022662948, 1.0, 2.0, 0.4865761022662948, 1.0, 2.0, 0.7746450014852779, 6.9112, 6.9112, 121.94756008, 1664604.957456021, 1664604.957456021, 337049.2910913784]
[2019-04-27 18:38:24,562] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 18:38:24,563] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.5811233e-05 1.6065380e-03 1.0662784e-09 4.4627418e-04 9.9793136e-01], sampled 0.18535311045667668
[2019-04-27 18:38:32,099] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.058465827]
[2019-04-27 18:38:32,100] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.23333333333333, 79.66666666666667, 1.0, 2.0, 0.2066308281035711, 1.0, 2.0, 0.2066308281035711, 1.0, 2.0, 0.3289630078371459, 6.9112, 6.9112, 121.94756008, 706459.9410488922, 706459.9410488922, 222772.8030942269]
[2019-04-27 18:38:32,101] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 18:38:32,105] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.4200569e-05 1.8073405e-03 6.5049788e-10 3.4943310e-04 9.9782902e-01], sampled 0.8279010568822447
[2019-04-27 18:38:38,861] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.058465827]
[2019-04-27 18:38:38,862] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.0, 62.0, 1.0, 2.0, 0.3962771177546221, 1.0, 2.0, 0.3962771177546221, 1.0, 2.0, 0.6316287493675119, 6.9112, 6.9112, 121.94756008, 1372970.064241804, 1372970.064241804, 295529.7675147395]
[2019-04-27 18:38:38,863] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 18:38:38,866] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.3363055e-05 3.3118932e-03 9.9282946e-09 8.6555060e-04 9.9576926e-01], sampled 0.2579237588479627
[2019-04-27 18:38:39,332] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.058465827]
[2019-04-27 18:38:39,335] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.35, 55.5, 1.0, 2.0, 0.1832808196449695, 1.0, 2.0, 0.1832808196449695, 1.0, 2.0, 0.2920843041391529, 6.9112, 6.9112, 121.94756008, 633944.7286852846, 633944.7286852846, 215208.0709315147]
[2019-04-27 18:38:39,336] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 18:38:39,337] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.0854110e-06 1.4898283e-03 2.6587918e-10 2.4446688e-04 9.9825662e-01], sampled 0.5205896280176013
[2019-04-27 18:38:44,707] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.058465827]
[2019-04-27 18:38:44,708] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.8, 92.66666666666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2520862121691246, 6.9112, 6.9112, 121.94756008, 559184.9004124514, 559184.9004124514, 206096.2175749823]
[2019-04-27 18:38:44,709] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 18:38:44,713] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.6008117e-05 3.5655152e-03 6.5189036e-09 8.9228031e-04 9.9549615e-01], sampled 0.43674610037171224
[2019-04-27 18:38:58,863] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.058465827]
[2019-04-27 18:38:58,867] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [18.173492665, 101.33358503, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2018036484462335, 6.9112, 6.9112, 121.94756008, 451967.0254147432, 451967.0254147432, 187586.4184341453]
[2019-04-27 18:38:58,868] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 18:38:58,871] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.2027216e-05 2.8724074e-03 3.0240739e-09 6.1018026e-04 9.9648535e-01], sampled 0.9013248840798199
[2019-04-27 18:38:59,036] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.058465827]
[2019-04-27 18:38:59,037] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.5, 75.0, 1.0, 2.0, 0.1959740884031974, 1.0, 2.0, 0.1959740884031974, 1.0, 2.0, 0.3119971311683688, 6.9112, 6.9112, 121.94756008, 670009.1886953064, 670009.1886953064, 219284.2326123598]
[2019-04-27 18:38:59,038] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 18:38:59,041] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.6062464e-05 1.9217159e-03 8.2282314e-10 3.7141124e-04 9.9769080e-01], sampled 0.7453637793615314
[2019-04-27 18:39:08,493] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 4283.7382 2917593855.0663 33.0000
[2019-04-27 18:39:08,559] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 4513.8735 3105122550.5627 2.0000
[2019-04-27 18:39:08,735] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 4620.1365 2892884173.1652 13.0000
[2019-04-27 18:39:08,752] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 4394.2306 2872322403.6234 10.0000
[2019-04-27 18:39:08,759] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 4490.2892 2938502437.0408 28.0000
[2019-04-27 18:39:09,775] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 425000, evaluation results [425000.0, 4513.873537866867, 3105122550.56267, 2.0, 4620.136465874452, 2892884173.1652484, 13.0, 4394.230582331608, 2872322403.623391, 10.0, 4490.289236404695, 2938502437.0408416, 28.0, 4283.738185263215, 2917593855.0663443, 33.0]
[2019-04-27 18:39:14,219] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.8238372e-05 1.0137048e-02 3.7899461e-09 7.9212862e-04 9.8904258e-01], sum to 1.0000
[2019-04-27 18:39:14,229] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3127
[2019-04-27 18:39:14,236] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [37.4, 15.0, 1.0, 2.0, 0.43611298442325, 1.0, 2.0, 0.43611298442325, 1.0, 2.0, 0.704589372159433, 6.911200000000001, 6.9112, 121.94756008, 1572336.474172786, 1572336.474172785, 312825.1235423491], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 136800.0000, 
sim time next is 137400.0000, 
raw observation next is [37.4, 14.5, 1.0, 2.0, 0.475397277818377, 1.0, 2.0, 0.475397277818377, 1.0, 2.0, 0.7681978629136148, 6.9112, 6.9112, 121.94756008, 1714647.627391503, 1714647.627391503, 331217.9783441977], 
processed observation next is [1.0, 0.6086956521739131, 0.9407407407407407, 0.145, 1.0, 1.0, 0.37547294978378215, 1.0, 1.0, 0.37547294978378215, 1.0, 1.0, 0.7102473286420186, 0.0, 0.0, 0.8096049824067558, 0.6123741526398225, 0.6123741526398225, 0.6369576506619186], 
reward next is 0.3630, 
noisyNet noise sample is [array([0.8749591], dtype=float32), -0.4148889]. 
=============================================
[2019-04-27 18:39:15,202] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.2874584e-08 4.4957374e-04 3.5714290e-14 4.1539872e-05 9.9950886e-01], sum to 1.0000
[2019-04-27 18:39:15,213] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6385
[2019-04-27 18:39:15,220] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.5, 46.0, 1.0, 2.0, 0.4117216419122046, 1.0, 2.0, 0.4117216419122046, 1.0, 2.0, 0.6558329957451631, 6.911199999999999, 6.9112, 121.94756008, 1419180.727987398, 1419180.727987398, 302317.6437473297], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 126000.0000, 
sim time next is 126600.0000, 
raw observation next is [30.88333333333333, 44.0, 1.0, 2.0, 0.4557033529915615, 1.0, 2.0, 0.4557033529915615, 1.0, 2.0, 0.7258339065273627, 6.911200000000001, 6.9112, 121.94756008, 1569660.155880899, 1569660.155880899, 322413.2392497975], 
processed observation next is [1.0, 0.4782608695652174, 0.6993827160493825, 0.44, 1.0, 1.0, 0.35202780118043037, 1.0, 1.0, 0.35202780118043037, 1.0, 1.0, 0.6572923831592034, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5605929128146068, 0.5605929128146068, 0.6200254600957644], 
reward next is 0.3800, 
noisyNet noise sample is [array([0.9566341], dtype=float32), 0.090920396]. 
=============================================
[2019-04-27 18:39:20,833] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.8412906e-11 9.9999225e-01 1.5518112e-22 1.3188469e-08 7.7785826e-06], sum to 1.0000
[2019-04-27 18:39:20,841] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9642
[2019-04-27 18:39:20,848] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.33333333333333, 13.33333333333333, 1.0, 2.0, 0.3768583626498536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 485775.5694201395, 485775.5694201395, 125586.4697225247], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 224400.0000, 
sim time next is 225000.0000, 
raw observation next is [33.34999999999999, 13.5, 1.0, 2.0, 0.3775442400541742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 486420.565585551, 486420.5655855506, 125682.7348079272], 
processed observation next is [0.0, 0.6086956521739131, 0.7907407407407403, 0.135, 1.0, 1.0, 0.2589812381597312, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17372163056626821, 0.17372163056626808, 0.24169756693832156], 
reward next is 0.7583, 
noisyNet noise sample is [array([-0.12954308], dtype=float32), 0.26502234]. 
=============================================
[2019-04-27 18:39:20,865] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[83.84046 ]
 [83.72506 ]
 [83.62334 ]
 [83.47691 ]
 [83.347336]], R is [[83.87065887]
 [83.79043579]
 [83.71131897]
 [83.63327026]
 [83.55634308]].
[2019-04-27 18:39:27,914] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.43380655e-11 9.99998331e-01 5.30434221e-19 6.58297736e-08
 1.56433111e-06], sum to 1.0000
[2019-04-27 18:39:27,921] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6770
[2019-04-27 18:39:27,929] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.35, 52.5, 1.0, 2.0, 0.2634414910418191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 339820.6988103485, 339820.6988103485, 102688.3589830012], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 351000.0000, 
sim time next is 351600.0000, 
raw observation next is [21.2, 53.0, 1.0, 2.0, 0.2615382937437919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 337365.170336205, 337365.170336205, 101830.890899253], 
processed observation next is [1.0, 0.043478260869565216, 0.34074074074074073, 0.53, 1.0, 1.0, 0.12087892112356179, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.12048756083435892, 0.12048756083435892, 0.1958286363447173], 
reward next is 0.8042, 
noisyNet noise sample is [array([0.03140559], dtype=float32), -0.9232147]. 
=============================================
[2019-04-27 18:39:28,121] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.6673739e-11 9.9998260e-01 1.9467360e-16 2.1398455e-07 1.7113982e-05], sum to 1.0000
[2019-04-27 18:39:28,133] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1874
[2019-04-27 18:39:28,138] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.2, 32.5, 1.0, 2.0, 0.8850200766303133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.107572117701318, 6.9112, 121.9250273248542, 1233738.055122334, 1133178.816692729, 218404.487276441], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 381000.0000, 
sim time next is 381600.0000, 
raw observation next is [27.4, 32.0, 1.0, 2.0, 0.8907213240981531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.144148633159764, 6.9112, 121.9248430278358, 1259255.07446384, 1139965.727231317, 219706.624479028], 
processed observation next is [1.0, 0.43478260869565216, 0.5703703703703703, 0.32, 1.0, 1.0, 0.869906338212087, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.02329486331597641, 0.0, 0.8094541648044548, 0.4497339551656572, 0.40713061686832747, 0.42251273938274614], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.333883], dtype=float32), 0.7849149]. 
=============================================
[2019-04-27 18:39:28,651] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.5161074e-13 9.9999952e-01 1.1497306e-19 8.7702304e-08 3.3017449e-07], sum to 1.0000
[2019-04-27 18:39:28,661] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1810
[2019-04-27 18:39:28,667] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.7, 68.0, 1.0, 2.0, 0.2372281749293574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 306000.6487118529, 306000.6487118529, 89868.51085617523], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 363600.0000, 
sim time next is 364200.0000, 
raw observation next is [18.11666666666667, 66.0, 1.0, 2.0, 0.2418719804256458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 311991.9122583827, 311991.9122583827, 91227.67017810735], 
processed observation next is [1.0, 0.21739130434782608, 0.22654320987654336, 0.66, 1.0, 1.0, 0.09746664336386406, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1114256829494224, 0.1114256829494224, 0.17543782726559107], 
reward next is 0.8246, 
noisyNet noise sample is [array([-0.17129235], dtype=float32), -1.4360936]. 
=============================================
[2019-04-27 18:39:29,014] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.8968553e-10 9.9997938e-01 1.9469014e-15 2.0797931e-06 1.8538127e-05], sum to 1.0000
[2019-04-27 18:39:29,021] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8216
[2019-04-27 18:39:29,026] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.43333333333334, 43.33333333333334, 1.0, 2.0, 0.391648088768946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 505252.5290949339, 505252.5290949339, 124941.3659417881], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 372000.0000, 
sim time next is 372600.0000, 
raw observation next is [23.85, 42.0, 1.0, 2.0, 0.3927432815619978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 506665.868683465, 506665.868683465, 126286.3028752449], 
processed observation next is [1.0, 0.30434782608695654, 0.43888888888888894, 0.42, 1.0, 1.0, 0.2770753351928545, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18095209595838035, 0.18095209595838035, 0.24285827476008634], 
reward next is 0.7571, 
noisyNet noise sample is [array([0.4539972], dtype=float32), 1.2918302]. 
=============================================
[2019-04-27 18:39:29,410] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.5451011e-10 9.9999774e-01 7.7367592e-17 5.2532442e-07 1.7975219e-06], sum to 1.0000
[2019-04-27 18:39:29,415] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9050
[2019-04-27 18:39:29,419] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.4, 32.0, 1.0, 2.0, 0.8907213240981531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.144148633159764, 6.9112, 121.9248430278358, 1259255.07446384, 1139965.727231317, 219706.624479028], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 381600.0000, 
sim time next is 382200.0000, 
raw observation next is [27.58333333333333, 31.5, 1.0, 2.0, 0.8574485204146501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.912057744659263, 6.9112, 121.92561940148, 1097341.034294007, 1096901.793888757, 212185.9657645609], 
processed observation next is [1.0, 0.43478260869565216, 0.5771604938271603, 0.315, 1.0, 1.0, 0.8302958576364883, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.577446592630266e-05, 0.0, 0.8094593191180806, 0.3919075122478597, 0.39175064067455606, 0.40804993416261715], 
reward next is 0.5877, 
noisyNet noise sample is [array([0.25896195], dtype=float32), 0.5378112]. 
=============================================
[2019-04-27 18:39:32,437] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.4015168e-11 9.9999988e-01 5.8031571e-18 3.6400694e-09 6.2086805e-08], sum to 1.0000
[2019-04-27 18:39:32,442] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7291
[2019-04-27 18:39:32,449] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1578979.903754656 W.
[2019-04-27 18:39:32,456] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.83333333333333, 28.5, 1.0, 2.0, 0.4385425096678819, 1.0, 2.0, 0.4385425096678819, 1.0, 2.0, 0.7079740012632043, 6.911200000000001, 6.9112, 121.94756008, 1578979.903754656, 1578979.903754656, 313985.3043978107], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 481800.0000, 
sim time next is 482400.0000, 
raw observation next is [32.0, 28.0, 1.0, 2.0, 0.4417781252611077, 1.0, 2.0, 0.4417781252611077, 1.0, 2.0, 0.7130133456707877, 6.9112, 6.9112, 121.94756008, 1589900.292907556, 1589900.292907556, 315493.5587520462], 
processed observation next is [1.0, 0.6086956521739131, 0.7407407407407407, 0.28, 1.0, 1.0, 0.3354501491203663, 1.0, 1.0, 0.3354501491203663, 1.0, 1.0, 0.6412666820884846, 0.0, 0.0, 0.8096049824067558, 0.56782153318127, 0.56782153318127, 0.6067183822154735], 
reward next is 0.3933, 
noisyNet noise sample is [array([-0.20964238], dtype=float32), 1.2277844]. 
=============================================
[2019-04-27 18:39:33,873] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.7871313e-10 9.9999988e-01 1.5153883e-16 1.2638214e-08 1.7049700e-07], sum to 1.0000
[2019-04-27 18:39:33,884] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4451
[2019-04-27 18:39:33,889] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.88333333333333, 48.83333333333333, 1.0, 2.0, 0.7655419863217277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 969359.8148844108, 969359.8148844104, 192376.7398699148], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 463800.0000, 
sim time next is 464400.0000, 
raw observation next is [25.2, 48.0, 1.0, 2.0, 0.7383933792942095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 933654.3363187202, 933654.3363187202, 186820.4754391763], 
processed observation next is [1.0, 0.391304347826087, 0.4888888888888889, 0.48, 1.0, 1.0, 0.6885635467788208, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3334479772566858, 0.3334479772566858, 0.35927014507533905], 
reward next is 0.6407, 
noisyNet noise sample is [array([-0.5420051], dtype=float32), -0.89448684]. 
=============================================
[2019-04-27 18:39:34,165] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2237307e-08 9.9999821e-01 1.1738623e-15 1.3516747e-07 1.6467521e-06], sum to 1.0000
[2019-04-27 18:39:34,175] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0820
[2019-04-27 18:39:34,182] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1380339.857615538 W.
[2019-04-27 18:39:34,185] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.35, 25.0, 1.0, 2.0, 0.3779561232915186, 1.0, 1.0, 0.3779561232915186, 1.0, 2.0, 0.6160543400748385, 6.9112, 6.9112, 121.94756008, 1380339.857615538, 1380339.857615538, 286530.5343742061], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 487800.0000, 
sim time next is 488400.0000, 
raw observation next is [32.4, 24.66666666666667, 1.0, 2.0, 0.5534164731599205, 1.0, 2.0, 0.5534164731599205, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1357072.800088481, 1357072.800088481, 256187.9226732902], 
processed observation next is [1.0, 0.6521739130434783, 0.7555555555555555, 0.2466666666666667, 1.0, 1.0, 0.46835294423800056, 1.0, 1.0, 0.46835294423800056, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4846688571744575, 0.4846688571744575, 0.4926690820640196], 
reward next is 0.5073, 
noisyNet noise sample is [array([0.6917005], dtype=float32), -0.8376443]. 
=============================================
[2019-04-27 18:39:36,146] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.0118392e-09 9.9971384e-01 1.3184933e-14 2.1868357e-07 2.8588966e-04], sum to 1.0000
[2019-04-27 18:39:36,153] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5727
[2019-04-27 18:39:36,157] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.46666666666667, 47.16666666666666, 1.0, 2.0, 0.3335143476090035, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 421654.4595051919, 421654.4595051919, 119789.2496177124], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 510600.0000, 
sim time next is 511200.0000, 
raw observation next is [25.2, 48.0, 1.0, 2.0, 0.331816353703491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 419873.7658518224, 419873.7658518224, 119573.4945579188], 
processed observation next is [1.0, 0.9565217391304348, 0.4888888888888889, 0.48, 1.0, 1.0, 0.20454327821844168, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14995491637565087, 0.14995491637565087, 0.2299490279959977], 
reward next is 0.7701, 
noisyNet noise sample is [array([1.280107], dtype=float32), 0.8214789]. 
=============================================
[2019-04-27 18:39:36,498] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.3271118e-09 9.9794167e-01 2.1536686e-16 9.5240955e-07 2.0573460e-03], sum to 1.0000
[2019-04-27 18:39:36,502] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3289
[2019-04-27 18:39:36,509] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.6, 53.0, 1.0, 2.0, 0.3136569475441648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 399175.0892156783, 399175.0892156783, 117275.0900786458], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 514800.0000, 
sim time next is 515400.0000, 
raw observation next is [23.43333333333333, 54.0, 1.0, 2.0, 0.3130455575148792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 398469.8502616474, 398469.8502616469, 117198.5845507922], 
processed observation next is [1.0, 1.0, 0.42345679012345666, 0.54, 1.0, 1.0, 0.18219709227961814, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14231066080773122, 0.14231066080773103, 0.2253818933669081], 
reward next is 0.7746, 
noisyNet noise sample is [array([-0.4329589], dtype=float32), -1.0466694]. 
=============================================
[2019-04-27 18:39:38,589] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0112219e-06 1.7207202e-01 4.2661472e-13 2.2206389e-04 8.2770491e-01], sum to 1.0000
[2019-04-27 18:39:38,597] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3215
[2019-04-27 18:39:38,602] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.46666666666667, 35.66666666666666, 1.0, 2.0, 0.4205855440839787, 1.0, 2.0, 0.4205855440839787, 1.0, 2.0, 0.6762474441293461, 6.911199999999999, 6.9112, 121.94756008, 1502169.042809665, 1502169.042809666, 306013.0266588351], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 568200.0000, 
sim time next is 568800.0000, 
raw observation next is [30.6, 35.0, 1.0, 2.0, 0.4052576165001706, 1.0, 2.0, 0.4052576165001706, 1.0, 2.0, 0.651930336090081, 6.911199999999999, 6.9112, 121.94756008, 1448961.609252728, 1448961.609252728, 299143.3812159903], 
processed observation next is [1.0, 0.6086956521739131, 0.688888888888889, 0.35, 1.0, 1.0, 0.2919733529763936, 1.0, 1.0, 0.2919733529763936, 1.0, 1.0, 0.5649129201126012, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5174862890188314, 0.5174862890188314, 0.5752757331076737], 
reward next is 0.4247, 
noisyNet noise sample is [array([-0.6810719], dtype=float32), 1.2870831]. 
=============================================
[2019-04-27 18:39:40,921] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.0051017e-07 9.6934533e-01 5.4524354e-13 1.7366743e-05 3.0636987e-02], sum to 1.0000
[2019-04-27 18:39:40,928] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9616
[2019-04-27 18:39:40,934] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.16666666666667, 57.0, 1.0, 2.0, 0.4416331105831963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 555148.0899734411, 555148.0899734411, 134787.7030915619], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 631200.0000, 
sim time next is 631800.0000, 
raw observation next is [24.45, 56.0, 1.0, 2.0, 0.4578880197557789, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 574934.2751851243, 574934.2751851243, 137217.5998403201], 
processed observation next is [1.0, 0.30434782608695654, 0.4611111111111111, 0.56, 1.0, 1.0, 0.3546285949473559, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20533366970897296, 0.20533366970897296, 0.26387999969292325], 
reward next is 0.7361, 
noisyNet noise sample is [array([1.161689], dtype=float32), 0.5617614]. 
=============================================
[2019-04-27 18:39:54,059] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.5189081e-17 9.9999976e-01 2.2313879e-22 5.0543777e-14 2.1842133e-07], sum to 1.0000
[2019-04-27 18:39:54,066] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1050
[2019-04-27 18:39:54,072] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.93333333333333, 36.0, 1.0, 2.0, 0.4489188958404463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 545137.7748510193, 545137.7748510193, 135426.9419153685], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 834000.0000, 
sim time next is 834600.0000, 
raw observation next is [31.96666666666667, 36.0, 1.0, 2.0, 0.4499147813351945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 546117.2340988846, 546117.2340988846, 135568.2262743013], 
processed observation next is [0.0, 0.6521739130434783, 0.7395061728395063, 0.36, 1.0, 1.0, 0.3451366444466602, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19504186932103024, 0.19504186932103024, 0.2607081274505794], 
reward next is 0.7393, 
noisyNet noise sample is [array([-0.31123152], dtype=float32), -1.7632947]. 
=============================================
[2019-04-27 18:39:56,269] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.8079521e-14 1.0000000e+00 3.9896593e-21 8.8169066e-13 9.5000781e-09], sum to 1.0000
[2019-04-27 18:39:56,276] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7500
[2019-04-27 18:39:56,282] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.93333333333334, 66.66666666666667, 1.0, 2.0, 0.3474193534320039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 439434.6684181796, 439434.6684181796, 121608.7052850023], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 876000.0000, 
sim time next is 876600.0000, 
raw observation next is [21.85, 66.5, 1.0, 2.0, 0.3429790681987868, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 434309.4052427977, 434309.4052427977, 121029.4824522859], 
processed observation next is [0.0, 0.13043478260869565, 0.36481481481481487, 0.665, 1.0, 1.0, 0.21783222404617478, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15511050187242775, 0.15511050187242775, 0.23274900471593443], 
reward next is 0.7673, 
noisyNet noise sample is [array([-0.23878683], dtype=float32), 1.1450531]. 
=============================================
[2019-04-27 18:40:00,720] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.8134039e-11 9.9999809e-01 3.1243385e-16 2.2220159e-10 1.9401741e-06], sum to 1.0000
[2019-04-27 18:40:00,733] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0534
[2019-04-27 18:40:00,739] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.25, 54.0, 1.0, 2.0, 0.6487603307131428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999997, 6.9112, 121.9260425654539, 809641.9499323657, 809641.949932367, 169291.6431856262], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 995400.0000, 
sim time next is 996000.0000, 
raw observation next is [25.26666666666667, 53.66666666666666, 1.0, 2.0, 0.684956163055249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156465, 855378.7195319572, 855378.7195319572, 176128.1143867613], 
processed observation next is [1.0, 0.5217391304347826, 0.49135802469135814, 0.5366666666666666, 1.0, 1.0, 0.6249478131610107, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288200343, 0.3054923998328418, 0.3054923998328418, 0.3387079122822333], 
reward next is 0.6613, 
noisyNet noise sample is [array([-0.40507928], dtype=float32), 0.40458867]. 
=============================================
[2019-04-27 18:40:00,752] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[51.892773]
 [51.287796]
 [50.11978 ]
 [50.488686]
 [50.381012]], R is [[52.21470261]
 [52.36699295]
 [52.48390198]
 [51.95906448]
 [51.91901779]].
[2019-04-27 18:40:01,393] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-04-27 18:40:01,393] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 18:40:01,394] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:40:01,394] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 18:40:01,395] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 18:40:01,398] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 18:40:01,398] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:40:01,400] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:40:01,399] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 18:40:01,400] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:40:01,403] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:40:01,422] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run19
[2019-04-27 18:40:01,423] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run19
[2019-04-27 18:40:01,423] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run19
[2019-04-27 18:40:01,491] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run19
[2019-04-27 18:40:01,512] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run19
[2019-04-27 18:40:05,962] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.055596605]
[2019-04-27 18:40:05,964] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [15.73333333333333, 61.0, 1.0, 2.0, 0.183345390628842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 236486.5245980562, 236486.5245980562, 73682.20136815352]
[2019-04-27 18:40:05,964] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 18:40:05,966] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.9340739e-13 9.9999976e-01 1.1392702e-19 4.9964698e-12 2.6293503e-07], sampled 0.2969857837911867
[2019-04-27 18:40:29,940] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.055596605]
[2019-04-27 18:40:29,943] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [31.25, 49.5, 1.0, 2.0, 0.5635779201009963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 655526.4354074282, 655526.4354074282, 152554.5250223405]
[2019-04-27 18:40:29,944] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 18:40:29,947] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.10875955e-13 9.99999881e-01 1.89727073e-20 1.33389925e-12
 1.10070538e-07], sampled 0.14539379581662504
[2019-04-27 18:41:12,380] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.055596605]
[2019-04-27 18:41:12,381] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.81948108, 84.50394638666667, 1.0, 2.0, 0.7332014337846496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 835662.8480636203, 835662.8480636203, 182529.1235625859]
[2019-04-27 18:41:12,383] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 18:41:12,386] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.9738800e-13 9.9999988e-01 4.8031880e-20 2.0674146e-12 1.4329437e-07], sampled 0.6591195737043813
[2019-04-27 18:41:13,547] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.055596605]
[2019-04-27 18:41:13,550] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.54057063666667, 70.41592885666667, 1.0, 2.0, 0.898967942150145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260425973201, 1052527.747538145, 1052527.747538146, 218685.0846023553]
[2019-04-27 18:41:13,551] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 18:41:13,554] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.4223215e-13 9.9999976e-01 5.8991484e-20 2.6997152e-12 2.3809812e-07], sampled 0.7382348168921957
[2019-04-27 18:41:15,447] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.055596605]
[2019-04-27 18:41:15,447] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.16452859, 83.5647443, 1.0, 2.0, 0.6253693270322594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 712704.5796790391, 712704.5796790391, 162496.3311782033]
[2019-04-27 18:41:15,447] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 18:41:15,449] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.5113191e-13 9.9999976e-01 1.0570828e-19 3.9565157e-12 2.2183558e-07], sampled 0.42800215330612035
[2019-04-27 18:41:20,707] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.055596605]
[2019-04-27 18:41:20,709] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.14586415333333, 74.12438964333333, 1.0, 2.0, 0.4495209377128798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 545894.7125163986, 545894.7125163986, 135518.0108823828]
[2019-04-27 18:41:20,709] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 18:41:20,713] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [5.8162139e-13 9.9999976e-01 2.1720897e-19 6.5266256e-12 2.9393149e-07], sampled 0.18605107889937988
[2019-04-27 18:41:38,324] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.055596605]
[2019-04-27 18:41:38,324] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [17.783090625, 79.29765596166666, 1.0, 2.0, 0.2780194217166803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 358157.25994005, 358157.25994005, 109100.682743773]
[2019-04-27 18:41:38,326] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 18:41:38,330] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.7980691e-13 9.9999976e-01 7.2697628e-20 3.3546885e-12 1.9740064e-07], sampled 0.3713309781732441
[2019-04-27 18:41:42,076] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.055596605]
[2019-04-27 18:41:42,077] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [19.80715642, 101.3847626, 1.0, 2.0, 0.4039566737188717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 497598.6619258521, 497598.6619258521, 129108.780231476]
[2019-04-27 18:41:42,077] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 18:41:42,079] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [5.1997968e-13 9.9999976e-01 1.8744881e-19 5.5124104e-12 2.5582526e-07], sampled 0.16632831112498103
[2019-04-27 18:41:49,238] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.6127 2195087804.9157 572.0000
[2019-04-27 18:41:49,452] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8583.7021 2248718286.8236 553.0000
[2019-04-27 18:41:49,592] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-04-27 18:41:49,594] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8099.2009 2445441634.5394 746.0000
[2019-04-27 18:41:49,661] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-04-27 18:41:50,678] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 450000, evaluation results [450000.0, 8099.200854368861, 2445441634.539353, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8583.702050975664, 2248718286.823596, 553.0, 8701.61270960664, 2195087804.9156528, 572.0]
[2019-04-27 18:41:58,822] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.6638133e-16 1.0000000e+00 3.0118288e-21 4.6975558e-16 1.9588454e-12], sum to 1.0000
[2019-04-27 18:41:58,829] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3017
[2019-04-27 18:41:58,834] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.28333333333333, 75.0, 1.0, 2.0, 0.2867344858935714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 367928.1274377487, 367928.1274377482, 113951.6446843914], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1120200.0000, 
sim time next is 1120800.0000, 
raw observation next is [19.26666666666667, 75.0, 1.0, 2.0, 0.2849537331626347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 365702.3390423155, 365702.3390423155, 113735.8917092682], 
processed observation next is [1.0, 1.0, 0.2691358024691359, 0.75, 1.0, 1.0, 0.14875444424123183, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1306079782293984, 0.1306079782293984, 0.2187228686716696], 
reward next is 0.7813, 
noisyNet noise sample is [array([-1.4007014], dtype=float32), -0.09224973]. 
=============================================
[2019-04-27 18:41:59,520] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1969587e-13 1.0000000e+00 1.7730248e-19 7.5241971e-14 2.5083638e-10], sum to 1.0000
[2019-04-27 18:41:59,531] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7426
[2019-04-27 18:41:59,538] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.68333333333334, 70.5, 1.0, 2.0, 0.3294628033630741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 423519.5024312892, 423519.5024312892, 119289.9970123308], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1149000.0000, 
sim time next is 1149600.0000, 
raw observation next is [19.76666666666667, 70.0, 1.0, 2.0, 0.2908443325931241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 373825.8434021468, 373825.8434021468, 114448.4988708161], 
processed observation next is [1.0, 0.30434782608695654, 0.2876543209876544, 0.7, 1.0, 1.0, 0.155767062610862, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.133509229786481, 0.133509229786481, 0.22009326705926172], 
reward next is 0.7799, 
noisyNet noise sample is [array([1.6560377], dtype=float32), 0.64252853]. 
=============================================
[2019-04-27 18:42:02,425] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.6217147e-16 1.0000000e+00 4.7047818e-24 1.8291420e-16 6.2199014e-13], sum to 1.0000
[2019-04-27 18:42:02,433] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1037
[2019-04-27 18:42:02,446] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.13333333333333, 74.5, 1.0, 2.0, 0.41150106775716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 518369.6714902932, 518369.6714902932, 130404.9824148515], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1185000.0000, 
sim time next is 1185600.0000, 
raw observation next is [21.06666666666667, 75.0, 1.0, 2.0, 0.349302033376883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 440232.0371912596, 440232.0371912596, 121839.0077206635], 
processed observation next is [1.0, 0.7391304347826086, 0.3358024691358026, 0.75, 1.0, 1.0, 0.22535956354390832, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.157225727568307, 0.157225727568307, 0.23430578407819905], 
reward next is 0.7657, 
noisyNet noise sample is [array([0.617868], dtype=float32), -1.2936585]. 
=============================================
[2019-04-27 18:42:13,804] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.1533354e-16 9.9999726e-01 1.5223673e-22 3.9625150e-13 2.6980745e-06], sum to 1.0000
[2019-04-27 18:42:13,812] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8612
[2019-04-27 18:42:13,818] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.25, 26.83333333333333, 1.0, 2.0, 0.3624490010122657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 456916.8465035775, 456916.8465035775, 123594.4009224252], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1422600.0000, 
sim time next is 1423200.0000, 
raw observation next is [31.40000000000001, 26.66666666666667, 1.0, 2.0, 0.3629684655944183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 457226.832503281, 457226.832503281, 123659.856803491], 
processed observation next is [0.0, 0.4782608695652174, 0.7185185185185189, 0.2666666666666667, 1.0, 1.0, 0.24162912570764086, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16329529732260037, 0.16329529732260037, 0.23780741692979038], 
reward next is 0.7622, 
noisyNet noise sample is [array([-0.21887168], dtype=float32), -0.3587465]. 
=============================================
[2019-04-27 18:42:21,187] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.6820724e-16 1.0000000e+00 3.1376730e-24 8.8642125e-15 2.1485663e-08], sum to 1.0000
[2019-04-27 18:42:21,198] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9520
[2019-04-27 18:42:21,200] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [35.26666666666667, 22.66666666666666, 1.0, 2.0, 0.4143403480324461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 510569.1311850894, 510569.1311850894, 130590.9073011844], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1516800.0000, 
sim time next is 1517400.0000, 
raw observation next is [35.4, 22.0, 1.0, 2.0, 0.4136899427819726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 510516.1453257408, 510516.1453257408, 130516.2013522478], 
processed observation next is [0.0, 0.5652173913043478, 0.8666666666666666, 0.22, 1.0, 1.0, 0.3020118366452054, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18232719475919315, 0.18232719475919315, 0.25099269490816883], 
reward next is 0.7490, 
noisyNet noise sample is [array([0.11999928], dtype=float32), 1.055712]. 
=============================================
[2019-04-27 18:42:29,189] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.0154190e-14 1.0000000e+00 1.9648753e-18 9.5219683e-14 5.3047629e-09], sum to 1.0000
[2019-04-27 18:42:29,201] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2783
[2019-04-27 18:42:29,206] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.9, 90.0, 1.0, 2.0, 0.3107073455456359, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 396984.9496668494, 396984.9496668494, 116909.7907213155], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1659600.0000, 
sim time next is 1660200.0000, 
raw observation next is [17.93333333333333, 89.83333333333333, 1.0, 2.0, 0.3319504422226907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 424131.9871794934, 424131.9871794929, 119615.6352820963], 
processed observation next is [1.0, 0.21739130434782608, 0.21975308641975297, 0.8983333333333333, 1.0, 1.0, 0.20470290740796512, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15147570970696195, 0.15147570970696175, 0.23003006785018518], 
reward next is 0.7700, 
noisyNet noise sample is [array([-0.17015274], dtype=float32), -0.89370185]. 
=============================================
[2019-04-27 18:42:31,299] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.7483907e-16 1.0000000e+00 1.6616282e-21 9.8737038e-15 6.6253114e-12], sum to 1.0000
[2019-04-27 18:42:31,305] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8237
[2019-04-27 18:42:31,311] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666667, 81.66666666666667, 1.0, 2.0, 0.3770172609191569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 469536.1994119554, 469536.1994119554, 125479.141267147], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1734000.0000, 
sim time next is 1734600.0000, 
raw observation next is [21.13333333333334, 81.83333333333334, 1.0, 2.0, 0.3770124807688675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 469600.4347329807, 469600.4347329807, 125479.8826367746], 
processed observation next is [1.0, 0.043478260869565216, 0.33827160493827185, 0.8183333333333335, 1.0, 1.0, 0.25834819139150894, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16771444097606453, 0.16771444097606453, 0.2413074666091819], 
reward next is 0.7587, 
noisyNet noise sample is [array([2.6662626], dtype=float32), -0.26249725]. 
=============================================
[2019-04-27 18:42:31,831] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.3701281e-18 1.0000000e+00 9.2080677e-25 1.9437328e-18 7.2254859e-13], sum to 1.0000
[2019-04-27 18:42:31,838] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1587
[2019-04-27 18:42:31,845] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.65, 71.33333333333333, 1.0, 2.0, 0.4095201986084645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 503216.7171282189, 503216.7171282189, 129866.4557221211], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1705800.0000, 
sim time next is 1706400.0000, 
raw observation next is [23.6, 72.0, 1.0, 2.0, 0.4154250196840721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 510090.9518778319, 510090.9518778315, 130699.9686985656], 
processed observation next is [1.0, 0.782608695652174, 0.4296296296296297, 0.72, 1.0, 1.0, 0.30407740438580005, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18217533995636853, 0.1821753399563684, 0.2513460936510877], 
reward next is 0.7487, 
noisyNet noise sample is [array([-0.27039048], dtype=float32), 1.1476128]. 
=============================================
[2019-04-27 18:42:36,006] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.45607402e-07 9.41342711e-01 1.21181285e-11 1.14701743e-05
 5.86457513e-02], sum to 1.0000
[2019-04-27 18:42:36,012] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9273
[2019-04-27 18:42:36,020] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.38333333333333, 85.83333333333334, 1.0, 2.0, 0.2992140063512206, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 382421.7175127527, 382421.7175127527, 115479.678601394], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1803000.0000, 
sim time next is 1803600.0000, 
raw observation next is [18.4, 86.0, 1.0, 2.0, 0.299861862123284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 383114.305733515, 383114.305733515, 115559.4926075108], 
processed observation next is [1.0, 0.9130434782608695, 0.237037037037037, 0.86, 1.0, 1.0, 0.1665022168134333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13682653776196965, 0.13682653776196965, 0.2222297934759823], 
reward next is 0.7778, 
noisyNet noise sample is [array([0.08436877], dtype=float32), 1.4942086]. 
=============================================
[2019-04-27 18:42:40,687] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.7721800e-10 9.9934131e-01 6.9629872e-18 4.2734197e-08 6.5864122e-04], sum to 1.0000
[2019-04-27 18:42:40,696] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0518
[2019-04-27 18:42:40,702] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.51666666666667, 87.83333333333334, 1.0, 2.0, 0.808777910332178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 990173.7003170619, 990173.7003170609, 200721.3804930054], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1875000.0000, 
sim time next is 1875600.0000, 
raw observation next is [21.5, 88.0, 1.0, 2.0, 0.799119034822411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 978267.6245918104, 978267.6245918104, 198670.0485049678], 
processed observation next is [1.0, 0.7391304347826086, 0.35185185185185186, 0.88, 1.0, 1.0, 0.7608559938362035, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.34938129449707517, 0.34938129449707517, 0.3820577855864765], 
reward next is 0.6179, 
noisyNet noise sample is [array([1.3367109], dtype=float32), 0.7123276]. 
=============================================
[2019-04-27 18:42:42,298] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-04-27 18:42:42,301] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 18:42:42,302] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:42:42,304] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 18:42:42,305] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 18:42:42,307] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 18:42:42,308] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:42:42,306] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 18:42:42,308] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:42:42,310] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:42:42,309] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:42:42,325] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run20
[2019-04-27 18:42:42,344] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run20
[2019-04-27 18:42:42,363] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run20
[2019-04-27 18:42:42,364] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run20
[2019-04-27 18:42:42,410] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run20
[2019-04-27 18:42:52,170] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.0552816]
[2019-04-27 18:42:52,174] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.66666666666667, 58.0, 1.0, 2.0, 0.2513362426076937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 324202.4929771682, 324202.4929771682, 103102.5952961947]
[2019-04-27 18:42:52,175] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 18:42:52,178] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.8088295e-11 9.9992919e-01 1.3451508e-16 5.4649747e-09 7.0826994e-05], sampled 0.5138598043753221
[2019-04-27 18:42:52,581] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.0552816]
[2019-04-27 18:42:52,582] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.596329485, 51.428968295, 1.0, 2.0, 0.4008876282922073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 490400.4692212659, 490400.4692212659, 128585.1383319774]
[2019-04-27 18:42:52,585] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 18:42:52,589] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.6620205e-11 9.9986351e-01 1.7838167e-15 1.9526549e-08 1.3652534e-04], sampled 0.1983844266791044
[2019-04-27 18:42:55,224] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.0552816]
[2019-04-27 18:42:55,225] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.63333333333334, 50.66666666666667, 1.0, 2.0, 0.4328400703884011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 529888.6139624728, 529888.6139624728, 133180.5529042904]
[2019-04-27 18:42:55,226] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 18:42:55,230] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.2223214e-11 9.9990726e-01 3.4991625e-16 8.7246548e-09 9.2784328e-05], sampled 0.878314551990736
[2019-04-27 18:43:02,547] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.0552816]
[2019-04-27 18:43:02,548] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.66666666666666, 41.33333333333334, 1.0, 2.0, 0.3608357624228353, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 452490.339966232, 452490.339966232, 123342.8939194434]
[2019-04-27 18:43:02,549] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 18:43:02,551] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.6784028e-11 9.9991286e-01 2.7484364e-16 7.7670936e-09 8.7192653e-05], sampled 0.034499088096601516
[2019-04-27 18:43:05,834] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.0552816]
[2019-04-27 18:43:05,834] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.0, 46.0, 1.0, 2.0, 0.5278759779383729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 634621.4876652813, 634621.4876652813, 147523.3152866775]
[2019-04-27 18:43:05,835] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 18:43:05,839] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.6617022e-11 9.9989903e-01 4.0866902e-16 9.5797592e-09 1.0101043e-04], sampled 0.9885233814660963
[2019-04-27 18:43:26,287] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.0552816]
[2019-04-27 18:43:26,288] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.91666666666667, 64.0, 1.0, 2.0, 0.554168750430173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 656057.7100618855, 656057.7100618855, 151473.5559558754]
[2019-04-27 18:43:26,290] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 18:43:26,293] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.7515646e-12 9.9994648e-01 3.1260353e-17 2.5123292e-09 5.3468273e-05], sampled 0.2449302707059271
[2019-04-27 18:43:53,139] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.0552816]
[2019-04-27 18:43:53,263] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.080681235, 77.79390267, 1.0, 2.0, 0.4237628502313336, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 523057.2903793722, 523057.2903793722, 131969.5558921493]
[2019-04-27 18:43:53,266] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 18:43:53,269] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.2650889e-11 9.9991250e-01 3.8323966e-16 8.6430774e-09 8.7447937e-05], sampled 0.7817641813249666
[2019-04-27 18:43:55,764] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.0552816]
[2019-04-27 18:43:55,766] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.6, 68.0, 1.0, 2.0, 0.5782395999790274, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9205762751156562, 6.9112, 6.9112, 121.9260426156618, 1318506.759671516, 1318506.759671516, 285495.0820563864]
[2019-04-27 18:43:55,767] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 18:43:55,769] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.7652675e-12 9.9995279e-01 2.5156136e-18 7.1180534e-10 4.7151698e-05], sampled 0.40486613048616593
[2019-04-27 18:43:55,770] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1318506.759671516 W.
[2019-04-27 18:44:11,110] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.0552816]
[2019-04-27 18:44:11,111] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.63333333333333, 76.0, 1.0, 2.0, 0.6644040016231963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 757212.5702492299, 757212.5702492299, 169513.5720693338]
[2019-04-27 18:44:11,112] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 18:44:11,115] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.4196941e-11 9.9993169e-01 9.7536036e-17 4.4751869e-09 6.8265472e-05], sampled 0.12397821099968132
[2019-04-27 18:44:24,888] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.0552816]
[2019-04-27 18:44:24,890] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [19.06666666666667, 96.33333333333334, 1.0, 2.0, 0.359380875289837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 449545.1044042325, 449545.1044042325, 123129.0177044808]
[2019-04-27 18:44:24,891] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 18:44:24,896] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.00893702e-11 9.99889731e-01 7.35435404e-16 1.27866837e-08
 1.10240944e-04], sampled 0.4674203549244118
[2019-04-27 18:44:30,749] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8768.6064 2170713223.4582 493.0000
[2019-04-27 18:44:30,891] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8699.2734 2195136532.3663 572.0000
[2019-04-27 18:44:30,967] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8921.9154 2120529504.2130 430.0000
[2019-04-27 18:44:31,280] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8097.0775 2445510666.3775 746.0000
[2019-04-27 18:44:31,294] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8583.7010 2248665784.9182 553.0000
[2019-04-27 18:44:32,311] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 475000, evaluation results [475000.0, 8097.0774877411095, 2445510666.377459, 746.0, 8768.606363529843, 2170713223.45824, 493.0, 8921.915400160186, 2120529504.213012, 430.0, 8583.700958564144, 2248665784.918216, 553.0, 8699.273420649935, 2195136532.3663483, 572.0]
[2019-04-27 18:44:34,754] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4280328e-10 2.6547497e-02 3.5417174e-17 9.8517539e-08 9.7345239e-01], sum to 1.0000
[2019-04-27 18:44:34,762] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5121
[2019-04-27 18:44:34,770] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.5, 61.5, 1.0, 2.0, 0.4270774189111391, 1.0, 2.0, 0.4270774189111391, 1.0, 2.0, 0.6800102496474019, 6.911200000000001, 6.9112, 121.94756008, 1464598.358701282, 1464598.358701282, 309173.3504617666], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1953000.0000, 
sim time next is 1953600.0000, 
raw observation next is [27.6, 61.33333333333333, 1.0, 2.0, 0.4344743301837854, 1.0, 2.0, 0.4344743301837854, 1.0, 2.0, 0.6917085780403749, 6.911199999999999, 6.9112, 121.94756008, 1486759.797156284, 1486759.797156285, 312517.256080129], 
processed observation next is [1.0, 0.6086956521739131, 0.5777777777777778, 0.6133333333333333, 1.0, 1.0, 0.32675515498069696, 1.0, 1.0, 0.32675515498069696, 1.0, 1.0, 0.6146357225504686, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5309856418415301, 0.5309856418415304, 0.6009947232310173], 
reward next is 0.3990, 
noisyNet noise sample is [array([0.59010506], dtype=float32), 0.71074146]. 
=============================================
[2019-04-27 18:44:38,444] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.8828457e-10 9.9992347e-01 1.6525682e-15 4.0184155e-08 7.6514414e-05], sum to 1.0000
[2019-04-27 18:44:38,451] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7929
[2019-04-27 18:44:38,458] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 66.0, 1.0, 2.0, 0.4473562480099098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 541925.8928000097, 541925.8928000097, 135153.6829438351], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2026800.0000, 
sim time next is 2027400.0000, 
raw observation next is [25.65, 66.0, 1.0, 2.0, 0.4533779156271329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 548068.3568314784, 548068.3568314784, 136014.4214523663], 
processed observation next is [0.0, 0.4782608695652174, 0.5055555555555555, 0.66, 1.0, 1.0, 0.3492594233656344, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19573869886838516, 0.19573869886838516, 0.26156619510070445], 
reward next is 0.7384, 
noisyNet noise sample is [array([0.428639], dtype=float32), 1.0155237]. 
=============================================
[2019-04-27 18:44:41,861] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.2414054e-13 9.9998009e-01 1.4418984e-18 2.9276037e-10 1.9928260e-05], sum to 1.0000
[2019-04-27 18:44:41,870] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6470
[2019-04-27 18:44:41,874] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.91666666666667, 86.5, 1.0, 2.0, 0.4352894704547075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 531438.348879268, 531438.348879268, 133498.6413928096], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2083800.0000, 
sim time next is 2084400.0000, 
raw observation next is [21.8, 87.0, 1.0, 2.0, 0.4329682321402208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 529030.5022538377, 529030.5022538372, 133170.7910171292], 
processed observation next is [0.0, 0.13043478260869565, 0.362962962962963, 0.87, 1.0, 1.0, 0.3249621811193105, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18893946509065632, 0.18893946509065615, 0.2560976750329408], 
reward next is 0.7439, 
noisyNet noise sample is [array([-0.6344491], dtype=float32), 0.15825462]. 
=============================================
[2019-04-27 18:44:41,934] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.4854652e-16 9.9999750e-01 8.6389720e-19 8.1133945e-12 2.5536119e-06], sum to 1.0000
[2019-04-27 18:44:41,945] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4185
[2019-04-27 18:44:41,953] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.85, 93.0, 1.0, 2.0, 0.4250632821242188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 521047.2783759242, 521047.2783759242, 132066.2929049886], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2089800.0000, 
sim time next is 2090400.0000, 
raw observation next is [20.73333333333333, 93.66666666666666, 1.0, 2.0, 0.4231961951511409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 519051.6536441457, 519051.6536441452, 131803.7560276996], 
processed observation next is [0.0, 0.17391304347826086, 0.3234567901234567, 0.9366666666666665, 1.0, 1.0, 0.31332880375135824, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18537559058719488, 0.18537559058719472, 0.25346876159173], 
reward next is 0.7465, 
noisyNet noise sample is [array([0.04096643], dtype=float32), -0.8411173]. 
=============================================
[2019-04-27 18:44:42,772] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.2599394e-13 9.9997151e-01 4.9178045e-17 1.8953215e-09 2.8469083e-05], sum to 1.0000
[2019-04-27 18:44:42,780] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2180
[2019-04-27 18:44:42,783] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.08333333333334, 92.5, 1.0, 2.0, 0.4283080461706963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 523842.4251697062, 523842.4251697062, 132505.3465400047], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2094600.0000, 
sim time next is 2095200.0000, 
raw observation next is [21.2, 92.0, 1.0, 2.0, 0.4305529365543475, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 526126.4833966147, 526126.4833966147, 132819.4466050382], 
processed observation next is [0.0, 0.2608695652173913, 0.34074074074074073, 0.92, 1.0, 1.0, 0.3220868292313661, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18790231549879094, 0.18790231549879094, 0.2554220127019965], 
reward next is 0.7446, 
noisyNet noise sample is [array([-0.30294985], dtype=float32), -0.7910556]. 
=============================================
[2019-04-27 18:44:43,952] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.7001845e-15 9.9997807e-01 1.1423875e-19 1.9279819e-12 2.1973767e-05], sum to 1.0000
[2019-04-27 18:44:43,964] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4556
[2019-04-27 18:44:43,968] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.9, 57.5, 1.0, 2.0, 0.5833911054648385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 673534.8135411338, 673534.8135411338, 155665.0544388376], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2122200.0000, 
sim time next is 2122800.0000, 
raw observation next is [30.1, 56.66666666666667, 1.0, 2.0, 0.5847041221479531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 674712.5973263858, 674712.5973263853, 155872.4526393441], 
processed observation next is [0.0, 0.5652173913043478, 0.6703703703703704, 0.5666666666666668, 1.0, 1.0, 0.5056001454142298, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2409687847594235, 0.24096878475942332, 0.29975471661412323], 
reward next is 0.7002, 
noisyNet noise sample is [array([-0.07744766], dtype=float32), 1.2147552]. 
=============================================
[2019-04-27 18:44:44,507] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.7545868e-16 9.9999976e-01 2.7093934e-19 8.1834012e-11 2.0391636e-07], sum to 1.0000
[2019-04-27 18:44:44,517] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5182
[2019-04-27 18:44:44,528] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.43333333333334, 64.0, 1.0, 2.0, 0.6258317396700851, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 713231.8151980605, 713231.8151980605, 162577.905988768], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2143200.0000, 
sim time next is 2143800.0000, 
raw observation next is [29.25, 65.5, 1.0, 2.0, 0.6375436997873716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 726585.7263487673, 726585.7263487673, 164656.5860248716], 
processed observation next is [0.0, 0.8260869565217391, 0.6388888888888888, 0.655, 1.0, 1.0, 0.5685044045087757, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2594949022674169, 0.2594949022674169, 0.31664728081706073], 
reward next is 0.6834, 
noisyNet noise sample is [array([-1.31], dtype=float32), -0.7652941]. 
=============================================
[2019-04-27 18:45:12,315] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.3505945e-18 1.0000000e+00 1.6440444e-20 1.1422482e-17 1.4087415e-12], sum to 1.0000
[2019-04-27 18:45:12,323] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8399
[2019-04-27 18:45:12,328] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 83.0, 1.0, 2.0, 0.5623548727326608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 656460.3237094629, 656460.3237094624, 152454.7274644275], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2635200.0000, 
sim time next is 2635800.0000, 
raw observation next is [25.0, 82.16666666666667, 1.0, 2.0, 0.5624640652775408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 657009.7687298772, 657009.7687298767, 152490.9264959844], 
processed observation next is [0.0, 0.5217391304347826, 0.48148148148148145, 0.8216666666666668, 1.0, 1.0, 0.4791238872351676, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23464634597495615, 0.23464634597495598, 0.29325178172304694], 
reward next is 0.7067, 
noisyNet noise sample is [array([-1.3132824], dtype=float32), 0.86996204]. 
=============================================
[2019-04-27 18:45:19,147] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3685753e-15 1.0000000e+00 2.5875119e-19 4.4121103e-13 7.7490393e-12], sum to 1.0000
[2019-04-27 18:45:19,159] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7400
[2019-04-27 18:45:19,166] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.83333333333334, 94.00000000000001, 1.0, 2.0, 0.6665552418570919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 759665.5255776319, 759665.5255776319, 169907.0119402978], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2765400.0000, 
sim time next is 2766000.0000, 
raw observation next is [24.66666666666667, 94.0, 1.0, 2.0, 0.6597399492486619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 751894.4035702609, 751894.4035702604, 168659.7031069087], 
processed observation next is [1.0, 0.0, 0.469135802469136, 0.94, 1.0, 1.0, 0.5949285110103117, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26853371556080746, 0.2685337155608073, 0.3243455828979014], 
reward next is 0.6757, 
noisyNet noise sample is [array([-0.78926086], dtype=float32), -0.06911264]. 
=============================================
[2019-04-27 18:45:19,182] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[65.052925]
 [65.23903 ]
 [66.08681 ]
 [66.11157 ]
 [66.147736]], R is [[64.93922424]
 [64.96308899]
 [64.98503113]
 [65.00723267]
 [65.02958679]].
[2019-04-27 18:45:23,758] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-04-27 18:45:23,761] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 18:45:23,762] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 18:45:23,762] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:45:23,763] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:45:23,763] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 18:45:23,765] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:45:23,764] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 18:45:23,764] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 18:45:23,765] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:45:23,766] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:45:23,771] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run21
[2019-04-27 18:45:23,791] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run21
[2019-04-27 18:45:23,810] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run21
[2019-04-27 18:45:23,831] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run21
[2019-04-27 18:45:23,849] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run21
[2019-04-27 18:45:32,293] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.053044215]
[2019-04-27 18:45:32,296] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [18.0, 83.0, 1.0, 2.0, 0.2615534903769774, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 336600.7004948413, 336600.7004948408, 110950.9117465833]
[2019-04-27 18:45:32,298] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 18:45:32,299] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.4734402e-15 1.0000000e+00 8.4226580e-20 1.5689477e-15 3.3239879e-13], sampled 0.568510667247482
[2019-04-27 18:45:57,915] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.053044215]
[2019-04-27 18:45:57,916] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [34.33333333333334, 45.66666666666667, 1.0, 2.0, 0.9057153622366153, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426156618, 1747608.667117043, 1747608.667117042, 358204.0233979094]
[2019-04-27 18:45:57,917] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 18:45:57,922] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.7550537e-16 1.0000000e+00 7.1080519e-21 3.3482501e-17 6.8948232e-15], sampled 0.2704104997472254
[2019-04-27 18:45:57,922] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1747608.667117043 W.
[2019-04-27 18:46:40,921] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.053044215]
[2019-04-27 18:46:40,921] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.62598240666667, 83.89311688666668, 1.0, 2.0, 0.3843032741047872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 479645.1310672064, 479645.1310672064, 126501.2829850949]
[2019-04-27 18:46:40,923] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 18:46:40,927] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.8614726e-16 1.0000000e+00 5.9190508e-21 1.6433016e-16 4.0973166e-14], sampled 0.6248386458359042
[2019-04-27 18:46:41,203] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.053044215]
[2019-04-27 18:46:41,207] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.91438585666667, 83.74143692000001, 1.0, 2.0, 0.3994216456537282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 492382.1419665805, 492382.14196658, 128479.1912395257]
[2019-04-27 18:46:41,208] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 18:46:41,210] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.0861825e-16 1.0000000e+00 6.7799374e-21 2.0170283e-16 5.0676426e-14], sampled 0.5045372535551075
[2019-04-27 18:46:41,853] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.053044215]
[2019-04-27 18:46:41,855] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.78333333333333, 86.66666666666667, 1.0, 2.0, 0.6018532581728843, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 695681.2839539953, 695681.2839539953, 158869.6347935727]
[2019-04-27 18:46:41,857] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 18:46:41,860] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.1706669e-17 1.0000000e+00 2.3671700e-21 8.0922517e-17 2.2117956e-14], sampled 0.009213390420143575
[2019-04-27 18:46:47,862] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.053044215]
[2019-04-27 18:46:47,864] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.39237601666667, 64.42108673999999, 1.0, 2.0, 0.943331886542979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.977622869637575, 6.9112, 121.9253724717271, 1143081.5827664, 1109067.32365735, 229104.2270896112]
[2019-04-27 18:46:47,864] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 18:46:47,868] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [5.5405029e-16 1.0000000e+00 2.4435899e-20 2.4408467e-16 5.2153397e-14], sampled 0.609846001970579
[2019-04-27 18:47:13,565] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.6619 2445343923.2757 746.0000
[2019-04-27 18:47:13,680] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-04-27 18:47:13,817] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-04-27 18:47:13,904] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.6127 2195087804.9157 572.0000
[2019-04-27 18:47:13,922] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.1046 2120496270.4403 430.0000
[2019-04-27 18:47:14,937] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 500000, evaluation results [500000.0, 8100.661928194693, 2445343923.2757144, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.104571701966, 2120496270.440313, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.61270960664, 2195087804.9156528, 572.0]
[2019-04-27 18:47:15,542] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.8807540e-17 1.0000000e+00 4.3875041e-21 7.6165343e-18 1.2443956e-13], sum to 1.0000
[2019-04-27 18:47:15,547] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6067
[2019-04-27 18:47:15,551] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 100.0, 1.0, 2.0, 0.8085600697676589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 957274.74533179, 957274.74533179, 199451.5342006757], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2863200.0000, 
sim time next is 2863800.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.8150437547333886, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 964900.7504894309, 964900.7504894309, 200820.5518070972], 
processed observation next is [1.0, 0.13043478260869565, 0.37037037037037035, 1.0, 1.0, 1.0, 0.7798139937302245, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3446074108890824, 0.3446074108890824, 0.38619336885980227], 
reward next is 0.6138, 
noisyNet noise sample is [array([-1.3481944], dtype=float32), -0.60581446]. 
=============================================
[2019-04-27 18:47:21,799] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.0633550e-14 1.0000000e+00 7.2251778e-18 2.6795315e-14 1.3151851e-11], sum to 1.0000
[2019-04-27 18:47:21,814] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7887
[2019-04-27 18:47:21,819] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1696368.875019027 W.
[2019-04-27 18:47:21,825] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.66666666666667, 87.0, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.952433606564314, 6.9112, 121.9223099799755, 1696368.875019027, 1163180.527546398, 245581.324300049], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2967600.0000, 
sim time next is 2968200.0000, 
raw observation next is [25.75, 87.5, 1.0, 2.0, 0.7099672348902389, 1.0, 1.0, 0.7099672348902389, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9254156009239, 1619185.103199163, 1619185.103199163, 307955.3211360193], 
processed observation next is [1.0, 0.34782608695652173, 0.5092592592592593, 0.875, 1.0, 1.0, 0.6547228986788559, 1.0, 0.5, 0.6547228986788559, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094579660943256, 0.5782803939997011, 0.5782803939997011, 0.5922217714154218], 
reward next is 0.4078, 
noisyNet noise sample is [array([-1.3056226], dtype=float32), -0.021369962]. 
=============================================
[2019-04-27 18:47:26,163] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.2448187e-14 1.0000000e+00 1.7536542e-17 6.2511540e-14 3.5452930e-12], sum to 1.0000
[2019-04-27 18:47:26,176] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6860
[2019-04-27 18:47:26,178] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 90.83333333333334, 1.0, 2.0, 0.6985539902553505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 796153.0795702597, 796153.0795702597, 175865.8282580346], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3042600.0000, 
sim time next is 3043200.0000, 
raw observation next is [24.2, 92.66666666666667, 1.0, 2.0, 0.6180552371731888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 710512.978676787, 710512.9786767865, 161512.810706164], 
processed observation next is [1.0, 0.21739130434782608, 0.45185185185185184, 0.9266666666666667, 1.0, 1.0, 0.5453038537776057, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.25375463524170966, 0.2537546352417095, 0.3106015590503154], 
reward next is 0.6894, 
noisyNet noise sample is [array([1.5950899], dtype=float32), -1.5788801]. 
=============================================
[2019-04-27 18:47:26,839] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.6130541e-13 1.0000000e+00 5.0546221e-17 4.8585522e-14 7.5597612e-13], sum to 1.0000
[2019-04-27 18:47:26,848] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5475
[2019-04-27 18:47:26,853] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.66666666666667, 79.66666666666667, 1.0, 2.0, 0.7725724500337684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 880561.5544982904, 880561.55449829, 190342.6209424391], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3093000.0000, 
sim time next is 3093600.0000, 
raw observation next is [28.33333333333334, 80.33333333333334, 1.0, 2.0, 0.76054156111366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 866841.2498507113, 866841.2498507113, 187925.4074796738], 
processed observation next is [1.0, 0.8260869565217391, 0.6049382716049385, 0.8033333333333335, 1.0, 1.0, 0.7149304298972142, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.30958616066096833, 0.30958616066096833, 0.3613950143839881], 
reward next is 0.6386, 
noisyNet noise sample is [array([-0.6627107], dtype=float32), -1.0890057]. 
=============================================
[2019-04-27 18:47:32,927] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.2613148e-15 1.0000000e+00 4.9096007e-18 1.8325861e-15 1.5284352e-14], sum to 1.0000
[2019-04-27 18:47:32,935] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2048
[2019-04-27 18:47:32,940] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.86666666666667, 62.66666666666667, 1.0, 2.0, 0.6608059537121388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 753109.9075548879, 753109.9075548876, 168855.2114822615], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3183600.0000, 
sim time next is 3184200.0000, 
raw observation next is [29.9, 60.0, 1.0, 2.0, 0.6444950809680569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 734520.3616293449, 734520.3616293444, 165899.9543810028], 
processed observation next is [1.0, 0.8695652173913043, 0.6629629629629629, 0.6, 1.0, 1.0, 0.5767798582953058, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2623287005819089, 0.2623287005819087, 0.3190383738096208], 
reward next is 0.6810, 
noisyNet noise sample is [array([-2.0950289], dtype=float32), -0.26505142]. 
=============================================
[2019-04-27 18:47:34,080] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.4110203e-18 1.0000000e+00 2.1445539e-23 1.4937429e-19 3.9438164e-18], sum to 1.0000
[2019-04-27 18:47:34,090] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0174
[2019-04-27 18:47:34,096] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.55, 85.0, 1.0, 2.0, 0.5747180400149255, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 671342.2983639446, 671342.2983639446, 154550.5050408131], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3205800.0000, 
sim time next is 3206400.0000, 
raw observation next is [24.36666666666667, 84.33333333333333, 1.0, 2.0, 0.5590283965162733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 656571.9675763813, 656571.9675763813, 152070.7290845285], 
processed observation next is [0.0, 0.08695652173913043, 0.4580246913580248, 0.8433333333333333, 1.0, 1.0, 0.47503380537651585, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2344899884201362, 0.2344899884201362, 0.2924437097779394], 
reward next is 0.7076, 
noisyNet noise sample is [array([-1.8611887], dtype=float32), -0.58916235]. 
=============================================
[2019-04-27 18:47:36,123] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.2008081e-21 1.0000000e+00 6.0086672e-27 3.5974495e-20 1.1235819e-19], sum to 1.0000
[2019-04-27 18:47:36,135] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3342
[2019-04-27 18:47:36,142] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 81.33333333333334, 1.0, 2.0, 0.4731051477948013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 571240.9294934982, 571240.9294934982, 138975.7482786729], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3219600.0000, 
sim time next is 3220200.0000, 
raw observation next is [23.5, 80.5, 1.0, 2.0, 0.4749967716696988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 573053.8262096572, 573053.8262096572, 139249.8188188967], 
processed observation next is [0.0, 0.2608695652173913, 0.42592592592592593, 0.805, 1.0, 1.0, 0.3749961567496414, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20466208078916331, 0.20466208078916331, 0.26778811311326284], 
reward next is 0.7322, 
noisyNet noise sample is [array([2.1101093], dtype=float32), 1.1401935]. 
=============================================
[2019-04-27 18:47:47,381] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.2941136e-16 1.0000000e+00 4.5536432e-20 1.2113843e-17 2.1145534e-16], sum to 1.0000
[2019-04-27 18:47:47,386] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2723
[2019-04-27 18:47:47,391] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.687556671858564, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 783612.8541800531, 783612.8541800531, 173801.0932862964], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3445800.0000, 
sim time next is 3446400.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.6880079618401421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 784127.4554207048, 784127.4554207039, 173885.559573154], 
processed observation next is [1.0, 0.9130434782608695, 0.5185185185185185, 0.89, 1.0, 1.0, 0.6285809069525501, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.2800455197931089, 0.28004551979310854, 0.33439530687144997], 
reward next is 0.6656, 
noisyNet noise sample is [array([-0.11254214], dtype=float32), -0.21745053]. 
=============================================
[2019-04-27 18:47:48,493] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.0775758e-19 1.0000000e+00 6.0409472e-23 9.0529223e-21 4.3097922e-19], sum to 1.0000
[2019-04-27 18:47:48,503] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7504
[2019-04-27 18:47:48,508] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.6, 81.66666666666667, 1.0, 2.0, 0.6612630163883826, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 753631.0706011817, 753631.0706011817, 168938.5527194393], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3442800.0000, 
sim time next is 3443400.0000, 
raw observation next is [26.45, 83.5, 1.0, 2.0, 0.6668605088682805, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 760013.6074413107, 760013.6074413107, 169963.7855563505], 
processed observation next is [1.0, 0.8695652173913043, 0.5351851851851852, 0.835, 1.0, 1.0, 0.6034053677003339, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2714334312290395, 0.2714334312290395, 0.32685343376221254], 
reward next is 0.6731, 
noisyNet noise sample is [array([0.5351405], dtype=float32), 0.66475743]. 
=============================================
[2019-04-27 18:47:57,568] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.9718649e-19 1.0000000e+00 3.8331004e-22 1.3383683e-21 7.5810142e-21], sum to 1.0000
[2019-04-27 18:47:57,575] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6126
[2019-04-27 18:47:57,579] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.58333333333333, 79.83333333333333, 1.0, 2.0, 0.5220669910516557, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 619415.5039641435, 619415.5039641435, 146281.6146581094], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3615000.0000, 
sim time next is 3615600.0000, 
raw observation next is [24.46666666666667, 81.66666666666667, 1.0, 2.0, 0.5246369835500817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 620811.9951095437, 620811.9951095437, 146630.6733424421], 
processed observation next is [1.0, 0.8695652173913043, 0.46172839506172847, 0.8166666666666668, 1.0, 1.0, 0.43409164708343057, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2217185696819799, 0.2217185696819799, 0.281982064120081], 
reward next is 0.7180, 
noisyNet noise sample is [array([0.47534862], dtype=float32), -1.0254931]. 
=============================================
[2019-04-27 18:47:58,877] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.8288593e-18 1.0000000e+00 1.5621570e-23 3.8149156e-19 8.1470673e-19], sum to 1.0000
[2019-04-27 18:47:58,885] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2669
[2019-04-27 18:47:58,890] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 100.0, 1.0, 2.0, 0.6168861117122553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 716167.1224770615, 716167.1224770615, 161637.5028450152], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3639600.0000, 
sim time next is 3640200.0000, 
raw observation next is [23.0, 99.00000000000001, 1.0, 2.0, 0.6172952091318696, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 717721.8551868756, 717721.8551868756, 161758.5414214221], 
processed observation next is [1.0, 0.13043478260869565, 0.4074074074074074, 0.9900000000000001, 1.0, 1.0, 0.544399058490321, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2563292339953127, 0.2563292339953127, 0.3110741181181194], 
reward next is 0.6889, 
noisyNet noise sample is [array([-1.3143463], dtype=float32), -1.4562976]. 
=============================================
[2019-04-27 18:48:00,957] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.84087622e-15 1.00000000e+00 1.04631273e-16 9.52515548e-16
 8.64534088e-15], sum to 1.0000
[2019-04-27 18:48:00,965] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3050
[2019-04-27 18:48:00,971] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1937858.042885079 W.
[2019-04-27 18:48:00,976] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.83333333333333, 88.5, 1.0, 2.0, 0.5663634267981097, 1.0, 1.0, 0.5663634267981097, 1.0, 2.0, 0.9016690206316771, 6.9112, 6.9112, 121.94756008, 1937858.042885079, 1937858.042885079, 377353.4777227839], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3682200.0000, 
sim time next is 3682800.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.7722551979335438, 1.0, 2.0, 0.7722551979335438, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426084911, 1761382.037305001, 1761382.037305001, 332424.0275730547], 
processed observation next is [1.0, 0.6521739130434783, 0.5555555555555556, 0.89, 1.0, 1.0, 0.7288752356351712, 1.0, 1.0, 0.7288752356351712, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.80946212877253, 0.6290650133232146, 0.6290650133232146, 0.6392769761020283], 
reward next is 0.3607, 
noisyNet noise sample is [array([-0.43156207], dtype=float32), 2.0611036]. 
=============================================
[2019-04-27 18:48:01,191] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4234772e-17 1.0000000e+00 1.5067684e-19 3.0963990e-18 1.6222858e-17], sum to 1.0000
[2019-04-27 18:48:01,203] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6593
[2019-04-27 18:48:01,210] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1758455.034910087 W.
[2019-04-27 18:48:01,214] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.95, 86.5, 1.0, 2.0, 0.7709731534437374, 1.0, 2.0, 0.7709731534437374, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1758455.034910087, 1758455.034910087, 331906.5112263969], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3688200.0000, 
sim time next is 3688800.0000, 
raw observation next is [26.93333333333333, 85.66666666666667, 1.0, 2.0, 0.9040051760603539, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911200000000002, 6.9112, 121.9260426156618, 1745656.455387256, 1745656.455387255, 357834.2768991025], 
processed observation next is [1.0, 0.6956521739130435, 0.5530864197530863, 0.8566666666666667, 1.0, 1.0, 0.8857204476908975, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, 1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.6234487340668772, 0.6234487340668767, 0.6881428401905817], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.9090195], dtype=float32), -2.507993]. 
=============================================
[2019-04-27 18:48:01,218] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.1029766e-16 1.0000000e+00 1.0773026e-20 1.6429372e-17 2.1906343e-15], sum to 1.0000
[2019-04-27 18:48:01,228] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6074
[2019-04-27 18:48:01,232] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.6734058294659245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 767476.9720285487, 767476.9720285492, 171168.8741508377], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3704400.0000, 
sim time next is 3705000.0000, 
raw observation next is [25.0, 94.00000000000001, 1.0, 2.0, 0.6695821858961557, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 763117.0169496551, 763117.0169496547, 170464.0102805504], 
processed observation next is [1.0, 0.9130434782608695, 0.48148148148148145, 0.9400000000000002, 1.0, 1.0, 0.6066454594001853, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27254179176773397, 0.2725417917677338, 0.32781540438567386], 
reward next is 0.6722, 
noisyNet noise sample is [array([-0.3816974], dtype=float32), 1.8265692]. 
=============================================
[2019-04-27 18:48:01,244] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[53.30879 ]
 [53.610146]
 [53.5146  ]
 [53.639946]
 [53.309814]], R is [[53.32587814]
 [53.46345139]
 [53.59680939]
 [53.72653198]
 [53.85333633]].
[2019-04-27 18:48:04,987] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.4130408e-11 1.0000000e+00 1.0101232e-12 1.6345000e-11 1.6301568e-11], sum to 1.0000
[2019-04-27 18:48:04,992] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9533
[2019-04-27 18:48:04,997] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2098274.580031764 W.
[2019-04-27 18:48:05,002] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.3, 77.0, 1.0, 2.0, 0.9197880712544133, 1.0, 2.0, 0.9197880712544133, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2098274.580031764, 2098274.580031764, 395740.1434162878], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3754800.0000, 
sim time next is 3755400.0000, 
raw observation next is [29.41666666666667, 77.33333333333334, 1.0, 2.0, 0.5963997534409174, 1.0, 2.0, 0.5963997534409174, 1.0, 1.0, 0.9494878308618933, 6.911200000000001, 6.9112, 121.94756008, 2040747.15656239, 2040747.156562389, 393417.4834547048], 
processed observation next is [1.0, 0.4782608695652174, 0.6450617283950619, 0.7733333333333334, 1.0, 1.0, 0.5195235160010921, 1.0, 1.0, 0.5195235160010921, 1.0, 0.5, 0.9368597885773666, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7288382702008536, 0.7288382702008532, 0.75657208356674], 
reward next is 0.2434, 
noisyNet noise sample is [array([0.23308282], dtype=float32), -1.1296026]. 
=============================================
[2019-04-27 18:48:06,092] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.2105981e-17 1.0000000e+00 7.1840790e-21 3.7431594e-17 5.6429944e-16], sum to 1.0000
[2019-04-27 18:48:06,101] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2847
[2019-04-27 18:48:06,107] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 71.0, 1.0, 2.0, 0.6793277239709042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 774229.5316514578, 774229.5316514578, 172267.9735396351], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3796800.0000, 
sim time next is 3797400.0000, 
raw observation next is [28.75, 74.0, 1.0, 2.0, 0.6954518332404814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 792615.6738845436, 792615.6738845436, 175286.0002065618], 
processed observation next is [1.0, 0.9565217391304348, 0.6203703703703703, 0.74, 1.0, 1.0, 0.6374426586196207, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.283077026387337, 0.283077026387337, 0.33708846193569575], 
reward next is 0.6629, 
noisyNet noise sample is [array([-0.25736737], dtype=float32), 1.3761252]. 
=============================================
[2019-04-27 18:48:06,335] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-04-27 18:48:06,336] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 18:48:06,336] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 18:48:06,336] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:48:06,338] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:48:06,338] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 18:48:06,341] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 18:48:06,342] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 18:48:06,343] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:48:06,342] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:48:06,347] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:48:06,356] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run22
[2019-04-27 18:48:06,356] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run22
[2019-04-27 18:48:06,394] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run22
[2019-04-27 18:48:06,418] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run22
[2019-04-27 18:48:06,436] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run22
[2019-04-27 18:48:35,237] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.05957833]
[2019-04-27 18:48:35,393] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.66666666666667, 79.66666666666667, 1.0, 2.0, 0.3668993694695532, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 455777.1267660941, 455777.1267660937, 124079.0809869889]
[2019-04-27 18:48:35,395] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 18:48:35,397] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.6083858e-17 1.0000000e+00 1.9296561e-21 6.4988322e-18 3.4321280e-16], sampled 0.5886192041664607
[2019-04-27 18:49:03,182] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.05957833]
[2019-04-27 18:49:03,183] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [32.16666666666666, 64.16666666666667, 1.0, 2.0, 0.8211514762304424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9259131813971, 935964.7012858054, 935964.7012858054, 200356.8450569169]
[2019-04-27 18:49:03,186] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 18:49:03,189] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.6054775e-19 1.0000000e+00 1.2269699e-23 8.3587066e-20 4.4578624e-18], sampled 0.9206581525037241
[2019-04-27 18:49:06,057] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.05957833]
[2019-04-27 18:49:06,058] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.30714984666667, 91.63661362666666, 1.0, 2.0, 0.5483257579214404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 644513.5313488486, 644513.5313488481, 150318.128251608]
[2019-04-27 18:49:06,059] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 18:49:06,062] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.6581884e-17 1.0000000e+00 1.9696978e-21 6.5338566e-18 3.7678882e-16], sampled 0.6628459630830446
[2019-04-27 18:49:17,217] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.05957833]
[2019-04-27 18:49:17,218] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.58333333333333, 82.33333333333333, 1.0, 2.0, 0.4930008180934154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 591015.7083954766, 591015.7083954766, 141908.2410163437]
[2019-04-27 18:49:17,219] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 18:49:17,226] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.6694981e-18 1.0000000e+00 1.6001186e-22 8.4450870e-19 5.5733994e-17], sampled 0.20629521060235745
[2019-04-27 18:49:22,795] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.05957833]
[2019-04-27 18:49:22,796] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.75, 44.66666666666667, 1.0, 2.0, 0.4916733476245529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 588061.1603805632, 588061.1603805632, 141652.818607382]
[2019-04-27 18:49:22,798] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 18:49:22,801] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.5131220e-19 1.0000000e+00 5.8417201e-24 5.5592062e-20 4.0364635e-18], sampled 0.09100023974315485
[2019-04-27 18:49:38,625] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.05957833]
[2019-04-27 18:49:38,626] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.07568571, 67.07064029, 1.0, 2.0, 0.2913929858199091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 372010.2292216109, 372010.2292216113, 114519.3423230682]
[2019-04-27 18:49:38,626] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 18:49:38,632] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.9455730e-19 1.0000000e+00 2.0933735e-23 1.6405995e-19 9.9533311e-18], sampled 0.9108042867603494
[2019-04-27 18:49:47,333] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.05957833]
[2019-04-27 18:49:47,333] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.11666666666667, 53.5, 1.0, 2.0, 0.2819304030228886, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 360319.1325440907, 360319.1325440907, 113373.1310502683]
[2019-04-27 18:49:47,335] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 18:49:47,337] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.0398109e-19 1.0000000e+00 1.3948386e-23 1.1797833e-19 7.5095575e-18], sampled 0.47790137590127746
[2019-04-27 18:49:53,267] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.05957833]
[2019-04-27 18:49:53,268] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.06666666666666, 35.66666666666667, 1.0, 2.0, 0.28941148792669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 373328.2926200925, 373328.2926200925, 109399.284118781]
[2019-04-27 18:49:53,269] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 18:49:53,272] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.9651505e-18 1.0000000e+00 1.2661409e-22 7.1321777e-19 4.0987170e-17], sampled 0.9021979525965781
[2019-04-27 18:49:55,748] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-04-27 18:49:55,800] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-04-27 18:49:55,832] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8099.9706 2445378853.1784 746.0000
[2019-04-27 18:49:55,889] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-04-27 18:49:55,930] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-04-27 18:49:56,946] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 525000, evaluation results [525000.0, 8099.970618414005, 2445378853.1783895, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-04-27 18:50:00,743] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.5198786e-19 1.0000000e+00 1.4723989e-25 4.9605569e-20 2.1293980e-17], sum to 1.0000
[2019-04-27 18:50:00,752] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8024
[2019-04-27 18:50:00,755] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.0, 58.5, 1.0, 2.0, 0.7374199455587808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 840473.5130255413, 840473.5130255413, 183355.9390402781], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3845400.0000, 
sim time next is 3846000.0000, 
raw observation next is [33.0, 58.0, 1.0, 2.0, 0.730337247942409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 832396.6331961409, 832396.6331961409, 181973.1819985857], 
processed observation next is [0.0, 0.5217391304347826, 0.7777777777777778, 0.58, 1.0, 1.0, 0.6789729142171536, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2972845118557646, 0.2972845118557646, 0.3499484269203571], 
reward next is 0.6501, 
noisyNet noise sample is [array([-0.04637522], dtype=float32), -3.1249564]. 
=============================================
[2019-04-27 18:50:00,786] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[69.79625]
 [69.78772]
 [69.86914]
 [69.92721]
 [69.95665]], R is [[69.78948975]
 [69.73899078]
 [69.68621063]
 [69.64616394]
 [69.61605835]].
[2019-04-27 18:50:09,839] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.0780257e-15 1.0000000e+00 3.5774184e-18 4.4567957e-16 1.2750346e-15], sum to 1.0000
[2019-04-27 18:50:09,848] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1243
[2019-04-27 18:50:09,853] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.25, 87.33333333333334, 1.0, 2.0, 0.628111740517323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 719861.8180995486, 719861.8180995486, 163180.908780983], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4047000.0000, 
sim time next is 4047600.0000, 
raw observation next is [25.2, 88.66666666666667, 1.0, 2.0, 0.632957247594428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 723302.7412843273, 723302.7412843273, 163936.722968898], 
processed observation next is [1.0, 0.8695652173913043, 0.4888888888888889, 0.8866666666666667, 1.0, 1.0, 0.563044342374319, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25832240760154546, 0.25832240760154546, 0.31526292878634227], 
reward next is 0.6847, 
noisyNet noise sample is [array([1.2560346], dtype=float32), -2.207802]. 
=============================================
[2019-04-27 18:50:19,242] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.8563136e-15 1.0000000e+00 9.1878905e-18 6.6967494e-16 8.6534910e-15], sum to 1.0000
[2019-04-27 18:50:19,249] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1475
[2019-04-27 18:50:19,253] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333334, 79.0, 1.0, 2.0, 0.5486227766390327, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 654975.9358547623, 654975.9358547623, 150765.7998863334], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4175400.0000, 
sim time next is 4176000.0000, 
raw observation next is [24.8, 76.0, 1.0, 2.0, 0.5474205992365633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 653269.297231357, 653269.297231357, 150556.6118653028], 
processed observation next is [1.0, 0.34782608695652173, 0.4740740740740741, 0.76, 1.0, 1.0, 0.4612149990911467, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2333104632969132, 0.2333104632969132, 0.28953194589481307], 
reward next is 0.7105, 
noisyNet noise sample is [array([-2.0902843], dtype=float32), 0.54972386]. 
=============================================
[2019-04-27 18:50:19,272] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[49.413017]
 [49.657726]
 [49.85394 ]
 [50.001377]
 [50.15772 ]], R is [[49.47369003]
 [49.68901825]
 [49.90504837]
 [50.12165451]
 [50.33697891]].
[2019-04-27 18:50:19,447] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.0354879e-12 1.0000000e+00 5.0615733e-15 5.1522792e-14 2.3930738e-13], sum to 1.0000
[2019-04-27 18:50:19,453] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5283
[2019-04-27 18:50:19,468] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1678733.409153463 W.
[2019-04-27 18:50:19,472] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.65, 31.5, 1.0, 2.0, 0.7127711946542686, 1.0, 1.0, 0.7127711946542686, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260424801442, 1678733.409153463, 1678733.409153463, 311583.0190958054], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4195800.0000, 
sim time next is 4196400.0000, 
raw observation next is [33.86666666666667, 30.0, 1.0, 2.0, 0.684102127891372, 1.0, 2.0, 0.684102127891372, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156205, 1615788.017480487, 1615788.017480487, 300816.4937703456], 
processed observation next is [1.0, 0.5652173913043478, 0.8098765432098766, 0.3, 1.0, 1.0, 0.6239311046325857, 1.0, 1.0, 0.6239311046325857, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288198618, 0.577067149100174, 0.577067149100174, 0.5784932572506646], 
reward next is 0.4215, 
noisyNet noise sample is [array([-0.64389545], dtype=float32), -1.3811477]. 
=============================================
[2019-04-27 18:50:31,988] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.7003471e-17 1.0000000e+00 1.7985599e-23 4.1709404e-17 1.2798883e-15], sum to 1.0000
[2019-04-27 18:50:31,997] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3155
[2019-04-27 18:50:32,002] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.1, 74.5, 1.0, 2.0, 0.6193386137137085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 710712.638730079, 710712.638730079, 161677.3140221527], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4447800.0000, 
sim time next is 4448400.0000, 
raw observation next is [27.2, 74.33333333333333, 1.0, 2.0, 0.6228840691169487, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 713687.0089832434, 713687.0089832434, 162247.9310680366], 
processed observation next is [0.0, 0.4782608695652174, 0.5629629629629629, 0.7433333333333333, 1.0, 1.0, 0.5510524632344628, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25488821749401547, 0.25488821749401547, 0.3120152520539165], 
reward next is 0.6880, 
noisyNet noise sample is [array([-1.5838456], dtype=float32), 0.068125576]. 
=============================================
[2019-04-27 18:50:34,312] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.0807365e-18 1.0000000e+00 1.2658734e-25 3.2333694e-19 2.3572198e-15], sum to 1.0000
[2019-04-27 18:50:34,320] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6542
[2019-04-27 18:50:34,324] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.2, 90.0, 1.0, 2.0, 0.6509199920010145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 741837.5841863996, 741837.5841863996, 167058.499585226], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4491000.0000, 
sim time next is 4491600.0000, 
raw observation next is [25.13333333333333, 91.33333333333334, 1.0, 2.0, 0.6560023219399654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 747632.6159221871, 747632.6159221871, 167980.0619064351], 
processed observation next is [0.0, 1.0, 0.4864197530864196, 0.9133333333333334, 1.0, 1.0, 0.590478954690435, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26701164854363824, 0.26701164854363824, 0.32303858058929824], 
reward next is 0.6770, 
noisyNet noise sample is [array([-0.9338897], dtype=float32), -0.8161824]. 
=============================================
[2019-04-27 18:50:38,947] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.5437846e-20 1.0000000e+00 1.2470045e-24 8.1409429e-20 7.2220089e-18], sum to 1.0000
[2019-04-27 18:50:38,954] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0672
[2019-04-27 18:50:38,960] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.86666666666667, 88.66666666666667, 1.0, 2.0, 0.6080803714328789, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 699698.0306910572, 699698.0306910577, 159801.563020042], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4540800.0000, 
sim time next is 4541400.0000, 
raw observation next is [25.3, 86.0, 1.0, 2.0, 0.6118500108688482, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 703010.5228182493, 703010.5228182493, 160409.2620616438], 
processed observation next is [0.0, 0.5652173913043478, 0.49259259259259264, 0.86, 1.0, 1.0, 0.5379166796057716, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2510751867208033, 0.2510751867208033, 0.30847935011854577], 
reward next is 0.6915, 
noisyNet noise sample is [array([-0.69915754], dtype=float32), -0.059608553]. 
=============================================
[2019-04-27 18:50:39,715] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.8036957e-20 1.0000000e+00 1.0708840e-24 4.6268881e-20 5.5084458e-17], sum to 1.0000
[2019-04-27 18:50:39,722] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7814
[2019-04-27 18:50:39,730] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.15, 99.16666666666667, 1.0, 2.0, 0.5892542273332497, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 683335.541315483, 683335.5413154826, 156804.3564006998], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4551000.0000, 
sim time next is 4551600.0000, 
raw observation next is [23.3, 98.33333333333334, 1.0, 2.0, 0.591492836881712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 685217.0198282539, 685217.0198282539, 157155.2754436195], 
processed observation next is [0.0, 0.6956521739130435, 0.41851851851851857, 0.9833333333333334, 1.0, 1.0, 0.5136819486687046, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2447203642243764, 0.2447203642243764, 0.3022216835454221], 
reward next is 0.6978, 
noisyNet noise sample is [array([-0.7482236], dtype=float32), -1.6948497]. 
=============================================
[2019-04-27 18:50:48,252] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-04-27 18:50:48,253] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 18:50:48,257] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:50:48,257] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 18:50:48,258] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 18:50:48,258] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:50:48,259] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 18:50:48,260] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:50:48,261] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:50:48,260] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 18:50:48,264] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:50:48,280] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run23
[2019-04-27 18:50:48,301] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run23
[2019-04-27 18:50:48,302] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run23
[2019-04-27 18:50:48,340] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run23
[2019-04-27 18:50:48,341] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run23
[2019-04-27 18:50:51,870] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.06588011]
[2019-04-27 18:50:51,871] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [15.5, 70.0, 1.0, 2.0, 0.1789827174498891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 230858.5201387564, 230858.5201387564, 74581.43137113652]
[2019-04-27 18:50:51,872] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 18:50:51,875] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.5655555e-16 1.0000000e+00 1.5024573e-20 8.6363334e-17 6.4035318e-15], sampled 0.7793848350497833
[2019-04-27 18:51:27,432] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.06588011]
[2019-04-27 18:51:27,434] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.73333333333333, 78.66666666666667, 1.0, 2.0, 0.6487344454046301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 739345.5689933927, 739345.5689933927, 166667.983784151]
[2019-04-27 18:51:27,436] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 18:51:27,439] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.8633377e-16 1.0000000e+00 1.6911150e-20 8.9375436e-17 7.8489139e-15], sampled 0.4543932362355796
[2019-04-27 18:52:00,850] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.06588011]
[2019-04-27 18:52:00,852] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [32.0, 59.33333333333334, 1.0, 2.0, 0.3937410872695004, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6268486341850191, 6.9112, 6.9112, 121.9260426156618, 897565.2908170131, 897565.2908170131, 222180.5720457403]
[2019-04-27 18:52:00,853] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 18:52:00,857] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.4686229e-18 1.0000000e+00 5.8569855e-23 2.5859628e-19 2.1464101e-17], sampled 0.9552735487593433
[2019-04-27 18:52:04,860] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.06588011]
[2019-04-27 18:52:04,861] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.40956528, 73.14245995, 1.0, 2.0, 0.4145651400117227, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 508356.3432011523, 508356.3432011523, 130558.2529904809]
[2019-04-27 18:52:04,864] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 18:52:04,869] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.3349421e-17 1.0000000e+00 7.6605477e-22 7.5223449e-18 7.9357373e-16], sampled 0.10867589502247299
[2019-04-27 18:52:37,564] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-04-27 18:52:37,582] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-04-27 18:52:37,664] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-04-27 18:52:37,956] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-04-27 18:52:38,070] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-04-27 18:52:39,088] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 550000, evaluation results [550000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-04-27 18:52:40,967] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.8439116e-16 1.0000000e+00 5.3792105e-21 1.6643340e-17 8.0361497e-15], sum to 1.0000
[2019-04-27 18:52:40,975] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9516
[2019-04-27 18:52:40,984] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 94.0, 1.0, 2.0, 0.6850679220476161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 790593.1290413323, 790593.1290413323, 173822.8758559487], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4762800.0000, 
sim time next is 4763400.0000, 
raw observation next is [24.0, 94.00000000000001, 1.0, 2.0, 0.6971177608444268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 804456.785193714, 804456.7851937135, 176093.4873498215], 
processed observation next is [1.0, 0.13043478260869565, 0.4444444444444444, 0.9400000000000002, 1.0, 1.0, 0.6394259057671747, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2873059947120407, 0.28730599471204055, 0.3386413218265798], 
reward next is 0.6614, 
noisyNet noise sample is [array([0.6022342], dtype=float32), -0.78302956]. 
=============================================
[2019-04-27 18:52:43,048] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.2834449e-13 1.0000000e+00 6.2865250e-17 3.4240497e-14 4.6951466e-12], sum to 1.0000
[2019-04-27 18:52:43,057] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5681
[2019-04-27 18:52:43,065] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1736890.028257782 W.
[2019-04-27 18:52:43,069] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.7615274225405319, 1.0, 1.0, 0.7615274225405319, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1736890.028257782, 1736890.028257782, 328113.3407676909], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4795200.0000, 
sim time next is 4795800.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.5421560060434231, 1.0, 2.0, 0.5421560060434231, 1.0, 1.0, 0.8631300184095617, 6.911200000000001, 6.9112, 121.94756008, 1854944.407455947, 1854944.407455946, 364761.197181817], 
processed observation next is [1.0, 0.5217391304347826, 0.5185185185185185, 0.89, 1.0, 1.0, 0.4549476262421703, 1.0, 1.0, 0.4549476262421703, 1.0, 0.5, 0.8289125230119521, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.662480145519981, 0.6624801455199807, 0.7014638407342635], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.6870542], dtype=float32), -2.0026739]. 
=============================================
[2019-04-27 18:52:44,202] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.9401446e-12 1.0000000e+00 1.9731310e-17 7.9688114e-14 1.5536489e-09], sum to 1.0000
[2019-04-27 18:52:44,212] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3441
[2019-04-27 18:52:44,215] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 94.00000000000001, 1.0, 2.0, 0.7938015909375321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 904772.3580829006, 904772.3580829006, 194669.4562563653], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4817400.0000, 
sim time next is 4818000.0000, 
raw observation next is [27.0, 94.0, 1.0, 2.0, 0.7772373642332258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 885881.5968871053, 885881.5968871053, 191288.7202012075], 
processed observation next is [1.0, 0.782608695652174, 0.5555555555555556, 0.94, 1.0, 1.0, 0.7348063859919354, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3163862846025376, 0.3163862846025376, 0.36786292346386057], 
reward next is 0.6321, 
noisyNet noise sample is [array([1.8049757], dtype=float32), -0.8412495]. 
=============================================
[2019-04-27 18:52:44,247] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[51.6493  ]
 [51.926613]
 [52.12683 ]
 [51.240753]
 [51.201103]], R is [[51.8822403 ]
 [51.98905563]
 [52.09943771]
 [52.22267151]
 [52.34905624]].
[2019-04-27 18:52:45,812] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.7675781e-12 1.0000000e+00 3.4846472e-16 6.0350388e-12 4.0921822e-08], sum to 1.0000
[2019-04-27 18:52:45,818] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6373
[2019-04-27 18:52:45,826] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1596873.042891187 W.
[2019-04-27 18:52:45,831] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.96666666666667, 93.83333333333334, 1.0, 2.0, 0.77365619820835, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426156315, 1596873.042891187, 1596873.042891186, 331060.5621889127], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4870200.0000, 
sim time next is 4870800.0000, 
raw observation next is [26.0, 94.0, 1.0, 2.0, 0.4838006443912733, 1.0, 1.0, 0.4838006443912733, 1.0, 2.0, 0.7702263821578912, 6.9112, 6.9112, 121.94756008, 1655101.161788221, 1655101.161788221, 335709.3675422046], 
processed observation next is [1.0, 0.391304347826087, 0.5185185185185185, 0.94, 1.0, 1.0, 0.38547695760865874, 1.0, 0.5, 0.38547695760865874, 1.0, 1.0, 0.712782977697364, 0.0, 0.0, 0.8096049824067558, 0.5911075577815075, 0.5911075577815075, 0.6455949375811627], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.13794656], dtype=float32), -1.7301844]. 
=============================================
[2019-04-27 18:52:46,871] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.6676335e-13 9.9999988e-01 8.7887470e-17 4.0361369e-12 1.4288022e-07], sum to 1.0000
[2019-04-27 18:52:46,879] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5624
[2019-04-27 18:52:46,882] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 95.0, 1.0, 2.0, 0.7007576060915878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 798665.8840208598, 798665.8840208598, 176285.4888292016], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4854600.0000, 
sim time next is 4855200.0000, 
raw observation next is [25.0, 95.33333333333334, 1.0, 2.0, 0.7021330694477667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 800234.3423646354, 800234.3423646354, 176546.3962223546], 
processed observation next is [1.0, 0.17391304347826086, 0.48148148148148145, 0.9533333333333335, 1.0, 1.0, 0.6453965112473412, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2857979794159412, 0.2857979794159412, 0.339512300427605], 
reward next is 0.6605, 
noisyNet noise sample is [array([-1.3945456], dtype=float32), -1.3121963]. 
=============================================
[2019-04-27 18:53:01,038] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.2872358e-16 1.0000000e+00 6.8659052e-21 1.4885228e-17 1.2478443e-13], sum to 1.0000
[2019-04-27 18:53:01,052] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1897
[2019-04-27 18:53:01,055] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.91666666666666, 94.0, 1.0, 2.0, 0.7277766804573926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 829476.6656039328, 829476.6656039328, 181470.5269141785], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5104200.0000, 
sim time next is 5104800.0000, 
raw observation next is [25.9, 94.0, 1.0, 2.0, 0.7233741735154634, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 824456.2507619836, 824456.2507619836, 180617.6095221585], 
processed observation next is [0.0, 0.08695652173913043, 0.5148148148148147, 0.94, 1.0, 1.0, 0.6706835398993611, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2944486609864227, 0.2944486609864227, 0.34734155677338174], 
reward next is 0.6527, 
noisyNet noise sample is [array([2.2760696], dtype=float32), -1.5805138]. 
=============================================
[2019-04-27 18:53:04,602] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.9491438e-14 1.0000000e+00 4.5766700e-18 2.3347485e-15 1.5028081e-11], sum to 1.0000
[2019-04-27 18:53:04,613] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4722
[2019-04-27 18:53:04,619] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.6748494630513809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 769123.0988516951, 769123.0988516951, 171435.6612174352], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5187000.0000, 
sim time next is 5187600.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.6746178602351648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 768859.0097118813, 768859.0097118813, 171392.8369413446], 
processed observation next is [1.0, 0.043478260869565216, 0.48148148148148145, 0.94, 1.0, 1.0, 0.6126403098037676, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27459250346852904, 0.27459250346852904, 0.32960160950258577], 
reward next is 0.6704, 
noisyNet noise sample is [array([-1.3953661], dtype=float32), -1.3288776]. 
=============================================
[2019-04-27 18:53:14,689] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.6445567e-15 1.0000000e+00 2.5084193e-19 9.4798445e-16 6.5054960e-13], sum to 1.0000
[2019-04-27 18:53:14,701] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9624
[2019-04-27 18:53:14,706] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.6, 88.66666666666667, 1.0, 2.0, 0.7754533329536198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 896698.4985974324, 896698.4985974324, 191575.6668961981], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5368800.0000, 
sim time next is 5369400.0000, 
raw observation next is [24.55, 89.0, 1.0, 2.0, 0.7800177780294841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 902071.2844874734, 902071.2844874734, 192510.7482531475], 
processed observation next is [1.0, 0.13043478260869565, 0.46481481481481485, 0.89, 1.0, 1.0, 0.7381164024160525, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.32216831588838335, 0.32216831588838335, 0.37021297740989906], 
reward next is 0.6298, 
noisyNet noise sample is [array([1.4053807], dtype=float32), 0.045525987]. 
=============================================
[2019-04-27 18:53:15,175] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.7184036e-13 1.0000000e+00 3.2980617e-18 3.6238937e-13 8.2071121e-12], sum to 1.0000
[2019-04-27 18:53:15,181] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3439
[2019-04-27 18:53:15,192] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1887263.474581133 W.
[2019-04-27 18:53:15,195] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.5, 80.0, 1.0, 2.0, 0.8273880419161286, 1.0, 1.0, 0.8273880419161286, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260036300588, 1887263.474581133, 1887263.474581133, 355201.6605289077], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5398200.0000, 
sim time next is 5398800.0000, 
raw observation next is [27.33333333333334, 81.33333333333334, 1.0, 2.0, 0.5453790589470046, 1.0, 2.0, 0.5453790589470046, 1.0, 1.0, 0.8682612235995684, 6.911199999999999, 6.9112, 121.94756008, 1865983.348183523, 1865983.348183523, 366419.5010104037], 
processed observation next is [1.0, 0.4782608695652174, 0.5679012345679014, 0.8133333333333335, 1.0, 1.0, 0.4587845939845292, 1.0, 1.0, 0.4587845939845292, 1.0, 0.5, 0.8353265294994605, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6664226243512582, 0.6664226243512582, 0.7046528865584686], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.8481619], dtype=float32), -0.53978884]. 
=============================================
[2019-04-27 18:53:15,741] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.5278332e-13 1.0000000e+00 5.6481818e-17 1.8286713e-12 2.7098804e-11], sum to 1.0000
[2019-04-27 18:53:15,747] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2403
[2019-04-27 18:53:15,751] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.65, 91.00000000000001, 1.0, 2.0, 0.7248544647170104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 832007.4164577109, 832007.4164577109, 181198.6426863543], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5382600.0000, 
sim time next is 5383200.0000, 
raw observation next is [24.7, 91.0, 1.0, 2.0, 0.7001758612858788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 802808.7307504405, 802808.73075044, 176417.9912776289], 
processed observation next is [1.0, 0.30434782608695654, 0.4703703703703703, 0.91, 1.0, 1.0, 0.6430665015308081, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.28671740383944305, 0.2867174038394429, 0.33926536784159406], 
reward next is 0.6607, 
noisyNet noise sample is [array([-0.22832125], dtype=float32), 1.2262554]. 
=============================================
[2019-04-27 18:53:16,429] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.3458893e-11 1.0000000e+00 2.4155168e-13 2.4779398e-10 1.1219558e-09], sum to 1.0000
[2019-04-27 18:53:16,434] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6295
[2019-04-27 18:53:16,440] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1758477.955438081 W.
[2019-04-27 18:53:16,443] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.33333333333334, 79.33333333333334, 1.0, 2.0, 0.9152370616229162, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1758477.955438081, 1758477.955438081, 360277.4119914168], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5394000.0000, 
sim time next is 5394600.0000, 
raw observation next is [27.5, 78.5, 1.0, 2.0, 0.7585285550742961, 1.0, 1.0, 0.7585285550742961, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1730043.594764327, 1730043.594764328, 326915.652372635], 
processed observation next is [1.0, 0.43478260869565216, 0.5740740740740741, 0.785, 1.0, 1.0, 0.7125339941360668, 1.0, 0.5, 0.7125339941360668, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6178727124158311, 0.6178727124158314, 0.6286839468704519], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1499658], dtype=float32), -0.32490322]. 
=============================================
[2019-04-27 18:53:16,534] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.3945881e-14 1.0000000e+00 1.6745618e-17 4.0533677e-14 1.6221436e-13], sum to 1.0000
[2019-04-27 18:53:16,544] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1357
[2019-04-27 18:53:16,548] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.71666666666667, 81.5, 1.0, 2.0, 0.7735168804882332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 881638.6152818288, 881638.6152818288, 190535.2443008686], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5429400.0000, 
sim time next is 5430000.0000, 
raw observation next is [28.63333333333334, 82.0, 1.0, 2.0, 0.7735810363414096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 881711.7808654008, 881711.7808654003, 190548.178987384], 
processed observation next is [1.0, 0.8695652173913043, 0.6160493827160496, 0.82, 1.0, 1.0, 0.7304536146921543, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.314897064594786, 0.31489706459478584, 0.36643880574496923], 
reward next is 0.6336, 
noisyNet noise sample is [array([1.5329739], dtype=float32), 1.2510121]. 
=============================================
[2019-04-27 18:53:16,560] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[50.20067 ]
 [50.35993 ]
 [50.73527 ]
 [51.088486]
 [51.120052]], R is [[49.38372803]
 [49.52347946]
 [49.66218185]
 [49.80034256]
 [49.9379425 ]].
[2019-04-27 18:53:17,992] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2043155e-11 1.0000000e+00 6.3660997e-14 7.8904487e-11 2.9749175e-10], sum to 1.0000
[2019-04-27 18:53:18,001] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5775
[2019-04-27 18:53:18,006] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.2, 94.0, 1.0, 2.0, 0.9314903747591982, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1061818.296472485, 1061818.296472485, 224606.913870452], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5457600.0000, 
sim time next is 5458200.0000, 
raw observation next is [26.18333333333333, 94.16666666666667, 1.0, 2.0, 0.9367500359967994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1067818.032228082, 1067818.032228082, 225815.8585610021], 
processed observation next is [1.0, 0.17391304347826086, 0.5253086419753085, 0.9416666666666668, 1.0, 1.0, 0.9247024238057135, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3813635829386007, 0.3813635829386007, 0.4342612664634656], 
reward next is 0.5657, 
noisyNet noise sample is [array([1.7626384], dtype=float32), 0.68859816]. 
=============================================
[2019-04-27 18:53:24,309] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.8762633e-11 1.0000000e+00 2.4415986e-14 4.8289889e-10 8.7446861e-10], sum to 1.0000
[2019-04-27 18:53:24,313] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9551
[2019-04-27 18:53:24,318] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1595686.081382297 W.
[2019-04-27 18:53:24,323] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.96666666666667, 82.66666666666667, 1.0, 2.0, 0.4664485865171611, 1.0, 1.0, 0.4664485865171611, 1.0, 2.0, 0.7426013409052326, 6.911199999999999, 6.9112, 121.94756008, 1595686.081382297, 1595686.081382297, 327412.2422381717], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5562600.0000, 
sim time next is 5563200.0000, 
raw observation next is [26.03333333333333, 82.33333333333334, 1.0, 2.0, 0.7364790976405057, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426156618, 1554438.801719441, 1554438.80171944, 323958.9676365827], 
processed observation next is [1.0, 0.391304347826087, 0.519753086419753, 0.8233333333333335, 1.0, 1.0, 0.686284640048221, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5551567148998003, 0.5551567148998, 0.6229980146857359], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.0301594], dtype=float32), 0.5540968]. 
=============================================
[2019-04-27 18:53:26,929] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2292565e-15 1.0000000e+00 1.4637168e-20 2.8947772e-15 1.9024296e-14], sum to 1.0000
[2019-04-27 18:53:26,934] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1338
[2019-04-27 18:53:26,938] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.98333333333333, 94.33333333333334, 1.0, 2.0, 0.6696340512320098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 763176.1568501076, 763176.1568501076, 170473.6962465814], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5605800.0000, 
sim time next is 5606400.0000, 
raw observation next is [24.86666666666667, 94.66666666666667, 1.0, 2.0, 0.6642675975172375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 757057.0355005105, 757057.0355005105, 169488.2944826844], 
processed observation next is [1.0, 0.9130434782608695, 0.47654320987654336, 0.9466666666666668, 1.0, 1.0, 0.6003185684729018, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27037751267875376, 0.27037751267875376, 0.3259390278513162], 
reward next is 0.6741, 
noisyNet noise sample is [array([0.44822147], dtype=float32), 0.6756888]. 
=============================================
[2019-04-27 18:53:30,268] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-04-27 18:53:30,269] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 18:53:30,270] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:53:30,271] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 18:53:30,271] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:53:30,272] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 18:53:30,272] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 18:53:30,272] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:53:30,273] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:53:30,273] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 18:53:30,276] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:53:30,288] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run24
[2019-04-27 18:53:30,307] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run24
[2019-04-27 18:53:30,308] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run24
[2019-04-27 18:53:30,329] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run24
[2019-04-27 18:53:30,366] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run24
[2019-04-27 18:53:57,936] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.06479069]
[2019-04-27 18:53:57,937] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.08333333333333, 57.66666666666667, 1.0, 2.0, 0.4118728697180286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 505404.3962627593, 505404.3962627588, 130183.3125619148]
[2019-04-27 18:53:57,938] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 18:53:57,942] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.5851646e-18 1.0000000e+00 1.9252204e-23 5.9433403e-17 4.4849706e-16], sampled 0.5071496168629321
[2019-04-27 18:54:14,300] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.06479069]
[2019-04-27 18:54:14,300] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.81402061, 91.51209712, 1.0, 2.0, 0.4256831007725365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 523666.8557191431, 523666.8557191431, 132205.2479894575]
[2019-04-27 18:54:14,304] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 18:54:14,308] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.7619904e-18 1.0000000e+00 1.3883409e-23 4.6519023e-17 3.4301123e-16], sampled 0.42443568001657506
[2019-04-27 18:54:29,791] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.06479069]
[2019-04-27 18:54:29,792] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [33.21617357, 50.74159135, 1.0, 2.0, 0.9786489509070321, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.013116127572481, 6.9112, 121.9255216929165, 1167842.067878132, 1115652.124380707, 235613.5530158862]
[2019-04-27 18:54:29,793] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 18:54:29,799] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.1711937e-17 1.0000000e+00 6.6524769e-22 9.0599237e-16 7.0092540e-15], sampled 0.6920100363935457
[2019-04-27 18:54:33,626] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.06479069]
[2019-04-27 18:54:33,627] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.0, 79.0, 1.0, 2.0, 0.671584592982212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 765400.2823636725, 765400.2823636722, 170836.9257330816]
[2019-04-27 18:54:33,628] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 18:54:33,632] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.1573217e-19 1.0000000e+00 1.5059594e-25 6.4648549e-19 4.7345209e-18], sampled 0.21205288736965366
[2019-04-27 18:54:49,996] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.06479069]
[2019-04-27 18:54:49,996] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [32.33333333333334, 47.33333333333334, 1.0, 2.0, 0.5840857687266164, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 672714.1810164286, 672714.1810164286, 155706.7387027433]
[2019-04-27 18:54:49,997] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 18:54:49,999] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.09092128e-18 1.00000000e+00 4.30011077e-23 1.10521924e-16
 9.04124556e-16], sampled 0.0037465631479814965
[2019-04-27 18:54:52,090] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.06479069]
[2019-04-27 18:54:52,091] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.77972088833334, 65.81335869833333, 1.0, 2.0, 0.5338942143887225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 631300.652327129, 631300.652327129, 148109.5663741932]
[2019-04-27 18:54:52,093] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 18:54:52,095] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.2188486e-18 1.0000000e+00 2.3614854e-23 7.1917716e-17 5.4240411e-16], sampled 0.41026218683902227
[2019-04-27 18:55:07,764] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.06479069]
[2019-04-27 18:55:07,765] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.5, 85.33333333333333, 1.0, 2.0, 0.6043099051827229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 692545.1807164123, 692545.1807164123, 159010.7514776636]
[2019-04-27 18:55:07,766] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 18:55:07,769] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.0317917e-18 1.0000000e+00 9.3935190e-24 3.6988870e-17 2.9449755e-16], sampled 0.9146570922940227
[2019-04-27 18:55:20,292] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.6619 2445343923.2757 746.0000
[2019-04-27 18:55:20,314] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8582.8836 2248719302.2630 553.0000
[2019-04-27 18:55:20,424] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-04-27 18:55:20,470] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-04-27 18:55:20,665] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-04-27 18:55:21,681] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 575000, evaluation results [575000.0, 8100.661928194693, 2445343923.2757144, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8582.883594560977, 2248719302.2630363, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-04-27 18:55:23,467] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.3828584e-19 1.0000000e+00 2.9449875e-23 9.0102145e-18 2.8770063e-17], sum to 1.0000
[2019-04-27 18:55:23,468] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2600
[2019-04-27 18:55:23,473] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.56666666666667, 74.0, 1.0, 2.0, 0.7312500074333736, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 833437.5098906177, 833437.5098906177, 182149.1916902764], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5682000.0000, 
sim time next is 5682600.0000, 
raw observation next is [29.4, 75.0, 1.0, 2.0, 0.7440681908811801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 848055.0349222095, 848055.034922209, 184659.0969731581], 
processed observation next is [0.0, 0.782608695652174, 0.6444444444444444, 0.75, 1.0, 1.0, 0.6953192748585478, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.30287679818650337, 0.3028767981865032, 0.35511364802530404], 
reward next is 0.6449, 
noisyNet noise sample is [array([-0.02309403], dtype=float32), -1.3756877]. 
=============================================
[2019-04-27 18:55:25,069] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.9125345e-16 1.0000000e+00 7.2744734e-22 1.1982915e-15 3.3980081e-13], sum to 1.0000
[2019-04-27 18:55:25,083] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3658
[2019-04-27 18:55:25,090] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.95, 97.0, 1.0, 2.0, 0.5092100330453363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 607666.6994001782, 607666.6994001782, 144361.5665911681], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5710200.0000, 
sim time next is 5710800.0000, 
raw observation next is [21.9, 97.0, 1.0, 2.0, 0.5073335924601324, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 605987.5222317474, 605987.5222317474, 144084.5163284274], 
processed observation next is [0.0, 0.08695652173913043, 0.36666666666666664, 0.97, 1.0, 1.0, 0.41349237197634814, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21642411508276693, 0.21642411508276693, 0.27708560832389884], 
reward next is 0.7229, 
noisyNet noise sample is [array([-0.16096294], dtype=float32), -0.90385795]. 
=============================================
[2019-04-27 18:55:37,943] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.2351106e-18 1.0000000e+00 7.3485446e-24 6.0265799e-17 1.8317036e-17], sum to 1.0000
[2019-04-27 18:55:37,952] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8170
[2019-04-27 18:55:37,961] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.98333333333333, 72.16666666666667, 1.0, 2.0, 0.4895213811556143, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 587936.2764403995, 587936.2764403995, 141404.3203550857], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5951400.0000, 
sim time next is 5952000.0000, 
raw observation next is [24.76666666666667, 73.33333333333334, 1.0, 2.0, 0.4874253980267235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 585736.4319147958, 585736.4319147958, 141089.5578702785], 
processed observation next is [1.0, 0.9130434782608695, 0.4728395061728396, 0.7333333333333334, 1.0, 1.0, 0.38979214050800426, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20919158282671277, 0.20919158282671277, 0.2713260728274587], 
reward next is 0.7287, 
noisyNet noise sample is [array([0.36361858], dtype=float32), 0.18307553]. 
=============================================
[2019-04-27 18:55:37,983] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[69.84295 ]
 [70.14781 ]
 [70.38512 ]
 [70.721634]
 [70.656944]], R is [[70.24337006]
 [70.26900482]
 [70.29387665]
 [70.31848907]
 [70.34323883]].
[2019-04-27 18:55:40,120] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.2434339e-15 1.0000000e+00 2.9664387e-19 2.1219238e-15 6.0207529e-14], sum to 1.0000
[2019-04-27 18:55:40,127] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9880
[2019-04-27 18:55:40,141] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1782913.841608608 W.
[2019-04-27 18:55:40,145] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 57.0, 1.0, 2.0, 0.5211241766101017, 1.0, 1.0, 0.5211241766101017, 1.0, 2.0, 0.829646660992849, 6.911199999999999, 6.9112, 121.94756008, 1782913.841608608, 1782913.841608609, 354078.0108364121], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6020400.0000, 
sim time next is 6021000.0000, 
raw observation next is [29.0, 56.5, 1.0, 2.0, 0.7796244177913461, 1.0, 2.0, 0.7796244177913461, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1778206.697305062, 1778206.697305061, 335404.9582643529], 
processed observation next is [1.0, 0.6956521739130435, 0.6296296296296297, 0.565, 1.0, 1.0, 0.7376481164182691, 1.0, 1.0, 0.7376481164182691, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6350738204660936, 0.6350738204660932, 0.6450095351237556], 
reward next is 0.3550, 
noisyNet noise sample is [array([-0.68883216], dtype=float32), 0.87517005]. 
=============================================
[2019-04-27 18:55:40,162] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[55.914707]
 [54.93024 ]
 [55.16654 ]
 [54.96477 ]
 [55.09156 ]], R is [[55.38537598]
 [54.8315239 ]
 [54.28321075]
 [53.74037933]
 [53.20297623]].
[2019-04-27 18:55:41,331] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.7486818e-14 1.0000000e+00 1.9485648e-19 2.4053366e-14 4.1384092e-14], sum to 1.0000
[2019-04-27 18:55:41,339] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4783
[2019-04-27 18:55:41,348] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1398422.541704565 W.
[2019-04-27 18:55:41,354] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.16666666666667, 65.33333333333333, 1.0, 2.0, 0.6132552131228193, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9763222716194788, 6.911199999999999, 6.9112, 121.9260426156618, 1398422.541704565, 1398422.541704565, 299050.5243349741], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6005400.0000, 
sim time next is 6006000.0000, 
raw observation next is [28.33333333333334, 64.66666666666667, 1.0, 2.0, 0.3737899885894023, 1.0, 1.0, 0.3737899885894023, 1.0, 2.0, 0.5950858353243812, 6.9112, 6.9112, 121.94756008, 1278444.98294127, 1278444.98294127, 285791.1407163669], 
processed observation next is [1.0, 0.5217391304347826, 0.6049382716049385, 0.6466666666666667, 1.0, 1.0, 0.25451189117785994, 1.0, 0.5, 0.25451189117785994, 1.0, 1.0, 0.49385729415547647, 0.0, 0.0, 0.8096049824067558, 0.45658749390759645, 0.45658749390759645, 0.5495983475314747], 
reward next is 0.4504, 
noisyNet noise sample is [array([0.49149254], dtype=float32), 1.5318491]. 
=============================================
[2019-04-27 18:55:41,376] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[54.900505]
 [54.191376]
 [52.894253]
 [52.896275]
 [53.230732]], R is [[54.6319809 ]
 [54.51056671]
 [54.34599304]
 [53.8025322 ]
 [53.67244339]].
[2019-04-27 18:55:41,807] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.8664158e-15 1.0000000e+00 1.7373772e-21 4.0303264e-17 2.5850580e-17], sum to 1.0000
[2019-04-27 18:55:41,817] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1685
[2019-04-27 18:55:41,825] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 63.0, 1.0, 2.0, 0.5247075830143278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 620250.5280835626, 620250.528083563, 146616.303947614], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6030000.0000, 
sim time next is 6030600.0000, 
raw observation next is [27.36666666666667, 63.83333333333333, 1.0, 2.0, 0.5270640805494377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 622866.6193444512, 622866.6193444512, 146989.4578061923], 
processed observation next is [1.0, 0.8260869565217391, 0.569135802469136, 0.6383333333333333, 1.0, 1.0, 0.43698104827314005, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22245236405158972, 0.22245236405158972, 0.2826720342426775], 
reward next is 0.7173, 
noisyNet noise sample is [array([1.024667], dtype=float32), -0.50218505]. 
=============================================
[2019-04-27 18:55:52,038] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.4880327e-19 1.0000000e+00 5.2193559e-23 5.3493456e-17 3.9389001e-18], sum to 1.0000
[2019-04-27 18:55:52,047] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0165
[2019-04-27 18:55:52,054] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 87.0, 1.0, 2.0, 0.4715221460329455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 569737.3137958134, 569737.3137958129, 138747.1275013859], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6237000.0000, 
sim time next is 6237600.0000, 
raw observation next is [22.4, 87.66666666666666, 1.0, 2.0, 0.4706855398522619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 568851.1073646268, 568851.1073646268, 138623.509583969], 
processed observation next is [0.0, 0.17391304347826086, 0.38518518518518513, 0.8766666666666666, 1.0, 1.0, 0.3698637379193594, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20316110977308102, 0.20316110977308102, 0.2665836722768634], 
reward next is 0.7334, 
noisyNet noise sample is [array([1.0922337], dtype=float32), 0.5834115]. 
=============================================
[2019-04-27 18:55:54,815] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.3553994e-19 1.0000000e+00 8.9853024e-24 1.5934162e-17 1.1561095e-17], sum to 1.0000
[2019-04-27 18:55:54,822] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0097
[2019-04-27 18:55:54,825] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.45, 76.0, 1.0, 2.0, 0.5875032077380148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 679854.5787086722, 679854.5787086722, 156438.3155841795], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6258600.0000, 
sim time next is 6259200.0000, 
raw observation next is [26.6, 75.66666666666667, 1.0, 2.0, 0.5920689914890056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 683783.4336084949, 683783.4336084949, 157156.7674908945], 
processed observation next is [0.0, 0.43478260869565216, 0.5407407407407407, 0.7566666666666667, 1.0, 1.0, 0.5143678470107209, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24420836914589106, 0.24420836914589106, 0.3022245528671048], 
reward next is 0.6978, 
noisyNet noise sample is [array([0.00907537], dtype=float32), 0.12941632]. 
=============================================
[2019-04-27 18:55:59,914] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.9365771e-17 1.0000000e+00 8.0473752e-23 8.1005948e-16 2.7578751e-17], sum to 1.0000
[2019-04-27 18:55:59,922] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0875
[2019-04-27 18:55:59,929] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.2, 58.5, 1.0, 2.0, 0.6780574793010264, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 772781.1045409853, 772781.1045409848, 172031.4063571482], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6355800.0000, 
sim time next is 6356400.0000, 
raw observation next is [31.26666666666667, 58.33333333333333, 1.0, 2.0, 0.6825207222271539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 777870.4369836274, 777870.4369836274, 172861.1098184675], 
processed observation next is [0.0, 0.5652173913043478, 0.7135802469135804, 0.5833333333333333, 1.0, 1.0, 0.6220484788418499, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2778108703512955, 0.2778108703512955, 0.3324252111893606], 
reward next is 0.6676, 
noisyNet noise sample is [array([1.7077397], dtype=float32), 1.1415939]. 
=============================================
[2019-04-27 18:56:04,697] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.5969348e-12 1.0000000e+00 1.2447907e-15 4.0847542e-10 1.1978175e-09], sum to 1.0000
[2019-04-27 18:56:04,708] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6851
[2019-04-27 18:56:04,716] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.93333333333334, 58.5, 1.0, 2.0, 0.642353881006864, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 732070.3353543069, 732070.3353543069, 165518.3694028962], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6459000.0000, 
sim time next is 6459600.0000, 
raw observation next is [30.86666666666667, 59.0, 1.0, 2.0, 0.6584961059983069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 750476.1226142009, 750476.1226142009, 168435.3067240789], 
processed observation next is [1.0, 0.782608695652174, 0.6987654320987656, 0.59, 1.0, 1.0, 0.5934477452360796, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2680271866479289, 0.2680271866479289, 0.32391405139245943], 
reward next is 0.6761, 
noisyNet noise sample is [array([-0.82356566], dtype=float32), -0.0149109]. 
=============================================
[2019-04-27 18:56:06,901] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.9719876e-07 9.9712640e-01 3.7231609e-09 4.5896009e-05 2.8272665e-03], sum to 1.0000
[2019-04-27 18:56:06,912] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2640
[2019-04-27 18:56:06,924] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2150828.562589556 W.
[2019-04-27 18:56:06,927] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.63333333333333, 83.0, 1.0, 2.0, 0.9427976323882511, 1.0, 2.0, 0.9427976323882511, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2150828.562589556, 2150828.562589556, 406294.2841230651], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6514800.0000, 
sim time next is 6515400.0000, 
raw observation next is [27.76666666666667, 82.5, 1.0, 2.0, 0.9573079152272512, 1.0, 2.0, 0.9573079152272512, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 2183971.730461764, 2183971.730461764, 413044.7027622255], 
processed observation next is [1.0, 0.391304347826087, 0.5839506172839507, 0.825, 1.0, 1.0, 0.9491760895562514, 1.0, 1.0, 0.9491760895562514, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7799899037363444, 0.7799899037363444, 0.7943167360812029], 
reward next is 0.2057, 
noisyNet noise sample is [array([0.9714795], dtype=float32), -2.2624784]. 
=============================================
[2019-04-27 18:56:07,734] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.3601134e-06 9.4345206e-01 9.3185048e-07 2.2919883e-03 5.4249655e-02], sum to 1.0000
[2019-04-27 18:56:07,745] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1565
[2019-04-27 18:56:07,756] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1831538.627381149 W.
[2019-04-27 18:56:07,759] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.7, 87.0, 1.0, 2.0, 0.8029829453594739, 1.0, 1.0, 0.8029829453594739, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.926042550699, 1831538.627381149, 1831538.627381149, 344988.8711621293], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6510600.0000, 
sim time next is 6511200.0000, 
raw observation next is [26.83333333333334, 86.33333333333334, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 7.023309466502132, 6.9112, 121.9255504164751, 1935546.74249697, 1878136.907174256, 383731.961981506], 
processed observation next is [1.0, 0.34782608695652173, 0.5493827160493829, 0.8633333333333334, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, 0.011210946650213226, 0.0, 0.8094588611293874, 0.6912666937489179, 0.6707631811336628, 0.7379460807336654], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5940455], dtype=float32), 1.1316347]. 
=============================================
[2019-04-27 18:56:12,582] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-04-27 18:56:12,583] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 18:56:12,585] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:56:12,586] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 18:56:12,588] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 18:56:12,588] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 18:56:12,591] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:56:12,590] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 18:56:12,591] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:56:12,595] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:56:12,592] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:56:12,616] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run25
[2019-04-27 18:56:12,617] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run25
[2019-04-27 18:56:12,617] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run25
[2019-04-27 18:56:12,673] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run25
[2019-04-27 18:56:12,675] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run25
[2019-04-27 18:56:13,725] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.060724884]
[2019-04-27 18:56:13,725] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [18.63333333333333, 75.0, 1.0, 2.0, 0.2692745902795285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 347346.6718483305, 347346.6718483309, 111197.987624245]
[2019-04-27 18:56:13,725] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 18:56:13,726] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.2413668e-08 9.9993014e-01 4.9397758e-10 2.3462371e-05 4.6338551e-05], sampled 0.8094652888225682
[2019-04-27 18:56:31,873] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.060724884]
[2019-04-27 18:56:31,875] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.25937965, 47.53234100500001, 1.0, 2.0, 0.254432371226145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 328196.9942423798, 328196.9942423798, 101185.5122601832]
[2019-04-27 18:56:31,877] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 18:56:31,880] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [7.5999198e-14 1.0000000e+00 1.9153079e-17 3.9161674e-09 1.7209443e-08], sampled 0.31656525339870256
[2019-04-27 18:56:51,161] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.060724884]
[2019-04-27 18:56:51,162] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.66666666666667, 85.33333333333333, 1.0, 2.0, 0.9247742919566583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1056314.858726264, 1056314.858726264, 223183.4757283327]
[2019-04-27 18:56:51,163] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 18:56:51,167] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.9920541e-12 9.9999893e-01 6.1911620e-15 1.7413505e-07 9.0739553e-07], sampled 0.7935643062727862
[2019-04-27 18:57:02,491] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.060724884]
[2019-04-27 18:57:02,492] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.18120187666667, 95.84018569, 1.0, 2.0, 0.7334016761515214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 835891.1978016682, 835891.1978016682, 182567.9664287667]
[2019-04-27 18:57:02,494] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 18:57:02,498] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.7485743e-13 1.0000000e+00 5.0853347e-17 8.6585690e-09 4.6224265e-08], sampled 0.06766768098897125
[2019-04-27 18:57:56,974] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.060724884]
[2019-04-27 18:57:56,976] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.720185365, 72.55583243666668, 1.0, 2.0, 0.4914020927360514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 583524.5421690084, 583524.5421690079, 141454.5213833009]
[2019-04-27 18:57:56,978] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 18:57:56,979] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.2938689e-14 1.0000000e+00 9.2170974e-18 2.5658224e-09 1.2560978e-08], sampled 0.547820074315203
[2019-04-27 18:58:02,170] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-04-27 18:58:02,680] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8922.7190 2120467268.8749 430.0000
[2019-04-27 18:58:02,947] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8582.0656 2248750565.3170 553.0000
[2019-04-27 18:58:02,969] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8699.4377 2195116417.8953 572.0000
[2019-04-27 18:58:02,992] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8099.1656 2445371312.7580 746.0000
[2019-04-27 18:58:04,003] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 600000, evaluation results [600000.0, 8099.165606819504, 2445371312.7580395, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8922.718977508366, 2120467268.8749216, 430.0, 8582.065595029597, 2248750565.317003, 553.0, 8699.437655287054, 2195116417.895288, 572.0]
[2019-04-27 18:58:09,137] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.2864990e-09 9.9885345e-01 3.1315234e-13 2.8188546e-05 1.1182984e-03], sum to 1.0000
[2019-04-27 18:58:09,146] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6687
[2019-04-27 18:58:09,153] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.56666666666667, 38.66666666666666, 1.0, 2.0, 0.6479344315465754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 824238.6104015063, 824238.6104015068, 169353.888502713], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6691200.0000, 
sim time next is 6691800.0000, 
raw observation next is [26.78333333333333, 37.83333333333334, 1.0, 2.0, 0.6545198065386889, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 832510.5006622557, 832510.5006622557, 170579.3979445776], 
processed observation next is [1.0, 0.43478260869565216, 0.5475308641975308, 0.3783333333333334, 1.0, 1.0, 0.5887140554032011, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29732517880794845, 0.29732517880794845, 0.3280373037395723], 
reward next is 0.6720, 
noisyNet noise sample is [array([0.54775006], dtype=float32), 0.42044088]. 
=============================================
[2019-04-27 18:58:13,809] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.0833611e-10 9.9957579e-01 1.3370503e-14 1.1013730e-04 3.1413638e-04], sum to 1.0000
[2019-04-27 18:58:13,819] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5288
[2019-04-27 18:58:13,825] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 58.0, 1.0, 2.0, 0.7632835497382564, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 964826.2721790615, 964826.2721790615, 191891.143111451], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6770400.0000, 
sim time next is 6771000.0000, 
raw observation next is [23.51666666666667, 57.5, 1.0, 2.0, 0.7731592881213829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 976317.893267955, 976317.893267955, 193922.3183322574], 
processed observation next is [1.0, 0.34782608695652173, 0.4265432098765433, 0.575, 1.0, 1.0, 0.7299515334778368, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3486849618814125, 0.3486849618814125, 0.37292753525434114], 
reward next is 0.6271, 
noisyNet noise sample is [array([0.2380631], dtype=float32), -1.3488991]. 
=============================================
[2019-04-27 18:58:13,839] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[63.22966 ]
 [63.403973]
 [63.57943 ]
 [65.1681  ]
 [65.56664 ]], R is [[63.04343796]
 [63.04398346]
 [63.05129623]
 [63.0873642 ]
 [63.19813538]].
[2019-04-27 18:58:15,218] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.9017511e-09 9.9300355e-01 2.0142028e-12 2.1889235e-03 4.8075970e-03], sum to 1.0000
[2019-04-27 18:58:15,227] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0864
[2019-04-27 18:58:15,231] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.91666666666666, 48.5, 1.0, 2.0, 0.348391169364436, 1.0, 1.0, 0.348391169364436, 1.0, 2.0, 0.5626152702302638, 6.9112, 6.9112, 121.94756008, 1254835.81152779, 1254835.81152779, 274687.7437342136], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6790200.0000, 
sim time next is 6790800.0000, 
raw observation next is [27.93333333333333, 49.0, 1.0, 2.0, 0.9637005213648152, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.305919152005115, 6.9112, 121.9246403033821, 1372109.978446163, 1169980.817804029, 235489.4624777246], 
processed observation next is [1.0, 0.6086956521739131, 0.5901234567901233, 0.49, 1.0, 1.0, 0.9567863349581134, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.03947191520051154, 0.0, 0.8094528189249007, 0.4900392780164868, 0.4178502920728675, 0.45286435091870114], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.45565093], dtype=float32), 0.7422028]. 
=============================================
[2019-04-27 18:58:18,469] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9728114e-13 9.9998856e-01 2.6628381e-16 1.0987569e-05 4.8219096e-07], sum to 1.0000
[2019-04-27 18:58:18,479] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5792
[2019-04-27 18:58:18,485] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.05, 76.0, 1.0, 2.0, 0.4170536794387336, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 511755.8165295028, 511755.8165295028, 130924.8463437082], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6852600.0000, 
sim time next is 6853200.0000, 
raw observation next is [23.13333333333333, 76.0, 1.0, 2.0, 0.4204704285994022, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 515324.5426450467, 515324.5426450462, 131399.8317686173], 
processed observation next is [0.0, 0.30434782608695654, 0.41234567901234553, 0.76, 1.0, 1.0, 0.3100838435707169, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18404447951608813, 0.18404447951608793, 0.2526919841704179], 
reward next is 0.7473, 
noisyNet noise sample is [array([-0.89095503], dtype=float32), 0.041374464]. 
=============================================
[2019-04-27 18:58:19,855] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.7970739e-13 9.9996626e-01 9.8667712e-17 3.3628810e-05 1.6416404e-07], sum to 1.0000
[2019-04-27 18:58:19,864] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7264
[2019-04-27 18:58:19,868] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666667, 72.33333333333333, 1.0, 2.0, 0.4112048771921649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 507460.512861023, 507460.5128610226, 130161.2760578632], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6914400.0000, 
sim time next is 6915000.0000, 
raw observation next is [23.13333333333334, 72.66666666666667, 1.0, 2.0, 0.4120184714681898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 508346.5577404366, 508346.5577404366, 130274.6076579101], 
processed observation next is [0.0, 0.0, 0.4123456790123459, 0.7266666666666667, 1.0, 1.0, 0.3000219898430831, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1815523420501559, 0.1815523420501559, 0.25052809164982714], 
reward next is 0.7495, 
noisyNet noise sample is [array([0.692198], dtype=float32), 0.59425956]. 
=============================================
[2019-04-27 18:58:19,893] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[72.32902 ]
 [72.22752 ]
 [72.448364]
 [72.77502 ]
 [73.43611 ]], R is [[72.46292114]
 [72.48797607]
 [72.51296234]
 [72.53783417]
 [72.56255341]].
[2019-04-27 18:58:20,370] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.7035801e-14 9.9998558e-01 2.4487106e-16 1.6664159e-06 1.2782051e-05], sum to 1.0000
[2019-04-27 18:58:20,379] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7264
[2019-04-27 18:58:20,383] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.6, 53.0, 1.0, 2.0, 0.4929506838303012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 590847.6961084902, 590847.6961084902, 141896.6194574644], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6886800.0000, 
sim time next is 6887400.0000, 
raw observation next is [28.48333333333333, 53.33333333333334, 1.0, 2.0, 0.4907255136696769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 588635.1604891283, 588635.1604891283, 141565.7191472813], 
processed observation next is [0.0, 0.7391304347826086, 0.6104938271604937, 0.5333333333333334, 1.0, 1.0, 0.3937208496067583, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21022684303183153, 0.21022684303183153, 0.2722417675909256], 
reward next is 0.7278, 
noisyNet noise sample is [array([0.09820734], dtype=float32), 0.6092205]. 
=============================================
[2019-04-27 18:58:41,286] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.2794733e-15 1.0000000e+00 5.5413847e-18 2.8880303e-09 3.0336171e-09], sum to 1.0000
[2019-04-27 18:58:41,297] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2064
[2019-04-27 18:58:41,301] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.7, 90.0, 1.0, 2.0, 0.390953302734521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 483099.5897598541, 483099.5897598541, 127321.8212736234], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7281600.0000, 
sim time next is 7282200.0000, 
raw observation next is [20.75, 90.0, 1.0, 2.0, 0.3998408377965622, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 493721.4800946898, 493721.4800946898, 128557.3675457648], 
processed observation next is [1.0, 0.2608695652173913, 0.32407407407407407, 0.9, 1.0, 1.0, 0.2855248069006693, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1763291000338178, 0.1763291000338178, 0.24722570681877848], 
reward next is 0.7528, 
noisyNet noise sample is [array([-0.36634517], dtype=float32), -1.2660613]. 
=============================================
[2019-04-27 18:58:43,746] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.6789625e-15 1.0000000e+00 5.0328367e-19 5.8785830e-09 2.5214830e-10], sum to 1.0000
[2019-04-27 18:58:43,754] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6454
[2019-04-27 18:58:43,759] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.16666666666666, 72.33333333333333, 1.0, 2.0, 0.4486950694861558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 545686.5581658657, 545686.5581658657, 135418.4745850024], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7329000.0000, 
sim time next is 7329600.0000, 
raw observation next is [24.0, 73.0, 1.0, 2.0, 0.4456425775408741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 542498.7842246711, 542498.7842246711, 134980.486429471], 
processed observation next is [1.0, 0.8695652173913043, 0.4444444444444444, 0.73, 1.0, 1.0, 0.34005068754865964, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19374956579452537, 0.19374956579452537, 0.25957785851821347], 
reward next is 0.7404, 
noisyNet noise sample is [array([-0.90652037], dtype=float32), -1.573194]. 
=============================================
[2019-04-27 18:58:55,762] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-04-27 18:58:55,763] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 18:58:55,764] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:58:55,765] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 18:58:55,767] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:58:55,767] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 18:58:55,768] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 18:58:55,768] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 18:58:55,768] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:58:55,770] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:58:55,770] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 18:58:55,792] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run26
[2019-04-27 18:58:55,792] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run26
[2019-04-27 18:58:55,839] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run26
[2019-04-27 18:58:55,859] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run26
[2019-04-27 18:58:55,886] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run26
[2019-04-27 18:58:58,890] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.05570606]
[2019-04-27 18:58:58,891] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.65, 13.0, 1.0, 2.0, 0.332429341624753, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 428834.9771359836, 428834.9771359836, 100398.2709084508]
[2019-04-27 18:58:58,894] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 18:58:58,896] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.2966255e-16 1.0000000e+00 6.0801433e-20 7.1871522e-09 9.2276447e-12], sampled 0.7908522797392393
[2019-04-27 18:59:35,958] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.05570606]
[2019-04-27 18:59:35,959] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.6, 78.5, 1.0, 2.0, 0.7239934534030468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 825162.4468520439, 825162.4468520439, 180734.5703107144]
[2019-04-27 18:59:35,961] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 18:59:35,965] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.3757614e-16 1.0000000e+00 1.9511682e-19 2.2818906e-08 4.0482822e-11], sampled 0.6742907707665391
[2019-04-27 18:59:42,186] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.05570606]
[2019-04-27 18:59:42,187] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.70605634, 66.1616507, 1.0, 2.0, 0.6762289577138736, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 770696.0935212574, 770696.0935212574, 171692.59702328]
[2019-04-27 18:59:42,190] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 18:59:42,192] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.2351905e-17 1.0000000e+00 3.3172754e-20 8.0384428e-09 1.0235602e-11], sampled 0.7215306939440728
[2019-04-27 18:59:53,584] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.05570606]
[2019-04-27 18:59:53,586] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.25282674, 63.54993228333333, 1.0, 2.0, 0.5371480435298558, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8761341027998586, 6.911200000000001, 6.9112, 121.9260426156618, 1308886.725998374, 1308886.725998374, 267451.855663999]
[2019-04-27 18:59:53,587] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 18:59:53,592] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.2031880e-15 9.9999976e-01 1.2039663e-18 2.9349201e-07 1.0006516e-09], sampled 0.20122174278730365
[2019-04-27 18:59:53,592] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1308886.725998374 W.
[2019-04-27 19:00:45,478] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8770.2619 2170687269.9890 493.0000
[2019-04-27 19:00:45,666] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8922.7936 2120465681.8079 430.0000
[2019-04-27 19:00:45,806] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8700.2439 2195050063.3561 572.0000
[2019-04-27 19:00:46,001] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8099.9706 2445378853.1784 746.0000
[2019-04-27 19:00:46,054] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8582.8787 2248724158.4353 553.0000
[2019-04-27 19:00:47,070] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 625000, evaluation results [625000.0, 8099.970618414005, 2445378853.1783895, 746.0, 8770.26189789365, 2170687269.989048, 493.0, 8922.793643896488, 2120465681.8079002, 430.0, 8582.87874517633, 2248724158.435329, 553.0, 8700.24389633916, 2195050063.35613, 572.0]
[2019-04-27 19:00:49,352] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.81342669e-14 1.00000000e+00 1.03769517e-16 3.66380313e-08
 6.95904134e-09], sum to 1.0000
[2019-04-27 19:00:49,362] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5646
[2019-04-27 19:00:49,368] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 64.0, 1.0, 2.0, 0.5563684855350272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 649402.1302626427, 649402.1302626427, 151455.2884353252], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7572600.0000, 
sim time next is 7573200.0000, 
raw observation next is [28.0, 63.33333333333333, 1.0, 2.0, 0.5520400656207464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 645809.8496416914, 645809.8496416914, 150802.1874930103], 
processed observation next is [0.0, 0.6521739130434783, 0.5925925925925926, 0.6333333333333333, 1.0, 1.0, 0.4667143638342218, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23064637487203266, 0.23064637487203266, 0.2900042067173275], 
reward next is 0.7100, 
noisyNet noise sample is [array([0.0337564], dtype=float32), -0.6147654]. 
=============================================
[2019-04-27 19:00:53,680] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.6712521e-12 9.9999797e-01 5.6127608e-14 1.9995216e-06 1.8783237e-09], sum to 1.0000
[2019-04-27 19:00:53,750] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2317
[2019-04-27 19:00:53,753] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.8, 80.0, 1.0, 2.0, 0.322042622797934, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 408737.690563814, 408737.6905638136, 118330.6812394425], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7680600.0000, 
sim time next is 7681200.0000, 
raw observation next is [19.76666666666667, 80.66666666666667, 1.0, 2.0, 0.3230369751178911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 409770.8072932655, 409770.8072932655, 118455.6877524351], 
processed observation next is [1.0, 0.9130434782608695, 0.2876543209876544, 0.8066666666666668, 1.0, 1.0, 0.19409163704510846, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14634671689045195, 0.14634671689045195, 0.22779939952391365], 
reward next is 0.7722, 
noisyNet noise sample is [array([1.0185932], dtype=float32), 1.6905005]. 
=============================================
[2019-04-27 19:00:55,024] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.5147166e-17 1.0000000e+00 7.0190328e-19 1.8593066e-10 9.5305394e-15], sum to 1.0000
[2019-04-27 19:00:55,034] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2267
[2019-04-27 19:00:55,039] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.61666666666667, 61.83333333333333, 1.0, 2.0, 0.2845657975707656, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 367076.0658637811, 367076.0658637811, 103239.6801006882], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7697400.0000, 
sim time next is 7698000.0000, 
raw observation next is [19.53333333333333, 63.66666666666667, 1.0, 2.0, 0.2569356552715931, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 331426.8222788958, 331426.8222788958, 101403.3617017033], 
processed observation next is [1.0, 0.08695652173913043, 0.2790123456790123, 0.6366666666666667, 1.0, 1.0, 0.11539958960903943, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1183667222424628, 0.1183667222424628, 0.19500646481096787], 
reward next is 0.8050, 
noisyNet noise sample is [array([-0.44986123], dtype=float32), 1.7519523]. 
=============================================
[2019-04-27 19:00:55,050] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[75.40698]
 [75.24019]
 [75.28917]
 [75.48834]
 [75.49926]], R is [[75.4678421 ]
 [75.51462555]
 [75.57784271]
 [75.63502502]
 [75.68575287]].
[2019-04-27 19:00:57,646] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.0834419e-13 9.9999905e-01 8.7127063e-15 9.1927188e-07 9.7734776e-10], sum to 1.0000
[2019-04-27 19:00:57,657] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2913
[2019-04-27 19:00:57,662] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.86666666666667, 88.33333333333333, 1.0, 2.0, 0.4143964881666974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 519414.6016883031, 519414.6016883035, 130782.3038034367], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7719000.0000, 
sim time next is 7719600.0000, 
raw observation next is [20.23333333333333, 86.66666666666667, 1.0, 2.0, 0.5090539534326908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 636627.2642614106, 636627.2642614106, 145160.2923676994], 
processed observation next is [1.0, 0.34782608695652173, 0.3049382716049382, 0.8666666666666667, 1.0, 1.0, 0.4155404207532033, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22736688009336092, 0.22736688009336092, 0.27915440839942196], 
reward next is 0.7208, 
noisyNet noise sample is [array([0.09695178], dtype=float32), 0.37123483]. 
=============================================
[2019-04-27 19:01:05,998] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.8566022e-10 2.8564527e-03 2.1655303e-10 9.9713886e-01 4.7152712e-06], sum to 1.0000
[2019-04-27 19:01:06,007] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9214
[2019-04-27 19:01:06,013] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.38333333333334, 79.33333333333334, 1.0, 2.0, 0.2104127855406149, 1.0, 2.0, 0.2104127855406149, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 513190.7817546589, 513190.7817546589, 161884.2754025391], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7869000.0000, 
sim time next is 7869600.0000, 
raw observation next is [22.3, 80.0, 1.0, 2.0, 0.2103964389357937, 1.0, 2.0, 0.2103964389357937, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 513089.0555081098, 513089.0555081103, 161878.7018955107], 
processed observation next is [1.0, 0.08695652173913043, 0.38148148148148153, 0.8, 1.0, 1.0, 0.05999576063784966, 1.0, 1.0, 0.05999576063784966, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18324609125289637, 0.18324609125289654, 0.3113051959529052], 
reward next is 0.6887, 
noisyNet noise sample is [array([-0.00752595], dtype=float32), 0.57845944]. 
=============================================
[2019-04-27 19:01:06,033] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9979758e-10 2.6956617e-03 2.2449956e-10 9.9729949e-01 4.8578518e-06], sum to 1.0000
[2019-04-27 19:01:06,041] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5853
[2019-04-27 19:01:06,046] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.3, 80.0, 1.0, 2.0, 0.2103964389357937, 1.0, 2.0, 0.2103964389357937, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 513089.0555081098, 513089.0555081103, 161878.7018955107], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7869600.0000, 
sim time next is 7870200.0000, 
raw observation next is [22.16666666666667, 80.5, 1.0, 2.0, 0.3305481517000073, 1.0, 2.0, 0.3305481517000073, 0.0, 2.0, 0.0, 6.9112, 6.9112, 122.0513847076852, 804579.6428085009, 804579.6428085009, 190067.1859164254], 
processed observation next is [1.0, 0.08695652173913043, 0.3765432098765434, 0.805, 1.0, 1.0, 0.2030335139285801, 1.0, 1.0, 0.2030335139285801, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8102942699645824, 0.2873498724316075, 0.2873498724316075, 0.3655138190700488], 
reward next is 0.6345, 
noisyNet noise sample is [array([-0.00752595], dtype=float32), 0.57845944]. 
=============================================
[2019-04-27 19:01:09,288] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:01:09,289] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:01:09,323] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run4
[2019-04-27 19:01:09,575] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:01:09,575] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:01:09,607] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run4
[2019-04-27 19:01:10,059] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:01:10,059] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:01:10,061] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run4
[2019-04-27 19:01:10,397] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:01:10,397] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:01:10,398] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run4
[2019-04-27 19:01:10,554] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:01:10,555] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:01:10,556] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run4
[2019-04-27 19:01:10,730] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:01:10,731] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:01:10,732] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run4
[2019-04-27 19:01:10,754] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:01:10,755] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:01:10,762] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:01:10,763] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:01:10,766] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:01:10,767] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:01:10,769] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run4
[2019-04-27 19:01:10,789] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:01:10,790] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:01:10,795] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run4
[2019-04-27 19:01:10,811] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:01:10,811] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:01:10,815] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run4
[2019-04-27 19:01:10,833] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run4
[2019-04-27 19:01:10,837] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:01:10,838] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:01:10,853] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:01:10,854] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:01:10,854] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:01:10,857] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:01:10,854] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:01:10,859] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:01:10,861] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:01:10,862] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:01:10,862] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run4
[2019-04-27 19:01:10,887] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run4
[2019-04-27 19:01:10,890] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run4
[2019-04-27 19:01:10,915] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run4
[2019-04-27 19:01:10,917] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run4
[2019-04-27 19:01:10,986] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run4
[2019-04-27 19:01:11,090] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.7446887e-13 5.2610307e-04 1.9615800e-11 9.9947387e-01 4.7030802e-08], sum to 1.0000
[2019-04-27 19:01:11,091] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2771
[2019-04-27 19:01:11,097] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.8, 48.0, 1.0, 2.0, 0.2080066055238081, 1.0, 2.0, 0.2080066055238081, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 507596.3586349685, 507596.3586349689, 161380.6093937097], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 72000.0000, 
sim time next is 72600.0000, 
raw observation next is [27.63333333333333, 48.83333333333333, 1.0, 2.0, 0.2083724138889098, 1.0, 2.0, 0.2083724138889098, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 508391.424617919, 508391.424617919, 161455.187344299], 
processed observation next is [1.0, 0.8695652173913043, 0.5790123456790122, 0.4883333333333333, 1.0, 1.0, 0.05758620701060692, 1.0, 1.0, 0.05758620701060692, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18156836593497108, 0.18156836593497108, 0.3104907448928827], 
reward next is 0.6895, 
noisyNet noise sample is [array([-1.1159136], dtype=float32), -0.80369663]. 
=============================================
[2019-04-27 19:01:14,450] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.0133442e-15 6.4666534e-07 2.3768791e-12 9.9999928e-01 1.0402060e-07], sum to 1.0000
[2019-04-27 19:01:14,460] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0876
[2019-04-27 19:01:14,466] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.43333333333333, 41.66666666666667, 1.0, 2.0, 0.3760034240126507, 1.0, 2.0, 0.3760034240126507, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 939907.2651692273, 939907.2651692268, 202668.2607006182], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 38400.0000, 
sim time next is 39000.0000, 
raw observation next is [26.66666666666667, 41.33333333333334, 1.0, 2.0, 0.3825296129812142, 1.0, 2.0, 0.3825296129812142, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 954718.2471548048, 954718.2471548048, 204432.8993193983], 
processed observation next is [1.0, 0.43478260869565216, 0.5432098765432101, 0.41333333333333344, 1.0, 1.0, 0.2649162059300169, 1.0, 1.0, 0.2649162059300169, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3409708025552874, 0.3409708025552874, 0.3931401909988429], 
reward next is 0.6069, 
noisyNet noise sample is [array([0.619195], dtype=float32), 0.4621986]. 
=============================================
[2019-04-27 19:01:14,478] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[67.66379 ]
 [67.361885]
 [67.08045 ]
 [66.732956]
 [66.35683 ]], R is [[67.83216095]
 [67.76409149]
 [67.69520569]
 [67.63143158]
 [67.56732941]].
[2019-04-27 19:01:16,136] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.5663340e-11 1.7316714e-04 1.8208511e-11 9.9982613e-01 7.6418507e-07], sum to 1.0000
[2019-04-27 19:01:16,148] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0517
[2019-04-27 19:01:16,156] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.63333333333333, 48.83333333333333, 1.0, 2.0, 0.2083724138889098, 1.0, 2.0, 0.2083724138889098, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 508391.424617919, 508391.424617919, 161455.187344299], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 72600.0000, 
sim time next is 73200.0000, 
raw observation next is [27.46666666666667, 49.66666666666666, 1.0, 2.0, 0.2089580245072081, 1.0, 2.0, 0.2089580245072081, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 509721.0223379351, 509721.0223379356, 161576.5784573222], 
processed observation next is [1.0, 0.8695652173913043, 0.5728395061728396, 0.4966666666666666, 1.0, 1.0, 0.05828336250858107, 1.0, 1.0, 0.05828336250858107, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18204322226354824, 0.1820432222635484, 0.31072418934100426], 
reward next is 0.6893, 
noisyNet noise sample is [array([0.3719331], dtype=float32), 1.6390388]. 
=============================================
[2019-04-27 19:01:16,978] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.4133622e-14 9.4814750e-06 2.0283952e-11 9.9999046e-01 5.9338191e-08], sum to 1.0000
[2019-04-27 19:01:16,986] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9590
[2019-04-27 19:01:16,996] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.8, 70.0, 1.0, 2.0, 0.2112528789525807, 1.0, 2.0, 0.2112528789525807, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 514965.0758530516, 514965.0758530516, 162054.5721010506], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 88200.0000, 
sim time next is 88800.0000, 
raw observation next is [23.7, 70.66666666666667, 1.0, 2.0, 0.2110202638709117, 1.0, 2.0, 0.2110202638709117, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 514370.8528701344, 514370.8528701344, 162003.9163078047], 
processed observation next is [1.0, 0.0, 0.4333333333333333, 0.7066666666666667, 1.0, 1.0, 0.06073840937013296, 1.0, 1.0, 0.06073840937013296, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.183703876025048, 0.183703876025048, 0.3115459928996244], 
reward next is 0.6885, 
noisyNet noise sample is [array([-0.61860937], dtype=float32), 0.76139295]. 
=============================================
[2019-04-27 19:01:28,530] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.2431908e-16 9.9958283e-01 1.0460764e-15 4.1714351e-04 1.7575490e-10], sum to 1.0000
[2019-04-27 19:01:28,538] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8494
[2019-04-27 19:01:28,542] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.53333333333333, 31.66666666666666, 1.0, 2.0, 0.3255146501780785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 417308.4994851525, 417308.4994851521, 118787.1440004978], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 308400.0000, 
sim time next is 309000.0000, 
raw observation next is [27.61666666666666, 31.83333333333333, 1.0, 2.0, 0.3284199911805811, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 420654.9027171928, 420654.9027171928, 119160.7371147522], 
processed observation next is [0.0, 0.5652173913043478, 0.5783950617283948, 0.3183333333333333, 1.0, 1.0, 0.20049998950069176, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15023389382756885, 0.15023389382756885, 0.22915526368221578], 
reward next is 0.7708, 
noisyNet noise sample is [array([-0.03215102], dtype=float32), -1.2934548]. 
=============================================
[2019-04-27 19:01:28,556] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[74.702805]
 [74.67882 ]
 [74.65346 ]
 [74.6222  ]
 [74.5983  ]], R is [[74.73801422]
 [74.76219177]
 [74.78642273]
 [74.81072235]
 [74.83509827]].
[2019-04-27 19:01:29,870] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.6433377e-15 9.9999094e-01 5.3582219e-17 9.0532294e-06 2.6836901e-11], sum to 1.0000
[2019-04-27 19:01:29,879] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0133
[2019-04-27 19:01:29,885] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.56666666666667, 38.0, 1.0, 2.0, 0.3089983855880311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 396999.1533287051, 396999.1533287051, 116692.2243855212], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 333600.0000, 
sim time next is 334200.0000, 
raw observation next is [25.43333333333334, 38.5, 1.0, 2.0, 0.3076428040405929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 395302.2177137018, 395302.2177137018, 116522.486019649], 
processed observation next is [0.0, 0.8695652173913043, 0.4975308641975311, 0.385, 1.0, 1.0, 0.17576524290546774, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1411793634691792, 0.1411793634691792, 0.2240817038839404], 
reward next is 0.7759, 
noisyNet noise sample is [array([1.6772529], dtype=float32), -0.21991009]. 
=============================================
[2019-04-27 19:01:30,466] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.3207200e-17 9.9999261e-01 1.2894588e-16 7.4132736e-06 7.1406440e-12], sum to 1.0000
[2019-04-27 19:01:30,474] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5981
[2019-04-27 19:01:30,477] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.3, 46.0, 1.0, 2.0, 0.2850492714174047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 367584.3988154322, 367584.3988154322, 113735.2502815941], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 343200.0000, 
sim time next is 343800.0000, 
raw observation next is [23.15, 46.5, 1.0, 2.0, 0.2833036039235055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 365426.5926981753, 365426.5926981753, 113217.1536443969], 
processed observation next is [0.0, 1.0, 0.4129629629629629, 0.465, 1.0, 1.0, 0.14679000467083989, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13050949739220546, 0.13050949739220546, 0.21772529546999403], 
reward next is 0.7823, 
noisyNet noise sample is [array([0.7415026], dtype=float32), 0.07968045]. 
=============================================
[2019-04-27 19:01:31,684] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.1204851e-10 9.9295104e-01 2.1792221e-10 7.0482786e-03 6.5710395e-07], sum to 1.0000
[2019-04-27 19:01:31,693] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2911
[2019-04-27 19:01:31,696] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.61666666666667, 28.66666666666667, 1.0, 2.0, 0.8346164714490397, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1066198.32306383, 1066198.32306383, 207136.6739364598], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 385800.0000, 
sim time next is 386400.0000, 
raw observation next is [28.73333333333333, 28.33333333333334, 1.0, 2.0, 0.8619720609519015, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.934334829982964, 6.9112, 121.9258814214401, 1112881.231436209, 1101034.146379936, 213192.8746299885], 
processed observation next is [1.0, 0.4782608695652174, 0.619753086419753, 0.2833333333333334, 1.0, 1.0, 0.8356810249427399, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.00231348299829639, 0.0, 0.809461058658134, 0.39745758265578895, 0.39322648084997713, 0.4099862973653625], 
reward next is 0.4743, 
noisyNet noise sample is [array([-0.8428066], dtype=float32), 0.10268744]. 
=============================================
[2019-04-27 19:01:31,704] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.8182853e-13 9.6254867e-01 6.8191039e-12 3.7451025e-02 1.9942061e-07], sum to 1.0000
[2019-04-27 19:01:31,717] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5815
[2019-04-27 19:01:31,722] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.4, 51.0, 1.0, 2.0, 0.3160735117197063, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 407730.292078171, 407730.292078171, 108785.4556091034], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 369000.0000, 
sim time next is 369600.0000, 
raw observation next is [21.8, 49.33333333333333, 1.0, 2.0, 0.3048605294815812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 393261.9971985405, 393261.9971985405, 107980.9358145416], 
processed observation next is [1.0, 0.2608695652173913, 0.362962962962963, 0.4933333333333333, 1.0, 1.0, 0.17245301128759669, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14045071328519304, 0.14045071328519304, 0.2076556457971954], 
reward next is 0.7923, 
noisyNet noise sample is [array([1.2896177], dtype=float32), -0.74370193]. 
=============================================
[2019-04-27 19:01:33,574] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.22431015e-14 1.25869393e-01 2.72462972e-11 8.74130547e-01
 7.41723305e-09], sum to 1.0000
[2019-04-27 19:01:33,582] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1502
[2019-04-27 19:01:33,588] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.16666666666667, 45.83333333333334, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 371073.858929012, 371073.8589290125, 146427.6795419576], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 431400.0000, 
sim time next is 432000.0000, 
raw observation next is [23.9, 47.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 367516.2610158184, 367516.2610158189, 145887.2341125823], 
processed observation next is [1.0, 0.0, 0.4407407407407407, 0.47, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1312558075056494, 0.1312558075056496, 0.28055237329342747], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4061756], dtype=float32), 0.976546]. 
=============================================
[2019-04-27 19:01:33,604] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[79.02947]
 [78.79541]
 [78.59972]
 [78.60851]
 [78.40574]], R is [[76.99008179]
 [76.22018433]
 [75.45798492]
 [74.70340729]
 [73.95637512]].
[2019-04-27 19:01:36,900] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3550341e-10 3.3171907e-01 1.7394660e-11 6.6827691e-01 4.0990085e-06], sum to 1.0000
[2019-04-27 19:01:36,907] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4187
[2019-04-27 19:01:36,912] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.36666666666667, 39.66666666666667, 1.0, 2.0, 0.4883743580818957, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8041387841206175, 6.911200000000001, 6.9112, 121.925822529228, 1202372.13885334, 1202372.138853339, 249516.4655629864], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 470400.0000, 
sim time next is 471000.0000, 
raw observation next is [28.68333333333333, 38.83333333333334, 1.0, 2.0, 0.4763992457646682, 1.0, 1.0, 0.4763992457646682, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260425485513, 1168130.371023035, 1168130.371023035, 231399.7962840865], 
processed observation next is [1.0, 0.43478260869565216, 0.6179012345679011, 0.3883333333333334, 1.0, 1.0, 0.3766657687674621, 1.0, 0.5, 0.3766657687674621, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.809462128374592, 0.4171894182225125, 0.4171894182225125, 0.4449996082386279], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.39837325], dtype=float32), 0.28870228]. 
=============================================
[2019-04-27 19:01:36,937] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[53.754074]
 [53.35835 ]
 [53.3644  ]
 [52.940098]
 [52.953735]], R is [[53.63761139]
 [53.62139511]
 [53.08518219]
 [52.55433273]
 [52.54896164]].
[2019-04-27 19:01:37,519] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.0411708e-11 6.8854940e-01 1.5350155e-14 3.1145057e-01 8.9387120e-09], sum to 1.0000
[2019-04-27 19:01:37,527] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9876
[2019-04-27 19:01:37,531] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.1, 27.0, 1.0, 2.0, 0.5395498151384978, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8874822867049479, 6.911199999999999, 6.9112, 121.9260426156618, 1327111.789659654, 1327111.789659654, 267562.5183674587], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 484200.0000, 
sim time next is 484800.0000, 
raw observation next is [32.13333333333334, 26.66666666666666, 1.0, 2.0, 0.5283513236183718, 1.0, 1.0, 0.5283513236183718, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1294735.423191036, 1294735.423191036, 247866.1220539128], 
processed observation next is [1.0, 0.6086956521739131, 0.7456790123456792, 0.2666666666666666, 1.0, 1.0, 0.4385134804980616, 1.0, 0.5, 0.4385134804980616, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.46240550828251287, 0.46240550828251287, 0.47666561933444773], 
reward next is 0.5233, 
noisyNet noise sample is [array([0.598381], dtype=float32), 0.68607837]. 
=============================================
[2019-04-27 19:01:37,932] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.543995e-12 5.750605e-01 1.876440e-13 4.249395e-01 9.733975e-09], sum to 1.0000
[2019-04-27 19:01:37,939] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0137
[2019-04-27 19:01:37,945] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1385889.480762385 W.
[2019-04-27 19:01:37,948] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.3, 25.33333333333334, 1.0, 2.0, 0.5649791078301906, 1.0, 2.0, 0.5649791078301906, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1385889.480762385, 1385889.480762385, 260103.7470597678], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 487200.0000, 
sim time next is 487800.0000, 
raw observation next is [32.35, 25.0, 1.0, 2.0, 0.5623743875236185, 1.0, 2.0, 0.5623743875236185, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1380303.018912247, 1380303.018912247, 259242.8441566816], 
processed observation next is [1.0, 0.6521739130434783, 0.7537037037037038, 0.25, 1.0, 1.0, 0.4790171280043077, 1.0, 1.0, 0.4790171280043077, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.49296536389723106, 0.49296536389723106, 0.4985439310705415], 
reward next is 0.5015, 
noisyNet noise sample is [array([0.6305358], dtype=float32), 1.1673391]. 
=============================================
[2019-04-27 19:01:38,758] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.8605103e-17 9.9998713e-01 7.9945426e-18 1.2834375e-05 1.9712644e-15], sum to 1.0000
[2019-04-27 19:01:38,763] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9752
[2019-04-27 19:01:38,768] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.76666666666667, 58.0, 1.0, 2.0, 0.3143918569470782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 400044.3823367539, 400044.3823367539, 117367.4629770729], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 517800.0000, 
sim time next is 518400.0000, 
raw observation next is [22.6, 59.0, 1.0, 2.0, 0.3161306310778657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 402241.7789574796, 402241.7789574796, 117586.9293508268], 
processed observation next is [1.0, 0.0, 0.39259259259259266, 0.59, 1.0, 1.0, 0.18586979890222108, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14365777819909986, 0.14365777819909986, 0.22612871029005155], 
reward next is 0.7739, 
noisyNet noise sample is [array([0.20232594], dtype=float32), 1.1106814]. 
=============================================
[2019-04-27 19:01:39,364] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-04-27 19:01:39,366] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 19:01:39,366] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:01:39,367] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 19:01:39,368] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:01:39,372] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 19:01:39,373] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:01:39,374] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 19:01:39,375] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:01:39,375] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 19:01:39,376] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:01:39,393] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run27
[2019-04-27 19:01:39,412] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run27
[2019-04-27 19:01:39,413] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run27
[2019-04-27 19:01:39,413] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run27
[2019-04-27 19:01:39,466] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run27
[2019-04-27 19:01:44,147] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.056391086]
[2019-04-27 19:01:44,149] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.4, 40.33333333333334, 1.0, 2.0, 0.2568608103298115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 331330.2573262817, 331330.2573262817, 99289.32532996582]
[2019-04-27 19:01:44,153] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 19:01:44,156] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.1636038e-16 9.9998736e-01 4.6098155e-18 1.2644923e-05 7.8912351e-15], sampled 0.11157912024411853
[2019-04-27 19:02:18,443] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.056391086]
[2019-04-27 19:02:18,444] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.450454275, 109.161371935, 1.0, 2.0, 0.6309080988205471, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 724361.7763412287, 724361.7763412287, 163740.1867190942]
[2019-04-27 19:02:18,446] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 19:02:18,451] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0060153e-16 9.9995530e-01 4.9144405e-18 4.4700890e-05 1.4737011e-14], sampled 0.4180796802941209
[2019-04-27 19:02:22,605] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.056391086]
[2019-04-27 19:02:22,606] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.0, 53.0, 1.0, 2.0, 0.6453518534597893, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9254638956889, 1450429.86086753, 1450429.860867531, 307577.9558551774]
[2019-04-27 19:02:22,607] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 19:02:22,610] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.0944628e-15 9.9822503e-01 1.5212632e-16 1.7750224e-03 9.4078911e-13], sampled 0.5781371663805333
[2019-04-27 19:02:22,613] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1450429.86086753 W.
[2019-04-27 19:02:24,066] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.056391086]
[2019-04-27 19:02:24,068] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.41666666666667, 81.16666666666666, 1.0, 2.0, 0.7418263987154212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 845498.5329754519, 845498.5329754519, 184218.1763405486]
[2019-04-27 19:02:24,071] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 19:02:24,073] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.1370437e-17 9.9999177e-01 3.4861157e-19 8.2526776e-06 1.2258467e-15], sampled 0.5075708525072166
[2019-04-27 19:02:41,113] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.056391086]
[2019-04-27 19:02:41,114] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.973019705, 93.771105135, 1.0, 2.0, 0.7813133261724123, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 890530.0063515453, 890530.0063515453, 192115.8895961471]
[2019-04-27 19:02:41,115] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 19:02:41,119] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.9294368e-17 9.9999118e-01 6.0655681e-19 8.8680727e-06 1.8129133e-15], sampled 0.9523654349556819
[2019-04-27 19:03:11,903] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.056391086]
[2019-04-27 19:03:11,904] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.08333333333333, 88.33333333333334, 1.0, 2.0, 0.5015441693889275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 598186.5484143368, 598186.5484143368, 143137.5368447128]
[2019-04-27 19:03:11,905] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 19:03:11,910] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.4334530e-18 9.9999785e-01 1.6284685e-19 2.1307744e-06 3.6694521e-16], sampled 0.9148172221993366
[2019-04-27 19:03:11,964] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.056391086]
[2019-04-27 19:03:11,965] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.33333333333334, 92.33333333333334, 1.0, 2.0, 0.4916709017359416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 588718.7999620141, 588718.7999620141, 141675.8536041503]
[2019-04-27 19:03:11,966] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 19:03:11,971] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.3293353e-17 9.9999142e-01 1.4776412e-18 8.5261654e-06 3.1806223e-15], sampled 0.07757749328575969
[2019-04-27 19:03:29,749] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8096.3411 2445087011.7662 743.0000
[2019-04-27 19:03:29,903] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8923.2317 2120150198.0973 429.0000
[2019-04-27 19:03:29,938] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8699.0396 2194715660.1928 572.0000
[2019-04-27 19:03:30,153] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.0025 2170074471.6137 489.0000
[2019-04-27 19:03:30,188] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8580.1185 2248724127.9618 551.0000
[2019-04-27 19:03:31,205] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 650000, evaluation results [650000.0, 8096.341071420186, 2445087011.766209, 743.0, 8771.002512944173, 2170074471.6137414, 489.0, 8923.231729776013, 2120150198.0973473, 429.0, 8580.118530832997, 2248724127.9617906, 551.0, 8699.039603475385, 2194715660.1928005, 572.0]
[2019-04-27 19:03:32,908] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.40049665e-11 9.99422669e-01 2.71154355e-13 5.77365456e-04
 1.38975831e-09], sum to 1.0000
[2019-04-27 19:03:32,913] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3714
[2019-04-27 19:03:32,916] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.6, 61.83333333333334, 1.0, 2.0, 0.4820516630407299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 610325.6266807457, 610325.6266807457, 140995.0138968359], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 546600.0000, 
sim time next is 547200.0000, 
raw observation next is [22.8, 61.0, 1.0, 2.0, 0.4468045129692679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 565374.5075995541, 565374.5075995541, 135605.1980425162], 
processed observation next is [1.0, 0.34782608695652173, 0.4, 0.61, 1.0, 1.0, 0.3414339440110332, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20191946699984076, 0.20191946699984076, 0.2607792270048388], 
reward next is 0.7392, 
noisyNet noise sample is [array([1.1085266], dtype=float32), -0.051490612]. 
=============================================
[2019-04-27 19:03:41,089] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.5843556e-15 9.9990034e-01 2.9692850e-15 9.9680023e-05 3.9546071e-15], sum to 1.0000
[2019-04-27 19:03:41,097] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2461
[2019-04-27 19:03:41,105] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.4, 36.0, 1.0, 2.0, 0.3265185410015409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 415281.4473621547, 415281.4473621547, 118908.7326844837], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 691200.0000, 
sim time next is 691800.0000, 
raw observation next is [27.25, 36.33333333333334, 1.0, 2.0, 0.3248276622884298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 413371.302047394, 413371.302047394, 118693.4771103282], 
processed observation next is [1.0, 0.0, 0.5648148148148148, 0.36333333333333345, 1.0, 1.0, 0.19622340748622596, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1476326078740693, 0.1476326078740693, 0.22825668675063115], 
reward next is 0.7717, 
noisyNet noise sample is [array([0.5095092], dtype=float32), -0.7840133]. 
=============================================
[2019-04-27 19:03:47,069] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.7517535e-19 1.0000000e+00 5.1663274e-23 2.2814433e-11 3.0157476e-22], sum to 1.0000
[2019-04-27 19:03:47,076] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8223
[2019-04-27 19:03:47,081] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.75, 59.5, 1.0, 2.0, 0.3967756018646837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 492753.2833602829, 492753.2833602829, 128190.6224741973], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 863400.0000, 
sim time next is 864000.0000, 
raw observation next is [24.6, 60.0, 1.0, 2.0, 0.3963819435663795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 492629.6902845696, 492629.6902845696, 128143.1040813485], 
processed observation next is [0.0, 0.0, 0.46666666666666673, 0.6, 1.0, 1.0, 0.2814070756742613, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17593917510163198, 0.17593917510163198, 0.2464290463102856], 
reward next is 0.7536, 
noisyNet noise sample is [array([2.8371093], dtype=float32), 1.014492]. 
=============================================
[2019-04-27 19:03:47,096] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[74.1765 ]
 [74.22145]
 [74.26995]
 [74.30523]
 [74.35147]], R is [[73.06277466]
 [73.08562469]
 [73.10805511]
 [73.12967682]
 [73.1504364 ]].
[2019-04-27 19:03:47,441] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.6186481e-22 1.0000000e+00 2.8634519e-24 3.0890644e-12 5.7451008e-24], sum to 1.0000
[2019-04-27 19:03:47,451] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1718
[2019-04-27 19:03:47,456] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.8, 36.0, 1.0, 2.0, 0.4428193808689765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 538629.9263188443, 538629.9263188443, 134549.417049791], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 831600.0000, 
sim time next is 832200.0000, 
raw observation next is [31.83333333333333, 36.0, 1.0, 2.0, 0.451744172047828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 549252.22961249, 549252.22961249, 135869.1248977841], 
processed observation next is [0.0, 0.6521739130434783, 0.7345679012345677, 0.36, 1.0, 1.0, 0.3473144905331286, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1961615105758893, 0.1961615105758893, 0.26128677864958477], 
reward next is 0.7387, 
noisyNet noise sample is [array([1.9485016], dtype=float32), 1.0651889]. 
=============================================
[2019-04-27 19:03:48,598] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.0436818e-21 1.0000000e+00 9.3938321e-26 2.5887690e-13 5.6302853e-24], sum to 1.0000
[2019-04-27 19:03:48,606] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6211
[2019-04-27 19:03:48,611] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.73333333333333, 36.0, 1.0, 2.0, 0.440577431192305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 536153.3300571898, 536153.3300571898, 134225.7522937798], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 826800.0000, 
sim time next is 827400.0000, 
raw observation next is [31.66666666666667, 36.0, 1.0, 2.0, 0.438918740594058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 534574.2719967477, 534574.2719967472, 133994.4202029712], 
processed observation next is [0.0, 0.5652173913043478, 0.7283950617283952, 0.36, 1.0, 1.0, 0.33204611975483095, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1909193828559813, 0.19091938285598115, 0.2576815773134062], 
reward next is 0.7423, 
noisyNet noise sample is [array([-0.14490318], dtype=float32), -2.0197585]. 
=============================================
[2019-04-27 19:03:51,745] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.3861606e-14 9.9999917e-01 1.2150321e-14 8.1669469e-07 8.1359005e-14], sum to 1.0000
[2019-04-27 19:03:51,753] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9725
[2019-04-27 19:03:51,761] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.13333333333333, 55.33333333333333, 1.0, 2.0, 0.8705229272035443, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260386307698, 1084525.2815283, 1084525.2815283, 214726.9673387181], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 992400.0000, 
sim time next is 993000.0000, 
raw observation next is [25.16666666666666, 55.16666666666667, 1.0, 2.0, 0.8841549373287773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.936555294524235, 6.9112, 121.9258529001212, 1114430.373187712, 1101446.216364027, 217805.4473415732], 
processed observation next is [1.0, 0.4782608695652174, 0.4876543209876541, 0.5516666666666667, 1.0, 1.0, 0.8620892111056873, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.002535529452423457, 0.0, 0.8094608693062366, 0.39801084756703997, 0.3933736487014382, 0.4188566295030254], 
reward next is 0.4544, 
noisyNet noise sample is [array([-1.1720557], dtype=float32), -1.148276]. 
=============================================
[2019-04-27 19:03:51,783] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[56.15878 ]
 [56.121944]
 [56.003323]
 [56.048088]
 [55.209595]], R is [[55.73840714]
 [55.76808548]
 [55.80903244]
 [55.86422348]
 [55.92518997]].
[2019-04-27 19:03:55,367] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.3019540e-17 1.0000000e+00 2.4205167e-20 3.8037751e-09 5.7269727e-20], sum to 1.0000
[2019-04-27 19:03:55,374] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4791
[2019-04-27 19:03:55,377] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 50.0, 1.0, 2.0, 0.3062173992077812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 390908.889819494, 390908.889819494, 116347.4439312228], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 945000.0000, 
sim time next is 945600.0000, 
raw observation next is [23.7, 49.66666666666667, 1.0, 2.0, 0.302166911303943, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 386270.7018576023, 386270.7018576023, 115844.8351577635], 
processed observation next is [0.0, 0.9565217391304348, 0.4333333333333333, 0.4966666666666667, 1.0, 1.0, 0.16924632298088454, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13795382209200083, 0.13795382209200083, 0.2227785291495452], 
reward next is 0.7772, 
noisyNet noise sample is [array([-1.6123147], dtype=float32), -0.48301947]. 
=============================================
[2019-04-27 19:04:01,434] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.0863341e-11 2.8422086e-02 1.5758813e-11 9.7157794e-01 8.4148737e-11], sum to 1.0000
[2019-04-27 19:04:01,444] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0342
[2019-04-27 19:04:01,446] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.6, 49.66666666666667, 1.0, 2.0, 0.3700635705101669, 1.0, 2.0, 0.3700635705101669, 0.0, 2.0, 0.0, 6.911200000000003, 6.9112, 121.9260426156618, 926247.6950631527, 926247.6950631513, 201071.0226837375], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1077600.0000, 
sim time next is 1078200.0000, 
raw observation next is [24.75, 49.0, 1.0, 2.0, 0.3517869082130597, 1.0, 2.0, 0.3517869082130597, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 880315.3116276235, 880315.311627623, 196163.6611830041], 
processed observation next is [1.0, 0.4782608695652174, 0.4722222222222222, 0.49, 1.0, 1.0, 0.2283177478726901, 1.0, 1.0, 0.2283177478726901, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3143983255812941, 0.31439832558129394, 0.37723780996731554], 
reward next is 0.6228, 
noisyNet noise sample is [array([0.87183833], dtype=float32), -0.36413354]. 
=============================================
[2019-04-27 19:04:13,636] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.9384696e-13 1.7842659e-06 3.1196958e-15 9.9999821e-01 4.1842662e-12], sum to 1.0000
[2019-04-27 19:04:13,641] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1009
[2019-04-27 19:04:13,647] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.4, 86.0, 1.0, 2.0, 0.1880602714680618, 1.0, 2.0, 0.1880602714680618, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 466070.7289551296, 466070.72895513, 157429.3490218834], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1296000.0000, 
sim time next is 1296600.0000, 
raw observation next is [20.31666666666667, 86.0, 1.0, 2.0, 0.1864133895604496, 1.0, 2.0, 0.1864133895604496, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 462496.604188363, 462496.6041883634, 157097.9177829754], 
processed observation next is [1.0, 0.0, 0.3080246913580248, 0.86, 1.0, 1.0, 0.0314445113814876, 1.0, 1.0, 0.0314445113814876, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1651773586387011, 0.16517735863870123, 0.30211138035187574], 
reward next is 0.6979, 
noisyNet noise sample is [array([0.0683628], dtype=float32), -1.0511093]. 
=============================================
[2019-04-27 19:04:13,872] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.4827831e-13 1.2252086e-05 6.4700097e-14 9.9998772e-01 2.4152119e-12], sum to 1.0000
[2019-04-27 19:04:13,881] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5479
[2019-04-27 19:04:13,885] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.06666666666667, 86.0, 1.0, 2.0, 0.1830066638207964, 1.0, 2.0, 0.1830066638207964, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 455571.8980364757, 455571.8980364757, 156426.99966199], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1298400.0000, 
sim time next is 1299000.0000, 
raw observation next is [19.98333333333333, 86.0, 1.0, 2.0, 0.1820128961664638, 1.0, 2.0, 0.1820128961664638, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 453589.4943546311, 453589.4943546316, 156232.5038588604], 
processed observation next is [1.0, 0.0, 0.2956790123456789, 0.86, 1.0, 1.0, 0.026205828769599752, 1.0, 1.0, 0.026205828769599752, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16199624798379683, 0.161996247983797, 0.3004471228055008], 
reward next is 0.6996, 
noisyNet noise sample is [array([-0.26395193], dtype=float32), -1.1873633]. 
=============================================
[2019-04-27 19:04:13,901] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[57.733723]
 [58.11186 ]
 [58.572594]
 [59.05919 ]
 [59.829338]], R is [[57.57774353]
 [57.70114899]
 [57.82307053]
 [57.94339371]
 [58.06184769]].
[2019-04-27 19:04:16,560] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.2233733e-18 2.4265212e-09 3.8003819e-16 1.0000000e+00 8.3646926e-15], sum to 1.0000
[2019-04-27 19:04:16,567] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5380
[2019-04-27 19:04:16,573] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.83333333333334, 31.33333333333334, 1.0, 2.0, 0.5118244714644212, 1.0, 2.0, 0.5118244714644212, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1251953.207101441, 1251953.207101441, 242452.7147138636], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1351200.0000, 
sim time next is 1351800.0000, 
raw observation next is [30.85, 31.0, 1.0, 2.0, 0.5038865330488532, 1.0, 2.0, 0.5038865330488532, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1233904.285710089, 1233904.28571009, 239958.6072573215], 
processed observation next is [1.0, 0.6521739130434783, 0.6981481481481482, 0.31, 1.0, 1.0, 0.40938872982006336, 1.0, 1.0, 0.40938872982006336, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.44068010203931746, 0.4406801020393179, 0.4614588601102337], 
reward next is 0.5385, 
noisyNet noise sample is [array([-1.2663888], dtype=float32), 1.5077221]. 
=============================================
[2019-04-27 19:04:19,709] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.6152002e-10 3.1112512e-03 3.7696338e-10 9.9688870e-01 4.5087190e-10], sum to 1.0000
[2019-04-27 19:04:19,715] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1903
[2019-04-27 19:04:19,720] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.15, 23.5, 1.0, 2.0, 0.1936134680430955, 1.0, 2.0, 0.1936134680430955, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 481406.8438933726, 481406.8438933726, 158621.9654485618], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1429800.0000, 
sim time next is 1430400.0000, 
raw observation next is [33.3, 23.0, 1.0, 2.0, 0.1941860356621836, 1.0, 2.0, 0.1941860356621836, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 482983.6902552617, 482983.6902552621, 158745.2055758859], 
processed observation next is [0.0, 0.5652173913043478, 0.7888888888888888, 0.23, 1.0, 1.0, 0.040697661502599514, 1.0, 1.0, 0.040697661502599514, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1724941750911649, 0.17249417509116502, 0.30527924149208824], 
reward next is 0.6947, 
noisyNet noise sample is [array([0.09839503], dtype=float32), -1.1713822]. 
=============================================
[2019-04-27 19:04:21,699] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-04-27 19:04:21,699] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 19:04:21,701] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:04:21,703] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 19:04:21,704] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 19:04:21,704] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 19:04:21,707] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:04:21,705] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:04:21,707] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 19:04:21,708] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:04:21,709] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:04:21,724] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run28
[2019-04-27 19:04:21,745] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run28
[2019-04-27 19:04:21,746] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run28
[2019-04-27 19:04:21,746] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run28
[2019-04-27 19:04:21,813] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run28
[2019-04-27 19:04:31,688] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.05612319]
[2019-04-27 19:04:31,689] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.54787323, 48.43398078, 1.0, 2.0, 0.2302312366980376, 1.0, 2.0, 0.2302312366980376, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 563905.2562347351, 563905.2562347355, 166262.3131165678]
[2019-04-27 19:04:31,690] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 19:04:31,696] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.3841384e-13 6.2593422e-06 5.0991411e-14 9.9999368e-01 5.0771067e-12], sampled 0.014154000565546498
[2019-04-27 19:04:36,220] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.05612319]
[2019-04-27 19:04:36,223] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.94229474666667, 58.63049171666667, 1.0, 2.0, 0.2771560482647844, 1.0, 2.0, 0.2771560482647844, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 660903.8858048199, 660903.8858048199, 176397.3625302441]
[2019-04-27 19:04:36,223] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 19:04:36,226] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.6455553e-14 2.2275935e-06 6.9347701e-15 9.9999774e-01 9.9368680e-13], sampled 0.7521237196653568
[2019-04-27 19:04:36,989] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.05612319]
[2019-04-27 19:04:36,991] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [15.81866900666667, 62.68422692333333, 1.0, 2.0, 0.2276943955277065, 1.0, 2.0, 0.2276943955277065, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 587513.8516050397, 587513.8516050401, 147094.7827955702]
[2019-04-27 19:04:36,991] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 19:04:36,994] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.1455748e-12 5.0522440e-06 3.5056341e-13 9.9999499e-01 2.6273749e-11], sampled 0.997095511444482
[2019-04-27 19:04:39,783] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.05612319]
[2019-04-27 19:04:39,784] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [32.2, 27.0, 1.0, 2.0, 0.1900435262176161, 1.0, 2.0, 0.1900435262176161, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 471017.0311527143, 471017.0311527147, 157840.4802510866]
[2019-04-27 19:04:39,784] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 19:04:39,787] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.5970740e-14 2.4200242e-05 1.5256246e-15 9.9997580e-01 2.3709450e-13], sampled 0.36619325000538394
[2019-04-27 19:04:42,322] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.05612319]
[2019-04-27 19:04:42,322] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [19.393039925, 79.72570582166666, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 403020.0897782726, 403020.089778273, 151575.6658196193]
[2019-04-27 19:04:42,323] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 19:04:42,325] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.9905354e-13 7.5152288e-06 1.2384028e-13 9.9999249e-01 1.0300389e-11], sampled 0.30928244427411344
[2019-04-27 19:05:02,075] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.05612319]
[2019-04-27 19:05:02,076] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.1, 93.33333333333334, 1.0, 2.0, 0.3207301828892761, 1.0, 2.0, 0.3207301828892761, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 731051.5388226864, 731051.5388226868, 185509.3750443479]
[2019-04-27 19:05:02,081] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 19:05:02,084] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.9400988e-14 8.9428073e-07 1.0608294e-14 9.9999905e-01 1.4145695e-12], sampled 0.5054187533740392
[2019-04-27 19:05:36,292] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.05612319]
[2019-04-27 19:05:36,293] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.9, 82.0, 1.0, 2.0, 0.3313803879365738, 1.0, 2.0, 0.3313803879365738, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 755338.8845864112, 755338.8845864115, 188162.0823489208]
[2019-04-27 19:05:36,293] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 19:05:36,296] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.6695241e-14 7.1995696e-06 3.6098325e-15 9.9999285e-01 5.3543915e-13], sampled 0.6347286200714756
[2019-04-27 19:05:44,602] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.05612319]
[2019-04-27 19:05:44,603] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.5, 53.0, 1.0, 2.0, 0.3192663638297047, 1.0, 2.0, 0.3192663638297047, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 727713.4210260657, 727713.4210260662, 185148.4227547232]
[2019-04-27 19:05:44,604] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 19:05:44,607] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.9612777e-14 7.3932715e-06 2.5449060e-15 9.9999261e-01 3.9595652e-13], sampled 0.09788857300901932
[2019-04-27 19:05:48,088] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.05612319]
[2019-04-27 19:05:48,089] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.05, 80.33333333333334, 1.0, 2.0, 0.2761944768140914, 1.0, 2.0, 0.2761944768140914, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 641154.1783912359, 641154.1783912363, 175419.2015531165]
[2019-04-27 19:05:48,090] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 19:05:48,094] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.6403416e-14 2.0831906e-06 1.2942374e-14 9.9999797e-01 1.5632774e-12], sampled 0.12005889158169658
[2019-04-27 19:05:49,437] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.05612319]
[2019-04-27 19:05:49,439] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.24822307, 105.6008655, 1.0, 2.0, 0.4437998394365567, 1.0, 2.0, 0.4437998394365567, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1011753.675996017, 1011753.675996017, 218552.5405019915]
[2019-04-27 19:05:49,441] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 19:05:49,443] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.6182731e-15 2.5843534e-07 2.3622512e-15 9.9999976e-01 4.0546215e-13], sampled 0.2256108028831283
[2019-04-27 19:06:03,329] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.05612319]
[2019-04-27 19:06:03,330] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [19.0, 73.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 349254.8612679919, 349254.8612679919, 142897.3356656491]
[2019-04-27 19:06:03,332] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 19:06:03,334] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.4991064e-12 5.5282570e-05 4.7886884e-13 9.9994469e-01 2.9866450e-11], sampled 0.7450427383309485
[2019-04-27 19:06:11,889] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.9084 2495448318.0155 47.0000
[2019-04-27 19:06:11,914] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7479.0331 2465949724.2996 46.0000
[2019-04-27 19:06:12,054] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7798.2372 2410710491.6652 22.0000
[2019-04-27 19:06:12,067] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7523.7271 2668527814.0102 68.0000
[2019-04-27 19:06:12,229] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7122.2316 2438810430.6919 34.0000
[2019-04-27 19:06:13,247] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 675000, evaluation results [675000.0, 7523.727130323888, 2668527814.010175, 68.0, 7122.231561568615, 2438810430.6918583, 34.0, 7798.23719837083, 2410710491.6652117, 22.0, 6905.908355438081, 2495448318.015453, 47.0, 7479.033116937025, 2465949724.2996373, 46.0]
[2019-04-27 19:06:16,983] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4174131e-18 2.2349781e-08 1.2855428e-18 1.0000000e+00 7.1860674e-17], sum to 1.0000
[2019-04-27 19:06:16,990] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1005
[2019-04-27 19:06:16,999] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.83333333333334, 28.33333333333334, 1.0, 2.0, 0.2148300471986914, 1.0, 2.0, 0.2148300471986914, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 520381.6508326149, 520381.6508326154, 162706.4031666087], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1510800.0000, 
sim time next is 1511400.0000, 
raw observation next is [33.96666666666667, 27.66666666666666, 1.0, 2.0, 0.2125773592122416, 1.0, 2.0, 0.2125773592122416, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 515594.0870352507, 515594.0870352512, 162247.6527597879], 
processed observation next is [0.0, 0.4782608695652174, 0.8135802469135803, 0.2766666666666666, 1.0, 1.0, 0.06259209430028763, 1.0, 1.0, 0.06259209430028763, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18414074536973238, 0.18414074536973257, 0.31201471684574594], 
reward next is 0.6880, 
noisyNet noise sample is [array([1.0940553], dtype=float32), -0.57593423]. 
=============================================
[2019-04-27 19:06:17,398] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.9672784e-16 8.1312442e-07 3.8789747e-15 9.9999917e-01 3.8697246e-14], sum to 1.0000
[2019-04-27 19:06:17,406] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9276
[2019-04-27 19:06:17,411] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.58333333333334, 69.16666666666667, 1.0, 2.0, 0.2139521872414087, 1.0, 2.0, 0.2139521872414087, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 523594.0053470066, 523594.0053470071, 162700.3409146367], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1548600.0000, 
sim time next is 1549200.0000, 
raw observation next is [23.56666666666667, 68.33333333333334, 1.0, 2.0, 0.2125256507337809, 1.0, 2.0, 0.2125256507337809, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 521178.0849802529, 521178.0849802529, 162427.9155110003], 
processed observation next is [0.0, 0.9565217391304348, 0.4283950617283952, 0.6833333333333335, 1.0, 1.0, 0.06253053658783442, 1.0, 1.0, 0.06253053658783442, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18613503035009032, 0.18613503035009032, 0.31236137598269287], 
reward next is 0.6876, 
noisyNet noise sample is [array([2.0386047], dtype=float32), 0.24641454]. 
=============================================
[2019-04-27 19:06:23,445] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.2555914e-14 2.9970753e-08 5.6754011e-15 1.0000000e+00 7.2748435e-12], sum to 1.0000
[2019-04-27 19:06:23,456] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7109
[2019-04-27 19:06:23,459] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.61666666666667, 71.83333333333333, 1.0, 2.0, 0.1745228642243394, 1.0, 2.0, 0.1745228642243394, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 441187.6842340814, 441187.6842340819, 154811.4147590881], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1651800.0000, 
sim time next is 1652400.0000, 
raw observation next is [20.4, 73.0, 1.0, 2.0, 0.173439852513517, 1.0, 2.0, 0.173439852513517, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 438739.3250672899, 438739.3250672899, 154592.466559848], 
processed observation next is [1.0, 0.13043478260869565, 0.31111111111111106, 0.73, 1.0, 1.0, 0.015999824420853584, 1.0, 1.0, 0.015999824420853584, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15669261609546067, 0.15669261609546067, 0.2972932049227846], 
reward next is 0.7027, 
noisyNet noise sample is [array([0.47686887], dtype=float32), -0.7637993]. 
=============================================
[2019-04-27 19:06:28,834] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.5144552e-17 2.4534658e-10 1.3794341e-17 1.0000000e+00 3.5956904e-14], sum to 1.0000
[2019-04-27 19:06:28,842] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2410
[2019-04-27 19:06:28,847] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.28333333333333, 86.5, 1.0, 2.0, 0.1853040701412869, 1.0, 2.0, 0.1853040701412869, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 459694.2830426893, 459694.2830426897, 156864.0676595354], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1741800.0000, 
sim time next is 1742400.0000, 
raw observation next is [20.2, 87.0, 1.0, 2.0, 0.1846892901003732, 1.0, 2.0, 0.1846892901003732, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 458310.6505138573, 458310.6505138573, 156739.4194136935], 
processed observation next is [1.0, 0.17391304347826086, 0.3037037037037037, 0.87, 1.0, 1.0, 0.029392012024253792, 1.0, 1.0, 0.029392012024253792, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16368237518352047, 0.16368237518352047, 0.30142196041094904], 
reward next is 0.6986, 
noisyNet noise sample is [array([-0.99065995], dtype=float32), 2.1562]. 
=============================================
[2019-04-27 19:06:41,472] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.0340296e-12 5.4886355e-04 4.0073357e-15 9.9945110e-01 1.0223684e-11], sum to 1.0000
[2019-04-27 19:06:41,480] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9012
[2019-04-27 19:06:41,484] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.5, 91.0, 1.0, 2.0, 0.182812219205062, 1.0, 2.0, 0.182812219205062, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 455014.7011625297, 455014.7011625302, 156384.5215651548], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1989600.0000, 
sim time next is 1990200.0000, 
raw observation next is [19.5, 91.0, 1.0, 2.0, 0.1823988110556189, 1.0, 2.0, 0.1823988110556189, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 453992.9751785071, 453992.9751785075, 156298.5072259824], 
processed observation next is [0.0, 0.0, 0.2777777777777778, 0.91, 1.0, 1.0, 0.026665251256689153, 1.0, 1.0, 0.026665251256689153, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16214034827803825, 0.1621403482780384, 0.3005740523576585], 
reward next is 0.6994, 
noisyNet noise sample is [array([-1.2633065], dtype=float32), 0.85273635]. 
=============================================
[2019-04-27 19:06:43,495] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.4042123e-16 1.2697539e-07 3.3472647e-18 9.9999988e-01 1.6774467e-15], sum to 1.0000
[2019-04-27 19:06:43,503] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7412
[2019-04-27 19:06:43,510] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.26666666666667, 87.33333333333334, 1.0, 2.0, 0.1852465198595403, 1.0, 2.0, 0.1852465198595403, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 459134.2362695792, 459134.2362695796, 156840.1768261299], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2010000.0000, 
sim time next is 2010600.0000, 
raw observation next is [20.4, 86.5, 1.0, 2.0, 0.1859349043842484, 1.0, 2.0, 0.1859349043842484, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 460643.6963706788, 460643.6963706793, 156978.6514895331], 
processed observation next is [0.0, 0.2608695652173913, 0.31111111111111106, 0.865, 1.0, 1.0, 0.030874886171724278, 1.0, 1.0, 0.030874886171724278, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.164515605846671, 0.1645156058466712, 0.301882022095256], 
reward next is 0.6981, 
noisyNet noise sample is [array([-0.7698215], dtype=float32), -0.5041485]. 
=============================================
[2019-04-27 19:06:44,385] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0993559e-13 1.2708253e-04 5.3352628e-15 9.9987292e-01 6.9264263e-14], sum to 1.0000
[2019-04-27 19:06:44,394] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3620
[2019-04-27 19:06:44,399] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.65, 66.0, 1.0, 2.0, 0.2289003267151148, 1.0, 2.0, 0.2289003267151148, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 548068.3568314784, 548068.3568314789, 165522.5015575355], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2027400.0000, 
sim time next is 2028000.0000, 
raw observation next is [25.8, 66.0, 1.0, 2.0, 0.2324114644506593, 1.0, 2.0, 0.2324114644506593, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 555110.0865824721, 555110.0865824725, 166239.1125335174], 
processed observation next is [0.0, 0.4782608695652174, 0.5111111111111112, 0.66, 1.0, 1.0, 0.08620412434602298, 1.0, 1.0, 0.08620412434602298, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19825360235088288, 0.19825360235088305, 0.31969060102599495], 
reward next is 0.6803, 
noisyNet noise sample is [array([1.1693045], dtype=float32), 0.18997647]. 
=============================================
[2019-04-27 19:06:44,415] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[62.032276]
 [62.00411 ]
 [61.952976]
 [61.92619 ]
 [61.908558]], R is [[62.13751602]
 [62.19782639]
 [62.25873566]
 [62.31986618]
 [62.38123322]].
[2019-04-27 19:06:47,375] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.6730525e-18 1.8800275e-08 5.1203653e-20 1.0000000e+00 8.8468446e-16], sum to 1.0000
[2019-04-27 19:06:47,385] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9405
[2019-04-27 19:06:47,389] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.6, 88.33333333333334, 1.0, 2.0, 0.2189116350945898, 1.0, 2.0, 0.2189116350945898, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 530466.2885022311, 530466.2885022316, 163593.0413694001], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2085600.0000, 
sim time next is 2086200.0000, 
raw observation next is [21.5, 89.0, 1.0, 2.0, 0.2187593264358955, 1.0, 2.0, 0.2187593264358955, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 530227.5143461018, 530227.5143461023, 163564.7769189053], 
processed observation next is [0.0, 0.13043478260869565, 0.35185185185185186, 0.89, 1.0, 1.0, 0.06995157909035177, 1.0, 1.0, 0.06995157909035177, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18936696940932207, 0.18936696940932224, 0.31454764792097173], 
reward next is 0.6855, 
noisyNet noise sample is [array([-1.6997937], dtype=float32), -2.1875093]. 
=============================================
[2019-04-27 19:06:49,344] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.8682588e-18 1.0913754e-07 1.2638698e-19 9.9999988e-01 1.8755222e-15], sum to 1.0000
[2019-04-27 19:06:49,352] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5415
[2019-04-27 19:06:49,356] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 51.0, 1.0, 2.0, 0.2881512150830349, 1.0, 2.0, 0.2881512150830349, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 660926.1010846783, 660926.1010846783, 177850.673532991], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2127600.0000, 
sim time next is 2128200.0000, 
raw observation next is [31.08333333333334, 50.5, 1.0, 2.0, 0.2869729788498229, 1.0, 2.0, 0.2869729788498229, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 658730.7007236711, 658730.7007236716, 177597.4363235528], 
processed observation next is [0.0, 0.6521739130434783, 0.7067901234567904, 0.505, 1.0, 1.0, 0.1511583081545511, 1.0, 1.0, 0.1511583081545511, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23526096454416826, 0.23526096454416842, 0.3415335313914477], 
reward next is 0.6585, 
noisyNet noise sample is [array([-0.04698917], dtype=float32), -0.88584256]. 
=============================================
[2019-04-27 19:06:49,473] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.2284536e-19 4.4403166e-09 2.6546463e-21 1.0000000e+00 7.7141102e-18], sum to 1.0000
[2019-04-27 19:06:49,484] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7246
[2019-04-27 19:06:49,488] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 72.0, 1.0, 2.0, 0.2891669843512689, 1.0, 2.0, 0.2891669843512689, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 662621.1014003617, 662621.1014003617, 178059.563448407], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2113200.0000, 
sim time next is 2113800.0000, 
raw observation next is [27.2, 71.0, 1.0, 2.0, 0.2907826468125426, 1.0, 2.0, 0.2907826468125426, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 665662.2999088445, 665662.299908845, 178409.5122265529], 
processed observation next is [0.0, 0.4782608695652174, 0.5629629629629629, 0.71, 1.0, 1.0, 0.15569362715778884, 1.0, 1.0, 0.15569362715778884, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2377365356817302, 0.23773653568173037, 0.34309521582029406], 
reward next is 0.6569, 
noisyNet noise sample is [array([0.79071134], dtype=float32), -1.7545428]. 
=============================================
[2019-04-27 19:06:52,984] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.5100025e-14 4.6840923e-06 4.1800521e-15 9.9999535e-01 3.5293789e-13], sum to 1.0000
[2019-04-27 19:06:52,988] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7953
[2019-04-27 19:06:52,996] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.16666666666667, 89.0, 1.0, 2.0, 0.2933296103427528, 1.0, 2.0, 0.2933296103427528, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 675968.0399159908, 675968.0399159903, 179233.3543505044], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2184600.0000, 
sim time next is 2185200.0000, 
raw observation next is [24.2, 89.0, 1.0, 2.0, 0.2951564460405887, 1.0, 2.0, 0.2951564460405887, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 679689.021735589, 679689.0217355895, 179646.2904596171], 
processed observation next is [1.0, 0.30434782608695654, 0.45185185185185184, 0.89, 1.0, 1.0, 0.16090053100070084, 1.0, 1.0, 0.16090053100070084, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2427460791912818, 0.24274607919128197, 0.34547363549926363], 
reward next is 0.6545, 
noisyNet noise sample is [array([0.08997118], dtype=float32), -0.14298864]. 
=============================================
[2019-04-27 19:06:57,843] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.4956704e-13 8.4603352e-07 4.5594242e-14 9.9999917e-01 1.4975313e-10], sum to 1.0000
[2019-04-27 19:06:57,855] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1188
[2019-04-27 19:06:57,859] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.8, 85.0, 1.0, 2.0, 0.4916682934618495, 1.0, 2.0, 0.4916682934618495, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1144403.494124326, 1144403.494124327, 233911.0867895606], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2288400.0000, 
sim time next is 2289000.0000, 
raw observation next is [23.9, 84.5, 1.0, 2.0, 0.4945414886392367, 1.0, 2.0, 0.4945414886392367, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1150605.314177367, 1150605.314177368, 234777.9426924629], 
processed observation next is [1.0, 0.4782608695652174, 0.4407407407407407, 0.845, 1.0, 1.0, 0.3982636769514723, 1.0, 1.0, 0.3982636769514723, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.41093046934905963, 0.41093046934906, 0.45149604363935175], 
reward next is 0.5485, 
noisyNet noise sample is [array([-0.18696414], dtype=float32), 1.8562129]. 
=============================================
[2019-04-27 19:06:57,871] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[49.309513]
 [49.15496 ]
 [49.000717]
 [49.10269 ]
 [48.880623]], R is [[49.47885895]
 [49.53424072]
 [49.58013153]
 [49.61679459]
 [49.68097687]].
[2019-04-27 19:06:58,841] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.4844766e-14 1.3157136e-06 7.8712121e-15 9.9999869e-01 7.2899945e-14], sum to 1.0000
[2019-04-27 19:06:58,849] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5420
[2019-04-27 19:06:58,853] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.7, 81.0, 1.0, 2.0, 0.5174376988661956, 1.0, 2.0, 0.5174376988661956, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1197786.025932771, 1197786.025932771, 241684.2284657148], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2293200.0000, 
sim time next is 2293800.0000, 
raw observation next is [24.8, 80.66666666666667, 1.0, 2.0, 0.4966166746572926, 1.0, 2.0, 0.4966166746572926, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1147587.612304481, 1147587.612304481, 235067.0203387763], 
processed observation next is [1.0, 0.5652173913043478, 0.4740740740740741, 0.8066666666666668, 1.0, 1.0, 0.4007341364967769, 1.0, 1.0, 0.4007341364967769, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.40985271868017176, 0.40985271868017176, 0.4520519621899544], 
reward next is 0.5479, 
noisyNet noise sample is [array([-0.6323273], dtype=float32), -0.4044843]. 
=============================================
[2019-04-27 19:07:00,760] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.8497370e-15 2.6037907e-07 3.6578850e-17 9.9999976e-01 4.9674988e-15], sum to 1.0000
[2019-04-27 19:07:00,770] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9824
[2019-04-27 19:07:00,778] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.5, 66.0, 1.0, 2.0, 0.20782494469948, 1.0, 2.0, 0.20782494469948, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 506059.1767771058, 506059.1767771062, 161304.7346156012], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2356200.0000, 
sim time next is 2356800.0000, 
raw observation next is [24.83333333333334, 63.0, 1.0, 2.0, 0.2049942590290232, 1.0, 2.0, 0.2049942590290232, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 500402.6448427203, 500402.6448427203, 160746.5785603404], 
processed observation next is [1.0, 0.2608695652173913, 0.47530864197530887, 0.63, 1.0, 1.0, 0.053564594082170486, 1.0, 1.0, 0.053564594082170486, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17871523030097153, 0.17871523030097153, 0.30912803569296227], 
reward next is 0.6909, 
noisyNet noise sample is [array([0.3580117], dtype=float32), 0.12405808]. 
=============================================
[2019-04-27 19:07:01,738] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.170200e-16 5.656936e-06 4.632026e-17 9.999944e-01 4.443890e-14], sum to 1.0000
[2019-04-27 19:07:01,750] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2880
[2019-04-27 19:07:01,755] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.55, 85.5, 1.0, 2.0, 0.2398711870085897, 1.0, 2.0, 0.2398711870085897, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 575107.6568329857, 575107.6568329862, 167976.461780767], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2352600.0000, 
sim time next is 2353200.0000, 
raw observation next is [22.86666666666667, 82.0, 1.0, 2.0, 0.2379479282260386, 1.0, 2.0, 0.2379479282260386, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 571972.70555177, 571972.7055517705, 167604.8953821795], 
processed observation next is [1.0, 0.21739130434782608, 0.4024691358024693, 0.82, 1.0, 1.0, 0.09279515265004597, 1.0, 1.0, 0.09279515265004597, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20427596626848932, 0.20427596626848946, 0.3223171065041913], 
reward next is 0.6777, 
noisyNet noise sample is [array([-1.2204516], dtype=float32), 1.8646617]. 
=============================================
[2019-04-27 19:07:01,806] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.0921327e-14 7.3161567e-07 9.9213346e-17 9.9999928e-01 2.2015160e-14], sum to 1.0000
[2019-04-27 19:07:01,816] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9784
[2019-04-27 19:07:01,822] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.45, 49.5, 1.0, 2.0, 0.2233559077658789, 1.0, 2.0, 0.2233559077658789, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 551330.588622058, 551330.5886220585, 164877.530120846], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2359800.0000, 
sim time next is 2360400.0000, 
raw observation next is [26.76666666666667, 47.0, 1.0, 2.0, 0.227075758090977, 1.0, 2.0, 0.227075758090977, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 561796.9991536792, 561796.9991536796, 165728.2132642897], 
processed observation next is [1.0, 0.30434782608695654, 0.5469135802469137, 0.47, 1.0, 1.0, 0.0798520929654488, 1.0, 1.0, 0.0798520929654488, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2006417854120283, 0.20064178541202843, 0.3187081024313263], 
reward next is 0.6813, 
noisyNet noise sample is [array([-2.0053024], dtype=float32), 0.13571544]. 
=============================================
[2019-04-27 19:07:03,120] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.6223235e-14 3.7529855e-06 1.1495489e-16 9.9999630e-01 7.6351103e-14], sum to 1.0000
[2019-04-27 19:07:03,127] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3071
[2019-04-27 19:07:03,130] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.93333333333333, 37.0, 1.0, 2.0, 0.5936857677618967, 1.0, 2.0, 0.5936857677618967, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1419642.428855144, 1419642.428855144, 268784.1094084438], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2388000.0000, 
sim time next is 2388600.0000, 
raw observation next is [30.9, 37.0, 1.0, 2.0, 0.5719788812177876, 1.0, 2.0, 0.5719788812177876, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1370090.975241923, 1370090.975241923, 261413.9580216397], 
processed observation next is [1.0, 0.6521739130434783, 0.7, 0.37, 1.0, 1.0, 0.4904510490687948, 1.0, 1.0, 0.4904510490687948, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.48931820544354393, 0.48931820544354393, 0.5027191500416148], 
reward next is 0.4973, 
noisyNet noise sample is [array([-1.5818315], dtype=float32), 0.19367382]. 
=============================================
[2019-04-27 19:07:03,609] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-04-27 19:07:03,612] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 19:07:03,613] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 19:07:03,613] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:07:03,614] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 19:07:03,614] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 19:07:03,614] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:07:03,615] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 19:07:03,616] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:07:03,618] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:07:03,617] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:07:03,633] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run29
[2019-04-27 19:07:03,654] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run29
[2019-04-27 19:07:03,674] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run29
[2019-04-27 19:07:03,703] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run29
[2019-04-27 19:07:03,724] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run29
[2019-04-27 19:07:55,691] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.052883953]
[2019-04-27 19:07:55,693] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [33.19428701, 46.899619955, 1.0, 2.0, 0.314731720552718, 1.0, 2.0, 0.314731720552718, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 717372.6358950405, 717372.6358950409, 184033.7700630987]
[2019-04-27 19:07:55,694] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 19:07:55,697] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.2666743e-14 1.5369686e-04 1.0695771e-15 9.9984622e-01 1.3186961e-13], sampled 0.9173869245028636
[2019-04-27 19:08:16,827] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.052883953]
[2019-04-27 19:08:16,829] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.66666666666666, 90.66666666666666, 1.0, 2.0, 0.5509090645078485, 1.0, 2.0, 0.5509090645078485, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1256136.346511828, 1256136.346511828, 251576.1294023813]
[2019-04-27 19:08:16,830] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 19:08:16,832] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.3376426e-13 4.7816662e-05 9.8481793e-15 9.9995220e-01 9.3694681e-13], sampled 0.4624728337255356
[2019-04-27 19:08:19,496] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.052883953]
[2019-04-27 19:08:19,497] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.5, 95.0, 1.0, 2.0, 0.3542554862691088, 1.0, 2.0, 0.3542554862691088, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 807507.1882519562, 807507.1882519567, 193990.8926134226]
[2019-04-27 19:08:19,498] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 19:08:19,501] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [8.5261754e-14 1.5864725e-04 1.9341089e-15 9.9984133e-01 1.8707076e-13], sampled 0.9676097109151757
[2019-04-27 19:08:27,634] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.052883953]
[2019-04-27 19:08:27,635] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.65, 91.0, 1.0, 2.0, 0.3448930187455074, 1.0, 2.0, 0.3448930187455074, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 796784.5420746921, 796784.5420746926, 192091.2196017613]
[2019-04-27 19:08:27,636] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 19:08:27,638] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.2029578e-13 3.9842103e-05 4.7708525e-15 9.9996018e-01 4.4850381e-13], sampled 0.5801727953720024
[2019-04-27 19:08:28,625] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.052883953]
[2019-04-27 19:08:28,626] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.7, 72.5, 1.0, 2.0, 0.2646453731173313, 1.0, 2.0, 0.2646453731173313, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 620516.0628820707, 620516.0628820711, 173031.8821534791]
[2019-04-27 19:08:28,628] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 19:08:28,632] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.4619898e-13 1.9785532e-04 3.4760079e-15 9.9980217e-01 3.0421184e-13], sampled 0.8201843012353179
[2019-04-27 19:08:47,342] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.052883953]
[2019-04-27 19:08:47,343] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.53333333333333, 83.83333333333334, 1.0, 2.0, 0.2595283251457731, 1.0, 2.0, 0.2595283251457731, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 643694.4432493176, 643694.443249318, 173100.9965157353]
[2019-04-27 19:08:47,345] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 19:08:47,348] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.5049055e-13 4.9987746e-05 6.1297610e-15 9.9995005e-01 5.0581604e-13], sampled 0.33532991296646375
[2019-04-27 19:08:54,333] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7120.7941 2438815229.4642 34.0000
[2019-04-27 19:08:54,507] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7797.0327 2410662930.0770 22.0000
[2019-04-27 19:08:54,565] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7478.3960 2465917100.5862 46.0000
[2019-04-27 19:08:54,781] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6906.1374 2495392346.7799 47.0000
[2019-04-27 19:08:54,898] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7522.4809 2668472510.2245 68.0000
[2019-04-27 19:08:55,915] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 700000, evaluation results [700000.0, 7522.4808819964865, 2668472510.224499, 68.0, 7120.7940628033675, 2438815229.4641614, 34.0, 7797.032693127033, 2410662930.0770326, 22.0, 6906.1374208322795, 2495392346.7799497, 47.0, 7478.396041438089, 2465917100.586185, 46.0]
[2019-04-27 19:09:00,530] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.99052450e-12 1.87869355e-05 1.08135404e-13 9.99981165e-01
 7.90445487e-12], sum to 1.0000
[2019-04-27 19:09:00,538] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1771
[2019-04-27 19:09:00,543] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.18333333333333, 23.16666666666667, 1.0, 2.0, 0.4910321395793644, 1.0, 2.0, 0.4910321395793644, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1196410.546619616, 1196410.546619617, 235726.2289099227], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2465400.0000, 
sim time next is 2466000.0000, 
raw observation next is [34.3, 23.0, 1.0, 2.0, 0.4966460385298743, 1.0, 2.0, 0.4966460385298743, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1210044.453570313, 1210044.453570313, 237486.8865452287], 
processed observation next is [1.0, 0.5652173913043478, 0.8259259259259258, 0.23, 1.0, 1.0, 0.4007690934879456, 1.0, 1.0, 0.4007690934879456, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.43215873341796895, 0.43215873341796895, 0.45670555104851673], 
reward next is 0.5433, 
noisyNet noise sample is [array([-0.313459], dtype=float32), 0.3227569]. 
=============================================
[2019-04-27 19:09:00,565] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[56.831684]
 [56.64764 ]
 [56.312225]
 [56.32583 ]
 [56.31767 ]], R is [[56.93949509]
 [56.91678238]
 [56.87781906]
 [56.77703857]
 [56.66230774]].
[2019-04-27 19:09:04,799] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.8035750e-11 1.9471403e-05 1.3120296e-12 9.9998057e-01 1.3258923e-10], sum to 1.0000
[2019-04-27 19:09:04,808] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4577
[2019-04-27 19:09:04,817] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.6, 30.0, 1.0, 2.0, 0.6119236039382384, 1.0, 2.0, 0.6119236039382384, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1470178.021323208, 1470178.021323208, 275433.8816020504], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2548800.0000, 
sim time next is 2549400.0000, 
raw observation next is [32.7, 30.0, 1.0, 2.0, 0.5881277621862789, 1.0, 2.0, 0.5881277621862789, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1412846.367108712, 1412846.367108712, 267097.3829405769], 
processed observation next is [1.0, 0.5217391304347826, 0.7666666666666667, 0.3, 1.0, 1.0, 0.5096759073646178, 1.0, 1.0, 0.5096759073646178, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5045879882531115, 0.5045879882531115, 0.5136488133472632], 
reward next is 0.4864, 
noisyNet noise sample is [array([0.152811], dtype=float32), 0.68519425]. 
=============================================
[2019-04-27 19:09:06,037] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1191301e-14 1.5241493e-06 6.3668538e-18 9.9999845e-01 7.0744280e-14], sum to 1.0000
[2019-04-27 19:09:06,052] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5931
[2019-04-27 19:09:06,056] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.65000000000001, 36.5, 1.0, 2.0, 0.2312637837138753, 1.0, 2.0, 0.2312637837138753, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 549731.7138641556, 549731.7138641556, 165877.9957949189], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2568600.0000, 
sim time next is 2569200.0000, 
raw observation next is [32.46666666666667, 37.33333333333334, 1.0, 2.0, 0.2335373610787828, 1.0, 2.0, 0.2335373610787828, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 554797.2437477414, 554797.2437477419, 166363.4075974142], 
processed observation next is [1.0, 0.7391304347826086, 0.7580246913580247, 0.3733333333333334, 1.0, 1.0, 0.08754447747474144, 1.0, 1.0, 0.08754447747474144, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19814187276705053, 0.1981418727670507, 0.3199296299950273], 
reward next is 0.6801, 
noisyNet noise sample is [array([0.86635154], dtype=float32), -0.95850325]. 
=============================================
[2019-04-27 19:09:08,096] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.5306112e-14 6.4456181e-06 1.4829638e-18 9.9999356e-01 5.1777782e-15], sum to 1.0000
[2019-04-27 19:09:08,102] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4532
[2019-04-27 19:09:08,107] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.53333333333333, 93.33333333333334, 1.0, 2.0, 0.2859548311960369, 1.0, 2.0, 0.2859548311960369, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 660217.2488969376, 660217.248896938, 177543.0475844938], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2676000.0000, 
sim time next is 2676600.0000, 
raw observation next is [23.4, 95.0, 1.0, 2.0, 0.2879846380874834, 1.0, 2.0, 0.2879846380874834, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 663790.8289512336, 663790.8289512341, 177969.7907346335], 
processed observation next is [0.0, 1.0, 0.42222222222222217, 0.95, 1.0, 1.0, 0.1523626643898612, 1.0, 1.0, 0.1523626643898612, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23706815319686916, 0.23706815319686933, 0.3422495975666029], 
reward next is 0.6578, 
noisyNet noise sample is [array([1.6562071], dtype=float32), -0.9179994]. 
=============================================
[2019-04-27 19:09:09,598] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4174942e-14 9.6126714e-06 1.0550912e-18 9.9999034e-01 1.6914312e-16], sum to 1.0000
[2019-04-27 19:09:09,606] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5627
[2019-04-27 19:09:09,615] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.33333333333334, 51.33333333333334, 1.0, 2.0, 0.2995682022690312, 1.0, 2.0, 0.2995682022690312, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 682794.8133842765, 682794.8133842765, 180357.0719636735], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2744400.0000, 
sim time next is 2745000.0000, 
raw observation next is [31.0, 54.0, 1.0, 2.0, 0.3047874154958862, 1.0, 2.0, 0.3047874154958862, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 694696.1647728212, 694696.1647728212, 181613.5749972699], 
processed observation next is [0.0, 0.782608695652174, 0.7037037037037037, 0.54, 1.0, 1.0, 0.172365970828436, 1.0, 1.0, 0.172365970828436, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24810577313315044, 0.24810577313315044, 0.3492568749947498], 
reward next is 0.6507, 
noisyNet noise sample is [array([-1.7148613], dtype=float32), -0.8281488]. 
=============================================
[2019-04-27 19:09:09,633] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[71.614914]
 [71.60918 ]
 [71.5936  ]
 [71.54031 ]
 [71.51718 ]], R is [[71.55123138]
 [71.48887634]
 [71.42935181]
 [71.37145996]
 [71.31174469]].
[2019-04-27 19:09:13,000] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.7803540e-15 2.1645935e-06 5.4048802e-17 9.9999785e-01 3.7325056e-14], sum to 1.0000
[2019-04-27 19:09:13,016] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1128
[2019-04-27 19:09:13,020] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 62.0, 1.0, 2.0, 0.2736918169364924, 1.0, 2.0, 0.2736918169364924, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 636314.5079477945, 636314.507947795, 174881.8023973466], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2714400.0000, 
sim time next is 2715000.0000, 
raw observation next is [28.08333333333334, 61.83333333333334, 1.0, 2.0, 0.2752461899668329, 1.0, 2.0, 0.2752461899668329, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 639303.133515033, 639303.1335150334, 175214.5342289057], 
processed observation next is [0.0, 0.43478260869565216, 0.5956790123456792, 0.6183333333333334, 1.0, 1.0, 0.1371978451986106, 1.0, 1.0, 0.1371978451986106, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22832254768394036, 0.2283225476839405, 0.33695102736328014], 
reward next is 0.6630, 
noisyNet noise sample is [array([-0.6625002], dtype=float32), -0.31967068]. 
=============================================
[2019-04-27 19:09:13,037] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[60.115234]
 [60.04433 ]
 [59.991386]
 [59.94678 ]
 [59.898293]], R is [[60.2201767 ]
 [60.2816658 ]
 [60.34268951]
 [60.40327454]
 [60.46350098]].
[2019-04-27 19:09:16,245] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.5255516e-12 1.6534036e-03 3.7505451e-13 9.9834657e-01 1.5006208e-11], sum to 1.0000
[2019-04-27 19:09:16,255] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0815
[2019-04-27 19:09:16,263] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.16666666666667, 83.16666666666666, 1.0, 2.0, 0.3271203529897058, 1.0, 2.0, 0.3271203529897058, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 745623.9612827501, 745623.9612827506, 187096.2437451459], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2757000.0000, 
sim time next is 2757600.0000, 
raw observation next is [26.0, 84.0, 1.0, 2.0, 0.3259104687321626, 1.0, 2.0, 0.3259104687321626, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 742864.8672195461, 742864.8672195461, 186794.7741786217], 
processed observation next is [0.0, 0.9565217391304348, 0.5185185185185185, 0.84, 1.0, 1.0, 0.19751246277638407, 1.0, 1.0, 0.19751246277638407, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2653088811498379, 0.2653088811498379, 0.35922071957427254], 
reward next is 0.6408, 
noisyNet noise sample is [array([-0.5907535], dtype=float32), -1.8977823]. 
=============================================
[2019-04-27 19:09:17,330] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.4634276e-11 1.3461866e-03 7.4514701e-14 9.9865377e-01 6.6210948e-10], sum to 1.0000
[2019-04-27 19:09:17,338] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7862
[2019-04-27 19:09:17,343] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.83333333333333, 89.83333333333333, 1.0, 2.0, 0.2982329993180726, 1.0, 2.0, 0.2982329993180726, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 690245.2612547623, 690245.2612547628, 180548.5822127197], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2785800.0000, 
sim time next is 2786400.0000, 
raw observation next is [24.0, 89.0, 1.0, 2.0, 0.3022526007931394, 1.0, 2.0, 0.3022526007931394, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 698698.5881410378, 698698.5881410383, 181479.0174245057], 
processed observation next is [1.0, 0.2608695652173913, 0.4444444444444444, 0.89, 1.0, 1.0, 0.16934833427754695, 1.0, 1.0, 0.16934833427754695, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24953521005037066, 0.24953521005037083, 0.3489981104317417], 
reward next is 0.6510, 
noisyNet noise sample is [array([0.25080192], dtype=float32), 0.14431325]. 
=============================================
[2019-04-27 19:09:17,774] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1261570e-12 1.7484634e-04 2.4481053e-14 9.9982518e-01 1.2790327e-11], sum to 1.0000
[2019-04-27 19:09:17,781] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9994
[2019-04-27 19:09:17,786] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.9, 80.0, 1.0, 2.0, 0.3974929774448103, 1.0, 2.0, 0.3974929774448103, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 906123.0901425779, 906123.0901425779, 205502.0618790873], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2793600.0000, 
sim time next is 2794200.0000, 
raw observation next is [27.08333333333334, 79.83333333333334, 1.0, 2.0, 0.4755183101876034, 1.0, 2.0, 0.4755183101876034, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1084115.085294425, 1084115.085294425, 227915.4833742731], 
processed observation next is [1.0, 0.34782608695652173, 0.5586419753086422, 0.7983333333333335, 1.0, 1.0, 0.375617035937623, 1.0, 1.0, 0.375617035937623, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3871839590337232, 0.3871839590337232, 0.43829900648898673], 
reward next is 0.5617, 
noisyNet noise sample is [array([-2.1083815], dtype=float32), -0.7532552]. 
=============================================
[2019-04-27 19:09:20,769] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3754579e-09 5.4049093e-01 4.7584329e-11 4.5950314e-01 5.9444214e-06], sum to 1.0000
[2019-04-27 19:09:20,780] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7461
[2019-04-27 19:09:20,783] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.75, 60.33333333333334, 1.0, 2.0, 0.6607921031650851, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 753094.1145550604, 753094.1145550604, 168854.5340013388], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2833800.0000, 
sim time next is 2834400.0000, 
raw observation next is [30.5, 61.66666666666667, 1.0, 2.0, 0.335061367571164, 1.0, 1.0, 0.335061367571164, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 763733.3831545894, 763733.3831545894, 189087.8359163259], 
processed observation next is [1.0, 0.8260869565217391, 0.6851851851851852, 0.6166666666666667, 1.0, 1.0, 0.20840638996567143, 1.0, 0.5, 0.20840638996567143, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27276192255521053, 0.27276192255521053, 0.3636304536852421], 
reward next is 0.6364, 
noisyNet noise sample is [array([-1.4181448], dtype=float32), 0.036194675]. 
=============================================
[2019-04-27 19:09:23,930] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.8403874e-11 1.2186231e-03 9.0526328e-12 9.9874359e-01 3.7887643e-05], sum to 1.0000
[2019-04-27 19:09:23,939] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2172
[2019-04-27 19:09:23,945] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.66666666666667, 85.66666666666667, 1.0, 2.0, 0.8430838003217501, 1.0, 2.0, 0.8430838003217501, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1923103.879747185, 1923103.879747185, 361879.05514651], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2907600.0000, 
sim time next is 2908200.0000, 
raw observation next is [26.83333333333333, 84.83333333333333, 1.0, 2.0, 0.8573919161540472, 1.0, 2.0, 0.8573919161540472, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1955776.932848066, 1955776.932848067, 368040.5226699585], 
processed observation next is [1.0, 0.6521739130434783, 0.5493827160493825, 0.8483333333333333, 1.0, 1.0, 0.8302284716119609, 1.0, 1.0, 0.8302284716119609, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6984917617314522, 0.6984917617314526, 0.7077702359037663], 
reward next is 0.2922, 
noisyNet noise sample is [array([1.315762], dtype=float32), 0.13166223]. 
=============================================
[2019-04-27 19:09:24,849] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.9435178e-14 1.9664991e-04 4.8836129e-16 9.9980336e-01 1.9029574e-08], sum to 1.0000
[2019-04-27 19:09:24,855] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1249
[2019-04-27 19:09:24,858] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.3426242617499594, 1.0, 2.0, 0.3426242617499594, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 780980.9021769626, 780980.902176963, 191004.3875118359], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2919600.0000, 
sim time next is 2920200.0000, 
raw observation next is [26.0, 88.33333333333334, 1.0, 2.0, 0.3416263743175867, 1.0, 2.0, 0.3416263743175867, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 778705.1529526182, 778705.1529526191, 190750.2878322926], 
processed observation next is [1.0, 0.8260869565217391, 0.5185185185185185, 0.8833333333333334, 1.0, 1.0, 0.21622187418760322, 1.0, 1.0, 0.21622187418760322, 0.0, 1.0, -0.25, -1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.27810898319736366, 0.278108983197364, 0.3668274766005627], 
reward next is 0.6332, 
noisyNet noise sample is [array([0.44765985], dtype=float32), -2.4003005]. 
=============================================
[2019-04-27 19:09:31,116] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.5964196e-12 1.0156162e-02 3.7775054e-13 9.8984319e-01 7.4682714e-07], sum to 1.0000
[2019-04-27 19:09:31,123] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7620
[2019-04-27 19:09:31,130] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.91666666666667, 58.83333333333334, 1.0, 2.0, 0.2841537974031185, 1.0, 2.0, 0.2841537974031185, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 656937.2063300388, 656937.2063300392, 177160.1355275362], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3103800.0000, 
sim time next is 3104400.0000, 
raw observation next is [28.83333333333334, 59.66666666666667, 1.0, 2.0, 0.2848949914515367, 1.0, 2.0, 0.2848949914515367, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 657755.5935035862, 657755.5935035867, 177292.2054806963], 
processed observation next is [1.0, 0.9565217391304348, 0.623456790123457, 0.5966666666666667, 1.0, 1.0, 0.14868451363278176, 1.0, 1.0, 0.14868451363278176, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2349127119655665, 0.23491271196556668, 0.3409465490013391], 
reward next is 0.6591, 
noisyNet noise sample is [array([-0.88665795], dtype=float32), 0.46912217]. 
=============================================
[2019-04-27 19:09:34,679] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.1310660e-09 3.4811012e-03 6.4605602e-13 9.8881537e-01 7.7036009e-03], sum to 1.0000
[2019-04-27 19:09:34,686] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4544
[2019-04-27 19:09:34,692] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 58.0, 1.0, 2.0, 0.2559781934862163, 1.0, 2.0, 0.2559781934862163, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 603372.2031876394, 603372.2031876397, 171191.5078505868], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3112800.0000, 
sim time next is 3113400.0000, 
raw observation next is [28.0, 58.0, 1.0, 2.0, 0.255769844150994, 1.0, 2.0, 0.255769844150994, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 602888.503701165, 602888.503701165, 171144.4535365568], 
processed observation next is [1.0, 0.0, 0.5925925925925926, 0.58, 1.0, 1.0, 0.11401171922737383, 1.0, 1.0, 0.11401171922737383, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21531732275041607, 0.21531732275041607, 0.3291239491087631], 
reward next is 0.6709, 
noisyNet noise sample is [array([0.37536618], dtype=float32), 1.0028653]. 
=============================================
[2019-04-27 19:09:35,252] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.7602613e-08 1.7410294e-03 3.0063027e-10 9.9406528e-01 4.1936366e-03], sum to 1.0000
[2019-04-27 19:09:35,261] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0031
[2019-04-27 19:09:35,268] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 58.0, 1.0, 2.0, 0.2563661815892296, 1.0, 2.0, 0.2563661815892296, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 604274.2109454266, 604274.2109454271, 171279.2280571413], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3112200.0000, 
sim time next is 3112800.0000, 
raw observation next is [28.0, 58.0, 1.0, 2.0, 0.2559781934862653, 1.0, 2.0, 0.2559781934862653, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 603372.2031876394, 603372.2031876397, 171191.5078505929], 
processed observation next is [1.0, 0.0, 0.5925925925925926, 0.58, 1.0, 1.0, 0.11425975415031586, 1.0, 1.0, 0.11425975415031586, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21549007256701405, 0.2154900725670142, 0.3292144381742171], 
reward next is 0.6708, 
noisyNet noise sample is [array([0.85209465], dtype=float32), -1.0893356]. 
=============================================
[2019-04-27 19:09:37,481] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.6063504e-07 3.1235736e-04 8.3156065e-10 9.9343163e-01 6.2558637e-03], sum to 1.0000
[2019-04-27 19:09:37,489] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5312
[2019-04-27 19:09:37,494] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.16666666666666, 37.66666666666667, 1.0, 2.0, 0.7469697070175663, 1.0, 2.0, 0.7469697070175663, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1721894.341916719, 1721894.341916719, 323267.3934691366], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3154200.0000, 
sim time next is 3154800.0000, 
raw observation next is [33.33333333333334, 37.33333333333334, 1.0, 2.0, 0.6919424000806261, 1.0, 2.0, 0.6919424000806261, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1595221.710037205, 1595221.710037206, 301992.5834912872], 
processed observation next is [1.0, 0.5217391304347826, 0.7901234567901239, 0.3733333333333334, 1.0, 1.0, 0.6332647620007453, 1.0, 1.0, 0.6332647620007453, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5697220392990018, 0.5697220392990021, 0.5807549682524754], 
reward next is 0.4192, 
noisyNet noise sample is [array([0.51620865], dtype=float32), 0.65700513]. 
=============================================
[2019-04-27 19:09:40,507] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.9396812e-13 1.3504728e-05 6.1756910e-15 9.9990773e-01 7.8731704e-05], sum to 1.0000
[2019-04-27 19:09:40,516] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9394
[2019-04-27 19:09:40,520] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.91666666666667, 62.16666666666667, 1.0, 2.0, 0.2319837829197773, 1.0, 2.0, 0.2319837829197773, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 558009.9874009512, 558009.9874009512, 166298.6200706912], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3225000.0000, 
sim time next is 3225600.0000, 
raw observation next is [26.3, 59.0, 1.0, 2.0, 0.2275333439377976, 1.0, 2.0, 0.2275333439377976, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 548893.1139790206, 548893.1139790211, 165381.0264448469], 
processed observation next is [0.0, 0.34782608695652173, 0.5296296296296297, 0.59, 1.0, 1.0, 0.0803968380211876, 1.0, 1.0, 0.0803968380211876, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19603325499250737, 0.19603325499250754, 0.3180404354708594], 
reward next is 0.6820, 
noisyNet noise sample is [array([-1.2605965], dtype=float32), 0.99433184]. 
=============================================
[2019-04-27 19:09:41,732] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.7018429e-14 3.8167786e-05 2.8049714e-17 9.9996126e-01 6.3656205e-07], sum to 1.0000
[2019-04-27 19:09:41,738] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9132
[2019-04-27 19:09:41,742] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.0, 58.33333333333334, 1.0, 2.0, 0.3098135881588779, 1.0, 2.0, 0.3098135881588779, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 706157.5011715004, 706157.5011715004, 182832.3159029172], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3259200.0000, 
sim time next is 3259800.0000, 
raw observation next is [30.25, 56.0, 1.0, 2.0, 0.3065133891192204, 1.0, 2.0, 0.3065133891192204, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 698631.9362909428, 698631.9362909433, 182030.9130610914], 
processed observation next is [0.0, 0.7391304347826086, 0.6759259259259259, 0.56, 1.0, 1.0, 0.17442070133240523, 1.0, 1.0, 0.17442070133240523, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24951140581819387, 0.24951140581819403, 0.35005944819440654], 
reward next is 0.6499, 
noisyNet noise sample is [array([0.07239795], dtype=float32), 2.0806212]. 
=============================================
[2019-04-27 19:09:46,301] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-04-27 19:09:46,303] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 19:09:46,303] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:09:46,304] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 19:09:46,305] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:09:46,305] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 19:09:46,305] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 19:09:46,306] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:09:46,307] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 19:09:46,308] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:09:46,309] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:09:46,326] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run30
[2019-04-27 19:09:46,327] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run30
[2019-04-27 19:09:46,346] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run30
[2019-04-27 19:09:46,367] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run30
[2019-04-27 19:09:46,409] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run30
[2019-04-27 19:09:50,636] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.05055364]
[2019-04-27 19:09:50,637] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [17.66666666666667, 53.83333333333334, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 266762.8323045673, 266762.8323045673, 104936.4872470592]
[2019-04-27 19:09:50,639] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 19:09:50,641] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.2713953e-11 1.4486324e-04 4.3527066e-13 9.9982101e-01 3.4203753e-05], sampled 0.47498634157602093
[2019-04-27 19:09:55,558] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.05055364]
[2019-04-27 19:09:55,558] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.272355985, 58.19778496, 1.0, 2.0, 0.1740899407377655, 1.0, 2.0, 0.1740899407377655, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 436962.2920296419, 436962.2920296419, 154665.705477472]
[2019-04-27 19:09:55,560] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 19:09:55,562] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.4793587e-11 1.1520411e-04 3.7360330e-13 9.9984896e-01 3.5709199e-05], sampled 0.4513125223801202
[2019-04-27 19:10:18,722] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.05055364]
[2019-04-27 19:10:18,724] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.7, 40.0, 1.0, 2.0, 0.2010957729728893, 1.0, 2.0, 0.2010957729728893, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 491031.7558955047, 491031.7558955052, 159928.8529579347]
[2019-04-27 19:10:18,726] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 19:10:18,727] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.0883474e-11 4.7535083e-04 4.4611819e-13 9.9949455e-01 3.0044284e-05], sampled 0.32427971593480354
[2019-04-27 19:10:27,327] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.05055364]
[2019-04-27 19:10:27,328] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.7, 66.0, 1.0, 2.0, 0.3374823862345505, 1.0, 2.0, 0.3374823862345505, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 769254.5824549315, 769254.5824549315, 189699.2041991689]
[2019-04-27 19:10:27,331] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 19:10:27,334] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.3130985e-11 1.4518460e-04 2.1192885e-13 9.9982822e-01 2.6563644e-05], sampled 0.780061334208105
[2019-04-27 19:10:44,327] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.05055364]
[2019-04-27 19:10:44,329] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.030268865, 74.07033815, 1.0, 2.0, 0.25269799929873, 1.0, 2.0, 0.25269799929873, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 596239.3657505186, 596239.3657505186, 170473.3374538045]
[2019-04-27 19:10:44,331] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 19:10:44,336] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.89395754e-11 1.12728245e-04 3.31956522e-13 9.99853015e-01
 3.41621744e-05], sampled 0.10012855957939559
[2019-04-27 19:10:50,478] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.05055364]
[2019-04-27 19:10:50,479] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.93333333333333, 90.0, 1.0, 2.0, 0.2960521524013029, 1.0, 2.0, 0.2960521524013029, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 674777.282865939, 674777.282865939, 179516.322967234]
[2019-04-27 19:10:50,480] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 19:10:50,485] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.6484451e-11 1.0169028e-04 1.8407869e-13 9.9987113e-01 2.7119153e-05], sampled 0.22940139898146128
[2019-04-27 19:11:37,693] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7475.3551 2465911325.7749 46.0000
[2019-04-27 19:11:37,694] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7797.5320 2410738340.9486 22.0000
[2019-04-27 19:11:37,814] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7522.3203 2668556630.4032 68.0000
[2019-04-27 19:11:37,820] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6905.6350 2495415958.1069 47.0000
[2019-04-27 19:11:37,881] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7119.8204 2438869617.7848 33.0000
[2019-04-27 19:11:38,897] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 725000, evaluation results [725000.0, 7522.320310886375, 2668556630.403155, 68.0, 7119.820432549996, 2438869617.784767, 33.0, 7797.53198016057, 2410738340.948586, 22.0, 6905.634958454075, 2495415958.1068993, 47.0, 7475.355050053777, 2465911325.7749224, 46.0]
[2019-04-27 19:11:53,178] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.8665411e-09 7.6915760e-04 2.1668138e-11 9.9918729e-01 4.3605156e-05], sum to 1.0000
[2019-04-27 19:11:53,184] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2151
[2019-04-27 19:11:53,188] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.2, 75.66666666666667, 1.0, 2.0, 0.541138748674711, 1.0, 2.0, 0.541138748674711, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1257497.322546846, 1257497.322546846, 249516.601487839], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3594000.0000, 
sim time next is 3594600.0000, 
raw observation next is [25.15, 77.5, 1.0, 2.0, 0.5643885219709581, 1.0, 2.0, 0.5643885219709581, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1305078.424531753, 1305078.424531753, 256888.6430193451], 
processed observation next is [1.0, 0.6086956521739131, 0.487037037037037, 0.775, 1.0, 1.0, 0.48141490710828344, 1.0, 1.0, 0.48141490710828344, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.46609943733276893, 0.46609943733276893, 0.4940166211910483], 
reward next is 0.5060, 
noisyNet noise sample is [array([0.17887014], dtype=float32), 0.45811513]. 
=============================================
[2019-04-27 19:12:00,073] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.4668311e-11 2.4948744e-05 1.0621481e-13 9.9997437e-01 6.7595528e-07], sum to 1.0000
[2019-04-27 19:12:00,080] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5222
[2019-04-27 19:12:00,084] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.75, 95.66666666666666, 1.0, 2.0, 0.3318130782948002, 1.0, 2.0, 0.3318130782948002, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 756325.633061577, 756325.6330615774, 188270.4378174437], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3721800.0000, 
sim time next is 3722400.0000, 
raw observation next is [24.7, 96.0, 1.0, 2.0, 0.3310011031800674, 1.0, 2.0, 0.3310011031800674, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 754473.9283978356, 754473.9283978356, 188066.7581191512], 
processed observation next is [1.0, 0.08695652173913043, 0.4703703703703703, 0.96, 1.0, 1.0, 0.20357274188103266, 1.0, 1.0, 0.20357274188103266, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2694549744277984, 0.2694549744277984, 0.36166684253682924], 
reward next is 0.6383, 
noisyNet noise sample is [array([-1.4277061], dtype=float32), -0.61948407]. 
=============================================
[2019-04-27 19:12:19,938] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.08044515e-09 1.38898895e-05 5.53558727e-11 9.55584168e-01
 4.44019549e-02], sum to 1.0000
[2019-04-27 19:12:19,945] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3190
[2019-04-27 19:12:19,950] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.3195460131579538, 1.0, 2.0, 0.3195460131579538, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 762228.7486964829, 762228.7486964833, 186715.0331047224], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4086000.0000, 
sim time next is 4086600.0000, 
raw observation next is [21.28333333333333, 97.33333333333334, 1.0, 2.0, 0.293367420648416, 1.0, 2.0, 0.293367420648416, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 699492.2599861127, 699492.2599861131, 180262.3450724956], 
processed observation next is [1.0, 0.30434782608695654, 0.3438271604938271, 0.9733333333333334, 1.0, 1.0, 0.1587707388671619, 1.0, 1.0, 0.1587707388671619, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24981866428075453, 0.24981866428075467, 0.3466583559086454], 
reward next is 0.6533, 
noisyNet noise sample is [array([0.32571876], dtype=float32), 0.03112958]. 
=============================================
[2019-04-27 19:12:22,097] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1964038e-10 2.7242600e-05 1.0757426e-12 9.9209702e-01 7.8757172e-03], sum to 1.0000
[2019-04-27 19:12:22,100] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3733
[2019-04-27 19:12:22,105] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.13333333333333, 95.0, 1.0, 2.0, 0.2309208865155549, 1.0, 2.0, 0.2309208865155549, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 556538.5049302343, 556538.5049302347, 166105.4495636091], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4141200.0000, 
sim time next is 4141800.0000, 
raw observation next is [21.2, 95.5, 1.0, 2.0, 0.2331028770417377, 1.0, 2.0, 0.2331028770417377, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 560577.4434555174, 560577.4434555178, 166540.8094213448], 
processed observation next is [1.0, 0.9565217391304348, 0.34074074074074073, 0.955, 1.0, 1.0, 0.08702723457349727, 1.0, 1.0, 0.08702723457349727, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20020622980554192, 0.20020622980554206, 0.32027078734874004], 
reward next is 0.6797, 
noisyNet noise sample is [array([-0.23528345], dtype=float32), 1.8208466]. 
=============================================
[2019-04-27 19:12:29,050] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-04-27 19:12:29,052] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 19:12:29,053] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:12:29,053] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 19:12:29,054] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 19:12:29,054] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:12:29,056] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 19:12:29,056] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:12:29,058] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:12:29,059] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 19:12:29,060] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:12:29,083] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run31
[2019-04-27 19:12:29,084] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run31
[2019-04-27 19:12:29,106] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run31
[2019-04-27 19:12:29,107] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run31
[2019-04-27 19:12:29,172] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run31
[2019-04-27 19:12:37,289] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.04876643]
[2019-04-27 19:12:37,291] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.1, 44.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 381336.4341311455, 381336.434131145, 148211.5915687938]
[2019-04-27 19:12:37,292] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 19:12:37,296] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.21492035e-11 3.69316263e-06 6.06159545e-14 9.99926686e-01
 6.96118732e-05], sampled 0.8835889848623923
[2019-04-27 19:12:51,916] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.04876643]
[2019-04-27 19:12:51,918] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [19.93058386333333, 73.69957377, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 395549.9036494358, 395549.9036494363, 150315.8068386999]
[2019-04-27 19:12:51,920] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 19:12:51,924] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.4925069e-11 9.1653692e-07 1.9015867e-13 9.9986339e-01 1.3559019e-04], sampled 0.8349834144907378
[2019-04-27 19:12:56,493] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.04876643]
[2019-04-27 19:12:56,494] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.83244354333333, 87.92584121833333, 1.0, 2.0, 0.2336417018613169, 1.0, 2.0, 0.2336417018613169, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 563640.5683923298, 563640.5683923303, 166725.8184261644]
[2019-04-27 19:12:56,495] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 19:12:56,498] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.6275349e-12 3.1874358e-06 4.6447814e-14 9.9992955e-01 6.7201712e-05], sampled 0.2367003988232368
[2019-04-27 19:13:23,475] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.04876643]
[2019-04-27 19:13:23,476] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.0, 75.0, 1.0, 2.0, 0.3354606808434581, 1.0, 2.0, 0.3354606808434581, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 764644.0252584241, 764644.0252584246, 189188.4293407949]
[2019-04-27 19:13:23,480] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 19:13:23,484] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [7.5237551e-12 2.5463771e-06 3.4534512e-14 9.9993455e-01 6.2910636e-05], sampled 0.45005371983527875
[2019-04-27 19:13:25,523] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.04876643]
[2019-04-27 19:13:25,526] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.0, 84.0, 1.0, 2.0, 0.4267452774121366, 1.0, 2.0, 0.4267452774121366, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 972848.8196905002, 972848.8196905002, 213659.346519709]
[2019-04-27 19:13:25,526] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 19:13:25,529] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.1453757e-11 2.7498577e-06 1.3155442e-13 9.9987733e-01 1.1986529e-04], sampled 0.4342486221770281
[2019-04-27 19:13:46,479] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.04876643]
[2019-04-27 19:13:46,480] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.60674277333333, 90.41060240666667, 1.0, 2.0, 0.5391675673749282, 1.0, 2.0, 0.5391675673749282, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1229342.893883096, 1229342.893883096, 247764.4136092301]
[2019-04-27 19:13:46,481] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 19:13:46,482] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.3971825e-11 3.2938112e-06 7.0192800e-14 9.9988008e-01 1.1658174e-04], sampled 0.1647863518945366
[2019-04-27 19:13:46,858] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.04876643]
[2019-04-27 19:13:46,862] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.66553955333333, 89.98501971333333, 1.0, 2.0, 0.3034580485324662, 1.0, 2.0, 0.3034580485324662, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 691664.7969784118, 691664.7969784118, 181292.5588075848]
[2019-04-27 19:13:46,862] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 19:13:46,864] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.6062873e-11 2.5909733e-06 8.8570068e-14 9.9990344e-01 9.3984374e-05], sampled 0.9736359161196568
[2019-04-27 19:13:47,534] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.04876643]
[2019-04-27 19:13:47,535] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.24196797666666, 75.2653063, 1.0, 2.0, 0.5164717226497151, 1.0, 2.0, 0.5164717226497151, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1177554.87697239, 1177554.87697239, 240526.9805765846]
[2019-04-27 19:13:47,537] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 19:13:47,539] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.7577894e-11 1.5184884e-06 1.0655829e-13 9.9987268e-01 1.2578091e-04], sampled 0.8452323782433746
[2019-04-27 19:13:49,229] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.04876643]
[2019-04-27 19:13:49,230] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.5, 38.33333333333334, 1.0, 2.0, 0.257738065640351, 1.0, 2.0, 0.257738065640351, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 601815.7069327715, 601815.7069327715, 171337.4964940236]
[2019-04-27 19:13:49,233] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 19:13:49,237] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.3730039e-12 1.9228867e-06 1.3200699e-14 9.9995518e-01 4.2903313e-05], sampled 0.7702263515641349
[2019-04-27 19:13:49,815] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.04876643]
[2019-04-27 19:13:49,817] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.33333333333334, 69.0, 1.0, 2.0, 0.5368836167846174, 1.0, 2.0, 0.5368836167846174, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1267914.888664497, 1267914.888664498, 249003.4429883716]
[2019-04-27 19:13:49,820] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 19:13:49,822] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.5200469e-10 6.5030463e-06 1.3700600e-12 9.9966753e-01 3.2590408e-04], sampled 0.6294871703316608
[2019-04-27 19:13:58,086] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.04876643]
[2019-04-27 19:13:58,087] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.29424477833334, 77.71214768333333, 1.0, 2.0, 0.2913799106403429, 1.0, 2.0, 0.2913799106403429, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 666164.3585703803, 666164.3585703803, 178508.0679023808]
[2019-04-27 19:13:58,087] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 19:13:58,089] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.0059310e-12 7.0404360e-07 3.9227627e-14 9.9992478e-01 7.4478929e-05], sampled 0.9483910355372747
[2019-04-27 19:14:04,858] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.04876643]
[2019-04-27 19:14:04,860] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.26666666666667, 60.16666666666667, 1.0, 2.0, 0.2386420851406423, 1.0, 2.0, 0.2386420851406423, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 565535.0668583444, 565535.0668583447, 167432.9719746118]
[2019-04-27 19:14:04,861] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 19:14:04,864] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.3002118e-11 7.8650592e-06 1.2311099e-13 9.9988067e-01 1.1144351e-04], sampled 0.9315685513259854
[2019-04-27 19:14:20,209] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 7122.2606 2438847622.0174 34.0000
[2019-04-27 19:14:20,815] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6903.0752 2495551701.7195 47.0000
[2019-04-27 19:14:20,820] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7521.6259 2668613015.4391 68.0000
[2019-04-27 19:14:20,834] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 7477.0496 2466051875.8345 46.0000
[2019-04-27 19:14:20,841] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7795.1018 2410846606.9868 22.0000
[2019-04-27 19:14:21,857] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 750000, evaluation results [750000.0, 7521.625949272081, 2668613015.439116, 68.0, 7122.260633411203, 2438847622.017374, 34.0, 7795.101786427961, 2410846606.9867787, 22.0, 6903.075188580684, 2495551701.7195253, 47.0, 7477.049607154005, 2466051875.834505, 46.0]
[2019-04-27 19:14:22,389] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.4001296e-10 4.9628481e-05 2.0596015e-13 8.9982897e-01 1.0012140e-01], sum to 1.0000
[2019-04-27 19:14:22,397] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1231
[2019-04-27 19:14:22,403] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.16666666666666, 42.33333333333334, 1.0, 2.0, 0.9523868099456276, 1.0, 2.0, 0.9523868099456276, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2172731.217729661, 2172731.217729661, 410745.1033548387], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4290600.0000, 
sim time next is 4291200.0000, 
raw observation next is [33.0, 44.0, 1.0, 2.0, 0.9479933532808145, 1.0, 2.0, 0.9479933532808145, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2162696.049944007, 2162696.049944008, 408701.1770919459], 
processed observation next is [1.0, 0.6956521739130435, 0.7777777777777778, 0.44, 1.0, 1.0, 0.938087325334303, 1.0, 1.0, 0.938087325334303, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7723914464085738, 0.7723914464085742, 0.7859638020998959], 
reward next is 0.2140, 
noisyNet noise sample is [array([-0.68984365], dtype=float32), -0.5804033]. 
=============================================
[2019-04-27 19:14:23,526] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.6773400e-10 2.1055939e-04 1.2348644e-12 9.3710029e-01 6.2689163e-02], sum to 1.0000
[2019-04-27 19:14:23,535] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7048
[2019-04-27 19:14:23,540] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.53333333333333, 59.0, 1.0, 2.0, 0.2944936895310822, 1.0, 2.0, 0.2944936895310822, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 672832.1059404433, 672832.1059404438, 179225.7025166614], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4304400.0000, 
sim time next is 4305000.0000, 
raw observation next is [29.41666666666667, 60.0, 1.0, 2.0, 0.2974770695756866, 1.0, 2.0, 0.2974770695756866, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 678488.7098236223, 678488.7098236223, 179879.6914160257], 
processed observation next is [1.0, 0.8260869565217391, 0.6450617283950619, 0.6, 1.0, 1.0, 0.16366317806629357, 1.0, 1.0, 0.16366317806629357, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24231739636557936, 0.24231739636557936, 0.3459224834923571], 
reward next is 0.6541, 
noisyNet noise sample is [array([-0.9948159], dtype=float32), -0.75725335]. 
=============================================
[2019-04-27 19:14:23,550] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[60.216694]
 [60.61516 ]
 [60.77621 ]
 [61.315823]
 [61.585304]], R is [[60.07157898]
 [60.12619781]
 [60.18113708]
 [60.23625946]
 [60.29149628]].
[2019-04-27 19:14:31,920] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.9396457e-11 5.0663322e-01 1.2021303e-15 4.5766868e-03 4.8879012e-01], sum to 1.0000
[2019-04-27 19:14:31,927] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6042
[2019-04-27 19:14:31,931] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.33333333333334, 82.33333333333334, 1.0, 2.0, 0.6381782678915837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 727309.2639811118, 727309.2639811118, 164769.3508700264], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4440000.0000, 
sim time next is 4440600.0000, 
raw observation next is [26.5, 81.5, 1.0, 2.0, 0.2141855923598445, 1.0, 1.0, 0.2141855923598445, 1.0, 1.0, 0.3409904385746279, 6.9112, 6.9112, 121.94756008, 732301.6183016202, 732301.6183016202, 225284.4225230027], 
processed observation next is [0.0, 0.391304347826087, 0.5370370370370371, 0.815, 1.0, 1.0, 0.06450665757124345, 1.0, 0.5, 0.06450665757124345, 1.0, 0.5, 0.17623804821828487, 0.0, 0.0, 0.8096049824067558, 0.2615362922505787, 0.2615362922505787, 0.43323927408269747], 
reward next is 0.5668, 
noisyNet noise sample is [array([0.02679205], dtype=float32), -0.9392782]. 
=============================================
[2019-04-27 19:14:38,379] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.1320256e-14 9.9999750e-01 1.3851109e-15 1.4267692e-08 2.5270235e-06], sum to 1.0000
[2019-04-27 19:14:38,384] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3095
[2019-04-27 19:14:38,387] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.15, 99.16666666666667, 1.0, 2.0, 0.5892542273332497, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 683335.541315483, 683335.5413154826, 156804.3564006998], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4551000.0000, 
sim time next is 4551600.0000, 
raw observation next is [23.3, 98.33333333333334, 1.0, 2.0, 0.591492836881712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 685217.0198282539, 685217.0198282539, 157155.2754436195], 
processed observation next is [0.0, 0.6956521739130435, 0.41851851851851857, 0.9833333333333334, 1.0, 1.0, 0.5136819486687046, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2447203642243764, 0.2447203642243764, 0.3022216835454221], 
reward next is 0.6978, 
noisyNet noise sample is [array([-0.26682472], dtype=float32), 2.791413]. 
=============================================
[2019-04-27 19:14:38,651] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0389634e-14 9.9999976e-01 3.5845347e-18 4.4713193e-09 2.7391994e-07], sum to 1.0000
[2019-04-27 19:14:38,660] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0729
[2019-04-27 19:14:38,664] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.2, 99.33333333333334, 1.0, 2.0, 0.4793661735792897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 577337.8604870326, 577337.8604870326, 139888.0475507564], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4584000.0000, 
sim time next is 4584600.0000, 
raw observation next is [21.3, 99.0, 1.0, 2.0, 0.4819720768641134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 579848.0421518955, 579848.042151895, 140268.466187379], 
processed observation next is [1.0, 0.043478260869565216, 0.3444444444444445, 0.99, 1.0, 1.0, 0.38330009150489697, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2070885864828198, 0.20708858648281964, 0.26974705036034424], 
reward next is 0.7303, 
noisyNet noise sample is [array([0.5941132], dtype=float32), -0.23366806]. 
=============================================
[2019-04-27 19:14:40,971] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.1054833e-14 1.0000000e+00 5.1461793e-18 5.6383282e-15 6.6448413e-15], sum to 1.0000
[2019-04-27 19:14:40,976] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4022
[2019-04-27 19:14:40,980] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 89.0, 1.0, 2.0, 0.5533560788796322, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8809608991257138, 6.911199999999999, 6.9112, 121.9260426156618, 1261720.417138654, 1261720.417138654, 276154.8345107848], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4710600.0000, 
sim time next is 4711200.0000, 
raw observation next is [26.66666666666667, 89.0, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 8.846922877367792, 6.9112, 121.9181397784654, 2154677.629286295, 1163478.753478036, 245587.7412555954], 
processed observation next is [1.0, 0.5217391304347826, 0.5432098765432101, 0.89, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.1935722877367792, 0.0, 0.8094096621995233, 0.7695277247451053, 0.41552812624215574, 0.4722841177992219], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2449479], dtype=float32), 1.0829854]. 
=============================================
[2019-04-27 19:14:43,303] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4829280e-18 1.0000000e+00 4.8701366e-23 3.3133075e-18 1.7141813e-17], sum to 1.0000
[2019-04-27 19:14:43,313] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0620
[2019-04-27 19:14:43,319] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.2, 90.0, 1.0, 2.0, 0.6947271333229492, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 791789.2971734446, 791789.2971734442, 175148.961310586], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4653600.0000, 
sim time next is 4654200.0000, 
raw observation next is [26.1, 92.0, 1.0, 2.0, 0.704287482935535, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 802691.0538926995, 802691.0538926995, 176958.6975358216], 
processed observation next is [1.0, 0.8695652173913043, 0.5222222222222223, 0.92, 1.0, 1.0, 0.6479612892089702, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2866753763902498, 0.2866753763902498, 0.34030518756888767], 
reward next is 0.6597, 
noisyNet noise sample is [array([-0.54916435], dtype=float32), -0.6099707]. 
=============================================
[2019-04-27 19:14:43,980] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.6311790e-17 1.0000000e+00 1.1693284e-22 1.0106993e-16 1.2553101e-15], sum to 1.0000
[2019-04-27 19:14:43,987] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1175
[2019-04-27 19:14:43,992] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.6648746103903599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 757749.1820240607, 757749.1820240607, 169599.6906452617], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4667400.0000, 
sim time next is 4668000.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.6657908827654112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 758793.9629268016, 758793.9629268016, 169767.6205528828], 
processed observation next is [1.0, 0.0, 0.48148148148148145, 0.94, 1.0, 1.0, 0.6021320032921562, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27099784390242915, 0.27099784390242915, 0.3264761933709285], 
reward next is 0.6735, 
noisyNet noise sample is [array([-1.2027649], dtype=float32), 0.08849811]. 
=============================================
[2019-04-27 19:14:44,014] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[63.615013]
 [63.72255 ]
 [63.84887 ]
 [64.349205]
 [65.331764]], R is [[63.46556854]
 [63.50476074]
 [63.5437088 ]
 [63.58222961]
 [63.62042236]].
[2019-04-27 19:14:56,171] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.9386486e-14 1.0000000e+00 1.1836708e-16 2.3678569e-13 2.0099124e-12], sum to 1.0000
[2019-04-27 19:14:56,178] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0387
[2019-04-27 19:14:56,184] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.66666666666667, 94.0, 1.0, 2.0, 0.861382225249219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 981849.8808982555, 981849.8808982555, 208959.0613235775], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4915200.0000, 
sim time next is 4915800.0000, 
raw observation next is [27.5, 94.0, 1.0, 2.0, 0.848784077106386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 967480.767738016, 967480.767738016, 206234.9912326126], 
processed observation next is [1.0, 0.9130434782608695, 0.5740740740740741, 0.94, 1.0, 1.0, 0.8199810441742691, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.34552884562072, 0.34552884562072, 0.39660575237040885], 
reward next is 0.6034, 
noisyNet noise sample is [array([1.0649327], dtype=float32), 0.6257961]. 
=============================================
[2019-04-27 19:14:56,754] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.1181391e-15 1.0000000e+00 6.2089249e-17 8.4097456e-14 3.4034713e-12], sum to 1.0000
[2019-04-27 19:14:56,762] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2813
[2019-04-27 19:14:56,769] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.35, 87.0, 1.0, 2.0, 0.7640105424445089, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 870797.3313841661, 870797.3313841661, 188619.6427363958], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4923000.0000, 
sim time next is 4923600.0000, 
raw observation next is [27.23333333333333, 86.0, 1.0, 2.0, 0.745342667135985, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 849508.4299333907, 849508.4299333907, 184907.8327708606], 
processed observation next is [1.0, 1.0, 0.5641975308641974, 0.86, 1.0, 1.0, 0.6968365084952202, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3033958678333538, 0.3033958678333538, 0.35559198609780884], 
reward next is 0.6444, 
noisyNet noise sample is [array([-0.20405222], dtype=float32), 0.50286573]. 
=============================================
[2019-04-27 19:15:02,658] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.56698814e-16 1.00000000e+00 5.02705899e-20 1.00835945e-13
 1.49477999e-12], sum to 1.0000
[2019-04-27 19:15:02,667] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7498
[2019-04-27 19:15:02,670] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 85.0, 1.0, 2.0, 0.608908429516885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 698643.6747963013, 698643.6747963013, 159848.7803150789], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5040000.0000, 
sim time next is 5040600.0000, 
raw observation next is [25.58333333333333, 85.66666666666667, 1.0, 2.0, 0.6171493611316272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 705928.6250583809, 705928.6250583809, 161181.6090536864], 
processed observation next is [0.0, 0.34782608695652173, 0.5030864197530862, 0.8566666666666667, 1.0, 1.0, 0.5442254299186038, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25211736609227886, 0.25211736609227886, 0.3099646327955508], 
reward next is 0.6900, 
noisyNet noise sample is [array([2.0192065], dtype=float32), 0.5800947]. 
=============================================
[2019-04-27 19:15:04,020] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.3657768e-16 1.0000000e+00 2.2355826e-20 1.7022719e-14 4.5808260e-11], sum to 1.0000
[2019-04-27 19:15:04,028] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3630
[2019-04-27 19:15:04,035] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 73.33333333333334, 1.0, 2.0, 0.809659128287883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 922857.6078973552, 922857.6078973549, 197954.845623841], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5070000.0000, 
sim time next is 5070600.0000, 
raw observation next is [31.0, 72.5, 1.0, 2.0, 0.8375314126650312, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 954646.5053557265, 954646.5053557265, 203826.60834575], 
processed observation next is [0.0, 0.6956521739130435, 0.7037037037037037, 0.725, 1.0, 1.0, 0.8065850150774181, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.34094518048418804, 0.34094518048418804, 0.39197424681875], 
reward next is 0.6080, 
noisyNet noise sample is [array([1.5174654], dtype=float32), 0.76782084]. 
=============================================
[2019-04-27 19:15:08,131] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.7956948e-15 1.0000000e+00 1.3109678e-18 8.0839995e-13 5.4175180e-12], sum to 1.0000
[2019-04-27 19:15:08,141] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5732
[2019-04-27 19:15:08,147] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 73.5, 1.0, 2.0, 0.838538983849669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000003, 6.9112, 121.9260426156618, 955795.6851281378, 955795.6851281364, 204042.4058404203], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5145000.0000, 
sim time next is 5145600.0000, 
raw observation next is [31.0, 72.0, 1.0, 2.0, 0.8055443315517179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 918164.7116741657, 918164.7116741657, 197097.9975262221], 
processed observation next is [0.0, 0.5652173913043478, 0.7037037037037037, 0.72, 1.0, 1.0, 0.768505156609188, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.32791596845505916, 0.32791596845505916, 0.3790346106273502], 
reward next is 0.6210, 
noisyNet noise sample is [array([-0.5241666], dtype=float32), 0.00078039797]. 
=============================================
[2019-04-27 19:15:09,602] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.9177366e-17 1.0000000e+00 2.3986392e-21 5.6034635e-15 6.5826291e-14], sum to 1.0000
[2019-04-27 19:15:09,608] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3942
[2019-04-27 19:15:09,614] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.83333333333334, 70.83333333333334, 1.0, 2.0, 0.8689497291473964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 990481.3043844161, 990481.3043844161, 210610.541553415], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5152200.0000, 
sim time next is 5152800.0000, 
raw observation next is [31.66666666666667, 70.66666666666667, 1.0, 2.0, 0.8189415965391534, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 933444.3020307735, 933444.3020307735, 199896.6539086189], 
processed observation next is [0.0, 0.6521739130434783, 0.7283950617283952, 0.7066666666666667, 1.0, 1.0, 0.7844542815942303, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3333729650109905, 0.3333729650109905, 0.3844166421319594], 
reward next is 0.6156, 
noisyNet noise sample is [array([-0.26321882], dtype=float32), 0.4160961]. 
=============================================
[2019-04-27 19:15:09,967] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.5750329e-17 1.0000000e+00 2.5800076e-22 3.4198691e-16 2.2716179e-14], sum to 1.0000
[2019-04-27 19:15:09,973] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4783
[2019-04-27 19:15:09,977] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 83.0, 1.0, 2.0, 0.7421702227304905, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 845890.6235252187, 845890.6235252187, 184283.3897647566], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5168400.0000, 
sim time next is 5169000.0000, 
raw observation next is [27.5, 84.0, 1.0, 2.0, 0.7395327964208376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 842882.9564575694, 842882.9564575689, 183765.2355557225], 
processed observation next is [0.0, 0.8260869565217391, 0.5740740740740741, 0.84, 1.0, 1.0, 0.6899199957390924, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3010296273062748, 0.30102962730627464, 0.3533946837610048], 
reward next is 0.6466, 
noisyNet noise sample is [array([0.2027139], dtype=float32), 0.1757444]. 
=============================================
[2019-04-27 19:15:10,004] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[68.18046 ]
 [68.17997 ]
 [68.181915]
 [68.181564]
 [68.093796]], R is [[68.14742279]
 [68.11155701]
 [68.07661438]
 [68.04650879]
 [68.01667786]].
[2019-04-27 19:15:10,868] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.1969544e-13 1.0000000e+00 7.1517776e-16 1.6945251e-12 4.1385440e-10], sum to 1.0000
[2019-04-27 19:15:10,877] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7900
[2019-04-27 19:15:10,884] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.68333333333334, 84.83333333333334, 1.0, 2.0, 0.6797782018583405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 793071.1890626182, 793071.1890626182, 173235.6663581333], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5284200.0000, 
sim time next is 5284800.0000, 
raw observation next is [24.6, 85.0, 1.0, 2.0, 0.6716486894705437, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 784542.5142433527, 784542.5142433527, 171761.3289078841], 
processed observation next is [1.0, 0.17391304347826086, 0.46666666666666673, 0.85, 1.0, 1.0, 0.6091055827030282, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2801937550869117, 0.2801937550869117, 0.33031024789977714], 
reward next is 0.6697, 
noisyNet noise sample is [array([0.21968734], dtype=float32), -0.39807394]. 
=============================================
[2019-04-27 19:15:11,759] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-04-27 19:15:11,761] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 19:15:11,762] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:15:11,765] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 19:15:11,766] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:15:11,766] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 19:15:11,769] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 19:15:11,770] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 19:15:11,772] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:15:11,769] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:15:11,775] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:15:11,783] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run32
[2019-04-27 19:15:11,784] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run32
[2019-04-27 19:15:11,825] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run32
[2019-04-27 19:15:11,826] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run32
[2019-04-27 19:15:11,869] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run32
[2019-04-27 19:15:18,358] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.04773342]
[2019-04-27 19:15:18,362] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [17.1, 88.0, 1.0, 2.0, 0.2975124589948135, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 383736.6024937903, 383736.6024937903, 115254.7922963723]
[2019-04-27 19:15:18,363] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 19:15:18,364] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.5917222e-15 1.0000000e+00 6.0982645e-19 1.3814695e-13 7.9091996e-13], sampled 0.6104584336633837
[2019-04-27 19:16:08,580] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.04773342]
[2019-04-27 19:16:08,581] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.35, 97.5, 1.0, 2.0, 0.4344660917385105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 532474.1263649714, 532474.1263649714, 133434.9458372723]
[2019-04-27 19:16:08,583] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 19:16:08,588] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.0599604e-15 1.0000000e+00 1.4854808e-19 2.9213025e-14 1.7629004e-13], sampled 0.2429746464719954
[2019-04-27 19:17:02,631] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.0845 2170631810.8436 493.0000
[2019-04-27 19:17:03,151] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.1818 2120456093.0328 430.0000
[2019-04-27 19:17:03,209] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-04-27 19:17:03,252] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.6001 2445376094.7952 746.0000
[2019-04-27 19:17:03,441] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.5373 2195127027.8664 572.0000
[2019-04-27 19:17:04,458] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 775000, evaluation results [775000.0, 8100.600059888084, 2445376094.795151, 746.0, 8771.084470098069, 2170631810.843588, 493.0, 8924.181835947267, 2120456093.0327566, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.53728085528, 2195127027.866359, 572.0]
[2019-04-27 19:17:07,365] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.2981181e-17 1.0000000e+00 8.5609679e-22 5.0185402e-17 3.7430899e-16], sum to 1.0000
[2019-04-27 19:17:07,375] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1047
[2019-04-27 19:17:07,380] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.55, 85.0, 1.0, 2.0, 0.7285430557872978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 830350.6078659545, 830350.6078659545, 181621.3725027654], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5254200.0000, 
sim time next is 5254800.0000, 
raw observation next is [27.43333333333333, 85.33333333333333, 1.0, 2.0, 0.7417282725855527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 845386.631788012, 845386.631788012, 184196.9815548106], 
processed observation next is [1.0, 0.8260869565217391, 0.5716049382716049, 0.8533333333333333, 1.0, 1.0, 0.6925336578399437, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3019237970671471, 0.3019237970671471, 0.3542249645284819], 
reward next is 0.6458, 
noisyNet noise sample is [array([1.6410944], dtype=float32), -1.7316971]. 
=============================================
[2019-04-27 19:17:14,072] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.33741304e-15 1.00000000e+00 1.64209595e-19 1.00153514e-14
 1.64497796e-14], sum to 1.0000
[2019-04-27 19:17:14,078] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5062
[2019-04-27 19:17:14,082] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 90.66666666666667, 1.0, 2.0, 0.7010730705493825, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 812966.2255348989, 812966.2255348989, 177034.6515176865], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5373600.0000, 
sim time next is 5374200.0000, 
raw observation next is [24.15, 90.83333333333334, 1.0, 2.0, 0.7154290619448428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 830055.6247510688, 830055.6247510688, 179811.0765928366], 
processed observation next is [1.0, 0.17391304347826086, 0.44999999999999996, 0.9083333333333334, 1.0, 1.0, 0.6612250737438604, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.296448437411096, 0.296448437411096, 0.34579053190930115], 
reward next is 0.6542, 
noisyNet noise sample is [array([-0.1889061], dtype=float32), -0.5158986]. 
=============================================
[2019-04-27 19:17:14,310] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.7218255e-14 1.0000000e+00 2.1824724e-19 1.1230657e-15 6.2800866e-14], sum to 1.0000
[2019-04-27 19:17:14,318] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6986
[2019-04-27 19:17:14,322] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.06666666666667, 90.16666666666667, 1.0, 2.0, 0.7640721984895665, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 871129.2699868899, 871129.2699868899, 188636.4993192971], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5386200.0000, 
sim time next is 5386800.0000, 
raw observation next is [25.23333333333333, 89.33333333333334, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.477114633178773, 6.9112, 121.9241823740752, 1452802.590331049, 1163008.138766894, 245580.7253210909], 
processed observation next is [1.0, 0.34782608695652173, 0.49012345679012337, 0.8933333333333334, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.056591463317877275, 0.0, 0.8094497787505158, 0.5188580679753746, 0.415360049559605, 0.4722706256174825], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5239968], dtype=float32), -0.3035072]. 
=============================================
[2019-04-27 19:17:17,517] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.8550129e-18 1.0000000e+00 6.6585856e-25 4.8048697e-22 2.8323763e-20], sum to 1.0000
[2019-04-27 19:17:17,525] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0144
[2019-04-27 19:17:17,533] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2273953.473923613 W.
[2019-04-27 19:17:17,540] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.75, 76.0, 1.0, 2.0, 0.9966997538090265, 1.0, 1.0, 0.9966997538090265, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9254504158739, 2273953.473923613, 2273953.473923612, 431738.0356412389], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5501400.0000, 
sim time next is 5502000.0000, 
raw observation next is [28.4, 77.0, 1.0, 2.0, 0.5879890320793805, 1.0, 2.0, 0.5879890320793805, 1.0, 1.0, 0.9360976885362547, 6.911200000000001, 6.9112, 121.94756008, 2011935.126289544, 2011935.126289544, 388870.2442988903], 
processed observation next is [1.0, 0.6956521739130435, 0.6074074074074074, 0.77, 1.0, 1.0, 0.509510752475453, 1.0, 1.0, 0.509510752475453, 1.0, 0.5, 0.9201221106703183, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7185482593891228, 0.7185482593891228, 0.7478273928824813], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3972027], dtype=float32), -0.7004621]. 
=============================================
[2019-04-27 19:17:17,549] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[54.88897 ]
 [55.642075]
 [55.97172 ]
 [55.311317]
 [54.599762]], R is [[54.62685776]
 [54.08058929]
 [53.53978348]
 [53.27357864]
 [52.99845886]].
[2019-04-27 19:17:26,342] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.1811010e-21 1.0000000e+00 1.5816915e-25 1.9963247e-21 3.7132025e-20], sum to 1.0000
[2019-04-27 19:17:26,356] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8123
[2019-04-27 19:17:26,359] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 98.0, 1.0, 2.0, 0.611679195904053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 703268.4904965481, 703268.4904965481, 160401.2498013153], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5613600.0000, 
sim time next is 5614200.0000, 
raw observation next is [23.65, 98.0, 1.0, 2.0, 0.6090040143692838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 700454.9358553117, 700454.9358553117, 159947.533409252], 
processed observation next is [1.0, 1.0, 0.4314814814814814, 0.98, 1.0, 1.0, 0.5345285885348616, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2501624770911827, 0.2501624770911827, 0.30759141040240773], 
reward next is 0.6924, 
noisyNet noise sample is [array([-0.252782], dtype=float32), 0.6143535]. 
=============================================
[2019-04-27 19:17:33,208] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.1087733e-21 1.0000000e+00 3.7424653e-29 6.9465762e-20 2.4970760e-20], sum to 1.0000
[2019-04-27 19:17:33,213] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6689
[2019-04-27 19:17:33,218] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 81.0, 1.0, 2.0, 0.4499352212176937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 548334.2882927612, 548334.2882927607, 135637.3647306392], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5734800.0000, 
sim time next is 5735400.0000, 
raw observation next is [23.0, 80.0, 1.0, 2.0, 0.4512291615844211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 549345.9534585624, 549345.9534585624, 135813.8327996884], 
processed observation next is [0.0, 0.391304347826087, 0.4074074074074074, 0.8, 1.0, 1.0, 0.3467013828385966, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.196194983378058, 0.196194983378058, 0.26118044769170845], 
reward next is 0.7388, 
noisyNet noise sample is [array([1.1734741], dtype=float32), 0.64010775]. 
=============================================
[2019-04-27 19:17:41,154] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.6072106e-18 1.0000000e+00 1.3559480e-22 1.8450921e-16 1.3737260e-17], sum to 1.0000
[2019-04-27 19:17:41,166] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9654
[2019-04-27 19:17:41,169] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.08333333333333, 84.33333333333334, 1.0, 2.0, 0.3163452293507079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 402227.4565958832, 402227.4565958832, 117612.4558754134], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5893800.0000, 
sim time next is 5894400.0000, 
raw observation next is [19.26666666666667, 83.66666666666667, 1.0, 2.0, 0.3127564984691673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 397269.2644279423, 397269.2644279423, 117157.1807040182], 
processed observation next is [1.0, 0.21739130434782608, 0.2691358024691359, 0.8366666666666667, 1.0, 1.0, 0.18185297436805634, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14188188015283654, 0.14188188015283654, 0.22530227058465038], 
reward next is 0.7747, 
noisyNet noise sample is [array([-2.8525054], dtype=float32), -0.39722982]. 
=============================================
[2019-04-27 19:17:41,234] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.2547642e-22 1.0000000e+00 4.4319669e-27 6.7810276e-20 2.4859627e-22], sum to 1.0000
[2019-04-27 19:17:41,241] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1463
[2019-04-27 19:17:41,244] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.65, 85.5, 1.0, 2.0, 0.4713366857674947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 569760.3210193092, 569760.3210193092, 138726.7495181194], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5959800.0000, 
sim time next is 5960400.0000, 
raw observation next is [22.63333333333333, 85.0, 1.0, 2.0, 0.4680733910078664, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 566588.464542882, 566588.4645428816, 138254.3504390669], 
processed observation next is [1.0, 1.0, 0.393827160493827, 0.85, 1.0, 1.0, 0.3667540369141266, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2023530230510293, 0.20235302305102915, 0.26587375084435944], 
reward next is 0.7341, 
noisyNet noise sample is [array([0.00320287], dtype=float32), -0.28339994]. 
=============================================
[2019-04-27 19:17:42,486] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2242367e-20 1.0000000e+00 8.8381735e-24 2.9837445e-20 5.6813680e-19], sum to 1.0000
[2019-04-27 19:17:42,490] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6913
[2019-04-27 19:17:42,497] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1521779.676844362 W.
[2019-04-27 19:17:42,500] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.45, 43.5, 1.0, 2.0, 0.9994226941005313, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.520460657254262, 6.9112, 121.9235153627071, 1521779.676844362, 1209790.232204904, 244033.6400759835], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5927400.0000, 
sim time next is 5928000.0000, 
raw observation next is [29.4, 44.0, 1.0, 2.0, 0.5795140684768063, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9365066171434066, 6.911199999999999, 6.9112, 121.9256757291099, 1393341.52837101, 1393341.528371011, 284032.6961464142], 
processed observation next is [1.0, 0.6086956521739131, 0.6444444444444444, 0.44, 1.0, 1.0, 0.49942151009143604, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.9206332714292581, -8.881784197001253e-17, 0.0, 0.8094596930749665, 0.49762197441821787, 0.4976219744182182, 0.5462167233584888], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.5306119], dtype=float32), -0.16163751]. 
=============================================
[2019-04-27 19:17:42,517] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[66.1105  ]
 [65.28789 ]
 [64.48652 ]
 [63.254234]
 [62.82856 ]], R is [[66.24513245]
 [65.58267975]
 [65.38860321]
 [65.18569946]
 [64.53384399]].
[2019-04-27 19:17:44,069] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.6094104e-19 1.0000000e+00 1.5513895e-24 1.1773965e-18 1.2792621e-17], sum to 1.0000
[2019-04-27 19:17:44,074] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0472
[2019-04-27 19:17:44,080] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.2, 71.0, 1.0, 2.0, 0.4912622727484668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 589847.3569530859, 589847.3569530859, 141669.2684141638], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5950800.0000, 
sim time next is 5951400.0000, 
raw observation next is [24.98333333333333, 72.16666666666667, 1.0, 2.0, 0.4895213811556143, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 587936.2764403995, 587936.2764403995, 141404.3203550857], 
processed observation next is [1.0, 0.9130434782608695, 0.4808641975308641, 0.7216666666666667, 1.0, 1.0, 0.3922873585185884, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20997724158585696, 0.20997724158585696, 0.27193138529824173], 
reward next is 0.7281, 
noisyNet noise sample is [array([1.7789263], dtype=float32), 0.4169739]. 
=============================================
[2019-04-27 19:17:46,369] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.5210207e-15 1.0000000e+00 5.1428011e-19 3.4812227e-14 7.2082897e-14], sum to 1.0000
[2019-04-27 19:17:46,378] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7684
[2019-04-27 19:17:46,388] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1348279.416588945 W.
[2019-04-27 19:17:46,395] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.38333333333333, 70.83333333333334, 1.0, 2.0, 0.3869491446745149, 1.0, 1.0, 0.3869491446745149, 1.0, 1.0, 0.6173497725089664, 6.911199999999999, 6.9112, 121.94756008, 1348279.416588945, 1348279.416588946, 291477.4633025115], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5998200.0000, 
sim time next is 5998800.0000, 
raw observation next is [25.56666666666667, 70.66666666666667, 1.0, 2.0, 0.5511079258236092, 1.0, 2.0, 0.5511079258236092, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.926042471671, 1285468.788907724, 1285468.788907724, 252995.6867983696], 
processed observation next is [1.0, 0.43478260869565216, 0.5024691358024692, 0.7066666666666667, 1.0, 1.0, 0.4656046735995348, 1.0, 1.0, 0.4656046735995348, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621278641867, 0.45909599603847284, 0.45909599603847284, 0.48653016691994155], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2635708], dtype=float32), 0.6328002]. 
=============================================
[2019-04-27 19:17:47,399] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.35239224e-17 1.00000000e+00 1.18830006e-22 4.37739679e-18
 9.58524693e-19], sum to 1.0000
[2019-04-27 19:17:47,404] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5671
[2019-04-27 19:17:47,411] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1540118.160795867 W.
[2019-04-27 19:17:47,413] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.5, 64.0, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.624132889900999, 6.9112, 121.9231880584627, 1540118.160795867, 1175041.347400323, 246267.938101005], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6006600.0000, 
sim time next is 6007200.0000, 
raw observation next is [28.66666666666666, 63.33333333333333, 1.0, 2.0, 0.3333283271537097, 1.0, 1.0, 0.3333283271537097, 1.0, 1.0, 0.5306695525744423, 6.911199999999999, 6.9112, 121.94756008, 1139954.146077859, 1139954.146077859, 269109.4775340238], 
processed observation next is [1.0, 0.5217391304347826, 0.6172839506172837, 0.6333333333333333, 1.0, 1.0, 0.20634324661155917, 1.0, 0.5, 0.20634324661155917, 1.0, 0.5, 0.41333694071805277, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.4071264807420925, 0.4071264807420925, 0.5175182260269688], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7759675], dtype=float32), 0.54758704]. 
=============================================
[2019-04-27 19:17:52,849] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.02069125e-17 1.00000000e+00 6.29200587e-21 1.99778586e-15
 8.51789673e-16], sum to 1.0000
[2019-04-27 19:17:52,855] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0522
[2019-04-27 19:17:52,861] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.06666666666666, 67.33333333333333, 1.0, 2.0, 0.5474847406658112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 643137.6318613628, 643137.6318613628, 150163.9271989192], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6122400.0000, 
sim time next is 6123000.0000, 
raw observation next is [26.98333333333333, 67.66666666666667, 1.0, 2.0, 0.5468965712095464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 642743.3579362264, 642743.3579362264, 150079.4776272151], 
processed observation next is [1.0, 0.8695652173913043, 0.5549382716049381, 0.6766666666666667, 1.0, 1.0, 0.4605911562018409, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22955119926293802, 0.22955119926293802, 0.2886143800523367], 
reward next is 0.7114, 
noisyNet noise sample is [array([-0.27627614], dtype=float32), -0.4831756]. 
=============================================
[2019-04-27 19:17:52,872] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[61.76291 ]
 [61.66278 ]
 [61.302177]
 [61.11552 ]
 [61.32394 ]], R is [[61.88128281]
 [61.97369385]
 [62.06519699]
 [62.15539932]
 [62.24382019]].
[2019-04-27 19:17:54,390] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-04-27 19:17:54,396] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 19:17:54,398] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 19:17:54,400] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 19:17:54,399] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 19:17:54,402] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:17:54,403] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:17:54,401] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 19:17:54,403] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:17:54,404] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:17:54,405] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:17:54,423] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run33
[2019-04-27 19:17:54,446] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run33
[2019-04-27 19:17:54,447] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run33
[2019-04-27 19:17:54,465] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run33
[2019-04-27 19:17:54,504] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run33
[2019-04-27 19:18:24,369] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.045453988]
[2019-04-27 19:18:24,370] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.56666666666667, 64.0, 1.0, 2.0, 0.5818937943790656, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 672370.1828270347, 672370.1828270347, 155437.1088764895]
[2019-04-27 19:18:24,371] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 19:18:24,377] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.1150221e-17 1.0000000e+00 2.5382840e-22 4.2143650e-16 3.5071847e-16], sampled 0.9882914787304147
[2019-04-27 19:18:32,654] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.045453988]
[2019-04-27 19:18:32,655] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.840594025, 50.31138751166667, 1.0, 2.0, 0.4187558040089207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 516703.2289631919, 516703.2289631914, 131241.7511348873]
[2019-04-27 19:18:32,657] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 19:18:32,660] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.3886948e-17 1.0000000e+00 3.3633601e-22 5.6180360e-16 4.6849572e-16], sampled 0.3222611867865658
[2019-04-27 19:18:39,668] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.045453988]
[2019-04-27 19:18:39,672] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.55, 76.0, 1.0, 2.0, 0.5321566928108671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 627871.9532679416, 627871.9532679416, 147773.5286661645]
[2019-04-27 19:18:39,673] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 19:18:39,676] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.3588538e-18 1.0000000e+00 2.0588847e-22 2.9847866e-16 2.3269406e-16], sampled 0.8221794060388988
[2019-04-27 19:19:38,784] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.045453988]
[2019-04-27 19:19:38,785] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.08333333333334, 22.16666666666667, 1.0, 2.0, 0.3298421508011709, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 425496.5662858033, 425496.5662858033, 116231.7555520525]
[2019-04-27 19:19:38,787] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 19:19:38,790] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.3487082e-18 1.0000000e+00 5.8282792e-23 6.9484952e-17 4.6558433e-17], sampled 0.621088584272897
[2019-04-27 19:19:46,105] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-04-27 19:19:46,357] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8922.7937 2120437309.6851 430.0000
[2019-04-27 19:19:46,383] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8583.7006 2248699398.1120 553.0000
[2019-04-27 19:19:46,479] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-04-27 19:19:46,532] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-04-27 19:19:47,552] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 800000, evaluation results [800000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8922.793663302313, 2120437309.6850784, 430.0, 8583.700649532175, 2248699398.111969, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-04-27 19:19:48,360] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.7278379e-15 1.0000000e+00 4.1628614e-19 3.8386305e-15 3.8892018e-15], sum to 1.0000
[2019-04-27 19:19:48,371] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9940
[2019-04-27 19:19:48,377] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1446233.107752338 W.
[2019-04-27 19:19:48,381] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.13333333333333, 73.0, 1.0, 2.0, 0.6337455002158574, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9865459619311236, 6.911199999999999, 6.9112, 121.9260426156618, 1446233.107752338, 1446233.107752338, 303556.9953057286], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6169800.0000, 
sim time next is 6170400.0000, 
raw observation next is [26.3, 72.0, 1.0, 2.0, 0.6513655090515214, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9867193787309007, 6.911199999999999, 6.9112, 121.9260426156618, 1466440.633461346, 1466440.633461346, 306627.8475205585], 
processed observation next is [1.0, 0.43478260869565216, 0.5296296296296297, 0.72, 1.0, 1.0, 0.5849589393470492, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9833992234136257, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5237287976647664, 0.5237287976647664, 0.5896689375395356], 
reward next is 0.4103, 
noisyNet noise sample is [array([-0.26787853], dtype=float32), 1.5268644]. 
=============================================
[2019-04-27 19:19:50,674] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.2029967e-13 1.0000000e+00 3.9543204e-16 5.5918713e-14 1.8813991e-14], sum to 1.0000
[2019-04-27 19:19:50,681] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4799
[2019-04-27 19:19:50,688] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1777117.508659253 W.
[2019-04-27 19:19:50,695] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.83333333333334, 54.66666666666667, 1.0, 2.0, 0.7791473561508129, 1.0, 1.0, 0.7791473561508129, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1777117.508659253, 1777117.508659253, 335211.5283371776], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6186000.0000, 
sim time next is 6186600.0000, 
raw observation next is [29.85, 54.5, 1.0, 2.0, 0.7902480201814122, 1.0, 2.0, 0.7902480201814122, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1802461.993215753, 1802461.993215754, 339739.6252794794], 
processed observation next is [1.0, 0.6086956521739131, 0.6611111111111112, 0.545, 1.0, 1.0, 0.7502952621207287, 1.0, 1.0, 0.7502952621207287, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6437364261484833, 0.6437364261484836, 0.6533454332297681], 
reward next is 0.3467, 
noisyNet noise sample is [array([0.8615262], dtype=float32), -0.58667666]. 
=============================================
[2019-04-27 19:20:01,339] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.8450554e-12 1.0000000e+00 1.0748957e-15 3.4941935e-11 2.9956818e-11], sum to 1.0000
[2019-04-27 19:20:01,349] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6350
[2019-04-27 19:20:01,358] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.76666666666667, 82.0, 1.0, 2.0, 0.6821823696665255, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 777484.6202186167, 777484.6202186163, 172796.7605566508], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6394800.0000, 
sim time next is 6395400.0000, 
raw observation next is [26.65, 82.5, 1.0, 2.0, 0.6825589677407253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 777914.0476021738, 777914.0476021738, 172866.6964049963], 
processed observation next is [1.0, 0.0, 0.5425925925925925, 0.825, 1.0, 1.0, 0.6220940092151492, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2778264455722049, 0.2778264455722049, 0.33243595462499287], 
reward next is 0.6676, 
noisyNet noise sample is [array([-0.13487193], dtype=float32), -0.5352371]. 
=============================================
[2019-04-27 19:20:01,719] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.2482763e-15 1.0000000e+00 1.0772133e-18 2.5589052e-14 2.6389354e-14], sum to 1.0000
[2019-04-27 19:20:01,727] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1641
[2019-04-27 19:20:01,731] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 81.0, 1.0, 2.0, 0.69008527670431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 786496.2002645655, 786496.2002645655, 174274.0362249814], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6393600.0000, 
sim time next is 6394200.0000, 
raw observation next is [26.88333333333333, 81.5, 1.0, 2.0, 0.6754689723546083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 769829.505557975, 769829.505557975, 171550.8640729823], 
processed observation next is [1.0, 0.0, 0.5512345679012344, 0.815, 1.0, 1.0, 0.6136535385173909, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27493910912784825, 0.27493910912784825, 0.32990550783265826], 
reward next is 0.6701, 
noisyNet noise sample is [array([1.4099178], dtype=float32), -0.39007926]. 
=============================================
[2019-04-27 19:20:03,993] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.9637092e-11 1.0000000e+00 1.4594455e-13 6.4901773e-13 2.4261404e-10], sum to 1.0000
[2019-04-27 19:20:03,999] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5825
[2019-04-27 19:20:04,007] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2073881.677588529 W.
[2019-04-27 19:20:04,010] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.85, 63.5, 1.0, 2.0, 0.6060719478962491, 1.0, 2.0, 0.6060719478962491, 1.0, 2.0, 0.964886279436163, 6.911199999999999, 6.9112, 121.94756008, 2073881.677588529, 2073881.677588529, 398693.8301831083], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6438600.0000, 
sim time next is 6439200.0000, 
raw observation next is [31.03333333333333, 62.33333333333334, 1.0, 2.0, 0.5627008082523746, 1.0, 2.0, 0.5627008082523746, 1.0, 2.0, 0.8958380126237084, 6.9112, 6.9112, 121.94756008, 1925312.593144805, 1925312.593144805, 375427.9261987095], 
processed observation next is [1.0, 0.5217391304347826, 0.7049382716049382, 0.6233333333333334, 1.0, 1.0, 0.4794057241099697, 1.0, 1.0, 0.4794057241099697, 1.0, 1.0, 0.8697975157796356, 0.0, 0.0, 0.8096049824067558, 0.6876116404088589, 0.6876116404088589, 0.7219767811513644], 
reward next is 0.2780, 
noisyNet noise sample is [array([-0.35826042], dtype=float32), 0.41936532]. 
=============================================
[2019-04-27 19:20:08,023] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.8526497e-07 9.9259371e-01 3.7030404e-10 4.5629308e-06 7.4008261e-03], sum to 1.0000
[2019-04-27 19:20:08,034] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1504
[2019-04-27 19:20:08,039] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.3, 88.66666666666666, 1.0, 2.0, 0.8413418979807646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 958992.5424878356, 958992.5424878352, 204628.2966761223], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6507600.0000, 
sim time next is 6508200.0000, 
raw observation next is [26.3, 88.83333333333334, 1.0, 2.0, 0.8275059340343895, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 943212.0947301729, 943212.0947301724, 201687.2666632207], 
processed observation next is [1.0, 0.30434782608695654, 0.5296296296296297, 0.8883333333333334, 1.0, 1.0, 0.7946499214695114, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3368614624036332, 0.336861462403633, 0.38786012819850135], 
reward next is 0.6121, 
noisyNet noise sample is [array([0.54684716], dtype=float32), 0.40111232]. 
=============================================
[2019-04-27 19:20:13,182] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2799540e-09 9.9999690e-01 1.0277195e-12 1.3859600e-09 3.1243237e-06], sum to 1.0000
[2019-04-27 19:20:13,188] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2938
[2019-04-27 19:20:13,195] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1327174.721596794 W.
[2019-04-27 19:20:13,200] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.53333333333333, 30.33333333333334, 1.0, 2.0, 0.3606181163858415, 1.0, 2.0, 0.3606181163858415, 1.0, 2.0, 0.5917266586895685, 6.911199999999999, 6.9112, 121.94756008, 1327174.721596794, 1327174.721596794, 278813.8359018885], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6626400.0000, 
sim time next is 6627000.0000, 
raw observation next is [29.66666666666667, 28.66666666666666, 1.0, 2.0, 0.5186745582529038, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8672075740557467, 6.911200000000001, 6.9112, 121.9260426156618, 1293590.817695283, 1293590.817695283, 258767.4687730496], 
processed observation next is [1.0, 0.6956521739130435, 0.6543209876543211, 0.2866666666666666, 1.0, 1.0, 0.42699352172964733, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.8340094675696832, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.46199672060545827, 0.46199672060545827, 0.49762974764048], 
reward next is 0.5024, 
noisyNet noise sample is [array([-0.90691704], dtype=float32), -0.5962461]. 
=============================================
[2019-04-27 19:20:13,209] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[39.616467]
 [39.815193]
 [39.463745]
 [39.487667]
 [39.08449 ]], R is [[40.02633667]
 [40.08989334]
 [39.68899536]
 [39.29210663]
 [38.89918518]].
[2019-04-27 19:20:13,841] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.0990836e-09 9.7275281e-01 4.5768684e-13 4.0386819e-08 2.7247151e-02], sum to 1.0000
[2019-04-27 19:20:13,847] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5743
[2019-04-27 19:20:13,855] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1509629.041708172 W.
[2019-04-27 19:20:13,860] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.13333333333333, 35.33333333333334, 1.0, 2.0, 0.6453606397033892, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9556966372235788, 6.9112, 6.9112, 121.9255524585025, 1509629.041708172, 1509629.041708172, 293586.1977365538], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6624600.0000, 
sim time next is 6625200.0000, 
raw observation next is [29.26666666666667, 33.66666666666667, 1.0, 2.0, 0.5445017952441785, 1.0, 1.0, 0.5445017952441785, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260424661967, 1340516.337954727, 1340516.337954727, 253356.1604073521], 
processed observation next is [1.0, 0.6956521739130435, 0.6395061728395063, 0.3366666666666667, 1.0, 1.0, 0.45774023243354584, 1.0, 0.5, 0.45774023243354584, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621278278431, 0.47875583498383106, 0.47875583498383106, 0.48722338539875404], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.9829297], dtype=float32), -0.590618]. 
=============================================
[2019-04-27 19:20:27,151] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.4117328e-11 9.9989808e-01 8.4299811e-16 1.1187848e-07 1.0175336e-04], sum to 1.0000
[2019-04-27 19:20:27,161] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9870
[2019-04-27 19:20:27,167] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.4, 49.66666666666667, 1.0, 2.0, 0.4831729864519688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 578912.4971410721, 578912.4971410721, 140371.2783160746], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6870000.0000, 
sim time next is 6870600.0000, 
raw observation next is [29.55, 49.5, 1.0, 2.0, 0.4890046624863106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 584910.2742605347, 584910.2742605347, 141239.1419209519], 
processed observation next is [0.0, 0.5217391304347826, 0.65, 0.495, 1.0, 1.0, 0.3916722172456078, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20889652652161952, 0.20889652652161952, 0.271613734463369], 
reward next is 0.7284, 
noisyNet noise sample is [array([0.06353464], dtype=float32), 0.5134469]. 
=============================================
[2019-04-27 19:20:29,782] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.5586547e-12 9.9998796e-01 1.1007760e-15 2.6250300e-09 1.2048078e-05], sum to 1.0000
[2019-04-27 19:20:29,790] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4135
[2019-04-27 19:20:29,795] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.03333333333333, 81.0, 1.0, 2.0, 0.4165695959733413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 513268.1903908714, 513268.1903908714, 130909.6147166401], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6924000.0000, 
sim time next is 6924600.0000, 
raw observation next is [21.95, 81.5, 1.0, 2.0, 0.4159822314287137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 512658.361617891, 512658.361617891, 130828.1050242323], 
processed observation next is [0.0, 0.13043478260869565, 0.36851851851851847, 0.815, 1.0, 1.0, 0.30474075170084963, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18309227200638964, 0.18309227200638964, 0.2515925096619852], 
reward next is 0.7484, 
noisyNet noise sample is [array([-0.90792227], dtype=float32), -2.675445]. 
=============================================
[2019-04-27 19:20:34,141] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.0713939e-09 9.9963450e-01 4.0993066e-13 1.0121354e-08 3.6543127e-04], sum to 1.0000
[2019-04-27 19:20:34,148] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6928
[2019-04-27 19:20:34,155] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333333, 81.33333333333333, 1.0, 2.0, 0.8542419107353447, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1038810.681990577, 1038810.681990577, 210355.0978676282], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7029600.0000, 
sim time next is 7030200.0000, 
raw observation next is [23.01666666666667, 80.66666666666667, 1.0, 2.0, 0.8686843987365739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1054787.728149049, 1054787.728149049, 213504.8998487096], 
processed observation next is [1.0, 0.34782608695652173, 0.40802469135802477, 0.8066666666666668, 1.0, 1.0, 0.843671903257826, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.37670990291037465, 0.37670990291037465, 0.4105863458629031], 
reward next is 0.5894, 
noisyNet noise sample is [array([0.15152392], dtype=float32), 1.2022392]. 
=============================================
[2019-04-27 19:20:37,406] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-04-27 19:20:37,408] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 19:20:37,408] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:20:37,409] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 19:20:37,410] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 19:20:37,411] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:20:37,411] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:20:37,412] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 19:20:37,413] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 19:20:37,415] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:20:37,416] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:20:37,428] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run34
[2019-04-27 19:20:37,428] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run34
[2019-04-27 19:20:37,467] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run34
[2019-04-27 19:20:37,494] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run34
[2019-04-27 19:20:37,517] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run34
[2019-04-27 19:20:40,707] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.04448562]
[2019-04-27 19:20:40,709] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [19.1, 50.0, 1.0, 2.0, 0.2138712546088815, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 275867.1364679461, 275867.1364679461, 81609.79790039537]
[2019-04-27 19:20:40,709] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 19:20:40,713] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.0090036e-14 1.0000000e+00 2.1001936e-18 1.7191831e-11 8.1318943e-09], sampled 0.2391331230363185
[2019-04-27 19:21:10,004] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.04448562]
[2019-04-27 19:21:10,004] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [34.2, 36.33333333333333, 1.0, 2.0, 0.7257561705751836, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9887754288677499, 6.911200000000001, 6.9112, 121.9260426156618, 1550392.833458567, 1550392.833458567, 320422.4210951025]
[2019-04-27 19:21:10,005] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 19:21:10,007] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.5297635e-16 1.0000000e+00 9.7044008e-22 4.0253852e-14 4.6599380e-10], sampled 0.39079690158440905
[2019-04-27 19:21:10,008] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1550392.833458567 W.
[2019-04-27 19:21:16,934] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.04448562]
[2019-04-27 19:21:16,935] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.0, 100.0, 1.0, 2.0, 0.6626073984976381, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 784989.0747185454, 784989.0747185454, 170558.4006346406]
[2019-04-27 19:21:16,936] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 19:21:16,939] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.6685108e-14 1.0000000e+00 3.3424418e-18 2.8747879e-11 2.8173773e-08], sampled 0.34483650623419826
[2019-04-27 19:21:37,237] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.04448562]
[2019-04-27 19:21:37,239] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.11560137833334, 82.74107418999999, 1.0, 2.0, 0.4151503118003803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 508909.6885786331, 508909.6885786331, 130637.7905855933]
[2019-04-27 19:21:37,241] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 19:21:37,243] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.0682684e-14 1.0000000e+00 8.3424013e-19 9.8348118e-12 7.0028880e-09], sampled 0.5205745327925945
[2019-04-27 19:21:50,131] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.04448562]
[2019-04-27 19:21:50,133] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.93334933, 72.81269466166665, 1.0, 2.0, 0.8597846340884179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156513, 980027.6959352694, 980027.6959352698, 208611.8630347009]
[2019-04-27 19:21:50,135] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 19:21:50,140] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.37396393e-14 1.00000000e+00 3.74321277e-19 6.37838176e-12
 1.21227055e-08], sampled 0.1709615336052639
[2019-04-27 19:21:52,066] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.04448562]
[2019-04-27 19:21:52,067] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.69996977, 73.69488028, 1.0, 2.0, 0.6560517173392939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 801404.9862152637, 801404.9862152637, 170208.9423752158]
[2019-04-27 19:21:52,069] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 19:21:52,071] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.62963342e-14 1.00000000e+00 1.93471528e-18 1.30961795e-11
 6.52825616e-09], sampled 0.024274223521543736
[2019-04-27 19:22:00,569] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.04448562]
[2019-04-27 19:22:00,571] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.56186737, 75.95379322333332, 1.0, 2.0, 0.3986300380881831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 491138.890798133, 491138.890798133, 128359.7557916596]
[2019-04-27 19:22:00,572] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 19:22:00,576] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.9935110e-14 1.0000000e+00 1.9411024e-18 1.8117924e-11 1.1453601e-08], sampled 0.8173905888080233
[2019-04-27 19:22:28,705] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-04-27 19:22:29,081] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8923.5144 2120682542.6928 431.0000
[2019-04-27 19:22:29,273] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8700.1902 2195180495.3879 572.0000
[2019-04-27 19:22:29,322] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8770.9825 2170706434.0998 493.0000
[2019-04-27 19:22:29,427] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8583.7021 2248718286.8236 553.0000
[2019-04-27 19:22:30,441] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 825000, evaluation results [825000.0, 8100.722247181571, 2445312557.402538, 746.0, 8770.982521107422, 2170706434.0998335, 493.0, 8923.514364720908, 2120682542.6927907, 431.0, 8583.702050975664, 2248718286.823596, 553.0, 8700.190165184516, 2195180495.38794, 572.0]
[2019-04-27 19:22:34,028] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.2493298e-17 1.0000000e+00 5.1824420e-20 3.1435970e-13 1.2895239e-10], sum to 1.0000
[2019-04-27 19:22:34,037] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5771
[2019-04-27 19:22:34,044] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.63333333333333, 75.33333333333334, 1.0, 2.0, 0.3657249767673954, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 457716.8219946089, 457716.8219946089, 123986.0397792484], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7150800.0000, 
sim time next is 7151400.0000, 
raw observation next is [21.45, 76.5, 1.0, 2.0, 0.364819306602703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 456691.2044678659, 456691.2044678659, 123865.6730230436], 
processed observation next is [1.0, 0.782608695652174, 0.35, 0.765, 1.0, 1.0, 0.24383250786036073, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16310400159566638, 0.16310400159566638, 0.23820321735200692], 
reward next is 0.7618, 
noisyNet noise sample is [array([0.1637312], dtype=float32), -0.68973714]. 
=============================================
[2019-04-27 19:22:36,229] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.6708642e-13 1.0000000e+00 3.3716027e-17 6.5293701e-11 5.4126303e-09], sum to 1.0000
[2019-04-27 19:22:36,240] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3339
[2019-04-27 19:22:36,245] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.71666666666667, 94.16666666666667, 1.0, 2.0, 0.3876649820267691, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 482120.5538435091, 482120.5538435091, 126933.4577469296], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7181400.0000, 
sim time next is 7182000.0000, 
raw observation next is [19.7, 94.0, 1.0, 2.0, 0.3848007816969857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 478797.5395913973, 478797.5395913973, 126541.5757477963], 
processed observation next is [1.0, 0.13043478260869565, 0.28518518518518515, 0.94, 1.0, 1.0, 0.2676199782106973, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17099912128264189, 0.17099912128264189, 0.2433491841303775], 
reward next is 0.7567, 
noisyNet noise sample is [array([0.09191433], dtype=float32), -0.48441818]. 
=============================================
[2019-04-27 19:22:36,266] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[68.78478 ]
 [68.92547 ]
 [69.45745 ]
 [69.913345]
 [70.04868 ]], R is [[68.76128387]
 [68.82956696]
 [68.89620972]
 [68.96096802]
 [69.02045441]].
[2019-04-27 19:22:40,249] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.7917938e-14 1.0000000e+00 7.5259367e-17 5.4266834e-11 8.8897725e-09], sum to 1.0000
[2019-04-27 19:22:40,257] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4486
[2019-04-27 19:22:40,268] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.65, 84.5, 1.0, 2.0, 0.3692135233960258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 460739.7213885247, 460739.7213885247, 124433.9287289316], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7263000.0000, 
sim time next is 7263600.0000, 
raw observation next is [20.63333333333333, 84.66666666666667, 1.0, 2.0, 0.3708024662062346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 462693.531615181, 462693.531615181, 124649.0432008818], 
processed observation next is [1.0, 0.043478260869565216, 0.3197530864197529, 0.8466666666666667, 1.0, 1.0, 0.25095531691218403, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16524768986256463, 0.16524768986256463, 0.23970969846323423], 
reward next is 0.7603, 
noisyNet noise sample is [array([0.02585528], dtype=float32), -0.5765228]. 
=============================================
[2019-04-27 19:22:43,658] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.0554090e-12 9.9887246e-01 4.9897424e-16 1.2449632e-07 1.1273612e-03], sum to 1.0000
[2019-04-27 19:22:43,671] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2496
[2019-04-27 19:22:43,680] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1354057.840527505 W.
[2019-04-27 19:22:43,693] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.8, 62.0, 1.0, 2.0, 0.5774873272719641, 1.0, 2.0, 0.5774873272719641, 0.0, 2.0, 0.0, 6.911199999999997, 6.9112, 121.9260426156618, 1354057.840527505, 1354057.840527506, 262122.4409605151], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7310400.0000, 
sim time next is 7311000.0000, 
raw observation next is [26.8, 62.0, 1.0, 2.0, 0.5782408721515389, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9261790098445364, 6.9112, 6.9112, 121.9260426156618, 1363400.434031479, 1363400.434031479, 284548.1839922156], 
processed observation next is [1.0, 0.6086956521739131, 0.5481481481481482, 0.62, 1.0, 1.0, 0.49790580018040337, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9077237623056705, 0.0, 0.0, 0.8094621288201359, 0.48692872643981394, 0.48692872643981394, 0.5472080461388762], 
reward next is 0.4528, 
noisyNet noise sample is [array([0.05247288], dtype=float32), 0.66218096]. 
=============================================
[2019-04-27 19:22:43,703] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[69.95155 ]
 [69.071106]
 [69.25198 ]
 [68.521255]
 [67.486496]], R is [[69.37390137]
 [69.1760788 ]
 [68.9825058 ]
 [68.75820923]
 [68.53713226]].
[2019-04-27 19:22:50,626] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.3438080e-13 9.9999964e-01 7.4732299e-19 1.1432495e-11 4.1675051e-07], sum to 1.0000
[2019-04-27 19:22:50,634] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6633
[2019-04-27 19:22:50,639] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.96666666666667, 90.0, 1.0, 2.0, 0.4010371180666452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 493753.5928773811, 493753.5928773811, 128690.2447979542], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7461600.0000, 
sim time next is 7462200.0000, 
raw observation next is [21.13333333333333, 89.5, 1.0, 2.0, 0.4054001993659094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 498347.0827528159, 498347.0827528159, 129286.6567881214], 
processed observation next is [0.0, 0.34782608695652173, 0.33827160493827146, 0.895, 1.0, 1.0, 0.29214309448322545, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17798110098314854, 0.17798110098314854, 0.24862818613100268], 
reward next is 0.7514, 
noisyNet noise sample is [array([0.1852566], dtype=float32), -0.67966247]. 
=============================================
[2019-04-27 19:22:53,755] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.1926898e-14 9.9999940e-01 9.6701529e-19 3.9324879e-10 6.3364990e-07], sum to 1.0000
[2019-04-27 19:22:53,761] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8698
[2019-04-27 19:22:53,766] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.1, 93.0, 1.0, 2.0, 0.4797784848120001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 576138.363140538, 576138.363140538, 139893.4372406062], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7509600.0000, 
sim time next is 7510200.0000, 
raw observation next is [22.05, 93.33333333333333, 1.0, 2.0, 0.4789473946605188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 575275.3882957068, 575275.3882957068, 139770.3168073402], 
processed observation next is [0.0, 0.9565217391304348, 0.37222222222222223, 0.9333333333333332, 1.0, 1.0, 0.3796992793577605, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2054554958198953, 0.2054554958198953, 0.2687890707833465], 
reward next is 0.7312, 
noisyNet noise sample is [array([-0.00686395], dtype=float32), -0.059361108]. 
=============================================
[2019-04-27 19:22:55,312] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.6144766e-13 9.9999833e-01 5.7597893e-18 7.7649692e-10 1.6552027e-06], sum to 1.0000
[2019-04-27 19:22:55,316] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7708
[2019-04-27 19:22:55,324] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 88.5, 1.0, 2.0, 0.472302222914937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 567207.3429454203, 567207.3429454203, 138749.790488445], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7551000.0000, 
sim time next is 7551600.0000, 
raw observation next is [22.9, 87.66666666666666, 1.0, 2.0, 0.4771896816415909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 572160.1558727993, 572160.1558727993, 139465.5090735751], 
processed observation next is [0.0, 0.391304347826087, 0.4037037037037037, 0.8766666666666666, 1.0, 1.0, 0.3776067638590368, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20434291281171404, 0.20434291281171404, 0.2682029020645675], 
reward next is 0.7318, 
noisyNet noise sample is [array([-0.0009435], dtype=float32), -0.934627]. 
=============================================
[2019-04-27 19:23:12,253] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:23:12,253] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:23:12,277] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run5
[2019-04-27 19:23:13,545] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:23:13,545] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:23:13,559] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run5
[2019-04-27 19:23:13,836] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.6287334e-08 9.7184932e-01 6.9533618e-10 8.5998527e-06 2.8142110e-02], sum to 1.0000
[2019-04-27 19:23:13,841] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8343
[2019-04-27 19:23:13,846] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1618419.956296927 W.
[2019-04-27 19:23:13,850] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.8, 47.0, 1.0, 2.0, 0.7699001277285459, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9737969216921957, 6.911200000000001, 6.9112, 121.926042322825, 1618419.956296927, 1618419.956296926, 325797.3215946], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7911600.0000, 
sim time next is 7912200.0000, 
raw observation next is [29.95, 46.5, 1.0, 2.0, 0.6922147497537267, 1.0, 1.0, 0.6922147497537267, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426155725, 1619530.312030389, 1619530.31203039, 303214.6470780642], 
processed observation next is [1.0, 0.5652173913043478, 0.6648148148148147, 0.465, 1.0, 1.0, 0.6335889878020555, 1.0, 0.5, 0.6335889878020555, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.809462128819543, 0.578403682867996, 0.5784036828679964, 0.5831050905347389], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.165652], dtype=float32), 0.14793298]. 
=============================================
[2019-04-27 19:23:16,229] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:23:16,229] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:23:16,232] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run5
[2019-04-27 19:23:16,431] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:23:16,431] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:23:16,433] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run5
[2019-04-27 19:23:16,492] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:23:16,492] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:23:16,495] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run5
[2019-04-27 19:23:16,517] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:23:16,518] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:23:16,525] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run5
[2019-04-27 19:23:16,543] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:23:16,543] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:23:16,553] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run5
[2019-04-27 19:23:16,637] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:23:16,637] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:23:16,638] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run5
[2019-04-27 19:23:16,737] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:23:16,737] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:23:16,738] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run5
[2019-04-27 19:23:16,761] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:23:16,763] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:23:16,763] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:23:16,764] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:23:16,770] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run5
[2019-04-27 19:23:16,797] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run5
[2019-04-27 19:23:16,825] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:23:16,825] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:23:16,830] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run5
[2019-04-27 19:23:16,855] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:23:16,857] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:23:16,863] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run5
[2019-04-27 19:23:16,885] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:23:16,890] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:23:16,891] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run5
[2019-04-27 19:23:16,965] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:23:16,965] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:23:16,967] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run5
[2019-04-27 19:23:17,078] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:23:17,079] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:23:17,083] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run5
[2019-04-27 19:23:21,057] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-04-27 19:23:21,058] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 19:23:21,060] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 19:23:21,061] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:23:21,061] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:23:21,063] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 19:23:21,062] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 19:23:21,064] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 19:23:21,064] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:23:21,065] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:23:21,067] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:23:21,087] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run35
[2019-04-27 19:23:21,109] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run35
[2019-04-27 19:23:21,110] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run35
[2019-04-27 19:23:21,146] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run35
[2019-04-27 19:23:21,146] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run35
[2019-04-27 19:23:42,832] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.05155839]
[2019-04-27 19:23:42,836] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.58333333333333, 53.33333333333334, 1.0, 2.0, 0.4822206754639745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 578233.0315436873, 578233.0315436873, 140240.6771134192]
[2019-04-27 19:23:42,837] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 19:23:42,841] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.4772978e-13 9.9998534e-01 1.0053133e-15 8.0637550e-09 1.4675781e-05], sampled 0.25030517371376615
[2019-04-27 19:24:56,336] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.05155839]
[2019-04-27 19:24:56,337] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.21029344, 59.71804707, 1.0, 2.0, 0.2665901353084576, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 342985.1637739887, 342985.1637739887, 111541.5574865847]
[2019-04-27 19:24:56,339] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 19:24:56,343] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.2748901e-12 9.9990427e-01 1.1598346e-14 5.0099345e-08 9.5675758e-05], sampled 0.41258896799210665
[2019-04-27 19:25:12,664] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8752.6147 2208265590.7979 342.0000
[2019-04-27 19:25:13,478] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8139.1110 2493721288.9787 433.0000
[2019-04-27 19:25:13,591] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8845.6632 2166442047.1548 292.0000
[2019-04-27 19:25:13,623] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8609.7348 2283344653.5016 356.0000
[2019-04-27 19:25:13,661] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8658.5916 2240035778.7284 384.0000
[2019-04-27 19:25:14,675] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 850000, evaluation results [850000.0, 8139.1109786196985, 2493721288.9787126, 433.0, 8752.614690466593, 2208265590.7978654, 342.0, 8845.663223716654, 2166442047.1548223, 292.0, 8609.734787755287, 2283344653.501573, 356.0, 8658.591640883955, 2240035778.72842, 384.0]
[2019-04-27 19:25:15,283] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.7452772e-15 9.9999952e-01 5.7116199e-17 1.6469898e-10 5.2977435e-07], sum to 1.0000
[2019-04-27 19:25:15,290] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9247
[2019-04-27 19:25:15,293] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.75, 43.5, 1.0, 2.0, 0.4056531892704527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 499842.1861612421, 499842.1861612421, 129352.5503765759], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 66600.0000, 
sim time next is 67200.0000, 
raw observation next is [28.63333333333333, 44.0, 1.0, 2.0, 0.4045681409863642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 498484.3204522337, 498484.3204522337, 129198.3530877402], 
processed observation next is [1.0, 0.782608695652174, 0.6160493827160493, 0.44, 1.0, 1.0, 0.2911525487932907, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17803011444722633, 0.17803011444722633, 0.24845837132257728], 
reward next is 0.7515, 
noisyNet noise sample is [array([0.51296043], dtype=float32), 2.5151896]. 
=============================================
[2019-04-27 19:25:18,554] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.7665177e-12 9.9995637e-01 3.2754757e-14 3.4504391e-10 4.3660570e-05], sum to 1.0000
[2019-04-27 19:25:18,565] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6768
[2019-04-27 19:25:18,573] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1447787.363651821 W.
[2019-04-27 19:25:18,577] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.65, 40.0, 1.0, 2.0, 0.4178951010288759, 1.0, 2.0, 0.4178951010288759, 1.0, 2.0, 0.6660757722796473, 6.911199999999999, 6.9112, 121.94756008, 1447787.363651821, 1447787.363651822, 305095.2227551929], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 127800.0000, 
sim time next is 128400.0000, 
raw observation next is [32.03333333333333, 38.0, 1.0, 2.0, 0.4751556868436849, 1.0, 2.0, 0.4751556868436849, 1.0, 2.0, 0.7572742349983869, 6.911200000000001, 6.9112, 121.94756008, 1645306.722571222, 1645306.722571222, 331661.9341419013], 
processed observation next is [1.0, 0.4782608695652174, 0.7419753086419753, 0.38, 1.0, 1.0, 0.37518534148057725, 1.0, 1.0, 0.37518534148057725, 1.0, 1.0, 0.6965927937479834, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5876095437754365, 0.5876095437754365, 0.6378114118113487], 
reward next is 0.3622, 
noisyNet noise sample is [array([-1.393069], dtype=float32), 0.6240662]. 
=============================================
[2019-04-27 19:25:31,541] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.7256248e-12 1.0444556e-01 2.9112239e-16 8.3622119e-08 8.9555442e-01], sum to 1.0000
[2019-04-27 19:25:31,550] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4067
[2019-04-27 19:25:31,557] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.0, 31.0, 1.0, 2.0, 0.4266587859730897, 1.0, 2.0, 0.4266587859730897, 1.0, 2.0, 0.6853490127663866, 6.9112, 6.9112, 121.94756008, 1520521.772205415, 1520521.772205415, 308808.5678915906], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 577800.0000, 
sim time next is 578400.0000, 
raw observation next is [32.1, 30.66666666666667, 1.0, 2.0, 0.4190978215966441, 1.0, 2.0, 0.4190978215966441, 1.0, 2.0, 0.6733719394083694, 6.9112, 6.9112, 121.94756008, 1494421.121705372, 1494421.121705372, 305378.7063038677], 
processed observation next is [1.0, 0.6956521739130435, 0.7444444444444445, 0.3066666666666667, 1.0, 1.0, 0.3084497876150525, 1.0, 1.0, 0.3084497876150525, 1.0, 1.0, 0.5917149242604617, 0.0, 0.0, 0.8096049824067558, 0.5337218291804899, 0.5337218291804899, 0.5872667428920533], 
reward next is 0.4127, 
noisyNet noise sample is [array([0.48608845], dtype=float32), 0.4576832]. 
=============================================
[2019-04-27 19:25:37,422] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.3335804e-12 1.4122924e-06 2.9252239e-14 3.4976544e-08 9.9999857e-01], sum to 1.0000
[2019-04-27 19:25:37,431] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9756
[2019-04-27 19:25:37,434] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.0, 28.0, 1.0, 2.0, 0.4418025734883684, 1.0, 2.0, 0.4418025734883684, 1.0, 2.0, 0.7130310386019928, 6.911200000000001, 6.9112, 121.94756008, 1589900.29290329, 1589900.29290329, 315506.533189987], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 482400.0000, 
sim time next is 483000.0000, 
raw observation next is [32.03333333333333, 27.66666666666667, 1.0, 2.0, 0.3855525951652041, 1.0, 2.0, 0.3855525951652041, 1.0, 2.0, 0.6232693433929649, 6.911199999999999, 6.9112, 121.94756008, 1391280.824853298, 1391280.824853299, 290271.224557093], 
processed observation next is [1.0, 0.6086956521739131, 0.7419753086419753, 0.2766666666666667, 1.0, 1.0, 0.26851499424429065, 1.0, 1.0, 0.26851499424429065, 1.0, 1.0, 0.5290866792412061, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.49688600887617784, 0.4968860088761782, 0.5582138933790249], 
reward next is 0.4418, 
noisyNet noise sample is [array([1.1357042], dtype=float32), 0.26100057]. 
=============================================
[2019-04-27 19:25:37,446] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[55.9208  ]
 [55.511597]
 [55.12731 ]
 [54.75853 ]
 [54.385475]], R is [[56.51144791]
 [56.33959198]
 [56.17220306]
 [56.00640488]
 [55.84072876]].
[2019-04-27 19:25:41,341] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.8704036e-10 8.3666074e-01 3.6593245e-10 9.5495532e-05 1.6324385e-01], sum to 1.0000
[2019-04-27 19:25:41,348] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5287
[2019-04-27 19:25:41,355] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.41666666666667, 67.0, 1.0, 2.0, 0.3437864480133992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 437053.6151384575, 437053.6151384575, 121149.2683511697], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 543000.0000, 
sim time next is 543600.0000, 
raw observation next is [21.6, 66.0, 1.0, 2.0, 0.342924859850282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 435823.0405378758, 435823.0405378758, 121035.2900978564], 
processed observation next is [1.0, 0.30434782608695654, 0.3555555555555556, 0.66, 1.0, 1.0, 0.21776769029795476, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1556510859063842, 0.1556510859063842, 0.23276017326510845], 
reward next is 0.7672, 
noisyNet noise sample is [array([-0.25314593], dtype=float32), -0.0013791721]. 
=============================================
[2019-04-27 19:25:42,211] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0590813e-11 5.1851023e-04 3.4164452e-13 8.6070692e-08 9.9948138e-01], sum to 1.0000
[2019-04-27 19:25:42,218] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2340
[2019-04-27 19:25:42,224] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.53333333333333, 32.33333333333334, 1.0, 2.0, 0.4533403882853137, 1.0, 2.0, 0.4533403882853137, 1.0, 2.0, 0.7279050112777736, 6.9112, 6.9112, 121.94756008, 1614100.047842609, 1614100.047842609, 321142.7628463046], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 574800.0000, 
sim time next is 575400.0000, 
raw observation next is [31.61666666666667, 32.16666666666666, 1.0, 2.0, 0.4563566806240788, 1.0, 2.0, 0.4563566806240788, 1.0, 2.0, 0.7325000751224932, 6.9112, 6.9112, 121.94756008, 1623502.058373797, 1623502.058373797, 322571.3156561641], 
processed observation next is [1.0, 0.6521739130434783, 0.7265432098765433, 0.32166666666666655, 1.0, 1.0, 0.3528055721715224, 1.0, 1.0, 0.3528055721715224, 1.0, 1.0, 0.6656250939031163, 0.0, 0.0, 0.8096049824067558, 0.5798221637049275, 0.5798221637049275, 0.6203294531849309], 
reward next is 0.3797, 
noisyNet noise sample is [array([0.60417354], dtype=float32), -1.5585351]. 
=============================================
[2019-04-27 19:25:44,783] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.3406759e-10 9.9961323e-01 7.0507063e-14 2.1707024e-07 3.8655626e-04], sum to 1.0000
[2019-04-27 19:25:44,790] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7610
[2019-04-27 19:25:44,795] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.43333333333333, 67.0, 1.0, 2.0, 0.3235004227071513, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 411387.6961089171, 411387.6961089171, 118522.2574463436], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 625200.0000, 
sim time next is 625800.0000, 
raw observation next is [21.71666666666667, 66.0, 1.0, 2.0, 0.3259983066991414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 414029.3941627031, 414029.3941627031, 118838.3386751046], 
processed observation next is [1.0, 0.21739130434782608, 0.3598765432098766, 0.66, 1.0, 1.0, 0.19761703178469217, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14786764077239395, 0.14786764077239395, 0.22853526668289348], 
reward next is 0.7715, 
noisyNet noise sample is [array([0.43850738], dtype=float32), -3.2058797]. 
=============================================
[2019-04-27 19:25:54,386] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.7915185e-20 1.0000000e+00 1.9153844e-21 5.1128417e-16 2.5213949e-15], sum to 1.0000
[2019-04-27 19:25:54,392] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1812
[2019-04-27 19:25:54,397] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 58.0, 1.0, 2.0, 0.3140743296346765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 398914.7459901513, 398914.7459901508, 117322.8927520336], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 799200.0000, 
sim time next is 799800.0000, 
raw observation next is [23.06666666666667, 58.16666666666667, 1.0, 2.0, 0.3172864357530921, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 402656.7213380275, 402656.7213380279, 117726.1771874299], 
processed observation next is [0.0, 0.2608695652173913, 0.40987654320987665, 0.5816666666666667, 1.0, 1.0, 0.1872457568489192, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1438059719064384, 0.14380597190643854, 0.22639649459121136], 
reward next is 0.7736, 
noisyNet noise sample is [array([-2.324911], dtype=float32), -0.8098418]. 
=============================================
[2019-04-27 19:25:55,173] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.5663155e-20 1.0000000e+00 7.8399647e-23 9.2902478e-16 6.5195972e-16], sum to 1.0000
[2019-04-27 19:25:55,183] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9012
[2019-04-27 19:25:55,188] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.16666666666667, 37.66666666666667, 1.0, 2.0, 0.4368096879782565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 532386.3438004741, 532386.3438004741, 133695.6496449537], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 821400.0000, 
sim time next is 822000.0000, 
raw observation next is [31.33333333333334, 37.33333333333334, 1.0, 2.0, 0.438642078807367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 534146.7608772811, 534146.7608772811, 133951.1530605483], 
processed observation next is [0.0, 0.5217391304347826, 0.7160493827160496, 0.3733333333333334, 1.0, 1.0, 0.33171676048496074, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19076670031331466, 0.19076670031331466, 0.2575983712702852], 
reward next is 0.7424, 
noisyNet noise sample is [array([0.38987586], dtype=float32), 1.2360697]. 
=============================================
[2019-04-27 19:25:55,204] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[84.269844]
 [84.17804 ]
 [84.02715 ]
 [83.91967 ]
 [83.83073 ]], R is [[84.25579834]
 [84.15612793]
 [84.0577774 ]
 [83.96056366]
 [83.86447906]].
[2019-04-27 19:26:04,195] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-04-27 19:26:04,197] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 19:26:04,198] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 19:26:04,199] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:26:04,199] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 19:26:04,199] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:26:04,201] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 19:26:04,200] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 19:26:04,202] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:26:04,204] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:26:04,201] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:26:04,222] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run36
[2019-04-27 19:26:04,223] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run36
[2019-04-27 19:26:04,260] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run36
[2019-04-27 19:26:04,261] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run36
[2019-04-27 19:26:04,300] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run36
[2019-04-27 19:27:03,574] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.05534732]
[2019-04-27 19:27:03,575] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [19.91666666666666, 99.16666666666666, 1.0, 2.0, 0.4199587683133157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 516648.7524605885, 516648.7524605885, 131377.416605304]
[2019-04-27 19:27:03,577] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 19:27:03,581] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0277323e-16 1.0000000e+00 1.4934581e-19 1.5459395e-13 2.5022771e-13], sampled 0.365654818707145
[2019-04-27 19:27:09,202] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.05534732]
[2019-04-27 19:27:09,205] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.0, 94.0, 1.0, 2.0, 0.6000171064649585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 692524.2615863256, 692524.2615863256, 158504.0664181812]
[2019-04-27 19:27:09,209] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 19:27:09,214] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.2302269e-17 1.0000000e+00 1.0703680e-19 1.0934412e-13 1.5582963e-13], sampled 0.563134343799606
[2019-04-27 19:27:17,944] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.05534732]
[2019-04-27 19:27:17,945] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.86666666666667, 90.0, 1.0, 2.0, 0.6277761451416136, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 719901.7097885847, 719901.7097885847, 163142.3549948393]
[2019-04-27 19:27:17,946] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 19:27:17,948] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.6654007e-17 1.0000000e+00 4.9771800e-20 5.9982184e-14 8.2617127e-14], sampled 0.1411192969640308
[2019-04-27 19:27:24,011] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.05534732]
[2019-04-27 19:27:24,013] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.23613688, 92.16713509, 1.0, 2.0, 0.7265964218465734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 881388.0808363477, 881388.0808363477, 183555.4214744117]
[2019-04-27 19:27:24,013] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 19:27:24,016] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0215404e-17 1.0000000e+00 1.3864431e-20 1.0251294e-14 1.9995022e-14], sampled 0.8800405134579992
[2019-04-27 19:27:43,671] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.05534732]
[2019-04-27 19:27:43,672] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.75, 65.33333333333333, 1.0, 2.0, 0.4346377599416013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 532776.0371350225, 532776.0371350225, 133462.5311352791]
[2019-04-27 19:27:43,673] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 19:27:43,675] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.6369191e-17 1.0000000e+00 2.1688270e-20 2.8502852e-14 3.0105645e-14], sampled 0.30962889164319995
[2019-04-27 19:27:56,978] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8579.6319 2248999596.6174 554.0000
[2019-04-27 19:27:57,105] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8767.7488 2170912002.3198 493.0000
[2019-04-27 19:27:57,175] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8922.0975 2120787404.9354 431.0000
[2019-04-27 19:27:57,198] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8096.7502 2445580780.6245 746.0000
[2019-04-27 19:27:57,219] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-04-27 19:27:58,234] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 875000, evaluation results [875000.0, 8096.75022514935, 2445580780.624495, 746.0, 8767.748750989802, 2170912002.319754, 493.0, 8922.097482657417, 2120787404.9354012, 431.0, 8579.631864032022, 2248999596.617444, 554.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-04-27 19:28:02,071] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2301912e-13 1.0000000e+00 1.2690902e-15 4.6904880e-10 4.5881756e-09], sum to 1.0000
[2019-04-27 19:28:02,078] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5405
[2019-04-27 19:28:02,083] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.9, 83.33333333333334, 1.0, 2.0, 0.5622896941642285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 709004.7268373884, 709004.7268373884, 154049.5999588493], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1240800.0000, 
sim time next is 1241400.0000, 
raw observation next is [20.1, 82.16666666666666, 1.0, 2.0, 0.5733634231095477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 722500.347279186, 722500.3472791855, 155939.0419660298], 
processed observation next is [1.0, 0.34782608695652173, 0.30000000000000004, 0.8216666666666665, 1.0, 1.0, 0.492099313225652, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.258035838313995, 0.25803583831399485, 0.29988277301159577], 
reward next is 0.7001, 
noisyNet noise sample is [array([0.6093825], dtype=float32), -0.07156974]. 
=============================================
[2019-04-27 19:28:03,071] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.0077446e-09 9.8343694e-01 3.0440600e-12 1.7098029e-05 1.6545948e-02], sum to 1.0000
[2019-04-27 19:28:03,078] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9302
[2019-04-27 19:28:03,083] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.2, 47.0, 1.0, 2.0, 0.7046918087407686, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 892584.961168791, 892584.9611687906, 180142.8683199326], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1080000.0000, 
sim time next is 1080600.0000, 
raw observation next is [25.33333333333333, 46.33333333333334, 1.0, 2.0, 0.8275573808543658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1047983.722436666, 1047983.722436666, 205528.0925790938], 
processed observation next is [1.0, 0.5217391304347826, 0.49382716049382697, 0.46333333333333343, 1.0, 1.0, 0.7947111676837688, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3742799008702379, 0.3742799008702379, 0.39524633188287267], 
reward next is 0.6048, 
noisyNet noise sample is [array([-0.92423254], dtype=float32), -0.3933836]. 
=============================================
[2019-04-27 19:28:05,175] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.1346943e-14 9.9999928e-01 2.1630225e-15 6.7745063e-09 7.5317428e-07], sum to 1.0000
[2019-04-27 19:28:05,181] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5497
[2019-04-27 19:28:05,186] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.3, 75.0, 1.0, 2.0, 0.2892488898256245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 371049.9269674128, 371049.9269674128, 114257.2517508903], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1119600.0000, 
sim time next is 1120200.0000, 
raw observation next is [19.28333333333333, 75.0, 1.0, 2.0, 0.2867344858935714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 367928.1274377487, 367928.1274377482, 113951.6446843914], 
processed observation next is [1.0, 1.0, 0.26975308641975304, 0.75, 1.0, 1.0, 0.15087438796853742, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13140290265633883, 0.13140290265633864, 0.21913777823921424], 
reward next is 0.7809, 
noisyNet noise sample is [array([0.18099947], dtype=float32), -0.7980911]. 
=============================================
[2019-04-27 19:28:07,920] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.2158864e-13 9.9999917e-01 2.6505530e-16 2.2667363e-08 7.7869828e-07], sum to 1.0000
[2019-04-27 19:28:07,928] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7999
[2019-04-27 19:28:07,932] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 65.0, 1.0, 2.0, 0.6740946622461158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 852144.4847909213, 852144.4847909213, 174220.6134524814], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1173600.0000, 
sim time next is 1174200.0000, 
raw observation next is [22.15, 65.5, 1.0, 2.0, 0.7439259653175881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 939913.8118372267, 939913.8118372267, 187929.7119485997], 
processed observation next is [1.0, 0.6086956521739131, 0.3759259259259259, 0.655, 1.0, 1.0, 0.6951499587114145, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.335683504227581, 0.335683504227581, 0.3614032922088456], 
reward next is 0.6386, 
noisyNet noise sample is [array([0.01991527], dtype=float32), -0.602014]. 
=============================================
[2019-04-27 19:28:10,441] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.7337585e-14 1.0000000e+00 3.7581965e-17 1.9989801e-10 3.1058907e-08], sum to 1.0000
[2019-04-27 19:28:10,443] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5928
[2019-04-27 19:28:10,448] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.03333333333333, 93.0, 1.0, 2.0, 0.3201543230683296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 407124.4579192356, 407124.4579192356, 118095.6602617229], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1219200.0000, 
sim time next is 1219800.0000, 
raw observation next is [18.01666666666667, 93.0, 1.0, 2.0, 0.3187481317550348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 405412.9230549557, 405412.9230549553, 117917.519327507], 
processed observation next is [1.0, 0.08695652173913043, 0.2228395061728396, 0.93, 1.0, 1.0, 0.1889858711369462, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14479032966248417, 0.14479032966248404, 0.22676446024520577], 
reward next is 0.7732, 
noisyNet noise sample is [array([0.7023418], dtype=float32), 0.9214445]. 
=============================================
[2019-04-27 19:28:19,519] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.9712339e-17 1.0000000e+00 1.1094967e-19 2.4001179e-13 6.2619153e-11], sum to 1.0000
[2019-04-27 19:28:19,537] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3331
[2019-04-27 19:28:19,541] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.18333333333334, 67.0, 1.0, 2.0, 0.31087256059901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 396080.9093634709, 396080.9093634709, 116927.1945497177], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1389000.0000, 
sim time next is 1389600.0000, 
raw observation next is [21.1, 67.0, 1.0, 2.0, 0.3079309893698134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 392643.1958353252, 392643.1958353252, 116560.0424598762], 
processed observation next is [0.0, 0.08695652173913043, 0.3370370370370371, 0.67, 1.0, 1.0, 0.17610832067834928, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14022971279833044, 0.14022971279833044, 0.22415392780745425], 
reward next is 0.7758, 
noisyNet noise sample is [array([0.37721637], dtype=float32), -1.2758758]. 
=============================================
[2019-04-27 19:28:25,377] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4789001e-18 1.0000000e+00 4.4659574e-21 1.9164374e-13 1.7442192e-11], sum to 1.0000
[2019-04-27 19:28:25,387] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3003
[2019-04-27 19:28:25,391] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.93333333333334, 71.0, 1.0, 2.0, 0.3591392910892195, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 451423.1299883565, 451423.129988356, 123131.8898022294], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1488000.0000, 
sim time next is 1488600.0000, 
raw observation next is [22.25, 69.5, 1.0, 2.0, 0.361570629305992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 453988.197053726, 453988.197053726, 123450.7006334623], 
processed observation next is [0.0, 0.21739130434782608, 0.37962962962962965, 0.695, 1.0, 1.0, 0.2399650348880857, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16213864180490214, 0.16213864180490214, 0.23740519352588904], 
reward next is 0.7626, 
noisyNet noise sample is [array([0.7867315], dtype=float32), -0.8377343]. 
=============================================
[2019-04-27 19:28:28,339] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2862269e-12 9.9998724e-01 3.9957377e-18 1.9663053e-10 1.2721669e-05], sum to 1.0000
[2019-04-27 19:28:28,348] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6419
[2019-04-27 19:28:28,352] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.7, 84.0, 1.0, 2.0, 0.3981871566105256, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 496886.3524487737, 496886.3524487732, 128436.83847891], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1738800.0000, 
sim time next is 1739400.0000, 
raw observation next is [20.61666666666667, 84.5, 1.0, 2.0, 0.4043323853494606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 504681.9895320423, 504681.9895320428, 129307.4854966442], 
processed observation next is [1.0, 0.13043478260869565, 0.319135802469136, 0.845, 1.0, 1.0, 0.29087188732078645, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1802435676900151, 0.1802435676900153, 0.2486682413397004], 
reward next is 0.7513, 
noisyNet noise sample is [array([-0.5174904], dtype=float32), 1.2739506]. 
=============================================
[2019-04-27 19:28:29,171] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.6535211e-12 9.9999821e-01 3.2573147e-14 1.6557257e-09 1.8472762e-06], sum to 1.0000
[2019-04-27 19:28:29,181] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4530
[2019-04-27 19:28:29,186] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 71.5, 1.0, 2.0, 0.3737509993278358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 470882.4814856182, 470882.4814856182, 125123.0434192982], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1578600.0000, 
sim time next is 1579200.0000, 
raw observation next is [21.8, 70.0, 1.0, 2.0, 0.3967305046824257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 499926.8813498668, 499926.8813498663, 128309.8927267384], 
processed observation next is [1.0, 0.2608695652173913, 0.362962962962963, 0.7, 1.0, 1.0, 0.28182202938384016, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17854531476780958, 0.17854531476780938, 0.24674979370526615], 
reward next is 0.7533, 
noisyNet noise sample is [array([-0.2030282], dtype=float32), -0.8103831]. 
=============================================
[2019-04-27 19:28:30,509] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.3407254e-11 8.4560700e-03 1.2358352e-12 1.1138176e-07 9.9154377e-01], sum to 1.0000
[2019-04-27 19:28:30,514] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6424
[2019-04-27 19:28:30,516] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.53333333333333, 56.66666666666667, 1.0, 2.0, 0.3230914222865602, 1.0, 2.0, 0.3230914222865602, 1.0, 2.0, 0.527159678993224, 6.911199999999999, 6.9112, 121.94756008, 1181304.242856679, 1181304.242856679, 263888.2715090933], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1588800.0000, 
sim time next is 1589400.0000, 
raw observation next is [24.65, 56.5, 1.0, 2.0, 0.3268721670509904, 1.0, 2.0, 0.3268721670509904, 1.0, 2.0, 0.5326482019456653, 6.9112, 6.9112, 121.94756008, 1193227.430540817, 1193227.430540817, 265465.031616473], 
processed observation next is [1.0, 0.391304347826087, 0.46851851851851845, 0.565, 1.0, 1.0, 0.19865734172736957, 1.0, 1.0, 0.19865734172736957, 1.0, 1.0, 0.4158102524320816, 0.0, 0.0, 0.8096049824067558, 0.42615265376457756, 0.42615265376457756, 0.510509676185525], 
reward next is 0.4895, 
noisyNet noise sample is [array([-1.511034], dtype=float32), -0.6660255]. 
=============================================
[2019-04-27 19:28:32,374] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.5210656e-13 1.0000000e+00 8.0665743e-18 3.5582221e-10 4.4081514e-08], sum to 1.0000
[2019-04-27 19:28:32,381] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1375
[2019-04-27 19:28:32,391] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.61666666666667, 45.66666666666667, 1.0, 2.0, 0.3541840133260504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 444261.5706635293, 444261.5706635293, 122455.9656789247], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1623000.0000, 
sim time next is 1623600.0000, 
raw observation next is [26.5, 46.0, 1.0, 2.0, 0.3535867119212586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 443710.7050359103, 443710.7050359098, 122379.685633187], 
processed observation next is [1.0, 0.8260869565217391, 0.5370370370370371, 0.46, 1.0, 1.0, 0.2304603713348317, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15846810894139654, 0.15846810894139635, 0.23534554929459037], 
reward next is 0.7647, 
noisyNet noise sample is [array([-0.03431008], dtype=float32), -0.6190446]. 
=============================================
[2019-04-27 19:28:33,331] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.4000574e-14 1.0000000e+00 8.1095612e-16 2.2205415e-10 7.7844708e-09], sum to 1.0000
[2019-04-27 19:28:33,331] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2628
[2019-04-27 19:28:33,338] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.4, 73.0, 1.0, 2.0, 0.3446703294715084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 438739.3250672903, 438739.3250672903, 121268.5974649417], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1652400.0000, 
sim time next is 1653000.0000, 
raw observation next is [20.2, 74.33333333333334, 1.0, 2.0, 0.4039888592097677, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 514337.7476434408, 514337.7476434404, 129384.4393694916], 
processed observation next is [1.0, 0.13043478260869565, 0.3037037037037037, 0.7433333333333334, 1.0, 1.0, 0.2904629276306758, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18369205272980027, 0.18369205272980013, 0.24881622955671462], 
reward next is 0.7512, 
noisyNet noise sample is [array([-0.29545096], dtype=float32), -0.47338104]. 
=============================================
[2019-04-27 19:28:33,351] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[63.186348]
 [63.262684]
 [63.33983 ]
 [63.586674]
 [63.802822]], R is [[63.12355423]
 [63.25911331]
 [63.3927803 ]
 [63.52288437]
 [63.64921188]].
[2019-04-27 19:28:34,286] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.0060477e-16 1.0000000e+00 4.5612278e-18 9.0570178e-13 7.6446449e-09], sum to 1.0000
[2019-04-27 19:28:34,292] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7185
[2019-04-27 19:28:34,298] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.03333333333333, 90.83333333333334, 1.0, 2.0, 0.4231051435618878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 519320.3118002451, 519320.3118002447, 131800.7473331259], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1885800.0000, 
sim time next is 1886400.0000, 
raw observation next is [21.0, 91.0, 1.0, 2.0, 0.4225686768681743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 518762.935848996, 518762.935848996, 131725.8206348477], 
processed observation next is [1.0, 0.8695652173913043, 0.3333333333333333, 0.91, 1.0, 1.0, 0.312581758176398, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18527247708892713, 0.18527247708892713, 0.2533188858362456], 
reward next is 0.7467, 
noisyNet noise sample is [array([-0.6155665], dtype=float32), -0.11706341]. 
=============================================
[2019-04-27 19:28:40,163] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.8340301e-11 6.2378400e-05 1.4978353e-15 8.0851610e-09 9.9993765e-01], sum to 1.0000
[2019-04-27 19:28:40,169] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2885
[2019-04-27 19:28:40,173] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.2, 66.33333333333334, 1.0, 2.0, 0.3160888116164898, 1.0, 2.0, 0.3160888116164898, 1.0, 2.0, 0.5059266876908299, 6.911200000000001, 6.9112, 121.94756008, 1115338.481271731, 1115338.48127173, 262180.7202776892], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1772400.0000, 
sim time next is 1773000.0000, 
raw observation next is [25.25, 66.0, 1.0, 2.0, 0.2920976714198048, 1.0, 2.0, 0.2920976714198048, 1.0, 2.0, 0.4681759590762075, 6.9112, 6.9112, 121.94756008, 1034863.170467129, 1034863.170467129, 252865.5635115661], 
processed observation next is [1.0, 0.5217391304347826, 0.49074074074074076, 0.66, 1.0, 1.0, 0.15725913264262478, 1.0, 1.0, 0.15725913264262478, 1.0, 1.0, 0.33521994884525935, 0.0, 0.0, 0.8096049824067558, 0.36959398945254607, 0.36959398945254607, 0.48627992982993484], 
reward next is 0.5137, 
noisyNet noise sample is [array([-0.48340875], dtype=float32), 1.438886]. 
=============================================
[2019-04-27 19:28:40,185] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[65.73951 ]
 [65.080605]
 [64.94298 ]
 [64.55294 ]
 [64.365685]], R is [[65.88314056]
 [65.72011566]
 [65.49369812]
 [65.30298615]
 [65.1109848 ]].
[2019-04-27 19:28:40,544] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.6418126e-13 9.9999988e-01 3.3282712e-16 8.7271357e-11 1.7667497e-07], sum to 1.0000
[2019-04-27 19:28:40,554] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6359
[2019-04-27 19:28:40,561] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.35, 85.5, 1.0, 2.0, 0.2991671463905156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 382627.7960521247, 382627.7960521247, 115474.1115160139], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1801800.0000, 
sim time next is 1802400.0000, 
raw observation next is [18.36666666666667, 85.66666666666666, 1.0, 2.0, 0.29893192994622, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 382194.828453599, 382194.8284535985, 115445.0034690849], 
processed observation next is [1.0, 0.8695652173913043, 0.2358024691358026, 0.8566666666666666, 1.0, 1.0, 0.16539515469788094, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1364981530191425, 0.1364981530191423, 0.2220096220559325], 
reward next is 0.7780, 
noisyNet noise sample is [array([-1.6230414], dtype=float32), 1.8173584]. 
=============================================
[2019-04-27 19:28:42,893] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.9128794e-14 1.0000000e+00 3.8776465e-15 2.0584093e-11 6.6322245e-09], sum to 1.0000
[2019-04-27 19:28:42,900] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7221
[2019-04-27 19:28:42,905] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 77.0, 1.0, 2.0, 0.6304784178293111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 786737.9349976546, 786737.9349976542, 165931.385654004], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1846800.0000, 
sim time next is 1847400.0000, 
raw observation next is [21.63333333333334, 77.0, 1.0, 2.0, 0.7066689076920537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 881283.7390133124, 881283.7390133124, 180309.9592153153], 
processed observation next is [1.0, 0.391304347826087, 0.35679012345679034, 0.77, 1.0, 1.0, 0.6507963186810163, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31474419250475444, 0.31474419250475444, 0.346749921567914], 
reward next is 0.6533, 
noisyNet noise sample is [array([-0.31505373], dtype=float32), 3.0735996]. 
=============================================
[2019-04-27 19:28:47,829] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-04-27 19:28:47,830] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 19:28:47,831] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:28:47,834] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 19:28:47,835] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 19:28:47,836] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:28:47,836] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:28:47,837] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 19:28:47,838] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 19:28:47,838] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:28:47,838] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:28:47,860] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run37
[2019-04-27 19:28:47,861] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run37
[2019-04-27 19:28:47,906] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run37
[2019-04-27 19:28:47,927] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run37
[2019-04-27 19:28:47,928] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run37
[2019-04-27 19:29:21,113] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.059760127]
[2019-04-27 19:29:21,114] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.0, 62.0, 1.0, 2.0, 0.5345707475192075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 628713.4579058837, 628713.4579058837, 148083.1756954062]
[2019-04-27 19:29:21,118] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 19:29:21,120] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.5659020e-16 1.0000000e+00 6.1998097e-18 3.0095455e-12 1.8337325e-08], sampled 0.19229645729879674
[2019-04-27 19:29:56,935] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.059760127]
[2019-04-27 19:29:56,936] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.36666666666667, 91.00000000000001, 1.0, 2.0, 0.4228338969105412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 516222.3528751186, 516222.3528751181, 131685.2908464549]
[2019-04-27 19:29:56,939] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 19:29:56,943] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.1056964e-15 1.0000000e+00 7.4114589e-18 3.5482357e-12 2.0057346e-08], sampled 0.6200159051859235
[2019-04-27 19:29:59,663] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.059760127]
[2019-04-27 19:29:59,663] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.5, 86.5, 1.0, 2.0, 0.6881858257256694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 784330.2718419184, 784330.2718419184, 173919.5616812159]
[2019-04-27 19:29:59,664] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 19:29:59,667] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.6952419e-17 1.0000000e+00 4.4043113e-19 3.0576488e-13 3.0458855e-09], sampled 0.8206200662547234
[2019-04-27 19:30:40,037] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8806.7201 2174851273.7309 427.0000
[2019-04-27 19:30:40,437] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8949.0951 2126494881.4775 368.0000
[2019-04-27 19:30:40,469] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8646.2948 2253074084.2950 417.0000
[2019-04-27 19:30:40,620] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8744.9472 2201950350.7681 468.0000
[2019-04-27 19:30:40,802] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8187.3306 2454137154.6361 509.0000
[2019-04-27 19:30:41,817] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 900000, evaluation results [900000.0, 8187.330633745936, 2454137154.6360693, 509.0, 8806.720108170324, 2174851273.7309356, 427.0, 8949.095139799254, 2126494881.4774592, 368.0, 8646.294824644834, 2253074084.2949934, 417.0, 8744.947180277703, 2201950350.768097, 468.0]
[2019-04-27 19:30:52,996] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.4752622e-14 1.0000000e+00 1.1018852e-16 6.3521058e-13 2.2823585e-10], sum to 1.0000
[2019-04-27 19:30:53,006] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3759
[2019-04-27 19:30:53,012] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 96.0, 1.0, 2.0, 0.477271231485558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 574555.7368010028, 574555.7368010032, 139557.1245956047], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2350800.0000, 
sim time next is 2351400.0000, 
raw observation next is [21.91666666666667, 92.5, 1.0, 2.0, 0.4944999073907056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 596162.9489348423, 596162.9489348418, 142257.6005006791], 
processed observation next is [1.0, 0.21739130434782608, 0.36728395061728414, 0.925, 1.0, 1.0, 0.39821417546512566, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21291533890530082, 0.21291533890530065, 0.27357230865515214], 
reward next is 0.7264, 
noisyNet noise sample is [array([-0.6190455], dtype=float32), -0.22487845]. 
=============================================
[2019-04-27 19:30:56,573] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.8478808e-12 1.0000000e+00 1.6748399e-13 1.1717394e-11 1.7929520e-09], sum to 1.0000
[2019-04-27 19:30:56,581] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6431
[2019-04-27 19:30:56,587] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1575159.25558219 W.
[2019-04-27 19:30:56,591] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.46666666666667, 88.33333333333334, 1.0, 2.0, 0.6906805649561636, 1.0, 2.0, 0.6906805649561636, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1575159.25558219, 1575159.25558219, 300651.8498024722], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2203800.0000, 
sim time next is 2204400.0000, 
raw observation next is [25.63333333333334, 87.66666666666667, 1.0, 2.0, 0.5240774972189808, 1.0, 2.0, 0.5240774972189808, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1194909.557302606, 1194909.557302606, 242929.2547976485], 
processed observation next is [1.0, 0.5217391304347826, 0.5049382716049385, 0.8766666666666667, 1.0, 1.0, 0.4334255919273581, 1.0, 1.0, 0.4334255919273581, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.42675341332235933, 0.42675341332235933, 0.46717164384163173], 
reward next is 0.5328, 
noisyNet noise sample is [array([-1.6879885], dtype=float32), 0.35728273]. 
=============================================
[2019-04-27 19:30:58,831] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1766267e-14 1.0000000e+00 2.7009747e-18 1.7094887e-14 1.6574585e-11], sum to 1.0000
[2019-04-27 19:30:58,841] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9986
[2019-04-27 19:30:58,847] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.45, 97.16666666666667, 1.0, 2.0, 0.4737710784912329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 570004.9978336083, 570004.9978336083, 139009.1746083504], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2260200.0000, 
sim time next is 2260800.0000, 
raw observation next is [21.3, 97.0, 1.0, 2.0, 0.4657562188611777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 562026.5994681667, 562026.5994681662, 137845.1633368017], 
processed observation next is [1.0, 0.17391304347826086, 0.3444444444444445, 0.97, 1.0, 1.0, 0.3639954986442591, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20072378552434525, 0.20072378552434508, 0.26508685257077247], 
reward next is 0.7349, 
noisyNet noise sample is [array([-1.3721983], dtype=float32), -0.5264772]. 
=============================================
[2019-04-27 19:31:00,376] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.0535346e-15 1.0000000e+00 1.7588740e-16 1.5430989e-14 1.1671729e-12], sum to 1.0000
[2019-04-27 19:31:00,383] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9274
[2019-04-27 19:31:00,390] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.4, 96.5, 1.0, 2.0, 0.4329399947933361, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 531142.2359017992, 531142.2359017987, 133225.8139168049], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2273400.0000, 
sim time next is 2274000.0000, 
raw observation next is [20.4, 96.66666666666666, 1.0, 2.0, 0.455937315283809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 559182.8290031264, 559182.8290031264, 136635.5027017118], 
processed observation next is [1.0, 0.30434782608695654, 0.31111111111111106, 0.9666666666666666, 1.0, 1.0, 0.3523063277188202, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19970815321540228, 0.19970815321540228, 0.2627605821186766], 
reward next is 0.7372, 
noisyNet noise sample is [array([-0.44811937], dtype=float32), 0.6568477]. 
=============================================
[2019-04-27 19:31:00,415] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[61.078087]
 [61.173996]
 [61.260654]
 [61.52672 ]
 [61.630787]], R is [[61.00084686]
 [61.13463593]
 [61.26591873]
 [61.38680267]
 [61.5199852 ]].
[2019-04-27 19:31:03,167] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.3336965e-18 1.0000000e+00 1.4185639e-20 1.3034544e-16 4.7478031e-15], sum to 1.0000
[2019-04-27 19:31:03,175] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9314
[2019-04-27 19:31:03,182] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 78.0, 1.0, 2.0, 0.476071991017273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 573856.5663192391, 573856.5663192391, 139398.1277685298], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2320200.0000, 
sim time next is 2320800.0000, 
raw observation next is [23.76666666666667, 78.66666666666666, 1.0, 2.0, 0.475465116135028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 573461.9685937813, 573461.9685937813, 139316.2934398247], 
processed observation next is [1.0, 0.8695652173913043, 0.43580246913580256, 0.7866666666666666, 1.0, 1.0, 0.3755537096845572, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20480784592635048, 0.20480784592635048, 0.2679159489227398], 
reward next is 0.7321, 
noisyNet noise sample is [array([0.20943142], dtype=float32), -0.2557486]. 
=============================================
[2019-04-27 19:31:04,723] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3524394e-16 1.0000000e+00 1.5567594e-18 1.4723847e-14 3.2093597e-14], sum to 1.0000
[2019-04-27 19:31:04,729] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9871
[2019-04-27 19:31:04,735] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.81666666666667, 54.5, 1.0, 2.0, 0.5208341443517752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 645774.6519207073, 645774.6519207073, 146950.1042005771], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2358600.0000, 
sim time next is 2359200.0000, 
raw observation next is [26.13333333333334, 52.00000000000001, 1.0, 2.0, 0.4326295783340272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 537490.3124129922, 537490.3124129922, 133342.1547014512], 
processed observation next is [1.0, 0.30434782608695654, 0.523456790123457, 0.52, 1.0, 1.0, 0.3245590218262229, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19196082586178295, 0.19196082586178295, 0.25642722057971384], 
reward next is 0.7436, 
noisyNet noise sample is [array([0.15781079], dtype=float32), 1.310559]. 
=============================================
[2019-04-27 19:31:07,561] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.0260958e-15 9.9999881e-01 9.3284392e-18 2.5581936e-11 1.1476122e-06], sum to 1.0000
[2019-04-27 19:31:07,568] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4397
[2019-04-27 19:31:07,570] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.53333333333333, 63.00000000000001, 1.0, 2.0, 0.3373014606054798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 426636.2744526397, 426636.2744526397, 120282.8062576669], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2420400.0000, 
sim time next is 2421000.0000, 
raw observation next is [22.4, 63.0, 1.0, 2.0, 0.3326110680575716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 421277.0515240226, 421277.0515240231, 119680.0266302358], 
processed observation next is [1.0, 0.0, 0.38518518518518513, 0.63, 1.0, 1.0, 0.20548936673520432, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15045608983000808, 0.15045608983000824, 0.23015389736583808], 
reward next is 0.7698, 
noisyNet noise sample is [array([1.0359895], dtype=float32), 1.4754665]. 
=============================================
[2019-04-27 19:31:07,578] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[70.08714 ]
 [70.594696]
 [71.46703 ]
 [73.00879 ]
 [73.008804]], R is [[69.64704132]
 [69.71925354]
 [69.78978729]
 [69.85852051]
 [69.92511749]].
[2019-04-27 19:31:09,393] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.7539022e-14 3.7323061e-05 8.1108985e-16 7.1843170e-10 9.9996269e-01], sum to 1.0000
[2019-04-27 19:31:09,402] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1988
[2019-04-27 19:31:09,406] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.4, 29.0, 1.0, 2.0, 0.3505290509781956, 1.0, 2.0, 0.3505290509781956, 1.0, 2.0, 0.5696368341368186, 6.911200000000001, 6.9112, 121.94756008, 1274998.966388962, 1274998.966388962, 275206.2749895181], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2455200.0000, 
sim time next is 2455800.0000, 
raw observation next is [31.65, 28.16666666666667, 1.0, 2.0, 0.3640115955338564, 1.0, 2.0, 0.3640115955338564, 1.0, 2.0, 0.591423285914248, 6.911200000000001, 6.9112, 121.94756008, 1323695.479715483, 1323695.479715483, 280819.7316663153], 
processed observation next is [1.0, 0.43478260869565216, 0.7277777777777777, 0.28166666666666673, 1.0, 1.0, 0.2428709470641148, 1.0, 1.0, 0.2428709470641148, 1.0, 1.0, 0.48927910739280994, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.4727483856126725, 0.4727483856126725, 0.5400379455121448], 
reward next is 0.4600, 
noisyNet noise sample is [array([0.44797888], dtype=float32), 1.8894472]. 
=============================================
[2019-04-27 19:31:09,692] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.9080338e-13 2.0578609e-06 8.2032287e-16 2.6401322e-11 9.9999797e-01], sum to 1.0000
[2019-04-27 19:31:09,701] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9267
[2019-04-27 19:31:09,706] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.65, 28.16666666666667, 1.0, 2.0, 0.364011595481618, 1.0, 2.0, 0.364011595481618, 1.0, 2.0, 0.5914232858900015, 6.911200000000001, 6.9112, 121.94756008, 1323695.479715483, 1323695.479715483, 280819.7316384185], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2455800.0000, 
sim time next is 2456400.0000, 
raw observation next is [31.9, 27.33333333333334, 1.0, 2.0, 0.3610495351696821, 1.0, 2.0, 0.3610495351696821, 1.0, 2.0, 0.5865732782200413, 6.9112, 6.9112, 121.94756008, 1312797.460866861, 1312797.460866861, 279584.1542239921], 
processed observation next is [1.0, 0.43478260869565216, 0.7370370370370369, 0.2733333333333334, 1.0, 1.0, 0.239344684725812, 1.0, 1.0, 0.239344684725812, 1.0, 1.0, 0.48321659777505166, 0.0, 0.0, 0.8096049824067558, 0.46885623602387894, 0.46885623602387894, 0.5376618350461386], 
reward next is 0.4623, 
noisyNet noise sample is [array([-0.42304927], dtype=float32), 0.59733355]. 
=============================================
[2019-04-27 19:31:11,388] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.1253385e-15 1.0000000e+00 9.6361702e-19 6.6920827e-14 2.0176876e-11], sum to 1.0000
[2019-04-27 19:31:11,400] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0735
[2019-04-27 19:31:11,405] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.18333333333333, 30.33333333333333, 1.0, 2.0, 0.3774510500875756, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 471109.4373869399, 471109.4373869399, 125558.4746779566], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2488200.0000, 
sim time next is 2488800.0000, 
raw observation next is [30.96666666666667, 30.66666666666667, 1.0, 2.0, 0.3676688287310182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 459376.6091422516, 459376.6091422511, 124235.0838586066], 
processed observation next is [1.0, 0.8260869565217391, 0.7024691358024692, 0.3066666666666667, 1.0, 1.0, 0.247224796108355, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1640630746936613, 0.1640630746936611, 0.2389136228050127], 
reward next is 0.7611, 
noisyNet noise sample is [array([-0.4499874], dtype=float32), 0.15614183]. 
=============================================
[2019-04-27 19:31:11,607] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.1606412e-17 1.0000000e+00 5.3643160e-20 2.2370140e-14 1.9368784e-11], sum to 1.0000
[2019-04-27 19:31:11,610] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3626
[2019-04-27 19:31:11,617] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.03333333333333, 84.66666666666667, 1.0, 2.0, 0.4036481447708115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 500493.2848324688, 500493.2848324693, 129142.0752542292], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2699400.0000, 
sim time next is 2700000.0000, 
raw observation next is [21.0, 83.0, 1.0, 2.0, 0.3929639115003881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 488877.1281617631, 488877.1281617631, 127674.5992172964], 
processed observation next is [0.0, 0.2608695652173913, 0.3333333333333333, 0.83, 1.0, 1.0, 0.27733798988141445, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1745989743434868, 0.1745989743434868, 0.2455280754178777], 
reward next is 0.7545, 
noisyNet noise sample is [array([-1.1038743], dtype=float32), 0.40483847]. 
=============================================
[2019-04-27 19:31:11,642] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[71.618286]
 [71.67814 ]
 [71.74189 ]
 [71.80516 ]
 [71.85381 ]], R is [[71.61777496]
 [71.65324402]
 [71.68540192]
 [71.71416473]
 [71.73960876]].
[2019-04-27 19:31:11,842] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.4858439e-17 1.0000000e+00 2.0536783e-20 3.4744831e-14 1.2843397e-10], sum to 1.0000
[2019-04-27 19:31:11,849] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3418
[2019-04-27 19:31:11,855] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.6, 39.0, 1.0, 2.0, 0.3701512428846956, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 462600.5349625243, 462600.5349625243, 124573.8984299724], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2496600.0000, 
sim time next is 2497200.0000, 
raw observation next is [28.43333333333334, 39.66666666666666, 1.0, 2.0, 0.3697827605569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 462118.4389293519, 462118.4389293519, 124523.4841514573], 
processed observation next is [1.0, 0.9130434782608695, 0.6086419753086423, 0.39666666666666656, 1.0, 1.0, 0.24974138161535717, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16504229961762568, 0.16504229961762568, 0.23946823875280251], 
reward next is 0.7605, 
noisyNet noise sample is [array([-1.7932225], dtype=float32), 0.4184544]. 
=============================================
[2019-04-27 19:31:16,189] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.3614620e-20 1.0000000e+00 4.5267693e-25 5.0777086e-20 2.2381437e-19], sum to 1.0000
[2019-04-27 19:31:16,197] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6034
[2019-04-27 19:31:16,202] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.76666666666667, 44.83333333333334, 1.0, 2.0, 0.4900808356884555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 585242.0924779715, 585242.0924779715, 141371.6745547597], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2573400.0000, 
sim time next is 2574000.0000, 
raw observation next is [30.5, 46.0, 1.0, 2.0, 0.4935308139621631, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 589153.8727813133, 589153.8727813133, 141901.3210362524], 
processed observation next is [1.0, 0.8260869565217391, 0.6851851851851852, 0.46, 1.0, 1.0, 0.39706049281209893, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2104120974218976, 0.2104120974218976, 0.2728871558389469], 
reward next is 0.7271, 
noisyNet noise sample is [array([1.0447677], dtype=float32), -1.3982906]. 
=============================================
[2019-04-27 19:31:16,224] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[70.37223 ]
 [70.7259  ]
 [70.41164 ]
 [70.208786]
 [69.85428 ]], R is [[70.12918091]
 [70.15602112]
 [70.18373108]
 [70.2121582 ]
 [70.24108124]].
[2019-04-27 19:31:18,244] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.1355089e-20 1.0000000e+00 1.7903388e-23 9.4593480e-19 8.0324637e-17], sum to 1.0000
[2019-04-27 19:31:18,251] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7201
[2019-04-27 19:31:18,258] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.3, 100.0, 1.0, 2.0, 0.4452467080750552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 543609.9136110509, 543609.9136110509, 134968.3889257964], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2613600.0000, 
sim time next is 2614200.0000, 
raw observation next is [20.41666666666667, 100.0, 1.0, 2.0, 0.4483157343167489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 546591.8740527994, 546591.8740527994, 135402.7871810676], 
processed observation next is [0.0, 0.2608695652173913, 0.31172839506172856, 1.0, 1.0, 1.0, 0.34323301704374876, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1952113835902855, 0.1952113835902855, 0.2603899753482069], 
reward next is 0.7396, 
noisyNet noise sample is [array([0.9582271], dtype=float32), -1.0566567]. 
=============================================
[2019-04-27 19:31:31,142] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.2326254e-19 1.0000000e+00 7.5457456e-24 1.3023377e-21 3.5204914e-18], sum to 1.0000
[2019-04-27 19:31:31,153] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7269
[2019-04-27 19:31:31,156] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.523713039724494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 628621.1900741623, 628621.1900741619, 146814.08079726], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2875200.0000, 
sim time next is 2875800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.5244900821170525, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 629555.9919148686, 629555.9919148686, 146939.7741583169], 
processed observation next is [1.0, 0.2608695652173913, 0.37037037037037035, 0.94, 1.0, 1.0, 0.4339167644250625, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22484142568388163, 0.22484142568388163, 0.28257648876599406], 
reward next is 0.7174, 
noisyNet noise sample is [array([0.6289812], dtype=float32), -0.4110175]. 
=============================================
[2019-04-27 19:31:31,258] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-27 19:31:31,259] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 19:31:31,260] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:31:31,260] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 19:31:31,261] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:31:31,261] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 19:31:31,262] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 19:31:31,264] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 19:31:31,268] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:31:31,266] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:31:31,270] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:31:31,284] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run38
[2019-04-27 19:31:31,306] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run38
[2019-04-27 19:31:31,330] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run38
[2019-04-27 19:31:31,331] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run38
[2019-04-27 19:31:31,331] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run38
[2019-04-27 19:31:40,317] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.060827497]
[2019-04-27 19:31:40,319] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [32.39964711666667, 25.25987310666667, 1.0, 2.0, 0.6175871193317466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 773100.8739067838, 773100.8739067838, 163645.0605181624]
[2019-04-27 19:31:40,320] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 19:31:40,323] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.5409824e-20 1.0000000e+00 1.0339496e-23 2.4082397e-20 7.7918925e-18], sampled 0.1415262553316795
[2019-04-27 19:32:06,781] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.060827497]
[2019-04-27 19:32:06,784] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [34.95, 44.5, 1.0, 2.0, 0.972356798210381, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.974352877117457, 6.9112, 121.9256914975379, 1140799.394289725, 1108459.569796785, 234122.6887387203]
[2019-04-27 19:32:06,786] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 19:32:06,788] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.4329152e-19 1.0000000e+00 9.4755441e-23 1.6026379e-19 5.4143845e-17], sampled 0.5021942821842422
[2019-04-27 19:32:20,417] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.060827497]
[2019-04-27 19:32:20,419] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.32392107333333, 84.44079542, 1.0, 2.0, 0.517168051281574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 621066.749301275, 621066.749301275, 145771.2859537227]
[2019-04-27 19:32:20,420] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 19:32:20,424] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.9107581e-21 1.0000000e+00 2.5825440e-25 9.7702955e-22 4.0825933e-19], sampled 0.8655311121789511
[2019-04-27 19:32:26,193] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.060827497]
[2019-04-27 19:32:26,195] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.0, 78.16666666666667, 1.0, 2.0, 0.5794574409792116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 672386.6430277174, 672386.6430277178, 155154.4090021297]
[2019-04-27 19:32:26,196] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 19:32:26,199] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.1686438e-21 1.0000000e+00 1.8081684e-25 7.8702035e-22 3.5483856e-19], sampled 0.2653788176590911
[2019-04-27 19:32:31,828] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.060827497]
[2019-04-27 19:32:31,830] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.01595072166667, 62.22607335666667, 1.0, 2.0, 0.6705483248405041, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 814905.7721110642, 814905.7721110642, 172789.758763673]
[2019-04-27 19:32:31,830] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 19:32:31,833] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.4912152e-20 1.0000000e+00 3.3053442e-24 8.8665861e-21 3.1448245e-18], sampled 0.16889088955190978
[2019-04-27 19:32:47,219] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.060827497]
[2019-04-27 19:32:47,221] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.96666666666667, 88.33333333333334, 1.0, 2.0, 0.4782902832544462, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7665418907020649, 6.9112, 6.9112, 121.9258591645552, 1129483.720127803, 1129483.720127803, 248588.9174237262]
[2019-04-27 19:32:47,222] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 19:32:47,228] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0055912e-18 1.0000000e+00 2.4160863e-22 3.9844621e-19 1.4424458e-16], sampled 0.45600003627627983
[2019-04-27 19:32:55,975] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.060827497]
[2019-04-27 19:32:55,976] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [16.74264296, 80.04178199, 1.0, 2.0, 0.2595202496554235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 334616.4697718616, 334616.4697718621, 97731.9961323385]
[2019-04-27 19:32:55,977] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 19:32:55,982] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.7164061e-21 1.0000000e+00 7.2675561e-25 1.8820241e-21 6.5549488e-19], sampled 0.43493057568838234
[2019-04-27 19:33:22,903] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8770.2619 2170687269.9890 493.0000
[2019-04-27 19:33:24,191] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8581.2600 2248881556.8485 554.0000
[2019-04-27 19:33:24,371] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8096.9038 2445628494.3108 746.0000
[2019-04-27 19:33:24,435] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8922.2563 2120684861.2065 430.0000
[2019-04-27 19:33:24,500] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8699.3424 2195282598.7024 572.0000
[2019-04-27 19:33:25,518] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 925000, evaluation results [925000.0, 8096.903836826734, 2445628494.3108454, 746.0, 8770.26189789365, 2170687269.989048, 493.0, 8922.256315340886, 2120684861.2065036, 430.0, 8581.259978242537, 2248881556.8485174, 554.0, 8699.342416479873, 2195282598.702448, 572.0]
[2019-04-27 19:33:33,500] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.5752922e-20 1.0000000e+00 3.1011061e-24 6.8072788e-21 2.3471522e-15], sum to 1.0000
[2019-04-27 19:33:33,509] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6362
[2019-04-27 19:33:33,517] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.25, 85.66666666666667, 1.0, 2.0, 0.6748575998085646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 769132.3769322633, 769132.3769322628, 171437.6686413757], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3010200.0000, 
sim time next is 3010800.0000, 
raw observation next is [26.0, 87.33333333333334, 1.0, 2.0, 0.672176889272827, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 766075.6556454656, 766075.6556454656, 170942.5013903054], 
processed observation next is [1.0, 0.8695652173913043, 0.5185185185185185, 0.8733333333333334, 1.0, 1.0, 0.6097343919914607, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27359844844480913, 0.27359844844480913, 0.32873557959674116], 
reward next is 0.6713, 
noisyNet noise sample is [array([-0.57273245], dtype=float32), -1.2698132]. 
=============================================
[2019-04-27 19:33:35,658] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.5328910e-13 3.6508808e-07 9.9728727e-16 8.8414399e-13 9.9999964e-01], sum to 1.0000
[2019-04-27 19:33:35,666] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0324
[2019-04-27 19:33:35,671] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.0, 89.0, 1.0, 2.0, 0.5946127605213805, 1.0, 2.0, 0.5946127605213805, 1.0, 2.0, 0.946642879935694, 6.9112, 6.9112, 121.94756008, 2034625.499941843, 2034625.499941843, 392448.1613578676], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3060000.0000, 
sim time next is 3060600.0000, 
raw observation next is [28.33333333333334, 86.83333333333334, 1.0, 2.0, 0.6002247375953069, 1.0, 2.0, 0.6002247375953069, 1.0, 2.0, 0.9555773302067183, 6.9112, 6.9112, 121.94756008, 2053850.449432133, 2053850.449432133, 395498.057005569], 
processed observation next is [1.0, 0.43478260869565216, 0.6049382716049385, 0.8683333333333334, 1.0, 1.0, 0.5240770685658416, 1.0, 1.0, 0.5240770685658416, 1.0, 1.0, 0.9444716627583979, 0.0, 0.0, 0.8096049824067558, 0.7335180176543332, 0.7335180176543332, 0.7605731865491712], 
reward next is 0.2394, 
noisyNet noise sample is [array([0.8182416], dtype=float32), 0.19500536]. 
=============================================
[2019-04-27 19:33:36,740] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.7534546e-12 1.0000000e+00 6.4756754e-16 1.9091543e-14 2.4357394e-09], sum to 1.0000
[2019-04-27 19:33:36,747] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2297
[2019-04-27 19:33:36,754] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1522716.240176437 W.
[2019-04-27 19:33:36,759] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.0, 76.33333333333334, 1.0, 2.0, 0.6677080352990035, 1.0, 1.0, 0.6677080352990035, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1522716.240176437, 1522716.240176437, 292124.23446359], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3069600.0000, 
sim time next is 3070200.0000, 
raw observation next is [31.0, 75.66666666666666, 1.0, 2.0, 0.437453130276156, 1.0, 2.0, 0.437453130276156, 1.0, 1.0, 0.6964396302534688, 6.911199999999999, 6.9112, 121.94756008, 1496399.776511676, 1496399.776511677, 313877.1000232172], 
processed observation next is [1.0, 0.5217391304347826, 0.7037037037037037, 0.7566666666666666, 1.0, 1.0, 0.3303013455668524, 1.0, 1.0, 0.3303013455668524, 1.0, 0.5, 0.620549537816836, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5344284916113128, 0.5344284916113132, 0.6036098077369562], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0155495], dtype=float32), -0.09643269]. 
=============================================
[2019-04-27 19:33:39,221] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.7758041e-20 1.0000000e+00 1.9869994e-24 1.1462841e-20 5.1172850e-18], sum to 1.0000
[2019-04-27 19:33:39,228] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6493
[2019-04-27 19:33:39,231] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.8, 93.33333333333334, 1.0, 2.0, 0.4847058664667073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 584532.0905157172, 584532.0905157176, 140737.8677213524], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3300000.0000, 
sim time next is 3300600.0000, 
raw observation next is [21.75, 93.16666666666666, 1.0, 2.0, 0.4810126132292717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 580779.0849603487, 580779.0849603487, 140190.0692645859], 
processed observation next is [0.0, 0.17391304347826086, 0.3611111111111111, 0.9316666666666665, 1.0, 1.0, 0.3821578728919901, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2074211017715531, 0.2074211017715531, 0.2695962870472806], 
reward next is 0.7304, 
noisyNet noise sample is [array([-0.45443448], dtype=float32), 0.53359896]. 
=============================================
[2019-04-27 19:33:59,617] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.8323314e-19 1.0000000e+00 2.8855705e-23 3.6409938e-20 7.7152618e-17], sum to 1.0000
[2019-04-27 19:33:59,626] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0305
[2019-04-27 19:33:59,633] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.61666666666667, 79.83333333333334, 1.0, 2.0, 0.6393759818285681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 728674.9050862273, 728674.9050862273, 164982.9304330549], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3525000.0000, 
sim time next is 3525600.0000, 
raw observation next is [26.23333333333333, 80.66666666666667, 1.0, 2.0, 0.6270577107400992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 716635.5239556787, 716635.5239556787, 162893.862783712], 
processed observation next is [1.0, 0.8260869565217391, 0.5271604938271603, 0.8066666666666668, 1.0, 1.0, 0.5560210842144038, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2559412585555995, 0.2559412585555995, 0.31325742843021537], 
reward next is 0.6867, 
noisyNet noise sample is [array([0.02007594], dtype=float32), -1.0410227]. 
=============================================
[2019-04-27 19:34:04,992] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.9525311e-13 5.8362850e-05 4.9418384e-18 7.3106604e-10 9.9994159e-01], sum to 1.0000
[2019-04-27 19:34:04,999] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5929
[2019-04-27 19:34:05,003] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.11666666666667, 87.16666666666667, 1.0, 2.0, 0.182938428989213, 1.0, 1.0, 0.182938428989213, 1.0, 1.0, 0.2916469478482976, 6.911200000000001, 6.9112, 121.94756008, 634393.3855695226, 634393.3855695222, 215088.6297820371], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3617400.0000, 
sim time next is 3618000.0000, 
raw observation next is [24.0, 89.0, 1.0, 2.0, 0.1859231614152141, 1.0, 2.0, 0.1859231614152141, 1.0, 2.0, 0.2961825878059366, 6.9112, 6.9112, 121.94756008, 641057.4898107678, 641057.4898107678, 216057.0595580479], 
processed observation next is [1.0, 0.9130434782608695, 0.4444444444444444, 0.89, 1.0, 1.0, 0.030860906446683437, 1.0, 1.0, 0.030860906446683437, 1.0, 1.0, 0.12022823475742073, 0.0, 0.0, 0.8096049824067558, 0.22894910350384565, 0.22894910350384565, 0.4154943453039383], 
reward next is 0.5845, 
noisyNet noise sample is [array([-0.42239335], dtype=float32), 1.4811742]. 
=============================================
[2019-04-27 19:34:05,021] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[59.904713]
 [59.52608 ]
 [59.518097]
 [59.458347]
 [59.133286]], R is [[60.31084061]
 [60.29410172]
 [60.40659714]
 [60.51951599]
 [60.63233948]].
[2019-04-27 19:34:12,482] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.4491909e-13 2.2930001e-06 1.2182500e-16 5.3099357e-12 9.9999774e-01], sum to 1.0000
[2019-04-27 19:34:12,490] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1272
[2019-04-27 19:34:12,498] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.3, 77.0, 1.0, 2.0, 0.6131934471388941, 1.0, 2.0, 0.6131934471388941, 1.0, 2.0, 0.9762239381614924, 6.9112, 6.9112, 121.94756008, 2098278.940048247, 2098278.940048247, 402610.9123276719], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3754800.0000, 
sim time next is 3755400.0000, 
raw observation next is [29.41666666666667, 77.33333333333334, 1.0, 2.0, 0.5963864708744403, 1.0, 2.0, 0.5963864708744403, 1.0, 2.0, 0.9494666845834785, 6.911199999999999, 6.9112, 121.94756008, 2040701.654654291, 2040701.654654291, 393410.2722217583], 
processed observation next is [1.0, 0.4782608695652174, 0.6450617283950619, 0.7733333333333334, 1.0, 1.0, 0.5195077034219527, 1.0, 1.0, 0.5195077034219527, 1.0, 1.0, 0.9368333557293481, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7288220195193896, 0.7288220195193896, 0.7565582158110737], 
reward next is 0.2434, 
noisyNet noise sample is [array([1.1020277], dtype=float32), 0.7566723]. 
=============================================
[2019-04-27 19:34:14,727] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-27 19:34:14,728] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 19:34:14,728] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:34:14,730] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 19:34:14,730] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:34:14,731] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 19:34:14,731] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:34:14,732] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 19:34:14,732] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 19:34:14,732] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:34:14,734] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:34:14,750] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run39
[2019-04-27 19:34:14,750] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run39
[2019-04-27 19:34:14,751] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run39
[2019-04-27 19:34:14,802] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run39
[2019-04-27 19:34:14,817] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run39
[2019-04-27 19:34:36,455] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.062315136]
[2019-04-27 19:34:36,458] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.60315439, 46.85956372, 1.0, 2.0, 0.511718242307787, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 595721.9910852491, 595721.9910852487, 144155.5951663502]
[2019-04-27 19:34:36,460] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 19:34:36,463] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.6803607e-19 1.0000000e+00 1.1818123e-23 6.9174126e-19 1.6734723e-14], sampled 0.43271373105246447
[2019-04-27 19:34:48,155] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.062315136]
[2019-04-27 19:34:48,156] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.10258764666667, 78.75393518000001, 1.0, 2.0, 0.5636778566769365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 663909.8168731035, 663909.8168731035, 152925.9298957746]
[2019-04-27 19:34:48,157] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 19:34:48,160] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.36280165e-17 1.00000000e+00 7.31108411e-22 3.71078682e-17
 1.74754829e-12], sampled 0.3389606036582856
[2019-04-27 19:35:00,718] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.062315136]
[2019-04-27 19:35:00,719] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [32.0, 61.0, 1.0, 2.0, 0.7255747288791724, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 826965.6579832134, 826965.6579832134, 181046.7916916269]
[2019-04-27 19:35:00,720] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 19:35:00,722] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.1097997e-18 1.0000000e+00 1.5203402e-22 1.1824022e-17 1.0538275e-12], sampled 0.3134352889496198
[2019-04-27 19:35:30,382] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.062315136]
[2019-04-27 19:35:30,383] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.5, 66.0, 1.0, 2.0, 1.014270343018707, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.232592037942267, 6.9112, 121.9247056439024, 1320955.350783172, 1156375.706369071, 244188.5856635421]
[2019-04-27 19:35:30,384] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 19:35:30,386] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.5637975e-17 1.0000000e+00 3.1577184e-21 7.4036073e-17 9.7594866e-12], sampled 0.3188562720332122
[2019-04-27 19:35:30,387] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1320955.350783172 W.
[2019-04-27 19:35:38,368] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.062315136]
[2019-04-27 19:35:38,370] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.88497897, 62.03719368, 1.0, 2.0, 0.4845290342443879, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 579191.507861872, 579191.507861872, 140532.0144914708]
[2019-04-27 19:35:38,375] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 19:35:38,377] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.1693752e-18 1.0000000e+00 9.9997353e-23 4.1812293e-18 8.4471547e-14], sampled 0.31200861060561513
[2019-04-27 19:35:49,663] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.062315136]
[2019-04-27 19:35:49,667] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.72151441, 54.17238680166666, 1.0, 2.0, 0.3956722741434569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 486598.812930836, 486598.8129308355, 127923.43934896]
[2019-04-27 19:35:49,668] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 19:35:49,673] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [5.6608403e-18 1.0000000e+00 3.3450628e-22 1.1552630e-17 1.9865141e-13], sampled 0.24335417060637388
[2019-04-27 19:35:52,834] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.062315136]
[2019-04-27 19:35:52,835] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.85, 94.5, 1.0, 2.0, 0.5234783938200326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 617947.855603271, 617947.8556032715, 146384.6070349985]
[2019-04-27 19:35:52,836] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 19:35:52,839] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.9952314e-18 1.0000000e+00 7.4805187e-23 5.0358545e-18 2.3588775e-13], sampled 0.8197154436487687
[2019-04-27 19:36:07,250] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8773.7133 2171104025.9383 481.0000
[2019-04-27 19:36:07,447] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8588.6424 2249496419.1929 516.0000
[2019-04-27 19:36:07,711] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8707.4412 2196129722.9849 545.0000
[2019-04-27 19:36:07,750] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8126.7419 2446836014.8843 635.0000
[2019-04-27 19:36:07,950] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8927.4001 2121267283.9499 421.0000
[2019-04-27 19:36:08,966] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 950000, evaluation results [950000.0, 8126.741876914776, 2446836014.884283, 635.0, 8773.713267201549, 2171104025.938257, 481.0, 8927.40006210366, 2121267283.9499261, 421.0, 8588.64238864599, 2249496419.1928515, 516.0, 8707.441212165764, 2196129722.9849157, 545.0]
[2019-04-27 19:36:20,670] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4981042e-08 7.5632681e-07 1.3825223e-10 2.1037909e-08 9.9999917e-01], sum to 1.0000
[2019-04-27 19:36:20,680] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9315
[2019-04-27 19:36:20,684] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.13333333333333, 85.66666666666666, 1.0, 2.0, 0.5383343793417033, 1.0, 2.0, 0.5383343793417033, 1.0, 2.0, 0.8570458642387313, 6.911200000000001, 6.9112, 121.94756008, 1841855.531101115, 1841855.531101115, 362802.1975851592], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4027200.0000, 
sim time next is 4027800.0000, 
raw observation next is [26.06666666666667, 87.33333333333334, 1.0, 2.0, 0.5463678927262816, 1.0, 2.0, 0.5463678927262816, 1.0, 2.0, 0.8698354791802454, 6.9112, 6.9112, 121.94756008, 1869370.126477655, 1869370.126477655, 366929.3949727673], 
processed observation next is [1.0, 0.6086956521739131, 0.5209876543209878, 0.8733333333333334, 1.0, 1.0, 0.4599617770550971, 1.0, 1.0, 0.4599617770550971, 1.0, 1.0, 0.8372943489753067, 0.0, 0.0, 0.8096049824067558, 0.6676321880277339, 0.6676321880277339, 0.7056334518707063], 
reward next is 0.2944, 
noisyNet noise sample is [array([-0.5242451], dtype=float32), 3.4491737]. 
=============================================
[2019-04-27 19:36:22,325] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.1447621e-13 9.9999988e-01 2.8443012e-17 1.2540143e-13 1.2494841e-07], sum to 1.0000
[2019-04-27 19:36:22,329] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4776
[2019-04-27 19:36:22,334] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.5211707735904737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 645663.4674207685, 645663.4674207685, 146992.7632711938], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4244400.0000, 
sim time next is 4245000.0000, 
raw observation next is [22.0, 78.0, 1.0, 2.0, 0.5014418541907318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 621583.0457302963, 621583.0457302963, 143831.3768454915], 
processed observation next is [1.0, 0.13043478260869565, 0.37037037037037035, 0.78, 1.0, 1.0, 0.4064783978461093, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22199394490367724, 0.22199394490367724, 0.2765988016259452], 
reward next is 0.7234, 
noisyNet noise sample is [array([0.79318964], dtype=float32), 0.8216684]. 
=============================================
[2019-04-27 19:36:22,350] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[57.25555 ]
 [57.481087]
 [57.727882]
 [57.886356]
 [57.69637 ]], R is [[57.47309875]
 [57.61569214]
 [57.74879074]
 [57.86832428]
 [57.95332718]].
[2019-04-27 19:36:43,008] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.7123405e-22 1.0000000e+00 1.6567624e-27 1.6873943e-23 6.1491631e-20], sum to 1.0000
[2019-04-27 19:36:43,017] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3079
[2019-04-27 19:36:43,021] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 74.0, 1.0, 2.0, 0.6650140950449489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 757908.2295115875, 757908.2295115875, 169625.4827970976], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4453200.0000, 
sim time next is 4453800.0000, 
raw observation next is [28.16666666666667, 72.5, 1.0, 2.0, 0.656081921955531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 747723.3787008525, 747723.3787008525, 167995.4560335104], 
processed observation next is [0.0, 0.5652173913043478, 0.5987654320987656, 0.725, 1.0, 1.0, 0.5905737166137273, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.267044063821733, 0.267044063821733, 0.3230681846798277], 
reward next is 0.6769, 
noisyNet noise sample is [array([1.4737251], dtype=float32), 0.3102158]. 
=============================================
[2019-04-27 19:36:50,134] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.90846652e-19 1.00000000e+00 4.43123683e-21 2.26995996e-17
 1.40725495e-14], sum to 1.0000
[2019-04-27 19:36:50,144] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6638
[2019-04-27 19:36:50,148] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.1, 92.33333333333334, 1.0, 2.0, 0.6517325000101698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 742764.028317804, 742764.028317804, 167206.4870051115], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4750800.0000, 
sim time next is 4751400.0000, 
raw observation next is [25.05, 93.16666666666667, 1.0, 2.0, 0.65494717910632, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 746429.5054207097, 746429.5054207097, 167789.2738715453], 
processed observation next is [1.0, 1.0, 0.48333333333333334, 0.9316666666666668, 1.0, 1.0, 0.5892228322694286, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26658196622168207, 0.26658196622168207, 0.3226716805222025], 
reward next is 0.6773, 
noisyNet noise sample is [array([-0.85605365], dtype=float32), 0.5026993]. 
=============================================
[2019-04-27 19:36:52,902] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.0245045e-17 1.0000000e+00 2.0453528e-19 2.3815319e-16 1.4669186e-14], sum to 1.0000
[2019-04-27 19:36:52,914] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0410
[2019-04-27 19:36:52,920] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.6, 82.0, 1.0, 2.0, 0.6670791849859876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 760262.9538084806, 760262.9538084806, 170003.581616416], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4651200.0000, 
sim time next is 4651800.0000, 
raw observation next is [26.5, 84.00000000000001, 1.0, 2.0, 0.671819686136028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 765668.350212739, 765668.350212739, 170876.7054468547], 
processed observation next is [1.0, 0.8695652173913043, 0.5370370370370371, 0.8400000000000002, 1.0, 1.0, 0.6093091501619381, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27345298221883535, 0.27345298221883535, 0.32860904893625903], 
reward next is 0.6714, 
noisyNet noise sample is [array([0.52709115], dtype=float32), 0.49046668]. 
=============================================
[2019-04-27 19:36:53,861] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.1762725e-17 1.0000000e+00 2.5896523e-21 8.8659236e-18 1.9087166e-11], sum to 1.0000
[2019-04-27 19:36:53,870] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6436
[2019-04-27 19:36:53,876] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.6961375141873676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 793397.5580085823, 793397.5580085819, 175414.5082497399], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4647600.0000, 
sim time next is 4648200.0000, 
raw observation next is [26.93333333333333, 83.66666666666667, 1.0, 2.0, 0.6933083398135331, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 790171.4467828627, 790171.4467828627, 174881.0324503953], 
processed observation next is [1.0, 0.8260869565217391, 0.5530864197530863, 0.8366666666666667, 1.0, 1.0, 0.6348908807303966, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28220408813673664, 0.28220408813673664, 0.3363096777892217], 
reward next is 0.6637, 
noisyNet noise sample is [array([-0.74519014], dtype=float32), 0.85362124]. 
=============================================
[2019-04-27 19:36:54,556] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.4677274e-14 9.9999869e-01 1.0014990e-15 6.3441943e-12 1.2857831e-06], sum to 1.0000
[2019-04-27 19:36:54,563] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7919
[2019-04-27 19:36:54,570] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.6648746103903599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 757749.1820240607, 757749.1820240607, 169599.6906452617], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4667400.0000, 
sim time next is 4668000.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.6657908827654112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 758793.9629268016, 758793.9629268016, 169767.6205528828], 
processed observation next is [1.0, 0.0, 0.48148148148148145, 0.94, 1.0, 1.0, 0.6021320032921562, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27099784390242915, 0.27099784390242915, 0.3264761933709285], 
reward next is 0.6735, 
noisyNet noise sample is [array([-1.3272338], dtype=float32), 1.662289]. 
=============================================
[2019-04-27 19:36:54,591] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[55.187237]
 [55.88475 ]
 [56.63714 ]
 [57.93866 ]
 [59.805492]], R is [[54.88186264]
 [55.00689316]
 [55.13082123]
 [55.25347137]
 [55.37495041]].
[2019-04-27 19:36:55,812] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.2840626e-16 1.0000000e+00 6.6301641e-20 1.2917034e-16 1.6066689e-15], sum to 1.0000
[2019-04-27 19:36:55,827] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7599
[2019-04-27 19:36:55,833] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.6931956329592966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 790042.9272913281, 790042.9272913281, 174857.4651048222], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4860000.0000, 
sim time next is 4860600.0000, 
raw observation next is [25.0, 94.00000000000001, 1.0, 2.0, 0.7776351569586679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 886335.2562777001, 886335.2562777001, 191358.4431401069], 
processed observation next is [1.0, 0.2608695652173913, 0.48148148148148145, 0.9400000000000002, 1.0, 1.0, 0.735279948760319, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3165483058134643, 0.3165483058134643, 0.3679970060386671], 
reward next is 0.6320, 
noisyNet noise sample is [array([-0.05848216], dtype=float32), -2.0096512]. 
=============================================
[2019-04-27 19:36:56,143] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2376072e-08 9.9992323e-01 2.7489530e-12 8.9925685e-09 7.6722055e-05], sum to 1.0000
[2019-04-27 19:36:56,149] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0997
[2019-04-27 19:36:56,155] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1599783.912671812 W.
[2019-04-27 19:36:56,160] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.21666666666667, 87.33333333333334, 1.0, 2.0, 0.7762066161072712, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426156618, 1599783.912671812, 1599783.912671811, 331554.3662558856], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4708200.0000, 
sim time next is 4708800.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.5269080529694642, 1.0, 1.0, 0.5269080529694642, 1.0, 2.0, 0.8388547805246565, 6.911199999999999, 6.9112, 121.94756008, 1802722.090427369, 1802722.090427369, 356992.0859570096], 
processed observation next is [1.0, 0.5217391304347826, 0.5185185185185185, 0.89, 1.0, 1.0, 0.436795301154124, 1.0, 0.5, 0.436795301154124, 1.0, 1.0, 0.7985684756558206, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6438293180097747, 0.6438293180097747, 0.6865232422250184], 
reward next is 0.3135, 
noisyNet noise sample is [array([-0.18046482], dtype=float32), -0.42260957]. 
=============================================
[2019-04-27 19:36:56,362] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.7189286e-07 3.6041364e-02 9.0061336e-10 2.9736377e-06 9.6395552e-01], sum to 1.0000
[2019-04-27 19:36:56,371] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9404
[2019-04-27 19:36:56,376] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.3, 79.0, 1.0, 2.0, 0.5075817279877253, 1.0, 2.0, 0.5075817279877253, 1.0, 2.0, 0.8080866417392651, 6.9112, 6.9112, 121.94756008, 1736536.249996312, 1736536.249996312, 347325.8342214818], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4705200.0000, 
sim time next is 4705800.0000, 
raw observation next is [27.08333333333333, 80.66666666666667, 1.0, 2.0, 0.5492358682287989, 1.0, 2.0, 0.5492358682287989, 1.0, 2.0, 0.8744013895836942, 6.911200000000001, 6.9112, 121.94756008, 1879193.08074965, 1879193.08074965, 368411.2611560495], 
processed observation next is [1.0, 0.4782608695652174, 0.5586419753086418, 0.8066666666666668, 1.0, 1.0, 0.46337603360571294, 1.0, 1.0, 0.46337603360571294, 1.0, 1.0, 0.8430017369796178, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6711403859820179, 0.6711403859820179, 0.7084831945308644], 
reward next is 0.2915, 
noisyNet noise sample is [array([0.29808125], dtype=float32), 1.1873429]. 
=============================================
[2019-04-27 19:36:57,025] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.3491163e-12 9.9999940e-01 8.8765486e-17 7.3663131e-11 6.1338022e-07], sum to 1.0000
[2019-04-27 19:36:57,033] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6884
[2019-04-27 19:36:57,039] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.75, 83.16666666666667, 1.0, 2.0, 0.6876479682134385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 783716.9584296992, 783716.9584296992, 173817.7603471531], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4737000.0000, 
sim time next is 4737600.0000, 
raw observation next is [26.7, 82.0, 1.0, 2.0, 0.6746052539358587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 768844.6351624278, 768844.6351624283, 171390.6010951293], 
processed observation next is [1.0, 0.8695652173913043, 0.5444444444444444, 0.82, 1.0, 1.0, 0.6126253023045937, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27458736970086706, 0.2745873697008672, 0.3295973097983256], 
reward next is 0.6704, 
noisyNet noise sample is [array([0.8284085], dtype=float32), 2.56056]. 
=============================================
[2019-04-27 19:36:58,068] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-04-27 19:36:58,069] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 19:36:58,070] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 19:36:58,070] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:36:58,071] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 19:36:58,072] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 19:36:58,073] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 19:36:58,071] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:36:58,074] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:36:58,075] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:36:58,077] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:36:58,092] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run40
[2019-04-27 19:36:58,113] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run40
[2019-04-27 19:36:58,114] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run40
[2019-04-27 19:36:58,161] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run40
[2019-04-27 19:36:58,161] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run40
[2019-04-27 19:37:07,359] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.064565696]
[2019-04-27 19:37:07,360] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.33333333333333, 21.66666666666667, 1.0, 2.0, 0.6273255478916044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 799842.9447617967, 799842.9447617967, 165576.2145974521]
[2019-04-27 19:37:07,361] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 19:37:07,365] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.7997749e-17 1.0000000e+00 1.0010890e-20 2.9843655e-16 1.4985402e-15], sampled 0.38588752551235317
[2019-04-27 19:37:11,792] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.064565696]
[2019-04-27 19:37:11,793] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.48916318, 67.52093918, 1.0, 2.0, 0.3851674752388156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 478228.9763310155, 478228.9763310151, 126571.0426855953]
[2019-04-27 19:37:11,793] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 19:37:11,796] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.2223383e-18 1.0000000e+00 3.3583856e-22 1.7585713e-17 6.6392600e-17], sampled 0.5686164733071931
[2019-04-27 19:37:22,962] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.064565696]
[2019-04-27 19:37:22,964] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.73333333333333, 38.0, 1.0, 2.0, 0.7889877298335057, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 976257.0759860028, 976257.0759860028, 196833.7478014424]
[2019-04-27 19:37:22,964] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 19:37:22,967] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.9838778e-16 1.0000000e+00 1.2968066e-19 2.5899170e-15 1.6152393e-14], sampled 0.6137297124234254
[2019-04-27 19:37:23,030] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.064565696]
[2019-04-27 19:37:23,031] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [18.5497897, 83.27619315666666, 1.0, 2.0, 0.3213615858413036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 410889.5156466952, 410889.5156466952, 118256.9343678933]
[2019-04-27 19:37:23,032] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 19:37:23,035] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.8314171e-17 1.0000000e+00 2.7370548e-21 9.1575227e-17 3.6069246e-16], sampled 0.1195655030106173
[2019-04-27 19:37:28,299] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.064565696]
[2019-04-27 19:37:28,300] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.0, 69.0, 1.0, 2.0, 0.3674269041205354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 457495.2155994705, 457495.2155994705, 124172.2055697669]
[2019-04-27 19:37:28,304] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 19:37:28,306] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.0012992e-18 1.0000000e+00 1.7316859e-22 1.1555010e-17 4.9847502e-17], sampled 0.8103553163836543
[2019-04-27 19:37:32,848] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.064565696]
[2019-04-27 19:37:32,849] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.33333333333334, 54.0, 1.0, 2.0, 0.6147420425495498, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9786893524894879, 6.911199999999999, 6.9112, 121.9260426156618, 1401816.10212435, 1401816.10212435, 299639.2987412109]
[2019-04-27 19:37:32,850] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 19:37:32,854] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.9267286e-13 1.0000000e+00 9.9837954e-17 8.9125426e-12 1.2643327e-08], sampled 0.24690639417583915
[2019-04-27 19:37:32,856] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1401816.10212435 W.
[2019-04-27 19:37:49,309] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.064565696]
[2019-04-27 19:37:49,312] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.52125099833333, 74.53902855, 1.0, 2.0, 0.7357490035937964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 123.4538213467382, 874425.2364860799, 874425.2364860799, 184931.5711351905]
[2019-04-27 19:37:49,314] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 19:37:49,317] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.01293806e-17 1.00000000e+00 3.01826957e-21 1.02618485e-16
 4.45283579e-16], sampled 0.42847121256331444
[2019-04-27 19:38:18,105] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.064565696]
[2019-04-27 19:38:18,106] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.808564455, 93.73115312, 1.0, 2.0, 0.5556117200432623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 647921.4805325133, 647921.4805325129, 151305.0967792062]
[2019-04-27 19:38:18,107] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 19:38:18,109] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.7871585e-16 1.0000000e+00 2.6774798e-20 6.1750089e-16 9.7865196e-15], sampled 0.5451348415338836
[2019-04-27 19:38:18,134] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.064565696]
[2019-04-27 19:38:18,135] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.11666666666667, 84.0, 1.0, 2.0, 0.5884248022646067, 1.0, 2.0, 0.5884248022646067, 1.0, 2.0, 0.936791448863179, 6.9112, 6.9112, 121.94756008, 2013427.891441787, 2013427.891441787, 389104.9063848588]
[2019-04-27 19:38:18,135] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 19:38:18,138] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.1146448e-12 5.6279827e-05 1.6569502e-16 6.5983746e-10 9.9994373e-01], sampled 0.5510341793799227
[2019-04-27 19:38:28,573] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.064565696]
[2019-04-27 19:38:28,575] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.29424477833334, 77.71214768333333, 1.0, 2.0, 0.5758965159665665, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 666569.0757107205, 666569.0757107205, 154475.3784129353]
[2019-04-27 19:38:28,578] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 19:38:28,580] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.75080349e-18 1.00000000e+00 5.16577827e-22 2.64728981e-17
 1.09826365e-16], sampled 0.952749892457993
[2019-04-27 19:38:31,950] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.064565696]
[2019-04-27 19:38:31,953] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.37050089333334, 77.62929843, 1.0, 2.0, 0.6241014818747408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 711259.004699401, 711259.004699401, 162274.2916437357]
[2019-04-27 19:38:31,955] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 19:38:31,957] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.1909329e-17 1.0000000e+00 2.8636419e-21 1.2140636e-16 7.0193112e-16], sampled 0.10458536530721929
[2019-04-27 19:38:51,339] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8774.5932 2171083040.1188 480.0000
[2019-04-27 19:38:51,446] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8702.7633 2196021527.2759 550.0000
[2019-04-27 19:38:51,533] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8598.3906 2249523729.2226 496.0000
[2019-04-27 19:38:51,534] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8145.3309 2446953471.4096 584.0000
[2019-04-27 19:38:51,548] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.0630 2120956920.0335 428.0000
[2019-04-27 19:38:52,563] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 975000, evaluation results [975000.0, 8145.330914236654, 2446953471.4095564, 584.0, 8774.593207009078, 2171083040.1187587, 480.0, 8924.063049988386, 2120956920.0334604, 428.0, 8598.390568891444, 2249523729.2226014, 496.0, 8702.763325739028, 2196021527.275868, 550.0]
[2019-04-27 19:38:56,880] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.2787726e-16 1.0000000e+00 7.8372597e-19 3.4562107e-16 2.5415257e-14], sum to 1.0000
[2019-04-27 19:38:56,893] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3704
[2019-04-27 19:38:56,900] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.06666666666667, 92.66666666666667, 1.0, 2.0, 0.7855354031976082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 895345.0817297838, 895345.0817297833, 192975.7273210943], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4821600.0000, 
sim time next is 4822200.0000, 
raw observation next is [27.1, 92.0, 1.0, 2.0, 0.7659836521009717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 873047.5061576838, 873047.5061576838, 189017.9623957552], 
processed observation next is [1.0, 0.8260869565217391, 0.5592592592592593, 0.92, 1.0, 1.0, 0.721409109644014, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31180268077060136, 0.31180268077060136, 0.36349608153029844], 
reward next is 0.6365, 
noisyNet noise sample is [array([-0.26418382], dtype=float32), -0.7453199]. 
=============================================
[2019-04-27 19:38:57,323] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.35349282e-21 1.00000000e+00 2.22216970e-24 1.15981385e-20
 1.12950171e-15], sum to 1.0000
[2019-04-27 19:38:57,332] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4647
[2019-04-27 19:38:57,336] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.06666666666667, 92.33333333333333, 1.0, 2.0, 0.7102817568412787, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 809526.4599810407, 809526.4599810407, 178100.9504440318], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4833600.0000, 
sim time next is 4834200.0000, 
raw observation next is [26.08333333333334, 92.16666666666667, 1.0, 2.0, 0.709582049442629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 808728.5646687681, 808728.5646687681, 177967.2701681992], 
processed observation next is [1.0, 0.9565217391304348, 0.5216049382716051, 0.9216666666666667, 1.0, 1.0, 0.6542643445745584, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2888316302388457, 0.2888316302388457, 0.34224475032346], 
reward next is 0.6578, 
noisyNet noise sample is [array([1.1393507], dtype=float32), -1.1694587]. 
=============================================
[2019-04-27 19:39:00,234] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.0350150e-14 1.0000000e+00 6.7204434e-17 1.1718159e-14 1.3969277e-13], sum to 1.0000
[2019-04-27 19:39:00,248] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5907
[2019-04-27 19:39:00,252] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 89.0, 1.0, 2.0, 0.8194036741313723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 933971.307292068, 933971.307292068, 199995.7139637082], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4903800.0000, 
sim time next is 4904400.0000, 
raw observation next is [29.0, 89.0, 1.0, 2.0, 0.8342625590314091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 950918.2441891799, 950918.2441891799, 203134.7543221284], 
processed observation next is [1.0, 0.782608695652174, 0.6296296296296297, 0.89, 1.0, 1.0, 0.8026935226564395, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3396136586389928, 0.3396136586389928, 0.3906437583117854], 
reward next is 0.6094, 
noisyNet noise sample is [array([-0.06397781], dtype=float32), 0.51981235]. 
=============================================
[2019-04-27 19:39:03,076] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.0562921e-20 1.0000000e+00 3.2791339e-24 3.1661374e-21 4.4727429e-21], sum to 1.0000
[2019-04-27 19:39:03,085] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4117
[2019-04-27 19:39:03,089] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 79.0, 1.0, 2.0, 0.5570819959366299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 662364.8689823588, 662364.8689823588, 152071.3645698683], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4942800.0000, 
sim time next is 4943400.0000, 
raw observation next is [24.41666666666667, 79.66666666666667, 1.0, 2.0, 0.6618298358293248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 787307.9628257001, 787307.9628257001, 170544.3810163243], 
processed observation next is [1.0, 0.21739130434782608, 0.4598765432098767, 0.7966666666666667, 1.0, 1.0, 0.5974164712253865, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2811814152948929, 0.2811814152948929, 0.32796996349293134], 
reward next is 0.6720, 
noisyNet noise sample is [array([-1.0226341], dtype=float32), -0.37746197]. 
=============================================
[2019-04-27 19:39:20,507] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.0322262e-13 1.0000000e+00 4.0278673e-17 6.0339136e-11 4.1855593e-08], sum to 1.0000
[2019-04-27 19:39:20,515] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2581
[2019-04-27 19:39:20,520] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.95, 90.0, 1.0, 2.0, 0.6970723638055253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 794463.5712312438, 794463.5712312438, 175589.9969296917], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5265000.0000, 
sim time next is 5265600.0000, 
raw observation next is [25.9, 90.0, 1.0, 2.0, 0.6943389435803018, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 791346.644029029, 791346.6440290285, 175074.4022322376], 
processed observation next is [1.0, 0.9565217391304348, 0.5148148148148147, 0.9, 1.0, 1.0, 0.6361177899765498, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2826238014389389, 0.2826238014389387, 0.33668154275430306], 
reward next is 0.6633, 
noisyNet noise sample is [array([0.43891332], dtype=float32), 1.1563861]. 
=============================================
[2019-04-27 19:39:25,866] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.2994735e-14 1.0000000e+00 2.8596524e-17 3.1131809e-11 3.4518796e-10], sum to 1.0000
[2019-04-27 19:39:25,875] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8295
[2019-04-27 19:39:25,882] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.65, 88.33333333333334, 1.0, 2.0, 0.7881734027457118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 911326.237493301, 911326.237493301, 194173.4080114843], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5368200.0000, 
sim time next is 5368800.0000, 
raw observation next is [24.6, 88.66666666666667, 1.0, 2.0, 0.7754533314569607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 896698.4985974324, 896698.4985974324, 191575.6666785618], 
processed observation next is [1.0, 0.13043478260869565, 0.46666666666666673, 0.8866666666666667, 1.0, 1.0, 0.7326825374487628, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3202494637847973, 0.3202494637847973, 0.36841474361261883], 
reward next is 0.6316, 
noisyNet noise sample is [array([0.30821952], dtype=float32), 3.571483]. 
=============================================
[2019-04-27 19:39:29,930] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.92427274e-16 1.00000000e+00 1.65631402e-19 1.04142044e-13
 9.18773385e-14], sum to 1.0000
[2019-04-27 19:39:29,939] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5529
[2019-04-27 19:39:29,944] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.3, 94.5, 1.0, 2.0, 0.8844049033979074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1008109.632239732, 1008109.632239732, 213999.0032592385], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5463000.0000, 
sim time next is 5463600.0000, 
raw observation next is [26.36666666666667, 94.33333333333334, 1.0, 2.0, 0.9045384453423105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1031074.761826388, 1031074.761826388, 218488.5542264229], 
processed observation next is [1.0, 0.21739130434782608, 0.5320987654320989, 0.9433333333333335, 1.0, 1.0, 0.8863552920741792, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3682409863665671, 0.3682409863665671, 0.4201702965892748], 
reward next is 0.5798, 
noisyNet noise sample is [array([0.9415458], dtype=float32), 1.5918694]. 
=============================================
[2019-04-27 19:39:31,721] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.8860946e-08 9.9999452e-01 1.1911737e-10 1.6332159e-08 5.4986895e-06], sum to 1.0000
[2019-04-27 19:39:31,726] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4157
[2019-04-27 19:39:31,732] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2612741.919279324 W.
[2019-04-27 19:39:31,740] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.84999999999999, 66.0, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 7.468119798038375, 6.9112, 121.9241195382778, 2612741.919279324, 2327553.703956414, 443050.4086813619], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5491800.0000, 
sim time next is 5492400.0000, 
raw observation next is [33.03333333333333, 65.0, 1.0, 2.0, 0.7733767613064993, 1.0, 2.0, 0.7000530426296844, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2395901.447292932, 2395901.447292932, 449539.6558661253], 
processed observation next is [1.0, 0.5652173913043478, 0.7790123456790122, 0.65, 1.0, 1.0, 0.7302104301267849, 1.0, 1.0, 0.6429202888448623, 1.0, 0.5, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.8556790883189043, 0.8556790883189043, 0.8644993382040871], 
reward next is 0.1355, 
noisyNet noise sample is [array([-0.89583355], dtype=float32), 1.1793798]. 
=============================================
[2019-04-27 19:39:33,474] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.1077044e-23 1.0000000e+00 4.6995143e-29 2.6465083e-20 2.9581609e-23], sum to 1.0000
[2019-04-27 19:39:33,481] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6084
[2019-04-27 19:39:33,484] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.73333333333333, 91.33333333333334, 1.0, 2.0, 0.6860379858818818, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 781881.1150001911, 781881.1150001911, 173517.3773061403], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5530800.0000, 
sim time next is 5531400.0000, 
raw observation next is [25.7, 91.5, 1.0, 2.0, 0.6853478859558648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 781094.2037263701, 781094.2037263701, 173388.4126883724], 
processed observation next is [1.0, 0.0, 0.5074074074074074, 0.915, 1.0, 1.0, 0.6254141499474581, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27896221561656076, 0.27896221561656076, 0.33343925516994694], 
reward next is 0.6666, 
noisyNet noise sample is [array([-0.10231944], dtype=float32), -0.8023133]. 
=============================================
[2019-04-27 19:39:35,156] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.7757380e-22 1.0000000e+00 1.7799132e-23 4.7946237e-19 1.0848081e-20], sum to 1.0000
[2019-04-27 19:39:35,163] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2963
[2019-04-27 19:39:35,172] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.48333333333333, 84.66666666666667, 1.0, 2.0, 0.6636929628448025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 762427.0367269114, 762427.0367269114, 169683.47952109], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5559000.0000, 
sim time next is 5559600.0000, 
raw observation next is [25.56666666666667, 84.33333333333334, 1.0, 2.0, 0.8954101806981414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1027768.655539467, 1027768.655539467, 216825.8601001565], 
processed observation next is [1.0, 0.34782608695652173, 0.5024691358024692, 0.8433333333333334, 1.0, 1.0, 0.8754883103549302, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3670602341212382, 0.3670602341212382, 0.41697280788491636], 
reward next is 0.5830, 
noisyNet noise sample is [array([0.54588544], dtype=float32), 0.7098415]. 
=============================================
[2019-04-27 19:39:41,242] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8842880e-20 1.0000000e+00 6.4550551e-24 2.5678375e-18 2.6413028e-21], sum to 1.0000
[2019-04-27 19:39:41,253] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8109
[2019-04-27 19:39:41,256] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.4, 67.0, 1.0, 2.0, 0.7185985838306056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 819010.4268365062, 819010.4268365062, 179697.6033102869], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5673600.0000, 
sim time next is 5674200.0000, 
raw observation next is [30.48333333333333, 66.66666666666667, 1.0, 2.0, 0.7096859762006885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 808847.0751153987, 808847.0751153987, 177988.8774762318], 
processed observation next is [0.0, 0.6956521739130435, 0.6845679012345678, 0.6666666666666667, 1.0, 1.0, 0.6543880669055816, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2888739553983567, 0.2888739553983567, 0.3422863028389073], 
reward next is 0.6577, 
noisyNet noise sample is [array([-0.42924044], dtype=float32), 1.3709791]. 
=============================================
[2019-04-27 19:39:41,768] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-27 19:39:41,770] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 19:39:41,771] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:39:41,771] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 19:39:41,772] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 19:39:41,772] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 19:39:41,773] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:39:41,774] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:39:41,774] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 19:39:41,775] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:39:41,780] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:39:41,796] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run41
[2019-04-27 19:39:41,817] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run41
[2019-04-27 19:39:41,860] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run41
[2019-04-27 19:39:41,945] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run41
[2019-04-27 19:39:42,072] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run41
[2019-04-27 19:40:02,401] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.067733146]
[2019-04-27 19:40:02,403] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [36.26666666666667, 19.0, 1.0, 2.0, 0.4168984349334156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426118662, 516699.7578330568, 516699.7578330563, 131028.4659965161]
[2019-04-27 19:40:02,404] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 19:40:02,408] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0336188e-22 1.0000000e+00 8.6994727e-28 1.0779039e-18 2.5112604e-21], sampled 0.957645322716794
[2019-04-27 19:40:04,010] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.067733146]
[2019-04-27 19:40:04,012] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.58004501333333, 58.26604490666666, 1.0, 2.0, 0.4016420437779966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 495496.1192133356, 495496.1192133352, 128800.3359354333]
[2019-04-27 19:40:04,013] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 19:40:04,016] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [8.4987822e-23 1.0000000e+00 2.1595728e-27 3.6487681e-19 1.1258455e-22], sampled 0.16471615347839963
[2019-04-27 19:40:27,104] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.067733146]
[2019-04-27 19:40:27,105] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.73333333333333, 92.66666666666667, 1.0, 2.0, 0.4566597148498227, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 552623.9447752483, 552623.9447752483, 136524.8494777404]
[2019-04-27 19:40:27,106] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 19:40:27,109] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.38203760e-23 1.00000000e+00 1.15327574e-27 2.78531901e-19
 1.00022154e-22], sampled 0.42119021386434885
[2019-04-27 19:40:47,452] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.067733146]
[2019-04-27 19:40:47,455] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.83333333333333, 79.83333333333334, 1.0, 2.0, 0.6311349763670839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 719278.5070766781, 719278.5070766781, 163516.5066615252]
[2019-04-27 19:40:47,456] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 19:40:47,459] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.7650793e-22 1.0000000e+00 5.0168877e-27 7.8263549e-19 2.8489748e-22], sampled 0.962816634346468
[2019-04-27 19:41:33,764] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.067733146]
[2019-04-27 19:41:33,766] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.33333333333334, 56.00000000000001, 1.0, 2.0, 0.4080402059113678, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 507242.6638279707, 507242.6638279707, 129793.7878157949]
[2019-04-27 19:41:33,767] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 19:41:33,772] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [7.7929471e-22 1.0000000e+00 3.1796006e-26 2.4434338e-18 1.0424258e-21], sampled 0.5023589679095789
[2019-04-27 19:41:34,972] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8922.6976 2120744736.1846 431.0000
[2019-04-27 19:41:35,298] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8769.5254 2170816039.9546 493.0000
[2019-04-27 19:41:35,327] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8587.5794 2249121731.1378 531.0000
[2019-04-27 19:41:35,360] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8108.3951 2446290932.0091 690.0000
[2019-04-27 19:41:35,475] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8698.8782 2195370702.9393 569.0000
[2019-04-27 19:41:36,491] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1000000, evaluation results [1000000.0, 8108.395144012419, 2446290932.0090528, 690.0, 8769.525395518618, 2170816039.9546046, 493.0, 8922.69755103512, 2120744736.1845772, 431.0, 8587.579434702553, 2249121731.13779, 531.0, 8698.878168970592, 2195370702.939322, 569.0]
[2019-04-27 19:41:39,298] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.89332818e-21 1.00000000e+00 1.64093878e-25 6.34678876e-17
 1.13952635e-20], sum to 1.0000
[2019-04-27 19:41:39,307] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4185
[2019-04-27 19:41:39,313] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 65.0, 1.0, 2.0, 0.4756606995428895, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 572876.3161116237, 572876.3161116233, 139318.8255063112], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5745600.0000, 
sim time next is 5746200.0000, 
raw observation next is [26.16666666666667, 64.5, 1.0, 2.0, 0.4772146242365359, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 574294.6567772274, 574294.6567772274, 139542.0073118035], 
processed observation next is [0.0, 0.5217391304347826, 0.5246913580246916, 0.645, 1.0, 1.0, 0.3776364574244475, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20510523456329552, 0.20510523456329552, 0.26835001406116055], 
reward next is 0.7316, 
noisyNet noise sample is [array([0.28004572], dtype=float32), 1.2095939]. 
=============================================
[2019-04-27 19:41:40,700] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.1297187e-21 1.0000000e+00 5.2703464e-26 2.9807102e-18 2.8641540e-22], sum to 1.0000
[2019-04-27 19:41:40,708] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2521
[2019-04-27 19:41:40,713] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.6, 62.0, 1.0, 2.0, 0.5166185202702386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 612011.1982120979, 612011.1982120979, 145371.9529705294], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5751600.0000, 
sim time next is 5752200.0000, 
raw observation next is [27.75, 62.0, 1.0, 2.0, 0.5236494538450929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 618746.1974985617, 618746.1974985617, 146436.1104614675], 
processed observation next is [0.0, 0.5652173913043478, 0.5833333333333334, 0.62, 1.0, 1.0, 0.4329160164822534, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2209807848209149, 0.2209807848209149, 0.2816079047335913], 
reward next is 0.7184, 
noisyNet noise sample is [array([-0.51311976], dtype=float32), 1.431498]. 
=============================================
[2019-04-27 19:41:41,868] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.5338258e-22 1.0000000e+00 4.3346878e-27 1.3758958e-19 1.0371561e-25], sum to 1.0000
[2019-04-27 19:41:41,876] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6835
[2019-04-27 19:41:41,881] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.4, 78.0, 1.0, 2.0, 0.553289402404515, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 649077.0246549468, 649077.0246549468, 151085.6642364415], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5774400.0000, 
sim time next is 5775000.0000, 
raw observation next is [25.3, 78.33333333333333, 1.0, 2.0, 0.5494605032191429, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 645248.5802993374, 645248.5802993374, 150480.776316475], 
processed observation next is [0.0, 0.8695652173913043, 0.49259259259259264, 0.7833333333333333, 1.0, 1.0, 0.4636434562132653, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23044592153547763, 0.23044592153547763, 0.2893861083009135], 
reward next is 0.7106, 
noisyNet noise sample is [array([-0.4136317], dtype=float32), -0.7062304]. 
=============================================
[2019-04-27 19:41:41,896] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[73.81291]
 [73.71672]
 [73.67665]
 [73.62892]
 [73.5767 ]], R is [[73.83184814]
 [73.80297852]
 [73.77308655]
 [73.74250793]
 [73.71178436]].
[2019-04-27 19:41:42,296] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.1152079e-24 1.0000000e+00 1.6322894e-28 4.5713959e-20 1.5582229e-23], sum to 1.0000
[2019-04-27 19:41:42,302] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3403
[2019-04-27 19:41:42,311] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.95, 88.5, 1.0, 2.0, 0.5400217623548569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 656226.9849621672, 656226.9849621672, 149739.1364786768], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5799000.0000, 
sim time next is 5799600.0000, 
raw observation next is [21.9, 89.0, 1.0, 2.0, 0.5276308919112929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 641051.1475370325, 641051.1475370325, 147704.1766388214], 
processed observation next is [1.0, 0.13043478260869565, 0.36666666666666664, 0.89, 1.0, 1.0, 0.43765582370392003, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22894683840608304, 0.22894683840608304, 0.284046493536195], 
reward next is 0.7160, 
noisyNet noise sample is [array([0.8966847], dtype=float32), 2.5929499]. 
=============================================
[2019-04-27 19:41:49,798] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.10666313e-29 1.22501216e-20 0.00000000e+00 1.38940938e-18
 1.00000000e+00], sum to 1.0000
[2019-04-27 19:41:49,806] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1229
[2019-04-27 19:41:49,808] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.4, 53.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2413836586857765, 6.911199999999999, 6.9112, 121.94756008, 534116.8065997597, 534116.8065997602, 203139.4638470735], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5938200.0000, 
sim time next is 5938800.0000, 
raw observation next is [28.26666666666667, 53.66666666666667, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2446057390579573, 6.911199999999999, 6.9112, 121.94756008, 541385.6458400011, 541385.6458400015, 204073.9507281703], 
processed observation next is [1.0, 0.7391304347826086, 0.6024691358024692, 0.5366666666666667, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.055757173822446604, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.19335201637142896, 0.19335201637142913, 0.3924499052464814], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.08903331], dtype=float32), -0.33641893]. 
=============================================
[2019-04-27 19:41:51,589] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.8503725e-15 1.0000000e+00 5.0482000e-19 2.9428942e-11 4.2836763e-14], sum to 1.0000
[2019-04-27 19:41:51,598] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0749
[2019-04-27 19:41:51,603] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 81.0, 1.0, 2.0, 0.4343272330427351, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 536555.9515231199, 536555.9515231199, 133523.1124676533], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5973600.0000, 
sim time next is 5974200.0000, 
raw observation next is [21.75, 81.5, 1.0, 2.0, 0.4224077360204338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 521987.2963273998, 521987.2963273998, 131788.5213069802], 
processed observation next is [1.0, 0.13043478260869565, 0.3611111111111111, 0.815, 1.0, 1.0, 0.3123901619290878, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18642403440264277, 0.18642403440264277, 0.253439464051885], 
reward next is 0.7466, 
noisyNet noise sample is [array([-0.64549184], dtype=float32), -0.6556907]. 
=============================================
[2019-04-27 19:41:51,983] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4052719e-19 1.0000000e+00 1.4656805e-24 9.6320053e-14 8.9021905e-17], sum to 1.0000
[2019-04-27 19:41:51,993] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3667
[2019-04-27 19:41:51,996] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.6, 81.5, 1.0, 2.0, 0.444042087099989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 541860.0935732728, 541860.0935732728, 134781.5853977911], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5964600.0000, 
sim time next is 5965200.0000, 
raw observation next is [22.6, 81.0, 1.0, 2.0, 0.4407898351510403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 538454.303919212, 538454.303919212, 134316.6413874249], 
processed observation next is [1.0, 0.043478260869565216, 0.39259259259259266, 0.81, 1.0, 1.0, 0.33427361327504795, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1923051085425757, 0.1923051085425757, 0.25830123343735556], 
reward next is 0.7417, 
noisyNet noise sample is [array([-0.4130259], dtype=float32), 0.76716316]. 
=============================================
[2019-04-27 19:41:53,290] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.7847030e-19 3.5781081e-14 9.2563823e-26 3.0279921e-13 1.0000000e+00], sum to 1.0000
[2019-04-27 19:41:53,299] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5072
[2019-04-27 19:41:53,303] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.11666666666667, 70.16666666666667, 1.0, 2.0, 0.4219051216501665, 1.0, 2.0, 0.4219051216501665, 1.0, 2.0, 0.6717086271061836, 6.911200000000001, 6.9112, 121.94756008, 1444219.256843345, 1444219.256843344, 306818.6369057567], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6000600.0000, 
sim time next is 6001200.0000, 
raw observation next is [26.3, 70.0, 1.0, 2.0, 0.3788783853784281, 1.0, 2.0, 0.3788783853784281, 1.0, 2.0, 0.6031867287300244, 6.9112, 6.9112, 121.94756008, 1295863.151361088, 1295863.151361088, 287953.3606417642], 
processed observation next is [1.0, 0.4782608695652174, 0.5296296296296297, 0.7, 1.0, 1.0, 0.2605695064028906, 1.0, 1.0, 0.2605695064028906, 1.0, 1.0, 0.5039834109125305, 0.0, 0.0, 0.8096049824067558, 0.46280826834324573, 0.46280826834324573, 0.5537564627726235], 
reward next is 0.4462, 
noisyNet noise sample is [array([0.3997744], dtype=float32), 0.10738385]. 
=============================================
[2019-04-27 19:41:53,583] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.4920610e-15 1.2116990e-09 2.0183635e-20 3.1305611e-08 1.0000000e+00], sum to 1.0000
[2019-04-27 19:41:53,597] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2309
[2019-04-27 19:41:53,602] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.11666666666667, 70.16666666666667, 1.0, 2.0, 0.4219051251689468, 1.0, 2.0, 0.4219051251689468, 1.0, 2.0, 0.6717086324426018, 6.911200000000001, 6.9112, 121.94756008, 1444219.256843345, 1444219.256843344, 306818.6384012461], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6000600.0000, 
sim time next is 6001200.0000, 
raw observation next is [26.3, 70.0, 1.0, 2.0, 0.3788783853784281, 1.0, 2.0, 0.3788783853784281, 1.0, 2.0, 0.6031867287300244, 6.9112, 6.9112, 121.94756008, 1295863.151361088, 1295863.151361088, 287953.3606417642], 
processed observation next is [1.0, 0.4782608695652174, 0.5296296296296297, 0.7, 1.0, 1.0, 0.2605695064028906, 1.0, 1.0, 0.2605695064028906, 1.0, 1.0, 0.5039834109125305, 0.0, 0.0, 0.8096049824067558, 0.46280826834324573, 0.46280826834324573, 0.5537564627726235], 
reward next is 0.4462, 
noisyNet noise sample is [array([-1.9546282], dtype=float32), -0.53549314]. 
=============================================
[2019-04-27 19:42:00,189] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.5152763e-22 1.0000000e+00 8.1474156e-25 5.9416342e-19 2.0500032e-24], sum to 1.0000
[2019-04-27 19:42:00,196] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6922
[2019-04-27 19:42:00,200] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 83.0, 1.0, 2.0, 0.5364251541512274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 632764.8064042099, 632764.8064042099, 148461.1885085593], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6138000.0000, 
sim time next is 6138600.0000, 
raw observation next is [24.26666666666667, 84.0, 1.0, 2.0, 0.5376291155636106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 634117.8633293684, 634117.863329368, 148654.7841930868], 
processed observation next is [1.0, 0.043478260869565216, 0.4543209876543211, 0.84, 1.0, 1.0, 0.4495584709090602, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22647066547477443, 0.22647066547477426, 0.28587458498670537], 
reward next is 0.7141, 
noisyNet noise sample is [array([2.1820798], dtype=float32), -2.3428428]. 
=============================================
[2019-04-27 19:42:01,899] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.9130300e-21 1.0000000e+00 5.8721031e-25 3.9410491e-18 1.2332108e-23], sum to 1.0000
[2019-04-27 19:42:01,904] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8002
[2019-04-27 19:42:01,911] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.1, 78.0, 1.0, 2.0, 0.6541449564695797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 745514.7845746785, 745514.7845746785, 167643.1314047589], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6340800.0000, 
sim time next is 6341400.0000, 
raw observation next is [27.35, 77.0, 1.0, 2.0, 0.6603217940671595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 752557.8477347752, 752557.8477347752, 168766.9531328925], 
processed observation next is [0.0, 0.391304347826087, 0.5685185185185185, 0.77, 1.0, 1.0, 0.5956211834132851, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2687706599052768, 0.2687706599052768, 0.32455183294787016], 
reward next is 0.6754, 
noisyNet noise sample is [array([-0.42935324], dtype=float32), -0.117964715]. 
=============================================
[2019-04-27 19:42:02,006] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2541764e-14 1.0000000e+00 1.6753925e-17 7.7780881e-13 9.0315248e-16], sum to 1.0000
[2019-04-27 19:42:02,015] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8817
[2019-04-27 19:42:02,022] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1486734.779845041 W.
[2019-04-27 19:42:02,027] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.11666666666667, 79.16666666666666, 1.0, 2.0, 0.6475245229583203, 1.0, 1.0, 0.6475245229583203, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156363, 1486734.779845041, 1486734.779845041, 285282.6500737552], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6166200.0000, 
sim time next is 6166800.0000, 
raw observation next is [25.3, 78.0, 1.0, 2.0, 0.438489520108134, 1.0, 2.0, 0.438489520108134, 1.0, 1.0, 0.6980895966188383, 6.911199999999999, 6.9112, 121.94756008, 1499948.435737553, 1499948.435737554, 314352.8817544946], 
processed observation next is [1.0, 0.391304347826087, 0.49259259259259264, 0.78, 1.0, 1.0, 0.33153514298587383, 1.0, 1.0, 0.33153514298587383, 1.0, 0.5, 0.6226119957735479, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5356958699062689, 0.5356958699062693, 0.6045247726047973], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5209973], dtype=float32), -0.6847958]. 
=============================================
[2019-04-27 19:42:15,121] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.0393569e-16 1.0000000e+00 3.4031281e-19 1.1273183e-13 6.4206686e-18], sum to 1.0000
[2019-04-27 19:42:15,130] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9273
[2019-04-27 19:42:15,138] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.7, 92.0, 1.0, 2.0, 0.8372517426894857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156519, 956478.9372993957, 956478.9372993957, 203867.2447140726], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6411600.0000, 
sim time next is 6412200.0000, 
raw observation next is [24.73333333333333, 92.0, 1.0, 2.0, 0.8521304787684283, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 973127.4189587552, 973127.4189587552, 207039.8124722378], 
processed observation next is [1.0, 0.21739130434782608, 0.4716049382716048, 0.92, 1.0, 1.0, 0.8239648556767003, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.347545506770984, 0.347545506770984, 0.39815348552353425], 
reward next is 0.6018, 
noisyNet noise sample is [array([-0.19247337], dtype=float32), -0.68883926]. 
=============================================
[2019-04-27 19:42:16,061] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.3707402e-11 9.1745016e-05 8.5558274e-16 1.2164346e-05 9.9989605e-01], sum to 1.0000
[2019-04-27 19:42:16,066] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4023
[2019-04-27 19:42:16,069] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.23333333333333, 55.0, 1.0, 2.0, 0.6622460445836734, 1.0, 2.0, 0.6444876842682715, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2205496.528986576, 2205496.528986575, 419249.0207434751], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6443400.0000, 
sim time next is 6444000.0000, 
raw observation next is [32.4, 54.0, 1.0, 2.0, 0.6644157685925799, 1.0, 2.0, 0.6455725462727248, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2209213.619547332, 2209213.619547332, 419814.8617980005], 
processed observation next is [1.0, 0.6086956521739131, 0.7555555555555555, 0.54, 1.0, 1.0, 0.6004949626102142, 1.0, 1.0, 0.5780625550865771, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8096049824067558, 0.7890048641240472, 0.7890048641240472, 0.8073362726884625], 
reward next is 0.1927, 
noisyNet noise sample is [array([-0.3217202], dtype=float32), -2.0513754]. 
=============================================
[2019-04-27 19:42:16,082] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[58.79867 ]
 [58.557484]
 [58.8192  ]
 [58.993195]
 [59.20039 ]], R is [[58.28384781]
 [57.89476395]
 [57.51536942]
 [57.14590073]
 [56.80952454]].
[2019-04-27 19:42:16,138] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.9522194e-11 9.9999750e-01 6.0611082e-15 6.2809526e-08 2.4325893e-06], sum to 1.0000
[2019-04-27 19:42:16,147] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2229
[2019-04-27 19:42:16,151] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.5, 37.5, 1.0, 2.0, 0.7910893587361623, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 985446.1235311514, 985446.1235311514, 197432.1920625464], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6611400.0000, 
sim time next is 6612000.0000, 
raw observation next is [28.66666666666666, 36.66666666666667, 1.0, 2.0, 0.7329501626942942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 918923.4534797218, 918923.4534797218, 185607.3581170361], 
processed observation next is [1.0, 0.5217391304347826, 0.6172839506172837, 0.3666666666666667, 1.0, 1.0, 0.6820835270170169, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3281869476713292, 0.3281869476713292, 0.35693722714814635], 
reward next is 0.6431, 
noisyNet noise sample is [array([-1.0117773], dtype=float32), 0.37775034]. 
=============================================
[2019-04-27 19:42:16,175] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[50.809715]
 [52.405952]
 [52.259243]
 [52.219646]
 [52.058414]], R is [[51.7604866 ]
 [51.86320496]
 [51.86396408]
 [51.81192017]
 [51.77230453]].
[2019-04-27 19:42:20,409] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.6639269e-06 6.7638890e-03 7.9493647e-09 4.0687346e-03 9.8916376e-01], sum to 1.0000
[2019-04-27 19:42:20,418] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2428
[2019-04-27 19:42:20,429] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.36666666666667, 84.0, 1.0, 2.0, 0.5925439332953969, 1.0, 2.0, 0.5925439332953969, 1.0, 2.0, 0.9433492396149291, 6.911200000000001, 6.9112, 121.94756008, 2027538.423043923, 2027538.423043923, 391328.1116155252], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6513600.0000, 
sim time next is 6514200.0000, 
raw observation next is [27.5, 83.5, 1.0, 2.0, 0.6075752972010782, 1.0, 2.0, 0.6075752972010782, 1.0, 2.0, 0.9672796604901197, 6.911199999999999, 6.9112, 121.94756008, 2079031.886989111, 2079031.886989111, 399518.4544867514], 
processed observation next is [1.0, 0.391304347826087, 0.5740740740740741, 0.835, 1.0, 1.0, 0.5328277347631882, 1.0, 1.0, 0.5328277347631882, 1.0, 1.0, 0.9590995756126497, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7425113882103969, 0.7425113882103969, 0.7683047201668296], 
reward next is 0.2317, 
noisyNet noise sample is [array([0.7116327], dtype=float32), -1.7196041]. 
=============================================
[2019-04-27 19:42:22,888] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.7403921e-17 1.0000000e+00 1.0665693e-19 1.1003075e-13 1.1286337e-19], sum to 1.0000
[2019-04-27 19:42:22,899] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6524
[2019-04-27 19:42:22,904] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 55.33333333333333, 1.0, 2.0, 0.4016593484904655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 497441.1045848861, 497441.1045848861, 128847.7229830337], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6572400.0000, 
sim time next is 6573000.0000, 
raw observation next is [25.63333333333333, 53.66666666666666, 1.0, 2.0, 0.3885985542534029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 483308.9249505846, 483308.9249505841, 127063.4032977015], 
processed observation next is [1.0, 0.043478260869565216, 0.5049382716049381, 0.5366666666666666, 1.0, 1.0, 0.27214113601595585, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1726103303394945, 0.17261033033949433, 0.24435269864942596], 
reward next is 0.7556, 
noisyNet noise sample is [array([1.2365344], dtype=float32), 0.4114098]. 
=============================================
[2019-04-27 19:42:22,924] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[57.195507]
 [57.26187 ]
 [57.205315]
 [57.31952 ]
 [57.39562 ]], R is [[57.5394783 ]
 [57.71630096]
 [57.88786316]
 [58.05403519]
 [58.21470261]].
[2019-04-27 19:42:24,286] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.0272180e-19 1.0000000e+00 2.5076023e-22 2.5440428e-14 1.1624892e-20], sum to 1.0000
[2019-04-27 19:42:24,294] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6593
[2019-04-27 19:42:24,303] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.3, 47.0, 1.0, 2.0, 0.6926809955517812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 876584.4494351948, 876584.4494351948, 177797.0259287853], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6598800.0000, 
sim time next is 6599400.0000, 
raw observation next is [25.46666666666667, 46.16666666666667, 1.0, 2.0, 0.716426016812558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 906621.9537029372, 906621.9537029372, 182442.2316892932], 
processed observation next is [1.0, 0.391304347826087, 0.4987654320987655, 0.4616666666666667, 1.0, 1.0, 0.6624119247768547, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.32379355489390615, 0.32379355489390615, 0.3508504455563331], 
reward next is 0.6491, 
noisyNet noise sample is [array([-0.61703706], dtype=float32), -0.3550452]. 
=============================================
[2019-04-27 19:42:25,792] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-04-27 19:42:25,793] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 19:42:25,794] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 19:42:25,795] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:42:25,797] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:42:25,797] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 19:42:25,800] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 19:42:25,802] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:42:25,803] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:42:25,799] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 19:42:25,806] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:42:25,820] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run42
[2019-04-27 19:42:25,839] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run42
[2019-04-27 19:42:25,862] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run42
[2019-04-27 19:42:25,865] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run42
[2019-04-27 19:42:25,865] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run42
[2019-04-27 19:42:33,166] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.07087468]
[2019-04-27 19:42:33,168] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [17.83333333333333, 79.66666666666667, 1.0, 2.0, 0.4893314134260517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 122.2899110003664, 631321.7353477225, 631321.7353477225, 140651.2944463608]
[2019-04-27 19:42:33,168] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 19:42:33,170] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.2534318e-19 1.0000000e+00 3.8777196e-23 2.7046094e-14 1.5534823e-21], sampled 0.10919296035357728
[2019-04-27 19:42:36,434] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.07087468]
[2019-04-27 19:42:36,435] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.0, 29.0, 1.0, 2.0, 0.3442912217015366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 439072.3724915865, 439072.372491586, 121222.2391528206]
[2019-04-27 19:42:36,436] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 19:42:36,439] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.9715112e-20 1.0000000e+00 1.1975463e-23 2.2670298e-14 1.3787684e-21], sampled 0.882822392464371
[2019-04-27 19:42:50,140] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.07087468]
[2019-04-27 19:42:50,140] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [18.4, 88.0, 1.0, 2.0, 0.3124994016960991, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 398291.2026140673, 398291.2026140668, 117132.2620315457]
[2019-04-27 19:42:50,143] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 19:42:50,145] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.8812201e-19 1.0000000e+00 1.4106837e-22 6.9482411e-14 5.9444846e-21], sampled 0.382560596636345
[2019-04-27 19:42:51,423] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.07087468]
[2019-04-27 19:42:51,424] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.46352635, 73.57224055, 1.0, 2.0, 0.3961558722697288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 491976.7022138068, 491976.7022138068, 128103.4276789852]
[2019-04-27 19:42:51,425] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 19:42:51,428] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.8397279e-18 1.0000000e+00 7.6239315e-22 2.9860551e-13 5.6619363e-20], sampled 0.9558869145714517
[2019-04-27 19:43:01,617] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.07087468]
[2019-04-27 19:43:01,619] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [34.48162482666667, 19.29954985666667, 1.0, 2.0, 0.5465764058556136, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 688373.2287981799, 688373.2287981799, 151386.6702924499]
[2019-04-27 19:43:01,623] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 19:43:01,626] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.14796077e-19 1.00000000e+00 1.03185783e-22 1.28257038e-13
 1.92528210e-20], sampled 0.8238026960625162
[2019-04-27 19:43:23,625] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.07087468]
[2019-04-27 19:43:23,626] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.33333333333334, 87.33333333333334, 1.0, 2.0, 0.903821914239751, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1745447.258606262, 1745447.258606262, 357793.4764073253]
[2019-04-27 19:43:23,627] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 19:43:23,629] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.5578132e-09 9.6434748e-01 3.8312062e-13 2.8584737e-02 7.0677884e-03], sampled 0.354544593445839
[2019-04-27 19:43:23,630] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1745447.258606262 W.
[2019-04-27 19:44:18,246] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.7839 2121096978.5736 421.0000
[2019-04-27 19:44:18,656] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8586.5201 2249030659.1591 514.0000
[2019-04-27 19:44:18,689] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8710.6878 2195666873.7945 544.0000
[2019-04-27 19:44:18,714] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8128.3755 2445770223.3577 606.0000
[2019-04-27 19:44:18,790] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8773.1746 2170723020.5766 476.0000
[2019-04-27 19:44:19,807] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1025000, evaluation results [1025000.0, 8128.375531367642, 2445770223.3577127, 606.0, 8773.174628856028, 2170723020.5765924, 476.0, 8924.783919468784, 2121096978.5736177, 421.0, 8586.52012287211, 2249030659.159085, 514.0, 8710.687757651742, 2195666873.794481, 544.0]
[2019-04-27 19:44:22,868] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.2483737e-20 1.0000000e+00 1.6498407e-23 4.0829601e-15 1.9131280e-21], sum to 1.0000
[2019-04-27 19:44:22,882] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1846
[2019-04-27 19:44:22,886] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.43333333333334, 50.33333333333334, 1.0, 2.0, 0.4705817381555523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 602336.7627038907, 602336.7627038902, 139251.9643351559], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6682800.0000, 
sim time next is 6683400.0000, 
raw observation next is [23.65, 49.5, 1.0, 2.0, 0.5153395514461533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 659140.0654743013, 659140.0654743013, 146323.5384411184], 
processed observation next is [1.0, 0.34782608695652173, 0.4314814814814814, 0.495, 1.0, 1.0, 0.42302327553113483, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23540716624082192, 0.23540716624082192, 0.28139142007907386], 
reward next is 0.7186, 
noisyNet noise sample is [array([1.3273444], dtype=float32), 0.13914838]. 
=============================================
[2019-04-27 19:44:29,052] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.6523694e-22 1.0000000e+00 1.6280182e-27 9.7727527e-15 1.0245793e-27], sum to 1.0000
[2019-04-27 19:44:29,068] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0242
[2019-04-27 19:44:29,072] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.83333333333334, 65.83333333333334, 1.0, 2.0, 0.4718105638330459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 568422.0054060986, 568422.0054060986, 138736.1645923495], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6808200.0000, 
sim time next is 6808800.0000, 
raw observation next is [25.66666666666667, 66.66666666666667, 1.0, 2.0, 0.4718307697336458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 568668.5849233386, 568668.5849233386, 138746.6887451666], 
processed observation next is [1.0, 0.8260869565217391, 0.506172839506173, 0.6666666666666667, 1.0, 1.0, 0.37122710682576876, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20309592318690664, 0.20309592318690664, 0.26682055527916654], 
reward next is 0.7332, 
noisyNet noise sample is [array([-0.7881863], dtype=float32), 0.2609745]. 
=============================================
[2019-04-27 19:44:30,375] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.6889594e-21 1.0000000e+00 3.9729562e-27 3.3621626e-17 2.6763294e-25], sum to 1.0000
[2019-04-27 19:44:30,384] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6501
[2019-04-27 19:44:30,386] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.36666666666667, 78.0, 1.0, 2.0, 0.4197682799386124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 517789.1971246097, 517789.1971246097, 131384.4112793922], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7004400.0000, 
sim time next is 7005000.0000, 
raw observation next is [22.28333333333333, 78.5, 1.0, 2.0, 0.4181989180339231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 515949.271886863, 515949.271886863, 131160.5728911365], 
processed observation next is [1.0, 0.043478260869565216, 0.38086419753086415, 0.785, 1.0, 1.0, 0.307379664326099, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18426759710245108, 0.18426759710245108, 0.25223187094449323], 
reward next is 0.7478, 
noisyNet noise sample is [array([0.41178367], dtype=float32), 1.1678326]. 
=============================================
[2019-04-27 19:44:30,414] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[68.023735]
 [68.17851 ]
 [68.42641 ]
 [68.513855]
 [68.682465]], R is [[68.13154602]
 [68.1975708 ]
 [68.26303101]
 [68.32802582]
 [68.39253998]].
[2019-04-27 19:44:34,290] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.2959893e-21 1.0000000e+00 4.6137585e-27 1.1763214e-14 3.2383819e-26], sum to 1.0000
[2019-04-27 19:44:34,291] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4549
[2019-04-27 19:44:34,459] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 64.0, 1.0, 2.0, 0.4252317168601469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 522453.933686141, 522453.933686141, 132122.5590049238], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6903600.0000, 
sim time next is 6904200.0000, 
raw observation next is [24.65, 64.5, 1.0, 2.0, 0.4233873475125478, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 520648.1975017693, 520648.1975017689, 131867.1965551804], 
processed observation next is [0.0, 0.9130434782608695, 0.46851851851851845, 0.645, 1.0, 1.0, 0.3135563660863664, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18594578482206045, 0.1859457848220603, 0.2535907626061161], 
reward next is 0.7464, 
noisyNet noise sample is [array([-0.6937613], dtype=float32), 0.1564426]. 
=============================================
[2019-04-27 19:44:44,777] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.3142319e-14 9.9998510e-01 9.2520058e-19 1.4940519e-05 4.1910282e-14], sum to 1.0000
[2019-04-27 19:44:44,784] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3604
[2019-04-27 19:44:44,790] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.26666666666667, 84.33333333333333, 1.0, 2.0, 0.3977179319427046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 492271.9335637794, 492271.9335637789, 128286.4202114219], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7101600.0000, 
sim time next is 7102200.0000, 
raw observation next is [21.13333333333333, 85.16666666666667, 1.0, 2.0, 0.3954878468858765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 489691.2734287261, 489691.2734287261, 127977.7578435989], 
processed observation next is [1.0, 0.17391304347826086, 0.33827160493827146, 0.8516666666666667, 1.0, 1.0, 0.2803426748641387, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17488974051025932, 0.17488974051025932, 0.24611107277615174], 
reward next is 0.7539, 
noisyNet noise sample is [array([0.08961862], dtype=float32), 0.41087815]. 
=============================================
[2019-04-27 19:44:46,493] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.3132235e-14 9.9999213e-01 6.8618324e-17 7.9048832e-06 1.0423010e-12], sum to 1.0000
[2019-04-27 19:44:46,501] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4348
[2019-04-27 19:44:46,505] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.6, 75.33333333333334, 1.0, 2.0, 0.8331985555587066, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1014719.888952674, 1014719.888952674, 205801.598434542], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7298400.0000, 
sim time next is 7299000.0000, 
raw observation next is [23.8, 74.5, 1.0, 2.0, 0.8605262614850931, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1046686.124343584, 1046686.124343584, 211753.3352452505], 
processed observation next is [1.0, 0.4782608695652174, 0.43703703703703706, 0.745, 1.0, 1.0, 0.8339598351013013, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.37381647297985143, 0.37381647297985143, 0.4072179523947125], 
reward next is 0.5928, 
noisyNet noise sample is [array([-1.1460671], dtype=float32), 0.7803651]. 
=============================================
[2019-04-27 19:44:46,516] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[57.639774]
 [57.53496 ]
 [57.037827]
 [56.317543]
 [56.36482 ]], R is [[57.90821075]
 [57.93335724]
 [57.98334503]
 [58.05110931]
 [58.10059357]].
[2019-04-27 19:44:50,223] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.0734844e-23 1.0000000e+00 1.9264244e-24 9.5936070e-15 2.2241456e-24], sum to 1.0000
[2019-04-27 19:44:50,231] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0312
[2019-04-27 19:44:50,234] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.65, 92.5, 1.0, 2.0, 0.3927668850734701, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 490158.2920594907, 490158.2920594902, 127677.2524216326], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7187400.0000, 
sim time next is 7188000.0000, 
raw observation next is [19.63333333333333, 92.33333333333333, 1.0, 2.0, 0.3800729449551913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 474551.2949743198, 474551.2949743198, 125921.6284981176], 
processed observation next is [1.0, 0.17391304347826086, 0.2827160493827159, 0.9233333333333333, 1.0, 1.0, 0.2619916011371325, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16948260534797135, 0.16948260534797135, 0.24215697788099538], 
reward next is 0.7578, 
noisyNet noise sample is [array([-0.5196038], dtype=float32), -1.164876]. 
=============================================
[2019-04-27 19:44:50,258] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[73.8088 ]
 [73.895  ]
 [73.94912]
 [74.16798]
 [74.1881 ]], R is [[73.78042603]
 [73.79708862]
 [73.81382751]
 [73.82488251]
 [73.84673309]].
[2019-04-27 19:44:50,650] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.3150362e-20 1.0000000e+00 1.5846213e-24 1.2164280e-12 7.4033271e-24], sum to 1.0000
[2019-04-27 19:44:50,665] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4656
[2019-04-27 19:44:50,668] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.93333333333333, 90.0, 1.0, 2.0, 0.3643296771383147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 454894.6098204996, 454894.6098204996, 123778.5622634611], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7191600.0000, 
sim time next is 7192200.0000, 
raw observation next is [20.01666666666667, 89.5, 1.0, 2.0, 0.3643130361611581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 454737.3940543436, 454737.3940543436, 123773.7732925298], 
processed observation next is [1.0, 0.21739130434782608, 0.29691358024691367, 0.895, 1.0, 1.0, 0.24322980495375968, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16240621216226556, 0.16240621216226556, 0.23802648710101884], 
reward next is 0.7620, 
noisyNet noise sample is [array([0.14992318], dtype=float32), -0.72740144]. 
=============================================
[2019-04-27 19:44:54,578] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.6899188e-20 1.0000000e+00 1.5923913e-22 7.6858298e-09 3.7531890e-21], sum to 1.0000
[2019-04-27 19:44:54,583] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0629
[2019-04-27 19:44:54,588] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.23333333333333, 89.33333333333334, 1.0, 2.0, 0.5595378203740596, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 686600.3761833212, 686600.3761833212, 153188.3629653082], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7287600.0000, 
sim time next is 7288200.0000, 
raw observation next is [21.35, 88.5, 1.0, 2.0, 0.6479486298418465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 794697.7834808667, 794697.7834808667, 168801.9979568262], 
processed observation next is [1.0, 0.34782608695652173, 0.3462962962962963, 0.885, 1.0, 1.0, 0.5808912260021982, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2838206369574524, 0.2838206369574524, 0.3246192268400504], 
reward next is 0.6754, 
noisyNet noise sample is [array([0.10465571], dtype=float32), 0.24575382]. 
=============================================
[2019-04-27 19:44:55,008] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.2788740e-15 9.9999809e-01 5.2952029e-19 1.8760712e-06 1.2988570e-14], sum to 1.0000
[2019-04-27 19:44:55,014] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1667
[2019-04-27 19:44:55,018] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.58333333333333, 86.83333333333333, 1.0, 2.0, 0.682821191814302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 836973.9345719052, 836973.9345719047, 175331.1587691557], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7289400.0000, 
sim time next is 7290000.0000, 
raw observation next is [21.7, 86.0, 1.0, 2.0, 0.6449332156307481, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 790432.9902705422, 790432.9902705422, 168230.1681527025], 
processed observation next is [1.0, 0.391304347826087, 0.3592592592592592, 0.86, 1.0, 1.0, 0.5773014471794621, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28229749652519365, 0.28229749652519365, 0.32351955413981254], 
reward next is 0.6765, 
noisyNet noise sample is [array([-1.510114], dtype=float32), 0.7604783]. 
=============================================
[2019-04-27 19:44:55,031] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[63.136223]
 [63.016224]
 [63.00411 ]
 [63.211815]
 [63.53391 ]], R is [[63.39644623]
 [63.42530823]
 [63.4560585 ]
 [63.49687958]
 [63.56731796]].
[2019-04-27 19:44:59,695] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.2923965e-19 1.0000000e+00 6.3930136e-22 3.9391393e-11 8.8052661e-23], sum to 1.0000
[2019-04-27 19:44:59,702] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4724
[2019-04-27 19:44:59,707] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 96.0, 1.0, 2.0, 0.3789534873130062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 471995.0521062265, 471995.0521062265, 125745.5189083229], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7363800.0000, 
sim time next is 7364400.0000, 
raw observation next is [19.36666666666667, 96.0, 1.0, 2.0, 0.3814648601614822, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 475338.084300661, 475338.084300661, 126095.0766824331], 
processed observation next is [1.0, 0.21739130434782608, 0.27283950617283964, 0.96, 1.0, 1.0, 0.26364864304938357, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16976360153595035, 0.16976360153595035, 0.2424905320816021], 
reward next is 0.7575, 
noisyNet noise sample is [array([-1.4003944], dtype=float32), -0.5063454]. 
=============================================
[2019-04-27 19:45:00,068] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.7951800e-13 9.9960917e-01 6.6805286e-18 3.9081209e-04 5.3796614e-14], sum to 1.0000
[2019-04-27 19:45:00,076] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3756
[2019-04-27 19:45:00,081] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.03333333333333, 94.33333333333334, 1.0, 2.0, 0.72142061080515, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 892474.5893471083, 892474.5893471083, 183048.3396612749], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7386000.0000, 
sim time next is 7386600.0000, 
raw observation next is [20.11666666666666, 94.16666666666667, 1.0, 2.0, 0.7149092479694468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 883661.3331055801, 883661.3331055801, 181743.9735551173], 
processed observation next is [1.0, 0.4782608695652174, 0.30061728395061704, 0.9416666666666668, 1.0, 1.0, 0.6606062475826747, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3155933332519929, 0.3155933332519929, 0.34950764145214863], 
reward next is 0.6505, 
noisyNet noise sample is [array([-1.4404562], dtype=float32), 0.6249835]. 
=============================================
[2019-04-27 19:45:09,486] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-04-27 19:45:09,488] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 19:45:09,488] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:45:09,488] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 19:45:09,489] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 19:45:09,491] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:45:09,491] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 19:45:09,490] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 19:45:09,493] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:45:09,494] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:45:09,495] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:45:09,515] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run43
[2019-04-27 19:45:09,537] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run43
[2019-04-27 19:45:09,539] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run43
[2019-04-27 19:45:09,561] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run43
[2019-04-27 19:45:09,587] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run43
[2019-04-27 19:45:29,501] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.07757378]
[2019-04-27 19:45:29,502] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [37.56666666666667, 16.66666666666667, 1.0, 2.0, 0.6742877158419096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 834944.7001326082, 834944.7001326077, 173935.0199183174]
[2019-04-27 19:45:29,503] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 19:45:29,505] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.4958951e-20 1.0000000e+00 6.0950162e-24 1.1475527e-09 1.1742543e-22], sampled 0.08651019875034671
[2019-04-27 19:46:10,644] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.07757378]
[2019-04-27 19:46:10,647] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.16666666666667, 54.83333333333333, 1.0, 2.0, 0.6841393981168816, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 832492.2256096203, 832492.2256096203, 175396.7689632603]
[2019-04-27 19:46:10,648] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 19:46:10,651] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.8771791e-19 1.0000000e+00 1.9280280e-23 6.8754702e-10 1.3715338e-22], sampled 0.030768004864801468
[2019-04-27 19:46:38,762] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.07757378]
[2019-04-27 19:46:38,762] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.62676697, 87.74395235333333, 1.0, 2.0, 0.4893714203936079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 588543.9782720611, 588543.9782720611, 141407.9143261556]
[2019-04-27 19:46:38,763] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 19:46:38,769] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0770890e-20 1.0000000e+00 7.3511483e-25 8.7087455e-11 2.9185700e-24], sampled 0.22071478414222567
[2019-04-27 19:46:45,330] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.07757378]
[2019-04-27 19:46:45,332] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.07568571, 67.07064029, 1.0, 2.0, 0.2846472331476894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 363408.3180280699, 363408.3180280699, 113700.2588089979]
[2019-04-27 19:46:45,333] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 19:46:45,335] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.3559453e-21 1.0000000e+00 1.6861828e-25 1.7653955e-11 2.4521465e-25], sampled 0.8645342159446678
[2019-04-27 19:46:53,742] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.07757378]
[2019-04-27 19:46:53,742] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.0, 68.0, 1.0, 2.0, 0.601065320520703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 690786.964271808, 690786.964271808, 158544.6615641284]
[2019-04-27 19:46:53,744] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 19:46:53,747] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.9054815e-20 1.0000000e+00 1.2670383e-24 2.0753502e-10 7.9909622e-24], sampled 0.7081966502567979
[2019-04-27 19:46:54,918] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.07757378]
[2019-04-27 19:46:54,919] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.5, 64.66666666666667, 1.0, 2.0, 0.2732412316355345, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 348568.4966775199, 348568.4966775199, 112332.9146718688]
[2019-04-27 19:46:54,920] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 19:46:54,927] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.5072039e-21 1.0000000e+00 9.6233160e-26 1.4455176e-11 1.4840432e-25], sampled 0.35811537938255245
[2019-04-27 19:47:01,786] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8720.1925 2190720427.8927 544.0000
[2019-04-27 19:47:02,336] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8781.8930 2167451091.3835 475.0000
[2019-04-27 19:47:02,339] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8154.0908 2435090792.0100 650.0000
[2019-04-27 19:47:02,354] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8929.3039 2118415782.0611 421.0000
[2019-04-27 19:47:02,419] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8603.7166 2241956665.3665 511.0000
[2019-04-27 19:47:03,435] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1050000, evaluation results [1050000.0, 8154.090803944635, 2435090792.009977, 650.0, 8781.893020177213, 2167451091.383532, 475.0, 8929.303913236867, 2118415782.0611494, 421.0, 8603.716611100526, 2241956665.3664846, 511.0, 8720.192461408196, 2190720427.8926764, 544.0]
[2019-04-27 19:47:12,076] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.2045988e-19 1.0000000e+00 1.7225027e-21 4.7357208e-11 7.3534872e-22], sum to 1.0000
[2019-04-27 19:47:12,078] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8556
[2019-04-27 19:47:12,084] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.43333333333333, 77.0, 1.0, 2.0, 0.7026868825771038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 867569.8130191348, 867569.8130191348, 179327.1831249861], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7723200.0000, 
sim time next is 7723800.0000, 
raw observation next is [22.8, 75.5, 1.0, 2.0, 0.7251282902196988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 893425.433933542, 893425.433933542, 183688.1695104371], 
processed observation next is [1.0, 0.391304347826087, 0.4, 0.755, 1.0, 1.0, 0.67277177407107, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31908051211912214, 0.31908051211912214, 0.35324647982776364], 
reward next is 0.6468, 
noisyNet noise sample is [array([-0.20779894], dtype=float32), 0.15964824]. 
=============================================
[2019-04-27 19:47:12,799] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2960041e-12 1.4540302e-06 6.2886398e-18 9.9987149e-01 1.2704309e-04], sum to 1.0000
[2019-04-27 19:47:12,805] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0834
[2019-04-27 19:47:12,811] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.4, 51.0, 1.0, 2.0, 0.4488093310475253, 1.0, 2.0, 0.4488093310475253, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1066295.07638999, 1066295.07638999, 221894.4026955074], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7736400.0000, 
sim time next is 7737000.0000, 
raw observation next is [28.6, 50.0, 1.0, 2.0, 0.4262846275685679, 1.0, 2.0, 0.4262846275685679, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1013709.376563312, 1013709.376563312, 215356.8900042976], 
processed observation next is [1.0, 0.5652173913043478, 0.6148148148148148, 0.5, 1.0, 1.0, 0.31700550901019986, 1.0, 1.0, 0.31700550901019986, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3620390630583257, 0.3620390630583257, 0.41414786539288], 
reward next is 0.5859, 
noisyNet noise sample is [array([0.38667282], dtype=float32), -0.90839463]. 
=============================================
[2019-04-27 19:47:12,832] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[73.89295 ]
 [73.504524]
 [73.16929 ]
 [72.793045]
 [72.28631 ]], R is [[74.10836029]
 [73.94055939]
 [73.76905823]
 [73.60019684]
 [73.43202209]].
[2019-04-27 19:47:15,234] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.7407041e-17 1.0000000e+00 4.9272673e-21 2.3627784e-08 3.9298139e-21], sum to 1.0000
[2019-04-27 19:47:15,239] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5392
[2019-04-27 19:47:15,244] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.06666666666667, 72.0, 1.0, 2.0, 0.3880338432937605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 491238.85314851, 491238.8531485095, 127119.0357887715], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7784400.0000, 
sim time next is 7785000.0000, 
raw observation next is [21.1, 71.5, 1.0, 2.0, 0.3617771086920903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 458227.8575588129, 458227.8575588129, 123527.794654248], 
processed observation next is [1.0, 0.08695652173913043, 0.3370370370370371, 0.715, 1.0, 1.0, 0.24021084368105988, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1636528062710046, 0.1636528062710046, 0.23755345125816923], 
reward next is 0.7624, 
noisyNet noise sample is [array([-0.69453144], dtype=float32), 0.34334326]. 
=============================================
[2019-04-27 19:47:15,260] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[63.029152]
 [63.25319 ]
 [63.205124]
 [63.302925]
 [63.431778]], R is [[62.5609169 ]
 [62.69084549]
 [62.8026123 ]
 [62.94562912]
 [63.08681488]].
[2019-04-27 19:47:15,579] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:47:15,579] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:47:15,638] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run6
[2019-04-27 19:47:15,979] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:47:15,979] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:47:16,022] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run6
[2019-04-27 19:47:17,254] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3644300e-10 7.0962051e-05 2.7030337e-13 9.9992788e-01 1.2019564e-06], sum to 1.0000
[2019-04-27 19:47:17,260] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7445
[2019-04-27 19:47:17,265] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 34.0, 1.0, 2.0, 0.5446735503571245, 1.0, 2.0, 0.5446735503571245, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1316650.701977508, 1316650.701977508, 252682.8583789239], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7832400.0000, 
sim time next is 7833000.0000, 
raw observation next is [31.0, 33.5, 1.0, 2.0, 0.5458094151255162, 1.0, 2.0, 0.5458094151255162, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1321258.767574937, 1321258.767574937, 253121.1157434258], 
processed observation next is [1.0, 0.6521739130434783, 0.7037037037037037, 0.335, 1.0, 1.0, 0.4592969227684716, 1.0, 1.0, 0.4592969227684716, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.47187813127676326, 0.47187813127676326, 0.486771376429665], 
reward next is 0.5132, 
noisyNet noise sample is [array([-0.46141663], dtype=float32), -1.1008171]. 
=============================================
[2019-04-27 19:47:17,278] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[52.462086]
 [52.41983 ]
 [52.25664 ]
 [52.355034]
 [51.94958 ]], R is [[52.58726501]
 [52.57546616]
 [52.57296753]
 [52.5665741 ]
 [52.55065155]].
[2019-04-27 19:47:17,740] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.0958454e-14 4.4475578e-07 3.7807091e-19 9.9999952e-01 2.9266292e-09], sum to 1.0000
[2019-04-27 19:47:17,749] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2904
[2019-04-27 19:47:17,756] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.73333333333333, 36.66666666666667, 1.0, 2.0, 0.5316594006505796, 1.0, 2.0, 0.5316594006505796, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1277969.018783156, 1277969.018783156, 248155.2029144199], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7827600.0000, 
sim time next is 7828200.0000, 
raw observation next is [30.8, 36.5, 1.0, 2.0, 0.5296378486353078, 1.0, 2.0, 0.5296378486353078, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1273534.063735993, 1273534.063735994, 247511.7627663306], 
processed observation next is [1.0, 0.6086956521739131, 0.6962962962962963, 0.365, 1.0, 1.0, 0.440045057899176, 1.0, 1.0, 0.440045057899176, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4548335941914261, 0.45483359419142644, 0.4759841591660204], 
reward next is 0.5240, 
noisyNet noise sample is [array([0.9174387], dtype=float32), -1.1225983]. 
=============================================
[2019-04-27 19:47:23,607] A3C_AGENT_WORKER-Thread-22 INFO:Local step 66500, global step 1060349: loss 0.0106
[2019-04-27 19:47:23,608] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 66500, global step 1060349: learning rate 0.0000
[2019-04-27 19:47:23,649] A3C_AGENT_WORKER-Thread-13 INFO:Local step 66500, global step 1060371: loss 0.0151
[2019-04-27 19:47:23,650] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 66500, global step 1060371: learning rate 0.0000
[2019-04-27 19:47:23,843] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:47:23,843] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:47:23,855] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run6
[2019-04-27 19:47:24,150] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:47:24,151] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:47:24,164] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run6
[2019-04-27 19:47:24,217] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:47:24,217] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:47:24,225] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run6
[2019-04-27 19:47:24,241] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:47:24,243] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:47:24,263] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run6
[2019-04-27 19:47:24,279] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:47:24,281] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:47:24,285] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:47:24,285] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:47:24,288] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run6
[2019-04-27 19:47:24,313] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:47:24,314] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:47:24,317] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:47:24,317] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:47:24,330] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run6
[2019-04-27 19:47:24,331] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run6
[2019-04-27 19:47:24,355] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:47:24,356] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:47:24,389] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run6
[2019-04-27 19:47:24,389] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:47:24,390] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:47:24,421] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run6
[2019-04-27 19:47:24,455] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run6
[2019-04-27 19:47:24,523] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:47:24,525] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:47:24,524] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:47:24,528] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:47:24,527] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:47:24,537] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:47:24,540] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run6
[2019-04-27 19:47:24,537] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run6
[2019-04-27 19:47:24,675] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 19:47:24,678] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:47:24,680] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run6
[2019-04-27 19:47:24,754] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run6
[2019-04-27 19:47:27,798] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.4838200e-13 9.9975973e-01 3.8771290e-15 2.4028178e-04 7.8615678e-13], sum to 1.0000
[2019-04-27 19:47:27,806] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2100
[2019-04-27 19:47:27,810] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.45, 40.0, 1.0, 2.0, 0.9072887615821416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.155866780078805, 6.9112, 121.9248662553361, 1267429.846615846, 1142139.795975272, 223344.8673680849], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 41400.0000, 
sim time next is 42000.0000, 
raw observation next is [27.63333333333333, 39.66666666666667, 1.0, 2.0, 0.9058112846836808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.139840227360165, 6.9112, 121.9247887273756, 1256249.571132971, 1139166.543188009, 222984.0986808797], 
processed observation next is [1.0, 0.4782608695652174, 0.5790123456790122, 0.3966666666666667, 1.0, 1.0, 0.8878705770043819, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.02286402273601649, 0.0, 0.8094538043058674, 0.4486605611189182, 0.4068451939957175, 0.4288155743863071], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3040899], dtype=float32), 0.13715816]. 
=============================================
[2019-04-27 19:47:27,821] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[56.309322]
 [56.611073]
 [57.085426]
 [57.56946 ]
 [58.091602]], R is [[55.52943802]
 [54.97414398]
 [54.42440414]
 [54.17785645]
 [54.24925232]].
[2019-04-27 19:47:30,275] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.6886752e-18 9.9998939e-01 4.8783244e-22 1.0659973e-05 9.1160490e-18], sum to 1.0000
[2019-04-27 19:47:30,283] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0897
[2019-04-27 19:47:30,289] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 69.33333333333334, 1.0, 2.0, 0.4187074376357676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 514863.4061783089, 514863.4061783089, 131190.7346649135], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 87600.0000, 
sim time next is 88200.0000, 
raw observation next is [23.8, 70.0, 1.0, 2.0, 0.4188200348123302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 514965.075853052, 514965.075853052, 131205.9941233662], 
processed observation next is [1.0, 0.0, 0.43703703703703706, 0.7, 1.0, 1.0, 0.30811908906229785, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18391609851894716, 0.18391609851894716, 0.2523192194680119], 
reward next is 0.7477, 
noisyNet noise sample is [array([-0.60165507], dtype=float32), -1.1651624]. 
=============================================
[2019-04-27 19:47:31,484] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.8727723e-12 2.4493120e-06 5.7421173e-16 9.9846679e-01 1.5306749e-03], sum to 1.0000
[2019-04-27 19:47:31,492] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2853
[2019-04-27 19:47:31,495] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.56666666666667, 54.5, 1.0, 2.0, 0.5698237669168106, 1.0, 2.0, 0.5698237669168106, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1351063.092264084, 1351063.092264083, 260151.2407154887], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 121800.0000, 
sim time next is 122400.0000, 
raw observation next is [28.0, 53.0, 1.0, 2.0, 0.582422353202195, 1.0, 2.0, 0.582422353202195, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1377805.881695347, 1377805.881695347, 264312.1748109253], 
processed observation next is [1.0, 0.43478260869565216, 0.5925925925925926, 0.53, 1.0, 1.0, 0.5028837538121369, 1.0, 1.0, 0.5028837538121369, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.4920735291769096, 0.4920735291769096, 0.5082926438671641], 
reward next is 0.4917, 
noisyNet noise sample is [array([-1.0325704], dtype=float32), -0.26190817]. 
=============================================
[2019-04-27 19:47:32,679] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.9524191e-16 4.7685831e-12 9.4423547e-21 9.9999976e-01 2.1531061e-07], sum to 1.0000
[2019-04-27 19:47:32,690] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5709
[2019-04-27 19:47:32,694] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.03333333333333, 38.0, 1.0, 2.0, 0.7021824881798113, 1.0, 2.0, 0.7021824881798113, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1645298.962450057, 1645298.962450057, 307123.9524321937], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 128400.0000, 
sim time next is 129000.0000, 
raw observation next is [32.41666666666666, 36.0, 1.0, 2.0, 0.719785790726716, 1.0, 2.0, 0.719785790726716, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1688475.505383417, 1688475.505383418, 314007.8325496034], 
processed observation next is [1.0, 0.4782608695652174, 0.7561728395061725, 0.36, 1.0, 1.0, 0.6664116556270429, 1.0, 1.0, 0.6664116556270429, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6030269662083633, 0.6030269662083636, 0.603861216441545], 
reward next is 0.3961, 
noisyNet noise sample is [array([0.5367636], dtype=float32), 1.0107665]. 
=============================================
[2019-04-27 19:47:32,707] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[73.739494]
 [73.66027 ]
 [73.496765]
 [73.117134]
 [72.863045]], R is [[73.68029785]
 [73.35287476]
 [73.08825684]
 [72.83518219]
 [72.53771973]].
[2019-04-27 19:47:33,277] A3C_AGENT_WORKER-Thread-3 INFO:Local step 66500, global step 1064573: loss 0.0050
[2019-04-27 19:47:33,279] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 66500, global step 1064573: learning rate 0.0000
[2019-04-27 19:47:33,295] A3C_AGENT_WORKER-Thread-21 INFO:Local step 66500, global step 1064579: loss 0.0157
[2019-04-27 19:47:33,298] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 66500, global step 1064579: learning rate 0.0000
[2019-04-27 19:47:33,755] A3C_AGENT_WORKER-Thread-17 INFO:Local step 66500, global step 1064816: loss 0.0097
[2019-04-27 19:47:33,759] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 66500, global step 1064816: learning rate 0.0000
[2019-04-27 19:47:33,761] A3C_AGENT_WORKER-Thread-14 INFO:Local step 66500, global step 1064817: loss 0.0092
[2019-04-27 19:47:33,765] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 66500, global step 1064817: learning rate 0.0000
[2019-04-27 19:47:33,923] A3C_AGENT_WORKER-Thread-10 INFO:Local step 66500, global step 1064901: loss 0.0113
[2019-04-27 19:47:33,930] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 66500, global step 1064901: learning rate 0.0000
[2019-04-27 19:47:33,968] A3C_AGENT_WORKER-Thread-15 INFO:Local step 66500, global step 1064920: loss 0.0217
[2019-04-27 19:47:33,969] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 66500, global step 1064920: learning rate 0.0000
[2019-04-27 19:47:34,033] A3C_AGENT_WORKER-Thread-2 INFO:Local step 66500, global step 1064952: loss 0.0411
[2019-04-27 19:47:34,034] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 66500, global step 1064952: learning rate 0.0000
[2019-04-27 19:47:34,112] A3C_AGENT_WORKER-Thread-18 INFO:Local step 66500, global step 1064988: loss 0.0089
[2019-04-27 19:47:34,115] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 66500, global step 1064989: learning rate 0.0000
[2019-04-27 19:47:34,155] A3C_AGENT_WORKER-Thread-20 INFO:Local step 66500, global step 1065010: loss 0.0322
[2019-04-27 19:47:34,156] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 66500, global step 1065010: learning rate 0.0000
[2019-04-27 19:47:34,179] A3C_AGENT_WORKER-Thread-11 INFO:Local step 66500, global step 1065021: loss 0.0148
[2019-04-27 19:47:34,181] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 66500, global step 1065021: learning rate 0.0000
[2019-04-27 19:47:34,183] A3C_AGENT_WORKER-Thread-9 INFO:Local step 66500, global step 1065021: loss 0.0126
[2019-04-27 19:47:34,187] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 66500, global step 1065022: learning rate 0.0000
[2019-04-27 19:47:34,262] A3C_AGENT_WORKER-Thread-12 INFO:Local step 66500, global step 1065067: loss 0.0065
[2019-04-27 19:47:34,264] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 66500, global step 1065067: learning rate 0.0000
[2019-04-27 19:47:34,363] A3C_AGENT_WORKER-Thread-16 INFO:Local step 66500, global step 1065116: loss 0.0377
[2019-04-27 19:47:34,366] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 66500, global step 1065117: learning rate 0.0000
[2019-04-27 19:47:34,675] A3C_AGENT_WORKER-Thread-19 INFO:Local step 66500, global step 1065276: loss 0.0054
[2019-04-27 19:47:34,676] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 66500, global step 1065276: learning rate 0.0000
[2019-04-27 19:47:34,692] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67000, global step 1065286: loss 0.1382
[2019-04-27 19:47:34,695] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67000, global step 1065286: learning rate 0.0000
[2019-04-27 19:47:35,060] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67000, global step 1065474: loss 0.0330
[2019-04-27 19:47:35,063] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67000, global step 1065474: learning rate 0.0000
[2019-04-27 19:47:36,302] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0472898e-18 9.9999595e-01 1.1020298e-20 4.0896030e-06 8.1041351e-19], sum to 1.0000
[2019-04-27 19:47:36,311] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8113
[2019-04-27 19:47:36,320] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.98333333333333, 60.66666666666666, 1.0, 2.0, 0.2550939688492493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 328602.1487773325, 328602.1487773325, 110198.279734927], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 195000.0000, 
sim time next is 195600.0000, 
raw observation next is [21.16666666666667, 61.33333333333334, 1.0, 2.0, 0.2582619160811347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 331972.5556729705, 331972.5556729705, 110570.5709980323], 
processed observation next is [0.0, 0.2608695652173913, 0.33950617283950635, 0.6133333333333334, 1.0, 1.0, 0.11697847152516035, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.11856162702606089, 0.11856162702606089, 0.21263571345775442], 
reward next is 0.7874, 
noisyNet noise sample is [array([-0.55496496], dtype=float32), -0.4654411]. 
=============================================
[2019-04-27 19:47:39,189] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.9443700e-18 9.9999976e-01 1.2755107e-23 2.4700014e-07 5.3737950e-21], sum to 1.0000
[2019-04-27 19:47:39,197] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4882
[2019-04-27 19:47:39,205] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.36666666666667, 38.16666666666667, 1.0, 2.0, 0.3091859978633472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 397677.9359154766, 397677.9359154766, 116713.2116388459], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 252600.0000, 
sim time next is 253200.0000, 
raw observation next is [25.03333333333333, 39.33333333333334, 1.0, 2.0, 0.3058587372962785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 393567.2671975353, 393567.2671975353, 116296.4946495438], 
processed observation next is [0.0, 0.9565217391304348, 0.482716049382716, 0.3933333333333334, 1.0, 1.0, 0.17364135392414107, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14055973828483403, 0.14055973828483403, 0.22364710509527655], 
reward next is 0.7764, 
noisyNet noise sample is [array([-1.3432516], dtype=float32), 0.19560967]. 
=============================================
[2019-04-27 19:47:40,434] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0224247e-18 9.9999988e-01 8.2722818e-24 1.1706727e-07 4.3069275e-21], sum to 1.0000
[2019-04-27 19:47:40,441] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1278
[2019-04-27 19:47:40,444] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 42.0, 1.0, 2.0, 0.2643613917138609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 341007.5687475064, 341007.5687475064, 93975.30024766689], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 283200.0000, 
sim time next is 283800.0000, 
raw observation next is [22.15, 41.0, 1.0, 2.0, 0.266605023861239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 343902.3450126949, 343902.3450126945, 94541.24628585525], 
processed observation next is [0.0, 0.2608695652173913, 0.3759259259259259, 0.41, 1.0, 1.0, 0.1269107426919512, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12282226607596246, 0.12282226607596232, 0.18181008901126008], 
reward next is 0.8182, 
noisyNet noise sample is [array([0.17353114], dtype=float32), 0.030996758]. 
=============================================
[2019-04-27 19:47:48,966] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67000, global step 1072552: loss 0.0156
[2019-04-27 19:47:48,968] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67000, global step 1072552: learning rate 0.0000
[2019-04-27 19:47:48,987] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67000, global step 1072560: loss 0.0117
[2019-04-27 19:47:48,990] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67000, global step 1072560: learning rate 0.0000
[2019-04-27 19:47:49,501] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67000, global step 1072801: loss 0.0062
[2019-04-27 19:47:49,504] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67000, global step 1072801: learning rate 0.0000
[2019-04-27 19:47:49,579] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67000, global step 1072841: loss 0.0340
[2019-04-27 19:47:49,581] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67000, global step 1072841: learning rate 0.0000
[2019-04-27 19:47:49,745] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67000, global step 1072917: loss 0.0071
[2019-04-27 19:47:49,751] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67000, global step 1072919: learning rate 0.0000
[2019-04-27 19:47:49,793] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67000, global step 1072941: loss 0.0146
[2019-04-27 19:47:49,796] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67000, global step 1072941: learning rate 0.0000
[2019-04-27 19:47:49,803] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67000, global step 1072943: loss 0.0234
[2019-04-27 19:47:49,805] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67000, global step 1072944: learning rate 0.0000
[2019-04-27 19:47:49,836] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67000, global step 1072958: loss 0.0344
[2019-04-27 19:47:49,841] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67000, global step 1072961: learning rate 0.0000
[2019-04-27 19:47:49,907] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67000, global step 1072992: loss 0.0740
[2019-04-27 19:47:49,910] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67000, global step 1072992: learning rate 0.0000
[2019-04-27 19:47:50,037] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67000, global step 1073053: loss 0.0078
[2019-04-27 19:47:50,039] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67000, global step 1073053: learning rate 0.0000
[2019-04-27 19:47:50,050] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67000, global step 1073059: loss 0.0098
[2019-04-27 19:47:50,053] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67000, global step 1073059: learning rate 0.0000
[2019-04-27 19:47:50,108] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67000, global step 1073087: loss 0.0368
[2019-04-27 19:47:50,108] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67000, global step 1073087: learning rate 0.0000
[2019-04-27 19:47:50,155] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67000, global step 1073109: loss 0.0502
[2019-04-27 19:47:50,158] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67000, global step 1073110: learning rate 0.0000
[2019-04-27 19:47:50,418] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67500, global step 1073232: loss 2.4262
[2019-04-27 19:47:50,425] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67500, global step 1073232: learning rate 0.0000
[2019-04-27 19:47:50,444] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67000, global step 1073242: loss 3.7095
[2019-04-27 19:47:50,447] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67000, global step 1073242: learning rate 0.0000
[2019-04-27 19:47:51,020] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67500, global step 1073521: loss 3.2021
[2019-04-27 19:47:51,021] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67500, global step 1073521: learning rate 0.0000
[2019-04-27 19:47:51,461] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.9145686e-18 9.9999869e-01 3.1528722e-23 1.2880548e-06 6.6825640e-20], sum to 1.0000
[2019-04-27 19:47:51,468] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5068
[2019-04-27 19:47:51,474] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.7, 29.0, 1.0, 2.0, 0.3445352374039399, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 437191.5270338323, 437191.5270338323, 121241.8462332826], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 763200.0000, 
sim time next is 763800.0000, 
raw observation next is [29.53333333333333, 29.5, 1.0, 2.0, 0.3430630999221184, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 435366.0811052377, 435366.0811052377, 121048.8365045616], 
processed observation next is [1.0, 0.8695652173913043, 0.6493827160493827, 0.295, 1.0, 1.0, 0.21793226181204575, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15548788610901346, 0.15548788610901346, 0.23278622404723384], 
reward next is 0.7672, 
noisyNet noise sample is [array([0.9689306], dtype=float32), 1.5109826]. 
=============================================
[2019-04-27 19:47:54,168] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-04-27 19:47:54,170] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 19:47:54,171] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:47:54,172] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 19:47:54,173] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 19:47:54,173] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:47:54,176] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 19:47:54,177] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:47:54,177] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:47:54,180] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 19:47:54,183] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:47:54,204] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run44
[2019-04-27 19:47:54,226] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run44
[2019-04-27 19:47:54,227] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run44
[2019-04-27 19:47:54,268] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run44
[2019-04-27 19:47:54,288] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run44
[2019-04-27 19:48:10,423] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.08410891]
[2019-04-27 19:48:10,425] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.765724015, 53.254073665, 1.0, 2.0, 0.4028957748622436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 512062.225387302, 512062.2253873015, 129224.1927830663]
[2019-04-27 19:48:10,426] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 19:48:10,428] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.4880742e-18 9.9999976e-01 9.2189057e-22 2.6557714e-07 1.5119962e-19], sampled 0.6628991451816012
[2019-04-27 19:48:29,620] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.08410891]
[2019-04-27 19:48:29,625] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [19.59066421166667, 71.48716237166667, 1.0, 2.0, 0.4997501046766034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 642531.7788893065, 642531.778889306, 143813.4546888009]
[2019-04-27 19:48:29,627] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 19:48:29,631] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0377059e-17 9.9999940e-01 2.9814883e-21 5.8073891e-07 8.4745135e-19], sampled 0.6106106999786869
[2019-04-27 19:48:59,504] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.08410891]
[2019-04-27 19:48:59,506] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.75, 73.16666666666667, 1.0, 2.0, 0.5633741474786002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 654419.6209586256, 654419.6209586256, 152481.8868015734]
[2019-04-27 19:48:59,509] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 19:48:59,513] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.78415227e-18 9.99999762e-01 3.62737556e-22 2.94529173e-07
 1.07152395e-19], sampled 0.5781989645927976
[2019-04-27 19:49:00,229] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.08410891]
[2019-04-27 19:49:00,231] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.81095732, 105.1921288833333, 1.0, 2.0, 0.527449559579736, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 627928.2645156877, 627928.2645156872, 147230.7734551087]
[2019-04-27 19:49:00,234] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 19:49:00,239] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.2816575e-18 9.9999952e-01 7.3637013e-22 4.3606443e-07 2.4391571e-19], sampled 0.2766158201419593
[2019-04-27 19:49:30,984] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.08410891]
[2019-04-27 19:49:30,985] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [18.233351, 82.11574105666666, 1.0, 2.0, 0.5590788936162786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 122.4889757264109, 718766.077460098, 718766.077460098, 153655.1089423336]
[2019-04-27 19:49:30,987] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 19:49:30,991] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.6492477e-18 9.9999976e-01 6.5090395e-22 2.7074881e-07 1.2789922e-19], sampled 0.11432587958030305
[2019-04-27 19:49:46,764] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8301.4167 2417096208.1141 479.0000
[2019-04-27 19:49:46,806] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8806.3037 2180822160.3524 441.0000
[2019-04-27 19:49:46,845] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8843.9253 2157116226.3243 413.0000
[2019-04-27 19:49:46,904] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8970.7822 2112870447.0286 376.0000
[2019-04-27 19:49:46,930] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8732.9613 2222623055.6011 382.0000
[2019-04-27 19:49:47,944] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1075000, evaluation results [1075000.0, 8301.41673374869, 2417096208.1141057, 479.0, 8843.925320886592, 2157116226.3242717, 413.0, 8970.78215003824, 2112870447.0285585, 376.0, 8732.961297312255, 2222623055.601148, 382.0, 8806.303691742305, 2180822160.352388, 441.0]
[2019-04-27 19:49:58,127] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.1879513e-11 1.2063816e-05 8.0057217e-15 9.9998689e-01 1.1020928e-06], sum to 1.0000
[2019-04-27 19:49:58,134] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4333
[2019-04-27 19:49:58,139] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.83333333333334, 53.0, 1.0, 2.0, 0.4630790664899889, 1.0, 2.0, 0.4630790664899889, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1132727.432039743, 1132727.432039743, 227249.1053513682], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 726000.0000, 
sim time next is 726600.0000, 
raw observation next is [25.96666666666667, 53.0, 1.0, 2.0, 0.4845106562198906, 1.0, 2.0, 0.4845106562198906, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 1181755.201044735, 1181755.201044736, 233730.5178638344], 
processed observation next is [1.0, 0.391304347826087, 0.517283950617284, 0.53, 1.0, 1.0, 0.38632220978558407, 1.0, 1.0, 0.38632220978558407, 0.0, 1.0, -0.25, -1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.4220554289445482, 0.42205542894454856, 0.44948176512275845], 
reward next is 0.5505, 
noisyNet noise sample is [array([0.7457835], dtype=float32), -1.2797195]. 
=============================================
[2019-04-27 19:49:58,803] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67500, global step 1080543: loss 0.0524
[2019-04-27 19:49:58,806] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67500, global step 1080543: learning rate 0.0000
[2019-04-27 19:49:58,960] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67500, global step 1080619: loss 0.1050
[2019-04-27 19:49:58,965] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67500, global step 1080620: learning rate 0.0000
[2019-04-27 19:49:59,306] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67500, global step 1080791: loss 0.9316
[2019-04-27 19:49:59,308] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67500, global step 1080791: learning rate 0.0000
[2019-04-27 19:49:59,363] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67500, global step 1080820: loss 0.2375
[2019-04-27 19:49:59,365] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67500, global step 1080822: learning rate 0.0000
[2019-04-27 19:49:59,530] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67500, global step 1080908: loss 0.0478
[2019-04-27 19:49:59,531] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67500, global step 1080908: learning rate 0.0000
[2019-04-27 19:49:59,560] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67500, global step 1080921: loss 0.1831
[2019-04-27 19:49:59,562] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67500, global step 1080921: learning rate 0.0000
[2019-04-27 19:49:59,576] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67500, global step 1080929: loss -0.0821
[2019-04-27 19:49:59,578] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67500, global step 1080929: learning rate 0.0000
[2019-04-27 19:49:59,657] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67500, global step 1080971: loss 0.0700
[2019-04-27 19:49:59,659] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67500, global step 1080971: learning rate 0.0000
[2019-04-27 19:49:59,695] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67500, global step 1080990: loss -0.7040
[2019-04-27 19:49:59,696] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67500, global step 1080990: learning rate 0.0000
[2019-04-27 19:49:59,759] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67500, global step 1081019: loss 0.1280
[2019-04-27 19:49:59,763] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67500, global step 1081019: learning rate 0.0000
[2019-04-27 19:49:59,871] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67500, global step 1081077: loss 0.1066
[2019-04-27 19:49:59,875] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67500, global step 1081079: learning rate 0.0000
[2019-04-27 19:49:59,880] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67500, global step 1081080: loss -0.1764
[2019-04-27 19:49:59,883] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67500, global step 1081081: learning rate 0.0000
[2019-04-27 19:49:59,977] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67500, global step 1081133: loss 0.1888
[2019-04-27 19:49:59,982] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67500, global step 1081135: learning rate 0.0000
[2019-04-27 19:50:00,087] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68000, global step 1081188: loss 0.0561
[2019-04-27 19:50:00,088] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68000, global step 1081188: learning rate 0.0000
[2019-04-27 19:50:00,180] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67500, global step 1081235: loss -0.0274
[2019-04-27 19:50:00,183] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67500, global step 1081236: learning rate 0.0000
[2019-04-27 19:50:00,804] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68000, global step 1081554: loss 0.0557
[2019-04-27 19:50:00,804] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68000, global step 1081554: learning rate 0.0000
[2019-04-27 19:50:14,355] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68000, global step 1088482: loss 0.0390
[2019-04-27 19:50:14,357] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68000, global step 1088482: learning rate 0.0000
[2019-04-27 19:50:14,781] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68000, global step 1088698: loss 0.1075
[2019-04-27 19:50:14,785] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68000, global step 1088698: learning rate 0.0000
[2019-04-27 19:50:15,058] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68000, global step 1088841: loss 0.0308
[2019-04-27 19:50:15,061] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68000, global step 1088843: learning rate 0.0000
[2019-04-27 19:50:15,141] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68000, global step 1088881: loss 0.0508
[2019-04-27 19:50:15,143] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68000, global step 1088881: learning rate 0.0000
[2019-04-27 19:50:15,225] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68000, global step 1088925: loss 0.1252
[2019-04-27 19:50:15,227] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68000, global step 1088926: learning rate 0.0000
[2019-04-27 19:50:15,228] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68000, global step 1088926: loss 0.1070
[2019-04-27 19:50:15,232] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68000, global step 1088927: loss 0.1155
[2019-04-27 19:50:15,233] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68000, global step 1088927: learning rate 0.0000
[2019-04-27 19:50:15,234] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68000, global step 1088927: learning rate 0.0000
[2019-04-27 19:50:15,245] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68000, global step 1088931: loss 0.1058
[2019-04-27 19:50:15,249] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68000, global step 1088931: learning rate 0.0000
[2019-04-27 19:50:15,312] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68000, global step 1088966: loss 0.0627
[2019-04-27 19:50:15,314] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68000, global step 1088966: learning rate 0.0000
[2019-04-27 19:50:15,359] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68000, global step 1088987: loss 0.0503
[2019-04-27 19:50:15,360] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68000, global step 1088988: learning rate 0.0000
[2019-04-27 19:50:15,657] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68000, global step 1089106: loss 0.0099
[2019-04-27 19:50:15,659] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68000, global step 1089106: loss 0.0215
[2019-04-27 19:50:15,660] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68000, global step 1089106: learning rate 0.0000
[2019-04-27 19:50:15,662] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68000, global step 1089107: loss 0.0067
[2019-04-27 19:50:15,663] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68000, global step 1089107: learning rate 0.0000
[2019-04-27 19:50:15,668] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68000, global step 1089108: learning rate 0.0000
[2019-04-27 19:50:15,725] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68500, global step 1089139: loss 0.0370
[2019-04-27 19:50:15,729] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68500, global step 1089140: learning rate 0.0000
[2019-04-27 19:50:15,885] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68000, global step 1089222: loss 0.0975
[2019-04-27 19:50:15,886] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68000, global step 1089222: learning rate 0.0000
[2019-04-27 19:50:16,572] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68500, global step 1089568: loss 0.1577
[2019-04-27 19:50:16,574] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68500, global step 1089569: learning rate 0.0000
[2019-04-27 19:50:22,305] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.5300524e-23 1.0000000e+00 9.4707093e-29 8.1592177e-14 9.1146832e-26], sum to 1.0000
[2019-04-27 19:50:22,314] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5323
[2019-04-27 19:50:22,317] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 67.16666666666667, 1.0, 2.0, 0.3392789999380946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 429217.0298702568, 429217.0298702568, 120541.4749301305], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1482600.0000, 
sim time next is 1483200.0000, 
raw observation next is [21.8, 68.0, 1.0, 2.0, 0.3397646611726808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 429709.7266107413, 429709.7266107413, 120603.610922482], 
processed observation next is [0.0, 0.17391304347826086, 0.362962962962963, 0.68, 1.0, 1.0, 0.21400554901509616, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15346775950383618, 0.15346775950383618, 0.23193002100477306], 
reward next is 0.7681, 
noisyNet noise sample is [array([0.5139829], dtype=float32), 1.0570099]. 
=============================================
[2019-04-27 19:50:28,329] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4854640e-18 9.9999964e-01 4.7309866e-23 3.5455986e-07 2.0537029e-18], sum to 1.0000
[2019-04-27 19:50:28,339] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0648
[2019-04-27 19:50:28,343] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.83333333333333, 89.33333333333334, 1.0, 2.0, 0.3261870456864056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 413072.896601484, 413072.896601484, 118852.4038604714], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1309200.0000, 
sim time next is 1309800.0000, 
raw observation next is [18.76666666666667, 89.66666666666666, 1.0, 2.0, 0.3243041313997863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 410818.2176039992, 410818.2176039992, 118612.5992738718], 
processed observation next is [1.0, 0.13043478260869565, 0.2506172839506174, 0.8966666666666666, 1.0, 1.0, 0.19560015642831705, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1467207920014283, 0.1467207920014283, 0.22810115244975346], 
reward next is 0.7719, 
noisyNet noise sample is [array([0.1358085], dtype=float32), -2.3180761]. 
=============================================
[2019-04-27 19:50:29,969] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68500, global step 1096453: loss 0.4573
[2019-04-27 19:50:29,971] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68500, global step 1096453: learning rate 0.0000
[2019-04-27 19:50:30,447] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68500, global step 1096689: loss 0.0891
[2019-04-27 19:50:30,452] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68500, global step 1096690: learning rate 0.0000
[2019-04-27 19:50:30,804] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68500, global step 1096861: loss 0.0234
[2019-04-27 19:50:30,805] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68500, global step 1096861: learning rate 0.0000
[2019-04-27 19:50:30,904] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68500, global step 1096910: loss 0.0076
[2019-04-27 19:50:30,906] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68500, global step 1096910: learning rate 0.0000
[2019-04-27 19:50:30,919] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68500, global step 1096915: loss 0.0070
[2019-04-27 19:50:30,921] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68500, global step 1096915: learning rate 0.0000
[2019-04-27 19:50:30,936] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68500, global step 1096925: loss 0.0096
[2019-04-27 19:50:30,938] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68500, global step 1096925: learning rate 0.0000
[2019-04-27 19:50:30,942] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68500, global step 1096926: loss 0.0070
[2019-04-27 19:50:30,943] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68500, global step 1096927: loss 0.0100
[2019-04-27 19:50:30,945] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68500, global step 1096927: learning rate 0.0000
[2019-04-27 19:50:30,945] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68500, global step 1096927: learning rate 0.0000
[2019-04-27 19:50:30,990] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68500, global step 1096943: loss 0.0129
[2019-04-27 19:50:30,990] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68500, global step 1096943: loss 0.0104
[2019-04-27 19:50:30,992] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68500, global step 1096943: learning rate 0.0000
[2019-04-27 19:50:30,994] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68500, global step 1096945: learning rate 0.0000
[2019-04-27 19:50:31,230] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68500, global step 1097065: loss 0.0305
[2019-04-27 19:50:31,235] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68500, global step 1097065: learning rate 0.0000
[2019-04-27 19:50:31,361] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69000, global step 1097125: loss 0.2974
[2019-04-27 19:50:31,363] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69000, global step 1097126: learning rate 0.0000
[2019-04-27 19:50:31,382] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68500, global step 1097133: loss 0.1499
[2019-04-27 19:50:31,383] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68500, global step 1097134: learning rate 0.0000
[2019-04-27 19:50:31,418] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68500, global step 1097153: loss 0.1341
[2019-04-27 19:50:31,421] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68500, global step 1097155: learning rate 0.0000
[2019-04-27 19:50:31,713] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68500, global step 1097296: loss 0.0084
[2019-04-27 19:50:31,716] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68500, global step 1097296: learning rate 0.0000
[2019-04-27 19:50:31,882] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.7375798e-19 1.0000000e+00 3.4331223e-24 4.3943921e-08 9.1824752e-22], sum to 1.0000
[2019-04-27 19:50:31,888] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1043
[2019-04-27 19:50:31,891] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.96666666666667, 55.0, 1.0, 2.0, 0.3699386937886776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 462855.7027137099, 462855.7027137099, 124554.2350127632], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1372200.0000, 
sim time next is 1372800.0000, 
raw observation next is [24.73333333333333, 56.00000000000001, 1.0, 2.0, 0.3677618062650594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 460363.8368436251, 460363.8368436246, 124263.0957564585], 
processed observation next is [1.0, 0.9130434782608695, 0.4716049382716048, 0.56, 1.0, 1.0, 0.24733548364888022, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1644156560155804, 0.16441565601558022, 0.23896749183934327], 
reward next is 0.7610, 
noisyNet noise sample is [array([-0.42949128], dtype=float32), -0.09471253]. 
=============================================
[2019-04-27 19:50:32,292] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69000, global step 1097571: loss 0.0417
[2019-04-27 19:50:32,294] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69000, global step 1097571: learning rate 0.0000
[2019-04-27 19:50:32,949] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.8492410e-14 6.4714768e-05 1.7698221e-19 9.9993527e-01 9.7118722e-09], sum to 1.0000
[2019-04-27 19:50:32,958] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8170
[2019-04-27 19:50:32,963] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.63333333333333, 77.33333333333334, 1.0, 2.0, 0.3732086402569912, 1.0, 2.0, 0.3732086402569912, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 929138.3123281476, 929138.312328148, 201830.0568417316], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1683600.0000, 
sim time next is 1684200.0000, 
raw observation next is [20.81666666666667, 76.66666666666667, 1.0, 2.0, 0.3799767238171061, 1.0, 2.0, 0.3799767238171061, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 944672.6232351062, 944672.6232351062, 203654.2689989029], 
processed observation next is [1.0, 0.4782608695652174, 0.32654320987654334, 0.7666666666666667, 1.0, 1.0, 0.2618770521632216, 1.0, 1.0, 0.2618770521632216, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.33738307972682363, 0.33738307972682363, 0.3916428249978902], 
reward next is 0.6084, 
noisyNet noise sample is [array([1.0249525], dtype=float32), 2.6910217]. 
=============================================
[2019-04-27 19:50:36,620] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.2580076e-22 1.0000000e+00 8.3890279e-26 7.2574960e-11 1.0911689e-23], sum to 1.0000
[2019-04-27 19:50:36,631] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0914
[2019-04-27 19:50:36,640] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.40000000000001, 25.66666666666667, 1.0, 2.0, 0.3807647349732278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 476910.4753062477, 476910.4753062477, 126043.2660267754], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1448400.0000, 
sim time next is 1449000.0000, 
raw observation next is [32.25, 26.0, 1.0, 2.0, 0.3789287462809612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 474734.4962608797, 474734.4962608792, 125792.7743504222], 
processed observation next is [0.0, 0.782608695652174, 0.75, 0.26, 1.0, 1.0, 0.2606294598582871, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1695480343788856, 0.16954803437888544, 0.24190918144311963], 
reward next is 0.7581, 
noisyNet noise sample is [array([-0.6196829], dtype=float32), -0.38532263]. 
=============================================
[2019-04-27 19:50:36,659] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[80.07126 ]
 [80.085144]
 [80.08828 ]
 [80.0276  ]
 [80.03618 ]], R is [[80.01467133]
 [79.97212982]
 [79.92832184]
 [79.88607788]
 [79.84381104]].
[2019-04-27 19:50:36,692] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3748398e-21 1.0000000e+00 2.1111424e-25 2.2190270e-09 3.0178751e-23], sum to 1.0000
[2019-04-27 19:50:36,705] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9211
[2019-04-27 19:50:36,710] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.3, 34.0, 1.0, 2.0, 0.3518712495278067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 442501.1318127343, 442501.1318127343, 122166.1356257667], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1460400.0000, 
sim time next is 1461000.0000, 
raw observation next is [29.15, 34.5, 1.0, 2.0, 0.3506615553385646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 441017.2635444006, 441017.2635444006, 122006.3336067187], 
processed observation next is [0.0, 0.9130434782608695, 0.6351851851851852, 0.345, 1.0, 1.0, 0.22697804206971975, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15750616555157163, 0.15750616555157163, 0.2346275646283052], 
reward next is 0.7654, 
noisyNet noise sample is [array([0.9156284], dtype=float32), 1.694218]. 
=============================================
[2019-04-27 19:50:36,727] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[77.87411 ]
 [77.88749 ]
 [77.89814 ]
 [77.912605]
 [77.92353 ]], R is [[77.85643005]
 [77.84293365]
 [77.82919312]
 [77.81510162]
 [77.80033112]].
[2019-04-27 19:50:37,369] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-04-27 19:50:37,373] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 19:50:37,374] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:50:37,374] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 19:50:37,375] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 19:50:37,375] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:50:37,375] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 19:50:37,375] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:50:37,376] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 19:50:37,377] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:50:37,378] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:50:37,398] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run45
[2019-04-27 19:50:37,398] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run45
[2019-04-27 19:50:37,399] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run45
[2019-04-27 19:50:37,473] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run45
[2019-04-27 19:50:37,500] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run45
[2019-04-27 19:50:47,165] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.08885357]
[2019-04-27 19:50:47,167] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.73333333333333, 54.5, 1.0, 2.0, 0.3263943742327777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 413940.9884732394, 413940.9884732394, 118884.3764148951]
[2019-04-27 19:50:47,168] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 19:50:47,173] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.6371875e-19 1.0000000e+00 2.0986678e-22 1.5809752e-08 1.6701764e-20], sampled 0.9823151942328163
[2019-04-27 19:50:51,159] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.08885357]
[2019-04-27 19:50:51,161] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.0, 29.0, 1.0, 2.0, 0.270151005558509, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 348477.4593671166, 348477.4593671166, 91949.11652373133]
[2019-04-27 19:50:51,162] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 19:50:51,168] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.4791766e-18 1.0000000e+00 5.1162009e-22 1.8530526e-08 2.8023913e-20], sampled 0.3474928571869469
[2019-04-27 19:50:52,185] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.08885357]
[2019-04-27 19:50:52,187] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.58614798666667, 47.89550647999999, 1.0, 2.0, 0.6357924261388774, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 799735.4404382429, 799735.4404382429, 167012.9757670199]
[2019-04-27 19:50:52,188] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 19:50:52,192] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.2717657e-18 9.9999988e-01 2.2111295e-21 6.6670552e-08 2.8771236e-19], sampled 0.2731761514329567
[2019-04-27 19:50:58,921] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.08885357]
[2019-04-27 19:50:58,926] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.43016695833333, 34.160254465, 1.0, 2.0, 0.3510917292887452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 439834.7642228963, 439834.7642228963, 122035.9674290975]
[2019-04-27 19:50:58,927] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 19:50:58,930] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.9802878e-19 1.0000000e+00 7.0202234e-23 8.8719361e-09 5.4705949e-21], sampled 0.5569227636750225
[2019-04-27 19:51:16,760] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.08885357]
[2019-04-27 19:51:16,762] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.41666666666666, 45.5, 1.0, 2.0, 0.6364472454250004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 725335.5453725553, 725335.5453725553, 164459.9481413011]
[2019-04-27 19:51:16,763] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 19:51:16,765] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.4968454e-19 1.0000000e+00 1.6130069e-22 3.1855240e-08 3.5079001e-20], sampled 0.6888021595113394
[2019-04-27 19:51:22,674] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.08885357]
[2019-04-27 19:51:22,675] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.0, 58.0, 1.0, 2.0, 0.507177532085923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 604274.2109454266, 604274.2109454266, 144003.4746726324]
[2019-04-27 19:51:22,678] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 19:51:22,683] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.0347489e-18 9.9999988e-01 7.9748597e-22 7.9194535e-08 2.0677580e-19], sampled 0.3317901637368409
[2019-04-27 19:51:32,403] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.08885357]
[2019-04-27 19:51:32,404] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.72434315666666, 63.60460395333334, 1.0, 2.0, 0.5672171854694263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 664758.1135712625, 664758.1135712625, 153380.4904569192]
[2019-04-27 19:51:32,404] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 19:51:32,408] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.8707064e-19 1.0000000e+00 1.6464214e-22 2.1142595e-08 2.0634156e-20], sampled 0.8968956036202291
[2019-04-27 19:51:42,949] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.08885357]
[2019-04-27 19:51:42,953] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.1, 88.33333333333334, 1.0, 2.0, 0.5951446887827175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 681703.4524531518, 681703.4524531518, 157415.4810256076]
[2019-04-27 19:51:42,955] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 19:51:42,958] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.9408129e-19 1.0000000e+00 1.9217655e-22 2.3926738e-08 2.6205193e-20], sampled 0.481934384340326
[2019-04-27 19:51:51,069] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.08885357]
[2019-04-27 19:51:51,075] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.0, 100.0, 1.0, 2.0, 0.7131085100507384, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 812749.8917409856, 812749.8917409856, 178641.3453040991]
[2019-04-27 19:51:51,076] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 19:51:51,082] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.3256083e-19 1.0000000e+00 1.4367411e-22 2.4494611e-08 2.2803539e-20], sampled 0.10812049446608651
[2019-04-27 19:52:10,672] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.08885357]
[2019-04-27 19:52:10,673] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.69849357666667, 77.66673302000001, 1.0, 2.0, 0.508005818544128, 1.0, 1.0, 0.508005818544128, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1163297.464021499, 1163297.4640215, 238115.2559930894]
[2019-04-27 19:52:10,674] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 19:52:10,678] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [5.3451189e-13 3.0685428e-01 4.8589856e-17 6.9314569e-01 2.6839657e-09], sampled 0.06301120829169105
[2019-04-27 19:52:26,973] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.08885357]
[2019-04-27 19:52:26,974] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.03333333333333, 35.83333333333333, 1.0, 2.0, 0.2987004543209917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 385313.6673597445, 385313.6673597441, 110793.3320414765]
[2019-04-27 19:52:26,975] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 19:52:26,978] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.2499278e-18 1.0000000e+00 3.9584737e-22 1.5878079e-08 2.4891632e-20], sampled 0.02328948749704307
[2019-04-27 19:52:29,412] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.08885357]
[2019-04-27 19:52:29,413] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.66666666666667, 70.5, 1.0, 2.0, 0.4102166193247315, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 504491.9779281075, 504491.9779281075, 129976.3492796582]
[2019-04-27 19:52:29,415] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 19:52:29,417] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [8.3212338e-19 1.0000000e+00 2.2471827e-22 1.7365139e-08 2.0229498e-20], sampled 0.027380946390722194
[2019-04-27 19:52:29,469] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8786.2047 2182715736.0678 471.0000
[2019-04-27 19:52:29,499] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8814.3832 2160351988.5613 439.0000
[2019-04-27 19:52:29,520] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8685.3332 2225315427.9867 433.0000
[2019-04-27 19:52:29,684] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8945.5559 2114601842.2664 400.0000
[2019-04-27 19:52:29,705] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8248.3472 2419778575.6604 543.0000
[2019-04-27 19:52:30,721] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1100000, evaluation results [1100000.0, 8248.347228650524, 2419778575.6603584, 543.0, 8814.383198940166, 2160351988.561336, 439.0, 8945.555874407244, 2114601842.266401, 400.0, 8685.33315822531, 2225315427.98673, 433.0, 8786.204725140726, 2182715736.06783, 471.0]
[2019-04-27 19:52:34,908] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1738341e-18 9.9999869e-01 2.3123666e-21 1.3271842e-06 1.1904418e-19], sum to 1.0000
[2019-04-27 19:52:34,915] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9369
[2019-04-27 19:52:34,919] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.2, 66.5, 1.0, 2.0, 0.3907700522048922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 487579.9581589521, 487579.9581589521, 127396.8807257692], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1553400.0000, 
sim time next is 1554000.0000, 
raw observation next is [23.1, 67.0, 1.0, 2.0, 0.3891950980865934, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 485737.2861942299, 485737.2861942294, 127179.8294724671], 
processed observation next is [0.0, 1.0, 0.41111111111111115, 0.67, 1.0, 1.0, 0.27285130724594453, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17347760221222497, 0.17347760221222477, 0.2445765951393598], 
reward next is 0.7554, 
noisyNet noise sample is [array([-0.0412886], dtype=float32), 1.2032272]. 
=============================================
[2019-04-27 19:52:34,932] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[73.879456]
 [73.84996 ]
 [73.8165  ]
 [73.783585]
 [73.71659 ]], R is [[73.91637421]
 [73.93221283]
 [73.94746399]
 [73.96206665]
 [73.97563934]].
[2019-04-27 19:52:38,461] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.7795756e-15 3.0096658e-06 3.1666488e-18 9.9999595e-01 1.0993766e-06], sum to 1.0000
[2019-04-27 19:52:38,470] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1433
[2019-04-27 19:52:38,473] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.46666666666667, 43.16666666666667, 1.0, 2.0, 0.558707928035314, 1.0, 2.0, 0.558707928035314, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1367117.013413013, 1367117.013413013, 257884.1815834848], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1608600.0000, 
sim time next is 1609200.0000, 
raw observation next is [27.5, 43.0, 1.0, 2.0, 0.5221994458643379, 1.0, 2.0, 0.5221994458643379, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1278824.499201624, 1278824.499201625, 245840.2568244034], 
processed observation next is [1.0, 0.6521739130434783, 0.5740740740740741, 0.43, 1.0, 1.0, 0.4311898165051641, 1.0, 1.0, 0.4311898165051641, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.45672303542915144, 0.45672303542915177, 0.4727697246623142], 
reward next is 0.5272, 
noisyNet noise sample is [array([-0.4449635], dtype=float32), -0.4973025]. 
=============================================
[2019-04-27 19:52:39,490] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69000, global step 1104473: loss 0.2645
[2019-04-27 19:52:39,492] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69000, global step 1104474: learning rate 0.0000
[2019-04-27 19:52:40,020] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69000, global step 1104735: loss 0.2748
[2019-04-27 19:52:40,025] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69000, global step 1104735: learning rate 0.0000
[2019-04-27 19:52:40,134] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69000, global step 1104791: loss 0.3277
[2019-04-27 19:52:40,136] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69000, global step 1104792: learning rate 0.0000
[2019-04-27 19:52:40,304] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69000, global step 1104878: loss 4.5413
[2019-04-27 19:52:40,305] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69000, global step 1104878: learning rate 0.0000
[2019-04-27 19:52:40,354] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69000, global step 1104901: loss 0.3963
[2019-04-27 19:52:40,358] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69000, global step 1104902: learning rate 0.0000
[2019-04-27 19:52:40,374] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69000, global step 1104910: loss 2.2542
[2019-04-27 19:52:40,374] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69000, global step 1104910: loss 1.6107
[2019-04-27 19:52:40,378] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69000, global step 1104910: learning rate 0.0000
[2019-04-27 19:52:40,379] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69000, global step 1104910: learning rate 0.0000
[2019-04-27 19:52:40,408] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69000, global step 1104927: loss 1.1821
[2019-04-27 19:52:40,410] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69000, global step 1104928: learning rate 0.0000
[2019-04-27 19:52:40,481] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69000, global step 1104966: loss 0.4706
[2019-04-27 19:52:40,483] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69000, global step 1104967: learning rate 0.0000
[2019-04-27 19:52:40,501] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69000, global step 1104976: loss 0.3202
[2019-04-27 19:52:40,503] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69000, global step 1104977: learning rate 0.0000
[2019-04-27 19:52:40,763] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69000, global step 1105107: loss 0.1692
[2019-04-27 19:52:40,768] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69000, global step 1105110: learning rate 0.0000
[2019-04-27 19:52:40,830] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69500, global step 1105139: loss 0.0421
[2019-04-27 19:52:40,831] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69500, global step 1105139: learning rate 0.0000
[2019-04-27 19:52:40,848] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69000, global step 1105147: loss 0.0576
[2019-04-27 19:52:40,850] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69000, global step 1105147: learning rate 0.0000
[2019-04-27 19:52:40,924] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69000, global step 1105192: loss 0.0064
[2019-04-27 19:52:40,929] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69000, global step 1105192: learning rate 0.0000
[2019-04-27 19:52:40,951] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69000, global step 1105204: loss 0.1641
[2019-04-27 19:52:40,953] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69000, global step 1105204: learning rate 0.0000
[2019-04-27 19:52:41,642] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69500, global step 1105552: loss 0.0422
[2019-04-27 19:52:41,643] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69500, global step 1105552: learning rate 0.0000
[2019-04-27 19:52:43,032] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.1605888e-14 5.1952462e-05 6.3381779e-19 9.9994802e-01 1.2994332e-11], sum to 1.0000
[2019-04-27 19:52:43,035] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2321
[2019-04-27 19:52:43,040] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.65, 71.33333333333333, 1.0, 2.0, 0.206524558860345, 1.0, 2.0, 0.206524558860345, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 503216.7171282184, 503216.7171282189, 161039.7803095322], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1705800.0000, 
sim time next is 1706400.0000, 
raw observation next is [23.6, 72.0, 1.0, 2.0, 0.2095230819102583, 1.0, 2.0, 0.2095230819102583, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 510090.9518778315, 510090.9518778319, 161662.7114718084], 
processed observation next is [1.0, 0.782608695652174, 0.4296296296296297, 0.72, 1.0, 1.0, 0.05895604989316466, 1.0, 1.0, 0.05895604989316466, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1821753399563684, 0.18217533995636853, 0.3108898297534777], 
reward next is 0.6891, 
noisyNet noise sample is [array([0.27075005], dtype=float32), -2.14643]. 
=============================================
[2019-04-27 19:52:47,306] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.3833656e-12 6.8572259e-01 9.6263953e-14 3.1427732e-01 6.1832839e-10], sum to 1.0000
[2019-04-27 19:52:47,314] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0912
[2019-04-27 19:52:47,321] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 63.5, 1.0, 2.0, 0.5425648753401301, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8695067078064151, 6.911199999999999, 6.9112, 121.9260426156618, 1281204.661885329, 1281204.66188533, 271211.8942843726], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1788600.0000, 
sim time next is 1789200.0000, 
raw observation next is [26.4, 63.0, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.592089705461829, 6.9112, 121.9232416997742, 1570159.349862822, 1221490.973317197, 248588.4711914504], 
processed observation next is [1.0, 0.7391304347826086, 0.5333333333333333, 0.63, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0680889705461829, 0.0, 0.8094435336513894, 0.5607711963795793, 0.43624677618471325, 0.4780547522912508], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.651602], dtype=float32), 1.0994004]. 
=============================================
[2019-04-27 19:52:49,325] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.832868e-21 9.999999e-01 1.837171e-22 6.394034e-08 9.021451e-20], sum to 1.0000
[2019-04-27 19:52:49,337] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4684
[2019-04-27 19:52:49,345] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.46666666666667, 91.66666666666667, 1.0, 2.0, 0.3256929583420394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 412938.2658790805, 412938.2658790805, 118793.5726852251], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1826400.0000, 
sim time next is 1827000.0000, 
raw observation next is [18.5, 91.5, 1.0, 2.0, 0.3274081930416759, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 415050.6314115379, 415050.6314115379, 119013.0158587112], 
processed observation next is [1.0, 0.13043478260869565, 0.24074074074074073, 0.915, 1.0, 1.0, 0.19929546790675703, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14823236836126352, 0.14823236836126352, 0.22887118434367537], 
reward next is 0.7711, 
noisyNet noise sample is [array([0.54809487], dtype=float32), -0.17888401]. 
=============================================
[2019-04-27 19:52:49,379] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[73.52355 ]
 [73.728935]
 [73.81904 ]
 [73.92954 ]
 [74.08294 ]], R is [[73.3710556 ]
 [73.4088974 ]
 [73.44454193]
 [73.48176575]
 [73.51856232]].
[2019-04-27 19:52:54,138] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.8118374e-19 1.0000000e+00 3.5877037e-21 1.5869547e-11 1.8826703e-21], sum to 1.0000
[2019-04-27 19:52:54,145] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0168
[2019-04-27 19:52:54,149] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 92.0, 1.0, 2.0, 0.3803657197211011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 475076.600390973, 475076.6003909726, 125964.9065623049], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1917600.0000, 
sim time next is 1918200.0000, 
raw observation next is [19.68333333333333, 92.0, 1.0, 2.0, 0.3786456588086801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 472823.016664621, 472823.016664621, 125726.5647679828], 
processed observation next is [1.0, 0.17391304347826086, 0.28456790123456777, 0.92, 1.0, 1.0, 0.2602924509627144, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1688653630945075, 0.1688653630945075, 0.24178185532304383], 
reward next is 0.7582, 
noisyNet noise sample is [array([0.22783813], dtype=float32), -0.38496014]. 
=============================================
[2019-04-27 19:52:55,102] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69500, global step 1112418: loss 0.0435
[2019-04-27 19:52:55,104] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69500, global step 1112419: learning rate 0.0000
[2019-04-27 19:52:55,562] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69500, global step 1112655: loss 0.0378
[2019-04-27 19:52:55,565] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69500, global step 1112655: learning rate 0.0000
[2019-04-27 19:52:55,975] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69500, global step 1112866: loss 0.1671
[2019-04-27 19:52:55,979] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69500, global step 1112867: loss 0.1788
[2019-04-27 19:52:55,980] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69500, global step 1112867: learning rate 0.0000
[2019-04-27 19:52:55,982] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69500, global step 1112867: learning rate 0.0000
[2019-04-27 19:52:56,024] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69500, global step 1112891: loss 0.0611
[2019-04-27 19:52:56,026] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69500, global step 1112891: learning rate 0.0000
[2019-04-27 19:52:56,072] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69500, global step 1112914: loss 0.1809
[2019-04-27 19:52:56,074] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69500, global step 1112914: learning rate 0.0000
[2019-04-27 19:52:56,110] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69500, global step 1112934: loss 0.1958
[2019-04-27 19:52:56,112] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69500, global step 1112934: learning rate 0.0000
[2019-04-27 19:52:56,182] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69500, global step 1112969: loss 0.1956
[2019-04-27 19:52:56,184] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69500, global step 1112971: learning rate 0.0000
[2019-04-27 19:52:56,272] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69500, global step 1113013: loss 0.0998
[2019-04-27 19:52:56,276] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69500, global step 1113014: learning rate 0.0000
[2019-04-27 19:52:56,358] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69500, global step 1113055: loss 0.0063
[2019-04-27 19:52:56,362] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69500, global step 1113055: learning rate 0.0000
[2019-04-27 19:52:56,402] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69500, global step 1113078: loss 0.0110
[2019-04-27 19:52:56,404] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69500, global step 1113079: learning rate 0.0000
[2019-04-27 19:52:56,418] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69500, global step 1113090: loss 0.0126
[2019-04-27 19:52:56,420] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69500, global step 1113090: learning rate 0.0000
[2019-04-27 19:52:56,431] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69500, global step 1113095: loss 0.0096
[2019-04-27 19:52:56,432] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69500, global step 1113096: learning rate 0.0000
[2019-04-27 19:52:56,556] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70000, global step 1113156: loss 0.0953
[2019-04-27 19:52:56,557] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70000, global step 1113157: learning rate 0.0000
[2019-04-27 19:52:56,646] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69500, global step 1113203: loss 0.0105
[2019-04-27 19:52:56,649] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69500, global step 1113204: learning rate 0.0000
[2019-04-27 19:52:57,414] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70000, global step 1113594: loss 0.1054
[2019-04-27 19:52:57,418] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70000, global step 1113595: learning rate 0.0000
[2019-04-27 19:52:58,070] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.7041849e-18 9.9977309e-01 1.2240809e-19 2.2692824e-04 2.4132223e-14], sum to 1.0000
[2019-04-27 19:52:58,080] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7081
[2019-04-27 19:52:58,084] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.51666666666667, 90.83333333333334, 1.0, 2.0, 0.3628847992984435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 454900.6736348631, 454900.6736348631, 123615.667577207], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1986600.0000, 
sim time next is 1987200.0000, 
raw observation next is [19.5, 91.0, 1.0, 2.0, 0.3629255962178805, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 454934.7871474361, 454934.7871474356, 123620.8794279519], 
processed observation next is [0.0, 0.0, 0.2777777777777778, 0.91, 1.0, 1.0, 0.24157809073557204, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1624767096955129, 0.1624767096955127, 0.23773246043836904], 
reward next is 0.7623, 
noisyNet noise sample is [array([0.9108548], dtype=float32), -1.2365531]. 
=============================================
[2019-04-27 19:52:59,942] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.8730197e-20 1.0000000e+00 7.1948157e-25 5.2244129e-09 1.8363435e-23], sum to 1.0000
[2019-04-27 19:52:59,954] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1322
[2019-04-27 19:52:59,957] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.95, 66.0, 1.0, 2.0, 0.4666433707456217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 561474.2768503869, 561474.2768503864, 137925.819584349], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2028600.0000, 
sim time next is 2029200.0000, 
raw observation next is [26.1, 66.0, 1.0, 2.0, 0.4726365363174186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 567326.6905175243, 567326.6905175238, 138791.074588555], 
processed observation next is [0.0, 0.4782608695652174, 0.5222222222222223, 0.66, 1.0, 1.0, 0.3721863527588317, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2026166751848301, 0.20261667518482993, 0.26690591267029806], 
reward next is 0.7331, 
noisyNet noise sample is [array([1.4561113], dtype=float32), 1.3561382]. 
=============================================
[2019-04-27 19:53:02,278] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.0001289e-20 9.9999976e-01 2.1109486e-25 1.8892410e-07 8.1277412e-23], sum to 1.0000
[2019-04-27 19:53:02,287] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6921
[2019-04-27 19:53:02,293] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.95, 78.0, 1.0, 2.0, 0.5271996135212117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 623539.8240002115, 623539.8240002115, 147031.5250722856], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2067000.0000, 
sim time next is 2067600.0000, 
raw observation next is [24.8, 78.0, 1.0, 2.0, 0.5207823362725307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 617626.6837530661, 617626.6837530661, 146064.6595756334], 
processed observation next is [0.0, 0.9565217391304348, 0.4740740740740741, 0.78, 1.0, 1.0, 0.42950278127682223, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2205809584832379, 0.2205809584832379, 0.28089357610698734], 
reward next is 0.7191, 
noisyNet noise sample is [array([-0.16879071], dtype=float32), -0.27384087]. 
=============================================
[2019-04-27 19:53:07,836] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.1484089e-14 1.0802735e-03 8.0637250e-20 9.9891973e-01 4.9449322e-10], sum to 1.0000
[2019-04-27 19:53:07,840] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8798
[2019-04-27 19:53:07,847] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.26666666666667, 89.0, 1.0, 2.0, 0.4583517376983618, 1.0, 2.0, 0.4583517376983618, 0.0, 2.0, 0.0, 6.9112, 6.9112, 122.3761217902864, 1050041.336084004, 1050041.336084004, 223113.7191903525], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2167800.0000, 
sim time next is 2168400.0000, 
raw observation next is [24.23333333333333, 89.0, 1.0, 2.0, 0.3873682897400657, 1.0, 2.0, 0.3873682897400657, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 887235.4145293833, 887235.4145293833, 202951.2339489761], 
processed observation next is [1.0, 0.08695652173913043, 0.45308641975308633, 0.89, 1.0, 1.0, 0.27067653540484016, 1.0, 1.0, 0.27067653540484016, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31686979090335116, 0.31686979090335116, 0.3902908345172617], 
reward next is 0.6097, 
noisyNet noise sample is [array([-0.7862779], dtype=float32), -1.1984448]. 
=============================================
[2019-04-27 19:53:10,844] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70000, global step 1120461: loss 0.0680
[2019-04-27 19:53:10,845] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70000, global step 1120461: learning rate 0.0000
[2019-04-27 19:53:11,106] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70000, global step 1120581: loss 0.0308
[2019-04-27 19:53:11,108] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70000, global step 1120581: learning rate 0.0000
[2019-04-27 19:53:11,573] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70000, global step 1120817: loss 0.0230
[2019-04-27 19:53:11,579] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70000, global step 1120817: learning rate 0.0000
[2019-04-27 19:53:11,666] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70000, global step 1120863: loss 0.0243
[2019-04-27 19:53:11,672] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70000, global step 1120866: learning rate 0.0000
[2019-04-27 19:53:11,705] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70000, global step 1120882: loss 0.0288
[2019-04-27 19:53:11,705] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70000, global step 1120882: loss 0.0216
[2019-04-27 19:53:11,707] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70000, global step 1120882: learning rate 0.0000
[2019-04-27 19:53:11,708] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70000, global step 1120882: learning rate 0.0000
[2019-04-27 19:53:11,799] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70000, global step 1120927: loss 0.0784
[2019-04-27 19:53:11,800] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70000, global step 1120927: learning rate 0.0000
[2019-04-27 19:53:11,829] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70000, global step 1120940: loss 0.1074
[2019-04-27 19:53:11,830] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70000, global step 1120940: learning rate 0.0000
[2019-04-27 19:53:12,030] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70000, global step 1121035: loss 0.1479
[2019-04-27 19:53:12,032] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70000, global step 1121036: learning rate 0.0000
[2019-04-27 19:53:12,053] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70000, global step 1121045: loss 0.1991
[2019-04-27 19:53:12,056] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70000, global step 1121045: learning rate 0.0000
[2019-04-27 19:53:12,069] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70000, global step 1121051: loss 0.2733
[2019-04-27 19:53:12,071] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70000, global step 1121051: learning rate 0.0000
[2019-04-27 19:53:12,163] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70000, global step 1121097: loss 0.2976
[2019-04-27 19:53:12,165] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70000, global step 1121097: learning rate 0.0000
[2019-04-27 19:53:12,285] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70500, global step 1121155: loss 0.6384
[2019-04-27 19:53:12,287] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70500, global step 1121155: learning rate 0.0000
[2019-04-27 19:53:12,411] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70000, global step 1121214: loss 0.2250
[2019-04-27 19:53:12,417] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70000, global step 1121217: learning rate 0.0000
[2019-04-27 19:53:12,490] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70000, global step 1121253: loss 0.4005
[2019-04-27 19:53:12,495] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70000, global step 1121254: learning rate 0.0000
[2019-04-27 19:53:12,653] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.7849228e-18 1.0000000e+00 3.0474156e-19 1.6848311e-08 2.6694855e-19], sum to 1.0000
[2019-04-27 19:53:12,660] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8939
[2019-04-27 19:53:12,668] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.4, 95.5, 1.0, 2.0, 0.4119282119501079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 506299.821431612, 506299.821431612, 130212.8729071048], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2266200.0000, 
sim time next is 2266800.0000, 
raw observation next is [20.4, 95.66666666666667, 1.0, 2.0, 0.4124473977187059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 506789.5223158078, 506789.5223158078, 130283.1625627234], 
processed observation next is [1.0, 0.21739130434782608, 0.31111111111111106, 0.9566666666666667, 1.0, 1.0, 0.3005326163317928, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18099625796993135, 0.18099625796993135, 0.2505445433898527], 
reward next is 0.7495, 
noisyNet noise sample is [array([-0.2099921], dtype=float32), -0.7436544]. 
=============================================
[2019-04-27 19:53:13,139] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70500, global step 1121557: loss 0.4897
[2019-04-27 19:53:13,141] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70500, global step 1121559: learning rate 0.0000
[2019-04-27 19:53:15,257] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.5505672e-19 9.9999893e-01 1.9121318e-23 1.0993160e-06 1.2163876e-19], sum to 1.0000
[2019-04-27 19:53:15,266] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9059
[2019-04-27 19:53:15,271] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.3, 71.5, 1.0, 2.0, 0.4922005961434702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 589404.1311654939, 589404.1311654939, 141760.3001124414], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2313000.0000, 
sim time next is 2313600.0000, 
raw observation next is [25.2, 72.0, 1.0, 2.0, 0.4931996030194867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 590793.2305399342, 590793.2305399338, 141923.023469174], 
processed observation next is [1.0, 0.782608695652174, 0.4888888888888889, 0.72, 1.0, 1.0, 0.3966661940708175, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2109975823356908, 0.21099758233569063, 0.27292889128687303], 
reward next is 0.7271, 
noisyNet noise sample is [array([1.3141248], dtype=float32), 1.4055088]. 
=============================================
[2019-04-27 19:53:17,005] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.8762599e-17 1.0000000e+00 1.8486886e-20 1.0807833e-08 1.5075915e-18], sum to 1.0000
[2019-04-27 19:53:17,012] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8709
[2019-04-27 19:53:17,021] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.45, 49.5, 1.0, 2.0, 0.442753522545723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 551330.5886220585, 551330.5886220585, 134863.0475841378], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2359800.0000, 
sim time next is 2360400.0000, 
raw observation next is [26.76666666666667, 47.0, 1.0, 2.0, 0.45010138520965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 561796.9991536792, 561796.9991536792, 135985.4552661561], 
processed observation next is [1.0, 0.30434782608695654, 0.5469135802469137, 0.47, 1.0, 1.0, 0.34535879191625, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2006417854120283, 0.2006417854120283, 0.261510490896454], 
reward next is 0.7385, 
noisyNet noise sample is [array([-0.10678323], dtype=float32), -1.1455032]. 
=============================================
[2019-04-27 19:53:20,415] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-04-27 19:53:20,417] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 19:53:20,418] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 19:53:20,419] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:53:20,419] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 19:53:20,419] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:53:20,422] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 19:53:20,420] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 19:53:20,423] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:53:20,425] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:53:20,424] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:53:20,448] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run46
[2019-04-27 19:53:20,471] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run46
[2019-04-27 19:53:20,472] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run46
[2019-04-27 19:53:20,514] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run46
[2019-04-27 19:53:20,533] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run46
[2019-04-27 19:53:24,208] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.093082316]
[2019-04-27 19:53:24,209] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [18.64315359, 49.66038397333334, 1.0, 2.0, 0.2282543692640298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 294423.1140752759, 294423.1140752754, 82506.8320203182]
[2019-04-27 19:53:24,211] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 19:53:24,214] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.3194508e-21 1.0000000e+00 1.3767114e-24 1.5156900e-11 1.3672861e-23], sampled 0.04429381896073148
[2019-04-27 19:54:07,836] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.093082316]
[2019-04-27 19:54:07,837] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.0, 84.0, 1.0, 2.0, 0.7480474441121173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 852592.929143459, 852592.9291434594, 185444.2661266066]
[2019-04-27 19:54:07,838] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 19:54:07,840] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.0423265e-21 1.0000000e+00 2.2174361e-24 2.9540645e-10 4.2016549e-22], sampled 0.5507717614836453
[2019-04-27 19:54:40,944] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.093082316]
[2019-04-27 19:54:40,945] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.5, 97.0, 1.0, 2.0, 0.5872549618468059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 679585.1008348123, 679585.1008348123, 156396.6314352482]
[2019-04-27 19:54:40,947] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 19:54:40,950] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.8637060e-21 1.0000000e+00 5.4249890e-25 2.4471132e-11 1.4331113e-23], sampled 0.6465972965868465
[2019-04-27 19:55:03,875] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.093082316]
[2019-04-27 19:55:03,876] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.41666666666666, 91.0, 1.0, 2.0, 0.6325489824289391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 729526.9225293774, 729526.9225293774, 164190.6493408728]
[2019-04-27 19:55:03,876] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 19:55:03,880] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [7.8741714e-21 1.0000000e+00 2.6253468e-24 6.8592645e-11 1.0684287e-22], sampled 0.13800838342661603
[2019-04-27 19:55:10,922] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.093082316]
[2019-04-27 19:55:10,922] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.86666666666667, 54.5, 1.0, 2.0, 0.4889634404323049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 598184.2183237014, 598184.2183237014, 141661.0657043328]
[2019-04-27 19:55:10,926] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 19:55:10,928] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0390477e-20 1.0000000e+00 3.9514997e-24 5.5573025e-11 1.0801573e-22], sampled 0.20871716945151664
[2019-04-27 19:55:12,187] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8947.0125 2114673688.0502 405.0000
[2019-04-27 19:55:12,383] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8815.1597 2161905274.9050 439.0000
[2019-04-27 19:55:12,471] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8247.3929 2421417995.4636 548.0000
[2019-04-27 19:55:12,488] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8782.1068 2183045886.4102 482.0000
[2019-04-27 19:55:12,496] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8680.1863 2227018995.0903 446.0000
[2019-04-27 19:55:13,512] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1125000, evaluation results [1125000.0, 8247.392855957254, 2421417995.463614, 548.0, 8815.159725355003, 2161905274.905023, 439.0, 8947.01249295735, 2114673688.050236, 405.0, 8680.186305304147, 2227018995.090285, 446.0, 8782.106787080202, 2183045886.4101596, 482.0]
[2019-04-27 19:55:14,782] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.3265798e-18 1.0000000e+00 8.0117604e-21 1.9725510e-10 4.9946236e-19], sum to 1.0000
[2019-04-27 19:55:14,790] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3792
[2019-04-27 19:55:14,793] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.76666666666667, 76.33333333333334, 1.0, 2.0, 0.2759191550640063, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 355137.9412800927, 355137.9412800922, 112645.2314566344], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2434800.0000, 
sim time next is 2435400.0000, 
raw observation next is [18.6, 77.5, 1.0, 2.0, 0.2820866148329948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 363138.2944253299, 363138.2944253299, 113383.6725330237], 
processed observation next is [1.0, 0.17391304347826086, 0.2444444444444445, 0.775, 1.0, 1.0, 0.14534120813451762, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.12969224800904638, 0.12969224800904638, 0.21804552410196865], 
reward next is 0.7820, 
noisyNet noise sample is [array([0.10754373], dtype=float32), 0.73761624]. 
=============================================
[2019-04-27 19:55:20,019] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.8878090e-17 1.0000000e+00 4.1745177e-19 1.1059000e-09 7.3162807e-20], sum to 1.0000
[2019-04-27 19:55:20,027] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0028
[2019-04-27 19:55:20,031] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.93333333333333, 49.83333333333334, 1.0, 2.0, 0.4603184489099446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 569856.6919778766, 569856.6919778766, 137429.1686600049], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2530200.0000, 
sim time next is 2530800.0000, 
raw observation next is [27.2, 49.0, 1.0, 2.0, 0.4457142395662474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 551179.0459050226, 551179.0459050226, 135220.5788017414], 
processed observation next is [1.0, 0.30434782608695654, 0.5629629629629629, 0.49, 1.0, 1.0, 0.3401359994836279, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1968496592517938, 0.1968496592517938, 0.26003957461873345], 
reward next is 0.7400, 
noisyNet noise sample is [array([-0.08472149], dtype=float32), -0.66274863]. 
=============================================
[2019-04-27 19:55:20,214] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70500, global step 1128426: loss -138.2614
[2019-04-27 19:55:20,219] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70500, global step 1128426: learning rate 0.0000
[2019-04-27 19:55:20,682] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70500, global step 1128666: loss 50.4963
[2019-04-27 19:55:20,684] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70500, global step 1128666: learning rate 0.0000
[2019-04-27 19:55:21,079] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70500, global step 1128858: loss -85.5760
[2019-04-27 19:55:21,081] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70500, global step 1128858: learning rate 0.0000
[2019-04-27 19:55:21,141] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70500, global step 1128890: loss -110.6491
[2019-04-27 19:55:21,142] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70500, global step 1128890: learning rate 0.0000
[2019-04-27 19:55:21,177] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70500, global step 1128909: loss -192.1348
[2019-04-27 19:55:21,180] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70500, global step 1128910: learning rate 0.0000
[2019-04-27 19:55:21,198] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70500, global step 1128920: loss -93.0420
[2019-04-27 19:55:21,202] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70500, global step 1128921: learning rate 0.0000
[2019-04-27 19:55:21,266] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70500, global step 1128950: loss -282.7281
[2019-04-27 19:55:21,267] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70500, global step 1128950: learning rate 0.0000
[2019-04-27 19:55:21,336] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70500, global step 1128991: loss -126.7457
[2019-04-27 19:55:21,339] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70500, global step 1128992: learning rate 0.0000
[2019-04-27 19:55:21,378] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70500, global step 1129008: loss -200.9229
[2019-04-27 19:55:21,381] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70500, global step 1129009: learning rate 0.0000
[2019-04-27 19:55:21,411] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70500, global step 1129022: loss -96.7834
[2019-04-27 19:55:21,414] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70500, global step 1129022: learning rate 0.0000
[2019-04-27 19:55:21,529] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71000, global step 1129086: loss 0.0054
[2019-04-27 19:55:21,531] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71000, global step 1129086: learning rate 0.0000
[2019-04-27 19:55:21,546] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70500, global step 1129091: loss -199.3185
[2019-04-27 19:55:21,549] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70500, global step 1129092: learning rate 0.0000
[2019-04-27 19:55:21,565] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70500, global step 1129100: loss -94.4423
[2019-04-27 19:55:21,570] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70500, global step 1129102: learning rate 0.0000
[2019-04-27 19:55:21,746] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70500, global step 1129189: loss -185.9975
[2019-04-27 19:55:21,749] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70500, global step 1129189: learning rate 0.0000
[2019-04-27 19:55:21,811] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70500, global step 1129223: loss -61.5710
[2019-04-27 19:55:21,818] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70500, global step 1129226: learning rate 0.0000
[2019-04-27 19:55:22,232] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71000, global step 1129434: loss 0.0221
[2019-04-27 19:55:22,235] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71000, global step 1129435: learning rate 0.0000
[2019-04-27 19:55:27,884] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.5803297e-24 1.0000000e+00 3.2351716e-26 1.7111834e-16 2.0432857e-27], sum to 1.0000
[2019-04-27 19:55:27,893] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0365
[2019-04-27 19:55:27,899] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 91.66666666666667, 1.0, 2.0, 0.5364770345790021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 634155.9320299699, 634155.9320299694, 148522.962804913], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2683200.0000, 
sim time next is 2683800.0000, 
raw observation next is [23.15, 90.5, 1.0, 2.0, 0.5307372687303148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 628566.2940291245, 628566.2940291245, 147637.1629331486], 
processed observation next is [0.0, 0.043478260869565216, 0.4129629629629629, 0.905, 1.0, 1.0, 0.4413538913456128, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22448796215325878, 0.22448796215325878, 0.2839176210252857], 
reward next is 0.7161, 
noisyNet noise sample is [array([-1.3774558], dtype=float32), 0.45527318]. 
=============================================
[2019-04-27 19:55:29,805] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.9283856e-24 1.0000000e+00 7.0612218e-27 1.4171226e-16 7.8607500e-30], sum to 1.0000
[2019-04-27 19:55:29,813] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0838
[2019-04-27 19:55:29,826] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.16666666666667, 76.83333333333334, 1.0, 2.0, 0.5260506828067963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 622357.0836936982, 622357.0836936982, 146853.3467888777], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2707800.0000, 
sim time next is 2708400.0000, 
raw observation next is [25.53333333333333, 74.66666666666667, 1.0, 2.0, 0.5297678624249826, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 626322.7777543446, 626322.7777543446, 147436.9138357511], 
processed observation next is [0.0, 0.34782608695652173, 0.5012345679012346, 0.7466666666666667, 1.0, 1.0, 0.4401998362202174, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22368670634083737, 0.22368670634083737, 0.2835325266072136], 
reward next is 0.7165, 
noisyNet noise sample is [array([0.0667751], dtype=float32), 1.5854472]. 
=============================================
[2019-04-27 19:55:32,122] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.6195655e-24 1.0000000e+00 7.5582403e-26 9.1121872e-17 3.6014480e-26], sum to 1.0000
[2019-04-27 19:55:32,126] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4662
[2019-04-27 19:55:32,133] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.25, 91.5, 1.0, 2.0, 0.667561648879245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 760813.0855881756, 760813.0855881751, 170092.173662014], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2763000.0000, 
sim time next is 2763600.0000, 
raw observation next is [25.16666666666666, 92.33333333333334, 1.0, 2.0, 0.668908552684417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 762348.901233638, 762348.901233639, 170339.842422244], 
processed observation next is [0.0, 1.0, 0.4876543209876541, 0.9233333333333335, 1.0, 1.0, 0.6058435151004964, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.2722674647262993, 0.27226746472629965, 0.32757662004277693], 
reward next is 0.6724, 
noisyNet noise sample is [array([0.51782465], dtype=float32), -0.16004767]. 
=============================================
[2019-04-27 19:55:35,699] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71000, global step 1136281: loss 0.2660
[2019-04-27 19:55:35,701] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71000, global step 1136282: learning rate 0.0000
[2019-04-27 19:55:36,334] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71000, global step 1136596: loss 0.2830
[2019-04-27 19:55:36,338] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71000, global step 1136596: learning rate 0.0000
[2019-04-27 19:55:36,646] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71000, global step 1136760: loss 0.5903
[2019-04-27 19:55:36,647] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71000, global step 1136760: learning rate 0.0000
[2019-04-27 19:55:36,785] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71000, global step 1136831: loss 0.7020
[2019-04-27 19:55:36,787] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71000, global step 1136833: learning rate 0.0000
[2019-04-27 19:55:36,870] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71000, global step 1136877: loss 0.5727
[2019-04-27 19:55:36,871] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71000, global step 1136877: learning rate 0.0000
[2019-04-27 19:55:36,900] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71000, global step 1136892: loss 0.5483
[2019-04-27 19:55:36,902] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71000, global step 1136892: learning rate 0.0000
[2019-04-27 19:55:36,936] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71000, global step 1136906: loss 0.4442
[2019-04-27 19:55:36,937] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71000, global step 1136906: learning rate 0.0000
[2019-04-27 19:55:37,031] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71000, global step 1136958: loss 0.4411
[2019-04-27 19:55:37,033] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71000, global step 1136958: learning rate 0.0000
[2019-04-27 19:55:37,096] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71000, global step 1136987: loss 0.3322
[2019-04-27 19:55:37,099] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71000, global step 1136987: learning rate 0.0000
[2019-04-27 19:55:37,143] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71000, global step 1137012: loss 0.3240
[2019-04-27 19:55:37,149] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71000, global step 1137013: learning rate 0.0000
[2019-04-27 19:55:37,327] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71000, global step 1137104: loss 0.3748
[2019-04-27 19:55:37,330] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71000, global step 1137105: learning rate 0.0000
[2019-04-27 19:55:37,366] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71000, global step 1137129: loss 0.3199
[2019-04-27 19:55:37,369] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71000, global step 1137129: learning rate 0.0000
[2019-04-27 19:55:37,459] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71000, global step 1137174: loss 0.3290
[2019-04-27 19:55:37,465] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71000, global step 1137175: learning rate 0.0000
[2019-04-27 19:55:37,562] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71000, global step 1137227: loss 0.2292
[2019-04-27 19:55:37,563] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71000, global step 1137227: learning rate 0.0000
[2019-04-27 19:55:37,764] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71500, global step 1137328: loss -2.0429
[2019-04-27 19:55:37,765] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71500, global step 1137328: learning rate 0.0000
[2019-04-27 19:55:38,741] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71500, global step 1137795: loss -3.8885
[2019-04-27 19:55:38,747] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71500, global step 1137797: learning rate 0.0000
[2019-04-27 19:55:39,579] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.6122485e-13 1.0000000e+00 9.0436257e-16 2.7975161e-12 1.5039856e-16], sum to 1.0000
[2019-04-27 19:55:39,584] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9875
[2019-04-27 19:55:39,593] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1819852.153058722 W.
[2019-04-27 19:55:39,598] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.33333333333334, 87.33333333333334, 1.0, 2.0, 0.9689998298407769, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426156577, 1819852.153058722, 1819852.153058721, 372282.2415757105], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2906400.0000, 
sim time next is 2907000.0000, 
raw observation next is [26.5, 86.5, 1.0, 2.0, 0.5442155429123868, 1.0, 1.0, 0.5442155429123868, 1.0, 2.0, 0.8664088681793852, 6.9112, 6.9112, 121.94756008, 1861998.295615154, 1861998.295615154, 365820.2086951214], 
processed observation next is [1.0, 0.6521739130434783, 0.5370370370370371, 0.865, 1.0, 1.0, 0.45739945584807956, 1.0, 0.5, 0.45739945584807956, 1.0, 1.0, 0.8330110852242314, 0.0, 0.0, 0.8096049824067558, 0.6649993912911265, 0.6649993912911265, 0.7035004013367719], 
reward next is 0.2965, 
noisyNet noise sample is [array([-1.3387039], dtype=float32), 0.65801036]. 
=============================================
[2019-04-27 19:55:39,614] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[34.302147]
 [34.708935]
 [34.473804]
 [33.599113]
 [33.21322 ]], R is [[33.50881577]
 [33.45780182]
 [33.41813278]
 [33.37586975]
 [33.04211044]].
[2019-04-27 19:55:45,992] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0274806e-25 1.0000000e+00 4.1219451e-29 1.5426268e-23 2.2986931e-29], sum to 1.0000
[2019-04-27 19:55:46,002] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3238
[2019-04-27 19:55:46,006] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.15, 99.33333333333334, 1.0, 2.0, 0.5893707608554889, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 682702.4555437241, 682702.4555437241, 156788.9512574606], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3023400.0000, 
sim time next is 3024000.0000, 
raw observation next is [23.0, 100.0, 1.0, 2.0, 0.5863049155116016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 680169.8014152587, 680169.8014152582, 156311.6548578711], 
processed observation next is [1.0, 0.0, 0.4074074074074074, 1.0, 1.0, 1.0, 0.5075058517995257, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24291778621973523, 0.24291778621973506, 0.30059933626513674], 
reward next is 0.6994, 
noisyNet noise sample is [array([-0.19356427], dtype=float32), 0.6649938]. 
=============================================
[2019-04-27 19:55:46,023] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[64.87918 ]
 [64.80999 ]
 [64.72357 ]
 [64.62143 ]
 [64.532135]], R is [[62.53749847]
 [62.61060715]
 [62.6819191 ]
 [62.75101089]
 [62.81772614]].
[2019-04-27 19:55:46,094] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.4037037e-24 1.0000000e+00 7.4963580e-27 1.5995352e-19 2.6204415e-26], sum to 1.0000
[2019-04-27 19:55:46,102] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9920
[2019-04-27 19:55:46,108] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.26666666666667, 93.66666666666667, 1.0, 2.0, 0.6088693384734479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 699822.8124878756, 699822.8124878751, 159901.3062110835], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3028800.0000, 
sim time next is 3029400.0000, 
raw observation next is [24.4, 93.5, 1.0, 2.0, 0.6147631605342778, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 704850.5152580119, 704850.5152580119, 160845.2393393603], 
processed observation next is [1.0, 0.043478260869565216, 0.4592592592592592, 0.935, 1.0, 1.0, 0.5413847149217593, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2517323268778614, 0.2517323268778614, 0.30931776796030824], 
reward next is 0.6907, 
noisyNet noise sample is [array([0.45956695], dtype=float32), 0.45019114]. 
=============================================
[2019-04-27 19:55:49,865] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.4605315e-26 1.0000000e+00 5.3672008e-28 3.4356394e-23 1.8953018e-29], sum to 1.0000
[2019-04-27 19:55:49,872] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2755
[2019-04-27 19:55:49,877] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 75.0, 1.0, 2.0, 0.7558060399204258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 861440.8190606196, 861440.8190606191, 186985.6200332145], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3088800.0000, 
sim time next is 3089400.0000, 
raw observation next is [29.83333333333333, 75.66666666666667, 1.0, 2.0, 0.7644798506396712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 871332.539489191, 871332.539489191, 188717.5144439273], 
processed observation next is [1.0, 0.782608695652174, 0.6604938271604937, 0.7566666666666667, 1.0, 1.0, 0.7196188698091324, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3111901926747111, 0.3111901926747111, 0.3629182970075525], 
reward next is 0.6371, 
noisyNet noise sample is [array([0.97274953], dtype=float32), 0.34066504]. 
=============================================
[2019-04-27 19:55:50,575] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3334479e-25 1.0000000e+00 1.8778939e-28 7.8848680e-22 2.9306130e-28], sum to 1.0000
[2019-04-27 19:55:50,583] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7915
[2019-04-27 19:55:50,590] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.13333333333333, 53.66666666666667, 1.0, 2.0, 0.4829786860274067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 581181.7074856109, 581181.7074856109, 140427.5778414997], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3115200.0000, 
sim time next is 3115800.0000, 
raw observation next is [28.2, 51.5, 1.0, 2.0, 0.4682373222975664, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 566642.286481591, 566642.286481591, 138274.3420336459], 
processed observation next is [1.0, 0.043478260869565216, 0.6, 0.515, 1.0, 1.0, 0.3669491932113886, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2023722451719968, 0.2023722451719968, 0.2659121962185498], 
reward next is 0.7341, 
noisyNet noise sample is [array([-0.6959271], dtype=float32), 1.2286556]. 
=============================================
[2019-04-27 19:55:51,580] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71500, global step 1144385: loss -79.1438
[2019-04-27 19:55:51,582] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71500, global step 1144386: learning rate 0.0000
[2019-04-27 19:55:52,301] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71500, global step 1144724: loss -106.6112
[2019-04-27 19:55:52,304] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71500, global step 1144725: learning rate 0.0000
[2019-04-27 19:55:52,444] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71500, global step 1144792: loss -56.2032
[2019-04-27 19:55:52,447] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71500, global step 1144793: learning rate 0.0000
[2019-04-27 19:55:52,575] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1536389e-23 1.0000000e+00 7.8016162e-26 3.8673533e-21 1.4422411e-25], sum to 1.0000
[2019-04-27 19:55:52,582] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3570
[2019-04-27 19:55:52,584] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71500, global step 1144865: loss -64.1721
[2019-04-27 19:55:52,586] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.58333333333333, 85.66666666666667, 1.0, 2.0, 0.6423572474497572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 733160.3053609648, 733160.3053609648, 165571.1013851172], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3451800.0000, 
sim time next is 3452400.0000, 
raw observation next is [25.5, 85.0, 1.0, 2.0, 0.6318879348253258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 724043.1903297909, 724043.1903297905, 163843.6231246729], 
processed observation next is [1.0, 1.0, 0.5, 0.85, 1.0, 1.0, 0.5617713509825307, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.258586853689211, 0.25858685368921086, 0.3150838906243709], 
reward next is 0.6849, 
noisyNet noise sample is [array([0.77820975], dtype=float32), 1.1945721]. 
=============================================
[2019-04-27 19:55:52,586] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71500, global step 1144865: learning rate 0.0000
[2019-04-27 19:55:52,679] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71500, global step 1144905: loss -235.1078
[2019-04-27 19:55:52,681] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71500, global step 1144905: learning rate 0.0000
[2019-04-27 19:55:52,767] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72000, global step 1144951: loss 5.3222
[2019-04-27 19:55:52,770] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72000, global step 1144953: learning rate 0.0000
[2019-04-27 19:55:52,811] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71500, global step 1144969: loss -202.7968
[2019-04-27 19:55:52,812] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71500, global step 1144969: learning rate 0.0000
[2019-04-27 19:55:52,845] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71500, global step 1144985: loss -178.9333
[2019-04-27 19:55:52,846] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71500, global step 1144985: loss -198.6633
[2019-04-27 19:55:52,847] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71500, global step 1144985: learning rate 0.0000
[2019-04-27 19:55:52,851] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71500, global step 1144986: learning rate 0.0000
[2019-04-27 19:55:52,896] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71500, global step 1145009: loss -97.1786
[2019-04-27 19:55:52,898] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71500, global step 1145010: learning rate 0.0000
[2019-04-27 19:55:52,987] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71500, global step 1145049: loss -99.2692
[2019-04-27 19:55:52,990] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71500, global step 1145049: learning rate 0.0000
[2019-04-27 19:55:53,074] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71500, global step 1145090: loss -166.3070
[2019-04-27 19:55:53,077] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71500, global step 1145090: learning rate 0.0000
[2019-04-27 19:55:53,114] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71500, global step 1145109: loss -95.0818
[2019-04-27 19:55:53,116] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71500, global step 1145109: learning rate 0.0000
[2019-04-27 19:55:53,343] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71500, global step 1145214: loss -138.7489
[2019-04-27 19:55:53,344] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71500, global step 1145215: learning rate 0.0000
[2019-04-27 19:55:53,549] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71500, global step 1145313: loss -7.4445
[2019-04-27 19:55:53,550] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71500, global step 1145313: learning rate 0.0000
[2019-04-27 19:55:53,972] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72000, global step 1145463: loss 2.8410
[2019-04-27 19:55:53,976] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72000, global step 1145463: learning rate 0.0000
[2019-04-27 19:55:55,488] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.13713074e-29 1.00000000e+00 2.74101138e-31 4.27574844e-26
 1.43221855e-33], sum to 1.0000
[2019-04-27 19:55:55,495] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9354
[2019-04-27 19:55:55,500] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 75.66666666666666, 1.0, 2.0, 0.5976344902619874, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 692522.6660965651, 692522.6660965651, 158220.3130606108], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3195600.0000, 
sim time next is 3196200.0000, 
raw observation next is [26.16666666666667, 74.83333333333334, 1.0, 2.0, 0.5796350760077945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 675639.7203346051, 675639.7203346051, 155320.5163890673], 
processed observation next is [1.0, 1.0, 0.5246913580246916, 0.7483333333333334, 1.0, 1.0, 0.4995655666759458, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2412999001195018, 0.2412999001195018, 0.2986933007482064], 
reward next is 0.7013, 
noisyNet noise sample is [array([-0.40252385], dtype=float32), 0.24468932]. 
=============================================
[2019-04-27 19:55:59,426] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.2344570e-31 1.0000000e+00 5.4313389e-35 5.8376346e-27 2.9667202e-35], sum to 1.0000
[2019-04-27 19:55:59,433] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5346
[2019-04-27 19:55:59,440] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.93333333333333, 78.0, 1.0, 2.0, 0.5822903748368836, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 676787.5739134444, 676787.5739134444, 155685.6868422117], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3271200.0000, 
sim time next is 3271800.0000, 
raw observation next is [25.96666666666667, 78.5, 1.0, 2.0, 0.5895041517715476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 683661.7149237253, 683661.7149237253, 156848.8812538577], 
processed observation next is [0.0, 0.8695652173913043, 0.517283950617284, 0.785, 1.0, 1.0, 0.5113144663946995, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24416489818704476, 0.24416489818704476, 0.3016324639497263], 
reward next is 0.6984, 
noisyNet noise sample is [array([-1.4743445], dtype=float32), -0.73724174]. 
=============================================
[2019-04-27 19:56:03,462] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-04-27 19:56:03,463] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 19:56:03,464] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:56:03,465] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 19:56:03,465] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:56:03,467] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 19:56:03,467] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 19:56:03,468] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:56:03,469] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:56:03,470] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 19:56:03,472] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:56:03,491] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run47
[2019-04-27 19:56:03,492] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run47
[2019-04-27 19:56:03,492] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run47
[2019-04-27 19:56:03,512] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run47
[2019-04-27 19:56:03,574] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run47
[2019-04-27 19:56:06,561] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.09057468]
[2019-04-27 19:56:06,562] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [34.86204441, 6.872141103500001, 1.0, 2.0, 0.3792101799526666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156597, 489201.6667699652, 489201.6667699652, 115943.1596998124]
[2019-04-27 19:56:06,563] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 19:56:06,565] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.8074733e-31 1.0000000e+00 1.4383775e-34 3.1311861e-28 4.7769260e-37], sampled 0.6363366753548577
[2019-04-27 19:56:06,768] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.09057468]
[2019-04-27 19:56:06,770] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [33.53117506333334, 4.908303112499999, 1.0, 2.0, 0.3684289526038271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 475288.989153152, 475288.989153152, 107499.9498038797]
[2019-04-27 19:56:06,771] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 19:56:06,774] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.7926936e-30 1.0000000e+00 3.8501661e-33 7.1138891e-27 2.9743804e-35], sampled 0.33528696883021303
[2019-04-27 19:56:12,865] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.09057468]
[2019-04-27 19:56:12,867] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.0315044, 45.16178530000001, 1.0, 2.0, 0.4389319723378501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 535055.9992103592, 535055.9992103592, 134009.5522674765]
[2019-04-27 19:56:12,867] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 19:56:12,869] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0960716e-29 1.0000000e+00 1.2933644e-32 1.8675373e-26 1.0033988e-34], sampled 0.0060249446743332324
[2019-04-27 19:56:40,655] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.09057468]
[2019-04-27 19:56:40,657] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.93333333333333, 46.66666666666667, 1.0, 2.0, 0.4911064941030391, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7818575328339364, 6.911199999999999, 6.9112, 121.9258208966945, 1119679.928829533, 1119679.928829533, 253884.1914724846]
[2019-04-27 19:56:40,658] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 19:56:40,659] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.5186910e-26 1.0000000e+00 3.1263506e-29 1.5780047e-23 8.4824876e-31], sampled 0.7517858069900009
[2019-04-27 19:56:58,536] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.09057468]
[2019-04-27 19:56:58,539] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.0, 83.0, 1.0, 2.0, 0.5632060140552573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 656727.8795208344, 656727.879520834, 152564.8038038145]
[2019-04-27 19:56:58,541] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 19:56:58,544] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.5826390e-29 1.0000000e+00 1.3476241e-31 1.5434140e-25 1.6124873e-33], sampled 0.17141042252518868
[2019-04-27 19:57:03,491] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.09057468]
[2019-04-27 19:57:03,495] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.40369742333333, 90.82533553666667, 1.0, 2.0, 0.5426989790783645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 638233.5008804756, 638233.5008804756, 149407.3019301434]
[2019-04-27 19:57:03,497] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 19:57:03,499] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.4113038e-28 1.0000000e+00 2.0086283e-31 2.1738408e-25 2.7229375e-33], sampled 0.20304592080981831
[2019-04-27 19:57:06,997] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.09057468]
[2019-04-27 19:57:06,999] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.0, 74.66666666666667, 1.0, 2.0, 0.615244172961707, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 707088.9030206772, 707088.9030206772, 161011.2846291801]
[2019-04-27 19:57:07,000] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 19:57:07,003] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0761400e-28 1.0000000e+00 1.4851884e-31 1.7406241e-25 1.9817747e-33], sampled 0.6549889290291853
[2019-04-27 19:57:09,228] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.09057468]
[2019-04-27 19:57:09,229] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.99547218666667, 89.21377059, 1.0, 2.0, 0.6056617052244775, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 694084.1263129064, 694084.1263129064, 159244.4955561546]
[2019-04-27 19:57:09,231] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 19:57:09,235] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.7014869e-29 1.0000000e+00 7.4085796e-32 9.5192228e-26 8.9666305e-34], sampled 0.4172377980921972
[2019-04-27 19:57:17,137] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.09057468]
[2019-04-27 19:57:17,139] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.16666666666667, 73.33333333333334, 1.0, 2.0, 0.5375175873747031, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 630677.4202002311, 630677.4202002311, 148500.1492278125]
[2019-04-27 19:57:17,140] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 19:57:17,145] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.9185567e-29 1.0000000e+00 1.4104566e-31 1.5781236e-25 1.6886992e-33], sampled 0.22108366204795937
[2019-04-27 19:57:30,508] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.09057468]
[2019-04-27 19:57:30,509] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.69616517, 77.34285204, 1.0, 2.0, 0.5176303928033242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 615233.9830629196, 615233.9830629196, 145611.1136449964]
[2019-04-27 19:57:30,510] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 19:57:30,514] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.8906081e-29 1.0000000e+00 2.1968666e-32 3.3133446e-26 2.2497166e-34], sampled 0.489065067663774
[2019-04-27 19:57:42,213] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.09057468]
[2019-04-27 19:57:42,215] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.33333333333334, 69.66666666666667, 1.0, 2.0, 0.4816378901047008, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 579256.8421304319, 579256.8421304319, 140210.4588242061]
[2019-04-27 19:57:42,215] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 19:57:42,218] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.1498235e-29 1.0000000e+00 1.1450670e-31 1.2952453e-25 1.2953042e-33], sampled 0.5480519231797275
[2019-04-27 19:57:43,922] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.09057468]
[2019-04-27 19:57:43,925] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.375198495, 81.28871692, 1.0, 2.0, 0.5289972471323559, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 626592.4626896122, 626592.4626896122, 147358.5996479838]
[2019-04-27 19:57:43,926] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 19:57:43,931] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.01585281e-29 1.00000000e+00 1.11677165e-32 1.95904454e-26
 1.10661819e-34], sampled 0.1475642394429063
[2019-04-27 19:57:55,190] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8098.3750 2445536342.0782 746.0000
[2019-04-27 19:57:55,199] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8582.0583 2248755290.3993 553.0000
[2019-04-27 19:57:55,378] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8770.2626 2170712315.3188 493.0000
[2019-04-27 19:57:55,524] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8923.3580 2120565869.7408 430.0000
[2019-04-27 19:57:55,525] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8699.3424 2195282598.7024 572.0000
[2019-04-27 19:57:56,542] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1150000, evaluation results [1150000.0, 8098.375034708541, 2445536342.078249, 746.0, 8770.262620159681, 2170712315.3187604, 493.0, 8923.358006227785, 2120565869.7408173, 430.0, 8582.058316992165, 2248755290.399296, 553.0, 8699.342416479873, 2195282598.702448, 572.0]
[2019-04-27 19:57:59,515] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.8986131e-18 1.0000000e+00 1.3310888e-19 1.1341338e-16 8.0179360e-21], sum to 1.0000
[2019-04-27 19:57:59,524] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6318
[2019-04-27 19:57:59,532] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1395276.066852006 W.
[2019-04-27 19:57:59,535] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.16666666666667, 99.00000000000001, 1.0, 2.0, 0.6099687558797283, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9712529299873445, 6.911199999999999, 6.9112, 121.9258251015877, 1395276.066852006, 1395276.066852006, 297702.0046663947], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3672600.0000, 
sim time next is 3673200.0000, 
raw observation next is [23.33333333333334, 98.0, 1.0, 2.0, 0.4566885823498656, 1.0, 1.0, 0.4566885823498656, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260425493356, 1041156.778849798, 1041156.778849799, 222312.4450123947], 
processed observation next is [1.0, 0.5217391304347826, 0.4197530864197533, 0.98, 1.0, 1.0, 0.35320069327364956, 1.0, 0.5, 0.35320069327364956, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.809462128379799, 0.37184170673207073, 0.37184170673207106, 0.42752393271614364], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.1758895], dtype=float32), -0.52412975]. 
=============================================
[2019-04-27 19:58:00,965] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72000, global step 1152239: loss 4.1179
[2019-04-27 19:58:00,971] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72000, global step 1152240: learning rate 0.0000
[2019-04-27 19:58:01,712] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72000, global step 1152613: loss 5.1850
[2019-04-27 19:58:01,713] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72000, global step 1152614: learning rate 0.0000
[2019-04-27 19:58:01,971] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72000, global step 1152742: loss 5.5255
[2019-04-27 19:58:01,980] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72000, global step 1152744: learning rate 0.0000
[2019-04-27 19:58:02,043] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.056510e-22 1.000000e+00 7.035313e-24 1.654261e-20 2.393534e-25], sum to 1.0000
[2019-04-27 19:58:02,051] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6378
[2019-04-27 19:58:02,057] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.75, 95.66666666666666, 1.0, 2.0, 0.6636261565896012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 756325.6330615779, 756325.6330615774, 169370.9416504656], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3721800.0000, 
sim time next is 3722400.0000, 
raw observation next is [24.7, 96.0, 1.0, 2.0, 0.6620022063601347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 754473.9283978356, 754473.9283978356, 169073.9856961255], 
processed observation next is [1.0, 0.08695652173913043, 0.4703703703703703, 0.96, 1.0, 1.0, 0.5976216742382556, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2694549744277984, 0.2694549744277984, 0.32514228018485675], 
reward next is 0.6749, 
noisyNet noise sample is [array([0.3515005], dtype=float32), 0.96672595]. 
=============================================
[2019-04-27 19:58:02,076] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72000, global step 1152797: loss 5.1168
[2019-04-27 19:58:02,077] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72000, global step 1152797: learning rate 0.0000
[2019-04-27 19:58:02,289] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72000, global step 1152904: loss 5.8219
[2019-04-27 19:58:02,294] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72000, global step 1152905: learning rate 0.0000
[2019-04-27 19:58:02,302] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72000, global step 1152909: loss 5.9311
[2019-04-27 19:58:02,303] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72000, global step 1152910: learning rate 0.0000
[2019-04-27 19:58:02,378] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72000, global step 1152949: loss 5.9969
[2019-04-27 19:58:02,379] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72000, global step 1152949: learning rate 0.0000
[2019-04-27 19:58:02,425] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72000, global step 1152973: loss 6.0419
[2019-04-27 19:58:02,429] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72000, global step 1152974: learning rate 0.0000
[2019-04-27 19:58:02,553] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.1516009e-23 1.0000000e+00 6.0572325e-25 3.7058281e-21 8.8332429e-26], sum to 1.0000
[2019-04-27 19:58:02,564] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3302
[2019-04-27 19:58:02,572] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.91666666666667, 93.50000000000001, 1.0, 2.0, 0.660580565573337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 752852.9101768514, 752852.9101768514, 168813.910160873], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3460200.0000, 
sim time next is 3460800.0000, 
raw observation next is [24.83333333333334, 93.0, 1.0, 2.0, 0.6530873355043881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 744308.8517556136, 744308.8517556131, 167450.8929907721], 
processed observation next is [1.0, 0.043478260869565216, 0.47530864197530887, 0.93, 1.0, 1.0, 0.5870087327433192, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2658245899127191, 0.26582458991271896, 0.3220209480591771], 
reward next is 0.6780, 
noisyNet noise sample is [array([-3.6485868], dtype=float32), -1.001039]. 
=============================================
[2019-04-27 19:58:02,579] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72000, global step 1153050: loss 6.0986
[2019-04-27 19:58:02,583] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72000, global step 1153051: learning rate 0.0000
[2019-04-27 19:58:02,604] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72500, global step 1153061: loss 79.5976
[2019-04-27 19:58:02,607] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72500, global step 1153062: learning rate 0.0000
[2019-04-27 19:58:02,610] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72000, global step 1153064: loss 6.0769
[2019-04-27 19:58:02,611] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72000, global step 1153064: learning rate 0.0000
[2019-04-27 19:58:02,751] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72000, global step 1153137: loss 5.7450
[2019-04-27 19:58:02,755] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72000, global step 1153138: learning rate 0.0000
[2019-04-27 19:58:02,784] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72000, global step 1153152: loss 5.4386
[2019-04-27 19:58:02,788] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72000, global step 1153153: learning rate 0.0000
[2019-04-27 19:58:02,929] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72000, global step 1153225: loss 4.8224
[2019-04-27 19:58:02,931] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72000, global step 1153226: learning rate 0.0000
[2019-04-27 19:58:03,133] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72000, global step 1153323: loss 3.9631
[2019-04-27 19:58:03,135] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72000, global step 1153325: learning rate 0.0000
[2019-04-27 19:58:03,898] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72500, global step 1153707: loss 53.1493
[2019-04-27 19:58:03,901] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72500, global step 1153709: learning rate 0.0000
[2019-04-27 19:58:15,860] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.1847661e-31 1.0000000e+00 5.2859093e-34 2.7071411e-27 4.6415102e-34], sum to 1.0000
[2019-04-27 19:58:15,868] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2793
[2019-04-27 19:58:15,873] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.6678205613402376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 761108.3119325403, 761108.3119325398, 170140.1196268963], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3705600.0000, 
sim time next is 3706200.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.6666920537628698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 759821.5258509154, 759821.5258509154, 169932.9163313321], 
processed observation next is [1.0, 0.9130434782608695, 0.48148148148148145, 0.94, 1.0, 1.0, 0.6032048259081783, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2713648306610412, 0.2713648306610412, 0.32679406986794635], 
reward next is 0.6732, 
noisyNet noise sample is [array([1.7803098], dtype=float32), -1.2118146]. 
=============================================
[2019-04-27 19:58:16,928] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72500, global step 1160316: loss -12.7842
[2019-04-27 19:58:16,930] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72500, global step 1160316: learning rate 0.0000
[2019-04-27 19:58:17,710] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72500, global step 1160716: loss -53.8923
[2019-04-27 19:58:17,713] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72500, global step 1160716: learning rate 0.0000
[2019-04-27 19:58:17,726] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72500, global step 1160723: loss -4.0472
[2019-04-27 19:58:17,728] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72500, global step 1160724: learning rate 0.0000
[2019-04-27 19:58:17,991] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73000, global step 1160856: loss 0.5599
[2019-04-27 19:58:17,994] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73000, global step 1160857: learning rate 0.0000
[2019-04-27 19:58:18,071] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72500, global step 1160895: loss -67.0649
[2019-04-27 19:58:18,073] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72500, global step 1160895: learning rate 0.0000
[2019-04-27 19:58:18,124] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72500, global step 1160922: loss -88.6622
[2019-04-27 19:58:18,127] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72500, global step 1160922: learning rate 0.0000
[2019-04-27 19:58:18,163] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72500, global step 1160938: loss 29.1264
[2019-04-27 19:58:18,166] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72500, global step 1160939: learning rate 0.0000
[2019-04-27 19:58:18,175] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72500, global step 1160944: loss -41.4930
[2019-04-27 19:58:18,176] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72500, global step 1160944: learning rate 0.0000
[2019-04-27 19:58:18,226] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72500, global step 1160974: loss 10.5416
[2019-04-27 19:58:18,228] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72500, global step 1160975: learning rate 0.0000
[2019-04-27 19:58:18,438] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72500, global step 1161075: loss -45.6569
[2019-04-27 19:58:18,441] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72500, global step 1161077: learning rate 0.0000
[2019-04-27 19:58:18,471] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72500, global step 1161091: loss -13.6038
[2019-04-27 19:58:18,472] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72500, global step 1161093: learning rate 0.0000
[2019-04-27 19:58:18,484] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72500, global step 1161098: loss -0.4712
[2019-04-27 19:58:18,485] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72500, global step 1161098: learning rate 0.0000
[2019-04-27 19:58:18,553] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72500, global step 1161135: loss -1.5861
[2019-04-27 19:58:18,554] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72500, global step 1161135: learning rate 0.0000
[2019-04-27 19:58:18,613] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72500, global step 1161160: loss -13.8398
[2019-04-27 19:58:18,613] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72500, global step 1161160: learning rate 0.0000
[2019-04-27 19:58:18,885] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72500, global step 1161303: loss 5.1740
[2019-04-27 19:58:18,888] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72500, global step 1161303: learning rate 0.0000
[2019-04-27 19:58:19,351] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73000, global step 1161538: loss 0.9074
[2019-04-27 19:58:19,352] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73000, global step 1161538: learning rate 0.0000
[2019-04-27 19:58:32,317] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73000, global step 1168201: loss 0.8961
[2019-04-27 19:58:32,319] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73000, global step 1168201: learning rate 0.0000
[2019-04-27 19:58:33,146] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.9849253e-24 1.0000000e+00 1.8247333e-28 3.6839211e-23 2.9177068e-28], sum to 1.0000
[2019-04-27 19:58:33,154] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9307
[2019-04-27 19:58:33,158] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.16666666666666, 99.0, 1.0, 2.0, 0.6659853117778005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 759015.6610729307, 759015.6610729302, 169802.302650631], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4053000.0000, 
sim time next is 4053600.0000, 
raw observation next is [24.0, 100.0, 1.0, 2.0, 0.66701890898558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 760194.2238362391, 760194.2238362391, 169991.7295244461], 
processed observation next is [1.0, 0.9565217391304348, 0.4444444444444444, 1.0, 1.0, 1.0, 0.6035939392685477, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2714979370843711, 0.2714979370843711, 0.32690717216239634], 
reward next is 0.6731, 
noisyNet noise sample is [array([-1.1009322], dtype=float32), 0.889513]. 
=============================================
[2019-04-27 19:58:33,260] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73000, global step 1168658: loss 0.7068
[2019-04-27 19:58:33,268] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73000, global step 1168658: learning rate 0.0000
[2019-04-27 19:58:33,276] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73000, global step 1168659: loss 0.6226
[2019-04-27 19:58:33,277] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73000, global step 1168659: learning rate 0.0000
[2019-04-27 19:58:33,675] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73000, global step 1168848: loss 0.3000
[2019-04-27 19:58:33,677] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73000, global step 1168850: learning rate 0.0000
[2019-04-27 19:58:33,704] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73000, global step 1168862: loss 0.2884
[2019-04-27 19:58:33,707] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73000, global step 1168862: learning rate 0.0000
[2019-04-27 19:58:33,745] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73000, global step 1168881: loss 0.3176
[2019-04-27 19:58:33,748] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73000, global step 1168881: learning rate 0.0000
[2019-04-27 19:58:33,823] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73000, global step 1168922: loss 0.3365
[2019-04-27 19:58:33,826] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73000, global step 1168923: learning rate 0.0000
[2019-04-27 19:58:33,954] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73000, global step 1168989: loss 0.3538
[2019-04-27 19:58:33,956] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73000, global step 1168989: learning rate 0.0000
[2019-04-27 19:58:34,008] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73500, global step 1169012: loss 117.3438
[2019-04-27 19:58:34,009] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73500, global step 1169012: learning rate 0.0000
[2019-04-27 19:58:34,170] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73000, global step 1169089: loss 0.2075
[2019-04-27 19:58:34,172] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73000, global step 1169089: learning rate 0.0000
[2019-04-27 19:58:34,210] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73000, global step 1169106: loss 0.2068
[2019-04-27 19:58:34,213] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73000, global step 1169108: learning rate 0.0000
[2019-04-27 19:58:34,294] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73000, global step 1169151: loss 0.1307
[2019-04-27 19:58:34,295] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73000, global step 1169152: loss 0.0875
[2019-04-27 19:58:34,297] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73000, global step 1169152: learning rate 0.0000
[2019-04-27 19:58:34,298] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73000, global step 1169152: learning rate 0.0000
[2019-04-27 19:58:34,362] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73000, global step 1169181: loss 0.1003
[2019-04-27 19:58:34,365] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73000, global step 1169182: learning rate 0.0000
[2019-04-27 19:58:34,617] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73000, global step 1169303: loss 0.1412
[2019-04-27 19:58:34,619] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73000, global step 1169303: learning rate 0.0000
[2019-04-27 19:58:35,725] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73500, global step 1169823: loss -45.4207
[2019-04-27 19:58:35,727] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73500, global step 1169824: learning rate 0.0000
[2019-04-27 19:58:42,116] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.7700096e-21 1.0000000e+00 7.6831913e-24 7.6429211e-21 1.4982712e-23], sum to 1.0000
[2019-04-27 19:58:42,124] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7481
[2019-04-27 19:58:42,133] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1595742.457022193 W.
[2019-04-27 19:58:42,139] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.21666666666667, 34.5, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.649246729740392, 6.9112, 121.9231154112839, 1595742.457022193, 1217805.639264147, 248425.1703358662], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4194600.0000, 
sim time next is 4195200.0000, 
raw observation next is [33.43333333333334, 33.0, 1.0, 2.0, 0.4809051218280138, 1.0, 1.0, 0.4809051218280138, 1.0, 1.0, 0.767316274590243, 6.911199999999999, 6.9112, 121.94756008, 1676747.696356532, 1676747.696356532, 334426.1811552747], 
processed observation next is [1.0, 0.5652173913043478, 0.7938271604938273, 0.33, 1.0, 1.0, 0.3820299069381117, 1.0, 0.5, 0.3820299069381117, 1.0, 0.5, 0.7091453432378036, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5988384629844757, 0.5988384629844757, 0.6431272714524513], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.5370842], dtype=float32), -0.17247294]. 
=============================================
[2019-04-27 19:58:42,362] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.4727706e-21 1.0000000e+00 5.1257657e-25 4.2329453e-22 1.5232180e-24], sum to 1.0000
[2019-04-27 19:58:42,372] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6828
[2019-04-27 19:58:42,379] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1554660.099070175 W.
[2019-04-27 19:58:42,382] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [34.2, 29.0, 1.0, 2.0, 0.706409663030623, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9657797107656284, 6.911199999999999, 6.9112, 121.9260426156618, 1554660.099070175, 1554660.099070176, 311480.2996002322], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4199400.0000, 
sim time next is 4200000.0000, 
raw observation next is [34.16666666666667, 29.66666666666666, 1.0, 2.0, 0.780893839351034, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9655368510046942, 6.911199999999999, 6.9112, 121.9260426156618, 1643734.689448399, 1643734.6894484, 325723.3619854025], 
processed observation next is [1.0, 0.6086956521739131, 0.8209876543209879, 0.29666666666666663, 1.0, 1.0, 0.7391593325607547, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9569210637558678, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5870481033744283, 0.5870481033744286, 0.6263910807411586], 
reward next is 0.3736, 
noisyNet noise sample is [array([1.306768], dtype=float32), -0.4812399]. 
=============================================
[2019-04-27 19:58:42,396] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[50.692554]
 [49.908867]
 [49.37226 ]
 [48.543335]
 [48.260372]], R is [[51.82141495]
 [51.70420074]
 [51.57809067]
 [51.4438591 ]
 [51.35942459]].
[2019-04-27 19:58:46,618] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-04-27 19:58:46,622] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 19:58:46,623] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:58:46,622] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 19:58:46,624] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 19:58:46,627] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 19:58:46,629] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 19:58:46,631] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:58:46,629] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:58:46,632] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:58:46,633] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 19:58:46,647] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run48
[2019-04-27 19:58:46,673] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run48
[2019-04-27 19:58:46,673] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run48
[2019-04-27 19:58:46,693] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run48
[2019-04-27 19:58:46,735] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run48
[2019-04-27 19:59:03,744] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.09083734]
[2019-04-27 19:59:03,746] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [17.0, 78.83333333333334, 1.0, 2.0, 0.344382685655179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 444259.2980758913, 444259.2980758913, 110568.1973609904]
[2019-04-27 19:59:03,747] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 19:59:03,749] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.3245493e-27 1.0000000e+00 2.2413435e-30 6.7891303e-27 1.0211669e-31], sampled 0.5280149907919804
[2019-04-27 20:00:05,301] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.09083734]
[2019-04-27 20:00:05,302] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [35.63333333333333, 47.33333333333334, 1.0, 2.0, 0.7196529556267771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 820212.7720206317, 820212.7720206317, 179904.6267512777]
[2019-04-27 20:00:05,303] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 20:00:05,305] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.8259092e-29 1.0000000e+00 1.8744260e-32 6.2805659e-29 4.6094674e-34], sampled 0.21559132596572428
[2019-04-27 20:00:31,974] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.09083734]
[2019-04-27 20:00:31,975] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.0, 47.0, 1.0, 2.0, 0.2798381965609152, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 358490.4373315661, 358490.4373315661, 113121.496047105]
[2019-04-27 20:00:31,975] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 20:00:31,979] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.3742251e-29 1.0000000e+00 6.4200594e-32 3.1069018e-28 2.6511894e-33], sampled 0.2528096041202954
[2019-04-27 20:00:34,656] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.09083734]
[2019-04-27 20:00:34,656] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.378799355, 75.15996696666667, 1.0, 2.0, 0.3820734939329428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 474494.9746019621, 474494.9746019616, 126146.4294796891]
[2019-04-27 20:00:34,657] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 20:00:34,660] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.8369694e-28 1.0000000e+00 2.4158541e-31 1.0685319e-27 1.2922597e-32], sampled 0.9403705312642603
[2019-04-27 20:00:38,177] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8922.6628 2120599135.7723 430.0000
[2019-04-27 20:00:38,239] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8582.8795 2248773970.1662 553.0000
[2019-04-27 20:00:38,269] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8769.4422 2170768739.9937 493.0000
[2019-04-27 20:00:38,566] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8699.3424 2195282598.7024 572.0000
[2019-04-27 20:00:38,578] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8098.3752 2445474890.6189 746.0000
[2019-04-27 20:00:39,593] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1175000, evaluation results [1175000.0, 8098.3752090653525, 2445474890.6188803, 746.0, 8769.442185004564, 2170768739.993712, 493.0, 8922.662781171732, 2120599135.7722971, 430.0, 8582.879467926026, 2248773970.1662407, 553.0, 8699.342416479873, 2195282598.702448, 572.0]
[2019-04-27 20:00:42,026] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73500, global step 1176242: loss -89.7162
[2019-04-27 20:00:42,029] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73500, global step 1176242: learning rate 0.0000
[2019-04-27 20:00:42,875] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73500, global step 1176676: loss -7.7616
[2019-04-27 20:00:42,878] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73500, global step 1176677: learning rate 0.0000
[2019-04-27 20:00:42,892] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74000, global step 1176683: loss 0.4813
[2019-04-27 20:00:42,893] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73500, global step 1176683: loss -43.8516
[2019-04-27 20:00:42,898] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74000, global step 1176684: learning rate 0.0000
[2019-04-27 20:00:42,902] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73500, global step 1176686: learning rate 0.0000
[2019-04-27 20:00:43,214] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73500, global step 1176852: loss -67.6290
[2019-04-27 20:00:43,219] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73500, global step 1176852: learning rate 0.0000
[2019-04-27 20:00:43,284] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73500, global step 1176882: loss -22.8415
[2019-04-27 20:00:43,287] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73500, global step 1176883: learning rate 0.0000
[2019-04-27 20:00:43,340] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73500, global step 1176914: loss -96.1245
[2019-04-27 20:00:43,343] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73500, global step 1176914: learning rate 0.0000
[2019-04-27 20:00:43,542] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73500, global step 1177015: loss -143.7554
[2019-04-27 20:00:43,543] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73500, global step 1177015: learning rate 0.0000
[2019-04-27 20:00:43,593] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73500, global step 1177041: loss -146.8183
[2019-04-27 20:00:43,595] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73500, global step 1177041: learning rate 0.0000
[2019-04-27 20:00:43,745] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73500, global step 1177119: loss -136.8455
[2019-04-27 20:00:43,747] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73500, global step 1177119: learning rate 0.0000
[2019-04-27 20:00:43,799] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73500, global step 1177139: loss -118.9987
[2019-04-27 20:00:43,802] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73500, global step 1177139: learning rate 0.0000
[2019-04-27 20:00:43,841] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73500, global step 1177163: loss -36.3740
[2019-04-27 20:00:43,842] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73500, global step 1177163: learning rate 0.0000
[2019-04-27 20:00:43,855] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73500, global step 1177170: loss -57.1598
[2019-04-27 20:00:43,856] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73500, global step 1177170: learning rate 0.0000
[2019-04-27 20:00:43,931] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73500, global step 1177207: loss -97.9739
[2019-04-27 20:00:43,935] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73500, global step 1177207: learning rate 0.0000
[2019-04-27 20:00:44,086] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73500, global step 1177284: loss -39.4941
[2019-04-27 20:00:44,087] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73500, global step 1177284: learning rate 0.0000
[2019-04-27 20:00:44,577] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74000, global step 1177530: loss 0.8168
[2019-04-27 20:00:44,579] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74000, global step 1177531: learning rate 0.0000
[2019-04-27 20:00:57,241] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.4046960e-21 1.0000000e+00 2.7661480e-23 2.7952925e-19 1.5608108e-23], sum to 1.0000
[2019-04-27 20:00:57,249] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3393
[2019-04-27 20:00:57,249] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1780990.674047101 W.
[2019-04-27 20:00:57,255] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.1, 66.5, 1.0, 2.0, 0.9349582547015297, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260425465249, 1780990.674047101, 1780990.674047102, 364621.5648902371], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4627800.0000, 
sim time next is 4628400.0000, 
raw observation next is [29.23333333333333, 65.66666666666667, 1.0, 2.0, 0.785118952741879, 1.0, 1.0, 0.785118952741879, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156407, 1790751.471913522, 1790751.471913521, 337643.2222209226], 
processed observation next is [1.0, 0.5652173913043478, 0.6382716049382715, 0.6566666666666667, 1.0, 1.0, 0.7441892294546179, 1.0, 0.5, 0.7441892294546179, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288199958, 0.6395540971119722, 0.6395540971119718, 0.6493138888863896], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.0525435], dtype=float32), 2.3091536]. 
=============================================
[2019-04-27 20:00:57,782] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74000, global step 1184245: loss 0.1307
[2019-04-27 20:00:57,789] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74000, global step 1184247: learning rate 0.0000
[2019-04-27 20:00:58,509] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74000, global step 1184612: loss 0.2676
[2019-04-27 20:00:58,511] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74000, global step 1184613: learning rate 0.0000
[2019-04-27 20:00:58,670] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74000, global step 1184695: loss 0.1681
[2019-04-27 20:00:58,671] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74000, global step 1184695: learning rate 0.0000
[2019-04-27 20:00:58,864] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74000, global step 1184788: loss 0.0500
[2019-04-27 20:00:58,866] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74500, global step 1184788: loss 1.5577
[2019-04-27 20:00:58,866] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74000, global step 1184788: learning rate 0.0000
[2019-04-27 20:00:58,869] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74500, global step 1184788: learning rate 0.0000
[2019-04-27 20:00:58,879] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74000, global step 1184795: loss 0.1133
[2019-04-27 20:00:58,882] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74000, global step 1184795: learning rate 0.0000
[2019-04-27 20:00:59,006] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74000, global step 1184859: loss 0.1524
[2019-04-27 20:00:59,008] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74000, global step 1184860: learning rate 0.0000
[2019-04-27 20:00:59,199] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74000, global step 1184962: loss 0.2247
[2019-04-27 20:00:59,203] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74000, global step 1184963: learning rate 0.0000
[2019-04-27 20:00:59,372] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74000, global step 1185050: loss 0.0938
[2019-04-27 20:00:59,373] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74000, global step 1185050: learning rate 0.0000
[2019-04-27 20:00:59,458] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74000, global step 1185097: loss 0.0757
[2019-04-27 20:00:59,463] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74000, global step 1185098: learning rate 0.0000
[2019-04-27 20:00:59,616] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74000, global step 1185174: loss 0.1535
[2019-04-27 20:00:59,622] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74000, global step 1185176: learning rate 0.0000
[2019-04-27 20:00:59,631] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74000, global step 1185183: loss 0.0087
[2019-04-27 20:00:59,634] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74000, global step 1185183: learning rate 0.0000
[2019-04-27 20:00:59,754] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74000, global step 1185247: loss 0.0451
[2019-04-27 20:00:59,756] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74000, global step 1185247: learning rate 0.0000
[2019-04-27 20:00:59,783] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74000, global step 1185258: loss 0.0530
[2019-04-27 20:00:59,786] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74000, global step 1185259: learning rate 0.0000
[2019-04-27 20:00:59,935] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74000, global step 1185338: loss 0.0528
[2019-04-27 20:00:59,937] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74000, global step 1185338: learning rate 0.0000
[2019-04-27 20:01:00,794] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74500, global step 1185767: loss 1.5462
[2019-04-27 20:01:00,796] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74500, global step 1185768: learning rate 0.0000
[2019-04-27 20:01:05,364] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3958545e-24 1.0000000e+00 1.3370331e-26 4.3986750e-24 1.9487735e-26], sum to 1.0000
[2019-04-27 20:01:05,370] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8824
[2019-04-27 20:01:05,376] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666666, 95.33333333333334, 1.0, 2.0, 0.6744947902870793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 780906.8064169359, 780906.8064169359, 171969.7466232431], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4768800.0000, 
sim time next is 4769400.0000, 
raw observation next is [23.58333333333334, 95.66666666666666, 1.0, 2.0, 0.6628769977609125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 768150.4308315817, 768150.4308315817, 169853.9862633504], 
processed observation next is [1.0, 0.17391304347826086, 0.4290123456790126, 0.9566666666666666, 1.0, 1.0, 0.5986630925725148, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27433943958270773, 0.27433943958270773, 0.32664228127567385], 
reward next is 0.6734, 
noisyNet noise sample is [array([-0.27960214], dtype=float32), 0.37926993]. 
=============================================
[2019-04-27 20:01:12,761] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.5512167e-26 1.0000000e+00 1.4470665e-28 3.0588787e-25 3.2488464e-28], sum to 1.0000
[2019-04-27 20:01:12,769] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6463
[2019-04-27 20:01:12,772] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.73333333333333, 73.66666666666667, 1.0, 2.0, 0.7343566242068686, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.926042615597, 836980.1897522464, 836980.1897522464, 182760.8457763135], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4900800.0000, 
sim time next is 4901400.0000, 
raw observation next is [30.3, 77.5, 1.0, 2.0, 0.7384889055027991, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 841692.5278468259, 841692.5278468254, 183570.3473023544], 
processed observation next is [1.0, 0.7391304347826086, 0.6777777777777778, 0.775, 1.0, 1.0, 0.6886772684557132, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3006044742310092, 0.30060447423100906, 0.35301989865837385], 
reward next is 0.6470, 
noisyNet noise sample is [array([-0.80732656], dtype=float32), -1.635829]. 
=============================================
[2019-04-27 20:01:13,299] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.5602861e-23 1.0000000e+00 1.0954014e-24 3.0240881e-22 5.5959155e-25], sum to 1.0000
[2019-04-27 20:01:13,306] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1319
[2019-04-27 20:01:13,311] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 79.66666666666667, 1.0, 2.0, 0.8225245862024017, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 974860.3800043736, 974860.3800043731, 202460.0222417321], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4954800.0000, 
sim time next is 4955400.0000, 
raw observation next is [24.75, 80.5, 1.0, 2.0, 0.8930843977613608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1054297.529979776, 1054297.529979776, 217768.0664475748], 
processed observation next is [1.0, 0.34782608695652173, 0.4722222222222222, 0.805, 1.0, 1.0, 0.8727195211444772, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.37653483213563427, 0.37653483213563427, 0.4187847431684131], 
reward next is 0.5812, 
noisyNet noise sample is [array([1.2171661], dtype=float32), -0.2970455]. 
=============================================
[2019-04-27 20:01:13,352] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74500, global step 1192223: loss 1.3612
[2019-04-27 20:01:13,353] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74500, global step 1192223: learning rate 0.0000
[2019-04-27 20:01:13,526] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.0195893e-24 1.0000000e+00 9.4745084e-28 2.5570604e-22 4.9835321e-25], sum to 1.0000
[2019-04-27 20:01:13,533] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7293
[2019-04-27 20:01:13,538] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.66666666666667, 94.0, 1.0, 2.0, 0.861382225249219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 981849.8808982555, 981849.8808982555, 208959.0613235775], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4915200.0000, 
sim time next is 4915800.0000, 
raw observation next is [27.5, 94.0, 1.0, 2.0, 0.848784077106386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 967480.767738016, 967480.767738016, 206234.9912326126], 
processed observation next is [1.0, 0.9130434782608695, 0.5740740740740741, 0.94, 1.0, 1.0, 0.8199810441742691, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.34552884562072, 0.34552884562072, 0.39660575237040885], 
reward next is 0.6034, 
noisyNet noise sample is [array([0.39855775], dtype=float32), -0.7304648]. 
=============================================
[2019-04-27 20:01:14,179] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75000, global step 1192621: loss 0.7795
[2019-04-27 20:01:14,180] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75000, global step 1192621: learning rate 0.0000
[2019-04-27 20:01:14,215] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74500, global step 1192639: loss 3.2373
[2019-04-27 20:01:14,218] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74500, global step 1192639: learning rate 0.0000
[2019-04-27 20:01:14,380] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74500, global step 1192714: loss 2.8759
[2019-04-27 20:01:14,385] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74500, global step 1192715: learning rate 0.0000
[2019-04-27 20:01:14,665] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74500, global step 1192849: loss 2.9731
[2019-04-27 20:01:14,667] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74500, global step 1192850: learning rate 0.0000
[2019-04-27 20:01:14,674] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74500, global step 1192852: loss 3.2130
[2019-04-27 20:01:14,677] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74500, global step 1192852: learning rate 0.0000
[2019-04-27 20:01:14,686] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74500, global step 1192857: loss 3.4897
[2019-04-27 20:01:14,687] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74500, global step 1192858: learning rate 0.0000
[2019-04-27 20:01:14,704] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74500, global step 1192865: loss 4.2165
[2019-04-27 20:01:14,706] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74500, global step 1192865: learning rate 0.0000
[2019-04-27 20:01:15,087] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74500, global step 1193048: loss 5.1712
[2019-04-27 20:01:15,089] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74500, global step 1193048: learning rate 0.0000
[2019-04-27 20:01:15,234] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74500, global step 1193126: loss 6.3367
[2019-04-27 20:01:15,237] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74500, global step 1193126: learning rate 0.0000
[2019-04-27 20:01:15,298] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74500, global step 1193153: loss 6.0933
[2019-04-27 20:01:15,302] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74500, global step 1193154: learning rate 0.0000
[2019-04-27 20:01:15,315] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74500, global step 1193162: loss 6.9003
[2019-04-27 20:01:15,318] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74500, global step 1193162: learning rate 0.0000
[2019-04-27 20:01:15,438] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74500, global step 1193220: loss 6.5783
[2019-04-27 20:01:15,439] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74500, global step 1193220: learning rate 0.0000
[2019-04-27 20:01:15,521] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74500, global step 1193260: loss 6.2062
[2019-04-27 20:01:15,526] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74500, global step 1193261: learning rate 0.0000
[2019-04-27 20:01:15,645] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74500, global step 1193319: loss 6.0206
[2019-04-27 20:01:15,647] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74500, global step 1193320: learning rate 0.0000
[2019-04-27 20:01:15,674] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.11402105e-13 1.00000000e+00 1.11847821e-15 5.72845753e-13
 6.79790527e-15], sum to 1.0000
[2019-04-27 20:01:15,682] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8474
[2019-04-27 20:01:15,688] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1328683.606966044 W.
[2019-04-27 20:01:15,692] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 83.0, 1.0, 2.0, 0.5809774372534294, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9250802129440288, 6.911199999999999, 6.9112, 121.9260426155736, 1328683.606966044, 1328683.606966045, 286480.1708518103], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4959600.0000, 
sim time next is 4960200.0000, 
raw observation next is [25.0, 83.0, 1.0, 2.0, 0.573804079613891, 1.0, 1.0, 0.573804079613891, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1309272.535567275, 1309272.535567276, 259194.2861359341], 
processed observation next is [1.0, 0.391304347826087, 0.48148148148148145, 0.83, 1.0, 1.0, 0.49262390430225117, 1.0, 0.5, 0.49262390430225117, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.46759733413116966, 0.46759733413117, 0.4984505502614117], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.26892206], dtype=float32), -1.8616946]. 
=============================================
[2019-04-27 20:01:16,138] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75000, global step 1193550: loss 0.1888
[2019-04-27 20:01:16,142] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75000, global step 1193550: learning rate 0.0000
[2019-04-27 20:01:18,093] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.4556747e-28 1.0000000e+00 3.8796864e-31 7.9863746e-28 4.9132541e-33], sum to 1.0000
[2019-04-27 20:01:18,099] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4549
[2019-04-27 20:01:18,107] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 100.0, 1.0, 2.0, 0.5798893898433631, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 673006.4251672392, 673006.4251672392, 155232.8688847886], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5014200.0000, 
sim time next is 5014800.0000, 
raw observation next is [23.0, 100.0, 1.0, 2.0, 0.5811371732558398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 674453.438564388, 674453.4385643876, 155444.5889903254], 
processed observation next is [0.0, 0.043478260869565216, 0.4074074074074074, 1.0, 1.0, 1.0, 0.5013537776855236, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24087622805870998, 0.24087622805870987, 0.29893190190447194], 
reward next is 0.7011, 
noisyNet noise sample is [array([-0.59405994], dtype=float32), 0.24760179]. 
=============================================
[2019-04-27 20:01:18,905] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.5384441e-30 1.0000000e+00 2.9613961e-34 3.0810497e-31 1.3521793e-34], sum to 1.0000
[2019-04-27 20:01:18,914] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1892
[2019-04-27 20:01:18,921] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.03333333333334, 70.66666666666667, 1.0, 2.0, 0.6260619411207824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 713818.8350089149, 713818.8350089149, 162634.1519366887], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5340000.0000, 
sim time next is 5340600.0000, 
raw observation next is [28.0, 71.0, 1.0, 2.0, 0.628694950867173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 716496.4110410073, 716496.4110410073, 163083.0487791537], 
processed observation next is [1.0, 0.8260869565217391, 0.5925925925925926, 0.71, 1.0, 1.0, 0.5579701796037774, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2558915753717883, 0.2558915753717883, 0.31362124765221866], 
reward next is 0.6864, 
noisyNet noise sample is [array([0.49831334], dtype=float32), 0.15491553]. 
=============================================
[2019-04-27 20:01:20,506] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.5647055e-27 1.0000000e+00 1.2015185e-30 1.7430144e-27 2.8458241e-30], sum to 1.0000
[2019-04-27 20:01:20,508] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7700
[2019-04-27 20:01:20,514] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.15, 73.5, 1.0, 2.0, 0.7975929490919456, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 909096.2983157603, 909096.2983157603, 195449.8686520484], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5058600.0000, 
sim time next is 5059200.0000, 
raw observation next is [30.3, 72.0, 1.0, 2.0, 0.7710655770878831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 878843.0681999413, 878843.0681999413, 190040.5160945226], 
processed observation next is [0.0, 0.5652173913043478, 0.6777777777777778, 0.72, 1.0, 1.0, 0.727459020342718, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3138725243571219, 0.3138725243571219, 0.365462530951005], 
reward next is 0.6345, 
noisyNet noise sample is [array([-0.30705503], dtype=float32), -0.7915881]. 
=============================================
[2019-04-27 20:01:21,472] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2095069e-29 1.0000000e+00 4.2266310e-32 4.5719157e-29 3.4818135e-33], sum to 1.0000
[2019-04-27 20:01:21,480] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6284
[2019-04-27 20:01:21,485] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.08333333333333, 66.83333333333333, 1.0, 2.0, 0.7398160524504519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 843205.9752796657, 843205.9752796657, 183824.4608313432], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5062200.0000, 
sim time next is 5062800.0000, 
raw observation next is [31.26666666666667, 67.66666666666667, 1.0, 2.0, 0.7564907673044645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 862221.6859499045, 862221.6859499045, 187121.5984666067], 
processed observation next is [0.0, 0.6086956521739131, 0.7135802469135804, 0.6766666666666667, 1.0, 1.0, 0.7101080563148388, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3079363164106802, 0.3079363164106802, 0.35984922782039747], 
reward next is 0.6402, 
noisyNet noise sample is [array([1.7001406], dtype=float32), -0.3213212]. 
=============================================
[2019-04-27 20:01:22,208] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.5498464e-33 1.0000000e+00 1.8006153e-35 1.1151296e-30 1.3251692e-37], sum to 1.0000
[2019-04-27 20:01:22,219] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3458
[2019-04-27 20:01:22,223] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 92.33333333333334, 1.0, 2.0, 0.8147154222686697, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 928624.3143419351, 928624.3143419351, 199006.4425251452], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5089200.0000, 
sim time next is 5089800.0000, 
raw observation next is [27.16666666666666, 93.16666666666667, 1.0, 2.0, 0.8113344911908748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 924768.3555280612, 924768.3555280612, 198299.9936333159], 
processed observation next is [0.0, 0.9130434782608695, 0.5617283950617282, 0.9316666666666668, 1.0, 1.0, 0.7753982037986604, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.33027441268859326, 0.33027441268859326, 0.38134614160253055], 
reward next is 0.6187, 
noisyNet noise sample is [array([1.6568295], dtype=float32), 1.0709859]. 
=============================================
[2019-04-27 20:01:22,309] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.9492589e-31 1.0000000e+00 2.6247526e-34 6.3111837e-30 4.8123772e-35], sum to 1.0000
[2019-04-27 20:01:22,318] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7196
[2019-04-27 20:01:22,324] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.16666666666666, 74.16666666666666, 1.0, 2.0, 0.8051560794074877, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 917721.9143665317, 917721.9143665312, 197014.9815915241], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5075400.0000, 
sim time next is 5076000.0000, 
raw observation next is [30.0, 75.0, 1.0, 2.0, 0.8034139010665098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 915734.9822468611, 915734.9822468611, 196653.6194484955], 
processed observation next is [0.0, 0.782608695652174, 0.6666666666666666, 0.75, 1.0, 1.0, 0.7659689298410831, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.32704820794530753, 0.32704820794530753, 0.3781800374009529], 
reward next is 0.6218, 
noisyNet noise sample is [array([1.1420387], dtype=float32), -0.32274845]. 
=============================================
[2019-04-27 20:01:22,341] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[72.85371 ]
 [72.82216 ]
 [72.80522 ]
 [72.752106]
 [72.64426 ]], R is [[72.85730743]
 [72.74986267]
 [72.64302826]
 [72.53949738]
 [72.44655609]].
[2019-04-27 20:01:25,670] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3154697e-28 1.0000000e+00 6.3864211e-33 1.8787170e-29 1.6559683e-32], sum to 1.0000
[2019-04-27 20:01:25,679] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3427
[2019-04-27 20:01:25,686] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.16666666666667, 66.83333333333333, 1.0, 2.0, 0.7624484661024202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 869015.9121291281, 869015.9121291281, 188309.3046508209], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5148600.0000, 
sim time next is 5149200.0000, 
raw observation next is [31.33333333333334, 67.66666666666667, 1.0, 2.0, 0.7526979106450001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 857896.3012762693, 857896.3012762688, 186368.1585533064], 
processed observation next is [0.0, 0.6086956521739131, 0.7160493827160496, 0.6766666666666667, 1.0, 1.0, 0.7055927507678573, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3063915361700962, 0.306391536170096, 0.3584003049102046], 
reward next is 0.6416, 
noisyNet noise sample is [array([0.9932084], dtype=float32), -1.3940758]. 
=============================================
[2019-04-27 20:01:29,645] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-27 20:01:29,648] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 20:01:29,648] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 20:01:29,650] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:01:29,651] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:01:29,652] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 20:01:29,653] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 20:01:29,654] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:01:29,650] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 20:01:29,655] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:01:29,656] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:01:29,674] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run49
[2019-04-27 20:01:29,695] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run49
[2019-04-27 20:01:29,716] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run49
[2019-04-27 20:01:29,735] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run49
[2019-04-27 20:01:29,757] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run49
[2019-04-27 20:01:44,406] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.08964765]
[2019-04-27 20:01:44,408] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.01666666666667, 58.83333333333334, 1.0, 2.0, 0.36912866551098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 472300.0001678134, 472300.0001678134, 124545.5988515884]
[2019-04-27 20:01:44,410] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 20:01:44,412] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.4717141e-21 1.0000000e+00 4.6987758e-23 7.1571124e-20 6.3192769e-23], sampled 0.9394210491667306
[2019-04-27 20:02:05,620] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.08964765]
[2019-04-27 20:02:05,621] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [34.40388681666667, 25.40607077333333, 1.0, 2.0, 0.7367683319367087, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 905090.4820573477, 905090.4820573477, 185934.8404116296]
[2019-04-27 20:02:05,623] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 20:02:05,628] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [8.3008117e-20 1.0000000e+00 5.8967587e-22 1.0827338e-18 2.1405512e-21], sampled 0.6504908513220684
[2019-04-27 20:02:07,654] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.08964765]
[2019-04-27 20:02:07,656] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.88333333333333, 100.0, 1.0, 2.0, 0.4676693364123399, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 565766.5096172723, 565766.5096172723, 138182.4981439878]
[2019-04-27 20:02:07,659] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 20:02:07,662] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.1655570e-21 1.0000000e+00 5.9958769e-24 1.2872934e-20 8.7697951e-24], sampled 0.044622275978945414
[2019-04-27 20:02:28,390] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.08964765]
[2019-04-27 20:02:28,392] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.7, 90.0, 1.0, 2.0, 0.6731157779450458, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 767146.2364612088, 767146.2364612088, 171121.345924232]
[2019-04-27 20:02:28,394] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 20:02:28,397] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.1807997e-18 1.0000000e+00 1.2167694e-19 4.0719901e-17 1.1920793e-19], sampled 0.8859548705909445
[2019-04-27 20:02:43,055] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.08964765]
[2019-04-27 20:02:43,057] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.65, 56.0, 1.0, 2.0, 0.5151843772412265, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 611034.1848312034, 611034.1848312034, 145170.9586227774]
[2019-04-27 20:02:43,058] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 20:02:43,059] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.5109160e-22 1.0000000e+00 5.4797316e-25 1.9473815e-21 1.1161757e-24], sampled 0.4187337793448189
[2019-04-27 20:02:56,897] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.08964765]
[2019-04-27 20:02:56,898] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.43333333333333, 67.0, 1.0, 2.0, 0.9982610202696023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.13394739827574, 6.9112, 121.9250575329714, 1252137.952497623, 1138072.297227247, 240309.3731563049]
[2019-04-27 20:02:56,899] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 20:02:56,902] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.0067326e-18 1.0000000e+00 4.7935239e-20 5.7944895e-17 2.1870562e-19], sampled 0.590636917886589
[2019-04-27 20:03:11,955] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.08964765]
[2019-04-27 20:03:11,957] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [18.56368057, 75.80516678500001, 1.0, 2.0, 0.2745218417821577, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 353854.5538030933, 353854.5538030938, 112473.9966660148]
[2019-04-27 20:03:11,960] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 20:03:11,961] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.7040937e-21 1.0000000e+00 4.2364323e-23 6.5355702e-20 5.7745243e-23], sampled 0.2462787185484211
[2019-04-27 20:03:17,843] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.08964765]
[2019-04-27 20:03:17,844] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.84138991666667, 74.83591217333333, 1.0, 2.0, 0.663614167544964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 781391.1044052548, 781391.1044052548, 170545.6682699628]
[2019-04-27 20:03:17,844] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 20:03:17,846] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.1356864e-19 1.0000000e+00 8.9779116e-22 1.5646001e-18 2.8711019e-21], sampled 0.5591738870883942
[2019-04-27 20:03:21,321] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8699.3424 2195282598.7024 572.0000
[2019-04-27 20:03:21,499] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8768.6241 2170826060.4938 493.0000
[2019-04-27 20:03:21,525] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8923.2149 2120679854.9146 431.0000
[2019-04-27 20:03:21,535] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8098.3750 2445536342.0782 746.0000
[2019-04-27 20:03:21,563] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8582.0590 2248830394.8409 553.0000
[2019-04-27 20:03:22,580] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1200000, evaluation results [1200000.0, 8098.375034708541, 2445536342.078249, 746.0, 8768.624117554622, 2170826060.49376, 493.0, 8923.21488654309, 2120679854.9146407, 431.0, 8582.059032767682, 2248830394.840892, 553.0, 8699.342416479873, 2195282598.702448, 572.0]
[2019-04-27 20:03:22,955] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75000, global step 1200189: loss 0.1917
[2019-04-27 20:03:22,959] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75000, global step 1200191: learning rate 0.0000
[2019-04-27 20:03:23,868] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75000, global step 1200649: loss 0.0777
[2019-04-27 20:03:23,870] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75000, global step 1200651: learning rate 0.0000
[2019-04-27 20:03:23,988] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75000, global step 1200714: loss 0.0912
[2019-04-27 20:03:23,989] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75000, global step 1200714: learning rate 0.0000
[2019-04-27 20:03:24,028] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75500, global step 1200731: loss 0.5577
[2019-04-27 20:03:24,030] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75500, global step 1200731: learning rate 0.0000
[2019-04-27 20:03:24,213] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.8074614e-17 1.0000000e+00 6.6229632e-19 4.9866761e-15 2.5560843e-15], sum to 1.0000
[2019-04-27 20:03:24,221] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5560
[2019-04-27 20:03:24,226] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.26666666666667, 89.33333333333334, 1.0, 2.0, 0.7091631232885149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 808250.8522177441, 808250.8522177441, 177886.1710285925], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5262000.0000, 
sim time next is 5262600.0000, 
raw observation next is [26.18333333333334, 89.66666666666666, 1.0, 2.0, 0.7077715180608061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 806663.9705148208, 806663.9705148208, 177620.5459297388], 
processed observation next is [1.0, 0.9130434782608695, 0.5253086419753089, 0.8966666666666666, 1.0, 1.0, 0.6521089500723881, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28809427518386455, 0.28809427518386455, 0.34157797294180536], 
reward next is 0.6584, 
noisyNet noise sample is [array([-1.014677], dtype=float32), -0.027814874]. 
=============================================
[2019-04-27 20:03:24,297] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75000, global step 1200873: loss 0.0483
[2019-04-27 20:03:24,299] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75000, global step 1200873: loss 0.0749
[2019-04-27 20:03:24,302] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75000, global step 1200873: learning rate 0.0000
[2019-04-27 20:03:24,303] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75000, global step 1200875: learning rate 0.0000
[2019-04-27 20:03:24,366] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75000, global step 1200903: loss 0.0802
[2019-04-27 20:03:24,370] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75000, global step 1200904: learning rate 0.0000
[2019-04-27 20:03:24,470] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75000, global step 1200960: loss 0.3934
[2019-04-27 20:03:24,472] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75000, global step 1200960: learning rate 0.0000
[2019-04-27 20:03:24,734] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75000, global step 1201087: loss 0.0491
[2019-04-27 20:03:24,738] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75000, global step 1201087: learning rate 0.0000
[2019-04-27 20:03:24,785] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75000, global step 1201119: loss 0.0944
[2019-04-27 20:03:24,786] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75000, global step 1201119: learning rate 0.0000
[2019-04-27 20:03:24,838] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75000, global step 1201145: loss 0.3063
[2019-04-27 20:03:24,842] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75000, global step 1201145: learning rate 0.0000
[2019-04-27 20:03:24,850] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75000, global step 1201151: loss 0.2269
[2019-04-27 20:03:24,852] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75000, global step 1201151: learning rate 0.0000
[2019-04-27 20:03:24,943] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75000, global step 1201195: loss 0.0481
[2019-04-27 20:03:24,945] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75000, global step 1201195: learning rate 0.0000
[2019-04-27 20:03:24,997] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75000, global step 1201221: loss 0.0728
[2019-04-27 20:03:24,998] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75000, global step 1201221: learning rate 0.0000
[2019-04-27 20:03:25,191] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75000, global step 1201318: loss 0.2176
[2019-04-27 20:03:25,193] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75000, global step 1201319: learning rate 0.0000
[2019-04-27 20:03:26,113] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75500, global step 1201785: loss 0.2167
[2019-04-27 20:03:26,117] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75500, global step 1201787: learning rate 0.0000
[2019-04-27 20:03:27,846] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.9612977e-13 1.0000000e+00 1.9667980e-15 1.6158690e-09 6.0714975e-09], sum to 1.0000
[2019-04-27 20:03:27,854] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0918
[2019-04-27 20:03:27,861] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1381499.33648108 W.
[2019-04-27 20:03:27,869] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.1, 79.66666666666667, 1.0, 2.0, 0.6031579110067534, 1.0, 2.0, 0.6031579110067534, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1381499.33648108, 1381499.33648108, 269432.9227438472], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5311200.0000, 
sim time next is 5311800.0000, 
raw observation next is [25.3, 78.5, 1.0, 2.0, 0.6153342164417344, 0.0, 1.0, 0.0, 1.0, 1.0, 0.980632024961698, 6.911199999999999, 6.9112, 121.9260426156618, 1419728.294017731, 1419728.294017731, 299627.7718320966], 
processed observation next is [1.0, 0.4782608695652174, 0.49259259259259264, 0.785, 1.0, 1.0, 0.5420645433830171, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9757900312021225, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5070458192920467, 0.5070458192920467, 0.5762072535232627], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.473398], dtype=float32), 1.4129859]. 
=============================================
[2019-04-27 20:03:30,342] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.5038103e-20 1.0000000e+00 1.5519460e-24 3.0683808e-17 7.8230120e-19], sum to 1.0000
[2019-04-27 20:03:30,348] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9815
[2019-04-27 20:03:30,353] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.65, 88.33333333333334, 1.0, 2.0, 0.7881733963587803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 911326.237493301, 911326.237493301, 194173.407067771], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5368200.0000, 
sim time next is 5368800.0000, 
raw observation next is [24.6, 88.66666666666667, 1.0, 2.0, 0.775453332891006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 896698.4985974324, 896698.4985974324, 191575.6668874439], 
processed observation next is [1.0, 0.13043478260869565, 0.46666666666666673, 0.8866666666666667, 1.0, 1.0, 0.7326825391559596, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3202494637847973, 0.3202494637847973, 0.3684147440143152], 
reward next is 0.6316, 
noisyNet noise sample is [array([0.1468707], dtype=float32), -1.2275616]. 
=============================================
[2019-04-27 20:03:36,819] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.6090921e-16 1.0000000e+00 1.6645555e-18 4.9928052e-15 7.3420141e-17], sum to 1.0000
[2019-04-27 20:03:36,828] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1003
[2019-04-27 20:03:36,836] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2530997.162758505 W.
[2019-04-27 20:03:36,840] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.85, 82.5, 1.0, 2.0, 0.8522116321472941, 1.0, 2.0, 0.7394704780500817, 1.0, 1.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2530997.162758505, 2530997.162758505, 472646.3186848588], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5482200.0000, 
sim time next is 5482800.0000, 
raw observation next is [30.0, 82.0, 1.0, 2.0, 0.8816539794489511, 1.0, 2.0, 0.7541916517009103, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2581456.411893124, 2581456.411893124, 481620.5326424196], 
processed observation next is [1.0, 0.4782608695652174, 0.6666666666666666, 0.82, 1.0, 1.0, 0.8591118802963703, 1.0, 1.0, 0.7073710139296551, 1.0, 1.0, 0.9972168686025908, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.9219487185332587, 0.9219487185332587, 0.9261933320046531], 
reward next is 0.0738, 
noisyNet noise sample is [array([-0.81980354], dtype=float32), -0.04379505]. 
=============================================
[2019-04-27 20:03:38,573] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75500, global step 1208099: loss 0.1803
[2019-04-27 20:03:38,578] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75500, global step 1208099: learning rate 0.0000
[2019-04-27 20:03:39,232] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76000, global step 1208434: loss 2.4919
[2019-04-27 20:03:39,234] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76000, global step 1208434: learning rate 0.0000
[2019-04-27 20:03:39,742] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75500, global step 1208701: loss 0.1386
[2019-04-27 20:03:39,744] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75500, global step 1208702: learning rate 0.0000
[2019-04-27 20:03:39,768] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75500, global step 1208715: loss 0.1861
[2019-04-27 20:03:39,769] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75500, global step 1208716: learning rate 0.0000
[2019-04-27 20:03:40,053] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75500, global step 1208860: loss 0.2231
[2019-04-27 20:03:40,053] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75500, global step 1208860: learning rate 0.0000
[2019-04-27 20:03:40,164] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75500, global step 1208916: loss 0.0938
[2019-04-27 20:03:40,166] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75500, global step 1208916: learning rate 0.0000
[2019-04-27 20:03:40,267] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75500, global step 1208968: loss 0.1952
[2019-04-27 20:03:40,269] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75500, global step 1208969: learning rate 0.0000
[2019-04-27 20:03:40,278] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75500, global step 1208973: loss 0.1101
[2019-04-27 20:03:40,284] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75500, global step 1208975: learning rate 0.0000
[2019-04-27 20:03:40,523] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75500, global step 1209102: loss 0.1234
[2019-04-27 20:03:40,524] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75500, global step 1209102: learning rate 0.0000
[2019-04-27 20:03:40,666] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75500, global step 1209171: loss 0.2936
[2019-04-27 20:03:40,670] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75500, global step 1209172: learning rate 0.0000
[2019-04-27 20:03:40,682] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75500, global step 1209175: loss 0.1657
[2019-04-27 20:03:40,684] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75500, global step 1209178: loss 0.3033
[2019-04-27 20:03:40,684] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75500, global step 1209178: learning rate 0.0000
[2019-04-27 20:03:40,685] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75500, global step 1209179: learning rate 0.0000
[2019-04-27 20:03:40,704] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75500, global step 1209187: loss 0.2144
[2019-04-27 20:03:40,705] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75500, global step 1209187: learning rate 0.0000
[2019-04-27 20:03:40,762] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75500, global step 1209219: loss 0.1828
[2019-04-27 20:03:40,765] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75500, global step 1209221: learning rate 0.0000
[2019-04-27 20:03:41,064] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75500, global step 1209367: loss 0.1054
[2019-04-27 20:03:41,067] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75500, global step 1209368: learning rate 0.0000
[2019-04-27 20:03:41,332] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76000, global step 1209498: loss 3.3122
[2019-04-27 20:03:41,333] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76000, global step 1209498: learning rate 0.0000
[2019-04-27 20:03:50,605] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.9925323e-32 1.0000000e+00 9.0816266e-37 3.7827074e-31 4.4236534e-36], sum to 1.0000
[2019-04-27 20:03:50,611] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0401
[2019-04-27 20:03:50,615] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.93333333333333, 62.0, 1.0, 2.0, 0.5358970541082627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 630777.6995150587, 630777.6995150587, 148319.5381894093], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5754000.0000, 
sim time next is 5754600.0000, 
raw observation next is [27.95, 62.0, 1.0, 2.0, 0.5372341065001436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 632163.2599130527, 632163.2599130527, 148529.5383209225], 
processed observation next is [0.0, 0.6086956521739131, 0.5907407407407407, 0.62, 1.0, 1.0, 0.4490882220239804, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22577259282609025, 0.22577259282609025, 0.2856337275402356], 
reward next is 0.7144, 
noisyNet noise sample is [array([-1.0304728], dtype=float32), 1.3041013]. 
=============================================
[2019-04-27 20:03:53,210] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.3002351e-23 1.0000000e+00 5.8843176e-27 6.1442561e-22 2.3591960e-25], sum to 1.0000
[2019-04-27 20:03:53,218] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4941
[2019-04-27 20:03:53,225] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.46666666666667, 93.0, 1.0, 2.0, 0.4996215951390963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 606429.1810520081, 606429.1810520081, 143194.5035622798], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5808000.0000, 
sim time next is 5808600.0000, 
raw observation next is [21.6, 92.0, 1.0, 2.0, 0.4914314815242251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 596405.1770601906, 596405.1770601906, 141905.1664435301], 
processed observation next is [1.0, 0.21739130434782608, 0.3555555555555556, 0.92, 1.0, 1.0, 0.3945612875288394, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21300184895006807, 0.21300184895006807, 0.2728945508529425], 
reward next is 0.7271, 
noisyNet noise sample is [array([0.99499506], dtype=float32), 0.445954]. 
=============================================
[2019-04-27 20:03:54,139] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76000, global step 1216097: loss 1.1972
[2019-04-27 20:03:54,141] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76000, global step 1216097: learning rate 0.0000
[2019-04-27 20:03:55,190] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76500, global step 1216602: loss 0.0533
[2019-04-27 20:03:55,193] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76500, global step 1216602: learning rate 0.0000
[2019-04-27 20:03:55,378] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76000, global step 1216690: loss 2.9761
[2019-04-27 20:03:55,379] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76000, global step 1216690: learning rate 0.0000
[2019-04-27 20:03:55,390] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76000, global step 1216697: loss 2.8435
[2019-04-27 20:03:55,393] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76000, global step 1216697: learning rate 0.0000
[2019-04-27 20:03:55,815] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76000, global step 1216909: loss 5.5472
[2019-04-27 20:03:55,818] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76000, global step 1216909: learning rate 0.0000
[2019-04-27 20:03:55,890] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76000, global step 1216938: loss 4.9115
[2019-04-27 20:03:55,893] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76000, global step 1216938: learning rate 0.0000
[2019-04-27 20:03:55,920] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76000, global step 1216954: loss 4.1413
[2019-04-27 20:03:55,924] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76000, global step 1216954: learning rate 0.0000
[2019-04-27 20:03:56,096] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76000, global step 1217035: loss 2.7079
[2019-04-27 20:03:56,098] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76000, global step 1217035: learning rate 0.0000
[2019-04-27 20:03:56,163] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76000, global step 1217068: loss 3.3812
[2019-04-27 20:03:56,165] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76000, global step 1217068: learning rate 0.0000
[2019-04-27 20:03:56,228] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76000, global step 1217094: loss 3.1709
[2019-04-27 20:03:56,228] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76000, global step 1217094: learning rate 0.0000
[2019-04-27 20:03:56,369] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76000, global step 1217164: loss 3.2123
[2019-04-27 20:03:56,373] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76000, global step 1217164: learning rate 0.0000
[2019-04-27 20:03:56,389] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76000, global step 1217173: loss 2.7081
[2019-04-27 20:03:56,391] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76000, global step 1217173: learning rate 0.0000
[2019-04-27 20:03:56,395] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76000, global step 1217176: loss 2.1332
[2019-04-27 20:03:56,398] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76000, global step 1217176: learning rate 0.0000
[2019-04-27 20:03:56,510] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76000, global step 1217238: loss 3.1862
[2019-04-27 20:03:56,512] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76000, global step 1217238: learning rate 0.0000
[2019-04-27 20:03:56,878] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76000, global step 1217414: loss 1.4872
[2019-04-27 20:03:56,879] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76000, global step 1217414: learning rate 0.0000
[2019-04-27 20:03:57,567] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76500, global step 1217740: loss 0.0152
[2019-04-27 20:03:57,570] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76500, global step 1217740: learning rate 0.0000
[2019-04-27 20:03:58,378] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.6342272e-28 1.0000000e+00 1.6614335e-34 3.7508855e-28 1.6462309e-32], sum to 1.0000
[2019-04-27 20:03:58,383] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8430
[2019-04-27 20:03:58,387] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.45, 66.0, 1.0, 2.0, 0.5534182329296136, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 648113.5129784897, 648113.5129784893, 151059.6848483814], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6208200.0000, 
sim time next is 6208800.0000, 
raw observation next is [27.3, 66.33333333333333, 1.0, 2.0, 0.5500297519962076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 645212.8137516091, 645212.8137516086, 150545.0820507121], 
processed observation next is [1.0, 0.8695652173913043, 0.5666666666666667, 0.6633333333333333, 1.0, 1.0, 0.4643211333288186, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2304331477684318, 0.23043314776843163, 0.28950977317444637], 
reward next is 0.7105, 
noisyNet noise sample is [array([-0.955868], dtype=float32), -0.04108468]. 
=============================================
[2019-04-27 20:04:01,213] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5143902e-29 1.0000000e+00 4.5849702e-33 1.3099214e-28 5.1301850e-33], sum to 1.0000
[2019-04-27 20:04:01,220] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5557
[2019-04-27 20:04:01,227] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 55.0, 1.0, 2.0, 0.4648816119903551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 558920.9004996613, 558920.9004996613, 137643.9994774496], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5940000.0000, 
sim time next is 5940600.0000, 
raw observation next is [27.86666666666667, 55.66666666666667, 1.0, 2.0, 0.4691902757406638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 564075.4774919626, 564075.4774919626, 138296.6239752711], 
processed observation next is [1.0, 0.782608695652174, 0.5876543209876545, 0.5566666666666668, 1.0, 1.0, 0.3680836615960284, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20145552767570093, 0.20145552767570093, 0.26595504610629056], 
reward next is 0.7340, 
noisyNet noise sample is [array([0.3918939], dtype=float32), 0.88028127]. 
=============================================
[2019-04-27 20:04:10,844] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76500, global step 1224037: loss 0.5189
[2019-04-27 20:04:10,848] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76500, global step 1224037: learning rate 0.0000
[2019-04-27 20:04:11,946] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77000, global step 1224564: loss 479.4779
[2019-04-27 20:04:11,948] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77000, global step 1224565: learning rate 0.0000
[2019-04-27 20:04:12,177] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76500, global step 1224676: loss 0.0284
[2019-04-27 20:04:12,180] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76500, global step 1224679: learning rate 0.0000
[2019-04-27 20:04:12,229] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76500, global step 1224700: loss 0.0371
[2019-04-27 20:04:12,230] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76500, global step 1224700: learning rate 0.0000
[2019-04-27 20:04:12,672] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76500, global step 1224920: loss 0.0719
[2019-04-27 20:04:12,672] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76500, global step 1224920: loss 0.0051
[2019-04-27 20:04:12,673] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76500, global step 1224920: learning rate 0.0000
[2019-04-27 20:04:12,675] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76500, global step 1224920: learning rate 0.0000
[2019-04-27 20:04:12,729] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76500, global step 1224944: loss 0.1459
[2019-04-27 20:04:12,730] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76500, global step 1224944: learning rate 0.0000
[2019-04-27 20:04:12,791] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76500, global step 1224972: loss 0.0074
[2019-04-27 20:04:12,792] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76500, global step 1224973: learning rate 0.0000
[2019-04-27 20:04:12,846] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-04-27 20:04:12,848] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 20:04:12,848] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:04:12,850] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 20:04:12,850] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 20:04:12,851] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:04:12,852] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:04:12,852] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 20:04:12,854] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:04:12,855] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 20:04:12,856] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:04:12,875] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run50
[2019-04-27 20:04:12,897] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run50
[2019-04-27 20:04:12,898] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run50
[2019-04-27 20:04:12,941] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run50
[2019-04-27 20:04:12,962] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run50
[2019-04-27 20:04:15,776] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.093199745]
[2019-04-27 20:04:15,778] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.25, 40.0, 1.0, 2.0, 0.2889772095874, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 372767.9562120461, 372767.9562120461, 93969.19970045402]
[2019-04-27 20:04:15,778] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 20:04:15,781] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.00357796e-28 1.00000000e+00 4.05894732e-32 1.05490802e-26
 2.20122866e-32], sampled 0.9698104228740713
[2019-04-27 20:04:46,541] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.093199745]
[2019-04-27 20:04:46,544] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [34.33333333333333, 38.66666666666666, 1.0, 2.0, 0.6227759549578312, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9914796026897326, 6.911199999999999, 6.9112, 121.9260426156618, 1420153.077072006, 1420153.077072006, 302823.6224022886]
[2019-04-27 20:04:46,545] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 20:04:46,547] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.7423437e-28 1.0000000e+00 1.0264550e-31 1.7024758e-26 6.3595608e-32], sampled 0.18389246657919534
[2019-04-27 20:04:46,548] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1420153.077072006 W.
[2019-04-27 20:04:56,952] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.093199745]
[2019-04-27 20:04:56,953] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.98333333333333, 88.33333333333334, 1.0, 2.0, 0.8715660540542065, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1001120.4433895, 1001120.4433895, 211579.9901976236]
[2019-04-27 20:04:56,955] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 20:04:56,958] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.9817483e-28 1.0000000e+00 3.4069263e-31 7.7311654e-26 2.6225848e-31], sampled 0.40230503370308623
[2019-04-27 20:04:58,577] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.093199745]
[2019-04-27 20:04:58,579] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.12236541333333, 47.80388852, 1.0, 2.0, 0.2823163069238144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 363823.3797575283, 363823.3797575283, 113408.0628202325]
[2019-04-27 20:04:58,581] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 20:04:58,585] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.9637654e-29 1.0000000e+00 1.0147707e-32 3.7198100e-27 5.9030953e-33], sampled 0.6950788766309534
[2019-04-27 20:05:23,059] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.093199745]
[2019-04-27 20:05:23,059] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.1, 65.0, 1.0, 2.0, 0.9724708395352037, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.052648599018722, 6.9112, 121.9253727634848, 1195421.262435748, 1122987.33515438, 234947.7436832414]
[2019-04-27 20:05:23,060] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 20:05:23,063] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.6753490e-29 1.0000000e+00 3.4054301e-32 7.2920977e-27 1.9235527e-32], sampled 0.7720939804819238
[2019-04-27 20:06:03,830] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8922.7405 2120493420.7059 430.0000
[2019-04-27 20:06:03,859] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8099.9424 2445324199.3218 746.0000
[2019-04-27 20:06:03,892] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-04-27 20:06:03,928] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-04-27 20:06:04,009] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8700.1130 2195220806.1349 572.0000
[2019-04-27 20:06:05,025] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1225000, evaluation results [1225000.0, 8099.942407935641, 2445324199.321786, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8922.740480148814, 2120493420.7058632, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8700.112961499688, 2195220806.134913, 572.0]
[2019-04-27 20:06:05,092] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76500, global step 1225034: loss 0.1164
[2019-04-27 20:06:05,094] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76500, global step 1225034: learning rate 0.0000
[2019-04-27 20:06:05,384] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76500, global step 1225182: loss 0.0672
[2019-04-27 20:06:05,385] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76500, global step 1225182: loss 0.0814
[2019-04-27 20:06:05,388] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76500, global step 1225183: learning rate 0.0000
[2019-04-27 20:06:05,391] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76500, global step 1225183: learning rate 0.0000
[2019-04-27 20:06:05,457] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76500, global step 1225217: loss 0.0711
[2019-04-27 20:06:05,458] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76500, global step 1225219: learning rate 0.0000
[2019-04-27 20:06:05,481] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76500, global step 1225229: loss 0.0420
[2019-04-27 20:06:05,484] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76500, global step 1225230: learning rate 0.0000
[2019-04-27 20:06:05,489] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76500, global step 1225233: loss 0.0106
[2019-04-27 20:06:05,493] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76500, global step 1225235: learning rate 0.0000
[2019-04-27 20:06:05,645] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76500, global step 1225315: loss 0.0285
[2019-04-27 20:06:05,647] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76500, global step 1225316: learning rate 0.0000
[2019-04-27 20:06:06,159] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77000, global step 1225577: loss 360.2661
[2019-04-27 20:06:06,163] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77000, global step 1225578: learning rate 0.0000
[2019-04-27 20:06:08,348] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.3038465e-26 1.0000000e+00 8.1556972e-30 1.1077304e-24 3.8629566e-30], sum to 1.0000
[2019-04-27 20:06:08,361] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1357
[2019-04-27 20:06:08,369] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1611787.138898687 W.
[2019-04-27 20:06:08,374] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.43333333333333, 79.83333333333334, 1.0, 2.0, 0.7867233996826072, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1611787.138898687, 1611787.138898687, 333610.4002644874], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6534600.0000, 
sim time next is 6535200.0000, 
raw observation next is [27.46666666666667, 79.66666666666667, 1.0, 2.0, 0.4800317679731369, 1.0, 1.0, 0.4800317679731369, 1.0, 2.0, 0.7642262081564823, 6.911199999999999, 6.9112, 121.94756008, 1642195.838112691, 1642195.838112691, 333896.5423954821], 
processed observation next is [1.0, 0.6521739130434783, 0.5728395061728396, 0.7966666666666667, 1.0, 1.0, 0.38099019996802014, 1.0, 0.5, 0.38099019996802014, 1.0, 1.0, 0.705282760195603, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5864985136116754, 0.5864985136116754, 0.642108735375927], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.15861994], dtype=float32), 1.2041878]. 
=============================================
[2019-04-27 20:06:08,660] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.3062210e-31 1.0000000e+00 1.7033784e-34 6.7887351e-29 1.1777913e-34], sum to 1.0000
[2019-04-27 20:06:08,668] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4995
[2019-04-27 20:06:08,677] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.9, 84.33333333333334, 1.0, 2.0, 0.4743831547518382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 572757.9198683313, 572757.9198683313, 139170.4011221134], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6234600.0000, 
sim time next is 6235200.0000, 
raw observation next is [22.8, 85.0, 1.0, 2.0, 0.4734882235290998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 571776.2603218477, 571776.2603218477, 139036.6527650436], 
processed observation next is [0.0, 0.17391304347826086, 0.4, 0.85, 1.0, 1.0, 0.37320026610607115, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20420580725780277, 0.20420580725780277, 0.2673781783943146], 
reward next is 0.7326, 
noisyNet noise sample is [array([-1.0506694], dtype=float32), -0.7876021]. 
=============================================
[2019-04-27 20:06:08,896] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.9418697e-21 1.0000000e+00 1.8570827e-23 8.0927728e-18 5.3849826e-20], sum to 1.0000
[2019-04-27 20:06:08,906] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4349
[2019-04-27 20:06:08,918] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1740708.864057106 W.
[2019-04-27 20:06:08,925] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.56666666666667, 87.66666666666667, 1.0, 2.0, 0.5088001773350576, 1.0, 1.0, 0.5088001773350576, 1.0, 1.0, 0.810026452782343, 6.9112, 6.9112, 121.94756008, 1740708.864057106, 1740708.864057106, 347929.2767175832], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6510000.0000, 
sim time next is 6510600.0000, 
raw observation next is [26.7, 87.0, 1.0, 2.0, 0.9792024056003221, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260425507926, 1831499.628021068, 1831499.628021067, 374617.6460044616], 
processed observation next is [1.0, 0.34782608695652173, 0.5444444444444444, 0.87, 1.0, 1.0, 0.9752409590480026, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 8.881784197001253e-17, 0.0, 0.809462128389472, 0.6541070100075242, 0.6541070100075239, 0.72041855000858], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.7714187], dtype=float32), -0.78359354]. 
=============================================
[2019-04-27 20:06:18,806] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77000, global step 1232110: loss 335.4190
[2019-04-27 20:06:18,808] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77000, global step 1232110: learning rate 0.0000
[2019-04-27 20:06:18,973] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.08603787e-22 1.00000000e+00 1.10000644e-26 7.35239730e-21
 2.09441781e-25], sum to 1.0000
[2019-04-27 20:06:18,980] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8236
[2019-04-27 20:06:18,984] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.93333333333334, 58.5, 1.0, 2.0, 0.642353881006864, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 732070.3353543069, 732070.3353543069, 165518.3694031697], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6459000.0000, 
sim time next is 6459600.0000, 
raw observation next is [30.86666666666667, 59.0, 1.0, 2.0, 0.6584961059983069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 750476.1226142009, 750476.1226142009, 168435.3067241023], 
processed observation next is [1.0, 0.782608695652174, 0.6987654320987656, 0.59, 1.0, 1.0, 0.5934477452360796, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2680271866479289, 0.2680271866479289, 0.3239140513925044], 
reward next is 0.6761, 
noisyNet noise sample is [array([0.16755217], dtype=float32), 0.27801266]. 
=============================================
[2019-04-27 20:06:19,756] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77500, global step 1232659: loss 0.4166
[2019-04-27 20:06:19,757] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77500, global step 1232659: learning rate 0.0000
[2019-04-27 20:06:19,820] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77000, global step 1232704: loss 408.7152
[2019-04-27 20:06:19,823] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77000, global step 1232704: learning rate 0.0000
[2019-04-27 20:06:19,926] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77000, global step 1232774: loss 450.3578
[2019-04-27 20:06:19,928] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77000, global step 1232775: learning rate 0.0000
[2019-04-27 20:06:20,161] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77000, global step 1232912: loss 397.7643
[2019-04-27 20:06:20,164] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77000, global step 1232912: learning rate 0.0000
[2019-04-27 20:06:20,348] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77000, global step 1233001: loss 404.1343
[2019-04-27 20:06:20,354] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77000, global step 1233004: learning rate 0.0000
[2019-04-27 20:06:20,385] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77000, global step 1233019: loss 410.0787
[2019-04-27 20:06:20,386] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77000, global step 1233020: learning rate 0.0000
[2019-04-27 20:06:20,412] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77000, global step 1233031: loss 459.8006
[2019-04-27 20:06:20,413] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77000, global step 1233032: learning rate 0.0000
[2019-04-27 20:06:20,501] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77000, global step 1233075: loss 405.6140
[2019-04-27 20:06:20,505] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77000, global step 1233076: learning rate 0.0000
[2019-04-27 20:06:20,619] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77000, global step 1233141: loss 466.0979
[2019-04-27 20:06:20,621] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77000, global step 1233141: learning rate 0.0000
[2019-04-27 20:06:20,680] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77000, global step 1233172: loss 372.4501
[2019-04-27 20:06:20,684] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77000, global step 1233172: learning rate 0.0000
[2019-04-27 20:06:20,753] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77000, global step 1233214: loss 334.8220
[2019-04-27 20:06:20,754] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77000, global step 1233214: learning rate 0.0000
[2019-04-27 20:06:20,786] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77000, global step 1233229: loss 261.1237
[2019-04-27 20:06:20,787] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77000, global step 1233229: learning rate 0.0000
[2019-04-27 20:06:20,886] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77000, global step 1233278: loss 275.3849
[2019-04-27 20:06:20,887] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77000, global step 1233278: learning rate 0.0000
[2019-04-27 20:06:21,155] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77000, global step 1233414: loss 207.9460
[2019-04-27 20:06:21,156] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77000, global step 1233414: learning rate 0.0000
[2019-04-27 20:06:21,233] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77500, global step 1233454: loss 0.1873
[2019-04-27 20:06:21,237] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77500, global step 1233454: learning rate 0.0000
[2019-04-27 20:06:21,353] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.04088266e-16 1.00000000e+00 1.17705854e-20 4.80619581e-12
 3.26928207e-11], sum to 1.0000
[2019-04-27 20:06:21,363] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1722
[2019-04-27 20:06:21,371] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1456374.213198546 W.
[2019-04-27 20:06:21,375] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.9, 48.0, 1.0, 2.0, 0.609257475662675, 1.0, 2.0, 0.609257475662675, 0.0, 1.0, 0.0, 6.911199999999997, 6.9112, 121.9260426156618, 1456374.213198546, 1456374.213198547, 274216.7389681234], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6789600.0000, 
sim time next is 6790200.0000, 
raw observation next is [27.91666666666666, 48.5, 1.0, 2.0, 0.3492383130388644, 1.0, 2.0, 0.3492383130388644, 1.0, 1.0, 0.5632311559340529, 6.911200000000001, 6.9112, 121.94756008, 1254835.811386946, 1254835.811386946, 275109.6975699845], 
processed observation next is [1.0, 0.6086956521739131, 0.5895061728395059, 0.485, 1.0, 1.0, 0.22528370599864808, 1.0, 1.0, 0.22528370599864808, 1.0, 0.5, 0.45403894491756613, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.44815564692390925, 0.44815564692390925, 0.5290571107115086], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.7359152], dtype=float32), -1.4359428]. 
=============================================
[2019-04-27 20:06:26,897] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.25816805e-29 1.00000000e+00 1.23010295e-34 1.23381524e-27
 6.19229970e-31], sum to 1.0000
[2019-04-27 20:06:26,905] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5746
[2019-04-27 20:06:26,912] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.6, 49.66666666666667, 1.0, 2.0, 0.4865595421507857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 611078.2403054578, 611078.2403054578, 141636.952817865], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6577800.0000, 
sim time next is 6578400.0000, 
raw observation next is [25.6, 49.33333333333334, 1.0, 2.0, 0.4615841536469219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 580078.5884446373, 580078.5884446373, 137786.2944969598], 
processed observation next is [1.0, 0.13043478260869565, 0.5037037037037038, 0.4933333333333334, 1.0, 1.0, 0.3590287543415737, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2071709244445133, 0.2071709244445133, 0.26497364326338424], 
reward next is 0.7350, 
noisyNet noise sample is [array([-1.3604683], dtype=float32), -1.7476891]. 
=============================================
[2019-04-27 20:06:29,400] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.0337517e-18 1.0000000e+00 1.4126776e-20 4.2057930e-14 9.5571630e-13], sum to 1.0000
[2019-04-27 20:06:29,424] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2812
[2019-04-27 20:06:29,424] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1548313.145669462 W.
[2019-04-27 20:06:29,447] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.16666666666667, 39.16666666666667, 1.0, 2.0, 0.9785377358206284, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.558494938034603, 6.9112, 121.9233656020853, 1548313.145669462, 1216847.560663499, 239975.7674032436], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6610200.0000, 
sim time next is 6610800.0000, 
raw observation next is [28.33333333333334, 38.33333333333334, 1.0, 2.0, 0.3054173516938682, 1.0, 1.0, 0.3054173516938682, 1.0, 1.0, 0.4996759808225925, 6.911200000000001, 6.9112, 121.94756008, 1120233.671659636, 1120233.671659635, 256815.5563937882], 
processed observation next is [1.0, 0.5217391304347826, 0.6049382716049385, 0.3833333333333334, 1.0, 1.0, 0.17311589487365261, 1.0, 0.5, 0.17311589487365261, 1.0, 0.5, 0.3745949760282406, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.40008345416415575, 0.4000834541641553, 0.4938760699880542], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.89783925], dtype=float32), 0.16639094]. 
=============================================
[2019-04-27 20:06:34,377] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77500, global step 1239983: loss 0.0280
[2019-04-27 20:06:34,381] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77500, global step 1239983: learning rate 0.0000
[2019-04-27 20:06:35,457] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78000, global step 1240508: loss 55.1110
[2019-04-27 20:06:35,459] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78000, global step 1240508: learning rate 0.0000
[2019-04-27 20:06:35,619] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77500, global step 1240590: loss 0.0058
[2019-04-27 20:06:35,623] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77500, global step 1240591: learning rate 0.0000
[2019-04-27 20:06:35,890] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77500, global step 1240728: loss 0.0202
[2019-04-27 20:06:35,895] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77500, global step 1240729: learning rate 0.0000
[2019-04-27 20:06:36,149] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3302776e-25 1.0000000e+00 6.2892657e-30 1.0966103e-23 1.6665801e-28], sum to 1.0000
[2019-04-27 20:06:36,160] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3500
[2019-04-27 20:06:36,165] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.33333333333334, 79.66666666666667, 1.0, 2.0, 0.3782850478497007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 482246.7349984547, 482246.7349984547, 125793.6101647652], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6747600.0000, 
sim time next is 6748200.0000, 
raw observation next is [19.25, 80.0, 1.0, 2.0, 0.3495971234475836, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 445913.8868425759, 445913.8868425759, 121922.5793000756], 
processed observation next is [1.0, 0.08695652173913043, 0.26851851851851855, 0.8, 1.0, 1.0, 0.22571086124712333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15925495958663424, 0.15925495958663424, 0.23446649865399152], 
reward next is 0.7655, 
noisyNet noise sample is [array([0.3376691], dtype=float32), -1.0816038]. 
=============================================
[2019-04-27 20:06:36,198] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77500, global step 1240871: loss 0.0058
[2019-04-27 20:06:36,200] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77500, global step 1240871: learning rate 0.0000
[2019-04-27 20:06:36,408] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77500, global step 1240967: loss 0.0111
[2019-04-27 20:06:36,411] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77500, global step 1240969: learning rate 0.0000
[2019-04-27 20:06:36,526] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77500, global step 1241027: loss 0.0619
[2019-04-27 20:06:36,531] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77500, global step 1241027: learning rate 0.0000
[2019-04-27 20:06:36,543] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77500, global step 1241033: loss 0.0436
[2019-04-27 20:06:36,545] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77500, global step 1241033: learning rate 0.0000
[2019-04-27 20:06:36,604] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77500, global step 1241058: loss 0.0469
[2019-04-27 20:06:36,605] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77500, global step 1241059: learning rate 0.0000
[2019-04-27 20:06:36,827] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77500, global step 1241176: loss 0.1374
[2019-04-27 20:06:36,830] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77500, global step 1241177: learning rate 0.0000
[2019-04-27 20:06:36,915] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77500, global step 1241214: loss 0.2311
[2019-04-27 20:06:36,916] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77500, global step 1241215: learning rate 0.0000
[2019-04-27 20:06:37,008] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77500, global step 1241263: loss 0.1658
[2019-04-27 20:06:37,010] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77500, global step 1241263: learning rate 0.0000
[2019-04-27 20:06:37,032] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77500, global step 1241273: loss 0.1702
[2019-04-27 20:06:37,034] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77500, global step 1241273: learning rate 0.0000
[2019-04-27 20:06:37,137] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77500, global step 1241324: loss 0.1074
[2019-04-27 20:06:37,143] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77500, global step 1241327: learning rate 0.0000
[2019-04-27 20:06:37,258] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77500, global step 1241379: loss 0.0168
[2019-04-27 20:06:37,262] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77500, global step 1241379: learning rate 0.0000
[2019-04-27 20:06:37,394] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78000, global step 1241445: loss 31.6301
[2019-04-27 20:06:37,395] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78000, global step 1241445: learning rate 0.0000
[2019-04-27 20:06:37,659] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.8820077e-25 1.0000000e+00 3.5166599e-29 7.6724460e-23 8.4876276e-25], sum to 1.0000
[2019-04-27 20:06:37,667] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7768
[2019-04-27 20:06:37,678] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.31666666666667, 48.83333333333334, 1.0, 2.0, 0.7942375442589892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 979964.474292484, 979964.474292484, 197864.2059837536], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6786600.0000, 
sim time next is 6787200.0000, 
raw observation next is [27.43333333333334, 48.66666666666667, 1.0, 2.0, 0.9833408625761044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.5334761386547, 6.9112, 121.9238304231106, 1530859.177366131, 1212203.95766226, 240855.9288483658], 
processed observation next is [1.0, 0.5652173913043478, 0.5716049382716052, 0.4866666666666667, 1.0, 1.0, 0.9801676935429815, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.062227613865469954, 0.0, 0.8094474421621141, 0.5467354204879039, 0.43292998487937856, 0.4631844785545496], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.2051426], dtype=float32), -1.0505446]. 
=============================================
[2019-04-27 20:06:37,931] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.8860891e-25 1.0000000e+00 9.6743156e-29 2.0941903e-21 1.0372567e-22], sum to 1.0000
[2019-04-27 20:06:37,940] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8376
[2019-04-27 20:06:37,946] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.48333333333333, 50.16666666666667, 1.0, 2.0, 0.7875203336330939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426119938, 977809.4647989569, 977809.4647989573, 196609.6936188099], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6781800.0000, 
sim time next is 6782400.0000, 
raw observation next is [26.6, 50.0, 1.0, 2.0, 0.8894542203737046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.946556520556906, 6.9112, 121.9259170170552, 1121407.276146264, 1103301.596142245, 218895.7698830202], 
processed observation next is [1.0, 0.5217391304347826, 0.5407407407407407, 0.5, 1.0, 1.0, 0.8683978813972674, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.003535652055690619, 0.0, 0.8094612949760015, 0.4005025986236657, 0.39403628433651605, 0.4209534036211927], 
reward next is 0.4023, 
noisyNet noise sample is [array([1.5768209], dtype=float32), -0.8129116]. 
=============================================
[2019-04-27 20:06:42,951] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.5514411e-33 1.0000000e+00 0.0000000e+00 2.3217472e-29 1.4009425e-33], sum to 1.0000
[2019-04-27 20:06:42,958] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1848
[2019-04-27 20:06:42,962] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.33333333333334, 48.66666666666667, 1.0, 2.0, 0.5129985590177474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 608064.3328104336, 608064.3328104331, 144808.282825858], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6873600.0000, 
sim time next is 6874200.0000, 
raw observation next is [30.5, 48.5, 1.0, 2.0, 0.5177542070867557, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 612454.0834738021, 612454.0834738021, 145517.9195579164], 
processed observation next is [0.0, 0.5652173913043478, 0.6851851851851852, 0.485, 1.0, 1.0, 0.425897865579471, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2187336012406436, 0.2187336012406436, 0.2798421529959931], 
reward next is 0.7202, 
noisyNet noise sample is [array([2.080758], dtype=float32), -1.7922884]. 
=============================================
[2019-04-27 20:06:44,265] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.6909297e-31 1.0000000e+00 2.1520803e-35 1.6282986e-26 4.3322282e-33], sum to 1.0000
[2019-04-27 20:06:44,274] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9109
[2019-04-27 20:06:44,278] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.3, 58.0, 1.0, 2.0, 0.4424390781885845, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 540342.1858348153, 540342.1858348148, 134556.7806394899], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6897600.0000, 
sim time next is 6898200.0000, 
raw observation next is [26.15, 58.66666666666667, 1.0, 2.0, 0.4400432766062248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 537761.4269045448, 537761.4269045448, 134212.7149113247], 
processed observation next is [0.0, 0.8695652173913043, 0.524074074074074, 0.5866666666666667, 1.0, 1.0, 0.33338485310264854, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19205765246590886, 0.19205765246590886, 0.2581013748294706], 
reward next is 0.7419, 
noisyNet noise sample is [array([-0.13163847], dtype=float32), 2.839001]. 
=============================================
[2019-04-27 20:06:47,366] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4436968e-29 1.0000000e+00 2.1562713e-35 8.8783375e-27 9.9455654e-30], sum to 1.0000
[2019-04-27 20:06:47,373] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4509
[2019-04-27 20:06:47,380] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666666, 63.83333333333334, 1.0, 2.0, 0.494890722322817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 591878.6501604292, 591878.6501604292, 142153.7248441265], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6948600.0000, 
sim time next is 6949200.0000, 
raw observation next is [26.93333333333333, 62.66666666666667, 1.0, 2.0, 0.498382988013368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 595493.9396871377, 595493.9396871377, 142680.4542686973], 
processed observation next is [0.0, 0.43478260869565216, 0.5530864197530863, 0.6266666666666667, 1.0, 1.0, 0.40283689049210475, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21267640703112062, 0.21267640703112062, 0.27438548897826404], 
reward next is 0.7256, 
noisyNet noise sample is [array([0.65928674], dtype=float32), 0.11359775]. 
=============================================
[2019-04-27 20:06:48,817] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.4171579e-30 1.0000000e+00 1.4101432e-33 9.5737750e-26 4.7888936e-30], sum to 1.0000
[2019-04-27 20:06:48,823] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5886
[2019-04-27 20:06:48,826] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 51.5, 1.0, 2.0, 0.5765040498830505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 668204.6193994812, 668204.6193994812, 154620.1215589724], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6965400.0000, 
sim time next is 6966000.0000, 
raw observation next is [31.0, 52.0, 1.0, 2.0, 0.5822471924000937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 673463.8641686036, 673463.864168604, 155528.9911550448], 
processed observation next is [0.0, 0.6521739130434783, 0.7037037037037037, 0.52, 1.0, 1.0, 0.5026752290477305, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24052280863164413, 0.2405228086316443, 0.2990942137597015], 
reward next is 0.7009, 
noisyNet noise sample is [array([1.5142819], dtype=float32), 1.7496943]. 
=============================================
[2019-04-27 20:06:48,843] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[78.39047 ]
 [78.3548  ]
 [78.29797 ]
 [78.244446]
 [78.17401 ]], R is [[78.41717529]
 [78.33565521]
 [78.25656891]
 [78.17987823]
 [78.10484314]].
[2019-04-27 20:06:51,391] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78000, global step 1248108: loss -171.2444
[2019-04-27 20:06:51,393] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78000, global step 1248108: learning rate 0.0000
[2019-04-27 20:06:52,078] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.8638340e-21 1.0000000e+00 7.3469988e-25 8.3388019e-20 1.7094035e-22], sum to 1.0000
[2019-04-27 20:06:52,085] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4644
[2019-04-27 20:06:52,092] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78500, global step 1248443: loss 0.2709
[2019-04-27 20:06:52,094] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.85, 85.0, 1.0, 2.0, 0.5510501042014846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 675430.3849379709, 675430.3849379704, 151740.5543534129], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7025400.0000, 
sim time next is 7026000.0000, 
raw observation next is [21.93333333333334, 84.66666666666667, 1.0, 2.0, 0.4806847461145044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 588869.3645233469, 588869.3645233469, 140396.0718676852], 
processed observation next is [1.0, 0.30434782608695654, 0.3679012345679015, 0.8466666666666667, 1.0, 1.0, 0.3817675548982195, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21031048732976673, 0.21031048732976673, 0.26999244589939464], 
reward next is 0.7300, 
noisyNet noise sample is [array([-0.0342351], dtype=float32), -0.79901147]. 
=============================================
[2019-04-27 20:06:52,096] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78500, global step 1248445: learning rate 0.0000
[2019-04-27 20:06:52,111] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[56.888382]
 [57.132866]
 [57.484688]
 [57.75202 ]
 [57.720737]], R is [[57.17216492]
 [57.30863571]
 [57.44689941]
 [57.58925629]
 [57.75722122]].
[2019-04-27 20:06:52,497] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78000, global step 1248635: loss -31.4155
[2019-04-27 20:06:52,503] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78000, global step 1248636: learning rate 0.0000
[2019-04-27 20:06:52,870] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78000, global step 1248810: loss 61.2182
[2019-04-27 20:06:52,871] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78000, global step 1248810: learning rate 0.0000
[2019-04-27 20:06:53,121] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78000, global step 1248934: loss 34.1440
[2019-04-27 20:06:53,123] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78000, global step 1248937: learning rate 0.0000
[2019-04-27 20:06:53,217] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78000, global step 1248978: loss 87.8540
[2019-04-27 20:06:53,220] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78000, global step 1248978: learning rate 0.0000
[2019-04-27 20:06:53,303] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78000, global step 1249021: loss 74.5841
[2019-04-27 20:06:53,304] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78000, global step 1249021: learning rate 0.0000
[2019-04-27 20:06:53,334] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78000, global step 1249033: loss 45.9479
[2019-04-27 20:06:53,336] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78000, global step 1249033: learning rate 0.0000
[2019-04-27 20:06:53,361] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78000, global step 1249043: loss 64.2374
[2019-04-27 20:06:53,363] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78000, global step 1249043: learning rate 0.0000
[2019-04-27 20:06:53,553] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78000, global step 1249132: loss -47.0112
[2019-04-27 20:06:53,556] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78000, global step 1249132: learning rate 0.0000
[2019-04-27 20:06:53,782] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78000, global step 1249241: loss -8.9071
[2019-04-27 20:06:53,785] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78000, global step 1249241: learning rate 0.0000
[2019-04-27 20:06:53,897] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78000, global step 1249304: loss -22.4645
[2019-04-27 20:06:53,902] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78000, global step 1249304: learning rate 0.0000
[2019-04-27 20:06:53,927] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78000, global step 1249314: loss 74.4016
[2019-04-27 20:06:53,930] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78000, global step 1249315: learning rate 0.0000
[2019-04-27 20:06:54,058] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78000, global step 1249382: loss 37.2714
[2019-04-27 20:06:54,061] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78000, global step 1249382: learning rate 0.0000
[2019-04-27 20:06:54,069] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78500, global step 1249386: loss 0.0038
[2019-04-27 20:06:54,072] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78500, global step 1249386: learning rate 0.0000
[2019-04-27 20:06:54,094] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78000, global step 1249394: loss 6.7092
[2019-04-27 20:06:54,096] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78000, global step 1249394: learning rate 0.0000
[2019-04-27 20:06:55,366] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-04-27 20:06:55,370] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 20:06:55,374] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 20:06:55,375] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:06:55,379] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:06:55,380] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 20:06:55,381] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 20:06:55,382] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 20:06:55,383] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:06:55,384] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:06:55,383] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:06:55,400] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run51
[2019-04-27 20:06:55,421] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run51
[2019-04-27 20:06:55,423] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run51
[2019-04-27 20:06:55,444] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run51
[2019-04-27 20:06:55,482] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run51
[2019-04-27 20:07:16,263] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.09664127]
[2019-04-27 20:07:16,263] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.33333333333334, 37.0, 1.0, 2.0, 0.3255649114224912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 413401.7020853552, 413401.7020853552, 118782.0223418983]
[2019-04-27 20:07:16,265] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 20:07:16,270] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.3508980e-30 1.0000000e+00 3.2905310e-35 1.3612879e-27 1.8540951e-31], sampled 0.6026830185832563
[2019-04-27 20:07:16,301] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.09664127]
[2019-04-27 20:07:16,305] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.0, 32.0, 1.0, 2.0, 0.4218378054546152, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 513566.799515136, 513566.799515136, 131499.5944843505]
[2019-04-27 20:07:16,307] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 20:07:16,309] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.70290846e-29 1.00000000e+00 3.49894756e-34 8.32586756e-27
 1.36013865e-30], sampled 0.4923356214687846
[2019-04-27 20:07:17,601] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.09664127]
[2019-04-27 20:07:17,603] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [19.03100939, 71.67167701333334, 1.0, 2.0, 0.2569679939864029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 331468.5453214962, 331468.5453214962, 108736.244878853]
[2019-04-27 20:07:17,605] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 20:07:17,609] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [8.1449750e-29 1.0000000e+00 2.2867588e-33 3.2167125e-26 5.6707913e-30], sampled 0.5601335083053299
[2019-04-27 20:07:18,085] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.09664127]
[2019-04-27 20:07:18,086] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [32.46666666666667, 33.0, 1.0, 2.0, 0.4337492038078856, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 529402.9951402056, 529402.9951402056, 133268.6647000677]
[2019-04-27 20:07:18,088] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 20:07:18,090] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.6163241e-29 1.0000000e+00 8.4155973e-34 1.6717839e-26 3.0088407e-30], sampled 0.9606282700865504
[2019-04-27 20:07:19,868] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.09664127]
[2019-04-27 20:07:19,871] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.86666666666667, 50.0, 1.0, 2.0, 0.3979532030102512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 492514.8931783518, 492514.8931783513, 128318.2397689211]
[2019-04-27 20:07:19,873] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 20:07:19,877] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.49372254e-31 1.00000000e+00 1.21440785e-36 1.27159693e-28
 1.36213112e-32], sampled 0.8027481304250205
[2019-04-27 20:07:31,841] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.09664127]
[2019-04-27 20:07:31,844] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [36.21505528, 23.20673883, 1.0, 2.0, 0.5877151913999441, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 717629.3689899067, 717629.3689899067, 157917.0080878619]
[2019-04-27 20:07:31,846] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 20:07:31,849] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.9171266e-29 1.0000000e+00 5.2404539e-34 2.0101051e-26 5.5721931e-30], sampled 0.8794226905595499
[2019-04-27 20:07:42,154] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.09664127]
[2019-04-27 20:07:42,155] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [20.4, 92.0, 1.0, 2.0, 0.3937164254435651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 487123.6369947006, 487123.6369947006, 127721.4979096181]
[2019-04-27 20:07:42,156] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 20:07:42,158] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.7391679e-28 1.0000000e+00 5.4253807e-33 6.9125872e-26 1.3835467e-29], sampled 0.3321054506751031
[2019-04-27 20:07:43,597] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.09664127]
[2019-04-27 20:07:43,598] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.08333333333334, 78.16666666666666, 1.0, 2.0, 0.6570224859552536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 748795.8441557282, 748795.8441557282, 168165.6709499928]
[2019-04-27 20:07:43,599] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 20:07:43,602] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.1105111e-28 1.0000000e+00 6.2387651e-33 1.0431237e-25 2.6399522e-29], sampled 0.5176232236626214
[2019-04-27 20:07:47,981] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.09664127]
[2019-04-27 20:07:47,982] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.1, 77.5, 1.0, 2.0, 0.9421001803316138, 1.0, 2.0, 0.9421001803316138, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 123.0848512560023, 2149211.179752586, 2149211.179752586, 406145.6390641514]
[2019-04-27 20:07:47,983] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 20:07:47,987] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.3946881e-32 1.0000000e+00 1.8565667e-37 3.3284290e-28 2.3747734e-31], sampled 0.6565683923903938
[2019-04-27 20:07:47,988] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2149211.179752586 W.
[2019-04-27 20:07:53,235] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.09664127]
[2019-04-27 20:07:53,238] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.231973915, 87.519745, 1.0, 2.0, 0.5906541000398581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 702449.2128899783, 702449.2128899783, 157783.0553474441]
[2019-04-27 20:07:53,239] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 20:07:53,243] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [7.3672544e-27 1.0000000e+00 3.8848699e-31 2.8260569e-24 1.2263264e-27], sampled 0.9614035807584661
[2019-04-27 20:08:01,457] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.09664127]
[2019-04-27 20:08:01,457] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.16666666666666, 82.66666666666667, 1.0, 2.0, 0.6110246967001571, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 696349.2409227063, 696349.2409227063, 159983.8512859349]
[2019-04-27 20:08:01,458] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 20:08:01,461] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.6652616e-28 1.0000000e+00 2.0309636e-32 2.3064801e-25 6.3134265e-29], sampled 0.5647547265833085
[2019-04-27 20:08:13,408] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.09664127]
[2019-04-27 20:08:13,409] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.3, 84.0, 1.0, 2.0, 0.783239923578256, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 892727.1940942667, 892727.1940942667, 192507.5156436846]
[2019-04-27 20:08:13,412] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 20:08:13,414] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.4767769e-29 1.0000000e+00 5.8586064e-34 3.6714295e-26 1.3505074e-29], sampled 0.6024274405698192
[2019-04-27 20:08:15,939] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.09664127]
[2019-04-27 20:08:15,941] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.0, 79.0, 1.0, 2.0, 0.5843213609956547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 676255.0770583535, 676255.0770583535, 155899.7260181926]
[2019-04-27 20:08:15,943] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 20:08:15,945] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.3162548e-28 1.0000000e+00 7.3435505e-33 9.9297398e-26 2.2378504e-29], sampled 0.17880085454279715
[2019-04-27 20:08:46,138] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8769.4422 2170768739.9937 493.0000
[2019-04-27 20:08:46,596] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.09664127]
[2019-04-27 20:08:46,596] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.089899815, 70.07893908166668, 1.0, 2.0, 0.6975661132170202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 795026.5965033736, 795026.5965033732, 175688.475608483]
[2019-04-27 20:08:46,597] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 20:08:46,599] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.305158e-28 1.000000e+00 2.539288e-32 8.549174e-25 6.003280e-28], sampled 0.6826222705324893
[2019-04-27 20:08:46,790] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8922.6628 2120599135.7723 430.0000
[2019-04-27 20:08:46,846] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8582.0590 2248830394.8409 553.0000
[2019-04-27 20:08:46,847] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8098.4495 2445508074.6415 746.0000
[2019-04-27 20:08:46,849] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8700.1130 2195220806.1349 572.0000
[2019-04-27 20:08:47,864] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1250000, evaluation results [1250000.0, 8098.4494892610255, 2445508074.64147, 746.0, 8769.442185004564, 2170768739.993712, 493.0, 8922.662781171732, 2120599135.7722971, 430.0, 8582.059032767682, 2248830394.840892, 553.0, 8700.112961499688, 2195220806.134913, 572.0]
[2019-04-27 20:08:55,835] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.20250064e-30 1.00000000e+00 3.19761394e-34 2.56806615e-23
 1.08573214e-26], sum to 1.0000
[2019-04-27 20:08:55,845] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7583
[2019-04-27 20:08:55,849] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.25, 76.0, 1.0, 2.0, 0.3919717795157055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 486138.9148172616, 486138.9148172616, 127504.321175569], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7245000.0000, 
sim time next is 7245600.0000, 
raw observation next is [22.16666666666667, 76.33333333333333, 1.0, 2.0, 0.3896076922121052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 483439.1701342592, 483439.1701342587, 127180.1531026539], 
processed observation next is [1.0, 0.8695652173913043, 0.3765432098765434, 0.7633333333333333, 1.0, 1.0, 0.2733424907286967, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17265684647652116, 0.17265684647652096, 0.24457721750510367], 
reward next is 0.7554, 
noisyNet noise sample is [array([-0.96086055], dtype=float32), -0.022482682]. 
=============================================
[2019-04-27 20:08:59,619] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78500, global step 1255997: loss 0.1770
[2019-04-27 20:08:59,621] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78500, global step 1255998: learning rate 0.0000
[2019-04-27 20:09:00,337] A3C_AGENT_WORKER-Thread-22 INFO:Local step 79000, global step 1256363: loss -84.4482
[2019-04-27 20:09:00,344] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 79000, global step 1256363: learning rate 0.0000
[2019-04-27 20:09:00,545] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2745217e-26 1.0000000e+00 5.5633759e-31 7.8159526e-24 5.2207789e-27], sum to 1.0000
[2019-04-27 20:09:00,552] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4324
[2019-04-27 20:09:00,555] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.73333333333333, 92.0, 1.0, 2.0, 0.3624408378109262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 452405.9401228782, 452405.9401228782, 123522.0075436594], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7622400.0000, 
sim time next is 7623000.0000, 
raw observation next is [19.8, 92.0, 1.0, 2.0, 0.3637969287197159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 453704.0441149747, 453704.0441149747, 123696.9229762139], 
processed observation next is [1.0, 0.21739130434782608, 0.2888888888888889, 0.92, 1.0, 1.0, 0.24261539133299515, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16203715861249096, 0.16203715861249096, 0.23787869803118059], 
reward next is 0.7621, 
noisyNet noise sample is [array([1.0695176], dtype=float32), -1.5030369]. 
=============================================
[2019-04-27 20:09:00,566] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[70.98831]
 [71.0714 ]
 [71.09308]
 [71.16285]
 [71.26895]], R is [[70.92681122]
 [70.98000336]
 [71.03150177]
 [71.0831604 ]
 [71.1326828 ]].
[2019-04-27 20:09:00,647] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.14795102e-28 1.00000000e+00 1.04277384e-32 1.30712304e-25
 6.16273778e-27], sum to 1.0000
[2019-04-27 20:09:00,655] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7891
[2019-04-27 20:09:00,659] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.25, 77.16666666666666, 1.0, 2.0, 0.4451632509385253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 543052.8888547067, 543052.8888547062, 134942.8404631437], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7332600.0000, 
sim time next is 7333200.0000, 
raw observation next is [23.1, 78.0, 1.0, 2.0, 0.4437119589189752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 541524.4306412261, 541524.4306412261, 134734.6542720724], 
processed observation next is [1.0, 0.9130434782608695, 0.41111111111111115, 0.78, 1.0, 1.0, 0.33775233204639904, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19340158237186647, 0.19340158237186647, 0.25910510436937], 
reward next is 0.7409, 
noisyNet noise sample is [array([0.6234161], dtype=float32), 1.9061615]. 
=============================================
[2019-04-27 20:09:00,720] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78500, global step 1256549: loss 0.2188
[2019-04-27 20:09:00,722] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78500, global step 1256549: learning rate 0.0000
[2019-04-27 20:09:01,118] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78500, global step 1256759: loss 0.3502
[2019-04-27 20:09:01,120] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78500, global step 1256761: learning rate 0.0000
[2019-04-27 20:09:01,387] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78500, global step 1256899: loss 0.2523
[2019-04-27 20:09:01,389] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78500, global step 1256899: learning rate 0.0000
[2019-04-27 20:09:01,466] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78500, global step 1256935: loss 0.1541
[2019-04-27 20:09:01,469] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78500, global step 1256936: learning rate 0.0000
[2019-04-27 20:09:01,504] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78500, global step 1256955: loss 0.1267
[2019-04-27 20:09:01,506] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78500, global step 1256955: learning rate 0.0000
[2019-04-27 20:09:01,617] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78500, global step 1257011: loss 0.1461
[2019-04-27 20:09:01,620] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78500, global step 1257011: learning rate 0.0000
[2019-04-27 20:09:01,745] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78500, global step 1257076: loss 0.1644
[2019-04-27 20:09:01,751] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78500, global step 1257076: learning rate 0.0000
[2019-04-27 20:09:01,832] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78500, global step 1257118: loss 0.1402
[2019-04-27 20:09:01,835] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78500, global step 1257119: learning rate 0.0000
[2019-04-27 20:09:02,086] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78500, global step 1257252: loss 0.2739
[2019-04-27 20:09:02,090] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78500, global step 1257254: learning rate 0.0000
[2019-04-27 20:09:02,170] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78500, global step 1257297: loss 0.2637
[2019-04-27 20:09:02,172] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78500, global step 1257297: learning rate 0.0000
[2019-04-27 20:09:02,342] A3C_AGENT_WORKER-Thread-13 INFO:Local step 79000, global step 1257385: loss -57.8073
[2019-04-27 20:09:02,347] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 79000, global step 1257385: learning rate 0.0000
[2019-04-27 20:09:02,409] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78500, global step 1257417: loss 0.0577
[2019-04-27 20:09:02,411] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78500, global step 1257417: learning rate 0.0000
[2019-04-27 20:09:02,423] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78500, global step 1257422: loss 0.0449
[2019-04-27 20:09:02,426] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78500, global step 1257423: learning rate 0.0000
[2019-04-27 20:09:02,493] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78500, global step 1257460: loss 0.0588
[2019-04-27 20:09:02,494] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78500, global step 1257460: learning rate 0.0000
[2019-04-27 20:09:03,683] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.6792794e-22 1.0000000e+00 2.4617896e-26 3.5741990e-18 1.3125354e-16], sum to 1.0000
[2019-04-27 20:09:03,695] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4195
[2019-04-27 20:09:03,700] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.3, 91.33333333333334, 1.0, 2.0, 0.7536003379888488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 919416.1196186217, 919416.1196186217, 189140.2694566397], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7396800.0000, 
sim time next is 7397400.0000, 
raw observation next is [21.3, 91.16666666666667, 1.0, 2.0, 0.7303052953307494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 891360.1030494439, 891360.1030494439, 184470.3430230255], 
processed observation next is [1.0, 0.6086956521739131, 0.3444444444444445, 0.9116666666666667, 1.0, 1.0, 0.6789348753937493, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31834289394622994, 0.31834289394622994, 0.3547506596596644], 
reward next is 0.6452, 
noisyNet noise sample is [array([-1.7515227], dtype=float32), -0.53181964]. 
=============================================
[2019-04-27 20:09:12,559] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.1270662e-29 1.0000000e+00 3.9139145e-34 6.2352394e-27 7.3348793e-31], sum to 1.0000
[2019-04-27 20:09:12,571] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1292
[2019-04-27 20:09:12,577] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 66.0, 1.0, 2.0, 0.564871445826686, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 655819.8805342345, 655819.8805342345, 152716.5061509302], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7570800.0000, 
sim time next is 7571400.0000, 
raw observation next is [28.0, 65.33333333333333, 1.0, 2.0, 0.5641669426975701, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 655540.187773559, 655540.1877735585, 152622.7493541865], 
processed observation next is [0.0, 0.6521739130434783, 0.5925925925925926, 0.6533333333333333, 1.0, 1.0, 0.48115112225901197, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23412149563341395, 0.23412149563341378, 0.2935052872195894], 
reward next is 0.7065, 
noisyNet noise sample is [array([0.9668411], dtype=float32), 1.0370444]. 
=============================================
[2019-04-27 20:09:12,660] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.7499433e-29 1.0000000e+00 9.5493708e-34 9.6664629e-28 3.3895815e-31], sum to 1.0000
[2019-04-27 20:09:12,668] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1764
[2019-04-27 20:09:12,671] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 64.66666666666667, 1.0, 2.0, 0.5603499506481299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 652563.397347733, 652563.3973477326, 152051.7144729476], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7572000.0000, 
sim time next is 7572600.0000, 
raw observation next is [28.0, 64.0, 1.0, 2.0, 0.5563684855350272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 649402.1302626427, 649402.1302626427, 151455.2884353252], 
processed observation next is [0.0, 0.6521739130434783, 0.5925925925925926, 0.64, 1.0, 1.0, 0.4718672446845561, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23192933223665813, 0.23192933223665813, 0.2912601700679331], 
reward next is 0.7087, 
noisyNet noise sample is [array([0.22598419], dtype=float32), -0.3877211]. 
=============================================
[2019-04-27 20:09:14,389] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.0930485e-26 1.0000000e+00 6.2141916e-30 1.1944439e-23 3.3523226e-27], sum to 1.0000
[2019-04-27 20:09:14,395] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1235
[2019-04-27 20:09:14,398] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.03333333333333, 85.66666666666667, 1.0, 2.0, 0.4522204360499196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 560051.4970123458, 560051.4970123458, 136212.4104277515], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7611600.0000, 
sim time next is 7612200.0000, 
raw observation next is [20.95, 86.0, 1.0, 2.0, 0.4085091613214916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 506279.8954035432, 506279.8954035432, 129827.0894807534], 
processed observation next is [1.0, 0.08695652173913043, 0.33148148148148143, 0.86, 1.0, 1.0, 0.2958442396684424, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18081424835840829, 0.18081424835840829, 0.24966747977067963], 
reward next is 0.7503, 
noisyNet noise sample is [array([-0.6106924], dtype=float32), -0.9719256]. 
=============================================
[2019-04-27 20:09:15,011] A3C_AGENT_WORKER-Thread-3 INFO:Local step 79000, global step 1263964: loss 67.3309
[2019-04-27 20:09:15,014] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 79000, global step 1263966: learning rate 0.0000
[2019-04-27 20:09:16,244] A3C_AGENT_WORKER-Thread-15 INFO:Local step 79000, global step 1264545: loss -12.6710
[2019-04-27 20:09:16,247] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 79000, global step 1264546: learning rate 0.0000
[2019-04-27 20:09:16,687] A3C_AGENT_WORKER-Thread-21 INFO:Local step 79000, global step 1264761: loss -11.1045
[2019-04-27 20:09:16,688] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 79000, global step 1264761: learning rate 0.0000
[2019-04-27 20:09:16,855] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:09:16,855] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:09:16,888] A3C_AGENT_WORKER-Thread-14 INFO:Local step 79000, global step 1264852: loss 41.1787
[2019-04-27 20:09:16,890] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 79000, global step 1264852: learning rate 0.0000
[2019-04-27 20:09:16,904] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run7
[2019-04-27 20:09:17,035] A3C_AGENT_WORKER-Thread-16 INFO:Local step 79000, global step 1264912: loss 44.9343
[2019-04-27 20:09:17,039] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 79000, global step 1264914: learning rate 0.0000
[2019-04-27 20:09:17,061] A3C_AGENT_WORKER-Thread-17 INFO:Local step 79000, global step 1264926: loss -5.6997
[2019-04-27 20:09:17,063] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 79000, global step 1264926: learning rate 0.0000
[2019-04-27 20:09:17,067] A3C_AGENT_WORKER-Thread-20 INFO:Local step 79000, global step 1264926: loss 1.1831
[2019-04-27 20:09:17,068] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 79000, global step 1264926: learning rate 0.0000
[2019-04-27 20:09:17,104] A3C_AGENT_WORKER-Thread-2 INFO:Local step 79000, global step 1264939: loss -16.3930
[2019-04-27 20:09:17,106] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 79000, global step 1264939: learning rate 0.0000
[2019-04-27 20:09:17,219] A3C_AGENT_WORKER-Thread-9 INFO:Local step 79000, global step 1265007: loss -76.1318
[2019-04-27 20:09:17,221] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 79000, global step 1265007: learning rate 0.0000
[2019-04-27 20:09:17,470] A3C_AGENT_WORKER-Thread-19 INFO:Local step 79000, global step 1265150: loss -56.0085
[2019-04-27 20:09:17,472] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 79000, global step 1265151: learning rate 0.0000
[2019-04-27 20:09:17,562] A3C_AGENT_WORKER-Thread-10 INFO:Local step 79000, global step 1265201: loss -1.2161
[2019-04-27 20:09:17,568] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 79000, global step 1265202: learning rate 0.0000
[2019-04-27 20:09:17,777] A3C_AGENT_WORKER-Thread-11 INFO:Local step 79000, global step 1265320: loss -96.7650
[2019-04-27 20:09:17,779] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 79000, global step 1265320: learning rate 0.0000
[2019-04-27 20:09:17,791] A3C_AGENT_WORKER-Thread-18 INFO:Local step 79000, global step 1265327: loss -48.0361
[2019-04-27 20:09:17,791] A3C_AGENT_WORKER-Thread-12 INFO:Local step 79000, global step 1265327: loss -78.1388
[2019-04-27 20:09:17,792] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 79000, global step 1265327: learning rate 0.0000
[2019-04-27 20:09:17,792] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 79000, global step 1265327: learning rate 0.0000
[2019-04-27 20:09:18,365] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.747396e-28 1.000000e+00 5.417770e-33 4.240972e-25 8.907775e-29], sum to 1.0000
[2019-04-27 20:09:18,376] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2769
[2019-04-27 20:09:18,382] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.7, 82.0, 1.0, 2.0, 0.3265804313983775, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 413802.9024953499, 413802.9024953499, 118905.0667213898], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7682400.0000, 
sim time next is 7683000.0000, 
raw observation next is [19.68333333333333, 82.66666666666667, 1.0, 2.0, 0.3307655717257229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 418815.8914944866, 418815.8914944861, 119440.6802811138], 
processed observation next is [1.0, 0.9565217391304348, 0.28456790123456777, 0.8266666666666667, 1.0, 1.0, 0.20329234729252726, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14957710410517377, 0.1495771041051736, 0.22969361592521886], 
reward next is 0.7703, 
noisyNet noise sample is [array([0.7143977], dtype=float32), -1.144427]. 
=============================================
[2019-04-27 20:09:18,399] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[79.95974 ]
 [79.816216]
 [79.8438  ]
 [79.85197 ]
 [79.78865 ]], R is [[79.98373413]
 [79.95523834]
 [79.92749786]
 [79.90042877]
 [79.87386322]].
[2019-04-27 20:09:18,923] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:09:18,923] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:09:18,983] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run7
[2019-04-27 20:09:19,072] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.7321543e-29 1.0000000e+00 1.8476117e-33 1.0198809e-26 8.3017474e-31], sum to 1.0000
[2019-04-27 20:09:19,078] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1642
[2019-04-27 20:09:19,083] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.73333333333333, 81.33333333333334, 1.0, 2.0, 0.3246351517216687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 411568.2498900276, 411568.2498900276, 118657.9591786152], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7681800.0000, 
sim time next is 7682400.0000, 
raw observation next is [19.7, 82.0, 1.0, 2.0, 0.3265804313983775, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 413802.9024953499, 413802.9024953499, 118905.0667213898], 
processed observation next is [1.0, 0.9565217391304348, 0.28518518518518515, 0.82, 1.0, 1.0, 0.19831003737902084, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1477867508911964, 0.1477867508911964, 0.22866358984882654], 
reward next is 0.7713, 
noisyNet noise sample is [array([1.4988012], dtype=float32), -0.5634403]. 
=============================================
[2019-04-27 20:09:23,084] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.9286473e-29 1.0000000e+00 1.5275461e-33 1.5411892e-26 5.5926448e-27], sum to 1.0000
[2019-04-27 20:09:23,094] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7782
[2019-04-27 20:09:23,098] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.4, 74.0, 1.0, 2.0, 0.3499820938754528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 440207.4466638992, 440207.4466638992, 121917.0039296335], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7776000.0000, 
sim time next is 7776600.0000, 
raw observation next is [21.36666666666667, 73.83333333333334, 1.0, 2.0, 0.3482817038363532, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 438319.4495411519, 438319.4495411519, 121695.7746161226], 
processed observation next is [1.0, 0.0, 0.3469135802469137, 0.7383333333333334, 1.0, 1.0, 0.2241448855194681, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15654266055041138, 0.15654266055041138, 0.23403033580023577], 
reward next is 0.7660, 
noisyNet noise sample is [array([0.5273371], dtype=float32), 1.1317211]. 
=============================================
[2019-04-27 20:09:30,102] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.6260881e-13 9.9997592e-01 5.5879145e-16 1.5549404e-08 2.4113395e-05], sum to 1.0000
[2019-04-27 20:09:30,115] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8070
[2019-04-27 20:09:30,121] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1403912.866699203 W.
[2019-04-27 20:09:30,125] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.01666666666667, 56.0, 1.0, 2.0, 0.9696823928041325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.351505531425807, 6.9112, 121.9240959772431, 1403912.866699203, 1178440.680433145, 236973.5546299653], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7901400.0000, 
sim time next is 7902000.0000, 
raw observation next is [27.3, 55.0, 1.0, 2.0, 0.5147408599705674, 1.0, 1.0, 0.5147408599705674, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9257774368527, 1227576.590930933, 1227576.590930933, 242335.9332655581], 
processed observation next is [1.0, 0.4782608695652174, 0.5666666666666667, 0.55, 1.0, 1.0, 0.42231054758400877, 1.0, 0.5, 0.42231054758400877, 0.0, 1.0, -0.25, 0.0, 0.0, 0.80946036830861, 0.43842021104676177, 0.43842021104676177, 0.46603064089530405], 
reward next is 0.5340, 
noisyNet noise sample is [array([-1.6158553], dtype=float32), 0.007356318]. 
=============================================
[2019-04-27 20:09:30,137] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[58.922604]
 [59.004658]
 [59.047604]
 [59.648724]
 [59.619045]], R is [[59.28481293]
 [58.69196701]
 [58.10504913]
 [58.11194229]
 [58.03390121]].
[2019-04-27 20:09:31,697] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:09:31,697] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:09:31,768] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run7
[2019-04-27 20:09:32,911] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:09:32,911] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:09:32,925] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run7
[2019-04-27 20:09:33,103] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.2454061e-26 1.0000000e+00 2.0989714e-30 4.3459100e-21 3.6825160e-23], sum to 1.0000
[2019-04-27 20:09:33,103] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1932
[2019-04-27 20:09:33,106] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 40.0, 1.0, 2.0, 0.303167304810273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 389778.7678291199, 389778.7678291199, 115963.8980081198], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 336000.0000, 
sim time next is 336600.0000, 
raw observation next is [24.85, 40.5, 1.0, 2.0, 0.3014614846650128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 387686.8572358489, 387686.8572358489, 115751.8048616694], 
processed observation next is [0.0, 0.9130434782608695, 0.475925925925926, 0.405, 1.0, 1.0, 0.1684065293631105, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13845959186994602, 0.13845959186994602, 0.22259962473397962], 
reward next is 0.7774, 
noisyNet noise sample is [array([-0.7387565], dtype=float32), -0.5316647]. 
=============================================
[2019-04-27 20:09:33,260] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:09:33,260] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:09:33,272] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run7
[2019-04-27 20:09:33,295] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:09:33,299] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:09:33,323] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run7
[2019-04-27 20:09:33,459] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:09:33,460] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:09:33,478] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run7
[2019-04-27 20:09:33,508] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:09:33,509] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:09:33,515] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:09:33,509] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:09:33,516] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:09:33,511] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:09:33,516] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:09:33,510] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:09:33,541] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run7
[2019-04-27 20:09:33,565] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run7
[2019-04-27 20:09:33,594] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run7
[2019-04-27 20:09:33,619] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run7
[2019-04-27 20:09:33,717] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:09:33,717] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:09:33,721] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run7
[2019-04-27 20:09:33,746] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:09:33,747] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:09:33,751] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run7
[2019-04-27 20:09:33,793] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:09:33,793] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:09:33,806] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:09:33,806] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:09:33,809] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run7
[2019-04-27 20:09:33,831] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:09:33,832] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:09:33,835] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run7
[2019-04-27 20:09:33,865] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run7
[2019-04-27 20:09:37,129] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.2292367e-16 9.9999976e-01 2.3355771e-22 5.8274462e-11 2.3320604e-07], sum to 1.0000
[2019-04-27 20:09:37,137] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3348
[2019-04-27 20:09:37,140] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.73333333333333, 42.66666666666667, 1.0, 2.0, 0.7346850497808546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 934249.3013005974, 934249.3013005974, 186125.0279047625], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 36600.0000, 
sim time next is 37200.0000, 
raw observation next is [25.96666666666667, 42.33333333333334, 1.0, 2.0, 0.7310919079655676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 928420.617739008, 928420.6177390076, 185393.7790668757], 
processed observation next is [1.0, 0.43478260869565216, 0.517283950617284, 0.42333333333333345, 1.0, 1.0, 0.679871319006628, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.33157879204964574, 0.3315787920496456, 0.3565264982055302], 
reward next is 0.6435, 
noisyNet noise sample is [array([1.8689594], dtype=float32), 1.0736402]. 
=============================================
[2019-04-27 20:09:38,367] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-04-27 20:09:38,370] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 20:09:38,373] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 20:09:38,373] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:09:38,374] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:09:38,374] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 20:09:38,375] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 20:09:38,376] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 20:09:38,376] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:09:38,376] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:09:38,376] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:09:38,399] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run52
[2019-04-27 20:09:38,400] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run52
[2019-04-27 20:09:38,442] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run52
[2019-04-27 20:09:38,442] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run52
[2019-04-27 20:09:38,481] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run52
[2019-04-27 20:09:51,111] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.10127008]
[2019-04-27 20:09:51,112] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [32.80655243, 37.14688139, 1.0, 2.0, 0.4617959315813697, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 553584.459479115, 553584.459479115, 137122.4501784148]
[2019-04-27 20:09:51,114] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 20:09:51,117] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.6805321e-30 1.0000000e+00 3.6158717e-35 1.9116559e-27 8.1899915e-30], sampled 0.906782452592633
[2019-04-27 20:10:08,237] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.10127008]
[2019-04-27 20:10:08,238] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.25, 63.0, 1.0, 2.0, 0.551760029563327, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 643823.4212184617, 643823.4212184612, 150684.3592150132]
[2019-04-27 20:10:08,239] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 20:10:08,242] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.7733811e-29 1.0000000e+00 3.2250544e-34 1.1367659e-26 5.7111954e-29], sampled 0.4233518634493668
[2019-04-27 20:10:08,581] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.10127008]
[2019-04-27 20:10:08,584] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.05, 74.5, 1.0, 2.0, 0.3632842649365619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 452991.3764051935, 452991.3764051935, 123626.4153524753]
[2019-04-27 20:10:08,585] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 20:10:08,588] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.1266156e-30 1.0000000e+00 6.0747413e-35 2.6719300e-27 1.1324619e-29], sampled 0.09820516889806974
[2019-04-27 20:10:21,704] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.10127008]
[2019-04-27 20:10:21,705] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.01349324166667, 64.975436345, 1.0, 2.0, 0.7799356352382006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 888958.8227806218, 888958.8227806218, 191827.3731706285]
[2019-04-27 20:10:21,706] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 20:10:21,709] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.42492055e-27 1.00000000e+00 4.85173832e-32 7.27973662e-25
 6.64693043e-27], sampled 0.09621499010859669
[2019-04-27 20:10:23,204] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.10127008]
[2019-04-27 20:10:23,205] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [30.74697404666667, 83.22544231666667, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 1.0, 2.0, 0.9977734948820727, 187.5468413875654, 6.9112, 144.3301726206284, 112502531.8348489, 3003603.962646914, 523215.4166959884]
[2019-04-27 20:10:23,206] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 20:10:23,211] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0. 0. 0. 0. 1.], sampled 0.45105068698152573
[2019-04-27 20:10:24,037] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.10127008]
[2019-04-27 20:10:24,041] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [34.55, 31.83333333333333, 1.0, 2.0, 0.953069812498524, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9767099728000929, 6.9112, 6.9112, 121.9260426156618, 1829067.967862782, 1829067.967862782, 365210.9224769534]
[2019-04-27 20:10:24,042] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 20:10:24,048] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.2075764e-27 1.0000000e+00 2.8282888e-32 4.5022629e-25 7.7139280e-27], sampled 0.4208399257559009
[2019-04-27 20:10:24,050] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1829067.967862782 W.
[2019-04-27 20:10:36,955] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.10127008]
[2019-04-27 20:10:36,956] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.9, 88.5, 1.0, 2.0, 0.7989028381953808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 910590.196666361, 910590.196666361, 195715.2474539786]
[2019-04-27 20:10:36,958] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 20:10:36,962] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.2673174e-27 1.0000000e+00 8.5534165e-32 1.0516024e-24 9.7339250e-27], sampled 0.9705006756280842
[2019-04-27 20:10:38,994] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.10127008]
[2019-04-27 20:10:38,997] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.0, 79.0, 1.0, 2.0, 0.7528319939035292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 858049.2097947865, 858049.2097947865, 186392.9116128498]
[2019-04-27 20:10:38,997] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 20:10:39,002] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0122211e-28 1.0000000e+00 2.2136649e-33 6.4810544e-26 4.4622463e-28], sampled 0.24656931881520538
[2019-04-27 20:11:06,188] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.10127008]
[2019-04-27 20:11:06,281] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.9, 86.0, 1.0, 2.0, 0.5630365697000225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 665332.5568710561, 665332.5568710561, 152907.2809829933]
[2019-04-27 20:11:06,283] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 20:11:06,284] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.7081908e-28 1.0000000e+00 1.1187672e-32 1.8546667e-25 1.2605040e-27], sampled 0.07995955137582011
[2019-04-27 20:11:28,148] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.10127008]
[2019-04-27 20:11:28,149] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.83333333333333, 65.83333333333333, 1.0, 2.0, 0.6620395427632871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 785133.8594874142, 785133.8594874138, 170486.5269475311]
[2019-04-27 20:11:28,149] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 20:11:28,152] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.5046142e-27 1.0000000e+00 5.4566213e-32 7.2667244e-25 6.0623579e-27], sampled 0.746977558902715
[2019-04-27 20:11:28,609] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8766.9960 2170944100.2627 493.0000
[2019-04-27 20:11:28,660] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8579.6129 2249005755.1099 553.0000
[2019-04-27 20:11:28,899] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8096.1228 2445685030.0399 746.0000
[2019-04-27 20:11:29,065] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8920.2845 2120775997.4899 430.0000
[2019-04-27 20:11:29,082] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8698.5544 2195342049.7036 572.0000
[2019-04-27 20:11:30,097] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1275000, evaluation results [1275000.0, 8096.1228420842035, 2445685030.039925, 746.0, 8766.996003344108, 2170944100.262687, 493.0, 8920.284511795213, 2120775997.4898655, 430.0, 8579.612851107222, 2249005755.1098666, 553.0, 8698.554408555452, 2195342049.703552, 572.0]
[2019-04-27 20:11:36,294] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.1116612e-26 1.0000000e+00 3.6734937e-31 1.1402856e-23 7.4026770e-24], sum to 1.0000
[2019-04-27 20:11:36,305] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7180
[2019-04-27 20:11:36,314] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.9, 12.66666666666667, 1.0, 2.0, 0.3346288182085058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 431673.1079750034, 431673.1079750034, 100979.9417050135], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 174000.0000, 
sim time next is 174600.0000, 
raw observation next is [28.65, 13.0, 1.0, 2.0, 0.332429341624753, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 428834.9771359836, 428834.9771359836, 100398.2709084508], 
processed observation next is [0.0, 0.0, 0.6166666666666666, 0.13, 1.0, 1.0, 0.20527302574375358, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.153155348977137, 0.153155348977137, 0.19307359790086692], 
reward next is 0.8069, 
noisyNet noise sample is [array([1.1525449], dtype=float32), 0.1063118]. 
=============================================
[2019-04-27 20:11:39,356] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.8046621e-25 1.0000000e+00 3.4842688e-27 5.2445913e-20 9.4168038e-24], sum to 1.0000
[2019-04-27 20:11:39,365] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9274
[2019-04-27 20:11:39,368] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.48333333333333, 15.5, 1.0, 2.0, 0.3848619138747487, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 492886.2030643176, 492886.2030643176, 126705.7155248914], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 234600.0000, 
sim time next is 235200.0000, 
raw observation next is [33.26666666666667, 16.0, 1.0, 2.0, 0.3814577846746978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 488467.9608543933, 488467.9608543938, 126234.5876607838], 
processed observation next is [0.0, 0.7391304347826086, 0.7876543209876545, 0.16, 1.0, 1.0, 0.26364021985083075, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17445284316228332, 0.1744528431622835, 0.24275882242458424], 
reward next is 0.7572, 
noisyNet noise sample is [array([-2.130601], dtype=float32), -0.006335107]. 
=============================================
[2019-04-27 20:11:42,005] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.7515277e-29 1.0000000e+00 6.8456500e-32 3.7649992e-24 2.4031770e-25], sum to 1.0000
[2019-04-27 20:11:42,014] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3794
[2019-04-27 20:11:42,022] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.01666666666667, 30.83333333333334, 1.0, 2.0, 0.3338279191838805, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 427074.7550995255, 427074.755099526, 119859.1155408171], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 317400.0000, 
sim time next is 318000.0000, 
raw observation next is [28.03333333333333, 30.66666666666667, 1.0, 2.0, 0.3338385569133337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 427180.3671322999, 427180.3671322995, 119860.5047748595], 
processed observation next is [0.0, 0.6956521739130435, 0.5938271604938271, 0.3066666666666667, 1.0, 1.0, 0.20695066299206394, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15256441683296426, 0.15256441683296412, 0.23050097072088366], 
reward next is 0.7695, 
noisyNet noise sample is [array([0.61134124], dtype=float32), 0.740035]. 
=============================================
[2019-04-27 20:11:42,034] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[85.15579]
 [85.13564]
 [85.05129]
 [85.03288]
 [85.02043]], R is [[85.09017944]
 [85.00878143]
 [84.92828369]
 [84.84870148]
 [84.77003479]].
[2019-04-27 20:11:45,035] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.2370453e-20 1.0000000e+00 1.5008903e-24 3.9841903e-18 6.5756356e-19], sum to 1.0000
[2019-04-27 20:11:45,042] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0393
[2019-04-27 20:11:45,052] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.95, 50.5, 1.0, 2.0, 0.2694582073309508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 347583.5916054388, 347583.5916054388, 105985.2170430282], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 348600.0000, 
sim time next is 349200.0000, 
raw observation next is [21.8, 51.0, 1.0, 2.0, 0.2678388048109389, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 345494.1969839053, 345494.1969839049, 105130.1605125173], 
processed observation next is [1.0, 0.043478260869565216, 0.362962962962963, 0.51, 1.0, 1.0, 0.12837952953683204, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12339078463710902, 0.1233907846371089, 0.2021733856009948], 
reward next is 0.7978, 
noisyNet noise sample is [array([-0.7260068], dtype=float32), -1.9908812]. 
=============================================
[2019-04-27 20:11:49,992] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.0839283e-19 1.0000000e+00 1.5999965e-22 6.4487497e-18 9.2940665e-18], sum to 1.0000
[2019-04-27 20:11:49,999] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2310
[2019-04-27 20:11:50,006] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 70.66666666666667, 1.0, 2.0, 0.2848357308308542, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 366891.2651914844, 366891.265191484, 113713.4366709146], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 444000.0000, 
sim time next is 444600.0000, 
raw observation next is [19.25, 71.5, 1.0, 2.0, 0.2810751382822442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 362167.6150971625, 362167.6150971621, 113259.173563454], 
processed observation next is [1.0, 0.13043478260869565, 0.26851851851851855, 0.715, 1.0, 1.0, 0.14413706938362403, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12934557682041517, 0.12934557682041503, 0.2178061030066423], 
reward next is 0.7822, 
noisyNet noise sample is [array([0.38643765], dtype=float32), -0.44333783]. 
=============================================
[2019-04-27 20:11:59,365] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.7369742e-19 1.0000000e+00 3.8157250e-22 6.4944835e-14 1.0171301e-11], sum to 1.0000
[2019-04-27 20:11:59,373] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5135
[2019-04-27 20:11:59,379] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.76666666666667, 63.33333333333333, 1.0, 2.0, 0.3762194495029246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 479118.1205071408, 479118.1205071408, 125507.7593300479], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 618000.0000, 
sim time next is 618600.0000, 
raw observation next is [21.58333333333333, 64.16666666666667, 1.0, 2.0, 0.3677192594262543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 468535.1334868283, 468535.1334868283, 124349.5147853625], 
processed observation next is [1.0, 0.13043478260869565, 0.35493827160493807, 0.6416666666666667, 1.0, 1.0, 0.2472848326503027, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16733397624529583, 0.16733397624529583, 0.23913368227954326], 
reward next is 0.7609, 
noisyNet noise sample is [array([-0.2133763], dtype=float32), -0.7007091]. 
=============================================
[2019-04-27 20:11:59,624] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.9659444e-21 1.0000000e+00 1.1871926e-25 2.0341048e-16 1.6458056e-15], sum to 1.0000
[2019-04-27 20:11:59,633] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1014
[2019-04-27 20:11:59,638] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 66.5, 1.0, 2.0, 0.3191929713570685, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 407242.8929824411, 407242.8929824415, 117979.6500708127], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1045800.0000, 
sim time next is 1046400.0000, 
raw observation next is [21.03333333333333, 67.0, 1.0, 2.0, 0.3055278783972733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 389829.385167547, 389829.3851675475, 116261.1198766306], 
processed observation next is [1.0, 0.08695652173913043, 0.3345679012345678, 0.67, 1.0, 1.0, 0.17324747428246823, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13922478041698105, 0.13922478041698125, 0.22357907668582808], 
reward next is 0.7764, 
noisyNet noise sample is [array([-1.049145], dtype=float32), -1.301074]. 
=============================================
[2019-04-27 20:12:03,754] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.1850477e-18 1.0000000e+00 4.2896252e-23 2.7324536e-14 3.2015417e-13], sum to 1.0000
[2019-04-27 20:12:03,763] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7277
[2019-04-27 20:12:03,767] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.36666666666667, 49.66666666666666, 1.0, 2.0, 0.3042910665982783, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 390191.9027488406, 390191.9027488406, 116107.7854659753], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 706800.0000, 
sim time next is 707400.0000, 
raw observation next is [23.2, 50.5, 1.0, 2.0, 0.2962978693749775, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 379998.5811926209, 379998.5811926213, 115119.5113859667], 
processed observation next is [1.0, 0.17391304347826086, 0.4148148148148148, 0.505, 1.0, 1.0, 0.16225936830354462, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13571377899736461, 0.13571377899736475, 0.22138367574224366], 
reward next is 0.7786, 
noisyNet noise sample is [array([0.54807574], dtype=float32), -0.7033024]. 
=============================================
[2019-04-27 20:12:12,355] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7461165e-26 1.0000000e+00 1.2765182e-31 1.4760727e-23 1.3021563e-25], sum to 1.0000
[2019-04-27 20:12:12,362] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3957
[2019-04-27 20:12:12,368] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.6, 36.66666666666666, 1.0, 2.0, 0.442769801324116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 538442.299008973, 538442.2990089725, 134538.1666025363], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 837600.0000, 
sim time next is 838200.0000, 
raw observation next is [31.5, 36.83333333333334, 1.0, 2.0, 0.4412180796836123, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 536902.7485832648, 536902.7485832648, 134319.3892850864], 
processed observation next is [0.0, 0.6956521739130435, 0.7222222222222222, 0.3683333333333334, 1.0, 1.0, 0.33478342819477663, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19175098163688029, 0.19175098163688029, 0.2583065178559354], 
reward next is 0.7417, 
noisyNet noise sample is [array([-0.44929034], dtype=float32), -0.062173948]. 
=============================================
[2019-04-27 20:12:12,823] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.62488724e-29 1.00000000e+00 2.51873657e-34 1.00286383e-25
 2.34617779e-29], sum to 1.0000
[2019-04-27 20:12:12,832] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6254
[2019-04-27 20:12:12,845] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.83333333333334, 55.0, 1.0, 2.0, 0.4007074542806749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 496280.7489411772, 496280.7489411772, 128714.1709372753], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 859200.0000, 
sim time next is 859800.0000, 
raw observation next is [25.66666666666666, 56.0, 1.0, 2.0, 0.4029223144603589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 498866.4382114506, 498866.4382114506, 129023.3136083342], 
processed observation next is [0.0, 0.9565217391304348, 0.5061728395061726, 0.56, 1.0, 1.0, 0.2891932315004273, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17816658507551808, 0.17816658507551808, 0.2481217569391042], 
reward next is 0.7519, 
noisyNet noise sample is [array([-0.43895105], dtype=float32), 0.42161253]. 
=============================================
[2019-04-27 20:12:18,685] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.9969655e-25 1.0000000e+00 5.9864429e-30 2.1390961e-23 1.1650605e-26], sum to 1.0000
[2019-04-27 20:12:18,691] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4874
[2019-04-27 20:12:18,696] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.3, 56.0, 1.0, 2.0, 0.2607860839245219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 336394.6542428664, 336394.6542428664, 108418.7880097483], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 957600.0000, 
sim time next is 958200.0000, 
raw observation next is [21.25, 56.33333333333334, 1.0, 2.0, 0.4523962606929762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 583651.6081105949, 583651.6081105944, 135763.0234870731], 
processed observation next is [1.0, 0.08695652173913043, 0.3425925925925926, 0.5633333333333335, 1.0, 1.0, 0.3480907865392574, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20844700289664103, 0.20844700289664087, 0.2610827374751406], 
reward next is 0.7389, 
noisyNet noise sample is [array([-1.4854695], dtype=float32), 0.2929737]. 
=============================================
[2019-04-27 20:12:20,565] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-04-27 20:12:20,566] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 20:12:20,567] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:12:20,567] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 20:12:20,569] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:12:20,570] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 20:12:20,572] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 20:12:20,574] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:12:20,575] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:12:20,573] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 20:12:20,578] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:12:20,598] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run53
[2019-04-27 20:12:20,618] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run53
[2019-04-27 20:12:20,640] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run53
[2019-04-27 20:12:20,660] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run53
[2019-04-27 20:12:20,681] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run53
[2019-04-27 20:12:33,610] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.10328463]
[2019-04-27 20:12:33,611] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.83333333333334, 26.83333333333333, 1.0, 2.0, 0.2584002962418674, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 333316.5046765258, 333316.5046765258, 84759.93474583347]
[2019-04-27 20:12:33,614] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 20:12:33,617] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.9535213e-27 1.0000000e+00 2.1411611e-31 2.5399198e-23 7.5783926e-26], sampled 0.2973214304442905
[2019-04-27 20:13:11,130] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.10328463]
[2019-04-27 20:13:11,132] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.15220055666667, 80.76136949666667, 1.0, 2.0, 1.009850704371121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.205355129840399, 6.9112, 121.9246100033525, 1301954.530368475, 1151322.582526115, 243108.9681143952]
[2019-04-27 20:13:11,133] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 20:13:11,136] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.2607475e-24 1.0000000e+00 1.8903422e-28 1.8870790e-20 7.1046595e-22], sampled 0.9206882404816888
[2019-04-27 20:13:11,138] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1301954.530368475 W.
[2019-04-27 20:13:26,541] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.10328463]
[2019-04-27 20:13:26,541] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.0, 94.0, 1.0, 2.0, 0.6028835249895087, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 695828.675862098, 695828.675862098, 158999.8210518725]
[2019-04-27 20:13:26,543] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 20:13:26,546] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.2898068e-25 1.0000000e+00 7.0369824e-30 5.2930441e-22 2.8148245e-24], sampled 0.5546430351172886
[2019-04-27 20:13:26,722] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.10328463]
[2019-04-27 20:13:26,724] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.0, 94.0, 1.0, 2.0, 0.5813727973226286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 671029.0586543378, 671029.0586543378, 155314.2755237757]
[2019-04-27 20:13:26,724] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 20:13:26,727] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.0507445e-25 1.0000000e+00 2.0214364e-29 8.6987028e-22 4.2112302e-24], sampled 0.7134770926854138
[2019-04-27 20:13:30,089] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.10328463]
[2019-04-27 20:13:30,092] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.07244703, 97.29238338, 1.0, 2.0, 0.5852023150627238, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426022679, 668504.0129576365, 668504.012957637, 155631.1102221678]
[2019-04-27 20:13:30,097] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 20:13:30,100] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.1232177e-24 1.0000000e+00 1.6263414e-28 7.7546664e-21 1.0569242e-22], sampled 0.7113726384042076
[2019-04-27 20:13:32,637] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.10328463]
[2019-04-27 20:13:32,638] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.13372618333333, 80.15584676666667, 1.0, 2.0, 0.683272599590274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 778727.7886366702, 778727.7886366697, 173000.267447955]
[2019-04-27 20:13:32,639] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 20:13:32,643] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.5312219e-25 1.0000000e+00 8.7529243e-30 5.5597735e-22 2.7361633e-24], sampled 0.9095190777322367
[2019-04-27 20:13:45,288] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.10328463]
[2019-04-27 20:13:45,292] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.87017970666667, 62.49472102666667, 1.0, 2.0, 0.4040376839709419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 498394.2165934388, 498394.2165934388, 129137.5287819908]
[2019-04-27 20:13:45,294] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 20:13:45,297] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.7887857e-26 1.0000000e+00 1.2193042e-30 1.0645718e-22 4.0863828e-25], sampled 0.0461629714749755
[2019-04-27 20:13:49,418] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.10328463]
[2019-04-27 20:13:49,423] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.73333333333333, 85.66666666666667, 1.0, 2.0, 0.5089168883296524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 603644.1389270577, 603644.1389270582, 144176.4214287817]
[2019-04-27 20:13:49,424] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 20:13:49,426] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.7005793e-26 1.0000000e+00 2.3055507e-30 1.8678758e-22 6.9015247e-25], sampled 0.9757519266595341
[2019-04-27 20:13:50,830] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.10328463]
[2019-04-27 20:13:50,831] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.2, 88.0, 1.0, 2.0, 0.5719195019028335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 668167.78254154, 668167.78254154, 154082.4114464166]
[2019-04-27 20:13:50,832] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 20:13:50,834] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.2684529e-26 1.0000000e+00 1.5473775e-30 1.2121486e-22 4.1365711e-25], sampled 0.8387248695659587
[2019-04-27 20:14:10,701] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8579.6129 2249005755.1099 553.0000
[2019-04-27 20:14:10,827] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8921.5789 2120867964.8883 431.0000
[2019-04-27 20:14:10,992] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8766.9960 2170944100.2627 493.0000
[2019-04-27 20:14:11,083] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8697.7347 2195397667.8018 572.0000
[2019-04-27 20:14:11,138] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8095.3398 2445740619.5097 746.0000
[2019-04-27 20:14:12,154] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1300000, evaluation results [1300000.0, 8095.339826117275, 2445740619.509737, 746.0, 8766.996003344108, 2170944100.262687, 493.0, 8921.578906979368, 2120867964.888314, 431.0, 8579.612851107222, 2249005755.1098666, 553.0, 8697.734692056189, 2195397667.8018346, 572.0]
[2019-04-27 20:14:19,483] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.5866231e-22 1.0000000e+00 2.3388070e-28 1.6228932e-16 8.4101305e-14], sum to 1.0000
[2019-04-27 20:14:19,492] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8891
[2019-04-27 20:14:19,495] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.03333333333333, 74.66666666666667, 1.0, 2.0, 0.2706610706418016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 348217.795530301, 348217.7955303015, 112021.7785363078], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1132800.0000, 
sim time next is 1133400.0000, 
raw observation next is [19.01666666666667, 74.83333333333333, 1.0, 2.0, 0.2705788677731082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 348099.7508344298, 348099.7508344298, 112012.1417184347], 
processed observation next is [1.0, 0.08695652173913043, 0.25987654320987663, 0.7483333333333333, 1.0, 1.0, 0.13164150925370022, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.12432133958372493, 0.12432133958372493, 0.21540796484314365], 
reward next is 0.7846, 
noisyNet noise sample is [array([1.7442663], dtype=float32), -0.1548718]. 
=============================================
[2019-04-27 20:14:29,778] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3028721e-17 1.0000000e+00 5.1095892e-22 1.1695695e-14 6.3136464e-13], sum to 1.0000
[2019-04-27 20:14:29,783] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3735
[2019-04-27 20:14:29,788] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.2, 43.0, 1.0, 2.0, 0.7650375356558748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 958505.8289226338, 958505.8289226328, 192119.6428165595], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1335600.0000, 
sim time next is 1336200.0000, 
raw observation next is [27.4, 42.5, 1.0, 2.0, 0.8932223794918553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.029694493772965, 6.9112, 121.9256216851274, 1179407.245156258, 1118727.682914218, 220001.1774125703], 
processed observation next is [1.0, 0.4782608695652174, 0.5703703703703703, 0.425, 1.0, 1.0, 0.8728837851093516, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.011849449377296484, 0.0, 0.8094593342791244, 0.42121687327009216, 0.3995456010407921, 0.423079187331866], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.41046104], dtype=float32), 2.0443678]. 
=============================================
[2019-04-27 20:14:30,311] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.9388969e-27 1.0000000e+00 4.6392891e-30 7.9679842e-23 2.0822373e-25], sum to 1.0000
[2019-04-27 20:14:30,320] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0443
[2019-04-27 20:14:30,325] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.53333333333333, 79.33333333333334, 1.0, 2.0, 0.3835537446694909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 477326.7218873044, 477326.7218873044, 126370.9300946081], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1725600.0000, 
sim time next is 1726200.0000, 
raw observation next is [21.5, 79.5, 1.0, 2.0, 0.382104612412524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 475592.7306500347, 475592.7306500343, 126172.4384962286], 
processed observation next is [1.0, 1.0, 0.35185185185185186, 0.795, 1.0, 1.0, 0.26441025287205244, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16985454666072666, 0.16985454666072655, 0.2426393048004396], 
reward next is 0.7574, 
noisyNet noise sample is [array([-1.689303], dtype=float32), 1.4542363]. 
=============================================
[2019-04-27 20:14:30,595] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.2255367e-12 1.4162580e-04 4.4727376e-17 2.7008689e-06 9.9985564e-01], sum to 1.0000
[2019-04-27 20:14:30,602] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3107
[2019-04-27 20:14:30,611] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.2, 40.5, 1.0, 2.0, 0.3279528589039564, 1.0, 1.0, 0.3279528589039564, 1.0, 2.0, 0.5348653977489729, 6.911199999999999, 6.9112, 121.94756008, 1198464.910762577, 1198464.910762577, 265845.7791126035], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1338600.0000, 
sim time next is 1339200.0000, 
raw observation next is [28.4, 40.0, 1.0, 2.0, 0.3318712721998904, 1.0, 2.0, 0.3318712721998904, 1.0, 2.0, 0.5396336257542306, 6.911199999999999, 6.9112, 121.94756008, 1208058.821955227, 1208058.821955227, 267589.063135843], 
processed observation next is [1.0, 0.5217391304347826, 0.6074074074074074, 0.4, 1.0, 1.0, 0.20460865738082187, 1.0, 1.0, 0.20460865738082187, 1.0, 1.0, 0.4245420321927882, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.43144957926972394, 0.43144957926972394, 0.5145943521843135], 
reward next is 0.4854, 
noisyNet noise sample is [array([0.05142616], dtype=float32), 1.8992532]. 
=============================================
[2019-04-27 20:14:33,021] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.3714727e-28 1.0000000e+00 8.9744710e-33 1.0979916e-23 6.1784584e-28], sum to 1.0000
[2019-04-27 20:14:33,026] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6487
[2019-04-27 20:14:33,030] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.7, 63.0, 1.0, 2.0, 0.2764673211313113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 355623.7935002372, 355623.7935002368, 112712.1638729917], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1396800.0000, 
sim time next is 1397400.0000, 
raw observation next is [20.66666666666667, 62.5, 1.0, 2.0, 0.2734326294460934, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 352006.4417327219, 352006.4417327219, 112348.6290890305], 
processed observation next is [0.0, 0.17391304347826086, 0.3209876543209878, 0.625, 1.0, 1.0, 0.13503884457868265, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.12571658633311497, 0.12571658633311497, 0.21605505594044325], 
reward next is 0.7839, 
noisyNet noise sample is [array([0.34861848], dtype=float32), -0.45204338]. 
=============================================
[2019-04-27 20:14:33,049] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.2894417e-30 1.0000000e+00 4.3382104e-35 2.8109693e-26 8.6990086e-28], sum to 1.0000
[2019-04-27 20:14:33,055] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0992
[2019-04-27 20:14:33,060] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.55, 26.5, 1.0, 2.0, 0.364471563955482, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 458767.6832045785, 458767.6832045785, 123857.7040088144], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1423800.0000, 
sim time next is 1424400.0000, 
raw observation next is [31.7, 26.33333333333334, 1.0, 2.0, 0.3663490734150568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 460774.7643392621, 460774.7643392621, 124106.3328404302], 
processed observation next is [0.0, 0.4782608695652174, 0.7296296296296296, 0.2633333333333334, 1.0, 1.0, 0.24565365882744858, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16456241583545075, 0.16456241583545075, 0.238666024693135], 
reward next is 0.7613, 
noisyNet noise sample is [array([0.19794421], dtype=float32), 1.1456465]. 
=============================================
[2019-04-27 20:14:41,636] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.7539724e-27 1.0000000e+00 4.3057728e-31 3.8936559e-22 2.1371457e-24], sum to 1.0000
[2019-04-27 20:14:41,643] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8324
[2019-04-27 20:14:41,649] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.6, 74.16666666666667, 1.0, 2.0, 0.4570737071116124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 558087.0356500836, 558087.0356500836, 136737.2689291612], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1545000.0000, 
sim time next is 1545600.0000, 
raw observation next is [23.6, 73.33333333333334, 1.0, 2.0, 0.4516590420500184, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 552490.8291008892, 552490.8291008887, 135953.4825038609], 
processed observation next is [0.0, 0.9130434782608695, 0.4296296296296297, 0.7333333333333334, 1.0, 1.0, 0.3472131452976409, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19731815325031757, 0.1973181532503174, 0.2614490048151171], 
reward next is 0.7386, 
noisyNet noise sample is [array([-0.10002878], dtype=float32), -1.9755567]. 
=============================================
[2019-04-27 20:14:45,290] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.1639279e-21 1.0000000e+00 1.0807770e-27 1.9819420e-17 3.0565916e-18], sum to 1.0000
[2019-04-27 20:14:45,297] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6881
[2019-04-27 20:14:45,307] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1367087.542140131 W.
[2019-04-27 20:14:45,310] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.46666666666667, 43.16666666666667, 1.0, 2.0, 0.5596945942756086, 1.0, 2.0, 0.5596945942756086, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1367087.542140131, 1367087.542140131, 258145.0236023295], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1608600.0000, 
sim time next is 1609200.0000, 
raw observation next is [27.5, 43.0, 1.0, 2.0, 0.5197911170245229, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8552183429119177, 6.911199999999999, 6.9112, 121.9260426156618, 1278824.489719525, 1278824.489719525, 260479.9762732235], 
processed observation next is [1.0, 0.6521739130434783, 0.5740740740740741, 0.43, 1.0, 1.0, 0.4283227583625272, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.819022928639897, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4567230320426875, 0.4567230320426875, 0.5009230312946605], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5224185], dtype=float32), -0.69142914]. 
=============================================
[2019-04-27 20:14:53,193] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3203404e-22 1.0000000e+00 4.7524515e-26 3.2290815e-18 3.7280361e-19], sum to 1.0000
[2019-04-27 20:14:53,201] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3314
[2019-04-27 20:14:53,209] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.46666666666667, 85.66666666666667, 1.0, 2.0, 0.3715282961535162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 463939.209516266, 463939.2095162655, 124754.1191922609], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1748400.0000, 
sim time next is 1749000.0000, 
raw observation next is [20.63333333333334, 84.83333333333333, 1.0, 2.0, 0.371970745970261, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 464125.969806471, 464125.969806471, 124807.4691155658], 
processed observation next is [1.0, 0.21739130434782608, 0.3197530864197533, 0.8483333333333333, 1.0, 1.0, 0.25234612615507257, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16575927493088252, 0.16575927493088252, 0.24001436368378037], 
reward next is 0.7600, 
noisyNet noise sample is [array([1.7713413], dtype=float32), 0.95859617]. 
=============================================
[2019-04-27 20:14:53,227] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[69.68968 ]
 [69.75174 ]
 [69.84529 ]
 [69.883125]
 [69.91905 ]], R is [[69.72677612]
 [69.78959656]
 [69.85118103]
 [69.91285706]
 [69.96889496]].
[2019-04-27 20:14:57,555] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.8724088e-21 1.0000000e+00 6.0492165e-26 1.0863456e-18 3.6897549e-17], sum to 1.0000
[2019-04-27 20:14:57,565] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4437
[2019-04-27 20:14:57,575] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1329675.199401838 W.
[2019-04-27 20:14:57,581] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.13333333333333, 89.0, 1.0, 2.0, 0.3887556216154244, 1.0, 2.0, 0.3887556216154244, 1.0, 1.0, 0.6189116104984492, 6.9112, 6.9112, 121.94756008, 1329675.199401838, 1329675.199401838, 292191.5137945941], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2216400.0000, 
sim time next is 2217000.0000, 
raw observation next is [24.91666666666666, 90.0, 1.0, 2.0, 0.5520281393526921, 1.0, 2.0, 0.5520281393526921, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1258690.062861829, 1258690.062861829, 251941.4725829582], 
processed observation next is [1.0, 0.6521739130434783, 0.47839506172839485, 0.9, 1.0, 1.0, 0.46670016589606206, 1.0, 1.0, 0.46670016589606206, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.4495321653077961, 0.4495321653077961, 0.48450283189030424], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.56297576], dtype=float32), -0.10426891]. 
=============================================
[2019-04-27 20:14:57,595] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[71.83506]
 [70.74671]
 [71.11092]
 [71.15397]
 [70.31102]], R is [[72.20625305]
 [71.48419189]
 [70.76934814]
 [70.4311142 ]
 [69.72680664]].
[2019-04-27 20:15:02,899] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-27 20:15:02,900] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 20:15:02,901] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:15:02,901] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 20:15:02,902] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 20:15:02,903] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 20:15:02,903] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:15:02,906] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:15:02,907] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 20:15:02,904] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:15:02,908] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:15:02,926] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run54
[2019-04-27 20:15:02,948] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run54
[2019-04-27 20:15:02,970] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run54
[2019-04-27 20:15:02,970] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run54
[2019-04-27 20:15:03,006] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run54
[2019-04-27 20:15:05,804] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.10441457]
[2019-04-27 20:15:05,808] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [30.5, 46.0, 1.0, 2.0, 0.6045526758737967, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9669658583988133, 6.9112, 6.9112, 121.9260426156618, 1419178.773913367, 1419178.773913367, 294846.5174456257]
[2019-04-27 20:15:05,809] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 20:15:05,811] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.2142200e-20 1.0000000e+00 3.9657702e-24 2.0783097e-17 1.6033978e-17], sampled 0.5946669149930887
[2019-04-27 20:15:05,813] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1419178.773913367 W.
[2019-04-27 20:15:40,193] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.10441457]
[2019-04-27 20:15:40,194] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.89275669, 47.69925065, 1.0, 2.0, 0.4601605778102074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 558540.511747409, 558540.511747409, 137104.0319975022]
[2019-04-27 20:15:40,196] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 20:15:40,200] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.6749884e-23 1.0000000e+00 3.3360446e-27 1.4635667e-19 2.8545583e-20], sampled 0.9084241863616561
[2019-04-27 20:16:16,856] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.10441457]
[2019-04-27 20:16:16,858] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.16666666666667, 57.5, 1.0, 2.0, 0.5087227058587347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 605174.1971338062, 605174.1971338062, 144212.9062976394]
[2019-04-27 20:16:16,859] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 20:16:16,862] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.7893752e-23 1.0000000e+00 1.7470484e-27 6.5329775e-20 7.9482598e-21], sampled 0.20989720571829595
[2019-04-27 20:16:28,023] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.10441457]
[2019-04-27 20:16:28,024] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.33333333333334, 89.66666666666667, 1.0, 2.0, 0.4549608007526503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 547951.1574103424, 547951.1574103424, 136184.0391771274]
[2019-04-27 20:16:28,024] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 20:16:28,027] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.4377034e-22 1.0000000e+00 2.3849017e-26 4.0966340e-19 5.6008205e-20], sampled 0.44661341587996894
[2019-04-27 20:16:45,085] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.10441457]
[2019-04-27 20:16:45,086] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.69496394, 79.86251114666668, 1.0, 2.0, 0.6385586824736453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 788734.4348082348, 788734.4348082348, 167224.4715555293]
[2019-04-27 20:16:45,087] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 20:16:45,089] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.8201861e-21 1.0000000e+00 1.8994023e-25 3.5889961e-18 1.2125951e-18], sampled 0.25169098906299125
[2019-04-27 20:16:47,247] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.10441457]
[2019-04-27 20:16:47,249] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.67653655333334, 95.92669128, 1.0, 2.0, 0.8072788822631195, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260420768318, 966565.984837313, 966565.984837313, 199629.3282909133]
[2019-04-27 20:16:47,251] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 20:16:47,257] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.5877807e-21 1.0000000e+00 7.7521075e-25 1.5373678e-17 8.5704613e-18], sampled 0.449146122644869
[2019-04-27 20:16:52,689] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8578.8209 2249060063.6286 554.0000
[2019-04-27 20:16:52,899] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8766.1737 2171010435.9928 493.0000
[2019-04-27 20:16:52,959] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8920.7572 2120923906.7993 431.0000
[2019-04-27 20:16:53,097] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8095.3398 2445740619.5097 746.0000
[2019-04-27 20:16:53,333] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8696.9130 2195453609.7127 572.0000
[2019-04-27 20:16:54,353] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1325000, evaluation results [1325000.0, 8095.339826117275, 2445740619.509737, 746.0, 8766.173736521037, 2171010435.992792, 493.0, 8920.757247613194, 2120923906.7993433, 431.0, 8578.820883205217, 2249060063.628618, 554.0, 8696.913032687911, 2195453609.7126694, 572.0]
[2019-04-27 20:16:55,050] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.2214279e-21 1.0000000e+00 1.6277661e-24 1.8314940e-17 3.7033889e-18], sum to 1.0000
[2019-04-27 20:16:55,057] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6627
[2019-04-27 20:16:55,063] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.3, 79.0, 1.0, 2.0, 0.6009595846768367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 690875.0926271727, 690875.0926271722, 158536.9781254607], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1972800.0000, 
sim time next is 1973400.0000, 
raw observation next is [25.93333333333333, 79.66666666666667, 1.0, 2.0, 0.5937440233652128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 685134.4781145791, 685134.4781145786, 157416.3595173758], 
processed observation next is [1.0, 0.8695652173913043, 0.5160493827160493, 0.7966666666666667, 1.0, 1.0, 0.5163619325776343, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2446908850409211, 0.24469088504092093, 0.30272376830264575], 
reward next is 0.6973, 
noisyNet noise sample is [array([0.20014478], dtype=float32), -0.2790386]. 
=============================================
[2019-04-27 20:16:55,459] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0900012e-14 9.9994326e-01 7.8367851e-19 3.0112568e-09 5.6779118e-05], sum to 1.0000
[2019-04-27 20:16:55,466] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6575
[2019-04-27 20:16:55,471] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1468665.245128548 W.
[2019-04-27 20:16:55,475] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.3, 60.0, 1.0, 2.0, 0.4293530644489773, 1.0, 1.0, 0.4293530644489773, 1.0, 2.0, 0.6835440616558731, 6.9112, 6.9112, 121.94756008, 1468665.245128548, 1468665.245128548, 310179.0192993088], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1958400.0000, 
sim time next is 1959000.0000, 
raw observation next is [28.4, 59.66666666666666, 1.0, 2.0, 0.412014754578589, 1.0, 2.0, 0.412014754578589, 1.0, 2.0, 0.6559409076728843, 6.911199999999999, 6.9112, 121.94756008, 1409302.448556897, 1409302.448556897, 302385.2545873619], 
processed observation next is [1.0, 0.6956521739130435, 0.6074074074074074, 0.5966666666666666, 1.0, 1.0, 0.30001756497451076, 1.0, 1.0, 0.30001756497451076, 1.0, 1.0, 0.5699261345911053, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5033223030560346, 0.5033223030560346, 0.5815101049756959], 
reward next is 0.4185, 
noisyNet noise sample is [array([1.3724133], dtype=float32), -1.2893131]. 
=============================================
[2019-04-27 20:16:55,494] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[62.497036]
 [62.052925]
 [62.002716]
 [61.7833  ]
 [61.494675]], R is [[63.08262634]
 [62.4518013 ]
 [61.82728577]
 [61.64454269]
 [61.02809906]].
[2019-04-27 20:16:56,107] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.9612039e-16 9.9983394e-01 2.5397219e-22 1.2884561e-11 1.6604004e-04], sum to 1.0000
[2019-04-27 20:16:56,108] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6523
[2019-04-27 20:16:56,114] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.2, 71.0, 1.0, 2.0, 0.5751125623683563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 666285.0123415362, 666285.0123415362, 154371.1167939289], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1969200.0000, 
sim time next is 1969800.0000, 
raw observation next is [27.05, 72.33333333333334, 1.0, 2.0, 0.5793241548252159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 670326.4210376343, 670326.4210376343, 155044.5699259704], 
processed observation next is [1.0, 0.8260869565217391, 0.5574074074074075, 0.7233333333333334, 1.0, 1.0, 0.4991954224109713, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23940229322772652, 0.23940229322772652, 0.29816263447302], 
reward next is 0.7018, 
noisyNet noise sample is [array([0.6144033], dtype=float32), -1.1541022]. 
=============================================
[2019-04-27 20:16:59,921] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.1726287e-24 1.0000000e+00 8.1448594e-27 5.9846526e-18 3.2810476e-17], sum to 1.0000
[2019-04-27 20:16:59,929] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7933
[2019-04-27 20:16:59,937] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.93333333333333, 65.33333333333333, 1.0, 2.0, 0.507921730890875, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 602321.1526738508, 602321.1526738512, 144013.5054007561], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2032800.0000, 
sim time next is 2033400.0000, 
raw observation next is [27.06666666666667, 65.16666666666667, 1.0, 2.0, 0.513096341967438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 607365.7298621207, 607365.7298621207, 144791.9870123268], 
processed observation next is [0.0, 0.5217391304347826, 0.5580246913580248, 0.6516666666666667, 1.0, 1.0, 0.4203527880564738, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21691633209361452, 0.21691633209361452, 0.27844612886985926], 
reward next is 0.7216, 
noisyNet noise sample is [array([1.143759], dtype=float32), -1.233537]. 
=============================================
[2019-04-27 20:17:00,129] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1027817e-22 1.0000000e+00 1.7835796e-27 1.4428845e-18 3.8946779e-16], sum to 1.0000
[2019-04-27 20:17:00,138] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8065
[2019-04-27 20:17:00,144] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.1, 63.0, 1.0, 2.0, 0.5970369466381196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 685399.5665739963, 685399.5665739963, 157814.4757968906], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2048400.0000, 
sim time next is 2049000.0000, 
raw observation next is [28.98333333333333, 63.66666666666666, 1.0, 2.0, 0.5984023003910804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 686681.698757802, 686681.698757802, 158035.5022592088], 
processed observation next is [0.0, 0.7391304347826086, 0.6290123456790122, 0.6366666666666666, 1.0, 1.0, 0.521907500465572, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24524346384207216, 0.24524346384207216, 0.3039144274215554], 
reward next is 0.6961, 
noisyNet noise sample is [array([2.0619333], dtype=float32), 1.3653846]. 
=============================================
[2019-04-27 20:17:00,158] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[78.11829 ]
 [78.03005 ]
 [78.00961 ]
 [77.99656 ]
 [77.986305]], R is [[78.06912994]
 [77.9849472 ]
 [77.90227509]
 [77.82090759]
 [77.7407608 ]].
[2019-04-27 20:17:06,534] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.6911923e-19 1.0000000e+00 7.3923808e-23 1.3627043e-15 1.3050697e-11], sum to 1.0000
[2019-04-27 20:17:06,544] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6409
[2019-04-27 20:17:06,550] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 89.5, 1.0, 2.0, 0.631922896713976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 738260.18922484, 738260.1892248405, 164514.2410584066], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2172600.0000, 
sim time next is 2173200.0000, 
raw observation next is [23.96666666666667, 89.66666666666667, 1.0, 2.0, 0.6240771214773022, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 729262.8886767506, 729262.8886767506, 163121.8741699757], 
processed observation next is [1.0, 0.13043478260869565, 0.4432098765432099, 0.8966666666666667, 1.0, 1.0, 0.552472763663455, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26045103167026806, 0.26045103167026806, 0.31369591186533785], 
reward next is 0.6863, 
noisyNet noise sample is [array([1.2950001], dtype=float32), -0.46455446]. 
=============================================
[2019-04-27 20:17:09,412] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.8535974e-22 1.0000000e+00 6.6715932e-28 6.3549160e-21 1.2418353e-16], sum to 1.0000
[2019-04-27 20:17:09,420] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3628
[2019-04-27 20:17:09,427] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.3, 95.5, 1.0, 2.0, 0.5532757494887125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 645303.8219801858, 645303.8219801858, 150921.9487670142], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2223000.0000, 
sim time next is 2223600.0000, 
raw observation next is [23.26666666666667, 95.33333333333333, 1.0, 2.0, 0.5528926581869309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 645632.2590537091, 645632.2590537091, 150892.4523301709], 
processed observation next is [1.0, 0.7391304347826086, 0.41728395061728407, 0.9533333333333333, 1.0, 1.0, 0.4677293549844415, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23058294966203896, 0.23058294966203896, 0.29017779294263635], 
reward next is 0.7098, 
noisyNet noise sample is [array([-0.34312084], dtype=float32), -1.2204328]. 
=============================================
[2019-04-27 20:17:10,752] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.4015128e-24 1.0000000e+00 1.2955737e-29 3.8401108e-22 1.4418824e-19], sum to 1.0000
[2019-04-27 20:17:10,756] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5121
[2019-04-27 20:17:10,760] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.2, 93.0, 1.0, 2.0, 0.4531381547051699, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 552208.2167029846, 552208.2167029846, 136115.0461109673], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2620800.0000, 
sim time next is 2621400.0000, 
raw observation next is [21.33333333333334, 93.16666666666667, 1.0, 2.0, 0.4553810021224509, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 554212.8298835364, 554212.8298835364, 136430.1151699364], 
processed observation next is [0.0, 0.34782608695652173, 0.3456790123456792, 0.9316666666666668, 1.0, 1.0, 0.3516440501457749, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19793315352983445, 0.19793315352983445, 0.26236560609603155], 
reward next is 0.7376, 
noisyNet noise sample is [array([-0.8712649], dtype=float32), 0.07504635]. 
=============================================
[2019-04-27 20:17:14,272] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.4210102e-20 1.0000000e+00 2.5426062e-22 1.8660798e-16 3.1388878e-13], sum to 1.0000
[2019-04-27 20:17:14,278] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1991
[2019-04-27 20:17:14,282] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 96.0, 1.0, 2.0, 0.4835032768577763, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 581315.4868908126, 581315.4868908126, 140492.0714795557], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2348400.0000, 
sim time next is 2349000.0000, 
raw observation next is [21.65, 96.0, 1.0, 2.0, 0.478593651284369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 575630.0528226176, 575630.0528226176, 139742.716554148], 
processed observation next is [1.0, 0.17391304347826086, 0.35740740740740734, 0.96, 1.0, 1.0, 0.3792781562909155, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20558216172236343, 0.20558216172236343, 0.26873599337336157], 
reward next is 0.7313, 
noisyNet noise sample is [array([-0.95033425], dtype=float32), 0.58258426]. 
=============================================
[2019-04-27 20:17:14,310] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[63.20373 ]
 [63.044727]
 [63.30158 ]
 [63.39278 ]
 [63.59008 ]], R is [[63.37172318]
 [63.46783066]
 [63.53843689]
 [63.63107681]
 [63.71868134]].
[2019-04-27 20:17:28,493] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.5624196e-24 1.0000000e+00 8.6798774e-29 4.4718366e-22 4.8556350e-21], sum to 1.0000
[2019-04-27 20:17:28,500] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0481
[2019-04-27 20:17:28,504] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.36666666666667, 93.0, 1.0, 2.0, 0.4575328598129764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 556288.0730518443, 556288.0730518443, 136736.9729126286], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2601600.0000, 
sim time next is 2602200.0000, 
raw observation next is [21.28333333333333, 93.5, 1.0, 2.0, 0.4562850471510073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 554976.0192901058, 554976.0192901058, 136555.5620334239], 
processed observation next is [0.0, 0.08695652173913043, 0.3438271604938271, 0.935, 1.0, 1.0, 0.3527202942273897, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1982057211750378, 0.1982057211750378, 0.2626068500642767], 
reward next is 0.7374, 
noisyNet noise sample is [array([1.3870438], dtype=float32), -1.4701177]. 
=============================================
[2019-04-27 20:17:30,350] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.4247115e-23 1.0000000e+00 6.7105943e-28 8.3049842e-22 4.9706317e-21], sum to 1.0000
[2019-04-27 20:17:30,357] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5449
[2019-04-27 20:17:30,362] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.41666666666667, 100.0, 1.0, 2.0, 0.4483157343167489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 546591.8740527994, 546591.8740527994, 135402.7871810676], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2614200.0000, 
sim time next is 2614800.0000, 
raw observation next is [20.53333333333333, 100.0, 1.0, 2.0, 0.4523581385789059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 550479.5263111467, 550479.5263111467, 135975.4928335256], 
processed observation next is [0.0, 0.2608695652173913, 0.3160493827160493, 1.0, 1.0, 1.0, 0.3480454030701261, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19659983082540952, 0.19659983082540952, 0.26149133237216465], 
reward next is 0.7385, 
noisyNet noise sample is [array([-0.26921844], dtype=float32), -1.4152577]. 
=============================================
[2019-04-27 20:17:31,843] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.9825974e-27 1.0000000e+00 3.8565664e-30 1.6425124e-23 5.8855031e-21], sum to 1.0000
[2019-04-27 20:17:31,850] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4952
[2019-04-27 20:17:31,854] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.85, 78.66666666666667, 1.0, 2.0, 0.5850620400428178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 679150.2033617734, 679150.2033617734, 156118.8482566037], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2661000.0000, 
sim time next is 2661600.0000, 
raw observation next is [25.7, 79.33333333333334, 1.0, 2.0, 0.5823288604521352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 676645.0392815848, 676645.0392815848, 155683.5998139509], 
processed observation next is [0.0, 0.8260869565217391, 0.5074074074074074, 0.7933333333333334, 1.0, 1.0, 0.5027724529192085, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.241658942600566, 0.241658942600566, 0.2993915381037517], 
reward next is 0.7006, 
noisyNet noise sample is [array([0.9350278], dtype=float32), 0.24749734]. 
=============================================
[2019-04-27 20:17:33,612] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.9146263e-24 1.0000000e+00 3.4552440e-26 3.0994212e-20 4.1730826e-20], sum to 1.0000
[2019-04-27 20:17:33,619] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8767
[2019-04-27 20:17:33,623] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 78.0, 1.0, 2.0, 0.588037537444193, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 681882.8798644984, 681882.8798644984, 156594.1470340539], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2660400.0000, 
sim time next is 2661000.0000, 
raw observation next is [25.85, 78.66666666666667, 1.0, 2.0, 0.5850620400428178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 679150.2033617734, 679150.2033617734, 156118.8482566037], 
processed observation next is [0.0, 0.8260869565217391, 0.5129629629629631, 0.7866666666666667, 1.0, 1.0, 0.5060262381462116, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2425536440577762, 0.2425536440577762, 0.3002285543396225], 
reward next is 0.6998, 
noisyNet noise sample is [array([-0.16905344], dtype=float32), -0.28135347]. 
=============================================
[2019-04-27 20:17:33,647] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[69.4555 ]
 [69.32608]
 [69.28026]
 [69.24809]
 [69.22745]], R is [[69.5413208 ]
 [69.54476929]
 [69.54708862]
 [69.54813385]
 [69.54780579]].
[2019-04-27 20:17:38,453] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.1948400e-26 1.0000000e+00 7.9253306e-31 1.1799339e-23 1.6378190e-24], sum to 1.0000
[2019-04-27 20:17:38,459] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4562
[2019-04-27 20:17:38,467] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.41666666666666, 89.83333333333334, 1.0, 2.0, 0.66134077416968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 753719.7334922912, 753719.7334922912, 168952.7045336798], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2761800.0000, 
sim time next is 2762400.0000, 
raw observation next is [25.33333333333334, 90.66666666666667, 1.0, 2.0, 0.6649332718305613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 757816.0707735464, 757816.0707735464, 169609.8991987137], 
processed observation next is [0.0, 1.0, 0.49382716049382736, 0.9066666666666667, 1.0, 1.0, 0.6011110378935253, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.270648596704838, 0.270648596704838, 0.32617288307444947], 
reward next is 0.6738, 
noisyNet noise sample is [array([0.44172186], dtype=float32), 1.7865467]. 
=============================================
[2019-04-27 20:17:39,151] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.6238659e-22 1.0000000e+00 7.0891053e-26 4.7687172e-21 1.0546864e-19], sum to 1.0000
[2019-04-27 20:17:39,160] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3944
[2019-04-27 20:17:39,168] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2311120.143541944 W.
[2019-04-27 20:17:39,172] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.58333333333333, 90.66666666666667, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 9.110208193238014, 6.9112, 123.1371926948288, 2311120.143541944, 1173845.421903266, 246355.9383257642], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2772600.0000, 
sim time next is 2773200.0000, 
raw observation next is [24.46666666666667, 91.33333333333334, 1.0, 2.0, 0.4735006046330825, 1.0, 1.0, 0.4735006046330825, 1.0, 1.0, 0.7538283834139755, 6.911200000000004, 6.9112, 122.1972213892962, 1619829.379392999, 1619829.379392998, 330826.3496659268], 
processed observation next is [1.0, 0.08695652173913043, 0.46172839506172847, 0.9133333333333334, 1.0, 1.0, 0.3732150055155744, 1.0, 0.5, 0.3732150055155744, 1.0, 0.5, 0.6922854792674693, 3.552713678800501e-16, 0.0, 0.8112624738710196, 0.5785104926403568, 0.5785104926403565, 0.6362045185883208], 
reward next is 0.3638, 
noisyNet noise sample is [array([0.05046359], dtype=float32), 0.84425706]. 
=============================================
[2019-04-27 20:17:39,375] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.5168323e-21 1.0000000e+00 1.6045660e-25 5.4029606e-22 1.2986736e-18], sum to 1.0000
[2019-04-27 20:17:39,383] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2254
[2019-04-27 20:17:39,387] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.7, 90.0, 1.0, 2.0, 0.6167539011887405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 709238.7628128926, 709238.7628128926, 161295.8492861982], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2772000.0000, 
sim time next is 2772600.0000, 
raw observation next is [24.58333333333333, 90.66666666666667, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 9.110208193238014, 6.9112, 123.1371926948288, 2311120.143541944, 1173845.421903266, 246355.9383257642], 
processed observation next is [1.0, 0.08695652173913043, 0.46604938271604923, 0.9066666666666667, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.2199008193238014, 0.0, 0.8175029058384926, 0.8254000512649801, 0.419230507822595, 0.47376141985723885], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.13898106], dtype=float32), -0.98733646]. 
=============================================
[2019-04-27 20:17:45,147] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-27 20:17:45,149] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 20:17:45,149] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 20:17:45,149] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:17:45,151] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:17:45,150] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 20:17:45,152] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 20:17:45,154] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:17:45,154] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:17:45,154] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 20:17:45,157] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:17:45,178] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run55
[2019-04-27 20:17:45,201] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run55
[2019-04-27 20:17:45,202] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run55
[2019-04-27 20:17:45,245] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run55
[2019-04-27 20:17:45,246] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run55
[2019-04-27 20:18:05,582] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.105855554]
[2019-04-27 20:18:05,583] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.046193055, 57.181437235, 1.0, 2.0, 0.3264155089365353, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 414788.112687241, 414788.112687241, 118893.2164146112]
[2019-04-27 20:18:05,585] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 20:18:05,587] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.1505486e-27 1.0000000e+00 4.6264187e-32 7.4491272e-26 3.0388626e-25], sampled 0.8345968099233257
[2019-04-27 20:18:48,963] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.105855554]
[2019-04-27 20:18:48,965] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.0, 79.0, 1.0, 2.0, 0.3985680228811757, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 492717.5786374283, 492717.5786374283, 128391.5651761818]
[2019-04-27 20:18:48,967] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 20:18:48,970] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.6938572e-27 1.0000000e+00 3.7401333e-32 5.1397037e-26 1.5842034e-25], sampled 0.18833502316806539
[2019-04-27 20:19:06,511] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.105855554]
[2019-04-27 20:19:06,512] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.11606759333333, 98.16793074, 1.0, 2.0, 0.5733782981348737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 666859.5157466594, 666859.5157466594, 154195.6216165257]
[2019-04-27 20:19:06,513] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 20:19:06,515] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.9930532e-27 1.0000000e+00 5.8520905e-32 8.1449876e-26 2.6234933e-25], sampled 0.48641476099056424
[2019-04-27 20:19:30,381] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.105855554]
[2019-04-27 20:19:30,383] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.85, 49.33333333333334, 1.0, 2.0, 0.3272488036212228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 414171.2117786185, 414171.2117786185, 118986.0001816556]
[2019-04-27 20:19:30,384] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 20:19:30,387] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [8.9914951e-27 1.0000000e+00 7.3670952e-32 1.1804775e-25 4.6064473e-25], sampled 0.2881387148253075
[2019-04-27 20:19:30,602] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.105855554]
[2019-04-27 20:19:30,603] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.70074128333334, 82.67465431000001, 1.0, 2.0, 0.4320567669273886, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 526334.6648713775, 526334.6648713775, 132992.3785114755]
[2019-04-27 20:19:30,605] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 20:19:30,607] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.7392622e-26 1.0000000e+00 2.9562874e-31 3.0161342e-25 9.7960688e-25], sampled 0.750289781010511
[2019-04-27 20:19:34,967] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8920.2845 2120775997.4899 430.0000
[2019-04-27 20:19:35,187] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8096.1228 2445685030.0399 746.0000
[2019-04-27 20:19:35,325] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8697.7347 2195397667.8018 572.0000
[2019-04-27 20:19:35,437] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8766.9960 2170944100.2627 493.0000
[2019-04-27 20:19:35,490] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8580.4445 2248939950.6587 554.0000
[2019-04-27 20:19:36,508] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1350000, evaluation results [1350000.0, 8096.1228420842035, 2445685030.039925, 746.0, 8766.996003344108, 2170944100.262687, 493.0, 8920.284511795213, 2120775997.4898655, 430.0, 8580.444490253156, 2248939950.6587467, 554.0, 8697.734692056189, 2195397667.8018346, 572.0]
[2019-04-27 20:19:37,797] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.0508138e-10 1.9890286e-03 7.8694179e-14 1.0877632e-06 9.9800986e-01], sum to 1.0000
[2019-04-27 20:19:37,803] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6890
[2019-04-27 20:19:37,809] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.88333333333333, 88.16666666666667, 1.0, 2.0, 0.4179769526963651, 1.0, 2.0, 0.4179769526963651, 1.0, 2.0, 0.6654329212516203, 6.9112, 6.9112, 121.94756008, 1429715.266074246, 1429715.266074246, 305046.5562879349], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2893800.0000, 
sim time next is 2894400.0000, 
raw observation next is [25.0, 89.0, 1.0, 2.0, 0.409997140100225, 1.0, 2.0, 0.409997140100225, 1.0, 2.0, 0.6527287997142126, 6.911200000000001, 6.9112, 121.94756008, 1402394.851576849, 1402394.851576848, 301489.1250272031], 
processed observation next is [1.0, 0.5217391304347826, 0.48148148148148145, 0.89, 1.0, 1.0, 0.2976156429764583, 1.0, 1.0, 0.2976156429764583, 1.0, 1.0, 0.5659109996427657, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5008553041345889, 0.5008553041345886, 0.5797867788984675], 
reward next is 0.4202, 
noisyNet noise sample is [array([1.1198015], dtype=float32), -0.38642168]. 
=============================================
[2019-04-27 20:19:37,985] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.1836888e-14 6.1644008e-03 4.2125755e-19 1.2892284e-11 9.9383563e-01], sum to 1.0000
[2019-04-27 20:19:37,995] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1702
[2019-04-27 20:19:38,001] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.88333333333333, 88.16666666666667, 1.0, 2.0, 0.4179769526963651, 1.0, 2.0, 0.4179769526963651, 1.0, 2.0, 0.6654329212516203, 6.9112, 6.9112, 121.94756008, 1429715.266074246, 1429715.266074246, 305046.5562879349], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2893800.0000, 
sim time next is 2894400.0000, 
raw observation next is [25.0, 89.0, 1.0, 2.0, 0.409997140100225, 1.0, 2.0, 0.409997140100225, 1.0, 2.0, 0.6527287997142126, 6.911200000000001, 6.9112, 121.94756008, 1402394.851576849, 1402394.851576848, 301489.1250272031], 
processed observation next is [1.0, 0.5217391304347826, 0.48148148148148145, 0.89, 1.0, 1.0, 0.2976156429764583, 1.0, 1.0, 0.2976156429764583, 1.0, 1.0, 0.5659109996427657, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5008553041345889, 0.5008553041345886, 0.5797867788984675], 
reward next is 0.4202, 
noisyNet noise sample is [array([-1.1483105], dtype=float32), -0.6164848]. 
=============================================
[2019-04-27 20:19:38,674] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0230334e-18 9.9999988e-01 2.0130667e-26 9.6132056e-15 1.4629224e-07], sum to 1.0000
[2019-04-27 20:19:38,680] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7559
[2019-04-27 20:19:38,685] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.1, 91.0, 1.0, 2.0, 0.6456726082182056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 735854.3988570881, 735854.3988570881, 166112.4596339399], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2937600.0000, 
sim time next is 2938200.0000, 
raw observation next is [25.08333333333334, 91.50000000000001, 1.0, 2.0, 0.6465532949932038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 736858.574518105, 736858.574518105, 166271.1785003643], 
processed observation next is [1.0, 0.0, 0.4845679012345681, 0.9150000000000001, 1.0, 1.0, 0.5792301130871473, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26316377661360896, 0.26316377661360896, 0.31975226634685444], 
reward next is 0.6802, 
noisyNet noise sample is [array([-0.73219156], dtype=float32), 0.88553965]. 
=============================================
[2019-04-27 20:19:49,536] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4004639e-10 9.7362208e-01 4.4354165e-15 3.7121115e-08 2.6377957e-02], sum to 1.0000
[2019-04-27 20:19:49,548] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5307
[2019-04-27 20:19:49,558] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1720453.954530046 W.
[2019-04-27 20:19:49,562] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.5, 77.0, 1.0, 2.0, 0.5028854670230577, 1.0, 2.0, 0.5028854670230577, 1.0, 2.0, 0.8006100413369726, 6.911199999999999, 6.9112, 121.94756008, 1720453.954530046, 1720453.954530047, 345007.5190558801], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3495600.0000, 
sim time next is 3496200.0000, 
raw observation next is [27.75, 75.83333333333334, 1.0, 2.0, 0.7711907099911122, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1594059.11496348, 1594059.11496348, 330580.0165905078], 
processed observation next is [1.0, 0.4782608695652174, 0.5833333333333334, 0.7583333333333334, 1.0, 1.0, 0.7276079880846573, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5693068267726714, 0.5693068267726714, 0.635730801135592], 
reward next is 0.3643, 
noisyNet noise sample is [array([0.44995457], dtype=float32), -0.19729868]. 
=============================================
[2019-04-27 20:19:50,818] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.0673884e-11 9.9998248e-01 8.2992668e-14 7.5693934e-10 1.7518088e-05], sum to 1.0000
[2019-04-27 20:19:50,826] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2631
[2019-04-27 20:19:50,835] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1713014.024863429 W.
[2019-04-27 20:19:50,837] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.9, 32.0, 1.0, 2.0, 0.7230639087742736, 1.0, 1.0, 0.7230639087742736, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1713014.024863429, 1713014.024863429, 316021.2300039037], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3150000.0000, 
sim time next is 3150600.0000, 
raw observation next is [32.91666666666667, 33.0, 1.0, 2.0, 0.7967716622314948, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9659079902873272, 6.9112, 6.9112, 121.9260426156618, 1661993.206053929, 1661993.206053929, 329018.3805278348], 
processed observation next is [1.0, 0.4782608695652174, 0.7746913580246916, 0.33, 1.0, 1.0, 0.7580615026565414, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9573849878591589, 0.0, 0.0, 0.8094621288201359, 0.5935690021621175, 0.5935690021621175, 0.6327276548612208], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.28512713], dtype=float32), -1.1971234]. 
=============================================
[2019-04-27 20:19:54,553] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.4410761e-23 1.0000000e+00 1.9475379e-28 1.4026583e-19 9.5017599e-21], sum to 1.0000
[2019-04-27 20:19:54,560] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5774
[2019-04-27 20:19:54,564] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 78.83333333333333, 1.0, 2.0, 0.4789178140511588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 576868.1971106707, 576868.1971106703, 139821.3974757766], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3221400.0000, 
sim time next is 3222000.0000, 
raw observation next is [24.0, 78.0, 1.0, 2.0, 0.4809447250016743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 578867.6894265086, 578867.6894265086, 140118.6654689587], 
processed observation next is [0.0, 0.30434782608695654, 0.4444444444444444, 0.78, 1.0, 1.0, 0.38207705357342175, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20673846050946737, 0.20673846050946737, 0.2694589720556898], 
reward next is 0.7305, 
noisyNet noise sample is [array([-0.8699376], dtype=float32), 1.3409888]. 
=============================================
[2019-04-27 20:19:54,583] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[74.84537 ]
 [74.87802 ]
 [74.92094 ]
 [74.97133 ]
 [75.033226]], R is [[74.88567352]
 [74.86792755]
 [74.85092926]
 [74.83462524]
 [74.81902313]].
[2019-04-27 20:19:55,054] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.7119427e-23 1.0000000e+00 4.8891244e-30 6.9441392e-20 6.0373399e-20], sum to 1.0000
[2019-04-27 20:19:55,063] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1732
[2019-04-27 20:19:55,067] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 70.0, 1.0, 2.0, 0.6913815048501891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 787974.2821359491, 787974.2821359491, 174518.1785221496], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3340800.0000, 
sim time next is 3341400.0000, 
raw observation next is [28.96666666666667, 70.66666666666667, 1.0, 2.0, 0.6825351489039823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 777886.8874435677, 777886.8874435677, 172864.094026863], 
processed observation next is [0.0, 0.6956521739130435, 0.6283950617283951, 0.7066666666666667, 1.0, 1.0, 0.6220656534571217, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2778167455155599, 0.2778167455155599, 0.3324309500516596], 
reward next is 0.6676, 
noisyNet noise sample is [array([-0.6174633], dtype=float32), 0.53293973]. 
=============================================
[2019-04-27 20:19:56,031] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.9920505e-22 1.0000000e+00 2.5574636e-27 9.9558651e-20 2.7434641e-20], sum to 1.0000
[2019-04-27 20:19:56,039] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2400
[2019-04-27 20:19:56,043] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.86666666666667, 77.0, 1.0, 2.0, 0.5711014422579751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 666670.673487403, 666670.673487403, 153921.0769450775], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3270000.0000, 
sim time next is 3270600.0000, 
raw observation next is [25.9, 77.5, 1.0, 2.0, 0.5760072263651067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 670948.1348651316, 670948.1348651316, 154685.572800095], 
processed observation next is [0.0, 0.8695652173913043, 0.5148148148148147, 0.775, 1.0, 1.0, 0.4952466980536984, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23962433388040413, 0.23962433388040413, 0.29747225538479805], 
reward next is 0.7025, 
noisyNet noise sample is [array([-0.42552525], dtype=float32), -0.58465886]. 
=============================================
[2019-04-27 20:20:00,317] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.6733443e-21 1.0000000e+00 4.3472587e-26 6.2734143e-19 6.0932187e-19], sum to 1.0000
[2019-04-27 20:20:00,327] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0839
[2019-04-27 20:20:00,332] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.6, 85.0, 1.0, 2.0, 0.5686438024488849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 664642.7378919611, 664642.7378919611, 153544.1557159847], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3321600.0000, 
sim time next is 3322200.0000, 
raw observation next is [24.75, 84.0, 1.0, 2.0, 0.5692717103705198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 665245.8423711429, 665245.8423711425, 153644.0452866682], 
processed observation next is [0.0, 0.43478260869565216, 0.4722222222222222, 0.84, 1.0, 1.0, 0.4872282266315712, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23758780084683676, 0.2375878008468366, 0.2954693178589773], 
reward next is 0.7045, 
noisyNet noise sample is [array([-0.43237594], dtype=float32), -0.4921132]. 
=============================================
[2019-04-27 20:20:03,988] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.3946799e-16 4.1556314e-09 1.8562074e-20 4.9478133e-11 1.0000000e+00], sum to 1.0000
[2019-04-27 20:20:03,994] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9349
[2019-04-27 20:20:03,998] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.33333333333334, 85.66666666666666, 1.0, 2.0, 0.2628089927921424, 1.0, 1.0, 0.2628089927921424, 1.0, 1.0, 0.4184004756164447, 6.911200000000001, 6.9112, 121.94756008, 898642.7083611895, 898642.708361189, 242213.2097999569], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3397200.0000, 
sim time next is 3397800.0000, 
raw observation next is [25.56666666666667, 84.33333333333333, 1.0, 2.0, 0.2644666090519974, 1.0, 2.0, 0.2644666090519974, 1.0, 2.0, 0.4210394546869265, 6.9112, 6.9112, 121.94756008, 904314.064770582, 904314.064770582, 242813.6082210089], 
processed observation next is [1.0, 0.30434782608695654, 0.5024691358024692, 0.8433333333333333, 1.0, 1.0, 0.12436501077618742, 1.0, 1.0, 0.12436501077618742, 1.0, 1.0, 0.27629931835865806, 0.0, 0.0, 0.8096049824067558, 0.32296930884663644, 0.32296930884663644, 0.4669492465788633], 
reward next is 0.5331, 
noisyNet noise sample is [array([1.4860032], dtype=float32), 0.008782899]. 
=============================================
[2019-04-27 20:20:05,131] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.7003838e-17 3.0734475e-13 1.2811006e-21 2.2213803e-10 1.0000000e+00], sum to 1.0000
[2019-04-27 20:20:05,138] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3707
[2019-04-27 20:20:05,144] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.06666666666666, 69.0, 1.0, 2.0, 0.6102190136329809, 1.0, 2.0, 0.6102190136329809, 1.0, 2.0, 0.9714885431495422, 6.911200000000001, 6.9112, 121.94756008, 2088088.864947258, 2088088.864947257, 400971.5480867643], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3408000.0000, 
sim time next is 3408600.0000, 
raw observation next is [29.28333333333333, 68.0, 1.0, 2.0, 0.6185876678181864, 1.0, 2.0, 0.6185876678181864, 1.0, 2.0, 0.9848117131604286, 6.911199999999999, 6.9112, 121.94756008, 2116759.230843812, 2116759.230843812, 405596.0863460613], 
processed observation next is [1.0, 0.43478260869565216, 0.6401234567901234, 0.68, 1.0, 1.0, 0.5459376997835552, 1.0, 1.0, 0.5459376997835552, 1.0, 1.0, 0.9810146414505357, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7559854395870758, 0.7559854395870758, 0.7799924737424256], 
reward next is 0.2200, 
noisyNet noise sample is [array([1.5457413], dtype=float32), 1.7024103]. 
=============================================
[2019-04-27 20:20:05,921] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.0309436e-12 8.9534722e-02 3.2095862e-16 3.0311165e-05 9.1043490e-01], sum to 1.0000
[2019-04-27 20:20:05,932] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2356
[2019-04-27 20:20:05,937] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.73333333333333, 67.33333333333334, 1.0, 2.0, 0.5942954564069161, 1.0, 2.0, 0.5942954564069161, 1.0, 2.0, 0.9461377214515929, 6.9112, 6.9112, 121.94756008, 2033538.523618028, 2033538.523618028, 392276.2252718977], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3429600.0000, 
sim time next is 3430200.0000, 
raw observation next is [29.51666666666667, 68.16666666666666, 1.0, 2.0, 0.5873988450529535, 1.0, 2.0, 0.5873988450529535, 1.0, 2.0, 0.9351580915691334, 6.9112, 6.9112, 121.94756008, 2009913.3980417, 2009913.3980417, 388552.5919483357], 
processed observation next is [1.0, 0.6956521739130435, 0.6487654320987656, 0.6816666666666665, 1.0, 1.0, 0.5088081488725636, 1.0, 1.0, 0.5088081488725636, 1.0, 1.0, 0.9189476144614167, 0.0, 0.0, 0.8096049824067558, 0.7178262135863215, 0.7178262135863215, 0.7472165229775687], 
reward next is 0.2528, 
noisyNet noise sample is [array([0.58864534], dtype=float32), 0.33717534]. 
=============================================
[2019-04-27 20:20:07,056] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.5307001e-15 9.8223692e-01 2.9823412e-20 2.1441697e-07 1.7762780e-02], sum to 1.0000
[2019-04-27 20:20:07,069] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0800
[2019-04-27 20:20:07,073] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.75, 79.83333333333333, 1.0, 2.0, 0.6555448508083718, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 747110.9912192042, 747110.9912192037, 167896.8159830316], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3442200.0000, 
sim time next is 3442800.0000, 
raw observation next is [26.6, 81.66666666666667, 1.0, 2.0, 0.6612630163883826, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 753631.0706011817, 753631.0706011817, 168938.5527194393], 
processed observation next is [1.0, 0.8695652173913043, 0.5407407407407407, 0.8166666666666668, 1.0, 1.0, 0.5967416861766459, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2691539537861363, 0.2691539537861363, 0.3248818321527679], 
reward next is 0.6751, 
noisyNet noise sample is [array([-2.058507], dtype=float32), -0.95168245]. 
=============================================
[2019-04-27 20:20:08,835] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.8593367e-11 9.9871826e-01 2.8463712e-14 2.0523539e-06 1.2796979e-03], sum to 1.0000
[2019-04-27 20:20:08,845] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2303
[2019-04-27 20:20:08,852] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.16666666666667, 91.33333333333334, 1.0, 2.0, 0.8153659350571235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 929366.2277341749, 929366.2277341749, 199130.1482285752], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3482400.0000, 
sim time next is 3483000.0000, 
raw observation next is [25.25, 90.0, 1.0, 2.0, 0.8016126170749517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 913680.6463050997, 913680.6463050992, 196267.8996272738], 
processed observation next is [1.0, 0.30434782608695654, 0.49074074074074076, 0.9, 1.0, 1.0, 0.7638245441368472, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3263145165375356, 0.32631451653753546, 0.37743826851398804], 
reward next is 0.6226, 
noisyNet noise sample is [array([-1.5233612], dtype=float32), 0.22932819]. 
=============================================
[2019-04-27 20:20:08,865] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[48.833305]
 [48.91053 ]
 [49.39149 ]
 [49.42323 ]
 [49.632153]], R is [[48.90660858]
 [49.0345993 ]
 [49.12273026]
 [49.28692245]
 [49.4382782 ]].
[2019-04-27 20:20:11,681] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.8161652e-19 1.0000000e+00 1.5979829e-23 8.7143738e-12 3.9773351e-10], sum to 1.0000
[2019-04-27 20:20:11,686] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3634
[2019-04-27 20:20:11,692] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.6501654199926091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 740977.201290164, 740977.201290164, 166923.1140949055], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3523200.0000, 
sim time next is 3523800.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.649761678800732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 740516.8453362356, 740516.8453362351, 166850.1938043852], 
processed observation next is [1.0, 0.782608695652174, 0.5555555555555556, 0.79, 1.0, 1.0, 0.583049617619919, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2644703019057984, 0.26447030190579823, 0.3208657573161254], 
reward next is 0.6791, 
noisyNet noise sample is [array([1.2260442], dtype=float32), 0.65673804]. 
=============================================
[2019-04-27 20:20:13,351] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.10448746e-13 9.99999881e-01 1.71939496e-16 9.14361777e-08
 5.20232000e-08], sum to 1.0000
[2019-04-27 20:20:13,358] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0293
[2019-04-27 20:20:13,362] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 88.5, 1.0, 2.0, 0.5418299974375347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 649858.249690774, 649858.2496907735, 149752.889173355], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3551400.0000, 
sim time next is 3552000.0000, 
raw observation next is [22.53333333333333, 92.33333333333333, 1.0, 2.0, 0.5461695139568726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 652482.8226426454, 652482.822642645, 150376.1049600856], 
processed observation next is [1.0, 0.08695652173913043, 0.3901234567901234, 0.9233333333333333, 1.0, 1.0, 0.45972561185341976, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2330295795152305, 0.23302957951523035, 0.2891848172309338], 
reward next is 0.7108, 
noisyNet noise sample is [array([0.12189294], dtype=float32), 1.5355514]. 
=============================================
[2019-04-27 20:20:13,376] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[52.06858 ]
 [52.030186]
 [51.375652]
 [51.42605 ]
 [51.593925]], R is [[52.33478928]
 [52.52345657]
 [52.69528198]
 [52.8258934 ]
 [53.03472519]].
[2019-04-27 20:20:14,753] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.0825138e-11 1.7802685e-01 9.3028265e-15 4.1312541e-04 8.2156008e-01], sum to 1.0000
[2019-04-27 20:20:14,764] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2920
[2019-04-27 20:20:14,772] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.0, 85.0, 1.0, 2.0, 0.3017596193658768, 1.0, 2.0, 0.3017596193658768, 1.0, 2.0, 0.4805810056922173, 6.911199999999999, 6.9112, 121.94756008, 1037720.864652476, 1037720.864652477, 256752.8721555078], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3586800.0000, 
sim time next is 3587400.0000, 
raw observation next is [24.0, 86.0, 1.0, 2.0, 0.2885332035856732, 1.0, 2.0, 0.2885332035856732, 1.0, 2.0, 0.4595420700007356, 6.9112, 6.9112, 121.94756008, 992837.7009866773, 992837.7009866773, 251728.8572213182], 
processed observation next is [1.0, 0.5217391304347826, 0.4444444444444444, 0.86, 1.0, 1.0, 0.15301571855437285, 1.0, 1.0, 0.15301571855437285, 1.0, 1.0, 0.3244275875009195, 0.0, 0.0, 0.8096049824067558, 0.35458489320952763, 0.35458489320952763, 0.4840939561948427], 
reward next is 0.5159, 
noisyNet noise sample is [array([-1.6023428], dtype=float32), -0.5296353]. 
=============================================
[2019-04-27 20:20:16,215] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.6289781e-14 9.9999928e-01 4.6791219e-20 2.7247783e-08 6.9774978e-07], sum to 1.0000
[2019-04-27 20:20:16,222] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7939
[2019-04-27 20:20:16,227] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.15, 81.0, 1.0, 2.0, 0.5441159950770332, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 633292.4574453039, 633292.4574453034, 149356.1807935782], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3605400.0000, 
sim time next is 3606000.0000, 
raw observation next is [25.1, 81.66666666666666, 1.0, 2.0, 0.5460115655096759, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 637941.6044230509, 637941.6044230514, 149774.4167569196], 
processed observation next is [1.0, 0.7391304347826086, 0.4851851851851852, 0.8166666666666665, 1.0, 1.0, 0.4595375779877094, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22783628729394675, 0.22783628729394692, 0.2880277245325377], 
reward next is 0.7120, 
noisyNet noise sample is [array([1.280323], dtype=float32), 1.3657076]. 
=============================================
[2019-04-27 20:20:16,246] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[70.707504]
 [70.97054 ]
 [71.10184 ]
 [70.85161 ]
 [70.5388  ]], R is [[71.08287048]
 [71.08481598]
 [70.95947266]
 [70.81303406]
 [70.55797577]].
[2019-04-27 20:20:24,590] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0630664e-13 2.5998961e-09 4.0325977e-18 6.6816119e-07 9.9999928e-01], sum to 1.0000
[2019-04-27 20:20:24,603] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8567
[2019-04-27 20:20:24,612] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.8, 64.0, 1.0, 2.0, 0.8622093496884555, 1.0, 2.0, 0.7444693368206625, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2548131.255301621, 2548131.255301621, 475672.6723601454], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3765600.0000, 
sim time next is 3766200.0000, 
raw observation next is [33.0, 61.16666666666667, 1.0, 2.0, 0.7711327359391342, 1.0, 2.0, 0.6989310299460018, 1.0, 2.0, 0.9977734948820727, 6.911200000000002, 6.9112, 121.94756008, 2392056.262798525, 2392056.262798524, 448901.5946477906], 
processed observation next is [1.0, 0.6086956521739131, 0.7777777777777778, 0.6116666666666667, 1.0, 1.0, 0.7275389713561121, 1.0, 1.0, 0.6415845594595259, 1.0, 1.0, 0.9972168686025908, 1.7763568394002506e-16, 0.0, 0.8096049824067558, 0.8543058081423304, 0.85430580814233, 0.8632722973995973], 
reward next is 0.1367, 
noisyNet noise sample is [array([1.7910807], dtype=float32), -0.0114592705]. 
=============================================
[2019-04-27 20:20:25,809] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.8478026e-18 1.0000000e+00 1.7953801e-22 3.3341524e-10 1.3040968e-11], sum to 1.0000
[2019-04-27 20:20:25,815] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5157
[2019-04-27 20:20:25,819] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.75, 67.0, 1.0, 2.0, 0.7802597750347094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 889328.4867677265, 889328.4867677265, 191904.0493726349], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3785400.0000, 
sim time next is 3786000.0000, 
raw observation next is [31.33333333333334, 70.66666666666667, 1.0, 2.0, 0.8065515221866764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 919313.4027274995, 919313.4027274995, 197307.5699735106], 
processed observation next is [1.0, 0.8260869565217391, 0.7160493827160496, 0.7066666666666667, 1.0, 1.0, 0.7697041930793767, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.32832621525982125, 0.32832621525982125, 0.37943763456444346], 
reward next is 0.6206, 
noisyNet noise sample is [array([-0.27085733], dtype=float32), -0.8269504]. 
=============================================
[2019-04-27 20:20:25,836] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[68.00313 ]
 [67.76859 ]
 [67.73413 ]
 [67.56572 ]
 [66.997246]], R is [[68.32781219]
 [68.27548218]
 [68.2382431 ]
 [68.20889282]
 [68.18031311]].
[2019-04-27 20:20:27,430] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-04-27 20:20:27,434] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 20:20:27,434] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:20:27,435] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 20:20:27,436] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 20:20:27,437] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:20:27,436] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 20:20:27,437] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:20:27,439] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 20:20:27,439] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:20:27,439] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:20:27,465] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run56
[2019-04-27 20:20:27,486] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run56
[2019-04-27 20:20:27,507] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run56
[2019-04-27 20:20:27,508] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run56
[2019-04-27 20:20:27,509] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run56
[2019-04-27 20:20:31,901] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.10860874]
[2019-04-27 20:20:31,902] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [33.696634305, 19.21263770166667, 1.0, 2.0, 0.3836873972046605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 486089.3364217142, 486089.3364217142, 126519.5286850398]
[2019-04-27 20:20:31,903] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 20:20:31,907] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.2499752e-20 1.0000000e+00 3.0425857e-25 4.0018451e-14 1.6553178e-17], sampled 0.3574218620215929
[2019-04-27 20:20:37,439] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.10860874]
[2019-04-27 20:20:37,440] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.5, 43.5, 1.0, 2.0, 0.5635381992850734, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9177286358642834, 6.9112, 6.9112, 121.926042615642, 1370495.757102307, 1370495.757102307, 277266.9526058098]
[2019-04-27 20:20:37,442] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 20:20:37,446] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.2207097e-15 1.0000000e+00 8.7180791e-20 4.5723697e-10 4.8973451e-12], sampled 0.8697900425071803
[2019-04-27 20:20:37,447] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1370495.757102307 W.
[2019-04-27 20:21:19,202] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.10860874]
[2019-04-27 20:21:19,203] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [35.0, 56.66666666666667, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 7.426018055228226, 6.9112, 121.9243442787354, 2141982.970102744, 1878353.784115212, 382295.4487304232]
[2019-04-27 20:21:19,204] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 20:21:19,206] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.8562465e-12 9.9874109e-01 7.2407096e-17 1.1839673e-04 1.1405768e-03], sampled 0.94416686838142
[2019-04-27 20:21:19,208] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2141982.970102744 W.
[2019-04-27 20:22:17,235] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8112.4302 2446687790.5100 663.0000
[2019-04-27 20:22:17,338] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8766.1525 2171308445.8811 489.0000
[2019-04-27 20:22:17,578] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8919.5917 2121025954.0099 431.0000
[2019-04-27 20:22:17,581] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8698.3875 2195908371.5916 559.0000
[2019-04-27 20:22:17,655] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8582.4249 2249705899.7760 518.0000
[2019-04-27 20:22:18,671] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1375000, evaluation results [1375000.0, 8112.430207466989, 2446687790.5100493, 663.0, 8766.152479237962, 2171308445.8810983, 489.0, 8919.591690173133, 2121025954.009886, 431.0, 8582.424880219454, 2249705899.7759876, 518.0, 8698.387535260083, 2195908371.5916266, 559.0]
[2019-04-27 20:22:20,342] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.0312824e-21 1.0000000e+00 9.8994016e-27 3.8552425e-15 1.0746312e-19], sum to 1.0000
[2019-04-27 20:22:20,353] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5889
[2019-04-27 20:22:20,357] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.0, 56.0, 1.0, 2.0, 0.7428159873016954, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 846627.0420447317, 846627.0420447312, 184411.9963826062], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3848400.0000, 
sim time next is 3849000.0000, 
raw observation next is [33.01666666666667, 55.16666666666667, 1.0, 2.0, 0.7216768438271586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 822520.7034468419, 822520.7034468414, 180291.7771446201], 
processed observation next is [0.0, 0.5652173913043478, 0.7783950617283953, 0.5516666666666667, 1.0, 1.0, 0.668662909318046, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2937573940881578, 0.29375739408815765, 0.34671495604734637], 
reward next is 0.6533, 
noisyNet noise sample is [array([-2.1065042], dtype=float32), 1.1263931]. 
=============================================
[2019-04-27 20:22:20,382] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[69.77908 ]
 [69.66145 ]
 [69.637665]
 [69.61571 ]
 [69.57952 ]], R is [[69.85178375]
 [69.79862976]
 [69.7445755 ]
 [69.69100189]
 [69.6423645 ]].
[2019-04-27 20:22:23,068] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.9765960e-19 1.0000000e+00 1.6575486e-24 9.2521273e-15 9.6494966e-17], sum to 1.0000
[2019-04-27 20:22:23,075] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2969
[2019-04-27 20:22:23,078] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 89.83333333333334, 1.0, 2.0, 0.7320571778248739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 834357.9779134631, 834357.9779134627, 182304.895869205], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3899400.0000, 
sim time next is 3900000.0000, 
raw observation next is [26.66666666666667, 90.66666666666667, 1.0, 2.0, 0.743657360419508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 847586.5301599253, 847586.5301599253, 184576.4000481186], 
processed observation next is [0.0, 0.13043478260869565, 0.5432098765432101, 0.9066666666666667, 1.0, 1.0, 0.6948301909756048, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3027094750571162, 0.3027094750571162, 0.3549546154771512], 
reward next is 0.6450, 
noisyNet noise sample is [array([-0.33692986], dtype=float32), -0.52083474]. 
=============================================
[2019-04-27 20:22:23,089] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[63.7899  ]
 [63.810917]
 [63.937096]
 [64.0775  ]
 [64.265335]], R is [[63.67933655]
 [63.69195938]
 [63.6967926 ]
 [63.70433807]
 [63.71487427]].
[2019-04-27 20:22:26,941] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.6544107e-22 1.0000000e+00 1.8562927e-27 5.3648152e-17 3.5271436e-19], sum to 1.0000
[2019-04-27 20:22:26,949] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7982
[2019-04-27 20:22:26,956] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.65, 86.0, 1.0, 2.0, 0.721240298650842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 822022.8906126631, 822022.8906126631, 180203.526526246], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3969000.0000, 
sim time next is 3969600.0000, 
raw observation next is [26.53333333333333, 85.0, 1.0, 2.0, 0.7099550571072729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 809153.9153157753, 809153.9153157753, 178035.6843484948], 
processed observation next is [0.0, 0.9565217391304348, 0.5382716049382715, 0.85, 1.0, 1.0, 0.654708401318182, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2889835411842055, 0.2889835411842055, 0.3423763160547977], 
reward next is 0.6576, 
noisyNet noise sample is [array([-0.9975402], dtype=float32), 0.26819023]. 
=============================================
[2019-04-27 20:22:28,126] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.9338400e-07 6.6944905e-02 6.0494373e-11 5.6920694e-03 9.2736262e-01], sum to 1.0000
[2019-04-27 20:22:28,134] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9293
[2019-04-27 20:22:28,144] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.8, 91.66666666666666, 1.0, 2.0, 0.311769042201862, 1.0, 2.0, 0.311769042201862, 1.0, 2.0, 0.4963464687942085, 6.911200000000001, 6.9112, 121.94756008, 1066171.958899958, 1066171.958899958, 260592.6849506921], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3991200.0000, 
sim time next is 3991800.0000, 
raw observation next is [24.75, 91.83333333333333, 1.0, 2.0, 0.3052976804709713, 1.0, 2.0, 0.3052976804709713, 1.0, 2.0, 0.4860438501610926, 6.9112, 6.9112, 121.94756008, 1044026.449887358, 1044026.449887358, 258086.7257427553], 
processed observation next is [1.0, 0.17391304347826086, 0.4722222222222222, 0.9183333333333333, 1.0, 1.0, 0.17297342913210867, 1.0, 1.0, 0.17297342913210867, 1.0, 1.0, 0.3575548127013657, 0.0, 0.0, 0.8096049824067558, 0.372866589245485, 0.372866589245485, 0.4963206264283756], 
reward next is 0.5037, 
noisyNet noise sample is [array([-1.3288229], dtype=float32), -0.49216]. 
=============================================
[2019-04-27 20:22:28,257] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.2207799e-09 9.9962163e-01 7.6091135e-13 6.9217989e-05 3.0907069e-04], sum to 1.0000
[2019-04-27 20:22:28,263] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8116
[2019-04-27 20:22:28,267] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 93.5, 1.0, 2.0, 0.7658021373649276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 875173.0821133527, 875173.0821133527, 189092.5103753095], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3997800.0000, 
sim time next is 3998400.0000, 
raw observation next is [24.46666666666667, 93.66666666666667, 1.0, 2.0, 0.7854393002469982, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 897856.7381129679, 897856.7381129679, 193082.9677909336], 
processed observation next is [1.0, 0.2608695652173913, 0.46172839506172847, 0.9366666666666668, 1.0, 1.0, 0.7445705955321407, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3206631207546314, 0.3206631207546314, 0.37131339959794923], 
reward next is 0.6287, 
noisyNet noise sample is [array([1.1072952], dtype=float32), 0.70105803]. 
=============================================
[2019-04-27 20:22:30,436] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.3621815e-21 1.0000000e+00 1.0490406e-27 2.6511819e-16 1.8610164e-18], sum to 1.0000
[2019-04-27 20:22:30,446] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9207
[2019-04-27 20:22:30,450] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.83333333333334, 68.66666666666667, 1.0, 2.0, 0.7054474172229217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 804013.748434573, 804013.748434573, 177179.5673573658], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4465200.0000, 
sim time next is 4465800.0000, 
raw observation next is [29.75, 68.0, 1.0, 2.0, 0.7073248436741485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 806154.6174109676, 806154.6174109671, 177535.9292897847], 
processed observation next is [0.0, 0.6956521739130435, 0.6574074074074074, 0.68, 1.0, 1.0, 0.6515771948501767, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.28791236336105985, 0.2879123633610597, 0.3414152486342013], 
reward next is 0.6586, 
noisyNet noise sample is [array([-1.1667004], dtype=float32), 0.026070923]. 
=============================================
[2019-04-27 20:22:45,178] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.6213728e-22 1.0000000e+00 1.7930494e-26 2.2181631e-17 2.8405716e-17], sum to 1.0000
[2019-04-27 20:22:45,187] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7856
[2019-04-27 20:22:45,193] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 74.0, 1.0, 2.0, 0.6137890269806593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 706835.9890686683, 706835.9890686683, 160824.697162276], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4312200.0000, 
sim time next is 4312800.0000, 
raw observation next is [27.0, 74.0, 1.0, 2.0, 0.6130068705476998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 705931.64816092, 705931.64816092, 160687.686198488], 
processed observation next is [1.0, 0.9565217391304348, 0.5555555555555556, 0.74, 1.0, 1.0, 0.5392938935091663, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2521184457717571, 0.2521184457717571, 0.30901478115093844], 
reward next is 0.6910, 
noisyNet noise sample is [array([-1.3373249], dtype=float32), 0.43143284]. 
=============================================
[2019-04-27 20:22:48,619] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.8717773e-11 9.9018490e-01 2.5715866e-17 2.2797964e-08 9.8151080e-03], sum to 1.0000
[2019-04-27 20:22:48,634] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1593
[2019-04-27 20:22:48,642] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1551283.05857156 W.
[2019-04-27 20:22:48,647] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.0, 60.5, 1.0, 2.0, 0.6802218526110013, 1.0, 2.0, 0.6802218526110013, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1551283.05857156, 1551283.058571561, 296746.0388338991], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4365000.0000, 
sim time next is 4365600.0000, 
raw observation next is [31.33333333333334, 60.0, 1.0, 2.0, 0.5400354035072082, 1.0, 2.0, 0.5400354035072082, 1.0, 1.0, 0.8597539501087048, 6.911199999999999, 6.9112, 121.94756008, 1847681.428345904, 1847681.428345905, 363673.1822539252], 
processed observation next is [1.0, 0.5217391304347826, 0.7160493827160496, 0.6, 1.0, 1.0, 0.45242309941334313, 1.0, 1.0, 0.45242309941334313, 1.0, 0.5, 0.8246924376358811, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6598862244092514, 0.6598862244092517, 0.6993715043344715], 
reward next is 0.3006, 
noisyNet noise sample is [array([-1.3108839], dtype=float32), 0.8337731]. 
=============================================
[2019-04-27 20:22:58,293] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.5776413e-26 1.0000000e+00 4.8656231e-31 3.6172890e-22 1.4924333e-26], sum to 1.0000
[2019-04-27 20:22:58,299] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6295
[2019-04-27 20:22:58,305] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 94.0, 1.0, 2.0, 0.7225834546487188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 823554.5551030238, 823554.5551030238, 180465.3629663561], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4657200.0000, 
sim time next is 4657800.0000, 
raw observation next is [26.0, 94.0, 1.0, 2.0, 0.7238144520453992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 824958.3225088773, 824958.3225088773, 180703.3165396995], 
processed observation next is [1.0, 0.9130434782608695, 0.5185185185185185, 0.94, 1.0, 1.0, 0.6712076810064276, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29462797232459903, 0.29462797232459903, 0.34750637796096057], 
reward next is 0.6525, 
noisyNet noise sample is [array([0.50206393], dtype=float32), 0.11321669]. 
=============================================
[2019-04-27 20:23:05,451] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.8955744e-12 6.3929647e-01 2.1737435e-17 2.3782027e-06 3.6070120e-01], sum to 1.0000
[2019-04-27 20:23:05,459] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6664
[2019-04-27 20:23:05,465] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.6644553955185261, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 757271.1721340936, 757271.1721340936, 169522.9075299803], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4666800.0000, 
sim time next is 4667400.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.2216305020281749, 1.0, 1.0, 0.2216305020281749, 1.0, 1.0, 0.3528429772303905, 6.911200000000001, 6.9112, 121.94756008, 757768.3812607583, 757768.3812607578, 227790.7615284182], 
processed observation next is [1.0, 0.0, 0.48148148148148145, 0.94, 1.0, 1.0, 0.07336964527163681, 1.0, 0.5, 0.07336964527163681, 1.0, 0.5, 0.19105372153798808, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2706315647359851, 0.27063156473598493, 0.4380591567854196], 
reward next is 0.5619, 
noisyNet noise sample is [array([-1.2513409], dtype=float32), 0.8519529]. 
=============================================
[2019-04-27 20:23:08,931] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.1057051e-14 9.2425911e-10 5.4082395e-22 1.5827434e-08 1.0000000e+00], sum to 1.0000
[2019-04-27 20:23:08,936] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8088
[2019-04-27 20:23:08,941] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.33333333333334, 87.33333333333334, 1.0, 2.0, 0.6024024587471689, 1.0, 2.0, 0.6024024587471689, 1.0, 2.0, 0.9590443332039091, 6.911200000000001, 6.9112, 121.94756008, 2061310.780087745, 2061310.780087744, 396686.1324356066], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4720800.0000, 
sim time next is 4721400.0000, 
raw observation next is [27.5, 86.5, 1.0, 2.0, 0.6111539675753306, 1.0, 2.0, 0.6111539675753306, 1.0, 2.0, 0.972977020275087, 6.911199999999999, 6.9112, 121.94756008, 2091291.899609765, 2091291.899609766, 401486.3367089916], 
processed observation next is [1.0, 0.6521739130434783, 0.5740740740740741, 0.865, 1.0, 1.0, 0.5370880566372983, 1.0, 1.0, 0.5370880566372983, 1.0, 1.0, 0.9662212753438587, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7468899641463447, 0.746889964146345, 0.7720891090557531], 
reward next is 0.2279, 
noisyNet noise sample is [array([-0.8305593], dtype=float32), -1.4443276]. 
=============================================
[2019-04-27 20:23:09,741] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-04-27 20:23:09,742] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 20:23:09,743] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:23:09,744] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 20:23:09,745] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 20:23:09,747] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:23:09,747] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 20:23:09,748] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:23:09,746] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 20:23:09,749] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:23:09,754] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:23:09,772] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run57
[2019-04-27 20:23:09,795] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run57
[2019-04-27 20:23:09,795] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run57
[2019-04-27 20:23:09,842] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run57
[2019-04-27 20:23:09,871] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run57
[2019-04-27 20:23:26,153] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.109375246]
[2019-04-27 20:23:26,154] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.66666666666667, 48.0, 1.0, 2.0, 0.3106514994981678, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 398496.5674444102, 398496.5674444102, 116901.9537856247]
[2019-04-27 20:23:26,155] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 20:23:26,159] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.0384982e-19 1.0000000e+00 1.3002912e-23 8.4832970e-16 7.9860457e-19], sampled 0.8467500638814152
[2019-04-27 20:23:37,627] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.109375246]
[2019-04-27 20:23:37,628] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [19.83333333333334, 92.0, 1.0, 2.0, 0.3771687304973097, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 469865.1844885266, 469865.1844885266, 125502.5982616036]
[2019-04-27 20:23:37,630] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 20:23:37,633] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.0848978e-19 1.0000000e+00 7.6309986e-23 3.3931020e-15 4.1986034e-18], sampled 0.7235858195013681
[2019-04-27 20:24:22,932] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.109375246]
[2019-04-27 20:24:22,933] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.1, 63.0, 1.0, 2.0, 0.4692273350838337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 566846.8640648755, 566846.8640648751, 138393.1260111517]
[2019-04-27 20:24:22,934] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 20:24:22,936] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.2312278e-21 1.0000000e+00 4.8572717e-26 2.7142898e-17 1.2716895e-20], sampled 0.2949591390844357
[2019-04-27 20:24:59,071] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8702.6127 2195951131.4504 554.0000
[2019-04-27 20:24:59,396] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8766.6969 2171255102.6275 487.0000
[2019-04-27 20:24:59,538] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8123.4542 2446295936.6220 636.0000
[2019-04-27 20:24:59,540] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8921.7060 2120941925.9853 429.0000
[2019-04-27 20:24:59,580] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8588.1790 2249397094.2724 509.0000
[2019-04-27 20:25:00,596] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1400000, evaluation results [1400000.0, 8123.454150226576, 2446295936.622025, 636.0, 8766.69688743876, 2171255102.627474, 487.0, 8921.705978896, 2120941925.9852688, 429.0, 8588.178973373519, 2249397094.2724047, 509.0, 8702.612668839005, 2195951131.4504156, 554.0]
[2019-04-27 20:25:09,412] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.2543276e-17 1.0000000e+00 4.2191090e-24 1.1415497e-12 2.1090072e-12], sum to 1.0000
[2019-04-27 20:25:09,421] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6804
[2019-04-27 20:25:09,427] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 94.0, 1.0, 2.0, 0.848784077106386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 967480.767738016, 967480.767738016, 206234.9912326126], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4915800.0000, 
sim time next is 4916400.0000, 
raw observation next is [27.33333333333334, 94.0, 1.0, 2.0, 0.8368100027931537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 953823.7063531845, 953823.7063531845, 203671.305290346], 
processed observation next is [1.0, 0.9130434782608695, 0.5679012345679014, 0.94, 1.0, 1.0, 0.8057261938013733, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3406513236975659, 0.3406513236975659, 0.39167558709681927], 
reward next is 0.6083, 
noisyNet noise sample is [array([-1.775282], dtype=float32), 1.312692]. 
=============================================
[2019-04-27 20:25:14,179] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.3195351e-28 1.0000000e+00 6.7851779e-32 7.2805216e-23 3.4695959e-29], sum to 1.0000
[2019-04-27 20:25:14,186] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0334
[2019-04-27 20:25:14,192] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 98.66666666666666, 1.0, 2.0, 0.5626508162788303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 657630.1992034715, 657630.1992034715, 152539.5739044454], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5028000.0000, 
sim time next is 5028600.0000, 
raw observation next is [22.75, 98.33333333333334, 1.0, 2.0, 0.55710116307148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 652355.9523323834, 652355.9523323829, 151667.4454500878], 
processed observation next is [0.0, 0.17391304347826086, 0.39814814814814814, 0.9833333333333334, 1.0, 1.0, 0.47273947984700004, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23298426869013691, 0.23298426869013675, 0.2916681643270919], 
reward next is 0.7083, 
noisyNet noise sample is [array([-0.9247922], dtype=float32), 0.3880041]. 
=============================================
[2019-04-27 20:25:39,318] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.3994314e-11 9.9986327e-01 6.3448348e-16 1.3674358e-04 1.7137022e-09], sum to 1.0000
[2019-04-27 20:25:39,323] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2363
[2019-04-27 20:25:39,329] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1455795.924130303 W.
[2019-04-27 20:25:39,334] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.63333333333333, 47.0, 1.0, 2.0, 0.9705158149843062, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.425876803151809, 6.9112, 121.9238874021394, 1455795.924130303, 1192240.058427211, 237609.2283796428], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5838600.0000, 
sim time next is 5839200.0000, 
raw observation next is [27.7, 47.0, 1.0, 2.0, 0.5635637966701724, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9187516941954106, 6.911200000000001, 6.9112, 121.925732686063, 1372436.039945762, 1372436.039945762, 277174.6116771749], 
processed observation next is [1.0, 0.6086956521739131, 0.5814814814814815, 0.47, 1.0, 1.0, 0.4804330912740148, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.8984396177442633, 8.881784197001253e-17, 0.0, 0.8094600712099039, 0.4901557285520578, 0.4901557285520578, 0.5330280993791825], 
reward next is 0.4670, 
noisyNet noise sample is [array([-1.252285], dtype=float32), -0.6736275]. 
=============================================
[2019-04-27 20:25:42,664] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.8336912e-22 1.0000000e+00 3.5861932e-24 1.3591628e-16 6.2508383e-27], sum to 1.0000
[2019-04-27 20:25:42,673] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7212
[2019-04-27 20:25:42,677] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.73333333333333, 74.33333333333333, 1.0, 2.0, 0.3923075469953139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 491342.7730998468, 491342.7730998468, 127644.513646288], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5902800.0000, 
sim time next is 5903400.0000, 
raw observation next is [21.91666666666667, 73.66666666666667, 1.0, 2.0, 0.4039883387855939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 505409.3781613049, 505409.3781613044, 129279.7204786983], 
processed observation next is [1.0, 0.30434782608695654, 0.36728395061728414, 0.7366666666666667, 1.0, 1.0, 0.29046230807808804, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18050334934332318, 0.180503349343323, 0.24861484707441983], 
reward next is 0.7514, 
noisyNet noise sample is [array([0.3115277], dtype=float32), 0.91561407]. 
=============================================
[2019-04-27 20:25:46,112] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.3272718e-25 1.0000000e+00 2.3693103e-29 4.3558917e-18 8.5282816e-28], sum to 1.0000
[2019-04-27 20:25:46,117] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5496
[2019-04-27 20:25:46,126] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2045773.946149102 W.
[2019-04-27 20:25:46,132] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.43333333333334, 83.0, 1.0, 2.0, 0.8968005153964308, 1.0, 2.0, 0.8968005153964308, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2045773.946149102, 2045773.946149102, 385377.8972464469], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5586000.0000, 
sim time next is 5586600.0000, 
raw observation next is [27.11666666666667, 84.0, 1.0, 2.0, 0.882636024644228, 1.0, 2.0, 0.882636024644228, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2013425.599997877, 2013425.599997877, 379084.3979069648], 
processed observation next is [1.0, 0.6521739130434783, 0.5598765432098767, 0.84, 1.0, 1.0, 0.860280981719319, 1.0, 1.0, 0.860280981719319, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.7190805714278132, 0.7190805714278132, 0.7290084575133939], 
reward next is 0.2710, 
noisyNet noise sample is [array([-0.04896951], dtype=float32), -2.5670285]. 
=============================================
[2019-04-27 20:25:46,186] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.64189131e-24 1.00000000e+00 1.38400672e-28 3.91829175e-19
 1.13946464e-29], sum to 1.0000
[2019-04-27 20:25:46,191] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9855
[2019-04-27 20:25:46,196] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.6, 81.0, 1.0, 2.0, 0.4407898351510403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 538454.303919212, 538454.303919212, 134316.6413874249], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5965200.0000, 
sim time next is 5965800.0000, 
raw observation next is [22.58333333333334, 80.5, 1.0, 2.0, 0.4376131015740147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 535227.64024695, 535227.64024695, 133866.8489964351], 
processed observation next is [1.0, 0.043478260869565216, 0.39197530864197555, 0.805, 1.0, 1.0, 0.3304917875881127, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.191152728659625, 0.191152728659625, 0.2574362480700675], 
reward next is 0.7426, 
noisyNet noise sample is [array([1.6593381], dtype=float32), 1.7623794]. 
=============================================
[2019-04-27 20:25:46,688] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.8219963e-24 1.0000000e+00 1.0933047e-26 1.1037098e-18 1.3693444e-28], sum to 1.0000
[2019-04-27 20:25:46,698] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9893
[2019-04-27 20:25:46,702] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.58333333333334, 82.5, 1.0, 2.0, 0.4194245141364842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 518560.8886312994, 518560.8886312994, 131363.5157513511], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5975400.0000, 
sim time next is 5976000.0000, 
raw observation next is [21.5, 83.0, 1.0, 2.0, 0.4130802993883881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 510844.9991523761, 510844.9991523761, 130454.7855782272], 
processed observation next is [1.0, 0.17391304347826086, 0.35185185185185186, 0.83, 1.0, 1.0, 0.301286070700462, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18244464255442003, 0.18244464255442003, 0.2508745876504369], 
reward next is 0.7491, 
noisyNet noise sample is [array([-1.1581862], dtype=float32), 2.5861344]. 
=============================================
[2019-04-27 20:25:46,721] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[59.70998 ]
 [59.768215]
 [59.968414]
 [60.12204 ]
 [60.12607 ]], R is [[59.72250366]
 [59.87265778]
 [60.02082062]
 [60.16717148]
 [60.30872726]].
[2019-04-27 20:25:48,159] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.0643970e-28 1.0000000e+00 6.0344479e-32 4.2448143e-22 6.8275444e-34], sum to 1.0000
[2019-04-27 20:25:48,168] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1466
[2019-04-27 20:25:48,171] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.2, 79.0, 1.0, 2.0, 0.450934390038609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 548479.5344253818, 548479.5344253823, 135754.6073402938], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5736000.0000, 
sim time next is 5736600.0000, 
raw observation next is [23.4, 78.0, 1.0, 2.0, 0.4538632959578224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 551548.2291505411, 551548.2291505411, 136177.7100275356], 
processed observation next is [0.0, 0.391304347826087, 0.42222222222222217, 0.78, 1.0, 1.0, 0.3498372570926457, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19698151041090756, 0.19698151041090756, 0.2618802115914146], 
reward next is 0.7381, 
noisyNet noise sample is [array([-0.8212422], dtype=float32), -0.38821125]. 
=============================================
[2019-04-27 20:25:49,358] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.6082718e-28 1.0000000e+00 1.8906062e-31 1.0549544e-22 1.0080299e-33], sum to 1.0000
[2019-04-27 20:25:49,363] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7590
[2019-04-27 20:25:49,369] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.5, 76.33333333333334, 1.0, 2.0, 0.7084546581062254, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 807442.9715171958, 807442.9715171958, 177752.3999610005], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5661600.0000, 
sim time next is 5662200.0000, 
raw observation next is [28.6, 75.66666666666666, 1.0, 2.0, 0.7080866126204345, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 807023.2803111611, 807023.2803111606, 177682.1533014436], 
processed observation next is [0.0, 0.5217391304347826, 0.6148148148148148, 0.7566666666666666, 1.0, 1.0, 0.6524840626433743, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.28822260011112893, 0.28822260011112877, 0.34169644865662235], 
reward next is 0.6583, 
noisyNet noise sample is [array([-0.9697438], dtype=float32), 0.084810525]. 
=============================================
[2019-04-27 20:25:51,903] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-04-27 20:25:51,905] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 20:25:51,906] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 20:25:51,908] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 20:25:51,907] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:25:51,909] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 20:25:51,911] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:25:51,911] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 20:25:51,908] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:25:51,911] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:25:51,913] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:25:51,936] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run58
[2019-04-27 20:25:51,937] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run58
[2019-04-27 20:25:51,956] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run58
[2019-04-27 20:25:51,999] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run58
[2019-04-27 20:25:52,000] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run58
[2019-04-27 20:26:15,277] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.1105898]
[2019-04-27 20:26:15,278] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.60963682, 39.48317532999999, 1.0, 2.0, 0.322774125370049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 410019.1436265833, 410019.1436265837, 118426.2875825252]
[2019-04-27 20:26:15,280] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 20:26:15,284] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.6442759e-27 1.0000000e+00 3.6878711e-31 8.1668487e-21 9.3643531e-33], sampled 0.9376051816910252
[2019-04-27 20:26:27,131] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.1105898]
[2019-04-27 20:26:27,133] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [17.73016850666666, 74.00225115, 1.0, 2.0, 0.3168949749775287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 408790.2468283407, 408790.2468283402, 107011.3650449016]
[2019-04-27 20:26:27,134] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 20:26:27,136] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.2979248e-25 1.0000000e+00 7.8468224e-29 2.4599116e-19 2.1530958e-30], sampled 0.15495801972802958
[2019-04-27 20:26:55,504] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.1105898]
[2019-04-27 20:26:55,504] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.05177377333333, 102.6662875933333, 1.0, 2.0, 0.536018046058569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 634701.6047745855, 634701.6047745855, 148491.5572878993]
[2019-04-27 20:26:55,505] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 20:26:55,512] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.9322735e-26 1.0000000e+00 1.6868541e-30 2.0708438e-20 3.9923015e-32], sampled 0.09690835885829108
[2019-04-27 20:27:17,339] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.1105898]
[2019-04-27 20:27:17,340] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.36666666666667, 87.66666666666666, 1.0, 2.0, 0.8621144727233956, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.926042615635, 1003826.665231301, 1003826.665231301, 210207.7744074901]
[2019-04-27 20:27:17,341] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 20:27:17,343] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.8357329e-24 1.0000000e+00 4.8121921e-28 1.0944609e-18 2.3095570e-29], sampled 0.7950920162349887
[2019-04-27 20:27:30,802] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.1105898]
[2019-04-27 20:27:30,803] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.3, 74.0, 1.0, 2.0, 0.425318505122557, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 521845.0599468233, 521845.0599468233, 132116.255744919]
[2019-04-27 20:27:30,806] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 20:27:30,808] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.0799104e-26 1.0000000e+00 9.5461125e-30 6.7764762e-20 2.7481097e-31], sampled 0.9568614418597965
[2019-04-27 20:27:41,477] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8581.2403 2248836743.0390 553.0000
[2019-04-27 20:27:41,601] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8769.4415 2170718401.9188 493.0000
[2019-04-27 20:27:41,617] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8923.2931 2120599604.7659 430.0000
[2019-04-27 20:27:41,637] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8099.8454 2445443945.8132 746.0000
[2019-04-27 20:27:41,761] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.4280 2195183862.5297 572.0000
[2019-04-27 20:27:42,779] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1425000, evaluation results [1425000.0, 8099.845440270135, 2445443945.8132024, 746.0, 8769.4414692295, 2170718401.9187684, 493.0, 8923.293131179622, 2120599604.7658622, 430.0, 8581.240261588895, 2248836743.0389643, 553.0, 8701.42798342572, 2195183862.529731, 572.0]
[2019-04-27 20:27:45,516] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.6349949e-27 1.0000000e+00 1.1302290e-32 2.6865841e-21 4.8692572e-33], sum to 1.0000
[2019-04-27 20:27:45,525] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9209
[2019-04-27 20:27:45,529] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.93333333333334, 85.0, 1.0, 2.0, 0.4297837373359449, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 526440.126591818, 526440.126591818, 132742.2024964879], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5732400.0000, 
sim time next is 5733000.0000, 
raw observation next is [22.15, 84.0, 1.0, 2.0, 0.4325989197289052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 529204.6763012672, 529204.6763012672, 133134.5216575525], 
processed observation next is [0.0, 0.34782608695652173, 0.3759259259259259, 0.84, 1.0, 1.0, 0.32452252348679184, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18900167010759544, 0.18900167010759544, 0.2560279262645241], 
reward next is 0.7440, 
noisyNet noise sample is [array([0.27023008], dtype=float32), -1.0158855]. 
=============================================
[2019-04-27 20:27:45,543] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[76.21664 ]
 [76.21845 ]
 [76.19549 ]
 [76.124596]
 [76.13943 ]], R is [[76.18666077]
 [76.16952515]
 [76.15319824]
 [76.13736725]
 [76.12122345]].
[2019-04-27 20:27:49,737] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.3250459e-23 1.0000000e+00 5.9790803e-27 1.1398820e-14 4.7658257e-21], sum to 1.0000
[2019-04-27 20:27:49,747] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6688
[2019-04-27 20:27:49,755] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1588820.654334977 W.
[2019-04-27 20:27:49,758] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.05, 48.5, 1.0, 2.0, 0.4545493154130543, 1.0, 1.0, 0.4545493154130543, 1.0, 2.0, 0.7256490868455249, 6.9112, 6.9112, 121.94756008, 1588820.654334977, 1588820.654334977, 321909.592351081], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5933400.0000, 
sim time next is 5934000.0000, 
raw observation next is [29.0, 49.0, 1.0, 2.0, 0.4790424120773937, 1.0, 2.0, 0.4790424120773937, 1.0, 2.0, 0.7637995127464492, 6.911200000000001, 6.9112, 121.94756008, 1663604.421314677, 1663604.421314676, 333530.809568934], 
processed observation next is [1.0, 0.6956521739130435, 0.6296296296296297, 0.49, 1.0, 1.0, 0.3798123953302306, 1.0, 1.0, 0.3798123953302306, 1.0, 1.0, 0.7047493909330615, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5941444361838132, 0.5941444361838129, 0.6414054030171809], 
reward next is 0.3586, 
noisyNet noise sample is [array([-1.9345518], dtype=float32), -3.1671023]. 
=============================================
[2019-04-27 20:27:49,767] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[74.65171]
 [74.42025]
 [73.90652]
 [73.56038]
 [72.83442]], R is [[74.43520355]
 [73.6908493 ]
 [73.38056183]
 [72.64675903]
 [72.38072968]].
[2019-04-27 20:27:51,228] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.7022687e-17 1.0000000e+00 9.5151034e-22 9.4902752e-10 1.4237378e-17], sum to 1.0000
[2019-04-27 20:27:51,234] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1268
[2019-04-27 20:27:51,242] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1314090.759930842 W.
[2019-04-27 20:27:51,247] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.9, 45.0, 1.0, 2.0, 0.5421093288970773, 1.0, 1.0, 0.5421093288970773, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.926042615629, 1314090.759930842, 1314090.759930842, 251954.8332099607], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5842800.0000, 
sim time next is 5843400.0000, 
raw observation next is [27.91666666666666, 44.66666666666666, 1.0, 2.0, 0.4945256467961012, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8072331066868642, 6.911199999999999, 6.9112, 121.9260426156618, 1206083.422237175, 1206083.422237176, 252365.2641384557], 
processed observation next is [1.0, 0.6521739130434783, 0.5895061728395059, 0.44666666666666655, 1.0, 1.0, 0.3982448176144062, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.7590413833585802, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.43074407937041964, 0.43074407937042, 0.48531781565087634], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.54918], dtype=float32), 1.0105176]. 
=============================================
[2019-04-27 20:27:53,638] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2150501e-24 1.0000000e+00 3.6104284e-27 2.0913366e-17 1.6311753e-28], sum to 1.0000
[2019-04-27 20:27:53,644] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7553
[2019-04-27 20:27:53,647] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.1, 73.0, 1.0, 2.0, 0.3837821640829172, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 479625.7139215429, 479625.7139215425, 126441.2073877151], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5904000.0000, 
sim time next is 5904600.0000, 
raw observation next is [22.35, 72.16666666666667, 1.0, 2.0, 0.4056772676021537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 506267.9693721088, 506267.9693721083, 129496.8024067949], 
processed observation next is [1.0, 0.34782608695652173, 0.38333333333333336, 0.7216666666666667, 1.0, 1.0, 0.2924729376216116, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18080998906146745, 0.18080998906146725, 0.24903231232075942], 
reward next is 0.7510, 
noisyNet noise sample is [array([-0.19079645], dtype=float32), -1.7484732]. 
=============================================
[2019-04-27 20:28:03,673] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.2732417e-19 1.0000000e+00 1.8860828e-23 2.0451494e-12 1.2846437e-21], sum to 1.0000
[2019-04-27 20:28:03,680] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3876
[2019-04-27 20:28:03,688] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1626463.737863562 W.
[2019-04-27 20:28:03,692] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.16666666666667, 53.33333333333334, 1.0, 2.0, 0.7970589532076912, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9947939103096644, 6.9112, 6.9112, 121.9260426156618, 1626463.737863562, 1626463.737863562, 335175.9146013005], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6081600.0000, 
sim time next is 6082200.0000, 
raw observation next is [29.95, 54.5, 1.0, 2.0, 0.7585182914473134, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9941422371046063, 6.9112, 6.9112, 121.9260426156618, 1582947.648210452, 1582947.648210452, 327549.2388847172], 
processed observation next is [1.0, 0.391304347826087, 0.6648148148148147, 0.545, 1.0, 1.0, 0.7125217755325159, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9926777963807578, 0.0, 0.0, 0.8094621288201359, 0.5653384457894471, 0.5653384457894471, 0.62990238247061], 
reward next is 0.3701, 
noisyNet noise sample is [array([1.9377723], dtype=float32), 0.66906774]. 
=============================================
[2019-04-27 20:28:20,719] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.3956513e-26 1.0000000e+00 5.2301426e-29 8.2889779e-20 7.3256274e-30], sum to 1.0000
[2019-04-27 20:28:20,726] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4470
[2019-04-27 20:28:20,730] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.35, 68.0, 1.0, 2.0, 0.685726127676014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 781525.5073587134, 781525.507358713, 173458.9171792014], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6381000.0000, 
sim time next is 6381600.0000, 
raw observation next is [29.23333333333333, 68.66666666666667, 1.0, 2.0, 0.6867650347170213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 782710.159471152, 782710.159471152, 173653.10622633], 
processed observation next is [0.0, 0.8695652173913043, 0.6382716049382715, 0.6866666666666668, 1.0, 1.0, 0.6271012318059778, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2795393426682686, 0.2795393426682686, 0.3339482812044808], 
reward next is 0.6661, 
noisyNet noise sample is [array([-1.3282913], dtype=float32), 1.3167739]. 
=============================================
[2019-04-27 20:28:20,977] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.5761337e-20 1.0000000e+00 1.9202402e-23 2.2965007e-15 5.6929416e-23], sum to 1.0000
[2019-04-27 20:28:20,988] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4761
[2019-04-27 20:28:20,993] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.85, 91.5, 1.0, 2.0, 0.9908721599732064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.089091350402673, 6.9112, 121.9250283258262, 1220845.465964674, 1129749.95263026, 238532.6222466305], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6409800.0000, 
sim time next is 6410400.0000, 
raw observation next is [24.8, 91.66666666666666, 1.0, 2.0, 0.91742065903591, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9259354540764, 1046566.264624653, 1046566.264624653, 221432.9461315556], 
processed observation next is [1.0, 0.17391304347826086, 0.4740740740740741, 0.9166666666666665, 1.0, 1.0, 0.9016912607570357, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094614173786491, 0.3737736659373761, 0.3737736659373761, 0.42583258871453], 
reward next is 0.5742, 
noisyNet noise sample is [array([0.19441405], dtype=float32), -0.7204279]. 
=============================================
[2019-04-27 20:28:23,719] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.8156249e-19 1.0000000e+00 1.1231811e-23 4.2970395e-14 1.2948434e-20], sum to 1.0000
[2019-04-27 20:28:23,726] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5761
[2019-04-27 20:28:23,737] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1925268.414514355 W.
[2019-04-27 20:28:23,746] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.03333333333333, 62.33333333333334, 1.0, 2.0, 0.8440317051001011, 1.0, 2.0, 0.8440317051001011, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1925268.414514355, 1925268.414514356, 362285.4109282973], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6439200.0000, 
sim time next is 6439800.0000, 
raw observation next is [31.21666666666667, 61.16666666666666, 1.0, 2.0, 0.5491181626254836, 1.0, 2.0, 0.5491181626254836, 1.0, 1.0, 0.8742139984298125, 6.911199999999999, 6.9112, 121.94756008, 1878789.9312618, 1878789.9312618, 368350.3558799273], 
processed observation next is [1.0, 0.5217391304347826, 0.7117283950617285, 0.6116666666666666, 1.0, 1.0, 0.4632359078874805, 1.0, 1.0, 0.4632359078874805, 1.0, 0.5, 0.8427674980372657, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6709964040220714, 0.6709964040220714, 0.7083660689998602], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.093382], dtype=float32), 1.0446371]. 
=============================================
[2019-04-27 20:28:29,616] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.7842489e-17 1.0000000e+00 5.5603489e-21 3.9111954e-13 9.2997318e-20], sum to 1.0000
[2019-04-27 20:28:29,624] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4110
[2019-04-27 20:28:29,633] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1839873.130871701 W.
[2019-04-27 20:28:29,641] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.2, 80.66666666666667, 1.0, 2.0, 0.5377555628450634, 1.0, 2.0, 0.5377555628450634, 1.0, 2.0, 0.8561243695253434, 6.911199999999999, 6.9112, 121.94756008, 1839873.130871701, 1839873.130871702, 362506.179865738], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6531600.0000, 
sim time next is 6532200.0000, 
raw observation next is [27.25, 80.5, 1.0, 2.0, 0.5185405671118756, 1.0, 2.0, 0.5185405671118756, 1.0, 2.0, 0.8255334705293859, 6.9112, 6.9112, 121.94756008, 1774065.803397518, 1774065.803397518, 352782.1707161831], 
processed observation next is [1.0, 0.6086956521739131, 0.5648148148148148, 0.805, 1.0, 1.0, 0.42683400846651853, 1.0, 1.0, 0.42683400846651853, 1.0, 1.0, 0.7819168381617322, 0.0, 0.0, 0.8096049824067558, 0.6335949297848278, 0.6335949297848278, 0.6784272513772751], 
reward next is 0.3216, 
noisyNet noise sample is [array([0.92800635], dtype=float32), 0.06662776]. 
=============================================
[2019-04-27 20:28:33,661] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.7219715e-25 1.0000000e+00 1.0594323e-27 2.2768620e-18 1.7200509e-24], sum to 1.0000
[2019-04-27 20:28:33,670] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7320
[2019-04-27 20:28:33,676] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.66666666666666, 36.66666666666667, 1.0, 2.0, 0.7328966186434158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156256, 918926.6363014303, 918926.6363014298, 185597.8969294149], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6612000.0000, 
sim time next is 6612600.0000, 
raw observation next is [28.83333333333334, 35.83333333333334, 1.0, 2.0, 0.7201357501286062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 903550.2039376388, 903550.2039376388, 183065.2963883426], 
processed observation next is [1.0, 0.5217391304347826, 0.623456790123457, 0.35833333333333345, 1.0, 1.0, 0.6668282739626264, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3226965014062996, 0.3226965014062996, 0.35204864690065885], 
reward next is 0.6480, 
noisyNet noise sample is [array([-0.43422222], dtype=float32), 0.009312246]. 
=============================================
[2019-04-27 20:28:33,690] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-04-27 20:28:33,691] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 20:28:33,691] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:28:33,692] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 20:28:33,693] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 20:28:33,693] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 20:28:33,694] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 20:28:33,695] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:28:33,695] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:28:33,695] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:28:33,697] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:28:33,719] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run59
[2019-04-27 20:28:33,743] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run59
[2019-04-27 20:28:33,743] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run59
[2019-04-27 20:28:33,743] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run59
[2019-04-27 20:28:33,803] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run59
[2019-04-27 20:28:36,222] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.11244702]
[2019-04-27 20:28:36,223] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.119707305, 87.75071030000001, 1.0, 2.0, 0.4538520813021967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 550979.0727336837, 550979.0727336837, 136158.9118618302]
[2019-04-27 20:28:36,224] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 20:28:36,227] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.9844813e-31 1.0000000e+00 8.6538274e-36 5.9214975e-26 2.3835150e-37], sampled 0.25842874447907827
[2019-04-27 20:28:51,300] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.11244702]
[2019-04-27 20:28:51,301] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.73333333333334, 31.33333333333334, 1.0, 2.0, 0.6989254142387321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 872272.3086358956, 872272.3086358956, 178813.7448037164]
[2019-04-27 20:28:51,303] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 20:28:51,307] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.4065358e-29 1.0000000e+00 2.4772290e-34 1.1471391e-24 1.4474533e-35], sampled 0.18142743056689958
[2019-04-27 20:29:14,125] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.11244702]
[2019-04-27 20:29:14,125] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.0, 83.0, 1.0, 2.0, 0.8172994897615167, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 952595.4915966251, 952595.4915966251, 200611.4986228269]
[2019-04-27 20:29:14,126] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 20:29:14,130] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.6849642e-29 1.0000000e+00 1.5912713e-33 3.6416533e-24 9.1796483e-35], sampled 0.11330488767449254
[2019-04-27 20:29:20,409] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.11244702]
[2019-04-27 20:29:20,410] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.0, 88.0, 1.0, 2.0, 0.4416480500264517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 537213.1935367932, 537213.1935367932, 134376.6461544163]
[2019-04-27 20:29:20,410] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 20:29:20,416] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.9451071e-31 1.0000000e+00 1.9954185e-36 2.0597211e-26 5.0011148e-38], sampled 0.8164413090704122
[2019-04-27 20:29:49,946] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.11244702]
[2019-04-27 20:29:49,947] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.83333333333334, 76.83333333333333, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.983120135483088, 6.9112, 121.9256491147244, 1914944.685142572, 1878115.266489155, 383874.5233779064]
[2019-04-27 20:29:49,947] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 20:29:49,949] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.6624555e-25 1.0000000e+00 4.4802190e-30 2.2862855e-20 7.5446037e-29], sampled 0.3259613504326776
[2019-04-27 20:29:49,950] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1914944.685142572 W.
[2019-04-27 20:30:08,802] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.11244702]
[2019-04-27 20:30:08,804] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.89825708, 45.29689736833333, 1.0, 2.0, 0.4010792908752792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 495993.8957086821, 495993.8957086821, 128749.1573836703]
[2019-04-27 20:30:08,805] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 20:30:08,809] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.338969e-32 1.000000e+00 4.078882e-37 7.784697e-27 0.000000e+00], sampled 0.9399489090796938
[2019-04-27 20:30:22,254] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8099.8454 2445443945.8132 746.0000
[2019-04-27 20:30:22,474] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8582.8795 2248773970.1662 553.0000
[2019-04-27 20:30:22,483] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8769.4422 2170768739.9937 493.0000
[2019-04-27 20:30:22,507] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8921.8922 2120660928.3939 430.0000
[2019-04-27 20:30:22,512] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8700.0481 2195254515.0420 572.0000
[2019-04-27 20:30:23,529] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1450000, evaluation results [1450000.0, 8099.845440270135, 2445443945.8132024, 746.0, 8769.442185004564, 2170768739.993712, 493.0, 8921.892236157437, 2120660928.3938506, 430.0, 8582.879467926026, 2248773970.1662407, 553.0, 8700.048136678424, 2195254515.0419693, 572.0]
[2019-04-27 20:30:24,324] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.25187434e-26 1.00000000e+00 1.98202717e-30 2.15215215e-22
 1.28349101e-31], sum to 1.0000
[2019-04-27 20:30:24,330] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6756
[2019-04-27 20:30:24,336] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.58333333333334, 82.66666666666667, 1.0, 2.0, 0.3243289672123256, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 415070.8225505165, 415070.8225505165, 118636.0339820403], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6753000.0000, 
sim time next is 6753600.0000, 
raw observation next is [18.5, 83.0, 1.0, 2.0, 0.3224692771444891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 412862.3873046073, 412862.3873046073, 118398.4011918252], 
processed observation next is [1.0, 0.17391304347826086, 0.24074074074074073, 0.83, 1.0, 1.0, 0.19341580612439177, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14745085260878832, 0.14745085260878832, 0.2276892330612023], 
reward next is 0.7723, 
noisyNet noise sample is [array([1.5653007], dtype=float32), -0.5293721]. 
=============================================
[2019-04-27 20:30:38,442] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.7014231e-29 1.0000000e+00 4.0634802e-35 1.0033694e-24 7.9921672e-35], sum to 1.0000
[2019-04-27 20:30:38,448] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7653
[2019-04-27 20:30:38,458] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.06666666666667, 86.33333333333333, 1.0, 2.0, 0.4053860645967617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 501325.623466861, 501325.623466861, 129358.4618981326], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7342800.0000, 
sim time next is 7343400.0000, 
raw observation next is [21.03333333333333, 86.16666666666667, 1.0, 2.0, 0.4032714623294372, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 499091.1192894863, 499091.1192894863, 129067.8589649362], 
processed observation next is [1.0, 1.0, 0.3345679012345678, 0.8616666666666667, 1.0, 1.0, 0.2896088837255205, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1782468283176737, 0.1782468283176737, 0.24820742108641577], 
reward next is 0.7518, 
noisyNet noise sample is [array([0.58098096], dtype=float32), 1.0157468]. 
=============================================
[2019-04-27 20:30:38,973] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.2462372e-32 1.0000000e+00 1.2641959e-37 2.2917446e-26 0.0000000e+00], sum to 1.0000
[2019-04-27 20:30:38,976] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6601
[2019-04-27 20:30:38,983] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.08333333333333, 80.33333333333334, 1.0, 2.0, 0.4517415931224061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 548877.4606845522, 548877.4606845522, 135857.5047616914], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6940200.0000, 
sim time next is 6940800.0000, 
raw observation next is [23.2, 80.0, 1.0, 2.0, 0.4547440782533805, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 551914.0090059382, 551914.0090059382, 136288.1093489259], 
processed observation next is [0.0, 0.34782608695652173, 0.4148148148148148, 0.8, 1.0, 1.0, 0.35088580744450054, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19711214607354935, 0.19711214607354935, 0.26209251797870364], 
reward next is 0.7379, 
noisyNet noise sample is [array([1.0511293], dtype=float32), 0.4684191]. 
=============================================
[2019-04-27 20:30:41,996] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.3832626e-32 1.0000000e+00 1.2700931e-37 3.8933340e-27 1.7606400e-38], sum to 1.0000
[2019-04-27 20:30:42,004] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7218
[2019-04-27 20:30:42,010] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.76666666666667, 60.66666666666666, 1.0, 2.0, 0.44332654742269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 541930.1219227909, 541930.1219227909, 134702.5501170874], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6986400.0000, 
sim time next is 6987000.0000, 
raw observation next is [25.63333333333333, 61.33333333333334, 1.0, 2.0, 0.4427628508542708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 541340.9370717123, 541340.9370717123, 134621.8796931429], 
processed observation next is [0.0, 0.8695652173913043, 0.5049382716049381, 0.6133333333333334, 1.0, 1.0, 0.3366224414931795, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19333604895418297, 0.19333604895418297, 0.25888823017912094], 
reward next is 0.7411, 
noisyNet noise sample is [array([0.30823845], dtype=float32), 0.38060305]. 
=============================================
[2019-04-27 20:30:42,028] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[80.90483 ]
 [80.929535]
 [80.93869 ]
 [80.93821 ]
 [80.91853 ]], R is [[80.81543732]
 [80.74824524]
 [80.68171692]
 [80.61564636]
 [80.54973602]].
[2019-04-27 20:30:45,787] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.1186482e-27 1.0000000e+00 9.2596035e-32 4.3005395e-22 1.1588111e-33], sum to 1.0000
[2019-04-27 20:30:45,793] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8923
[2019-04-27 20:30:45,797] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 78.33333333333334, 1.0, 2.0, 0.4724994812849011, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260425283488, 567299.3950262448, 567299.3950262448, 138773.6095734954], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7060800.0000, 
sim time next is 7061400.0000, 
raw observation next is [23.8, 78.5, 1.0, 2.0, 0.4621494494020797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156352, 557157.9778054851, 557157.9778054847, 137282.593881717], 
processed observation next is [1.0, 0.7391304347826086, 0.43703703703703706, 0.785, 1.0, 1.0, 0.3597017254786663, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288199593, 0.19898499207338755, 0.19898499207338738, 0.26400498823407115], 
reward next is 0.7360, 
noisyNet noise sample is [array([0.29227048], dtype=float32), 2.0159616]. 
=============================================
[2019-04-27 20:30:51,885] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.0627348e-29 1.0000000e+00 1.7743053e-32 1.8305720e-17 6.3173152e-26], sum to 1.0000
[2019-04-27 20:30:51,893] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2860
[2019-04-27 20:30:51,900] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.75, 61.66666666666667, 1.0, 2.0, 0.7596519742714257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 949488.1165410368, 949488.1165410363, 190968.285062437], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7138200.0000, 
sim time next is 7138800.0000, 
raw observation next is [23.7, 62.0, 1.0, 2.0, 0.7568312661886129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000003, 6.9112, 121.9260426156618, 945905.5276380178, 945905.5276380164, 190389.2543925533], 
processed observation next is [1.0, 0.6521739130434783, 0.4333333333333333, 0.62, 1.0, 1.0, 0.710513412129301, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 2.6645352591003756e-16, 0.0, 0.8094621288201359, 0.3378234027278635, 0.337823402727863, 0.3661331815241409], 
reward next is 0.6339, 
noisyNet noise sample is [array([0.22157238], dtype=float32), -0.43729344]. 
=============================================
[2019-04-27 20:30:55,393] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1145249e-24 1.0000000e+00 3.6540266e-30 3.7315238e-18 2.1696490e-25], sum to 1.0000
[2019-04-27 20:30:55,403] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2135
[2019-04-27 20:30:55,413] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 78.0, 1.0, 2.0, 0.7524859448479796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 930684.1379439892, 930684.1379439892, 189277.8111770307], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7204200.0000, 
sim time next is 7204800.0000, 
raw observation next is [22.33333333333334, 78.0, 1.0, 2.0, 0.7722032393597588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 952772.09762612, 952772.09762612, 193263.1264515275], 
processed observation next is [1.0, 0.391304347826087, 0.38271604938271625, 0.78, 1.0, 1.0, 0.728813380190189, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3402757491521857, 0.3402757491521857, 0.3716598585606298], 
reward next is 0.6283, 
noisyNet noise sample is [array([0.9764572], dtype=float32), -0.41852722]. 
=============================================
[2019-04-27 20:30:56,579] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.2183793e-28 1.0000000e+00 4.2658117e-33 1.6423215e-19 5.4106940e-30], sum to 1.0000
[2019-04-27 20:30:56,588] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0881
[2019-04-27 20:30:56,592] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.63333333333333, 74.66666666666667, 1.0, 2.0, 0.4054462794123124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 501545.5253718356, 501545.5253718351, 129370.3999841722], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7242000.0000, 
sim time next is 7242600.0000, 
raw observation next is [22.56666666666667, 74.83333333333333, 1.0, 2.0, 0.4040650260654175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 500121.0811755305, 500121.0811755305, 129181.2624998778], 
processed observation next is [1.0, 0.8260869565217391, 0.39135802469135816, 0.7483333333333333, 1.0, 1.0, 0.2905536024588304, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17861467184840374, 0.17861467184840374, 0.24842550480745731], 
reward next is 0.7516, 
noisyNet noise sample is [array([0.56731564], dtype=float32), 0.48940554]. 
=============================================
[2019-04-27 20:31:01,056] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0865041e-31 1.0000000e+00 0.0000000e+00 7.6272288e-27 2.5921502e-38], sum to 1.0000
[2019-04-27 20:31:01,065] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0288
[2019-04-27 20:31:01,069] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.3, 67.66666666666667, 1.0, 2.0, 0.4648905495254304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 562119.9053760772, 562119.9053760772, 137751.2968817561], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7324800.0000, 
sim time next is 7325400.0000, 
raw observation next is [25.15, 68.33333333333333, 1.0, 2.0, 0.4636911497769893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 561009.1373151537, 561009.1373151537, 137580.5908174705], 
processed observation next is [1.0, 0.782608695652174, 0.487037037037037, 0.6833333333333332, 1.0, 1.0, 0.36153708306784443, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20036040618398349, 0.20036040618398349, 0.2645780592643664], 
reward next is 0.7354, 
noisyNet noise sample is [array([-0.7099868], dtype=float32), -0.83885825]. 
=============================================
[2019-04-27 20:31:05,790] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4000767e-26 1.0000000e+00 7.9608164e-30 3.2217802e-21 4.1565480e-33], sum to 1.0000
[2019-04-27 20:31:05,798] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5053
[2019-04-27 20:31:05,806] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.75, 90.0, 1.0, 2.0, 0.4115324270713762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 507916.1943108754, 507916.1943108754, 130209.2317966661], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7409400.0000, 
sim time next is 7410000.0000, 
raw observation next is [20.7, 90.0, 1.0, 2.0, 0.4116740904454801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 508452.938072915, 508452.938072915, 130238.1868192066], 
processed observation next is [1.0, 0.782608695652174, 0.3222222222222222, 0.9, 1.0, 1.0, 0.29961201243509533, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18159033502604108, 0.18159033502604108, 0.2504580515753973], 
reward next is 0.7495, 
noisyNet noise sample is [array([-0.7141383], dtype=float32), -0.9843273]. 
=============================================
[2019-04-27 20:31:05,824] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[71.20673 ]
 [70.953705]
 [70.62193 ]
 [70.46788 ]
 [70.319   ]], R is [[71.35371399]
 [71.38977051]
 [71.42575836]
 [71.46147919]
 [71.49682617]].
[2019-04-27 20:31:06,904] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2706688e-31 1.0000000e+00 1.4934851e-36 2.5562775e-24 2.3063980e-35], sum to 1.0000
[2019-04-27 20:31:06,914] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8287
[2019-04-27 20:31:06,919] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.28333333333333, 90.0, 1.0, 2.0, 0.3851170264154949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 478582.9441831722, 478582.9441831722, 126572.7796376187], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7426200.0000, 
sim time next is 7426800.0000, 
raw observation next is [20.3, 90.0, 1.0, 2.0, 0.3840881073214752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 477198.1306143554, 477198.1306143554, 126428.3204310284], 
processed observation next is [1.0, 1.0, 0.3074074074074074, 0.9, 1.0, 1.0, 0.26677155633508953, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17042790379084122, 0.17042790379084122, 0.2431313854442854], 
reward next is 0.7569, 
noisyNet noise sample is [array([1.1804041], dtype=float32), 0.24670015]. 
=============================================
[2019-04-27 20:31:08,698] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9173784e-30 1.0000000e+00 5.8548531e-34 2.1793337e-21 5.7830039e-33], sum to 1.0000
[2019-04-27 20:31:08,706] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5146
[2019-04-27 20:31:08,714] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 84.0, 1.0, 2.0, 0.446704625465028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 541789.3584816528, 541789.3584816528, 135077.3838553633], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7468200.0000, 
sim time next is 7468800.0000, 
raw observation next is [22.86666666666667, 83.33333333333334, 1.0, 2.0, 0.4495048309900979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 544509.3103551534, 544509.3103551534, 135472.5435487642], 
processed observation next is [0.0, 0.43478260869565216, 0.4024691358024693, 0.8333333333333335, 1.0, 1.0, 0.3446486083215452, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1944676108411262, 0.1944676108411262, 0.26052412220916193], 
reward next is 0.7395, 
noisyNet noise sample is [array([3.898758], dtype=float32), 0.5279207]. 
=============================================
[2019-04-27 20:31:13,720] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:31:13,720] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:31:13,766] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run8
[2019-04-27 20:31:14,788] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-04-27 20:31:14,788] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 20:31:14,789] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 20:31:14,790] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:31:14,790] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 20:31:14,791] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 20:31:14,792] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 20:31:14,792] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:31:14,793] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:31:14,795] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:31:14,794] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:31:14,809] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run60
[2019-04-27 20:31:14,826] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run60
[2019-04-27 20:31:14,848] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run60
[2019-04-27 20:31:14,848] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run60
[2019-04-27 20:31:14,884] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run60
[2019-04-27 20:31:21,130] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.11604557]
[2019-04-27 20:31:21,132] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.95, 30.5, 1.0, 2.0, 0.825086479965565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426154913, 1055009.078818609, 1055009.078818609, 205060.5286455875]
[2019-04-27 20:31:21,135] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 20:31:21,137] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.0126661e-26 1.0000000e+00 4.9186062e-30 2.4789943e-21 4.0755043e-31], sampled 0.316642094813829
[2019-04-27 20:31:22,696] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.11604557]
[2019-04-27 20:31:22,697] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [32.7, 22.0, 1.0, 2.0, 0.4998887504683751, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8331312447862862, 6.9112, 6.9112, 121.9260425064805, 1243724.62162333, 1243724.62162333, 252480.9912793392]
[2019-04-27 20:31:22,699] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 20:31:22,702] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.0615919e-29 1.0000000e+00 2.7763884e-33 9.2486266e-24 1.0114692e-34], sampled 0.7069082018363476
[2019-04-27 20:31:22,918] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.11604557]
[2019-04-27 20:31:22,920] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [30.79228248166666, 24.34535452333333, 1.0, 2.0, 0.3556205004492329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 452377.8006320989, 452377.8006320993, 122717.6328503992]
[2019-04-27 20:31:22,921] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 20:31:22,926] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.4073086e-29 1.0000000e+00 5.0636683e-34 2.6137352e-24 1.8497679e-35], sampled 0.8155158528811057
[2019-04-27 20:31:39,375] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.11604557]
[2019-04-27 20:31:39,376] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.66666666666666, 33.33333333333334, 1.0, 2.0, 0.455402717965734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 559972.3340150488, 559972.3340150488, 136593.1303663172]
[2019-04-27 20:31:39,379] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 20:31:39,381] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.1930099e-29 1.0000000e+00 8.8082400e-34 4.2431586e-24 3.5403118e-35], sampled 0.8116339550372768
[2019-04-27 20:31:42,962] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.11604557]
[2019-04-27 20:31:42,965] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [19.58333333333334, 92.0, 1.0, 2.0, 0.3656142412663756, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 457160.9042486206, 457160.9042486206, 123963.8114241449]
[2019-04-27 20:31:42,966] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 20:31:42,967] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.6456885e-29 1.0000000e+00 1.7019959e-33 5.6416370e-24 5.5713927e-35], sampled 0.9341887233921513
[2019-04-27 20:32:09,092] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.11604557]
[2019-04-27 20:32:09,093] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [36.079152505, 49.360391245, 1.0, 2.0, 1.014362751297137, 1.0, 2.0, 1.014362751297137, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156053, 2314303.520515746, 2314303.520515747, 440296.177667492]
[2019-04-27 20:32:09,094] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 20:32:09,096] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.6852397e-25 1.0000000e+00 4.8516532e-29 1.5978633e-20 6.4200657e-30], sampled 0.497610101142836
[2019-04-27 20:32:09,099] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2314303.520515746 W.
[2019-04-27 20:32:12,682] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.11604557]
[2019-04-27 20:32:12,683] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.8, 87.33333333333334, 1.0, 2.0, 0.9498953252602274, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426156618, 1798042.457492078, 1798042.457492077, 367957.6723812476]
[2019-04-27 20:32:12,684] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 20:32:12,686] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.2902481e-24 1.0000000e+00 6.7090073e-28 7.6047108e-20 6.1949992e-29], sampled 0.08997463962717112
[2019-04-27 20:32:12,687] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1798042.457492078 W.
[2019-04-27 20:33:04,027] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8700.0481 2195254515.0420 572.0000
[2019-04-27 20:33:04,122] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8099.9088 2445411000.3494 746.0000
[2019-04-27 20:33:04,215] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8582.8787 2248748925.1610 553.0000
[2019-04-27 20:33:04,294] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8922.6628 2120599135.7723 430.0000
[2019-04-27 20:33:04,314] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.0845 2170631810.8436 493.0000
[2019-04-27 20:33:05,331] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1475000, evaluation results [1475000.0, 8099.908796931282, 2445411000.349406, 746.0, 8771.084470098069, 2170631810.843588, 493.0, 8922.662781171732, 2120599135.7722971, 430.0, 8582.878745663738, 2248748925.160952, 553.0, 8700.048136678424, 2195254515.0419693, 572.0]
[2019-04-27 20:33:06,564] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:33:06,566] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:33:06,635] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run8
[2019-04-27 20:33:08,272] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.5165330e-21 1.0000000e+00 1.7655304e-22 2.6944515e-17 1.0459858e-23], sum to 1.0000
[2019-04-27 20:33:08,279] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7079
[2019-04-27 20:33:08,283] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 85.33333333333334, 1.0, 2.0, 0.8928720569332268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1080033.891940228, 1080033.891940228, 218803.3800703943], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7636200.0000, 
sim time next is 7636800.0000, 
raw observation next is [22.93333333333333, 84.66666666666667, 1.0, 2.0, 0.8884462518652094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1071342.973196152, 1071342.973196152, 217673.5930311434], 
processed observation next is [1.0, 0.391304347826087, 0.40493827160493817, 0.8466666666666667, 1.0, 1.0, 0.867197918887154, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3826224904271971, 0.3826224904271971, 0.4186030635214296], 
reward next is 0.5814, 
noisyNet noise sample is [array([0.10187635], dtype=float32), 0.27859497]. 
=============================================
[2019-04-27 20:33:12,494] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0059246e-26 1.0000000e+00 7.1103010e-29 4.4524703e-20 7.5371244e-29], sum to 1.0000
[2019-04-27 20:33:12,503] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8612
[2019-04-27 20:33:12,509] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.38333333333334, 72.5, 1.0, 2.0, 0.4173254442210857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 513265.2796244831, 513265.2796244831, 130994.5022609922], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 90600.0000, 
sim time next is 91200.0000, 
raw observation next is [23.26666666666667, 73.0, 1.0, 2.0, 0.4154812850417616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 511288.0635719888, 511288.0635719888, 130737.1915383735], 
processed observation next is [1.0, 0.043478260869565216, 0.41728395061728407, 0.73, 1.0, 1.0, 0.3041443869544781, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18260287984713885, 0.18260287984713885, 0.25141767603533366], 
reward next is 0.7486, 
noisyNet noise sample is [array([0.61070716], dtype=float32), -2.4447289]. 
=============================================
[2019-04-27 20:33:20,416] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:33:20,416] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:33:20,491] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run8
[2019-04-27 20:33:20,993] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.8392773e-27 1.0000000e+00 1.6976143e-31 1.3526615e-23 1.5183105e-31], sum to 1.0000
[2019-04-27 20:33:21,001] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6901
[2019-04-27 20:33:21,006] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.8, 89.0, 1.0, 2.0, 0.3771738574534522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 472251.8701632459, 472251.8701632459, 125547.1010237306], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7880400.0000, 
sim time next is 7881000.0000, 
raw observation next is [19.93333333333333, 88.0, 1.0, 2.0, 0.4131876063349491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 517394.9871402792, 517394.9871402792, 130600.139720621], 
processed observation next is [1.0, 0.21739130434782608, 0.293827160493827, 0.88, 1.0, 1.0, 0.3014138170654156, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18478392397867113, 0.18478392397867113, 0.25115411484734806], 
reward next is 0.7488, 
noisyNet noise sample is [array([-0.33223948], dtype=float32), 2.3746252]. 
=============================================
[2019-04-27 20:33:21,018] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[68.119  ]
 [68.24525]
 [68.3208 ]
 [68.49538]
 [68.60252]], R is [[68.15014648]
 [68.22720337]
 [68.30232239]
 [68.37510681]
 [68.44478607]].
[2019-04-27 20:33:24,855] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:33:24,856] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:33:24,911] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run8
[2019-04-27 20:33:25,280] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:33:25,280] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:33:25,298] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run8
[2019-04-27 20:33:25,463] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:33:25,464] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:33:25,490] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run8
[2019-04-27 20:33:25,569] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:33:25,570] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:33:25,581] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run8
[2019-04-27 20:33:25,605] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:33:25,607] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:33:25,623] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run8
[2019-04-27 20:33:25,641] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:33:25,642] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:33:25,656] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run8
[2019-04-27 20:33:26,098] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:33:26,099] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:33:26,115] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run8
[2019-04-27 20:33:26,148] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:33:26,148] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:33:26,154] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run8
[2019-04-27 20:33:26,171] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:33:26,171] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:33:26,173] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:33:26,176] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:33:26,172] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:33:26,179] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:33:26,192] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run8
[2019-04-27 20:33:26,218] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:33:26,224] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:33:26,228] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run8
[2019-04-27 20:33:26,247] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run8
[2019-04-27 20:33:26,270] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run8
[2019-04-27 20:33:26,295] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:33:26,295] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:33:26,324] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run8
[2019-04-27 20:33:27,304] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.8682523e-29 1.0000000e+00 1.5559385e-35 5.5029895e-23 3.8138844e-33], sum to 1.0000
[2019-04-27 20:33:27,306] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0746
[2019-04-27 20:33:27,312] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.9, 16.0, 1.0, 2.0, 0.3163058034277408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 408030.0247647578, 408030.0247647578, 96698.84718563565], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 178800.0000, 
sim time next is 179400.0000, 
raw observation next is [26.65, 16.5, 1.0, 2.0, 0.3132196184447515, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 404047.840884294, 404047.840884294, 96081.27465838272], 
processed observation next is [0.0, 0.043478260869565216, 0.5425925925925925, 0.165, 1.0, 1.0, 0.1824043076723232, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1443028003158193, 0.1443028003158193, 0.18477168203535138], 
reward next is 0.8152, 
noisyNet noise sample is [array([-1.0936079], dtype=float32), -0.7334812]. 
=============================================
[2019-04-27 20:33:27,422] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0820525e-18 1.0000000e+00 8.7269833e-23 2.1577459e-11 7.5891604e-17], sum to 1.0000
[2019-04-27 20:33:27,424] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5268
[2019-04-27 20:33:27,430] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.03333333333333, 75.33333333333334, 1.0, 2.0, 0.2767966402091786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 357051.8970645203, 357051.8970645203, 105203.93946089], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 16800.0000, 
sim time next is 17400.0000, 
raw observation next is [18.01666666666667, 75.16666666666666, 1.0, 2.0, 0.2702366987328751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 348588.0231836425, 348588.0231836425, 103811.9003358166], 
processed observation next is [1.0, 0.17391304347826086, 0.2228395061728396, 0.7516666666666666, 1.0, 1.0, 0.13123416515818465, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1244957225655866, 0.1244957225655866, 0.19963826987657038], 
reward next is 0.8004, 
noisyNet noise sample is [array([0.7622623], dtype=float32), -0.10968067]. 
=============================================
[2019-04-27 20:33:29,584] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.1781774e-14 9.9999988e-01 1.3264722e-17 8.2881421e-08 3.1886111e-12], sum to 1.0000
[2019-04-27 20:33:29,591] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4573
[2019-04-27 20:33:29,596] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.41666666666667, 45.5, 1.0, 2.0, 0.6326383058549737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 809255.5995718925, 809255.5995718925, 166553.0525502829], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 33000.0000, 
sim time next is 33600.0000, 
raw observation next is [24.63333333333334, 45.0, 1.0, 2.0, 0.676406552488862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 864387.051537312, 864387.0515373115, 174728.8751910382], 
processed observation next is [1.0, 0.391304347826087, 0.4679012345679015, 0.45, 1.0, 1.0, 0.6147697053438832, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3087096612633257, 0.30870966126332555, 0.3360170676750735], 
reward next is 0.6640, 
noisyNet noise sample is [array([-0.41717836], dtype=float32), -0.685987]. 
=============================================
[2019-04-27 20:33:31,844] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.6934652e-21 1.0000000e+00 1.9537627e-24 4.2303013e-13 5.2121983e-21], sum to 1.0000
[2019-04-27 20:33:31,857] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4684
[2019-04-27 20:33:31,860] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.11666666666667, 76.16666666666667, 1.0, 2.0, 0.4539934868595846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 563732.5779177318, 563732.5779177318, 136511.7569416787], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 97800.0000, 
sim time next is 98400.0000, 
raw observation next is [22.03333333333333, 76.33333333333334, 1.0, 2.0, 0.4162664216086311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 517322.1323777921, 517322.1323777917, 130968.0306738157], 
processed observation next is [1.0, 0.13043478260869565, 0.37160493827160485, 0.7633333333333334, 1.0, 1.0, 0.30507907334360845, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18475790442064002, 0.18475790442063988, 0.2518615974496456], 
reward next is 0.7481, 
noisyNet noise sample is [array([1.0030681], dtype=float32), 0.74749243]. 
=============================================
[2019-04-27 20:33:32,072] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.6255863e-26 1.0000000e+00 1.2861573e-31 2.2417163e-18 2.3729308e-27], sum to 1.0000
[2019-04-27 20:33:32,081] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2774
[2019-04-27 20:33:32,091] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 65.0, 1.0, 2.0, 0.4260724219117081, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 522518.6557235957, 522518.6557235957, 132219.0752668787], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 82800.0000, 
sim time next is 83400.0000, 
raw observation next is [24.68333333333333, 65.5, 1.0, 2.0, 0.42637734689497, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 523054.8940471189, 523054.8940471189, 132267.6628994296], 
processed observation next is [1.0, 1.0, 0.46975308641975294, 0.655, 1.0, 1.0, 0.3171158891606785, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18680531930254246, 0.18680531930254246, 0.2543608901912108], 
reward next is 0.7456, 
noisyNet noise sample is [array([-0.3579663], dtype=float32), -0.14928237]. 
=============================================
[2019-04-27 20:33:33,223] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2210739e-21 1.0000000e+00 5.6879864e-25 3.6394617e-15 4.7307537e-23], sum to 1.0000
[2019-04-27 20:33:33,230] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5256
[2019-04-27 20:33:33,234] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.2, 77.0, 1.0, 2.0, 0.3867931238494923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 485114.1888441486, 485114.1888441486, 126887.3677155409], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 103800.0000, 
sim time next is 104400.0000, 
raw observation next is [21.1, 77.0, 1.0, 2.0, 0.3757296254574978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 471806.1999414878, 471806.1999414878, 125371.2698195949], 
processed observation next is [1.0, 0.21739130434782608, 0.3370370370370371, 0.77, 1.0, 1.0, 0.25682098268749737, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16850221426481707, 0.16850221426481707, 0.24109859580691329], 
reward next is 0.7589, 
noisyNet noise sample is [array([-1.9915144], dtype=float32), 0.296328]. 
=============================================
[2019-04-27 20:33:34,386] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.6908003e-28 1.0000000e+00 9.5092396e-34 1.6233535e-21 8.7526481e-32], sum to 1.0000
[2019-04-27 20:33:34,392] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0271
[2019-04-27 20:33:34,397] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.33333333333334, 13.0, 1.0, 2.0, 0.3744037703406473, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 482985.013067246, 482985.013067246, 125198.76485877], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 156000.0000, 
sim time next is 156600.0000, 
raw observation next is [33.05, 13.5, 1.0, 2.0, 0.3714191872577372, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 479147.3829352708, 479147.3829352704, 124517.8099618375], 
processed observation next is [1.0, 0.8260869565217391, 0.7796296296296296, 0.135, 1.0, 1.0, 0.2516895086401633, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17112406533402527, 0.17112406533402513, 0.23945732684968749], 
reward next is 0.7605, 
noisyNet noise sample is [array([0.06098629], dtype=float32), -1.5217035]. 
=============================================
[2019-04-27 20:33:35,060] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.5471118e-28 1.0000000e+00 3.1159889e-31 7.4109637e-22 6.1044682e-30], sum to 1.0000
[2019-04-27 20:33:35,067] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0144
[2019-04-27 20:33:35,072] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.21666666666667, 35.66666666666666, 1.0, 2.0, 0.3159580041047877, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 405679.3099143423, 405679.3099143418, 117568.8320970916], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 330600.0000, 
sim time next is 331200.0000, 
raw observation next is [26.1, 36.0, 1.0, 2.0, 0.3146857426640555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 404141.7012999707, 404141.7012999707, 117407.7417048088], 
processed observation next is [0.0, 0.8695652173913043, 0.5222222222222223, 0.36, 1.0, 1.0, 0.18414969364768516, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14433632189284668, 0.14433632189284668, 0.22578411866309384], 
reward next is 0.7742, 
noisyNet noise sample is [array([-1.0185639], dtype=float32), 0.30608654]. 
=============================================
[2019-04-27 20:33:35,223] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.4105099e-19 1.0000000e+00 7.1181381e-23 7.7774430e-15 1.2941472e-20], sum to 1.0000
[2019-04-27 20:33:35,230] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4010
[2019-04-27 20:33:35,235] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.7, 51.0, 1.0, 2.0, 0.3360650690401358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 424937.752278861, 424937.752278861, 120120.6976543885], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 607200.0000, 
sim time next is 607800.0000, 
raw observation next is [24.55, 51.5, 1.0, 2.0, 0.3341991769342739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 422794.366228377, 422794.3662283766, 119880.853147273], 
processed observation next is [1.0, 0.0, 0.46481481481481485, 0.515, 1.0, 1.0, 0.2073799725408023, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15099798793870606, 0.15099798793870592, 0.23054010220629423], 
reward next is 0.7695, 
noisyNet noise sample is [array([0.10068811], dtype=float32), -0.659343]. 
=============================================
[2019-04-27 20:33:38,885] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.6681830e-28 1.0000000e+00 8.8991006e-32 1.2761986e-21 1.7383361e-31], sum to 1.0000
[2019-04-27 20:33:38,891] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2120
[2019-04-27 20:33:38,897] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.36666666666667, 13.66666666666667, 1.0, 2.0, 0.3782787623170034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 487123.8338677238, 487123.8338677238, 125785.6340415473], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 225600.0000, 
sim time next is 226200.0000, 
raw observation next is [33.38333333333333, 13.83333333333333, 1.0, 2.0, 0.379568129455126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 488537.4932761791, 488537.4932761791, 125964.8874467357], 
processed observation next is [0.0, 0.6086956521739131, 0.7919753086419753, 0.1383333333333333, 1.0, 1.0, 0.26139063030372145, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17447767617006396, 0.17447767617006396, 0.2422401681667994], 
reward next is 0.7578, 
noisyNet noise sample is [array([0.03123618], dtype=float32), -0.85168916]. 
=============================================
[2019-04-27 20:33:47,269] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.9040164e-12 9.9461246e-01 2.9173989e-17 5.3032837e-03 8.4353625e-05], sum to 1.0000
[2019-04-27 20:33:47,278] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0857
[2019-04-27 20:33:47,287] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.31666666666667, 29.5, 1.0, 2.0, 0.8409203877117951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1074523.13678014, 1074523.13678014, 208521.3027725562], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 384600.0000, 
sim time next is 385200.0000, 
raw observation next is [28.5, 29.0, 1.0, 2.0, 0.8237641360003205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1052438.14018638, 1052438.14018638, 204771.2444846189], 
processed observation next is [1.0, 0.4782608695652174, 0.6111111111111112, 0.29, 1.0, 1.0, 0.7901954000003816, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3758707643522785, 0.3758707643522785, 0.39379085477811326], 
reward next is 0.6062, 
noisyNet noise sample is [array([0.3119867], dtype=float32), 0.89770675]. 
=============================================
[2019-04-27 20:33:48,954] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.19840350e-15 9.99898911e-01 1.20113333e-19 1.01042795e-04
 9.06681452e-10], sum to 1.0000
[2019-04-27 20:33:48,962] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0553
[2019-04-27 20:33:48,969] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.46666666666667, 26.66666666666667, 1.0, 2.0, 0.2801065090053537, 1.0, 1.0, 0.2801065090053537, 1.0, 1.0, 0.4717394198714237, 6.9112, 6.9112, 121.94756008, 1052942.231547944, 1052942.231547944, 245562.8015574537], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 390000.0000, 
sim time next is 390600.0000, 
raw observation next is [29.6, 26.5, 1.0, 2.0, 0.7704109525557228, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260425542799, 977337.0465694506, 977337.0465694506, 193401.1607836204], 
processed observation next is [1.0, 0.5217391304347826, 0.6518518518518519, 0.265, 1.0, 1.0, 0.7266797054234795, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.809462128412624, 0.3490489452033752, 0.3490489452033752, 0.37192530919927], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.38020056], dtype=float32), 2.694684]. 
=============================================
[2019-04-27 20:33:50,528] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.2008066e-31 1.0000000e+00 3.8379121e-38 1.6741973e-25 6.5624010e-35], sum to 1.0000
[2019-04-27 20:33:50,542] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3646
[2019-04-27 20:33:50,549] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.9, 29.0, 1.0, 2.0, 0.3528843012926106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 446919.7624988323, 446919.7624988323, 122338.1699310382], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 410400.0000, 
sim time next is 411000.0000, 
raw observation next is [29.75, 29.33333333333334, 1.0, 2.0, 0.3514688201716045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 445291.652077164, 445291.6520771636, 122151.7059458758], 
processed observation next is [1.0, 0.782608695652174, 0.6574074074074074, 0.2933333333333334, 1.0, 1.0, 0.22793907163286253, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15903273288470143, 0.1590327328847013, 0.23490712681899192], 
reward next is 0.7651, 
noisyNet noise sample is [array([-0.47161606], dtype=float32), 1.2936372]. 
=============================================
[2019-04-27 20:33:50,562] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[83.84417 ]
 [83.93957 ]
 [83.62967 ]
 [83.933846]
 [82.908905]], R is [[83.97939301]
 [83.90433502]
 [83.83003998]
 [83.75619507]
 [83.6827774 ]].
[2019-04-27 20:33:53,633] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.9454024e-15 1.0000000e+00 8.4571806e-18 2.9027145e-09 3.6118629e-11], sum to 1.0000
[2019-04-27 20:33:53,640] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6727
[2019-04-27 20:33:53,647] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1373293.683159265 W.
[2019-04-27 20:33:53,652] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.05, 40.5, 1.0, 2.0, 0.936479655595171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.307614768804655, 6.9112, 121.9241946761607, 1373293.683159265, 1170296.967093441, 230015.262266746], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 469800.0000, 
sim time next is 470400.0000, 
raw observation next is [28.36666666666667, 39.66666666666667, 1.0, 2.0, 0.491015090791367, 1.0, 1.0, 0.491015090791367, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.925803857235, 1206446.872335939, 1206446.872335939, 236009.7642716559], 
processed observation next is [1.0, 0.43478260869565216, 0.606172839506173, 0.3966666666666667, 1.0, 1.0, 0.394065584275437, 1.0, 0.5, 0.394065584275437, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094605437124732, 0.43087388297712104, 0.43087388297712104, 0.45386493129164596], 
reward next is 0.5461, 
noisyNet noise sample is [array([-0.6420718], dtype=float32), 0.53519946]. 
=============================================
[2019-04-27 20:33:56,921] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-04-27 20:33:56,925] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 20:33:56,926] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:33:56,928] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 20:33:56,930] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:33:56,931] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 20:33:56,931] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 20:33:56,932] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:33:56,932] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 20:33:56,933] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:33:56,934] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:33:56,943] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run61
[2019-04-27 20:33:56,943] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run61
[2019-04-27 20:33:56,986] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run61
[2019-04-27 20:33:57,014] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run61
[2019-04-27 20:33:57,014] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run61
[2019-04-27 20:34:22,353] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.118428774]
[2019-04-27 20:34:22,354] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.91775410166667, 77.77978829, 1.0, 2.0, 0.505116943933209, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 633737.5612794467, 633737.5612794467, 144563.6015799297]
[2019-04-27 20:34:22,358] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 20:34:22,360] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.1884443e-24 1.0000000e+00 9.6940104e-28 2.6855506e-20 2.5737085e-28], sampled 0.9245249249085623
[2019-04-27 20:34:27,507] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.118428774]
[2019-04-27 20:34:27,508] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.66666666666667, 55.83333333333333, 1.0, 2.0, 0.3834072655836567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 474993.2502061077, 474993.2502061072, 126304.6305825823]
[2019-04-27 20:34:27,509] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 20:34:27,511] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.1506336e-27 1.0000000e+00 4.9410391e-31 9.1606391e-23 9.4463396e-32], sampled 0.32077885397179795
[2019-04-27 20:34:59,069] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.118428774]
[2019-04-27 20:34:59,069] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.665620325, 79.63046762666667, 1.0, 2.0, 0.5691528362096295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 660737.4062764999, 660737.4062764999, 153430.2809824882]
[2019-04-27 20:34:59,072] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 20:34:59,076] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.5412202e-24 1.0000000e+00 6.2334287e-28 1.9804956e-20 1.6302111e-28], sampled 0.4215351220697855
[2019-04-27 20:35:27,197] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.118428774]
[2019-04-27 20:35:27,198] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.07588551166667, 75.80889362333333, 1.0, 2.0, 0.799504826911402, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 911276.7519075141, 911276.7519075141, 195851.6294779582]
[2019-04-27 20:35:27,199] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 20:35:27,204] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.5613409e-26 1.0000000e+00 5.2839445e-30 5.6364155e-22 1.2546351e-30], sampled 0.08236544971334225
[2019-04-27 20:35:33,668] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.118428774]
[2019-04-27 20:35:33,669] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.20914793, 62.84355722833333, 1.0, 2.0, 0.4163129416010904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 510946.1992113128, 510946.1992113128, 130821.4937290222]
[2019-04-27 20:35:33,670] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 20:35:33,671] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.7274005e-26 1.0000000e+00 3.6681882e-30 3.6640635e-22 6.5707811e-31], sampled 0.14617676947897307
[2019-04-27 20:35:38,732] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.118428774]
[2019-04-27 20:35:38,733] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.910087405, 73.96995706499999, 1.0, 2.0, 0.7652353196067367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 872194.0916352654, 872194.0916352654, 188857.6964841118]
[2019-04-27 20:35:38,734] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 20:35:38,737] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.1392421e-23 1.0000000e+00 6.3367895e-27 1.3370787e-19 2.2342617e-27], sampled 0.8466407058341385
[2019-04-27 20:35:45,971] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.118428774]
[2019-04-27 20:35:45,972] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.63333333333334, 77.33333333333334, 1.0, 2.0, 0.4187023381481245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 515286.7629207319, 515286.7629207314, 131201.046386016]
[2019-04-27 20:35:45,973] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 20:35:45,976] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.4077752e-26 1.0000000e+00 1.3583712e-29 9.1505502e-22 2.5073911e-30], sampled 0.11865702364529529
[2019-04-27 20:35:46,442] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8581.2410 2248887715.3409 553.0000
[2019-04-27 20:35:46,465] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8768.6241 2170826060.4938 493.0000
[2019-04-27 20:35:46,538] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8698.5544 2195342049.7036 572.0000
[2019-04-27 20:35:46,665] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8921.1042 2120720379.3876 430.0000
[2019-04-27 20:35:46,674] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8096.9038 2445628494.3108 746.0000
[2019-04-27 20:35:47,693] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1500000, evaluation results [1500000.0, 8096.903836826734, 2445628494.3108454, 746.0, 8768.624117554622, 2170826060.49376, 493.0, 8921.104228266262, 2120720379.387646, 430.0, 8581.240965317736, 2248887715.34094, 553.0, 8698.554408555452, 2195342049.703552, 572.0]
[2019-04-27 20:35:54,936] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0306758e-33 1.0000000e+00 1.4147571e-38 2.7246915e-27 0.0000000e+00], sum to 1.0000
[2019-04-27 20:35:54,945] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4575
[2019-04-27 20:35:54,951] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.3, 31.0, 1.0, 2.0, 0.3501385986089117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 443560.777992088, 443560.777992088, 121974.9871829955], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 684000.0000, 
sim time next is 684600.0000, 
raw observation next is [29.11666666666667, 31.66666666666667, 1.0, 2.0, 0.3472202209935241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 439815.1522518914, 439815.1522518914, 121588.7619775265], 
processed observation next is [1.0, 0.9565217391304348, 0.6339506172839507, 0.3166666666666667, 1.0, 1.0, 0.2228812154684811, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1570768400899612, 0.1570768400899612, 0.23382454226447405], 
reward next is 0.7662, 
noisyNet noise sample is [array([0.37703377], dtype=float32), -0.06418779]. 
=============================================
[2019-04-27 20:35:57,048] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.9680740e-23 1.0000000e+00 1.8191125e-26 9.4756312e-20 1.7424094e-27], sum to 1.0000
[2019-04-27 20:35:57,060] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3622
[2019-04-27 20:35:57,065] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 53.66666666666667, 1.0, 2.0, 0.3584681859608675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 457978.5643456761, 457978.5643456761, 123106.2769067973], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 711600.0000, 
sim time next is 712200.0000, 
raw observation next is [23.2, 53.83333333333333, 1.0, 2.0, 0.3565618619418943, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 455046.8842745315, 455046.8842745315, 122850.0301790194], 
processed observation next is [1.0, 0.21739130434782608, 0.4148148148148148, 0.5383333333333333, 1.0, 1.0, 0.23400221659749323, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16251674438376126, 0.16251674438376126, 0.23625005803657578], 
reward next is 0.7637, 
noisyNet noise sample is [array([-1.1890482], dtype=float32), 0.245965]. 
=============================================
[2019-04-27 20:35:57,131] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.6631285e-18 1.0000000e+00 2.5353712e-22 7.0462169e-13 7.7790410e-16], sum to 1.0000
[2019-04-27 20:35:57,142] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7676
[2019-04-27 20:35:57,147] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.56666666666667, 53.0, 1.0, 2.0, 0.8104838671208588, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260425503564, 1007347.704311884, 1007347.704311885, 201499.0174640816], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 724800.0000, 
sim time next is 725400.0000, 
raw observation next is [25.7, 53.0, 1.0, 2.0, 0.8085304530192357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156419, 1006643.503186435, 1006643.503186435, 201122.2595502139], 
processed observation next is [1.0, 0.391304347826087, 0.5074074074074074, 0.53, 1.0, 1.0, 0.7720600631181377, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288200039, 0.3595155368522982, 0.3595155368522982, 0.38677357605810364], 
reward next is 0.6132, 
noisyNet noise sample is [array([0.78906953], dtype=float32), -0.09120663]. 
=============================================
[2019-04-27 20:35:59,888] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.8018031e-36 1.0000000e+00 0.0000000e+00 3.9564307e-32 0.0000000e+00], sum to 1.0000
[2019-04-27 20:35:59,895] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4105
[2019-04-27 20:35:59,902] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.53333333333333, 39.5, 1.0, 2.0, 0.3137228885461306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 399090.184398965, 399090.184398965, 117282.517355739], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 774600.0000, 
sim time next is 775200.0000, 
raw observation next is [26.36666666666667, 40.0, 1.0, 2.0, 0.3116794752786375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 396646.2641832416, 396646.2641832416, 117026.3011513787], 
processed observation next is [1.0, 1.0, 0.5320987654320989, 0.4, 1.0, 1.0, 0.18057080390313987, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14165938006544343, 0.14165938006544343, 0.22505057913726675], 
reward next is 0.7749, 
noisyNet noise sample is [array([-0.73340386], dtype=float32), 0.9481115]. 
=============================================
[2019-04-27 20:36:04,310] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.8266656e-32 1.0000000e+00 1.2531144e-37 2.0547357e-28 1.6244630e-35], sum to 1.0000
[2019-04-27 20:36:04,319] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5525
[2019-04-27 20:36:04,325] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.83333333333334, 55.0, 1.0, 2.0, 0.4007074542806749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 496280.7489411772, 496280.7489411772, 128714.1709372753], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 859200.0000, 
sim time next is 859800.0000, 
raw observation next is [25.66666666666666, 56.0, 1.0, 2.0, 0.4029223144603589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 498866.4382114506, 498866.4382114506, 129023.3136083342], 
processed observation next is [0.0, 0.9565217391304348, 0.5061728395061726, 0.56, 1.0, 1.0, 0.2891932315004273, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17816658507551808, 0.17816658507551808, 0.2481217569391042], 
reward next is 0.7519, 
noisyNet noise sample is [array([0.64147264], dtype=float32), 0.16053194]. 
=============================================
[2019-04-27 20:36:06,477] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.9034266e-32 1.0000000e+00 5.1620775e-36 1.6628017e-28 4.5423442e-37], sum to 1.0000
[2019-04-27 20:36:06,484] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5205
[2019-04-27 20:36:06,489] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.45, 64.66666666666667, 1.0, 2.0, 0.3826147677718219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 477617.58263286, 477617.58263286, 126269.7850799687], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 868200.0000, 
sim time next is 868800.0000, 
raw observation next is [23.3, 65.33333333333334, 1.0, 2.0, 0.3813466816399761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 476272.3008159588, 476272.3008159588, 126099.3659897173], 
processed observation next is [0.0, 0.043478260869565216, 0.41851851851851857, 0.6533333333333334, 1.0, 1.0, 0.2635079543333049, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17009725029141387, 0.17009725029141387, 0.24249878074945636], 
reward next is 0.7575, 
noisyNet noise sample is [array([-0.18695214], dtype=float32), -0.7876223]. 
=============================================
[2019-04-27 20:36:12,525] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.1635373e-20 1.0000000e+00 2.2660165e-23 3.6424080e-14 2.2709438e-20], sum to 1.0000
[2019-04-27 20:36:12,534] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0759
[2019-04-27 20:36:12,538] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 68.0, 1.0, 2.0, 0.7330785276424029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 924842.8634783081, 924842.8634783076, 185724.3367977001], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1177200.0000, 
sim time next is 1177800.0000, 
raw observation next is [21.83333333333333, 68.5, 1.0, 2.0, 0.6596437671107611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 832139.2166320868, 832139.2166320868, 171469.0875671291], 
processed observation next is [1.0, 0.6521739130434783, 0.36419753086419737, 0.685, 1.0, 1.0, 0.5948140084651918, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29719257736860244, 0.29719257736860244, 0.3297482453214021], 
reward next is 0.6703, 
noisyNet noise sample is [array([-0.03447807], dtype=float32), 0.7461001]. 
=============================================
[2019-04-27 20:36:13,334] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.9435641e-28 1.0000000e+00 4.1004509e-33 1.2336348e-22 2.4604946e-33], sum to 1.0000
[2019-04-27 20:36:13,343] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3972
[2019-04-27 20:36:13,346] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.88333333333334, 50.0, 1.0, 2.0, 0.3406292852797939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 430812.020818318, 430812.020818318, 120716.5792071436], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1471800.0000, 
sim time next is 1472400.0000, 
raw observation next is [24.6, 51.0, 1.0, 2.0, 0.3372560567729525, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 426893.7490251196, 426893.7490251191, 120280.1290462655], 
processed observation next is [0.0, 0.043478260869565216, 0.46666666666666673, 0.51, 1.0, 1.0, 0.21101911520589584, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15246205322325698, 0.15246205322325682, 0.2313079404735875], 
reward next is 0.7687, 
noisyNet noise sample is [array([1.6787513], dtype=float32), -0.39470035]. 
=============================================
[2019-04-27 20:36:15,595] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.5223512e-24 1.0000000e+00 4.8829091e-26 3.2136193e-20 2.5954991e-27], sum to 1.0000
[2019-04-27 20:36:15,608] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7457
[2019-04-27 20:36:15,613] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333333, 71.33333333333334, 1.0, 2.0, 0.3182387287525402, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 406278.9636301027, 406278.9636301022, 117859.2349278032], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1053600.0000, 
sim time next is 1054200.0000, 
raw observation next is [20.26666666666667, 71.66666666666666, 1.0, 2.0, 0.312073112548416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 398497.7701074292, 398497.7701074292, 117080.923247401], 
processed observation next is [1.0, 0.17391304347826086, 0.3061728395061729, 0.7166666666666666, 1.0, 1.0, 0.18103941970049525, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1423206321812247, 0.1423206321812247, 0.22515562162961733], 
reward next is 0.7748, 
noisyNet noise sample is [array([0.6115379], dtype=float32), -0.3564235]. 
=============================================
[2019-04-27 20:36:19,981] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.8271517e-34 1.0000000e+00 0.0000000e+00 2.0599021e-33 0.0000000e+00], sum to 1.0000
[2019-04-27 20:36:19,996] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4343
[2019-04-27 20:36:20,000] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.26666666666667, 68.33333333333334, 1.0, 2.0, 0.320238882137346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 406811.75589362, 406811.75589362, 118103.6145758228], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1111200.0000, 
sim time next is 1111800.0000, 
raw observation next is [21.13333333333333, 68.66666666666666, 1.0, 2.0, 0.317337544319592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 403462.0314744873, 403462.0314744873, 117737.6996696451], 
processed observation next is [1.0, 0.8695652173913043, 0.33827160493827146, 0.6866666666666665, 1.0, 1.0, 0.18730660038046665, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14409358266945974, 0.14409358266945974, 0.22641865321085594], 
reward next is 0.7736, 
noisyNet noise sample is [array([-1.8134257], dtype=float32), -1.7450877]. 
=============================================
[2019-04-27 20:36:29,465] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4863068e-21 1.0000000e+00 8.4600224e-25 1.5243693e-16 8.6769332e-21], sum to 1.0000
[2019-04-27 20:36:29,473] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1236
[2019-04-27 20:36:29,478] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.05, 73.0, 1.0, 2.0, 0.7506458070916131, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 926070.9052026729, 926070.9052026729, 188842.2717063745], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1758600.0000, 
sim time next is 1759200.0000, 
raw observation next is [23.16666666666666, 72.66666666666667, 1.0, 2.0, 0.7464334993573952, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 919915.7682511035, 919915.768251103, 187962.6898719355], 
processed observation next is [1.0, 0.34782608695652173, 0.41358024691358003, 0.7266666666666667, 1.0, 1.0, 0.6981351182826133, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.32854134580396555, 0.3285413458039654, 0.36146671129218366], 
reward next is 0.6385, 
noisyNet noise sample is [array([-1.2801499], dtype=float32), -0.60590124]. 
=============================================
[2019-04-27 20:36:31,518] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.4203548e-24 1.0000000e+00 8.2894582e-26 7.8209609e-17 1.5364267e-21], sum to 1.0000
[2019-04-27 20:36:31,529] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2372
[2019-04-27 20:36:31,537] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1328696.181427162 W.
[2019-04-27 20:36:31,540] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.2, 40.5, 1.0, 2.0, 0.9343088073849283, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.243687855128421, 6.9112, 121.9246277016174, 1328696.181427162, 1158434.658029426, 229279.6984393071], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1338600.0000, 
sim time next is 1339200.0000, 
raw observation next is [28.4, 40.0, 1.0, 2.0, 0.5074322077521921, 1.0, 1.0, 0.5074322077521921, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9258423972982, 1244847.316728402, 1244847.316728402, 241151.2715946382], 
processed observation next is [1.0, 0.5217391304347826, 0.6074074074074074, 0.4, 1.0, 1.0, 0.413609771133562, 1.0, 0.5, 0.413609771133562, 0.0, 1.0, -0.25, 0.0, 0.0, 0.809460799578414, 0.4445883274030007, 0.4445883274030007, 0.46375244537430427], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.61025083], dtype=float32), 0.16248792]. 
=============================================
[2019-04-27 20:36:33,962] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2646075e-27 1.0000000e+00 4.6813104e-32 9.3272113e-24 3.2546700e-32], sum to 1.0000
[2019-04-27 20:36:33,974] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7466
[2019-04-27 20:36:33,980] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 74.66666666666667, 1.0, 2.0, 0.3849497485639278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 480758.9306342684, 480758.9306342684, 126596.6817153714], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1561200.0000, 
sim time next is 1561800.0000, 
raw observation next is [21.8, 75.33333333333333, 1.0, 2.0, 0.3845454231739961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 480284.6345435274, 480284.6345435269, 126541.2990701588], 
processed observation next is [1.0, 0.043478260869565216, 0.362962962962963, 0.7533333333333333, 1.0, 1.0, 0.267315979969043, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17153022662268835, 0.1715302266226882, 0.2433486520579977], 
reward next is 0.7567, 
noisyNet noise sample is [array([-0.03883245], dtype=float32), -0.6793171]. 
=============================================
[2019-04-27 20:36:39,526] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-04-27 20:36:39,527] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 20:36:39,527] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:36:39,528] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 20:36:39,528] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 20:36:39,529] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:36:39,529] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:36:39,529] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 20:36:39,530] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 20:36:39,533] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:36:39,534] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:36:39,558] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run62
[2019-04-27 20:36:39,582] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run62
[2019-04-27 20:36:39,583] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run62
[2019-04-27 20:36:39,584] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run62
[2019-04-27 20:36:39,647] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run62
[2019-04-27 20:36:58,438] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12190489]
[2019-04-27 20:36:58,440] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.3, 59.5, 1.0, 2.0, 0.774234865550613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 986211.0402010479, 986211.0402010474, 194228.5056251161]
[2019-04-27 20:36:58,441] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 20:36:58,445] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.2077830e-29 1.0000000e+00 3.8304769e-33 5.9290273e-25 1.3713999e-34], sampled 0.013671878453458741
[2019-04-27 20:37:10,418] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12190489]
[2019-04-27 20:37:10,421] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.852015325, 76.278705605, 1.0, 2.0, 0.4456890280991688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 541348.2285895598, 541348.2285895598, 134951.783390805]
[2019-04-27 20:37:10,422] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 20:37:10,426] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.7398824e-31 1.0000000e+00 2.8165809e-35 1.9815021e-26 9.4679249e-37], sampled 0.33663350584469154
[2019-04-27 20:38:27,912] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8768.6241 2170826060.4938 493.0000
[2019-04-27 20:38:28,398] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8097.6795 2445569542.8369 746.0000
[2019-04-27 20:38:28,411] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8921.8922 2120660928.3939 430.0000
[2019-04-27 20:38:28,546] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8699.3424 2195282598.7024 572.0000
[2019-04-27 20:38:28,584] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8581.2410 2248887715.3409 553.0000
[2019-04-27 20:38:29,601] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1525000, evaluation results [1525000.0, 8097.679510568991, 2445569542.8369265, 746.0, 8768.624117554622, 2170826060.49376, 493.0, 8921.892236157437, 2120660928.3938506, 430.0, 8581.240965317736, 2248887715.34094, 553.0, 8699.342416479873, 2195282598.702448, 572.0]
[2019-04-27 20:38:34,063] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.1339897e-27 1.0000000e+00 6.9544691e-30 7.8912129e-23 5.7940312e-30], sum to 1.0000
[2019-04-27 20:38:34,071] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1574
[2019-04-27 20:38:34,075] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.86666666666667, 88.66666666666667, 1.0, 2.0, 0.3628439515022747, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 454281.8495337713, 454281.8495337713, 123600.6785421771], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1745400.0000, 
sim time next is 1746000.0000, 
raw observation next is [19.8, 89.0, 1.0, 2.0, 0.3603857028667307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 451356.6497012962, 451356.6497012962, 123273.1118447614], 
processed observation next is [1.0, 0.21739130434782608, 0.2888888888888889, 0.89, 1.0, 1.0, 0.23855440817467943, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16119880346474863, 0.16119880346474863, 0.23706367662454114], 
reward next is 0.7629, 
noisyNet noise sample is [array([-1.3229624], dtype=float32), 0.6126533]. 
=============================================
[2019-04-27 20:38:34,092] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[71.594986]
 [71.618866]
 [71.64302 ]
 [71.697845]
 [71.778496]], R is [[71.6151886 ]
 [71.66134644]
 [71.7067337 ]
 [71.75085449]
 [71.79309845]].
[2019-04-27 20:38:34,951] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.5889900e-26 1.0000000e+00 2.5986753e-30 9.1236426e-22 2.0664615e-30], sum to 1.0000
[2019-04-27 20:38:34,962] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2013
[2019-04-27 20:38:34,965] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.8, 75.33333333333333, 1.0, 2.0, 0.3845454231739961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 480284.6345435274, 480284.6345435269, 126541.2990701588], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1561800.0000, 
sim time next is 1562400.0000, 
raw observation next is [21.7, 76.0, 1.0, 2.0, 0.3840485144116421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 479699.6430867161, 479699.6430867161, 126473.2350892989], 
processed observation next is [1.0, 0.08695652173913043, 0.3592592592592592, 0.76, 1.0, 1.0, 0.26672442191862156, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17132130110239863, 0.17132130110239863, 0.24321775978711327], 
reward next is 0.7568, 
noisyNet noise sample is [array([-0.5280281], dtype=float32), 1.0869691]. 
=============================================
[2019-04-27 20:38:39,723] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0436233e-21 1.0000000e+00 1.3166623e-24 3.1674141e-16 2.6608574e-24], sum to 1.0000
[2019-04-27 20:38:39,729] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6011
[2019-04-27 20:38:39,734] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 89.33333333333333, 1.0, 2.0, 0.6728236960120794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 788074.2075355757, 788074.2075355753, 172076.5350864086], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2180400.0000, 
sim time next is 2181000.0000, 
raw observation next is [23.95, 89.16666666666667, 1.0, 2.0, 0.6766847625584228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 792147.9657667733, 792147.9657667733, 172777.6927888496], 
processed observation next is [1.0, 0.21739130434782608, 0.4425925925925926, 0.8916666666666667, 1.0, 1.0, 0.6151009078076461, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2829099877738476, 0.2829099877738476, 0.3322647938247108], 
reward next is 0.6677, 
noisyNet noise sample is [array([-0.08699919], dtype=float32), -1.7979637]. 
=============================================
[2019-04-27 20:38:39,752] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[56.804085]
 [57.009235]
 [57.203476]
 [57.547867]
 [57.828873]], R is [[56.72260284]
 [56.82445908]
 [56.92991257]
 [57.03240204]
 [57.11924744]].
[2019-04-27 20:38:47,414] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.2371933e-30 1.0000000e+00 4.4216525e-33 2.9708251e-24 3.5118383e-34], sum to 1.0000
[2019-04-27 20:38:47,423] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2044
[2019-04-27 20:38:47,429] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.68333333333333, 87.83333333333334, 1.0, 2.0, 0.3172280644040283, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 403239.4775545163, 403239.4775545163, 117723.4198759763], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1810200.0000, 
sim time next is 1810800.0000, 
raw observation next is [18.7, 88.0, 1.0, 2.0, 0.317639069271565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 403607.0220586109, 403607.0220586109, 117774.4513529494], 
processed observation next is [1.0, 1.0, 0.24814814814814812, 0.88, 1.0, 1.0, 0.187665558656625, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14414536502093248, 0.14414536502093248, 0.2264893295249027], 
reward next is 0.7735, 
noisyNet noise sample is [array([-1.1612866], dtype=float32), 1.6587714]. 
=============================================
[2019-04-27 20:38:52,446] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3017079e-27 1.0000000e+00 6.2786639e-32 4.7657552e-20 6.6107228e-26], sum to 1.0000
[2019-04-27 20:38:52,454] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9435
[2019-04-27 20:38:52,458] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.56666666666667, 87.33333333333334, 1.0, 2.0, 0.7664963847689765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260425692793, 938519.2160332879, 938519.2160332884, 191878.2307800898], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1873200.0000, 
sim time next is 1873800.0000, 
raw observation next is [21.55, 87.5, 1.0, 2.0, 0.7640994011766364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156477, 935644.0195044762, 935644.0195044762, 191388.0239328518], 
processed observation next is [1.0, 0.6956521739130435, 0.35370370370370374, 0.875, 1.0, 1.0, 0.71916595378171, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288200423, 0.3341585783944558, 0.3341585783944558, 0.36805389217856116], 
reward next is 0.6319, 
noisyNet noise sample is [array([0.5428646], dtype=float32), -0.2238556]. 
=============================================
[2019-04-27 20:38:57,304] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.1099428e-25 1.0000000e+00 2.1424285e-30 3.9039010e-23 9.6590081e-30], sum to 1.0000
[2019-04-27 20:38:57,319] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6897
[2019-04-27 20:38:57,325] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.66666666666667, 78.33333333333333, 1.0, 2.0, 0.3081805303214837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 396365.0269854169, 396365.0269854169, 116587.7974385369], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2437800.0000, 
sim time next is 2438400.0000, 
raw observation next is [19.23333333333333, 75.66666666666667, 1.0, 2.0, 0.2861664021983515, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 367364.7699542817, 367364.7699542813, 113882.4203541325], 
processed observation next is [1.0, 0.21739130434782608, 0.26790123456790116, 0.7566666666666667, 1.0, 1.0, 0.15019809785518035, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1312017035551006, 0.13120170355510047, 0.21900465452717788], 
reward next is 0.7810, 
noisyNet noise sample is [array([0.0770416], dtype=float32), -0.97777367]. 
=============================================
[2019-04-27 20:38:59,737] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.0580372e-29 1.0000000e+00 9.8529087e-35 1.9609361e-26 5.8097585e-33], sum to 1.0000
[2019-04-27 20:38:59,744] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3431
[2019-04-27 20:38:59,751] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.25, 63.0, 1.0, 2.0, 0.551760029563327, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 643823.4212184617, 643823.4212184612, 150684.3592150132], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2039400.0000, 
sim time next is 2040000.0000, 
raw observation next is [28.3, 63.0, 1.0, 2.0, 0.5540502139519635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 645897.0565159271, 645897.0565159266, 151036.5534967503], 
processed observation next is [0.0, 0.6086956521739131, 0.6037037037037037, 0.63, 1.0, 1.0, 0.4691073975618613, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23067752018425966, 0.2306775201842595, 0.2904549105706737], 
reward next is 0.7095, 
noisyNet noise sample is [array([0.1765255], dtype=float32), 2.0872102]. 
=============================================
[2019-04-27 20:38:59,767] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[71.198166]
 [71.22192 ]
 [71.25152 ]
 [71.27096 ]
 [71.2427  ]], R is [[71.17176056]
 [71.1702652 ]
 [71.16953278]
 [71.16970062]
 [71.17089081]].
[2019-04-27 20:39:00,209] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.9348163e-30 1.0000000e+00 5.6451632e-33 2.3576587e-24 3.9656178e-32], sum to 1.0000
[2019-04-27 20:39:00,218] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1436
[2019-04-27 20:39:00,222] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.8, 84.0, 1.0, 2.0, 0.3722370767566662, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 464033.1602484185, 464033.1602484185, 124835.5308662179], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2012400.0000, 
sim time next is 2013000.0000, 
raw observation next is [20.91666666666667, 83.16666666666667, 1.0, 2.0, 0.373120185447367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 465047.9171999443, 465047.9171999443, 124954.0982908087], 
processed observation next is [0.0, 0.30434782608695654, 0.3302469135802471, 0.8316666666666667, 1.0, 1.0, 0.25371450648496074, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16608854185712296, 0.16608854185712296, 0.24029634286693982], 
reward next is 0.7597, 
noisyNet noise sample is [array([-1.2240841], dtype=float32), -0.20192394]. 
=============================================
[2019-04-27 20:39:00,234] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[72.06093 ]
 [72.0336  ]
 [72.0765  ]
 [72.11973 ]
 [72.156525]], R is [[72.07587433]
 [72.11505127]
 [72.15398407]
 [72.19278717]
 [72.23159027]].
[2019-04-27 20:39:03,124] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1328917e-33 1.0000000e+00 6.6039309e-37 3.6649469e-28 2.0717751e-36], sum to 1.0000
[2019-04-27 20:39:03,134] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5414
[2019-04-27 20:39:03,140] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.61666666666667, 94.5, 1.0, 2.0, 0.4207809699237333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 516439.5341104118, 516439.5341104113, 131464.2659939436], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2092200.0000, 
sim time next is 2092800.0000, 
raw observation next is [20.73333333333333, 94.0, 1.0, 2.0, 0.4223334168373572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 517898.7626031915, 517898.7626031915, 131676.5697465199], 
processed observation next is [0.0, 0.21739130434782608, 0.3234567901234567, 0.94, 1.0, 1.0, 0.31230168671113956, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1849638437868541, 0.1849638437868541, 0.25322417258946134], 
reward next is 0.7468, 
noisyNet noise sample is [array([-0.70349413], dtype=float32), 1.0792286]. 
=============================================
[2019-04-27 20:39:06,195] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6369715e-29 1.0000000e+00 2.7422936e-34 2.3141552e-26 1.1734719e-35], sum to 1.0000
[2019-04-27 20:39:06,203] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9967
[2019-04-27 20:39:06,211] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.36666666666667, 81.0, 1.0, 2.0, 0.5693743025814705, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 662907.6950306101, 662907.6950306101, 153553.3460403517], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2158800.0000, 
sim time next is 2159400.0000, 
raw observation next is [25.28333333333333, 81.5, 1.0, 2.0, 0.5687727720824777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 662337.8966197898, 662337.8966197898, 153458.1306126975], 
processed observation next is [0.0, 1.0, 0.49197530864197525, 0.815, 1.0, 1.0, 0.48663425247914005, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23654924879278205, 0.23654924879278205, 0.2951117896398029], 
reward next is 0.7049, 
noisyNet noise sample is [array([0.51139146], dtype=float32), 0.50858265]. 
=============================================
[2019-04-27 20:39:16,387] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1573276e-24 1.0000000e+00 3.6597777e-28 3.1075157e-22 8.1712411e-29], sum to 1.0000
[2019-04-27 20:39:16,395] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7563
[2019-04-27 20:39:16,402] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 95.0, 1.0, 2.0, 0.4907984438994214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 588096.0494287006, 588096.0494287001, 141555.0943661428], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2340000.0000, 
sim time next is 2340600.0000, 
raw observation next is [21.98333333333333, 95.16666666666667, 1.0, 2.0, 0.6879333448862882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 823968.0027519426, 823968.0027519426, 175662.571377764], 
processed observation next is [1.0, 0.08695652173913043, 0.36975308641975296, 0.9516666666666667, 1.0, 1.0, 0.6284920772455812, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29427428669712236, 0.29427428669712236, 0.33781263726493077], 
reward next is 0.6622, 
noisyNet noise sample is [array([3.0164995], dtype=float32), 0.13688076]. 
=============================================
[2019-04-27 20:39:17,140] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.4760201e-21 1.0000000e+00 5.0873151e-24 6.3359723e-18 1.7519313e-22], sum to 1.0000
[2019-04-27 20:39:17,147] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9680
[2019-04-27 20:39:17,155] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 96.0, 1.0, 2.0, 0.4835032768577763, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 581315.4868908126, 581315.4868908126, 140492.0714795557], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2348400.0000, 
sim time next is 2349000.0000, 
raw observation next is [21.65, 96.0, 1.0, 2.0, 0.478593651284369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 575630.0528226176, 575630.0528226176, 139742.716554148], 
processed observation next is [1.0, 0.17391304347826086, 0.35740740740740734, 0.96, 1.0, 1.0, 0.3792781562909155, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20558216172236343, 0.20558216172236343, 0.26873599337336157], 
reward next is 0.7313, 
noisyNet noise sample is [array([-0.37281165], dtype=float32), -0.94545615]. 
=============================================
[2019-04-27 20:39:17,169] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[52.72681 ]
 [52.626488]
 [53.072353]
 [53.194107]
 [53.425632]], R is [[52.97134399]
 [53.17145538]
 [53.34502411]
 [53.53959656]
 [53.72811508]].
[2019-04-27 20:39:19,206] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.6326905e-31 1.0000000e+00 4.3938229e-34 7.1244607e-25 9.2916825e-35], sum to 1.0000
[2019-04-27 20:39:19,214] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2531
[2019-04-27 20:39:19,224] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1367016.029650888 W.
[2019-04-27 20:39:19,228] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.01666666666667, 37.0, 1.0, 2.0, 0.5692897609884051, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9193192661457669, 6.911199999999999, 6.9112, 121.9260426156618, 1367016.029650888, 1367016.029650888, 280255.851275817], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2386200.0000, 
sim time next is 2386800.0000, 
raw observation next is [31.0, 37.0, 1.0, 2.0, 0.5851675339244277, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9465459531184386, 6.911200000000001, 6.9112, 121.9260426156618, 1409204.982817064, 1409204.982817064, 286079.82059335], 
processed observation next is [1.0, 0.6521739130434783, 0.7037037037037037, 0.37, 1.0, 1.0, 0.5061518261005091, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9331824413980483, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5032874938632371, 0.5032874938632371, 0.5501535011410577], 
reward next is 0.4498, 
noisyNet noise sample is [array([-0.5379039], dtype=float32), -0.014698979]. 
=============================================
[2019-04-27 20:39:21,589] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-04-27 20:39:21,593] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 20:39:21,595] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 20:39:21,595] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:39:21,596] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:39:21,596] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 20:39:21,597] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 20:39:21,598] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 20:39:21,599] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:39:21,602] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:39:21,601] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:39:21,629] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run63
[2019-04-27 20:39:21,652] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run63
[2019-04-27 20:39:21,653] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run63
[2019-04-27 20:39:21,672] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run63
[2019-04-27 20:39:21,717] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run63
[2019-04-27 20:39:36,870] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.121995375]
[2019-04-27 20:39:36,871] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.27635076333333, 54.84316949666668, 1.0, 2.0, 0.3067881411810411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 390747.6219916703, 390747.6219916703, 116415.7909126153]
[2019-04-27 20:39:36,872] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 20:39:36,874] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.2572022e-28 1.0000000e+00 4.9797326e-32 2.7918541e-24 2.8546063e-32], sampled 0.8686758482134559
[2019-04-27 20:39:41,185] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.121995375]
[2019-04-27 20:39:41,187] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.8, 86.0, 1.0, 2.0, 0.3914779672959464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 486229.6669977697, 486229.6669977697, 127450.6675199662]
[2019-04-27 20:39:41,190] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 20:39:41,192] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.3482372e-29 1.0000000e+00 3.6763215e-33 3.9012325e-25 2.1281462e-33], sampled 0.011213869042329239
[2019-04-27 20:40:01,357] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.121995375]
[2019-04-27 20:40:01,358] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.13333333333333, 89.66666666666667, 1.0, 2.0, 0.4372240712030313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 536457.5241597111, 536457.5241597111, 133855.9994478117]
[2019-04-27 20:40:01,359] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 20:40:01,361] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.2145065e-29 1.0000000e+00 1.4412240e-32 1.1426799e-24 9.5321616e-33], sampled 0.30070913896411744
[2019-04-27 20:40:06,915] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.121995375]
[2019-04-27 20:40:06,917] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.18312060666667, 45.17674489333333, 1.0, 2.0, 0.4880749194057053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 580720.1952087362, 580720.1952087362, 140982.4231210538]
[2019-04-27 20:40:06,917] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 20:40:06,920] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.5610225e-27 1.0000000e+00 1.1191184e-30 3.0750972e-23 8.1291980e-31], sampled 0.9877484579301652
[2019-04-27 20:40:32,892] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.121995375]
[2019-04-27 20:40:32,892] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.80503426, 78.20304202, 1.0, 2.0, 0.7632056922293879, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 869879.4655668807, 869879.4655668807, 188464.4606812968]
[2019-04-27 20:40:32,895] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 20:40:32,899] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.5251247e-28 1.0000000e+00 1.3514646e-31 7.4228672e-24 1.1732774e-31], sampled 0.21330925310416138
[2019-04-27 20:40:33,984] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.121995375]
[2019-04-27 20:40:33,985] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.03333333333333, 51.83333333333334, 1.0, 2.0, 0.5329128463798513, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 627124.978881518, 627124.978881518, 147828.8908422498]
[2019-04-27 20:40:33,985] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 20:40:33,990] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.4322317e-29 1.0000000e+00 1.6224652e-32 1.2867851e-24 1.0469510e-32], sampled 0.3596353570758313
[2019-04-27 20:41:09,728] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8769.4422 2170768739.9937 493.0000
[2019-04-27 20:41:09,871] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8921.8922 2120660928.3939 430.0000
[2019-04-27 20:41:09,943] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8699.3424 2195282598.7024 572.0000
[2019-04-27 20:41:10,093] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.121995375]
[2019-04-27 20:41:10,093] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.5, 64.0, 1.0, 2.0, 0.540715504933169, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 666216.7407206362, 666216.7407206362, 150112.1263841116]
[2019-04-27 20:41:10,094] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 20:41:10,095] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.5712026e-27 1.0000000e+00 1.6901262e-30 4.2059022e-23 1.2766699e-30], sampled 0.020212432686147586
[2019-04-27 20:41:10,203] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8582.0590 2248830394.8409 553.0000
[2019-04-27 20:41:10,204] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8097.6795 2445569542.8369 746.0000
[2019-04-27 20:41:11,219] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1550000, evaluation results [1550000.0, 8097.679510568991, 2445569542.8369265, 746.0, 8769.442185004564, 2170768739.993712, 493.0, 8921.892236157437, 2120660928.3938506, 430.0, 8582.059032767682, 2248830394.840892, 553.0, 8699.342416479873, 2195282598.702448, 572.0]
[2019-04-27 20:41:12,272] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.5966934e-30 1.0000000e+00 3.9406672e-36 1.5694186e-25 1.8952690e-33], sum to 1.0000
[2019-04-27 20:41:12,273] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3503
[2019-04-27 20:41:12,280] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.65, 96.83333333333334, 1.0, 2.0, 0.4458410735145249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 544345.2075842358, 544345.2075842354, 135056.8733707511], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2609400.0000, 
sim time next is 2610000.0000, 
raw observation next is [20.6, 97.0, 1.0, 2.0, 0.4444046744616402, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 542857.3420342486, 542857.3420342486, 134851.279304727], 
processed observation next is [0.0, 0.21739130434782608, 0.3185185185185186, 0.97, 1.0, 1.0, 0.33857699340671454, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1938776221550888, 0.1938776221550888, 0.25932938327832117], 
reward next is 0.7407, 
noisyNet noise sample is [array([-1.2760295], dtype=float32), 0.09588588]. 
=============================================
[2019-04-27 20:41:12,312] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[72.867744]
 [72.8825  ]
 [72.89293 ]
 [72.89512 ]
 [72.90347 ]], R is [[72.94725037]
 [72.95805359]
 [72.96839905]
 [72.97834015]
 [72.98787689]].
[2019-04-27 20:41:23,989] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.21478191e-32 1.00000000e+00 1.15262125e-33 8.95066408e-28
 1.03166158e-36], sum to 1.0000
[2019-04-27 20:41:24,000] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0947
[2019-04-27 20:41:24,004] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.18333333333333, 87.83333333333334, 1.0, 2.0, 0.5696167563854587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 666001.9788128743, 666001.9788128743, 153717.3379478166], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2667000.0000, 
sim time next is 2667600.0000, 
raw observation next is [24.0, 89.0, 1.0, 2.0, 0.5660726851972167, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 662202.7005069326, 662202.7005069326, 153136.9756564188], 
processed observation next is [0.0, 0.9130434782608695, 0.4444444444444444, 0.89, 1.0, 1.0, 0.4834198633300198, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23650096446676164, 0.23650096446676164, 0.29449418395465154], 
reward next is 0.7055, 
noisyNet noise sample is [array([-0.3257392], dtype=float32), 0.09877717]. 
=============================================
[2019-04-27 20:41:27,312] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.1422598e-31 1.0000000e+00 2.4364425e-34 5.0555630e-26 1.9012585e-32], sum to 1.0000
[2019-04-27 20:41:27,320] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9449
[2019-04-27 20:41:27,325] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 94.16666666666666, 1.0, 2.0, 0.4717347610908037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 571850.9361365397, 571850.9361365397, 138838.6368055314], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2695800.0000, 
sim time next is 2696400.0000, 
raw observation next is [21.2, 93.0, 1.0, 2.0, 0.4591232413775544, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 559069.157127115, 559069.157127115, 137001.5699384149], 
processed observation next is [0.0, 0.21739130434782608, 0.34074074074074073, 0.93, 1.0, 1.0, 0.356099096878041, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19966755611682677, 0.19966755611682677, 0.2634645575738748], 
reward next is 0.7365, 
noisyNet noise sample is [array([-1.0456022], dtype=float32), -0.8734179]. 
=============================================
[2019-04-27 20:41:28,476] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.8348423e-19 1.0000000e+00 3.0891253e-22 9.6523631e-18 9.1105262e-23], sum to 1.0000
[2019-04-27 20:41:28,486] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3674
[2019-04-27 20:41:28,493] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1819894.539130978 W.
[2019-04-27 20:41:28,499] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.33333333333334, 87.33333333333334, 1.0, 2.0, 0.5319221895205538, 1.0, 2.0, 0.5319221895205538, 1.0, 1.0, 0.8468374492130181, 6.9112, 6.9112, 121.94756008, 1819894.539130978, 1819894.539130978, 359532.9991097201], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2906400.0000, 
sim time next is 2907000.0000, 
raw observation next is [26.5, 86.5, 1.0, 2.0, 0.8162869352480439, 1.0, 2.0, 0.8162869352480439, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1861915.572367535, 1861915.572367535, 350530.4702320872], 
processed observation next is [1.0, 0.6521739130434783, 0.5370370370370371, 0.865, 1.0, 1.0, 0.7812939705333856, 1.0, 1.0, 0.7812939705333856, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6649698472741197, 0.6649698472741197, 0.6740970581386292], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4370325], dtype=float32), 0.8025857]. 
=============================================
[2019-04-27 20:41:28,523] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[47.94644 ]
 [47.578377]
 [46.9647  ]
 [46.660736]
 [46.216164]], R is [[47.9212265 ]
 [47.44201279]
 [47.31809616]
 [46.8449173 ]
 [46.37646866]].
[2019-04-27 20:41:29,124] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.4851278e-30 1.0000000e+00 2.3436683e-33 6.3432743e-26 2.7705336e-36], sum to 1.0000
[2019-04-27 20:41:29,131] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3767
[2019-04-27 20:41:29,136] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.86666666666667, 58.0, 1.0, 2.0, 0.61220063289616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 697689.9967348226, 697689.9967348226, 160190.0366392704], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3181200.0000, 
sim time next is 3181800.0000, 
raw observation next is [30.33333333333334, 63.0, 1.0, 2.0, 0.6409895857272603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 730514.7504372733, 730514.7504372733, 165275.2315169972], 
processed observation next is [1.0, 0.8260869565217391, 0.6790123456790126, 0.63, 1.0, 1.0, 0.5726066496753098, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26089812515616906, 0.26089812515616906, 0.3178369836865331], 
reward next is 0.6822, 
noisyNet noise sample is [array([-0.15811357], dtype=float32), 0.05336663]. 
=============================================
[2019-04-27 20:41:35,719] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.5032037e-26 1.0000000e+00 5.5512738e-30 4.4495556e-25 7.0075394e-31], sum to 1.0000
[2019-04-27 20:41:35,729] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8217
[2019-04-27 20:41:35,734] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5156416014019962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 618940.0426366295, 618940.0426366292, 145515.7777552072], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2876400.0000, 
sim time next is 2877000.0000, 
raw observation next is [22.13333333333334, 93.33333333333334, 1.0, 2.0, 0.5736053005243759, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 688030.6495149565, 688030.6495149565, 155078.876460065], 
processed observation next is [1.0, 0.30434782608695654, 0.3753086419753089, 0.9333333333333335, 1.0, 1.0, 0.4923872625290189, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24572523196962734, 0.24572523196962734, 0.2982286085770481], 
reward next is 0.7018, 
noisyNet noise sample is [array([-0.7583801], dtype=float32), -0.7659616]. 
=============================================
[2019-04-27 20:41:35,749] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[60.91318 ]
 [60.912037]
 [60.863323]
 [60.559685]
 [60.50888 ]], R is [[60.71335983]
 [60.82638931]
 [60.93554688]
 [61.04385757]
 [61.15061951]].
[2019-04-27 20:41:39,858] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.1659873e-33 1.0000000e+00 2.4027432e-35 2.8186102e-29 5.0051225e-38], sum to 1.0000
[2019-04-27 20:41:39,863] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3504
[2019-04-27 20:41:39,870] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1908883.110161441 W.
[2019-04-27 20:41:39,878] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.25, 79.83333333333334, 1.0, 2.0, 0.5579041763036926, 1.0, 2.0, 0.5579041763036926, 1.0, 1.0, 0.8882016183460101, 6.9112, 6.9112, 121.94756008, 1908883.110161441, 1908883.110161441, 372917.1422689021], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2911800.0000, 
sim time next is 2912400.0000, 
raw observation next is [28.5, 79.0, 1.0, 2.0, 0.5544339500971671, 1.0, 2.0, 0.5544339500971671, 1.0, 2.0, 0.8826769052078441, 6.911199999999999, 6.9112, 121.94756008, 1896997.036893044, 1896997.036893044, 371108.4083247139], 
processed observation next is [1.0, 0.7391304347826086, 0.6111111111111112, 0.79, 1.0, 1.0, 0.4695642263061513, 1.0, 1.0, 0.4695642263061513, 1.0, 1.0, 0.8533461315098051, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6774989417475157, 0.6774989417475157, 0.7136700160090651], 
reward next is 0.2863, 
noisyNet noise sample is [array([-1.7090305], dtype=float32), 0.28111777]. 
=============================================
[2019-04-27 20:41:40,760] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.7048556e-27 1.0000000e+00 7.5617763e-29 4.9834394e-24 2.4287825e-30], sum to 1.0000
[2019-04-27 20:41:40,767] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2279
[2019-04-27 20:41:40,774] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.06666666666667, 92.0, 1.0, 2.0, 0.6483665087519366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 738926.0391655882, 738926.0391655882, 166598.1242952867], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2938800.0000, 
sim time next is 2939400.0000, 
raw observation next is [25.05, 92.5, 1.0, 2.0, 0.6509688237675572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 741893.2634871993, 741893.2634871993, 167068.2437727579], 
processed observation next is [1.0, 0.0, 0.48333333333333334, 0.925, 1.0, 1.0, 0.5844866949613775, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2649618798168569, 0.2649618798168569, 0.3212850841783806], 
reward next is 0.6787, 
noisyNet noise sample is [array([-1.2739874], dtype=float32), 0.91043156]. 
=============================================
[2019-04-27 20:41:42,864] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.86850004e-23 1.00000000e+00 5.05674237e-25 1.27272796e-20
 8.16180607e-28], sum to 1.0000
[2019-04-27 20:41:42,872] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1141
[2019-04-27 20:41:42,883] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1835530.307928484 W.
[2019-04-27 20:41:42,888] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.26666666666667, 81.33333333333334, 1.0, 2.0, 0.8047311811370315, 1.0, 2.0, 0.8047311811370315, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1835530.307928484, 1835530.307928485, 345714.2581682344], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2978400.0000, 
sim time next is 2979000.0000, 
raw observation next is [28.2, 82.0, 1.0, 2.0, 0.8206679664547504, 1.0, 2.0, 0.8206679664547504, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1871918.98889443, 1871918.98889443, 352369.7434736834], 
processed observation next is [1.0, 0.4782608695652174, 0.6, 0.82, 1.0, 1.0, 0.7865094838747029, 1.0, 1.0, 0.7865094838747029, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.668542496033725, 0.668542496033725, 0.6776341220647758], 
reward next is 0.3224, 
noisyNet noise sample is [array([0.85888165], dtype=float32), -1.6264415]. 
=============================================
[2019-04-27 20:41:42,904] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[50.032887]
 [49.986347]
 [50.44371 ]
 [50.285923]
 [49.87962 ]], R is [[49.84321594]
 [49.6799469 ]
 [49.47963715]
 [49.2399559 ]
 [49.02021408]].
[2019-04-27 20:41:48,905] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4521495e-34 1.0000000e+00 0.0000000e+00 9.7996591e-32 0.0000000e+00], sum to 1.0000
[2019-04-27 20:41:48,911] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5388
[2019-04-27 20:41:48,915] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.85, 87.83333333333334, 1.0, 2.0, 0.4833800623684459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 580452.6149714615, 580452.614971461, 140448.798725006], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3541800.0000, 
sim time next is 3542400.0000, 
raw observation next is [23.0, 89.0, 1.0, 2.0, 0.4964532956093672, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 592973.9238051678, 592973.9238051673, 142370.5071180806], 
processed observation next is [1.0, 0.0, 0.4074074074074074, 0.89, 1.0, 1.0, 0.40053963763019906, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21177640135898848, 0.21177640135898831, 0.27378943676553963], 
reward next is 0.7262, 
noisyNet noise sample is [array([1.4045113], dtype=float32), 0.46275353]. 
=============================================
[2019-04-27 20:41:52,632] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.3339245e-19 1.0000000e+00 3.3965623e-21 2.6169983e-16 1.2681337e-20], sum to 1.0000
[2019-04-27 20:41:52,639] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7418
[2019-04-27 20:41:52,646] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 100.0, 1.0, 2.0, 0.5128298618452397, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8183554716413856, 6.911200000000001, 6.9112, 121.9260425415101, 1192411.269969639, 1192411.269969639, 261065.142270711], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3665400.0000, 
sim time next is 3666000.0000, 
raw observation next is [22.33333333333334, 100.0, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.505355070218577, 6.9112, 121.9236792896351, 1500866.213422852, 1196611.610058362, 247420.7310138092], 
processed observation next is [1.0, 0.43478260869565216, 0.38271604938271625, 1.0, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.05941550702185774, 0.0, 0.8094464387930045, 0.5360236476510186, 0.4273612893065578, 0.47580909810347927], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.2605828], dtype=float32), 0.47526503]. 
=============================================
[2019-04-27 20:41:52,663] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[47.585327]
 [48.51491 ]
 [48.089825]
 [48.457916]
 [48.35335 ]], R is [[46.97522354]
 [46.50547028]
 [46.04041672]
 [45.58001328]
 [45.12421417]].
[2019-04-27 20:41:53,976] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.6186814e-25 1.0000000e+00 2.2556701e-28 2.3299701e-23 1.0281523e-30], sum to 1.0000
[2019-04-27 20:41:53,986] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5101
[2019-04-27 20:41:53,991] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 70.5, 1.0, 2.0, 0.5895587574511035, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 681224.407216681, 681224.4072166806, 156743.1369953], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3191400.0000, 
sim time next is 3192000.0000, 
raw observation next is [27.33333333333334, 73.33333333333333, 1.0, 2.0, 0.6061041154056335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 695904.2742955671, 695904.2742955671, 159385.2284702255], 
processed observation next is [1.0, 0.9565217391304348, 0.5679012345679014, 0.7333333333333333, 1.0, 1.0, 0.5310763278638494, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24853724081984538, 0.24853724081984538, 0.30651005475043364], 
reward next is 0.6935, 
noisyNet noise sample is [array([0.8889965], dtype=float32), 0.97698176]. 
=============================================
[2019-04-27 20:41:54,004] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[59.973766]
 [60.091724]
 [60.17468 ]
 [60.147408]
 [59.919025]], R is [[59.90271378]
 [60.0022583 ]
 [60.10546875]
 [60.21249771]
 [60.32195663]].
[2019-04-27 20:41:54,966] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.0164716e-30 1.0000000e+00 5.6564284e-36 1.6613752e-28 1.4830679e-35], sum to 1.0000
[2019-04-27 20:41:54,974] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5578
[2019-04-27 20:41:54,980] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.00000000000001, 1.0, 2.0, 0.6695821858961557, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 763117.0169496551, 763117.0169496547, 170464.0102805504], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3705000.0000, 
sim time next is 3705600.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.6678205613402376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 761108.3119325403, 761108.3119325398, 170140.1196268963], 
processed observation next is [1.0, 0.9130434782608695, 0.48148148148148145, 0.94, 1.0, 1.0, 0.6045482873098067, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2718243971187644, 0.2718243971187642, 0.32719253774403134], 
reward next is 0.6728, 
noisyNet noise sample is [array([0.11966734], dtype=float32), 0.73090583]. 
=============================================
[2019-04-27 20:41:55,126] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.20380595e-33 1.00000000e+00 8.71873555e-37 2.88753134e-30
 0.00000000e+00], sum to 1.0000
[2019-04-27 20:41:55,132] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3408
[2019-04-27 20:41:55,138] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 79.66666666666667, 1.0, 2.0, 0.4768913652870718, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 574877.5705442546, 574877.5705442551, 139525.0800512155], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3220800.0000, 
sim time next is 3221400.0000, 
raw observation next is [23.83333333333333, 78.83333333333333, 1.0, 2.0, 0.4789178140511588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 576868.1971106707, 576868.1971106703, 139821.3974757766], 
processed observation next is [0.0, 0.2608695652173913, 0.43827160493827144, 0.7883333333333333, 1.0, 1.0, 0.37966406434661765, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20602435611095382, 0.20602435611095365, 0.26888730283803197], 
reward next is 0.7311, 
noisyNet noise sample is [array([1.2190199], dtype=float32), 0.2111026]. 
=============================================
[2019-04-27 20:42:00,047] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.8855045e-26 1.0000000e+00 4.8753055e-30 8.5853843e-25 1.1276069e-31], sum to 1.0000
[2019-04-27 20:42:00,054] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3132
[2019-04-27 20:42:00,065] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 89.0, 1.0, 2.0, 0.6045640048116646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 697690.424491094, 697690.424491094, 159287.5860510836], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3274800.0000, 
sim time next is 3275400.0000, 
raw observation next is [24.33333333333333, 91.5, 1.0, 2.0, 0.6054836968546371, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 698701.933609694, 698701.933609694, 159444.9115075087], 
processed observation next is [0.0, 0.9130434782608695, 0.45679012345678993, 0.915, 1.0, 1.0, 0.5303377343507585, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.249536404860605, 0.249536404860605, 0.3066248298221321], 
reward next is 0.6934, 
noisyNet noise sample is [array([-1.0902293], dtype=float32), 0.3970084]. 
=============================================
[2019-04-27 20:42:03,424] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-04-27 20:42:03,426] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 20:42:03,428] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 20:42:03,428] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 20:42:03,429] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:42:03,430] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:42:03,430] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 20:42:03,431] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 20:42:03,433] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:42:03,433] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:42:03,432] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:42:03,458] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run64
[2019-04-27 20:42:03,481] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run64
[2019-04-27 20:42:03,482] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run64
[2019-04-27 20:42:03,502] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run64
[2019-04-27 20:42:03,523] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run64
[2019-04-27 20:42:10,239] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12168382]
[2019-04-27 20:42:10,239] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.46666666666667, 49.0, 1.0, 2.0, 0.2635797772792538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 339999.1177147107, 339999.1177147107, 107915.3964981183]
[2019-04-27 20:42:10,241] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 20:42:10,243] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.8155722e-31 1.0000000e+00 2.8005745e-35 9.1870325e-29 8.6155157e-37], sampled 0.7711097165292353
[2019-04-27 20:42:58,534] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12168382]
[2019-04-27 20:42:58,536] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [34.11162186, 47.91258488, 1.0, 2.0, 0.6522342091853012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 743336.09157141, 743336.0915714095, 167301.1999972128]
[2019-04-27 20:42:58,539] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 20:42:58,542] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [5.9288738e-31 1.0000000e+00 1.0815857e-34 2.2464131e-28 2.4330593e-36], sampled 0.301861287969569
[2019-04-27 20:43:51,377] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8922.6628 2120599135.7723 430.0000
[2019-04-27 20:43:51,829] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8582.8795 2248773970.1662 553.0000
[2019-04-27 20:43:51,951] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12168382]
[2019-04-27 20:43:51,952] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.6, 54.0, 1.0, 2.0, 0.5745045277249782, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9256779738761143, 6.911200000000001, 6.9112, 121.925502867455, 1373839.495726532, 1373839.495726532, 282454.1169569015]
[2019-04-27 20:43:51,952] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 20:43:51,954] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.5757411e-25 1.0000000e+00 2.7426889e-28 6.7277592e-23 4.5991336e-29], sampled 0.9270336230707069
[2019-04-27 20:43:51,954] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1373839.495726532 W.
[2019-04-27 20:43:52,134] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8700.1130 2195220806.1349 572.0000
[2019-04-27 20:43:52,142] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8770.2626 2170712315.3188 493.0000
[2019-04-27 20:43:52,201] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8099.2132 2445444095.4335 746.0000
[2019-04-27 20:43:53,219] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1575000, evaluation results [1575000.0, 8099.213190057684, 2445444095.433475, 746.0, 8770.262620159681, 2170712315.3187604, 493.0, 8922.662781171732, 2120599135.7722971, 430.0, 8582.879467926026, 2248773970.1662407, 553.0, 8700.112961499688, 2195220806.134913, 572.0]
[2019-04-27 20:43:57,923] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4422419e-24 1.0000000e+00 1.0795702e-26 2.2677126e-22 3.4076836e-29], sum to 1.0000
[2019-04-27 20:43:57,935] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3618
[2019-04-27 20:43:57,946] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2132863.7957927 W.
[2019-04-27 20:43:57,953] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.06666666666667, 62.33333333333333, 1.0, 2.0, 0.6232883457548736, 1.0, 2.0, 0.6232883457548736, 1.0, 2.0, 0.992295345526027, 6.9112, 6.9112, 121.94756008, 2132863.7957927, 2132863.7957927, 408210.2093056671], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3426000.0000, 
sim time next is 3426600.0000, 
raw observation next is [30.83333333333334, 63.16666666666666, 1.0, 2.0, 0.9233134860191097, 1.0, 2.0, 0.9233134860191097, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2106326.448907588, 2106326.448907588, 397344.5929813028], 
processed observation next is [1.0, 0.6521739130434783, 0.6975308641975311, 0.6316666666666666, 1.0, 1.0, 0.9087065309751305, 1.0, 1.0, 0.9087065309751305, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.7522594460384243, 0.7522594460384243, 0.7641242172717362], 
reward next is 0.2359, 
noisyNet noise sample is [array([-0.08404949], dtype=float32), -1.7654715]. 
=============================================
[2019-04-27 20:44:11,745] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.6412417e-29 1.0000000e+00 3.3435403e-32 6.9835403e-26 1.3026080e-33], sum to 1.0000
[2019-04-27 20:44:11,753] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7542
[2019-04-27 20:44:11,758] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.96666666666667, 87.33333333333333, 1.0, 2.0, 0.6785158134958583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 773303.7308414768, 773303.7308414768, 172120.1741186725], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3692400.0000, 
sim time next is 3693000.0000, 
raw observation next is [26.98333333333333, 88.16666666666667, 1.0, 2.0, 0.690441611992112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 786902.5271619424, 786902.5271619424, 174346.2086796618], 
processed observation next is [1.0, 0.7391304347826086, 0.5549382716049381, 0.8816666666666667, 1.0, 1.0, 0.631478109514419, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28103661684355086, 0.28103661684355086, 0.33528117053781115], 
reward next is 0.6647, 
noisyNet noise sample is [array([1.2331895], dtype=float32), 2.4688282]. 
=============================================
[2019-04-27 20:44:11,777] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[72.40163 ]
 [73.12211 ]
 [72.816284]
 [72.59699 ]
 [71.47423 ]], R is [[71.89880371]
 [71.84881592]
 [71.80373383]
 [71.08569336]
 [70.37483978]].
[2019-04-27 20:44:15,711] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.1220516e-24 1.0000000e+00 5.3095756e-26 2.2178614e-22 1.8601286e-26], sum to 1.0000
[2019-04-27 20:44:15,720] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3528
[2019-04-27 20:44:15,729] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1728004.598829714 W.
[2019-04-27 20:44:15,733] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.66666666666667, 72.33333333333334, 1.0, 2.0, 0.5050903739942367, 1.0, 1.0, 0.5050903739942367, 1.0, 2.0, 0.8041203250438963, 6.911199999999999, 6.9112, 121.94756008, 1728004.598829714, 1728004.598829714, 346094.4850749064], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3761400.0000, 
sim time next is 3762000.0000, 
raw observation next is [32.0, 71.0, 1.0, 2.0, 0.7922862733633077, 1.0, 2.0, 0.7922862733633077, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1807115.709750559, 1807115.709750559, 340579.9505027013], 
processed observation next is [1.0, 0.5652173913043478, 0.7407407407407407, 0.71, 1.0, 1.0, 0.7527217540039377, 1.0, 1.0, 0.7527217540039377, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6453984677680568, 0.6453984677680568, 0.6549614432744255], 
reward next is 0.3450, 
noisyNet noise sample is [array([-0.3843714], dtype=float32), 1.1380527]. 
=============================================
[2019-04-27 20:44:15,753] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[55.581646]
 [55.468605]
 [55.410763]
 [55.70011 ]
 [55.134464]], R is [[55.21973038]
 [54.66753387]
 [54.4704361 ]
 [54.32382584]
 [54.14600372]].
[2019-04-27 20:44:17,293] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.9376173e-28 1.0000000e+00 7.6863260e-32 1.5829349e-25 8.3907671e-31], sum to 1.0000
[2019-04-27 20:44:17,299] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0893
[2019-04-27 20:44:17,306] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2383085.663549216 W.
[2019-04-27 20:44:17,313] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.8, 49.83333333333334, 1.0, 2.0, 0.7658975133412368, 1.0, 2.0, 0.696313418647053, 1.0, 1.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2383085.663549216, 2383085.663549216, 447417.2555514671], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3768600.0000, 
sim time next is 3769200.0000, 
raw observation next is [34.0, 47.0, 1.0, 2.0, 0.9954466886942084, 1.0, 2.0, 0.9954466886942084, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260425192635, 2271090.976877895, 2271090.976877896, 431134.640934268], 
processed observation next is [1.0, 0.6521739130434783, 0.8148148148148148, 0.47, 1.0, 1.0, 0.9945793913026291, 1.0, 1.0, 0.9945793913026291, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621281801515, 0.811103920313534, 0.8111039203135343, 0.8291050787197461], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5727212], dtype=float32), -0.03412146]. 
=============================================
[2019-04-27 20:44:30,045] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.4048466e-20 1.0000000e+00 2.3089672e-21 2.2489649e-16 1.8674901e-23], sum to 1.0000
[2019-04-27 20:44:30,051] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2150
[2019-04-27 20:44:30,059] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1578035.829937102 W.
[2019-04-27 20:44:30,064] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.06666666666667, 87.33333333333334, 1.0, 2.0, 0.6919405955269844, 1.0, 2.0, 0.6919405955269844, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.926042573722, 1578035.829937102, 1578035.829937102, 301125.5149342175], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4018800.0000, 
sim time next is 4019400.0000, 
raw observation next is [26.1, 86.5, 1.0, 2.0, 0.6419067978855801, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.926042615649, 1446498.084486243, 1446498.084486243, 306984.6282821172], 
processed observation next is [1.0, 0.5217391304347826, 0.5222222222222223, 0.865, 1.0, 1.0, 0.5736985689114049, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, 0.0, 0.0, 0.809462128820051, 0.5166064587450868, 0.5166064587450868, 0.590355054388687], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.15288198], dtype=float32), -0.58005863]. 
=============================================
[2019-04-27 20:44:31,196] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1199442e-27 1.0000000e+00 6.5276039e-33 2.4276945e-26 4.5185190e-34], sum to 1.0000
[2019-04-27 20:44:31,207] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0293
[2019-04-27 20:44:31,214] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1672823.573252807 W.
[2019-04-27 20:44:31,223] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [34.41666666666666, 25.66666666666666, 1.0, 2.0, 0.7011344449930488, 1.0, 2.0, 0.7011344449930488, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156542, 1672823.573252807, 1672823.573252807, 307993.2757011551], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4207800.0000, 
sim time next is 4208400.0000, 
raw observation next is [34.5, 24.0, 1.0, 2.0, 0.4658625130933493, 1.0, 2.0, 0.4658625130933493, 1.0, 1.0, 0.7479283770551469, 6.911200000000001, 6.9112, 121.94756008, 1658279.9985151, 1658279.9985151, 327032.8140964354], 
processed observation next is [1.0, 0.7391304347826086, 0.8333333333333334, 0.24, 1.0, 1.0, 0.36412203939684445, 1.0, 1.0, 0.36412203939684445, 1.0, 0.5, 0.6849104713189336, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5922428566125357, 0.5922428566125357, 0.6289092578777603], 
reward next is 0.3711, 
noisyNet noise sample is [array([0.7897149], dtype=float32), -1.4875507]. 
=============================================
[2019-04-27 20:44:37,289] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.6471763e-37 1.0000000e+00 0.0000000e+00 1.0098278e-32 0.0000000e+00], sum to 1.0000
[2019-04-27 20:44:37,300] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0979
[2019-04-27 20:44:37,309] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 92.5, 1.0, 2.0, 0.4729865145930924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 572363.6398157337, 572363.6398157332, 138998.4791906111], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4145400.0000, 
sim time next is 4146000.0000, 
raw observation next is [21.8, 91.0, 1.0, 2.0, 0.46820157694321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 567381.7504105831, 567381.7504105836, 138294.0841031905], 
processed observation next is [1.0, 1.0, 0.362962962962963, 0.91, 1.0, 1.0, 0.36690663921810723, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2026363394323511, 0.20263633943235126, 0.2659501617369048], 
reward next is 0.7340, 
noisyNet noise sample is [array([-0.13680671], dtype=float32), -0.2241023]. 
=============================================
[2019-04-27 20:44:37,320] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[84.16518 ]
 [83.97863 ]
 [83.795235]
 [83.526146]
 [83.13482 ]], R is [[84.21117401]
 [84.10176086]
 [83.99246216]
 [83.88394928]
 [83.77680206]].
[2019-04-27 20:44:39,959] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.6130473e-24 1.0000000e+00 1.2686191e-25 1.6249899e-20 7.8024500e-26], sum to 1.0000
[2019-04-27 20:44:39,966] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7532
[2019-04-27 20:44:39,970] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.86666666666667, 82.0, 1.0, 2.0, 0.539521440047729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 644565.9723726596, 644565.9723726601, 149281.6428662833], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4174800.0000, 
sim time next is 4175400.0000, 
raw observation next is [24.33333333333334, 79.0, 1.0, 2.0, 0.5486227766390327, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 654975.9358547623, 654975.9358547623, 150765.7998863334], 
processed observation next is [1.0, 0.30434782608695654, 0.4567901234567903, 0.79, 1.0, 1.0, 0.4626461626655151, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23391997709098655, 0.23391997709098655, 0.28993423055064116], 
reward next is 0.7101, 
noisyNet noise sample is [array([-0.28220102], dtype=float32), -0.1892195]. 
=============================================
[2019-04-27 20:44:40,010] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.6744333e-24 1.0000000e+00 1.7054660e-26 5.4276082e-21 1.2722083e-28], sum to 1.0000
[2019-04-27 20:44:40,017] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0932
[2019-04-27 20:44:40,023] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1377730.357145843 W.
[2019-04-27 20:44:40,029] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.83333333333333, 37.66666666666666, 1.0, 2.0, 0.3985459202967557, 1.0, 1.0, 0.3985459202967557, 1.0, 1.0, 0.6350535941014915, 6.9112, 6.9112, 121.94756008, 1377730.357145843, 1377730.357145843, 296516.2627874456], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4193400.0000, 
sim time next is 4194000.0000, 
raw observation next is [33.0, 36.0, 1.0, 2.0, 0.5235579040819303, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8375300613302618, 6.911199999999999, 6.9112, 121.9260424903539, 1229455.186113785, 1229455.186113785, 264562.8620353475], 
processed observation next is [1.0, 0.5652173913043478, 0.7777777777777778, 0.36, 1.0, 1.0, 0.4328070286689646, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.7969125766628271, -8.881784197001253e-17, 0.0, 0.8094621279882217, 0.43909113789778037, 0.43909113789778037, 0.5087747346833605], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.14600416], dtype=float32), -1.2072091]. 
=============================================
[2019-04-27 20:44:40,044] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[54.095005]
 [54.02558 ]
 [53.674232]
 [53.462074]
 [52.560246]], R is [[54.74206161]
 [54.19464111]
 [53.6526947 ]
 [53.11616898]
 [53.03185654]].
[2019-04-27 20:44:40,692] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.9339211e-31 1.0000000e+00 6.2548410e-36 5.3261466e-27 7.0906686e-35], sum to 1.0000
[2019-04-27 20:44:40,699] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6150
[2019-04-27 20:44:40,710] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1678509.101195292 W.
[2019-04-27 20:44:40,717] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [33.43333333333334, 33.0, 1.0, 2.0, 0.4816273585244679, 1.0, 1.0, 0.4816273585244679, 1.0, 1.0, 0.7684010585828396, 6.9112, 6.9112, 121.94756008, 1678509.101195292, 1678509.101195292, 334774.2892350844], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4195200.0000, 
sim time next is 4195800.0000, 
raw observation next is [33.65, 31.5, 1.0, 2.0, 0.8159807444278535, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9695317405698669, 6.911199999999999, 6.9112, 121.9260424771189, 1678834.266370398, 1678834.266370398, 333953.5096762222], 
processed observation next is [1.0, 0.5652173913043478, 0.8018518518518518, 0.315, 1.0, 1.0, 0.7809294576522066, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9619146757123337, -8.881784197001253e-17, 0.0, 0.8094621279003551, 0.5995836665608564, 0.5995836665608564, 0.6422182878388889], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.06290497], dtype=float32), -0.11653146]. 
=============================================
[2019-04-27 20:44:41,758] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0978397e-25 1.0000000e+00 4.8813558e-29 7.3668446e-24 5.2935072e-30], sum to 1.0000
[2019-04-27 20:44:41,765] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8962
[2019-04-27 20:44:41,771] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1660239.890730805 W.
[2019-04-27 20:44:41,775] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [34.01666666666667, 33.5, 1.0, 2.0, 0.806940891230517, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9750504630379108, 6.911199999999999, 6.9112, 121.9260426156618, 1660239.890730805, 1660239.890730806, 333460.120503652], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4204200.0000, 
sim time next is 4204800.0000, 
raw observation next is [34.0, 34.0, 1.0, 2.0, 0.7898271841107907, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9763736503195055, 6.911199999999999, 6.9112, 121.9260426156618, 1638459.819927596, 1638459.819927596, 330321.4399527039], 
processed observation next is [1.0, 0.6956521739130435, 0.8148148148148148, 0.34, 1.0, 1.0, 0.7497942667985603, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9704670628993819, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5851642214027128, 0.5851642214027128, 0.6352335383705844], 
reward next is 0.3648, 
noisyNet noise sample is [array([1.7050204], dtype=float32), 1.7330915]. 
=============================================
[2019-04-27 20:44:45,537] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-04-27 20:44:45,538] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 20:44:45,539] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:44:45,540] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 20:44:45,542] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 20:44:45,542] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:44:45,543] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:44:45,544] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 20:44:45,545] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 20:44:45,546] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:44:45,546] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:44:45,560] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run65
[2019-04-27 20:44:45,583] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run65
[2019-04-27 20:44:45,605] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run65
[2019-04-27 20:44:45,624] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run65
[2019-04-27 20:44:45,625] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run65
[2019-04-27 20:45:01,956] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12259518]
[2019-04-27 20:45:01,957] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.957348865, 48.859629795, 1.0, 2.0, 0.5290542427696037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 669836.0027196576, 669836.0027196576, 148522.8632570682]
[2019-04-27 20:45:01,958] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 20:45:01,962] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.911133e-27 1.000000e+00 5.221309e-30 5.274636e-24 5.768468e-31], sampled 0.9813225171186357
[2019-04-27 20:45:33,052] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12259518]
[2019-04-27 20:45:33,055] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.8, 93.33333333333334, 1.0, 2.0, 0.594869684416782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 689644.5846719232, 689644.5846719232, 157758.7102275949]
[2019-04-27 20:45:33,058] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 20:45:33,061] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.2957687e-30 1.0000000e+00 4.2801557e-33 1.5469203e-26 3.0591095e-34], sampled 0.262674663013045
[2019-04-27 20:45:33,120] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12259518]
[2019-04-27 20:45:33,121] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.24932453833333, 83.45453037, 1.0, 2.0, 0.6067720844133205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 700553.6883232335, 700553.688323234, 159685.2851112027]
[2019-04-27 20:45:33,122] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 20:45:33,124] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.0819017e-30 1.0000000e+00 4.6892255e-33 1.7004769e-26 3.4779220e-34], sampled 0.18005388095620944
[2019-04-27 20:45:50,655] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12259518]
[2019-04-27 20:45:50,656] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.86904701333334, 102.9802328916667, 1.0, 2.0, 0.5723752889185031, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9141656472790521, 6.911199999999999, 6.9112, 121.9260426156618, 1336216.846334493, 1336216.846334493, 282699.9162755636]
[2019-04-27 20:45:50,657] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 20:45:50,659] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.6320712e-23 1.0000000e+00 1.9835299e-25 1.1432796e-20 1.8232461e-26], sampled 0.4083051533794163
[2019-04-27 20:45:50,660] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1336216.846334493 W.
[2019-04-27 20:46:33,460] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8922.6628 2120599135.7723 430.0000
[2019-04-27 20:46:33,520] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8582.0590 2248830394.8409 553.0000
[2019-04-27 20:46:33,636] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8098.4495 2445508074.6415 746.0000
[2019-04-27 20:46:33,655] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8770.2626 2170712315.3188 493.0000
[2019-04-27 20:46:33,668] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8700.1130 2195220806.1349 572.0000
[2019-04-27 20:46:34,685] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1600000, evaluation results [1600000.0, 8098.4494892610255, 2445508074.64147, 746.0, 8770.262620159681, 2170712315.3187604, 493.0, 8922.662781171732, 2120599135.7722971, 430.0, 8582.059032767682, 2248830394.840892, 553.0, 8700.112961499688, 2195220806.134913, 572.0]
[2019-04-27 20:46:36,884] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.2108294e-20 1.0000000e+00 1.7955385e-21 1.1220508e-15 4.2683163e-19], sum to 1.0000
[2019-04-27 20:46:36,892] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2193
[2019-04-27 20:46:36,897] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333333, 94.0, 1.0, 2.0, 0.7673068744368967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156577, 896961.4327080201, 896961.4327080206, 190388.2564389051], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4333200.0000, 
sim time next is 4333800.0000, 
raw observation next is [23.16666666666667, 94.0, 1.0, 2.0, 0.7472805935967749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 876510.6665447103, 876510.6665447103, 186496.8122103045], 
processed observation next is [1.0, 0.13043478260869565, 0.4135802469135804, 0.94, 1.0, 1.0, 0.6991435638056844, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31303952376596794, 0.31303952376596794, 0.3586477157890471], 
reward next is 0.6414, 
noisyNet noise sample is [array([-0.18768786], dtype=float32), -1.1860251]. 
=============================================
[2019-04-27 20:46:37,689] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2103220e-17 1.0000000e+00 6.7697810e-21 3.4809439e-14 3.8626284e-17], sum to 1.0000
[2019-04-27 20:46:37,699] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0684
[2019-04-27 20:46:37,703] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 87.0, 1.0, 2.0, 0.8323778816197304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 963995.9076926167, 963995.9076926158, 203512.7633266901], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4347600.0000, 
sim time next is 4348200.0000, 
raw observation next is [25.0, 86.5, 1.0, 2.0, 0.8882664356812737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1025778.725137577, 1025778.725137577, 215562.3012407032], 
processed observation next is [1.0, 0.30434782608695654, 0.48148148148148145, 0.865, 1.0, 1.0, 0.8669838520015163, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3663495446919918, 0.3663495446919918, 0.41454288700135233], 
reward next is 0.5855, 
noisyNet noise sample is [array([-0.3534723], dtype=float32), -0.4184393]. 
=============================================
[2019-04-27 20:46:59,264] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.1741207e-27 1.0000000e+00 1.3231225e-31 4.9837246e-24 8.3434003e-31], sum to 1.0000
[2019-04-27 20:46:59,276] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2148
[2019-04-27 20:46:59,286] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1762739.621017832 W.
[2019-04-27 20:46:59,290] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.53333333333333, 78.33333333333334, 1.0, 2.0, 0.515233307121852, 1.0, 2.0, 0.515233307121852, 1.0, 1.0, 0.8202682049153303, 6.911199999999998, 6.9112, 121.94756008, 1762739.621017832, 1762739.621017833, 351128.6513670264], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4717200.0000, 
sim time next is 4717800.0000, 
raw observation next is [28.15, 81.0, 1.0, 2.0, 0.7437155160408015, 1.0, 2.0, 0.7437155160408015, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1696226.102172411, 1696226.102172411, 321046.4620779297], 
processed observation next is [1.0, 0.6086956521739131, 0.5981481481481481, 0.81, 1.0, 1.0, 0.6948994238580971, 1.0, 1.0, 0.6948994238580971, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6057950364901468, 0.6057950364901468, 0.6173970424575571], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0501468], dtype=float32), 1.0964007]. 
=============================================
[2019-04-27 20:47:00,962] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.7303322e-22 1.0000000e+00 9.3135896e-25 4.2250954e-19 6.8538831e-24], sum to 1.0000
[2019-04-27 20:47:00,970] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2240
[2019-04-27 20:47:00,975] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.1, 93.0, 1.0, 2.0, 0.7990436565311503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260425828736, 922463.2185481113, 922463.2185481113, 196347.0836540677], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4761000.0000, 
sim time next is 4761600.0000, 
raw observation next is [24.06666666666667, 93.33333333333334, 1.0, 2.0, 0.7131027160633253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156518, 823171.890396723, 823171.890396723, 179160.4240013389], 
processed observation next is [1.0, 0.08695652173913043, 0.4469135802469137, 0.9333333333333335, 1.0, 1.0, 0.6584556143611016, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288200695, 0.2939899608559725, 0.2939899608559725, 0.3445392769256517], 
reward next is 0.6555, 
noisyNet noise sample is [array([-0.1636534], dtype=float32), -0.70533764]. 
=============================================
[2019-04-27 20:47:05,249] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.3411937e-25 1.0000000e+00 8.3906518e-28 4.6151433e-22 5.1529471e-29], sum to 1.0000
[2019-04-27 20:47:05,257] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4343
[2019-04-27 20:47:05,261] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.4, 88.66666666666667, 1.0, 2.0, 0.5555690286505225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 657943.4551882119, 657943.4551882119, 151716.8572907148], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5291400.0000, 
sim time next is 5292000.0000, 
raw observation next is [23.3, 89.0, 1.0, 2.0, 0.5494410286935945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 651378.1674455381, 651378.1674455381, 150726.937108558], 
processed observation next is [1.0, 0.2608695652173913, 0.41851851851851857, 0.89, 1.0, 1.0, 0.4636202722542791, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2326350598019779, 0.2326350598019779, 0.2898594944395346], 
reward next is 0.7101, 
noisyNet noise sample is [array([0.2952199], dtype=float32), 0.502309]. 
=============================================
[2019-04-27 20:47:05,279] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[59.022583]
 [59.147938]
 [59.28091 ]
 [59.357067]
 [59.341995]], R is [[58.78899384]
 [58.9093399 ]
 [59.02580643]
 [59.13905716]
 [59.25387192]].
[2019-04-27 20:47:07,212] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.5634201e-24 1.0000000e+00 1.6236945e-28 1.7716514e-20 2.0728924e-26], sum to 1.0000
[2019-04-27 20:47:07,226] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2805
[2019-04-27 20:47:07,232] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.33333333333334, 1.0, 2.0, 0.7509595276384351, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 855913.8524398622, 855913.8524398617, 186012.2817266246], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4853400.0000, 
sim time next is 4854000.0000, 
raw observation next is [25.0, 94.66666666666667, 1.0, 2.0, 0.6991251121188184, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 796804.3345639971, 796804.3345639971, 175976.2964273786], 
processed observation next is [1.0, 0.17391304347826086, 0.48148148148148145, 0.9466666666666668, 1.0, 1.0, 0.6418156096652601, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.284572976629999, 0.284572976629999, 0.33841595466803576], 
reward next is 0.6616, 
noisyNet noise sample is [array([1.351391], dtype=float32), -2.295552]. 
=============================================
[2019-04-27 20:47:07,246] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[57.44778 ]
 [57.682835]
 [57.74577 ]
 [57.86553 ]
 [58.219494]], R is [[57.28280258]
 [57.35226059]
 [57.42937469]
 [57.50218964]
 [57.57378387]].
[2019-04-27 20:47:07,683] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.2561056e-22 1.0000000e+00 4.8217573e-24 3.0832922e-18 4.4675203e-23], sum to 1.0000
[2019-04-27 20:47:07,693] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3646
[2019-04-27 20:47:07,698] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.7321617197777475, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 834477.193869531, 834477.193869531, 182318.6288627731], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4863000.0000, 
sim time next is 4863600.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.815932987721882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 930012.9549849208, 930012.9549849208, 199249.7346859789], 
processed observation next is [1.0, 0.30434782608695654, 0.48148148148148145, 0.94, 1.0, 1.0, 0.780872604430812, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.332147483923186, 0.332147483923186, 0.3831725667038056], 
reward next is 0.6168, 
noisyNet noise sample is [array([0.0087697], dtype=float32), -0.6896715]. 
=============================================
[2019-04-27 20:47:08,159] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1398983e-31 1.0000000e+00 4.0104136e-35 3.9306674e-29 1.6688072e-35], sum to 1.0000
[2019-04-27 20:47:08,167] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2696
[2019-04-27 20:47:08,172] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 89.0, 1.0, 2.0, 0.8385345432811339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 955790.620458339, 955790.620458339, 204044.320501998], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4905000.0000, 
sim time next is 4905600.0000, 
raw observation next is [29.0, 89.0, 1.0, 2.0, 0.8765319382996154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 999129.5980529427, 999129.5980529427, 212273.6395617697], 
processed observation next is [1.0, 0.782608695652174, 0.6296296296296297, 0.89, 1.0, 1.0, 0.8530142122614469, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3568319993046224, 0.3568319993046224, 0.4082185376187879], 
reward next is 0.5918, 
noisyNet noise sample is [array([0.12350489], dtype=float32), -0.12909047]. 
=============================================
[2019-04-27 20:47:19,084] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.1607913e-28 1.0000000e+00 6.2979083e-30 1.4123730e-24 7.8133530e-33], sum to 1.0000
[2019-04-27 20:47:19,091] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5771
[2019-04-27 20:47:19,096] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 0.8169351814601947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 931155.9647937408, 931155.9647937408, 199471.6414838236], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5072400.0000, 
sim time next is 5073000.0000, 
raw observation next is [30.83333333333334, 70.83333333333334, 1.0, 2.0, 0.7758058220970323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 884249.0088389845, 884249.0088389842, 190999.7918336705], 
processed observation next is [0.0, 0.7391304347826086, 0.6975308641975311, 0.7083333333333335, 1.0, 1.0, 0.7331021691631336, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.31580321744249445, 0.31580321744249434, 0.36730729198782786], 
reward next is 0.6327, 
noisyNet noise sample is [array([-0.18561023], dtype=float32), 0.7386657]. 
=============================================
[2019-04-27 20:47:19,126] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[65.45175]
 [65.32066]
 [65.32383]
 [65.32497]
 [65.29829]], R is [[65.57111359]
 [65.53180695]
 [65.48821259]
 [65.44098663]
 [65.39459991]].
[2019-04-27 20:47:22,475] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.8961075e-22 1.0000000e+00 1.5921347e-24 2.0019528e-21 1.3469910e-25], sum to 1.0000
[2019-04-27 20:47:22,481] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1572
[2019-04-27 20:47:22,485] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 69.0, 1.0, 2.0, 0.3538174526414863, 1.0, 2.0, 0.3538174526414863, 1.0, 1.0, 0.5632889076352142, 6.911199999999999, 6.9112, 121.94756008, 1210080.518803247, 1210080.518803247, 277443.1166077183], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5317200.0000, 
sim time next is 5317800.0000, 
raw observation next is [27.2, 68.0, 1.0, 2.0, 0.933965277703046, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260339489805, 1082606.666591138, 1082606.666591138, 226145.0153438757], 
processed observation next is [1.0, 0.5652173913043478, 0.5629629629629629, 0.68, 1.0, 1.0, 0.921387235360769, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094620712823849, 0.3866452380682636, 0.3866452380682636, 0.43489426027668404], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0976386], dtype=float32), -0.022057582]. 
=============================================
[2019-04-27 20:47:23,108] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.2647725e-30 1.0000000e+00 9.7536695e-33 2.3351186e-26 4.3674202e-34], sum to 1.0000
[2019-04-27 20:47:23,118] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4029
[2019-04-27 20:47:23,123] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.3, 83.0, 1.0, 2.0, 0.8621133458275945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 982683.7858832052, 982683.7858832052, 209118.0022840916], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5135400.0000, 
sim time next is 5136000.0000, 
raw observation next is [29.4, 81.0, 1.0, 2.0, 0.8476675353321426, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 966207.2828439244, 966207.2828439244, 205994.7891753983], 
processed observation next is [0.0, 0.43478260869565216, 0.6444444444444444, 0.81, 1.0, 1.0, 0.8186518277763601, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.34507402958711586, 0.34507402958711586, 0.3961438253373044], 
reward next is 0.6039, 
noisyNet noise sample is [array([-0.7473364], dtype=float32), 0.82842875]. 
=============================================
[2019-04-27 20:47:23,131] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[68.14792 ]
 [68.079124]
 [68.04307 ]
 [67.915794]
 [67.896774]], R is [[68.14031219]
 [68.05675507]
 [67.97250366]
 [67.89506531]
 [67.80192566]].
[2019-04-27 20:47:24,464] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.4901973e-34 1.0000000e+00 0.0000000e+00 1.8084881e-30 0.0000000e+00], sum to 1.0000
[2019-04-27 20:47:24,474] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5043
[2019-04-27 20:47:24,481] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.93333333333333, 92.0, 1.0, 2.0, 0.6472790486336369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 737686.0934874393, 737686.0934874393, 166401.4549401015], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5182800.0000, 
sim time next is 5183400.0000, 
raw observation next is [24.96666666666667, 93.0, 1.0, 2.0, 0.6568404434628013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 748588.2725341527, 748588.2725341527, 168132.6424921345], 
processed observation next is [0.0, 1.0, 0.48024691358024696, 0.93, 1.0, 1.0, 0.5914767184080968, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2673529544764831, 0.2673529544764831, 0.32333200479256635], 
reward next is 0.6767, 
noisyNet noise sample is [array([0.1213141], dtype=float32), -0.4750786]. 
=============================================
[2019-04-27 20:47:27,254] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-04-27 20:47:27,255] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 20:47:27,256] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:47:27,256] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 20:47:27,258] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 20:47:27,259] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 20:47:27,260] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:47:27,256] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 20:47:27,261] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:47:27,262] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:47:27,262] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:47:27,286] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run66
[2019-04-27 20:47:27,305] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run66
[2019-04-27 20:47:27,306] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run66
[2019-04-27 20:47:27,322] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run66
[2019-04-27 20:47:27,362] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run66
[2019-04-27 20:47:29,882] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12369519]
[2019-04-27 20:47:29,883] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.78089613, 80.95164155666667, 1.0, 2.0, 0.4210214386533366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 514549.7957479329, 514549.7957479329, 131439.8312594208]
[2019-04-27 20:47:29,884] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 20:47:29,892] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.2041824e-27 1.0000000e+00 5.1294300e-30 1.6971865e-24 4.3172856e-31], sampled 0.3073384390882916
[2019-04-27 20:47:31,190] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12369519]
[2019-04-27 20:47:31,191] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [33.4, 14.0, 1.0, 2.0, 0.3806981412604579, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 489741.855954825, 489741.855954825, 126122.3037683828]
[2019-04-27 20:47:31,192] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 20:47:31,196] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.3636878e-29 1.0000000e+00 1.1846867e-32 1.1414981e-26 7.5981034e-34], sampled 0.42449495949459315
[2019-04-27 20:47:55,370] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12369519]
[2019-04-27 20:47:55,371] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [19.0, 94.33333333333334, 1.0, 2.0, 0.3449806381277407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 433052.5177388142, 433052.5177388142, 121244.5999941062]
[2019-04-27 20:47:55,372] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 20:47:55,374] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.6905244e-27 1.0000000e+00 6.0537752e-30 2.0578068e-24 5.5177653e-31], sampled 0.133439669370771
[2019-04-27 20:47:59,756] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12369519]
[2019-04-27 20:47:59,756] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.30378249, 92.4055035, 1.0, 2.0, 0.6418648761330504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 770188.2895388317, 770188.2895388317, 167128.6812013898]
[2019-04-27 20:47:59,758] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 20:47:59,762] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [7.7495902e-26 1.0000000e+00 1.6361421e-28 3.3618832e-23 2.2088108e-29], sampled 0.8525795632948849
[2019-04-27 20:48:05,206] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12369519]
[2019-04-27 20:48:05,207] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.110742315, 50.806110345, 1.0, 2.0, 0.3969936246070837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 490157.2921077486, 490157.2921077486, 128156.6050400274]
[2019-04-27 20:48:05,208] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 20:48:05,211] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.6067970e-30 1.0000000e+00 1.8985687e-33 2.1655289e-27 1.0068036e-34], sampled 0.4568324078987277
[2019-04-27 20:48:22,260] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12369519]
[2019-04-27 20:48:22,261] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [33.83333333333334, 50.5, 1.0, 2.0, 0.7129851947525844, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 812609.2713123546, 812609.2713123546, 178619.029262026]
[2019-04-27 20:48:22,262] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 20:48:22,265] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.1246302e-29 1.0000000e+00 1.8749552e-32 1.6387048e-26 1.3085347e-33], sampled 0.4924156749885663
[2019-04-27 20:48:26,578] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12369519]
[2019-04-27 20:48:26,579] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.60883954666667, 91.63418912833332, 1.0, 2.0, 0.4658854521893386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 559601.818933463, 559601.818933463, 137779.4384520244]
[2019-04-27 20:48:26,580] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 20:48:26,582] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.4449703e-28 1.0000000e+00 1.6466902e-31 9.3369564e-26 1.1170103e-32], sampled 0.8733780069639074
[2019-04-27 20:48:39,534] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12369519]
[2019-04-27 20:48:39,537] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [32.09274614, 73.77190908666667, 1.0, 2.0, 0.8887374743812223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1013051.479243632, 1013051.479243632, 214973.4817155509]
[2019-04-27 20:48:39,538] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 20:48:39,541] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [7.7287430e-27 1.0000000e+00 1.2371792e-29 4.3133668e-24 1.6504832e-30], sampled 0.8794719798991694
[2019-04-27 20:48:49,761] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12369519]
[2019-04-27 20:48:49,764] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.90818998, 46.00029026333333, 1.0, 2.0, 0.664543190005086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 812832.9165272893, 812832.9165272893, 171825.2904397035]
[2019-04-27 20:48:49,765] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 20:48:49,767] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.0399260e-27 1.0000000e+00 4.5636016e-30 1.3130058e-24 3.6946864e-31], sampled 0.4832031404718875
[2019-04-27 20:49:05,108] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12369519]
[2019-04-27 20:49:05,109] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.52397915, 74.18378567, 1.0, 2.0, 0.3566543821209289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 448868.0681698071, 448868.0681698071, 122808.2411865306]
[2019-04-27 20:49:05,110] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 20:49:05,112] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.9433169e-27 1.0000000e+00 6.4935632e-30 2.0561277e-24 5.4570191e-31], sampled 0.5482450049922474
[2019-04-27 20:49:14,349] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8099.2132 2445444095.4335 746.0000
[2019-04-27 20:49:14,721] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-04-27 20:49:14,838] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-04-27 20:49:15,019] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8700.1130 2195220806.1349 572.0000
[2019-04-27 20:49:15,067] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8923.4199 2120533710.1715 430.0000
[2019-04-27 20:49:16,087] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1625000, evaluation results [1625000.0, 8099.213190057684, 2445444095.433475, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8923.419851553375, 2120533710.171511, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8700.112961499688, 2195220806.134913, 572.0]
[2019-04-27 20:49:20,367] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.7570833e-26 1.0000000e+00 2.2547666e-28 8.3064062e-23 8.9946119e-28], sum to 1.0000
[2019-04-27 20:49:20,382] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5684
[2019-04-27 20:49:20,389] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 87.0, 1.0, 2.0, 0.5583365039067092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 657704.8431916254, 657704.8431916254, 152036.4902211149], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5288400.0000, 
sim time next is 5289000.0000, 
raw observation next is [23.8, 87.33333333333333, 1.0, 2.0, 0.6303335009479755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 743322.3166025099, 743322.3166025095, 164527.3993608841], 
processed observation next is [1.0, 0.21739130434782608, 0.43703703703703706, 0.8733333333333333, 1.0, 1.0, 0.5599208344618756, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2654722559294678, 0.26547225592946766, 0.3163988449247771], 
reward next is 0.6836, 
noisyNet noise sample is [array([0.5075173], dtype=float32), 1.1624693]. 
=============================================
[2019-04-27 20:49:20,398] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[56.278908]
 [56.381855]
 [56.457924]
 [56.455723]
 [56.573486]], R is [[56.27355957]
 [56.41844559]
 [56.56071472]
 [56.69874191]
 [56.83058548]].
[2019-04-27 20:49:21,095] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.8085643e-22 1.0000000e+00 1.4205104e-24 2.9379116e-20 4.7667251e-25], sum to 1.0000
[2019-04-27 20:49:21,103] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8325
[2019-04-27 20:49:21,110] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.48333333333333, 91.33333333333334, 1.0, 2.0, 0.673537784560523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 805867.8690010362, 805867.8690010362, 172907.080214341], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5296200.0000, 
sim time next is 5296800.0000, 
raw observation next is [22.36666666666667, 91.66666666666667, 1.0, 2.0, 0.625874461054364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 749756.2849295713, 749756.2849295713, 164188.3733727979], 
processed observation next is [1.0, 0.30434782608695654, 0.38395061728395075, 0.9166666666666667, 1.0, 1.0, 0.5546124536361475, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2677701017605612, 0.2677701017605612, 0.3157468718707652], 
reward next is 0.6843, 
noisyNet noise sample is [array([-0.786489], dtype=float32), -1.2148068]. 
=============================================
[2019-04-27 20:49:24,438] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.37459723e-23 1.00000000e+00 2.49018004e-27 8.79187372e-23
 1.39137085e-27], sum to 1.0000
[2019-04-27 20:49:24,450] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4276
[2019-04-27 20:49:24,456] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.1, 84.66666666666667, 1.0, 2.0, 0.3579557707776854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 449506.680267098, 449506.6802670975, 122966.9392552335], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5881800.0000, 
sim time next is 5882400.0000, 
raw observation next is [20.0, 85.0, 1.0, 2.0, 0.3562434871023075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 447672.2012988198, 447672.2012988198, 122742.9982728611], 
processed observation next is [1.0, 0.08695652173913043, 0.2962962962962963, 0.85, 1.0, 1.0, 0.23362319893131847, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15988292903529278, 0.15988292903529278, 0.2360442274478098], 
reward next is 0.7640, 
noisyNet noise sample is [array([-0.49061018], dtype=float32), 0.30779573]. 
=============================================
[2019-04-27 20:49:24,463] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.6762879e-35 1.0000000e+00 0.0000000e+00 1.6372609e-34 0.0000000e+00], sum to 1.0000
[2019-04-27 20:49:24,470] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8297
[2019-04-27 20:49:24,473] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.6927178e-25 1.0000000e+00 1.0887385e-27 1.2439840e-22 1.5380456e-28], sum to 1.0000
[2019-04-27 20:49:24,477] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.06666666666667, 80.33333333333334, 1.0, 2.0, 0.6117496946975947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 703345.0271769393, 703345.0271769393, 160413.3186551879], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5355600.0000, 
sim time next is 5356200.0000, 
raw observation next is [25.98333333333333, 80.66666666666666, 1.0, 2.0, 0.6093975378175688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 701133.2967930916, 701133.2967930916, 160026.8718926322], 
processed observation next is [1.0, 1.0, 0.5179012345679012, 0.8066666666666665, 1.0, 1.0, 0.534997068830439, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25040474885467556, 0.25040474885467556, 0.30774398440890804], 
reward next is 0.6923, 
noisyNet noise sample is [array([0.10183223], dtype=float32), -0.093333475]. 
=============================================
[2019-04-27 20:49:24,485] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4334
[2019-04-27 20:49:24,491] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.4, 93.0, 1.0, 2.0, 0.7219490960710951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 822831.165547859, 822831.165547859, 180339.0067038121], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5544000.0000, 
sim time next is 5544600.0000, 
raw observation next is [25.38333333333333, 93.0, 1.0, 2.0, 0.8360083646352285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 952909.4045742946, 952909.4045742936, 203489.0231539115], 
processed observation next is [1.0, 0.17391304347826086, 0.49567901234567885, 0.93, 1.0, 1.0, 0.8047718626609863, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.34032478734796234, 0.340324787347962, 0.3913250445267529], 
reward next is 0.6087, 
noisyNet noise sample is [array([-0.7307388], dtype=float32), -0.22642876]. 
=============================================
[2019-04-27 20:49:28,199] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.9604889e-32 1.0000000e+00 9.8818832e-37 1.5064440e-30 1.3946583e-37], sum to 1.0000
[2019-04-27 20:49:28,204] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2628
[2019-04-27 20:49:28,208] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 79.5, 1.0, 2.0, 0.7665893980431414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 873738.3125956326, 873738.3125956331, 189139.7191462424], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5427000.0000, 
sim time next is 5427600.0000, 
raw observation next is [28.93333333333333, 80.0, 1.0, 2.0, 0.7683218459755021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 875714.0390243975, 875714.0390243975, 189487.9638079533], 
processed observation next is [1.0, 0.8260869565217391, 0.6271604938271603, 0.8, 1.0, 1.0, 0.7241926737803597, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31275501393728483, 0.31275501393728483, 0.36439993039991014], 
reward next is 0.6356, 
noisyNet noise sample is [array([2.2594655], dtype=float32), 1.0501819]. 
=============================================
[2019-04-27 20:49:38,367] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.6358413e-33 1.0000000e+00 2.3936576e-36 2.1705696e-31 3.0551616e-38], sum to 1.0000
[2019-04-27 20:49:38,374] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5697
[2019-04-27 20:49:38,377] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 96.0, 1.0, 2.0, 0.6249562141305062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 714263.1110789693, 714263.1110789698, 162524.531026068], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5641200.0000, 
sim time next is 5641800.0000, 
raw observation next is [24.26666666666667, 95.83333333333333, 1.0, 2.0, 0.6282126213237692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 717219.674622882, 717219.674622882, 163061.7969178535], 
processed observation next is [0.0, 0.30434782608695654, 0.4543209876543211, 0.9583333333333333, 1.0, 1.0, 0.5573959777663919, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2561498837938864, 0.2561498837938864, 0.3135803786881798], 
reward next is 0.6864, 
noisyNet noise sample is [array([-0.78954136], dtype=float32), -0.2971454]. 
=============================================
[2019-04-27 20:49:38,638] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.3722362e-33 1.0000000e+00 2.2066121e-37 1.5334744e-30 0.0000000e+00], sum to 1.0000
[2019-04-27 20:49:38,652] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8984
[2019-04-27 20:49:38,659] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.51666666666667, 95.66666666666666, 1.0, 2.0, 0.6545430137022182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 745968.6624914559, 745968.6624914559, 167714.920192067], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5608200.0000, 
sim time next is 5608800.0000, 
raw observation next is [24.4, 96.0, 1.0, 2.0, 0.650280585860091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 741108.5163858557, 741108.5163858557, 166942.9005547114], 
processed observation next is [1.0, 0.9565217391304348, 0.4592592592592592, 0.96, 1.0, 1.0, 0.5836673641191559, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26468161299494847, 0.26468161299494847, 0.3210440395282912], 
reward next is 0.6790, 
noisyNet noise sample is [array([0.8635727], dtype=float32), -1.42139]. 
=============================================
[2019-04-27 20:49:39,855] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.9502307e-22 1.0000000e+00 1.8960433e-25 2.1444917e-20 2.7586096e-26], sum to 1.0000
[2019-04-27 20:49:39,862] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0163
[2019-04-27 20:49:39,871] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 86.0, 1.0, 2.0, 0.5630365697000225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 665332.5568710561, 665332.5568710561, 152907.2809829933], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6161400.0000, 
sim time next is 6162000.0000, 
raw observation next is [24.0, 85.66666666666667, 1.0, 2.0, 0.5592191833166501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 660156.4161806185, 660156.4161806185, 152241.4929332614], 
processed observation next is [1.0, 0.30434782608695654, 0.4444444444444444, 0.8566666666666667, 1.0, 1.0, 0.47526093251982154, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23577014863593515, 0.23577014863593515, 0.2927721017947335], 
reward next is 0.7072, 
noisyNet noise sample is [array([0.22409993], dtype=float32), -0.80129]. 
=============================================
[2019-04-27 20:49:39,883] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[52.33723 ]
 [52.37575 ]
 [52.40506 ]
 [52.561275]
 [52.597446]], R is [[52.38831711]
 [52.57038116]
 [52.74910736]
 [52.90775299]
 [53.0862236 ]].
[2019-04-27 20:49:41,244] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.1917960e-37 1.0000000e+00 0.0000000e+00 8.0319075e-33 0.0000000e+00], sum to 1.0000
[2019-04-27 20:49:41,253] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7034
[2019-04-27 20:49:41,258] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.36666666666667, 76.33333333333334, 1.0, 2.0, 0.5347138977926466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 630874.7560476072, 630874.7560476072, 148187.7915130049], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6133200.0000, 
sim time next is 6133800.0000, 
raw observation next is [25.23333333333333, 77.16666666666666, 1.0, 2.0, 0.5343480859753537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 630514.3072786106, 630514.3072786102, 148131.1735287312], 
processed observation next is [1.0, 1.0, 0.49012345679012337, 0.7716666666666666, 1.0, 1.0, 0.44565248330399243, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22518368117093238, 0.2251836811709322, 0.28486764140140614], 
reward next is 0.7151, 
noisyNet noise sample is [array([-0.6168894], dtype=float32), -0.23931125]. 
=============================================
[2019-04-27 20:49:50,340] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.0478434e-34 1.0000000e+00 6.4215096e-38 1.8373801e-31 0.0000000e+00], sum to 1.0000
[2019-04-27 20:49:50,346] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5081
[2019-04-27 20:49:50,356] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.56666666666667, 64.66666666666667, 1.0, 2.0, 0.6072403608543481, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 699594.3739285101, 699594.3739285101, 159696.5042580312], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6290400.0000, 
sim time next is 6291000.0000, 
raw observation next is [28.45, 65.0, 1.0, 2.0, 0.6062330539222954, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 699190.8287905091, 699190.8287905091, 159557.3134208887], 
processed observation next is [0.0, 0.8260869565217391, 0.6092592592592593, 0.65, 1.0, 1.0, 0.5312298260979708, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2497110102823247, 0.2497110102823247, 0.3068409873478629], 
reward next is 0.6932, 
noisyNet noise sample is [array([-0.26234463], dtype=float32), 0.7590038]. 
=============================================
[2019-04-27 20:49:50,375] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[76.67813 ]
 [76.61757 ]
 [76.53881 ]
 [76.38468 ]
 [76.338646]], R is [[76.65937042]
 [76.58567047]
 [76.51176453]
 [76.43682098]
 [76.36112976]].
[2019-04-27 20:49:51,480] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.1360146e-21 1.0000000e+00 8.4000713e-27 6.1100006e-19 4.0990977e-22], sum to 1.0000
[2019-04-27 20:49:51,487] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6573
[2019-04-27 20:49:51,490] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.53333333333333, 45.33333333333334, 1.0, 2.0, 0.9001202130156413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.086052491005064, 6.9112, 121.9251150123098, 1218725.264107981, 1129185.84178886, 221619.7634638274], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5829600.0000, 
sim time next is 5830200.0000, 
raw observation next is [26.6, 45.5, 1.0, 2.0, 0.9038185791195201, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.104559769049052, 6.9112, 121.9250150377203, 1231636.606345274, 1132619.956799492, 222449.1399466163], 
processed observation next is [1.0, 0.4782608695652174, 0.5407407407407407, 0.455, 1.0, 1.0, 0.8854983084756192, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.019335976904905204, 0.0, 0.8094553067712101, 0.4398702165518836, 0.40450712742839, 0.42778680758964677], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.1498883], dtype=float32), -0.53894174]. 
=============================================
[2019-04-27 20:49:54,150] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5631247e-28 1.0000000e+00 1.2179362e-32 5.8243334e-27 1.8047449e-31], sum to 1.0000
[2019-04-27 20:49:54,163] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8264
[2019-04-27 20:49:54,169] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.1, 84.66666666666667, 1.0, 2.0, 0.3579557707776854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 449506.680267098, 449506.6802670975, 122966.9392552335], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5881800.0000, 
sim time next is 5882400.0000, 
raw observation next is [20.0, 85.0, 1.0, 2.0, 0.3562434871023075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 447672.2012988198, 447672.2012988198, 122742.9982728611], 
processed observation next is [1.0, 0.08695652173913043, 0.2962962962962963, 0.85, 1.0, 1.0, 0.23362319893131847, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15988292903529278, 0.15988292903529278, 0.2360442274478098], 
reward next is 0.7640, 
noisyNet noise sample is [array([0.68098885], dtype=float32), -0.26365802]. 
=============================================
[2019-04-27 20:50:04,650] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.1120684e-28 1.0000000e+00 9.2731769e-32 1.2616653e-24 7.4242683e-28], sum to 1.0000
[2019-04-27 20:50:04,657] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5221
[2019-04-27 20:50:04,661] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 83.0, 1.0, 2.0, 0.5126235108985875, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 609231.5549521815, 609231.5549521815, 144810.5617840939], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6071400.0000, 
sim time next is 6072000.0000, 
raw observation next is [24.06666666666667, 82.66666666666667, 1.0, 2.0, 0.5718375886006896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 679337.4781324554, 679337.4781324558, 154532.7647036214], 
processed observation next is [1.0, 0.2608695652173913, 0.4469135802469137, 0.8266666666666667, 1.0, 1.0, 0.49028284357224944, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24262052790444835, 0.24262052790444852, 0.2971783936608104], 
reward next is 0.7028, 
noisyNet noise sample is [array([-0.1664882], dtype=float32), -2.4937172]. 
=============================================
[2019-04-27 20:50:04,676] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[67.28011 ]
 [67.2078  ]
 [67.145805]
 [67.037315]
 [67.21633 ]], R is [[67.11851501]
 [67.16885376]
 [67.21625519]
 [67.24915314]
 [67.28538513]].
[2019-04-27 20:50:08,854] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-04-27 20:50:08,856] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 20:50:08,857] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:50:08,858] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 20:50:08,859] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:50:08,859] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 20:50:08,860] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 20:50:08,861] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 20:50:08,861] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:50:08,863] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:50:08,862] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:50:08,884] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run67
[2019-04-27 20:50:08,884] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run67
[2019-04-27 20:50:08,929] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run67
[2019-04-27 20:50:08,960] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run67
[2019-04-27 20:50:08,982] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run67
[2019-04-27 20:51:04,995] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12595284]
[2019-04-27 20:51:04,996] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.33333333333334, 92.50000000000001, 1.0, 2.0, 0.6611240679292221, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 753472.6353949148, 753472.6353949148, 168914.4880713395]
[2019-04-27 20:51:04,996] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 20:51:04,999] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.7158661e-28 1.0000000e+00 6.3764679e-32 5.0894449e-26 7.8906910e-33], sampled 0.9698780581795328
[2019-04-27 20:51:19,172] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12595284]
[2019-04-27 20:51:19,174] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.25, 92.50000000000001, 1.0, 2.0, 0.5923320784556791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 683083.7411347777, 683083.7411347777, 157154.729065079]
[2019-04-27 20:51:19,174] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 20:51:19,177] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.4522078e-29 1.0000000e+00 2.1769950e-32 2.0290183e-26 2.2423921e-33], sampled 0.6568171111972531
[2019-04-27 20:51:19,911] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12595284]
[2019-04-27 20:51:19,911] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.41666666666667, 56.66666666666666, 1.0, 2.0, 0.5112630095985693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 607351.9983049335, 607351.9983049335, 144584.089236037]
[2019-04-27 20:51:19,912] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 20:51:19,913] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.1100985e-30 1.0000000e+00 4.6072169e-34 8.4945788e-28 4.0384771e-35], sampled 0.8700565991295897
[2019-04-27 20:51:38,835] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12595284]
[2019-04-27 20:51:38,837] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.30818492, 91.19020037, 1.0, 2.0, 0.7081703093624994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 807118.7217186622, 807118.7217186622, 177698.4023744927]
[2019-04-27 20:51:38,838] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 20:51:38,840] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.3012200e-29 1.0000000e+00 6.4745325e-33 7.8342385e-27 7.5051150e-34], sampled 0.5631215433768751
[2019-04-27 20:51:54,926] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.0852 2170656631.3663 493.0000
[2019-04-27 20:51:55,332] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8923.4199 2120533710.1715 430.0000
[2019-04-27 20:51:55,453] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8583.7021 2248718286.8236 553.0000
[2019-04-27 20:51:55,551] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8098.4495 2445508074.6415 746.0000
[2019-04-27 20:51:55,571] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8700.8700 2195155380.8105 572.0000
[2019-04-27 20:51:56,591] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1650000, evaluation results [1650000.0, 8098.4494892610255, 2445508074.64147, 746.0, 8771.085197215923, 2170656631.3662677, 493.0, 8923.419851553375, 2120533710.171511, 430.0, 8583.702050975664, 2248718286.823596, 553.0, 8700.870031992405, 2195155380.8105125, 572.0]
[2019-04-27 20:52:13,931] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4325978e-30 1.0000000e+00 1.2551317e-32 8.7434174e-29 9.6900628e-34], sum to 1.0000
[2019-04-27 20:52:13,941] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2496
[2019-04-27 20:52:13,947] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2225488.538317707 W.
[2019-04-27 20:52:13,952] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.65, 55.0, 1.0, 2.0, 0.6739155873723266, 1.0, 2.0, 0.6503224556625979, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2225488.538317707, 2225488.538317707, 422304.2973055762], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6451800.0000, 
sim time next is 6452400.0000, 
raw observation next is [31.6, 55.0, 1.0, 2.0, 0.6193366102786736, 1.0, 2.0, 0.6193366102786736, 1.0, 2.0, 0.9860040539488774, 6.911200000000001, 6.9112, 121.94756008, 2119325.095009853, 2119325.095009852, 406011.7898156627], 
processed observation next is [1.0, 0.6956521739130435, 0.725925925925926, 0.55, 1.0, 1.0, 0.5468292979508019, 1.0, 1.0, 0.5468292979508019, 1.0, 1.0, 0.9825050674360966, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7569018196463762, 0.7569018196463758, 0.7807919034916591], 
reward next is 0.2192, 
noisyNet noise sample is [array([1.944623], dtype=float32), -0.18039556]. 
=============================================
[2019-04-27 20:52:14,741] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.1418268e-30 1.0000000e+00 1.8519364e-34 5.1869723e-27 1.4710727e-34], sum to 1.0000
[2019-04-27 20:52:14,752] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5279
[2019-04-27 20:52:14,757] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.93333333333334, 58.5, 1.0, 2.0, 0.642353881006864, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 732070.3353543069, 732070.3353543069, 165518.3694036835], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6459000.0000, 
sim time next is 6459600.0000, 
raw observation next is [30.86666666666667, 59.0, 1.0, 2.0, 0.6584961059983069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 750476.1226142009, 750476.1226142009, 168435.3067240966], 
processed observation next is [1.0, 0.782608695652174, 0.6987654320987656, 0.59, 1.0, 1.0, 0.5934477452360796, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2680271866479289, 0.2680271866479289, 0.32391405139249346], 
reward next is 0.6761, 
noisyNet noise sample is [array([-0.41463205], dtype=float32), -0.30666775]. 
=============================================
[2019-04-27 20:52:17,657] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.3431401e-19 1.0000000e+00 2.8197618e-21 2.3398104e-17 1.5974741e-19], sum to 1.0000
[2019-04-27 20:52:17,664] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4052
[2019-04-27 20:52:17,672] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2183925.059311491 W.
[2019-04-27 20:52:17,680] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.76666666666667, 82.5, 1.0, 2.0, 0.9572874826891766, 1.0, 2.0, 0.9572874826891766, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 2183925.059311491, 2183925.059311491, 413035.1418444856], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6515400.0000, 
sim time next is 6516000.0000, 
raw observation next is [27.9, 82.0, 1.0, 2.0, 0.934800361106195, 1.0, 2.0, 0.934800361106195, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2132562.393895558, 2132562.393895558, 402605.1485501909], 
processed observation next is [1.0, 0.43478260869565216, 0.5888888888888888, 0.82, 1.0, 1.0, 0.9223813822692798, 1.0, 1.0, 0.9223813822692798, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7616294263912707, 0.7616294263912707, 0.7742406702888287], 
reward next is 0.2258, 
noisyNet noise sample is [array([2.044027], dtype=float32), 1.015534]. 
=============================================
[2019-04-27 20:52:17,694] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[44.86455 ]
 [45.19092 ]
 [43.882736]
 [44.13924 ]
 [42.94012 ]], R is [[45.0354538 ]
 [44.58509827]
 [44.13924789]
 [43.9420433 ]
 [43.50262451]].
[2019-04-27 20:52:20,640] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.9780116e-29 1.0000000e+00 8.5867623e-32 4.8822386e-26 1.6865050e-32], sum to 1.0000
[2019-04-27 20:52:20,647] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6090
[2019-04-27 20:52:20,651] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.7, 57.0, 1.0, 2.0, 0.4147870532348812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 511464.3713755981, 511464.3713755981, 130663.2806097992], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6571800.0000, 
sim time next is 6572400.0000, 
raw observation next is [25.66666666666667, 55.33333333333333, 1.0, 2.0, 0.4016593484904655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 497441.1045848861, 497441.1045848861, 128847.7229830337], 
processed observation next is [1.0, 0.043478260869565216, 0.506172839506173, 0.5533333333333332, 1.0, 1.0, 0.2876897005838875, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17765753735174503, 0.17765753735174503, 0.2477840826596802], 
reward next is 0.7522, 
noisyNet noise sample is [array([-1.368991], dtype=float32), -0.939245]. 
=============================================
[2019-04-27 20:52:29,271] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.4107164e-35 1.0000000e+00 0.0000000e+00 2.5421847e-33 0.0000000e+00], sum to 1.0000
[2019-04-27 20:52:29,273] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0600
[2019-04-27 20:52:29,278] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.25, 31.16666666666667, 1.0, 2.0, 0.3454398656302953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 437501.6757580708, 437501.6757580708, 121353.6147512986], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6717000.0000, 
sim time next is 6717600.0000, 
raw observation next is [29.0, 32.0, 1.0, 2.0, 0.3453279534466891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 437376.6201298659, 437376.6201298659, 121339.0396483638], 
processed observation next is [1.0, 0.782608695652174, 0.6296296296296297, 0.32, 1.0, 1.0, 0.2206285160079632, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15620593576066638, 0.15620593576066638, 0.23334430701608425], 
reward next is 0.7667, 
noisyNet noise sample is [array([0.7508721], dtype=float32), 1.4581562]. 
=============================================
[2019-04-27 20:52:30,570] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.6578321e-31 1.0000000e+00 3.5616485e-34 2.2761731e-28 9.2205792e-33], sum to 1.0000
[2019-04-27 20:52:30,580] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5032
[2019-04-27 20:52:30,586] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.06666666666667, 73.33333333333333, 1.0, 2.0, 0.4080885823153282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 503209.6180078526, 503209.6180078526, 129707.2970268482], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7238400.0000, 
sim time next is 7239000.0000, 
raw observation next is [22.98333333333333, 73.66666666666667, 1.0, 2.0, 0.4081346591852679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 503502.5664998583, 503502.5664998583, 129719.647880465], 
processed observation next is [1.0, 0.782608695652174, 0.40679012345679005, 0.7366666666666667, 1.0, 1.0, 0.2953984037919856, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1798223451785208, 0.1798223451785208, 0.24946086130858652], 
reward next is 0.7505, 
noisyNet noise sample is [array([0.28069547], dtype=float32), 0.96367335]. 
=============================================
[2019-04-27 20:52:30,604] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[77.36794]
 [77.44867]
 [77.01001]
 [76.70704]
 [76.58338]], R is [[77.07374573]
 [77.05357361]
 [77.03225708]
 [77.00991821]
 [76.98760223]].
[2019-04-27 20:52:31,179] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.6131426e-28 1.0000000e+00 4.1534277e-32 5.5564092e-27 8.2584741e-31], sum to 1.0000
[2019-04-27 20:52:31,187] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8231
[2019-04-27 20:52:31,197] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.5, 83.0, 1.0, 2.0, 0.3224692771444891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 412862.3873046073, 412862.3873046073, 118398.4011918252], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6753600.0000, 
sim time next is 6754200.0000, 
raw observation next is [18.41666666666667, 83.33333333333334, 1.0, 2.0, 0.3769921223279845, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 482822.4138636118, 482822.4138636118, 125619.549212766], 
processed observation next is [1.0, 0.17391304347826086, 0.2376543209876545, 0.8333333333333335, 1.0, 1.0, 0.2583239551523625, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17243657637986137, 0.17243657637986137, 0.24157605617839614], 
reward next is 0.7584, 
noisyNet noise sample is [array([1.2721196], dtype=float32), -0.83741045]. 
=============================================
[2019-04-27 20:52:33,008] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.4003113e-31 1.0000000e+00 1.7085495e-37 4.3353119e-29 1.4004677e-32], sum to 1.0000
[2019-04-27 20:52:33,015] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1463
[2019-04-27 20:52:33,020] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.68333333333333, 80.33333333333333, 1.0, 2.0, 0.4822354777582938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 580067.1145566411, 580067.1145566411, 140305.7219665083], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6821400.0000, 
sim time next is 6822000.0000, 
raw observation next is [23.6, 81.0, 1.0, 2.0, 0.4838609596029941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 581913.4956293113, 581913.4956293113, 140553.169583479], 
processed observation next is [1.0, 1.0, 0.4296296296296297, 0.81, 1.0, 1.0, 0.38554876143213584, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20782624843903974, 0.20782624843903974, 0.27029455689130577], 
reward next is 0.7297, 
noisyNet noise sample is [array([0.33203074], dtype=float32), -1.4453351]. 
=============================================
[2019-04-27 20:52:33,036] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[74.10074 ]
 [74.06087 ]
 [74.018326]
 [73.94266 ]
 [73.86526 ]], R is [[74.38485718]
 [74.3711853 ]
 [74.35778046]
 [74.34414673]
 [74.33061981]].
[2019-04-27 20:52:45,271] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.9963560e-32 1.0000000e+00 5.8750274e-36 4.2105470e-28 3.3504169e-35], sum to 1.0000
[2019-04-27 20:52:45,277] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4426
[2019-04-27 20:52:45,281] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 95.0, 1.0, 2.0, 0.4357045955477148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 530869.5181663992, 530869.5181663992, 133528.3550181051], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7545600.0000, 
sim time next is 7546200.0000, 
raw observation next is [21.18333333333333, 94.33333333333334, 1.0, 2.0, 0.4393901362459653, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 534754.4986671219, 534754.4986671219, 134052.3347524344], 
processed observation next is [0.0, 0.34782608695652173, 0.34012345679012335, 0.9433333333333335, 1.0, 1.0, 0.33260730505472064, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1909837495239721, 0.1909837495239721, 0.2577929514469892], 
reward next is 0.7422, 
noisyNet noise sample is [array([-0.5404766], dtype=float32), -1.7095944]. 
=============================================
[2019-04-27 20:52:46,370] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.5717387e-28 1.0000000e+00 2.4492596e-31 3.3049138e-25 2.0143423e-26], sum to 1.0000
[2019-04-27 20:52:46,380] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2380
[2019-04-27 20:52:46,385] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.93333333333333, 89.66666666666666, 1.0, 2.0, 0.4891636714449316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 602548.9873234936, 602548.9873234931, 141802.3038094791], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7018800.0000, 
sim time next is 7019400.0000, 
raw observation next is [21.01666666666667, 89.33333333333333, 1.0, 2.0, 0.4887504962153975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 601673.7167324402, 601673.7167324397, 141728.3146024143], 
processed observation next is [1.0, 0.21739130434782608, 0.3339506172839507, 0.8933333333333333, 1.0, 1.0, 0.3913696383516638, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21488347026158577, 0.2148834702615856, 0.27255445115848903], 
reward next is 0.7274, 
noisyNet noise sample is [array([-0.48819086], dtype=float32), -0.2882635]. 
=============================================
[2019-04-27 20:52:49,576] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-04-27 20:52:49,578] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 20:52:49,579] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:52:49,580] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 20:52:49,580] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:52:49,581] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 20:52:49,581] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 20:52:49,582] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:52:49,582] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 20:52:49,583] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:52:49,584] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:52:49,607] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run68
[2019-04-27 20:52:49,608] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run68
[2019-04-27 20:52:49,608] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run68
[2019-04-27 20:52:49,649] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run68
[2019-04-27 20:52:49,649] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run68
[2019-04-27 20:53:43,447] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12726384]
[2019-04-27 20:53:43,448] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.0, 74.0, 1.0, 2.0, 0.4688549046589027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 568381.6001705527, 568381.6001705527, 138399.6147180252]
[2019-04-27 20:53:43,449] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 20:53:43,452] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.8899534e-35 1.0000000e+00 0.0000000e+00 2.7937818e-32 0.0000000e+00], sampled 0.16820803746799717
[2019-04-27 20:53:53,631] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12726384]
[2019-04-27 20:53:53,632] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.0, 89.0, 1.0, 2.0, 0.6066148837832892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 694985.9889504672, 694985.9889504672, 159400.2595746484]
[2019-04-27 20:53:53,633] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 20:53:53,636] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0467753e-32 1.0000000e+00 5.8951622e-37 1.1164283e-29 1.7152833e-36], sampled 0.9915473129069484
[2019-04-27 20:53:56,060] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12726384]
[2019-04-27 20:53:56,062] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.0, 88.5, 1.0, 2.0, 0.8315010812634274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260425976448, 990211.6484524378, 990211.6484524374, 204583.3730948922]
[2019-04-27 20:53:56,062] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 20:53:56,064] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.1768310e-30 1.0000000e+00 2.0904333e-34 1.5405654e-27 1.2734917e-33], sampled 0.8171939928704581
[2019-04-27 20:54:25,105] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12726384]
[2019-04-27 20:54:25,107] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.5, 84.33333333333334, 1.0, 2.0, 0.5534337162727762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 682420.0236321852, 682420.0236321852, 152247.6667799015]
[2019-04-27 20:54:25,107] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 20:54:25,109] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.5901735e-32 1.0000000e+00 5.7545851e-36 5.9532198e-29 1.2836450e-35], sampled 0.3734082600843268
[2019-04-27 20:54:31,363] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12726384]
[2019-04-27 20:54:31,363] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.50342289666667, 85.43592554666667, 1.0, 2.0, 0.5079934489694707, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 604342.822599475, 604342.8225994746, 144098.3193488651]
[2019-04-27 20:54:31,364] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 20:54:31,366] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.1306368e-36 1.0000000e+00 0.0000000e+00 3.9165304e-33 0.0000000e+00], sampled 0.9424011846759551
[2019-04-27 20:54:37,146] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.0852 2170656631.3663 493.0000
[2019-04-27 20:54:37,274] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8098.4495 2445508074.6415 746.0000
[2019-04-27 20:54:37,313] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8700.8700 2195155380.8105 572.0000
[2019-04-27 20:54:37,343] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8923.4199 2120533710.1715 430.0000
[2019-04-27 20:54:37,611] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8583.7021 2248718286.8236 553.0000
[2019-04-27 20:54:38,628] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1675000, evaluation results [1675000.0, 8098.4494892610255, 2445508074.64147, 746.0, 8771.085197215923, 2170656631.3662677, 493.0, 8923.419851553375, 2120533710.171511, 430.0, 8583.702050975664, 2248718286.823596, 553.0, 8700.870031992405, 2195155380.8105125, 572.0]
[2019-04-27 20:54:52,145] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.0549372e-30 1.0000000e+00 4.3059328e-33 4.1393112e-28 2.9871513e-34], sum to 1.0000
[2019-04-27 20:54:52,153] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1816
[2019-04-27 20:54:52,160] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.9, 96.0, 1.0, 2.0, 0.4383501295906114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 533984.7759384912, 533984.7759384912, 133913.8438600072], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7527600.0000, 
sim time next is 7528200.0000, 
raw observation next is [20.9, 96.0, 1.0, 2.0, 0.4383429611470255, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 533976.3554238365, 533976.355423836, 133912.7984093979], 
processed observation next is [0.0, 0.13043478260869565, 0.32962962962962955, 0.96, 1.0, 1.0, 0.33136066803217323, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19070584122279874, 0.19070584122279857, 0.2575246123257652], 
reward next is 0.7425, 
noisyNet noise sample is [array([0.31426203], dtype=float32), 0.6758422]. 
=============================================
[2019-04-27 20:54:58,460] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:54:58,461] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:54:58,508] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run9
[2019-04-27 20:54:58,843] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.8960443e-34 1.0000000e+00 1.2551854e-38 2.0945015e-29 6.7734232e-36], sum to 1.0000
[2019-04-27 20:54:58,853] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6872
[2019-04-27 20:54:58,858] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.78333333333333, 78.66666666666667, 1.0, 2.0, 0.5185310200625776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 614441.4705036068, 614441.4705036068, 145683.9262028838], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7492200.0000, 
sim time next is 7492800.0000, 
raw observation next is [24.66666666666667, 79.33333333333334, 1.0, 2.0, 0.5165849728438026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 612336.4326784036, 612336.4326784036, 145380.6292170055], 
processed observation next is [0.0, 0.7391304347826086, 0.469135802469136, 0.7933333333333334, 1.0, 1.0, 0.4245059200521459, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21869158309942985, 0.21869158309942985, 0.279578133109626], 
reward next is 0.7204, 
noisyNet noise sample is [array([0.4540896], dtype=float32), -1.348936]. 
=============================================
[2019-04-27 20:54:58,900] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.61908781e-34 1.00000000e+00 1.77002745e-38 1.47480662e-30
 1.11582036e-35], sum to 1.0000
[2019-04-27 20:54:58,913] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7505
[2019-04-27 20:54:58,917] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.3, 59.5, 1.0, 2.0, 0.4917265328938383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 589346.4652164247, 589346.4652164247, 141704.4443693892], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7932600.0000, 
sim time next is 7933200.0000, 
raw observation next is [27.13333333333333, 60.0, 1.0, 2.0, 0.492499917014654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 590934.9848711631, 590934.9848711631, 141848.3320257238], 
processed observation next is [1.0, 0.8260869565217391, 0.5604938271604937, 0.6, 1.0, 1.0, 0.39583323454125474, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21104820888255826, 0.21104820888255826, 0.2727852538956227], 
reward next is 0.7272, 
noisyNet noise sample is [array([-0.37386715], dtype=float32), 1.0759463]. 
=============================================
[2019-04-27 20:55:00,593] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:55:00,593] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:55:00,659] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run9
[2019-04-27 20:55:01,825] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.4068796e-28 1.0000000e+00 6.3352986e-32 7.9070128e-28 9.5179902e-33], sum to 1.0000
[2019-04-27 20:55:01,831] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7072
[2019-04-27 20:55:01,836] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.93333333333333, 96.0, 1.0, 2.0, 0.4375735928087751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 532793.1975728913, 532793.1975728913, 133792.3974413281], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7539600.0000, 
sim time next is 7540200.0000, 
raw observation next is [20.95, 96.0, 1.0, 2.0, 0.4382123090340981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 533425.6217944389, 533425.6217944389, 133881.9930066861], 
processed observation next is [0.0, 0.2608695652173913, 0.33148148148148143, 0.96, 1.0, 1.0, 0.3312051298024978, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19050915064087104, 0.19050915064087104, 0.25746537116670404], 
reward next is 0.7425, 
noisyNet noise sample is [array([-2.0184312], dtype=float32), 0.4915294]. 
=============================================
[2019-04-27 20:55:03,459] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.8655602e-32 1.0000000e+00 5.3074603e-37 1.5555567e-30 3.3834105e-36], sum to 1.0000
[2019-04-27 20:55:03,471] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8445
[2019-04-27 20:55:03,477] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.8, 65.5, 1.0, 2.0, 0.5107267373185771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 606565.3915639599, 606565.3915639599, 144493.2864185198], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7579800.0000, 
sim time next is 7580400.0000, 
raw observation next is [26.63333333333333, 66.66666666666667, 1.0, 2.0, 0.5133861055654559, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 609322.5633415286, 609322.5633415286, 144900.7733438944], 
processed observation next is [0.0, 0.7391304347826086, 0.5419753086419752, 0.6666666666666667, 1.0, 1.0, 0.42069774472078086, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21761520119340308, 0.21761520119340308, 0.27865533335364306], 
reward next is 0.7213, 
noisyNet noise sample is [array([0.962813], dtype=float32), -0.7752269]. 
=============================================
[2019-04-27 20:55:09,468] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.4676273e-31 1.0000000e+00 8.2991254e-37 2.3619851e-27 1.5579816e-35], sum to 1.0000
[2019-04-27 20:55:09,474] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9769
[2019-04-27 20:55:09,483] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.15, 15.5, 1.0, 2.0, 0.3193496385474931, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 411957.583782145, 411957.583782145, 97300.66504555776], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 178200.0000, 
sim time next is 178800.0000, 
raw observation next is [26.9, 16.0, 1.0, 2.0, 0.3163058034277408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 408030.0247647578, 408030.0247647578, 96698.84718563565], 
processed observation next is [0.0, 0.043478260869565216, 0.5518518518518518, 0.16, 1.0, 1.0, 0.1860783374139771, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14572500884455636, 0.14572500884455636, 0.18595932151083777], 
reward next is 0.8140, 
noisyNet noise sample is [array([0.4454688], dtype=float32), -1.4463369]. 
=============================================
[2019-04-27 20:55:15,222] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.7716523e-34 1.0000000e+00 4.6856757e-37 6.9412095e-32 3.6138669e-38], sum to 1.0000
[2019-04-27 20:55:15,230] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2426
[2019-04-27 20:55:15,239] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1549349.866443273 W.
[2019-04-27 20:55:15,244] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.13333333333333, 50.66666666666667, 1.0, 2.0, 0.6625444815615752, 1.0, 1.0, 0.6625444815615752, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1549349.866443273, 1549349.866443273, 292079.167423701], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7748400.0000, 
sim time next is 7749000.0000, 
raw observation next is [29.1, 51.0, 1.0, 2.0, 0.7038253888526583, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9730812702064386, 6.9112, 6.9112, 121.9260426156618, 1541651.907852865, 1541651.907852865, 313061.2453623897], 
processed observation next is [1.0, 0.6956521739130435, 0.6333333333333334, 0.51, 1.0, 1.0, 0.6474111772055456, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9663515877580483, 0.0, 0.0, 0.8094621288201359, 0.5505899670903089, 0.5505899670903089, 0.602040856466134], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3821828], dtype=float32), 1.3589734]. 
=============================================
[2019-04-27 20:55:15,267] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[81.90529]
 [82.09486]
 [81.75917]
 [81.65321]
 [81.60586]], R is [[82.11177826]
 [81.29066467]
 [80.47776031]
 [79.67298126]
 [78.87625122]].
[2019-04-27 20:55:16,481] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:55:16,481] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:55:16,542] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run9
[2019-04-27 20:55:24,538] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:55:24,538] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:55:24,597] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run9
[2019-04-27 20:55:24,761] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.9216496e-28 1.0000000e+00 6.1100268e-33 1.5499970e-27 5.0949463e-32], sum to 1.0000
[2019-04-27 20:55:24,767] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0097
[2019-04-27 20:55:24,771] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1644510.406262112 W.
[2019-04-27 20:55:24,774] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.1, 48.0, 1.0, 2.0, 0.4785717594679786, 1.0, 1.0, 0.4785717594679786, 1.0, 2.0, 0.7621010637441913, 6.911199999999999, 6.9112, 121.94756008, 1644510.406262112, 1644510.406262112, 333245.6221926783], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7920000.0000, 
sim time next is 7920600.0000, 
raw observation next is [30.1, 48.33333333333333, 1.0, 2.0, 0.8330432098315443, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9804879577853796, 6.911199999999999, 6.9112, 121.9260426156618, 1683739.664547418, 1683739.664547419, 339932.2216722256], 
processed observation next is [1.0, 0.6956521739130435, 0.6703703703703704, 0.4833333333333333, 1.0, 1.0, 0.8012419164661242, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9756099472317245, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6013355944812208, 0.6013355944812211, 0.6537158109081262], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.09262083], dtype=float32), -0.52325684]. 
=============================================
[2019-04-27 20:55:24,806] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:55:24,806] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:55:24,851] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run9
[2019-04-27 20:55:25,323] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:55:25,323] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:55:25,333] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:55:25,333] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:55:25,354] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.9052803e-25 1.0000000e+00 1.8980449e-28 3.3758762e-24 8.1121421e-28], sum to 1.0000
[2019-04-27 20:55:25,356] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run9
[2019-04-27 20:55:25,356] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5652
[2019-04-27 20:55:25,384] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.2, 76.66666666666667, 1.0, 2.0, 0.2799694444603035, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 361145.59734834, 361145.59734834, 109593.056054378], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 448800.0000, 
sim time next is 449400.0000, 
raw observation next is [18.05, 77.33333333333333, 1.0, 2.0, 0.2771871598564386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 357555.7625890263, 357555.7625890263, 108354.5181531878], 
processed observation next is [1.0, 0.17391304347826086, 0.2240740740740741, 0.7733333333333333, 1.0, 1.0, 0.13950852363861738, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.12769848663893796, 0.12769848663893796, 0.208374073371515], 
reward next is 0.7916, 
noisyNet noise sample is [array([-0.57313436], dtype=float32), 0.85072076]. 
=============================================
[2019-04-27 20:55:25,394] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run9
[2019-04-27 20:55:25,520] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:55:25,520] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:55:25,527] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run9
[2019-04-27 20:55:25,810] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:55:25,810] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:55:25,841] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run9
[2019-04-27 20:55:25,921] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:55:25,921] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:55:25,941] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run9
[2019-04-27 20:55:26,235] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:55:26,235] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:55:26,244] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run9
[2019-04-27 20:55:26,264] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:55:26,265] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:55:26,268] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run9
[2019-04-27 20:55:26,340] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:55:26,341] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:55:26,345] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run9
[2019-04-27 20:55:26,372] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:55:26,372] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:55:26,375] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:55:26,381] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:55:26,393] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run9
[2019-04-27 20:55:26,418] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run9
[2019-04-27 20:55:26,478] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 20:55:26,478] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:55:26,482] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run9
[2019-04-27 20:55:27,611] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.4367685e-26 1.0000000e+00 5.2626788e-31 7.1591149e-25 8.2693269e-29], sum to 1.0000
[2019-04-27 20:55:27,613] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8881
[2019-04-27 20:55:27,623] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.0, 74.66666666666667, 1.0, 2.0, 0.2593170419313834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 334499.2939728476, 334499.2939728476, 101406.370129977], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 18600.0000, 
sim time next is 19200.0000, 
raw observation next is [18.0, 74.33333333333334, 1.0, 2.0, 0.2493206403070959, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 321601.9913945755, 321601.9913945755, 99532.10862250344], 
processed observation next is [1.0, 0.21739130434782608, 0.2222222222222222, 0.7433333333333334, 1.0, 1.0, 0.10633409560368558, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.11485785406949126, 0.11485785406949126, 0.191407901197122], 
reward next is 0.8086, 
noisyNet noise sample is [array([-0.4463306], dtype=float32), 0.1928057]. 
=============================================
[2019-04-27 20:55:30,696] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-04-27 20:55:30,699] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 20:55:30,700] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 20:55:30,700] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:55:30,701] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:55:30,703] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 20:55:30,704] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 20:55:30,706] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:55:30,705] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 20:55:30,707] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:55:30,708] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:55:30,724] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run69
[2019-04-27 20:55:30,748] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run69
[2019-04-27 20:55:30,771] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run69
[2019-04-27 20:55:30,771] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run69
[2019-04-27 20:55:30,810] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run69
[2019-04-27 20:56:20,302] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12643546]
[2019-04-27 20:56:20,302] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.749105265, 83.70486428999999, 1.0, 2.0, 0.8077886792945532, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 920724.3706469144, 920724.3706469144, 197562.6735263877]
[2019-04-27 20:56:20,304] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 20:56:20,307] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.8378567e-31 1.0000000e+00 7.8004461e-36 2.8768130e-29 7.0113755e-35], sampled 0.5690155359008144
[2019-04-27 20:56:45,080] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12643546]
[2019-04-27 20:56:45,082] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.41666666666666, 71.5, 1.0, 2.0, 0.7115619210129795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 810986.2680349182, 810986.2680349192, 178346.4452958576]
[2019-04-27 20:56:45,083] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 20:56:45,086] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.2569184e-34 1.0000000e+00 1.7396501e-38 1.7172451e-31 1.4073030e-37], sampled 0.9997844969774456
[2019-04-27 20:56:49,055] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12643546]
[2019-04-27 20:56:49,056] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.0, 66.0, 1.0, 2.0, 0.6260154275891757, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 713441.253336149, 713441.253336149, 162610.074107255]
[2019-04-27 20:56:49,058] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 20:56:49,060] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.1152749e-33 1.0000000e+00 1.0788355e-37 8.4148073e-31 9.6509806e-37], sampled 0.45308614379683143
[2019-04-27 20:57:03,493] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12643546]
[2019-04-27 20:57:03,497] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.97977425333334, 59.00590971333334, 1.0, 2.0, 0.3836692196152714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 477283.3051036214, 477283.3051036214, 126383.8230191765]
[2019-04-27 20:57:03,501] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 20:57:03,505] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.9954053e-34 1.0000000e+00 0.0000000e+00 4.7392755e-32 3.1072061e-38], sampled 0.9599097593515944
[2019-04-27 20:57:17,556] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8921.8922 2120660928.3939 430.0000
[2019-04-27 20:57:17,605] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8582.0590 2248830394.8409 553.0000
[2019-04-27 20:57:18,185] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8098.4495 2445508074.6415 746.0000
[2019-04-27 20:57:18,311] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8769.4422 2170768739.9937 493.0000
[2019-04-27 20:57:18,400] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8699.3424 2195282598.7024 572.0000
[2019-04-27 20:57:19,419] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1700000, evaluation results [1700000.0, 8098.4494892610255, 2445508074.64147, 746.0, 8769.442185004564, 2170768739.993712, 493.0, 8921.892236157437, 2120660928.3938506, 430.0, 8582.059032767682, 2248830394.840892, 553.0, 8699.342416479873, 2195282598.702448, 572.0]
[2019-04-27 20:57:19,657] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.6595069e-32 1.0000000e+00 1.3216757e-37 3.7465756e-31 9.5069397e-37], sum to 1.0000
[2019-04-27 20:57:19,669] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4854
[2019-04-27 20:57:19,674] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.21666666666667, 67.5, 1.0, 2.0, 0.4196528812373806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 515773.9558479113, 515773.9558479113, 131320.3525264404], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 85800.0000, 
sim time next is 86400.0000, 
raw observation next is [24.1, 68.0, 1.0, 2.0, 0.4177922823182848, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 513741.0900432094, 513741.0900432099, 131059.0871083672], 
processed observation next is [1.0, 0.0, 0.4481481481481482, 0.68, 1.0, 1.0, 0.3068955741884343, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18347896072971764, 0.1834789607297178, 0.2520367059776292], 
reward next is 0.7480, 
noisyNet noise sample is [array([1.39935], dtype=float32), -0.5124328]. 
=============================================
[2019-04-27 20:57:26,199] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.4456639e-32 1.0000000e+00 9.7041735e-38 1.1439205e-28 1.1167109e-34], sum to 1.0000
[2019-04-27 20:57:26,207] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8665
[2019-04-27 20:57:26,210] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.81666666666667, 67.33333333333334, 1.0, 2.0, 0.3573439351555622, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 447758.4551323603, 447758.4551323603, 122869.8798434741], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 201000.0000, 
sim time next is 201600.0000, 
raw observation next is [23.0, 68.0, 1.0, 2.0, 0.3682960262470761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 459907.0458982203, 459907.0458982207, 124315.6953246518], 
processed observation next is [0.0, 0.34782608695652173, 0.4074074074074074, 0.68, 1.0, 1.0, 0.24797145981794771, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16425251639222155, 0.16425251639222166, 0.2390686448550996], 
reward next is 0.7609, 
noisyNet noise sample is [array([0.04231375], dtype=float32), 0.90761733]. 
=============================================
[2019-04-27 20:57:26,498] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5171472e-23 1.0000000e+00 6.5380618e-28 5.0776288e-21 8.0436800e-26], sum to 1.0000
[2019-04-27 20:57:26,506] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3886
[2019-04-27 20:57:26,518] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1381554.679651021 W.
[2019-04-27 20:57:26,522] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.4, 42.83333333333334, 1.0, 2.0, 0.3833850078645434, 1.0, 1.0, 0.3833850078645434, 1.0, 2.0, 0.6192706235820825, 6.9112, 6.9112, 121.94756008, 1381554.679651021, 1381554.679651021, 289382.4985639438], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 733800.0000, 
sim time next is 734400.0000, 
raw observation next is [28.7, 41.0, 1.0, 2.0, 0.3823213774455716, 1.0, 2.0, 0.3823213774455716, 1.0, 2.0, 0.6170005960911433, 6.911199999999999, 6.9112, 121.94756008, 1375522.512289789, 1375522.512289789, 288975.0714633958], 
processed observation next is [1.0, 0.5217391304347826, 0.6185185185185185, 0.41, 1.0, 1.0, 0.26466830648282336, 1.0, 1.0, 0.26466830648282336, 1.0, 1.0, 0.5212507451139291, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.4912580401034961, 0.4912580401034961, 0.5557212912757611], 
reward next is 0.4443, 
noisyNet noise sample is [array([0.16170134], dtype=float32), 1.9001426]. 
=============================================
[2019-04-27 20:57:35,505] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.6013260e-25 1.0000000e+00 2.5610256e-28 1.4952223e-23 1.7064014e-28], sum to 1.0000
[2019-04-27 20:57:35,513] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5094
[2019-04-27 20:57:35,521] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.95, 50.5, 1.0, 2.0, 0.2694582073309508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 347583.5916054388, 347583.5916054388, 105985.2170430282], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 348600.0000, 
sim time next is 349200.0000, 
raw observation next is [21.8, 51.0, 1.0, 2.0, 0.2678388048109389, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 345494.1969839053, 345494.1969839049, 105130.1605125173], 
processed observation next is [1.0, 0.043478260869565216, 0.362962962962963, 0.51, 1.0, 1.0, 0.12837952953683204, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12339078463710902, 0.1233907846371089, 0.2021733856009948], 
reward next is 0.7978, 
noisyNet noise sample is [array([-0.4112764], dtype=float32), 1.5919076]. 
=============================================
[2019-04-27 20:57:55,118] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.44994345e-22 1.00000000e+00 4.08013266e-27 1.07200255e-19
 2.10287713e-20], sum to 1.0000
[2019-04-27 20:57:55,129] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2676
[2019-04-27 20:57:55,135] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.03333333333333, 53.33333333333333, 1.0, 2.0, 0.479948796504953, 1.0, 1.0, 0.479948796504953, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.925658487826, 1184139.640926292, 1184139.640926292, 232689.4096308448], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 722400.0000, 
sim time next is 723000.0000, 
raw observation next is [25.16666666666667, 53.16666666666667, 1.0, 2.0, 0.8616507372948488, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260176617274, 1073666.849312075, 1073666.849312075, 212743.3164710493], 
processed observation next is [1.0, 0.34782608695652173, 0.4876543209876545, 0.5316666666666667, 1.0, 1.0, 0.8352984967795819, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094619631519618, 0.38345244618288393, 0.38345244618288393, 0.4091217624443256], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2162126], dtype=float32), -0.33641174]. 
=============================================
[2019-04-27 20:57:55,147] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[60.653057]
 [61.128025]
 [61.611923]
 [62.813435]
 [63.37561 ]], R is [[60.40702057]
 [60.35547256]
 [59.75191879]
 [59.15439987]
 [59.2299118 ]].
[2019-04-27 20:57:58,809] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.0243017e-33 1.0000000e+00 1.2212609e-35 1.4432343e-29 9.2540454e-35], sum to 1.0000
[2019-04-27 20:57:58,811] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9162
[2019-04-27 20:57:58,815] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.8, 53.16666666666666, 1.0, 2.0, 0.3799260576840032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 472983.279061183, 472983.2790611825, 125874.8014675363], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 810600.0000, 
sim time next is 811200.0000, 
raw observation next is [26.1, 52.33333333333334, 1.0, 2.0, 0.3840932160572779, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 477416.9237210405, 477416.9237210405, 126433.5905156698], 
processed observation next is [0.0, 0.391304347826087, 0.5222222222222223, 0.5233333333333334, 1.0, 1.0, 0.2667776381634261, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1705060441860859, 0.1705060441860859, 0.24314152022244193], 
reward next is 0.7569, 
noisyNet noise sample is [array([1.4388573], dtype=float32), -0.9217271]. 
=============================================
[2019-04-27 20:58:08,567] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.0330632e-33 1.0000000e+00 0.0000000e+00 5.3021114e-32 2.7736186e-38], sum to 1.0000
[2019-04-27 20:58:08,576] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6362
[2019-04-27 20:58:08,581] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.26666666666667, 50.0, 1.0, 2.0, 0.2874957181507429, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 368755.2394148224, 368755.2394148224, 114044.4328058891], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 948000.0000, 
sim time next is 948600.0000, 
raw observation next is [23.15, 50.5, 1.0, 2.0, 0.2856101507405612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 366404.2364530615, 366404.2364530615, 113815.754651611], 
processed observation next is [0.0, 1.0, 0.4129629629629629, 0.505, 1.0, 1.0, 0.1495358937387633, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1308586558760934, 0.1308586558760934, 0.21887645125309807], 
reward next is 0.7811, 
noisyNet noise sample is [array([0.7330993], dtype=float32), 0.72796655]. 
=============================================
[2019-04-27 20:58:11,504] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.7066707e-22 1.0000000e+00 6.9359712e-24 5.4752770e-19 1.4298813e-19], sum to 1.0000
[2019-04-27 20:58:11,509] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1701
[2019-04-27 20:58:11,513] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.73333333333333, 56.33333333333333, 1.0, 2.0, 0.9121778744055924, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.114153929648143, 6.9112, 121.9251262683552, 1238329.421561412, 1134399.650865575, 224191.3476336258], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 988800.0000, 
sim time next is 989400.0000, 
raw observation next is [24.86666666666667, 56.16666666666667, 1.0, 2.0, 0.9248992315748125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.21941814017108, 6.9112, 121.9245621504212, 1311765.273983093, 1153931.954476953, 227246.0871394973], 
processed observation next is [1.0, 0.43478260869565216, 0.47654320987654336, 0.5616666666666668, 1.0, 1.0, 0.9105943233033482, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.03082181401710802, 0.0, 0.8094523000705137, 0.4684875978511046, 0.41211855517034035, 0.43701170603749484], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.13609529], dtype=float32), -0.29486004]. 
=============================================
[2019-04-27 20:58:11,752] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6322911e-26 1.0000000e+00 6.8724276e-29 7.7808791e-24 2.5636256e-28], sum to 1.0000
[2019-04-27 20:58:11,762] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7572
[2019-04-27 20:58:11,766] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 69.33333333333334, 1.0, 2.0, 0.3871088853160263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 483393.1992034506, 483393.1992034501, 126894.7890214228], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1556400.0000, 
sim time next is 1557000.0000, 
raw observation next is [22.6, 70.0, 1.0, 2.0, 0.3867182427415263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 482894.4651534687, 482894.4651534682, 126840.3839731678], 
processed observation next is [1.0, 0.0, 0.39259259259259266, 0.7, 1.0, 1.0, 0.2699026699303884, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1724623089833817, 0.1724623089833815, 0.243923815333015], 
reward next is 0.7561, 
noisyNet noise sample is [array([1.1039466], dtype=float32), -1.1367688]. 
=============================================
[2019-04-27 20:58:11,782] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[61.96978]
 [64.00219]
 [67.87698]
 [72.51125]
 [72.47712]], R is [[61.15853882]
 [61.30292511]
 [61.44593048]
 [61.5874939 ]
 [61.72737503]].
[2019-04-27 20:58:11,920] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-04-27 20:58:11,922] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 20:58:11,922] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:58:11,924] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 20:58:11,924] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 20:58:11,924] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:58:11,925] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:58:11,927] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 20:58:11,929] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 20:58:11,930] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:58:11,931] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 20:58:11,955] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run70
[2019-04-27 20:58:11,955] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run70
[2019-04-27 20:58:11,955] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run70
[2019-04-27 20:58:12,019] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run70
[2019-04-27 20:58:12,020] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run70
[2019-04-27 20:58:13,162] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12737992]
[2019-04-27 20:58:13,164] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.85, 21.0, 1.0, 2.0, 0.5793138175396801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 743354.37390081, 743354.37390081, 157050.7644763628]
[2019-04-27 20:58:13,168] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 20:58:13,172] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.5065663e-27 1.0000000e+00 7.6369663e-31 5.7348068e-25 8.5732207e-30], sampled 0.4369522393789841
[2019-04-27 20:58:35,895] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12737992]
[2019-04-27 20:58:35,896] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.53333333333333, 54.66666666666667, 1.0, 2.0, 0.9419780592410129, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.286298932931869, 6.9112, 121.9244599620819, 1358422.854128841, 1166341.167842541, 231051.2112514927]
[2019-04-27 20:58:35,898] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 20:58:35,901] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.9467058e-23 1.0000000e+00 3.3147097e-26 3.5875393e-21 3.9044929e-25], sampled 0.6073955677224245
[2019-04-27 20:58:35,902] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1358422.854128841 W.
[2019-04-27 20:58:36,343] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12737992]
[2019-04-27 20:58:36,344] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [34.0, 28.0, 1.0, 2.0, 0.6740559906192664, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 823369.7301638292, 823369.7301638292, 173581.7970960471]
[2019-04-27 20:58:36,345] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 20:58:36,348] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.0420018e-27 1.0000000e+00 5.6171576e-31 4.5876832e-25 6.7363899e-30], sampled 0.1820147473244239
[2019-04-27 20:58:49,959] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12737992]
[2019-04-27 20:58:49,960] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.07069156, 66.98516230333334, 1.0, 2.0, 0.3499798440645716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 442018.4808715677, 442018.4808715677, 121940.0983182313]
[2019-04-27 20:58:49,961] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 20:58:49,964] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.4730491e-27 1.0000000e+00 1.4658821e-31 1.4470024e-25 1.4788178e-30], sampled 0.3560618946390868
[2019-04-27 20:59:07,418] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12737992]
[2019-04-27 20:59:07,420] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.83333333333334, 95.0, 1.0, 2.0, 0.7118885425142594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 811358.7243796494, 811358.7243796494, 178408.8904242311]
[2019-04-27 20:59:07,420] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 20:59:07,423] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.5363238e-27 1.0000000e+00 5.3223582e-31 4.4725973e-25 6.0770515e-30], sampled 0.3355608445192184
[2019-04-27 20:59:35,139] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12737992]
[2019-04-27 20:59:35,140] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.83333333333333, 94.0, 1.0, 2.0, 0.5571273321284209, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 646040.512996534, 646040.512996534, 151392.8104855471]
[2019-04-27 20:59:35,141] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 20:59:35,145] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [7.0811021e-27 1.0000000e+00 8.7720062e-31 6.7863150e-25 1.0178311e-29], sampled 0.18669596375731057
[2019-04-27 20:59:58,557] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8768.6241 2170826060.4938 493.0000
[2019-04-27 20:59:59,399] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8699.3424 2195282598.7024 572.0000
[2019-04-27 20:59:59,628] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8581.2410 2248887715.3409 553.0000
[2019-04-27 20:59:59,671] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8921.8922 2120660928.3939 430.0000
[2019-04-27 20:59:59,852] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8097.6795 2445569542.8369 746.0000
[2019-04-27 21:00:00,871] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1725000, evaluation results [1725000.0, 8097.679510568991, 2445569542.8369265, 746.0, 8768.624117554622, 2170826060.49376, 493.0, 8921.892236157437, 2120660928.3938506, 430.0, 8581.240965317736, 2248887715.34094, 553.0, 8699.342416479873, 2195282598.702448, 572.0]
[2019-04-27 21:00:13,612] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2292064e-20 1.0000000e+00 9.2582898e-26 1.7068993e-17 1.3597185e-15], sum to 1.0000
[2019-04-27 21:00:13,621] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7130
[2019-04-27 21:00:13,628] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.3, 75.16666666666667, 1.0, 2.0, 0.6705115514397066, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 842062.543147205, 842062.543147205, 173461.7232244515], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1245000.0000, 
sim time next is 1245600.0000, 
raw observation next is [21.5, 74.0, 1.0, 2.0, 0.6915228865664614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 868073.2946939792, 868073.2946939792, 177474.1859402438], 
processed observation next is [1.0, 0.43478260869565216, 0.35185185185185186, 0.74, 1.0, 1.0, 0.6327653411505493, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31002617667642113, 0.31002617667642113, 0.3412965114235458], 
reward next is 0.6587, 
noisyNet noise sample is [array([-0.660474], dtype=float32), 0.27295816]. 
=============================================
[2019-04-27 21:00:14,435] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.3913573e-31 1.0000000e+00 7.9665033e-36 7.4033644e-29 4.1093850e-29], sum to 1.0000
[2019-04-27 21:00:14,443] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9398
[2019-04-27 21:00:14,447] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 71.0, 1.0, 2.0, 0.4135043326408532, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 509359.9782602221, 509359.9782602221, 130466.7682512844], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1284000.0000, 
sim time next is 1284600.0000, 
raw observation next is [23.3, 72.0, 1.0, 2.0, 0.4118373762853879, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 507627.6089707423, 507627.6089707423, 130236.4732028431], 
processed observation next is [1.0, 0.8695652173913043, 0.41851851851851857, 0.72, 1.0, 1.0, 0.29980640033974754, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18129557463240797, 0.18129557463240797, 0.2504547561593137], 
reward next is 0.7495, 
noisyNet noise sample is [array([1.8063583], dtype=float32), 1.0817512]. 
=============================================
[2019-04-27 21:00:22,819] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4038177e-22 1.0000000e+00 2.6916539e-27 1.8458267e-21 6.9406324e-23], sum to 1.0000
[2019-04-27 21:00:22,830] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6482
[2019-04-27 21:00:22,835] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.9, 73.0, 1.0, 2.0, 0.8114588926413626, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156335, 969305.139773768, 969305.139773768, 200423.5068136753], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1945800.0000, 
sim time next is 1946400.0000, 
raw observation next is [25.16666666666667, 71.66666666666667, 1.0, 2.0, 0.735632595047104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 881843.5295816587, 881843.5295816587, 184974.7179867071], 
processed observation next is [1.0, 0.5217391304347826, 0.4876543209876545, 0.7166666666666667, 1.0, 1.0, 0.6852768988656, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3149441177077352, 0.3149441177077352, 0.3557206115128983], 
reward next is 0.6443, 
noisyNet noise sample is [array([-1.9695233], dtype=float32), -1.3400548]. 
=============================================
[2019-04-27 21:00:23,168] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.6831168e-31 1.0000000e+00 1.0028238e-36 2.0199717e-29 2.0656355e-36], sum to 1.0000
[2019-04-27 21:00:23,176] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3019
[2019-04-27 21:00:23,189] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.93333333333333, 65.33333333333334, 1.0, 2.0, 0.2947244638888094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 377238.5161715128, 377238.5161715128, 114927.4492429597], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1392600.0000, 
sim time next is 1393200.0000, 
raw observation next is [20.9, 65.0, 1.0, 2.0, 0.2927174310334548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 374944.4511863582, 374944.4511863582, 114681.4552010036], 
processed observation next is [0.0, 0.13043478260869565, 0.32962962962962955, 0.65, 1.0, 1.0, 0.15799694170649384, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1339087325665565, 0.1339087325665565, 0.22054126000193], 
reward next is 0.7795, 
noisyNet noise sample is [array([1.2442007], dtype=float32), -0.4803582]. 
=============================================
[2019-04-27 21:00:25,061] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.6067717e-34 1.0000000e+00 8.7358562e-35 2.5150247e-31 8.6953142e-38], sum to 1.0000
[2019-04-27 21:00:25,071] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3485
[2019-04-27 21:00:25,075] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.16666666666667, 22.5, 1.0, 2.0, 0.4051908548016208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 505017.0099025817, 505017.0099025813, 129415.2445149718], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1437000.0000, 
sim time next is 1437600.0000, 
raw observation next is [34.33333333333334, 22.0, 1.0, 2.0, 0.3992922397993027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 497820.3392054979, 497820.3392054979, 128583.9787233765], 
processed observation next is [0.0, 0.6521739130434783, 0.8271604938271608, 0.22, 1.0, 1.0, 0.2848717140467889, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17779297828767782, 0.17779297828767782, 0.2472768821603394], 
reward next is 0.7527, 
noisyNet noise sample is [array([-0.4350692], dtype=float32), 2.3701007]. 
=============================================
[2019-04-27 21:00:32,205] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.7754722e-23 1.0000000e+00 3.2094566e-26 7.9576305e-22 5.6581276e-23], sum to 1.0000
[2019-04-27 21:00:32,211] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8406
[2019-04-27 21:00:32,219] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.76666666666667, 57.66666666666667, 1.0, 2.0, 0.6781732922170783, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 854572.9600062153, 854572.9600062153, 174962.3340024203], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1585200.0000, 
sim time next is 1585800.0000, 
raw observation next is [23.9, 57.5, 1.0, 2.0, 0.7363644300639351, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 926590.8748521244, 926590.8748521239, 186349.7051581718], 
processed observation next is [1.0, 0.34782608695652173, 0.4407407407407407, 0.575, 1.0, 1.0, 0.6861481310284943, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.33092531244718726, 0.3309253124471871, 0.35836481761186884], 
reward next is 0.6416, 
noisyNet noise sample is [array([-1.2687262], dtype=float32), 0.08716396]. 
=============================================
[2019-04-27 21:00:34,748] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.0538721e-22 1.0000000e+00 3.6588481e-25 3.1780837e-19 1.9302892e-21], sum to 1.0000
[2019-04-27 21:00:34,755] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0100
[2019-04-27 21:00:34,758] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 57.5, 1.0, 2.0, 0.7363644300639351, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 926590.8748521244, 926590.8748521239, 186349.7051581718], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1585800.0000, 
sim time next is 1586400.0000, 
raw observation next is [24.03333333333333, 57.33333333333334, 1.0, 2.0, 0.7675409090965998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 964614.9543326052, 964614.9543326052, 192688.7973818687], 
processed observation next is [1.0, 0.34782608695652173, 0.4456790123456789, 0.5733333333333335, 1.0, 1.0, 0.7232629870197617, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3445053408330733, 0.3445053408330733, 0.3705553795805167], 
reward next is 0.6294, 
noisyNet noise sample is [array([-0.24587676], dtype=float32), 1.319787]. 
=============================================
[2019-04-27 21:00:37,249] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.6684800e-38 1.0000000e+00 0.0000000e+00 6.3064273e-35 0.0000000e+00], sum to 1.0000
[2019-04-27 21:00:37,257] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0145
[2019-04-27 21:00:37,263] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.76666666666667, 59.0, 1.0, 2.0, 0.3192721874444605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 405642.7657352912, 405642.7657352908, 117981.2735467374], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1640400.0000, 
sim time next is 1641000.0000, 
raw observation next is [22.68333333333333, 59.5, 1.0, 2.0, 0.3196390402238327, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 406104.3324141823, 406104.3324141823, 118027.8342555657], 
processed observation next is [1.0, 1.0, 0.39567901234567887, 0.595, 1.0, 1.0, 0.19004647645694372, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1450372615764937, 0.1450372615764937, 0.22697660433762634], 
reward next is 0.7730, 
noisyNet noise sample is [array([-0.05302906], dtype=float32), -0.16758458]. 
=============================================
[2019-04-27 21:00:37,279] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[94.10197]
 [94.04796]
 [93.95556]
 [93.86715]
 [93.7061 ]], R is [[93.98306274]
 [93.81634521]
 [93.65126038]
 [93.48762512]
 [93.3252182 ]].
[2019-04-27 21:00:41,331] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.6437237e-31 1.0000000e+00 8.8875774e-37 4.4984942e-29 5.7794561e-32], sum to 1.0000
[2019-04-27 21:00:41,341] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8267
[2019-04-27 21:00:41,350] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 79.0, 1.0, 2.0, 0.43727946306548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 534564.3627017266, 534564.3627017266, 133810.6098291677], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1714800.0000, 
sim time next is 1715400.0000, 
raw observation next is [22.75, 79.0, 1.0, 2.0, 0.432837475294517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 529792.4357921862, 529792.4357921862, 133177.4180527725], 
processed observation next is [1.0, 0.8695652173913043, 0.39814814814814814, 0.79, 1.0, 1.0, 0.3248065182077583, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18921158421149506, 0.18921158421149506, 0.2561104193322548], 
reward next is 0.7439, 
noisyNet noise sample is [array([0.28533933], dtype=float32), 0.59136456]. 
=============================================
[2019-04-27 21:00:53,558] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-04-27 21:00:53,559] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 21:00:53,560] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 21:00:53,562] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 21:00:53,563] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:00:53,561] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 21:00:53,564] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:00:53,564] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:00:53,566] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:00:53,563] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 21:00:53,572] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:00:53,587] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run71
[2019-04-27 21:00:53,611] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run71
[2019-04-27 21:00:53,611] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run71
[2019-04-27 21:00:53,630] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run71
[2019-04-27 21:00:53,673] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run71
[2019-04-27 21:01:06,509] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.124288134]
[2019-04-27 21:01:06,510] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [31.11688103, 29.352079025, 1.0, 2.0, 0.3580655508608694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 449972.7570845526, 449972.7570845526, 122987.4704686957]
[2019-04-27 21:01:06,511] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 21:01:06,514] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.4593441e-30 1.0000000e+00 1.0469899e-34 3.3658909e-28 7.9734434e-34], sampled 0.4656288221342848
[2019-04-27 21:01:48,383] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.124288134]
[2019-04-27 21:01:48,384] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.0, 100.0, 1.0, 2.0, 0.6954791816236476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 792646.8593159624, 792646.8593159624, 175291.3200031121]
[2019-04-27 21:01:48,385] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 21:01:48,387] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.8420608e-29 1.0000000e+00 1.6900139e-33 3.3601711e-27 1.3301105e-32], sampled 0.7238160636193492
[2019-04-27 21:01:54,908] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.124288134]
[2019-04-27 21:01:54,910] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [31.26666666666667, 57.33333333333334, 1.0, 2.0, 0.6268960013638267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 714445.2707951992, 714445.2707951992, 162767.8466749262]
[2019-04-27 21:01:54,910] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 21:01:54,913] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.9996050e-31 1.0000000e+00 1.1708338e-35 4.3118258e-29 4.6803570e-35], sampled 0.30365181868314894
[2019-04-27 21:01:55,149] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.124288134]
[2019-04-27 21:01:55,150] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.45801532, 85.92745117, 1.0, 2.0, 0.5739216913871167, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 670351.3573391498, 670351.3573391498, 154413.3937251232]
[2019-04-27 21:01:55,152] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 21:01:55,155] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.7364681e-30 1.0000000e+00 1.0274758e-34 3.5374759e-28 1.0747219e-33], sampled 0.4918438021672954
[2019-04-27 21:02:12,417] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.124288134]
[2019-04-27 21:02:12,417] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.33333333333334, 64.0, 1.0, 2.0, 0.4797636617589131, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 576656.6260548182, 576656.6260548182, 139909.7832670463]
[2019-04-27 21:02:12,418] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 21:02:12,421] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.7921102e-30 1.0000000e+00 2.2140101e-34 6.5950991e-28 1.8476964e-33], sampled 0.0211643230086207
[2019-04-27 21:02:41,248] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8581.2410 2248887715.3409 553.0000
[2019-04-27 21:02:41,324] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8768.6241 2170826060.4938 493.0000
[2019-04-27 21:02:41,573] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8097.6795 2445569542.8369 746.0000
[2019-04-27 21:02:41,703] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8921.8922 2120660928.3939 430.0000
[2019-04-27 21:02:41,709] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8699.3424 2195282598.7024 572.0000
[2019-04-27 21:02:42,728] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1750000, evaluation results [1750000.0, 8097.679510568991, 2445569542.8369265, 746.0, 8768.624117554622, 2170826060.49376, 493.0, 8921.892236157437, 2120660928.3938506, 430.0, 8581.240965317736, 2248887715.34094, 553.0, 8699.342416479873, 2195282598.702448, 572.0]
[2019-04-27 21:02:59,411] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.2668717e-31 1.0000000e+00 3.6811894e-34 9.5966868e-29 1.2883952e-33], sum to 1.0000
[2019-04-27 21:02:59,418] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6620
[2019-04-27 21:02:59,423] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.73333333333333, 98.0, 1.0, 2.0, 0.5520567281347377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 647625.4848806574, 647625.4848806574, 150881.5435902786], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2244000.0000, 
sim time next is 2244600.0000, 
raw observation next is [22.75, 98.0, 1.0, 2.0, 0.5516968049812161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 646986.1148935963, 646986.1148935963, 150812.8625797749], 
processed observation next is [1.0, 1.0, 0.39814814814814814, 0.98, 1.0, 1.0, 0.4663057202157334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2310664696048558, 0.2310664696048558, 0.2900247357303363], 
reward next is 0.7100, 
noisyNet noise sample is [array([1.1101196], dtype=float32), 0.48551548]. 
=============================================
[2019-04-27 21:03:08,865] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1419885e-29 1.0000000e+00 2.4772127e-32 1.6050059e-26 1.2185642e-31], sum to 1.0000
[2019-04-27 21:03:08,873] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8403
[2019-04-27 21:03:08,878] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 74.66666666666667, 1.0, 2.0, 0.6034079003132248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 695372.9325631983, 695372.9325631983, 159040.4963275515], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2657400.0000, 
sim time next is 2658000.0000, 
raw observation next is [26.66666666666667, 75.33333333333334, 1.0, 2.0, 0.6032175095075227, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 695969.4004889142, 695969.4004889142, 159046.0953150608], 
processed observation next is [0.0, 0.782608695652174, 0.5432098765432101, 0.7533333333333334, 1.0, 1.0, 0.5276398922708604, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24856050017461223, 0.24856050017461223, 0.3058578756058862], 
reward next is 0.6941, 
noisyNet noise sample is [array([0.71942866], dtype=float32), -0.035502438]. 
=============================================
[2019-04-27 21:03:08,898] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[70.87233 ]
 [70.8579  ]
 [70.79019 ]
 [70.80322 ]
 [70.802444]], R is [[70.86804962]
 [70.85352325]
 [70.8396759 ]
 [70.82875061]
 [70.82016754]].
[2019-04-27 21:03:14,471] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.6148359e-33 1.0000000e+00 7.4632286e-35 4.6304688e-29 6.6846891e-35], sum to 1.0000
[2019-04-27 21:03:14,477] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3512
[2019-04-27 21:03:14,483] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.83333333333334, 35.66666666666667, 1.0, 2.0, 0.4643379307158049, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 555635.9696665161, 555635.9696665161, 137468.6211516802], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2568000.0000, 
sim time next is 2568600.0000, 
raw observation next is [32.65000000000001, 36.5, 1.0, 2.0, 0.4577934147756291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 549731.7138641565, 549731.7138641565, 136553.141469672], 
processed observation next is [1.0, 0.7391304347826086, 0.7648148148148153, 0.365, 1.0, 1.0, 0.3545159699709871, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19633275495148447, 0.19633275495148447, 0.26260219513398464], 
reward next is 0.7374, 
noisyNet noise sample is [array([1.6510408], dtype=float32), -0.06173811]. 
=============================================
[2019-04-27 21:03:17,237] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2069243e-24 1.0000000e+00 9.9851540e-27 2.3256291e-22 7.8556741e-25], sum to 1.0000
[2019-04-27 21:03:17,244] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2482
[2019-04-27 21:03:17,250] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1742041.667751396 W.
[2019-04-27 21:03:17,255] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.26666666666667, 35.66666666666667, 1.0, 2.0, 0.5018743251450101, 1.0, 2.0, 0.5018743251450101, 1.0, 2.0, 0.8001354086313247, 6.911199999999999, 6.9112, 121.94756008, 1742041.667751396, 1742041.667751396, 344628.0572802949], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3148800.0000, 
sim time next is 3149400.0000, 
raw observation next is [32.58333333333334, 33.83333333333334, 1.0, 2.0, 0.8610882236937278, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9679772693207603, 6.9112, 6.9112, 121.9260426156618, 1734808.096135011, 1734808.096135011, 342939.4792953625], 
processed observation next is [1.0, 0.43478260869565216, 0.7623456790123461, 0.33833333333333343, 1.0, 1.0, 0.8346288377306283, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9599715866509503, 0.0, 0.0, 0.8094621288201359, 0.6195743200482182, 0.6195743200482182, 0.6594989986449279], 
reward next is 0.3405, 
noisyNet noise sample is [array([-0.09423722], dtype=float32), -0.51139235]. 
=============================================
[2019-04-27 21:03:24,296] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.7792989e-26 1.0000000e+00 9.3343638e-32 1.1463861e-25 5.6160678e-30], sum to 1.0000
[2019-04-27 21:03:24,305] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6518
[2019-04-27 21:03:24,307] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 89.0, 1.0, 2.0, 0.6045640048116646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 697690.424491094, 697690.424491094, 159287.5860510836], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3274800.0000, 
sim time next is 3275400.0000, 
raw observation next is [24.33333333333333, 91.5, 1.0, 2.0, 0.6054836968546371, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 698701.933609694, 698701.933609694, 159444.9115075087], 
processed observation next is [0.0, 0.9130434782608695, 0.45679012345678993, 0.915, 1.0, 1.0, 0.5303377343507585, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.249536404860605, 0.249536404860605, 0.3066248298221321], 
reward next is 0.6934, 
noisyNet noise sample is [array([0.20183444], dtype=float32), -1.1862607]. 
=============================================
[2019-04-27 21:03:29,540] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.1020356e-25 1.0000000e+00 4.7527501e-30 1.8953933e-24 6.3038792e-27], sum to 1.0000
[2019-04-27 21:03:29,547] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5213
[2019-04-27 21:03:29,552] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.91666666666667, 91.66666666666666, 1.0, 2.0, 0.5283611796627021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 626987.9529033051, 626987.9529033051, 147300.6103292744], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3311400.0000, 
sim time next is 3312000.0000, 
raw observation next is [23.1, 90.0, 1.0, 2.0, 0.5253814687296308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 623801.4337682694, 623801.4337682694, 146832.6091107315], 
processed observation next is [0.0, 0.34782608695652173, 0.41111111111111115, 0.9, 1.0, 1.0, 0.4349779389638461, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2227862263458105, 0.2227862263458105, 0.2823704021360221], 
reward next is 0.7176, 
noisyNet noise sample is [array([0.43243453], dtype=float32), -0.37651828]. 
=============================================
[2019-04-27 21:03:29,570] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[66.91005 ]
 [66.94274 ]
 [66.98513 ]
 [67.033714]
 [67.08637 ]], R is [[67.00197601]
 [67.04868317]
 [67.09420776]
 [67.13895416]
 [67.18313599]].
[2019-04-27 21:03:35,187] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-04-27 21:03:35,189] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 21:03:35,190] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:03:35,190] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 21:03:35,191] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:03:35,191] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 21:03:35,192] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 21:03:35,193] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 21:03:35,198] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:03:35,198] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:03:35,202] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:03:35,217] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run72
[2019-04-27 21:03:35,236] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run72
[2019-04-27 21:03:35,238] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run72
[2019-04-27 21:03:35,281] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run72
[2019-04-27 21:03:35,306] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run72
[2019-04-27 21:03:46,710] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12545021]
[2019-04-27 21:03:46,714] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [35.33333333333334, 20.33333333333334, 1.0, 2.0, 0.4965631592616008, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 617020.411621061, 617020.4116210606, 143090.5204625718]
[2019-04-27 21:03:46,715] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 21:03:46,719] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.2580656e-29 1.0000000e+00 8.7979346e-33 6.9894794e-27 1.4896304e-32], sampled 0.2116670343924193
[2019-04-27 21:04:40,388] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12545021]
[2019-04-27 21:04:40,389] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.58333333333333, 58.5, 1.0, 2.0, 0.4961019797913535, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 594338.8797017044, 594338.879701704, 142379.5445845233]
[2019-04-27 21:04:40,390] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 21:04:40,392] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.6894244e-29 1.0000000e+00 1.6563149e-33 1.6991985e-27 2.7787406e-33], sampled 0.4783938631301051
[2019-04-27 21:05:13,898] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12545021]
[2019-04-27 21:05:13,900] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [19.946798845, 74.82616003166666, 1.0, 2.0, 0.3399349810848917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 433061.9388496045, 433061.938849604, 120649.1499020001]
[2019-04-27 21:05:13,901] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 21:05:13,905] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.6659162e-29 1.0000000e+00 1.0878598e-32 9.5046677e-27 2.2038838e-32], sampled 0.0504409843220901
[2019-04-27 21:05:21,925] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8922.6628 2120599135.7723 430.0000
[2019-04-27 21:05:22,029] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8582.0590 2248830394.8409 553.0000
[2019-04-27 21:05:22,143] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8769.4422 2170768739.9937 493.0000
[2019-04-27 21:05:22,220] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8098.4495 2445508074.6415 746.0000
[2019-04-27 21:05:22,534] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8700.1130 2195220806.1349 572.0000
[2019-04-27 21:05:23,550] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1775000, evaluation results [1775000.0, 8098.4494892610255, 2445508074.64147, 746.0, 8769.442185004564, 2170768739.993712, 493.0, 8922.662781171732, 2120599135.7722971, 430.0, 8582.059032767682, 2248830394.840892, 553.0, 8700.112961499688, 2195220806.134913, 572.0]
[2019-04-27 21:05:31,896] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.0853669e-23 1.0000000e+00 1.4190574e-26 2.3235919e-20 1.0378843e-25], sum to 1.0000
[2019-04-27 21:05:31,903] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0615
[2019-04-27 21:05:31,908] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 100.0, 1.0, 2.0, 0.5863049155116016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 680169.8014152587, 680169.8014152582, 156311.6548578711], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3024000.0000, 
sim time next is 3024600.0000, 
raw observation next is [23.16666666666667, 99.00000000000001, 1.0, 2.0, 0.5872522156250599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 681053.1782313308, 681053.1782313308, 156463.7602176274], 
processed observation next is [1.0, 0.0, 0.4135802469135804, 0.9900000000000001, 1.0, 1.0, 0.5086335900298332, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24323327793976102, 0.24323327793976102, 0.3008918465723604], 
reward next is 0.6991, 
noisyNet noise sample is [array([0.31513804], dtype=float32), 0.8577097]. 
=============================================
[2019-04-27 21:05:34,875] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.3839429e-20 1.0000000e+00 2.3717321e-23 1.7600352e-16 1.0211965e-19], sum to 1.0000
[2019-04-27 21:05:34,884] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7893
[2019-04-27 21:05:34,894] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 96.0, 1.0, 2.0, 0.9325744172685365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1078008.108414811, 1078008.108414811, 225668.512602495], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3674400.0000, 
sim time next is 3675000.0000, 
raw observation next is [23.83333333333333, 95.0, 1.0, 2.0, 0.9630156976081281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.994661292742606, 6.9112, 121.9256397903056, 1154967.190175178, 1112227.689810632, 232719.9219828913], 
processed observation next is [1.0, 0.5217391304347826, 0.43827160493827144, 0.95, 1.0, 1.0, 0.9559710685811049, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.008346129274260594, 0.0, 0.8094594544786796, 0.4124882822054207, 0.39722417493236856, 0.4475383115055602], 
reward next is 0.1352, 
noisyNet noise sample is [array([1.7305348], dtype=float32), 0.3032057]. 
=============================================
[2019-04-27 21:05:34,909] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[54.902584]
 [54.353714]
 [54.317375]
 [54.465626]
 [53.576122]], R is [[54.88031006]
 [54.8975296 ]
 [54.34855652]
 [53.80507278]
 [53.74365997]].
[2019-04-27 21:05:40,063] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.6803740e-26 1.0000000e+00 4.9906699e-31 7.8263911e-25 1.1016803e-29], sum to 1.0000
[2019-04-27 21:05:40,069] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7733
[2019-04-27 21:05:40,073] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.93333333333334, 48.0, 1.0, 2.0, 0.5514753578975072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 640309.6037684492, 640309.6037684492, 150497.3606591798], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3180000.0000, 
sim time next is 3180600.0000, 
raw observation next is [31.4, 53.0, 1.0, 2.0, 0.5832825844651521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 668966.2982240412, 668966.2982240412, 155436.1572540672], 
processed observation next is [1.0, 0.8260869565217391, 0.7185185185185184, 0.53, 1.0, 1.0, 0.5039078386489906, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23891653508001473, 0.23891653508001473, 0.2989156870270523], 
reward next is 0.7011, 
noisyNet noise sample is [array([0.79771227], dtype=float32), -1.8914064]. 
=============================================
[2019-04-27 21:05:50,762] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.9257769e-20 1.0000000e+00 4.4130999e-22 9.1877902e-17 1.5837785e-20], sum to 1.0000
[2019-04-27 21:05:50,769] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4370
[2019-04-27 21:05:50,774] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 94.0, 1.0, 2.0, 0.7727387500392631, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 891611.7837771899, 891611.7837771894, 190927.0295185815], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3382200.0000, 
sim time next is 3382800.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.7780804842725164, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 897791.7815440743, 897791.7815440743, 192013.6370079856], 
processed observation next is [1.0, 0.13043478260869565, 0.4444444444444444, 0.94, 1.0, 1.0, 0.7358101003244243, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.32063992198002655, 0.32063992198002655, 0.3692569942461262], 
reward next is 0.6307, 
noisyNet noise sample is [array([-0.6560221], dtype=float32), -0.7510763]. 
=============================================
[2019-04-27 21:05:56,034] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.4382758e-27 1.0000000e+00 1.6787472e-29 1.9403350e-23 1.7389490e-28], sum to 1.0000
[2019-04-27 21:05:56,040] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3647
[2019-04-27 21:05:56,044] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.6880079618401421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 784127.4554207048, 784127.4554207039, 173885.559573154], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3446400.0000, 
sim time next is 3447000.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.6890878480145702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 785358.8397206649, 785358.8397206644, 174087.8194373618], 
processed observation next is [1.0, 0.9130434782608695, 0.5185185185185185, 0.89, 1.0, 1.0, 0.6298664857316312, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.28048529990023746, 0.2804852999002373, 0.33478426814877266], 
reward next is 0.6652, 
noisyNet noise sample is [array([-0.14348617], dtype=float32), 0.7289793]. 
=============================================
[2019-04-27 21:05:56,063] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[67.04383 ]
 [67.28363 ]
 [67.40474 ]
 [67.38245 ]
 [67.574974]], R is [[67.16698456]
 [67.16091919]
 [67.15507507]
 [67.15015411]
 [67.14778137]].
[2019-04-27 21:05:57,063] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.4124270e-22 1.0000000e+00 1.9062472e-25 6.5314575e-20 1.7491115e-24], sum to 1.0000
[2019-04-27 21:05:57,075] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7369
[2019-04-27 21:05:57,087] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1866204.311191464 W.
[2019-04-27 21:05:57,095] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.41666666666667, 79.0, 1.0, 2.0, 0.8181652094040164, 1.0, 2.0, 0.8181652094040164, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1866204.311191464, 1866204.311191464, 351317.6503707647], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3495000.0000, 
sim time next is 3495600.0000, 
raw observation next is [27.5, 77.0, 1.0, 2.0, 0.7543282570979467, 1.0, 2.0, 0.7543282570979467, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1720454.375992818, 1720454.375992818, 325243.2518375786], 
processed observation next is [1.0, 0.4782608695652174, 0.5740740740740741, 0.77, 1.0, 1.0, 0.7075336394023175, 1.0, 1.0, 0.7075336394023175, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.6144479914260065, 0.6144479914260065, 0.6254677919953434], 
reward next is 0.3745, 
noisyNet noise sample is [array([-0.7256692], dtype=float32), 1.7968675]. 
=============================================
[2019-04-27 21:06:03,224] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2481928e-19 1.0000000e+00 3.2034310e-23 2.7840819e-15 1.1449142e-16], sum to 1.0000
[2019-04-27 21:06:03,236] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9000
[2019-04-27 21:06:03,240] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.4, 91.0, 1.0, 2.0, 0.8720249397678693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1045760.656697897, 1045760.656697897, 213756.5660985068], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3574800.0000, 
sim time next is 3575400.0000, 
raw observation next is [22.5, 90.66666666666667, 1.0, 2.0, 0.9602563925929403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.200854905725208, 6.9112, 121.9249444599202, 1298814.346106648, 1150486.481275673, 234063.1464219672], 
processed observation next is [1.0, 0.391304347826087, 0.3888888888888889, 0.9066666666666667, 1.0, 1.0, 0.9526861816582622, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.028965490572520826, 0.0, 0.8094548382080132, 0.46386226646666, 0.4108880290270261, 0.45012143542686], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.52335584], dtype=float32), 0.5127437]. 
=============================================
[2019-04-27 21:06:11,166] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.7233827e-20 1.0000000e+00 2.4315828e-22 3.4575938e-17 6.8876625e-18], sum to 1.0000
[2019-04-27 21:06:11,172] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1801
[2019-04-27 21:06:11,181] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1734983.216954721 W.
[2019-04-27 21:06:11,187] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.8, 94.0, 1.0, 2.0, 0.8946550868571626, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426156394, 1734983.216954721, 1734983.21695472, 355815.905668258], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3746400.0000, 
sim time next is 3747000.0000, 
raw observation next is [25.9, 94.0, 1.0, 2.0, 0.5023435550181388, 1.0, 1.0, 0.5023435550181388, 1.0, 2.0, 0.7997472997762998, 6.911200000000001, 6.9112, 121.94756008, 1718598.201291834, 1718598.201291834, 344740.7730553633], 
processed observation next is [1.0, 0.34782608695652173, 0.5148148148148147, 0.94, 1.0, 1.0, 0.40755185121206994, 1.0, 0.5, 0.40755185121206994, 1.0, 1.0, 0.7496841247203747, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6137850718899407, 0.6137850718899407, 0.6629630251064679], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.06279532], dtype=float32), 1.429699]. 
=============================================
[2019-04-27 21:06:11,222] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[50.800316]
 [50.36946 ]
 [49.65538 ]
 [50.022053]
 [50.156887]], R is [[51.06882477]
 [50.55813599]
 [50.05255508]
 [49.88061905]
 [49.38181305]].
[2019-04-27 21:06:12,187] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.3264183e-16 1.0000000e+00 8.3455163e-20 3.3073035e-14 2.4828750e-13], sum to 1.0000
[2019-04-27 21:06:12,196] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2646
[2019-04-27 21:06:12,203] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1734983.21695472 W.
[2019-04-27 21:06:12,211] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.8, 94.0, 1.0, 2.0, 0.7606922054050156, 1.0, 2.0, 0.7606922054050156, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156394, 1734983.21695472, 1734983.21695472, 327779.8921998711], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3746400.0000, 
sim time next is 3747000.0000, 
raw observation next is [25.9, 94.0, 1.0, 2.0, 0.7534976258527388, 1.0, 2.0, 0.7534976258527388, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1718558.069214415, 1718558.069214415, 324914.0267686853], 
processed observation next is [1.0, 0.34782608695652173, 0.5148148148148147, 0.94, 1.0, 1.0, 0.7065447926818319, 1.0, 1.0, 0.7065447926818319, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6137707390051482, 0.6137707390051482, 0.6248346668628564], 
reward next is 0.3752, 
noisyNet noise sample is [array([0.59875226], dtype=float32), 0.9671786]. 
=============================================
[2019-04-27 21:06:12,226] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[50.20909 ]
 [49.961227]
 [49.544395]
 [50.10263 ]
 [50.27706 ]], R is [[49.82769775]
 [49.69907761]
 [49.2020874 ]
 [49.03865814]
 [48.54827118]].
[2019-04-27 21:06:16,110] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-04-27 21:06:16,111] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 21:06:16,112] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:06:16,112] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 21:06:16,113] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:06:16,115] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 21:06:16,116] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 21:06:16,116] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:06:16,117] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:06:16,118] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 21:06:16,120] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:06:16,141] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run73
[2019-04-27 21:06:16,163] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run73
[2019-04-27 21:06:16,189] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run73
[2019-04-27 21:06:16,192] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run73
[2019-04-27 21:06:16,235] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run73
[2019-04-27 21:06:38,847] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12542139]
[2019-04-27 21:06:38,848] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.33333333333333, 75.33333333333334, 1.0, 2.0, 0.5314125101487577, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 629394.553888192, 629394.5538881925, 147748.0058071443]
[2019-04-27 21:06:38,849] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 21:06:38,852] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0022772e-28 1.0000000e+00 1.2361158e-32 3.1565902e-26 4.8055052e-32], sampled 0.8078536473017767
[2019-04-27 21:06:39,548] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12542139]
[2019-04-27 21:06:39,549] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.53435754, 58.94160936500001, 1.0, 2.0, 0.4688953933415678, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 567490.011076725, 567490.011076725, 138375.5916672666]
[2019-04-27 21:06:39,551] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 21:06:39,554] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.3086684e-27 1.0000000e+00 2.2427365e-31 3.4288406e-25 9.1757453e-31], sampled 0.39342164308567407
[2019-04-27 21:07:11,867] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12542139]
[2019-04-27 21:07:11,868] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.84593566333334, 94.02330787, 1.0, 2.0, 0.8353888897396373, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 952202.8683466422, 952202.8683466422, 203371.7627830901]
[2019-04-27 21:07:11,869] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 21:07:11,872] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.6855142e-28 1.0000000e+00 4.9800365e-32 1.0372868e-25 2.3231624e-31], sampled 0.8303035563064218
[2019-04-27 21:08:03,106] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8922.6628 2120599135.7723 430.0000
[2019-04-27 21:08:03,704] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8582.0590 2248830394.8409 553.0000
[2019-04-27 21:08:03,741] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8770.2626 2170712315.3188 493.0000
[2019-04-27 21:08:03,773] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8098.4495 2445508074.6415 746.0000
[2019-04-27 21:08:03,964] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8700.1130 2195220806.1349 572.0000
[2019-04-27 21:08:04,985] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1800000, evaluation results [1800000.0, 8098.4494892610255, 2445508074.64147, 746.0, 8770.262620159681, 2170712315.3187604, 493.0, 8922.662781171732, 2120599135.7722971, 430.0, 8582.059032767682, 2248830394.840892, 553.0, 8700.112961499688, 2195220806.134913, 572.0]
[2019-04-27 21:08:07,778] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.8051360e-25 1.0000000e+00 1.3183979e-29 1.3442300e-24 9.7604956e-30], sum to 1.0000
[2019-04-27 21:08:07,785] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0172
[2019-04-27 21:08:07,792] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.13333333333333, 89.0, 1.0, 2.0, 0.7791379038215649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 888049.0538070562, 888049.0538070562, 191670.9700489151], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3883200.0000, 
sim time next is 3883800.0000, 
raw observation next is [26.91666666666666, 89.0, 1.0, 2.0, 0.7654363243009326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 872423.3216320499, 872423.3216320499, 188904.6798355668], 
processed observation next is [0.0, 0.9565217391304348, 0.5524691358024689, 0.89, 1.0, 1.0, 0.7207575289296816, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3115797577257321, 0.3115797577257321, 0.3632782304530131], 
reward next is 0.6367, 
noisyNet noise sample is [array([-0.16949691], dtype=float32), -0.18385555]. 
=============================================
[2019-04-27 21:08:07,841] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.3814314e-24 1.0000000e+00 9.1624376e-27 2.5274818e-22 4.1231579e-28], sum to 1.0000
[2019-04-27 21:08:07,846] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1374
[2019-04-27 21:08:07,850] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 94.0, 1.0, 2.0, 0.7365721423684509, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 839506.7011383262, 839506.7011383262, 183184.8507221237], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3902400.0000, 
sim time next is 3903000.0000, 
raw observation next is [25.85, 94.33333333333334, 1.0, 2.0, 0.7306647913521597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 832770.1512549352, 832770.1512549352, 182031.6845773126], 
processed observation next is [0.0, 0.17391304347826086, 0.5129629629629631, 0.9433333333333335, 1.0, 1.0, 0.6793628468478091, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29741791116247684, 0.29741791116247684, 0.3500609318794473], 
reward next is 0.6499, 
noisyNet noise sample is [array([0.5024565], dtype=float32), -0.11434757]. 
=============================================
[2019-04-27 21:08:07,871] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[62.09028 ]
 [62.148193]
 [62.133602]
 [62.158543]
 [62.183937]], R is [[62.14282608]
 [62.16911697]
 [62.19376755]
 [62.21687317]
 [62.23873901]].
[2019-04-27 21:08:10,328] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.8194605e-25 1.0000000e+00 2.4223637e-28 6.7197853e-22 1.3472671e-27], sum to 1.0000
[2019-04-27 21:08:10,337] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9471
[2019-04-27 21:08:10,343] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.7538073365757941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 859161.4912816457, 859161.4912816457, 186583.8622495098], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3920400.0000, 
sim time next is 3921000.0000, 
raw observation next is [27.16666666666666, 87.33333333333334, 1.0, 2.0, 0.7508021557287434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 855734.3860518129, 855734.3860518129, 185987.3922403012], 
processed observation next is [0.0, 0.391304347826087, 0.5617283950617282, 0.8733333333333334, 1.0, 1.0, 0.7033358996770755, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.30561942358993316, 0.30561942358993316, 0.35766806200057927], 
reward next is 0.6423, 
noisyNet noise sample is [array([0.21990281], dtype=float32), -0.720636]. 
=============================================
[2019-04-27 21:08:10,362] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[62.646145]
 [62.624096]
 [62.67666 ]
 [62.73263 ]
 [62.745434]], R is [[62.62896347]
 [62.64385986]
 [62.65869141]
 [62.67493439]
 [62.69692612]].
[2019-04-27 21:08:14,197] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6179830e-26 1.0000000e+00 5.0127864e-30 2.3947968e-23 3.5160698e-29], sum to 1.0000
[2019-04-27 21:08:14,203] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9624
[2019-04-27 21:08:14,207] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.15, 95.5, 1.0, 2.0, 0.5598456523289733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 655716.6029313749, 655716.6029313749, 152130.7083294911], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4512600.0000, 
sim time next is 4513200.0000, 
raw observation next is [23.1, 97.0, 1.0, 2.0, 0.5662570512823466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 661380.609349485, 661380.609349485, 153123.1596569433], 
processed observation next is [0.0, 0.21739130434782608, 0.41111111111111115, 0.97, 1.0, 1.0, 0.48363934676469833, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23620736048195892, 0.23620736048195892, 0.2944676147248909], 
reward next is 0.7055, 
noisyNet noise sample is [array([0.98792374], dtype=float32), -0.68717927]. 
=============================================
[2019-04-27 21:08:15,231] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0414138e-18 1.0000000e+00 1.1969498e-20 2.8459312e-16 9.5432486e-20], sum to 1.0000
[2019-04-27 21:08:15,238] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2599
[2019-04-27 21:08:15,241] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 87.0, 1.0, 2.0, 0.6551279104768192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 746727.5416251323, 746727.5416251323, 167824.8857204596], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3981600.0000, 
sim time next is 3982200.0000, 
raw observation next is [25.45, 87.33333333333333, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 9.674755884861383, 6.9112, 123.2512833898409, 2594316.267253665, 1163746.667233072, 245781.169387438], 
processed observation next is [1.0, 0.08695652173913043, 0.4981481481481481, 0.8733333333333333, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.27635558848613834, 0.0, 0.8182603494074124, 0.926541524019166, 0.41562380972609714, 0.4726560949758423], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1522517], dtype=float32), 1.923601]. 
=============================================
[2019-04-27 21:08:15,358] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.34537919e-16 1.00000000e+00 1.05945376e-17 9.76836003e-14
 6.66186807e-16], sum to 1.0000
[2019-04-27 21:08:15,369] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9458
[2019-04-27 21:08:15,376] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1314806.688927927 W.
[2019-04-27 21:08:15,380] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.95, 91.16666666666667, 1.0, 2.0, 1.01283967744716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.223778768800777, 6.9112, 121.9248676944203, 1314806.688927927, 1154739.963801425, 243832.6126567458], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3989400.0000, 
sim time next is 3990000.0000, 
raw observation next is [24.9, 91.33333333333334, 1.0, 2.0, 0.4656977094408901, 1.0, 1.0, 0.4656977094408901, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9258543862258, 1061709.981145011, 1061709.981145011, 224978.0124315072], 
processed observation next is [1.0, 0.17391304347826086, 0.47777777777777775, 0.9133333333333334, 1.0, 1.0, 0.3639258445724883, 1.0, 0.5, 0.3639258445724883, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094608791724257, 0.3791821361232182, 0.3791821361232182, 0.4326500239067446], 
reward next is 0.5673, 
noisyNet noise sample is [array([-0.15750706], dtype=float32), 0.9676321]. 
=============================================
[2019-04-27 21:08:15,395] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[41.78678 ]
 [41.712643]
 [42.042847]
 [41.92243 ]
 [42.943382]], R is [[41.78930283]
 [41.37141037]
 [41.51855087]
 [41.10336685]
 [40.71966934]].
[2019-04-27 21:08:19,495] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.6005569e-25 1.0000000e+00 3.0794549e-29 4.9851342e-23 3.6298448e-27], sum to 1.0000
[2019-04-27 21:08:19,502] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1248
[2019-04-27 21:08:19,512] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1715884.503441987 W.
[2019-04-27 21:08:19,518] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.16666666666667, 70.0, 1.0, 2.0, 0.501551106338658, 1.0, 2.0, 0.501551106338658, 1.0, 2.0, 0.7984856956703146, 6.9112, 6.9112, 121.94756008, 1715884.503441987, 1715884.503441987, 344350.9917892648], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4104600.0000, 
sim time next is 4105200.0000, 
raw observation next is [28.33333333333334, 70.0, 1.0, 2.0, 0.718792801746228, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1534251.274729227, 1534251.274729227, 320667.2984879756], 
processed observation next is [1.0, 0.5217391304347826, 0.6049382716049385, 0.7, 1.0, 1.0, 0.6652295258883666, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8094621288201359, 0.5479468838318667, 0.5479468838318667, 0.6166678817076454], 
reward next is 0.3833, 
noisyNet noise sample is [array([-0.01681335], dtype=float32), -2.4097767]. 
=============================================
[2019-04-27 21:08:22,544] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.1569144e-31 1.0000000e+00 1.6456264e-34 4.0821718e-27 8.2600059e-34], sum to 1.0000
[2019-04-27 21:08:22,553] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3830
[2019-04-27 21:08:22,557] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 88.0, 1.0, 2.0, 0.4618896322444098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 559762.6025340921, 559762.6025340918, 137336.9906985486], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4125600.0000, 
sim time next is 4126200.0000, 
raw observation next is [21.88333333333334, 88.66666666666667, 1.0, 2.0, 0.4584188576608469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 557507.4871600659, 557507.4871600659, 136874.5993543274], 
processed observation next is [1.0, 0.782608695652174, 0.36604938271604964, 0.8866666666666667, 1.0, 1.0, 0.3552605448343415, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19910981684288068, 0.19910981684288068, 0.2632203833737065], 
reward next is 0.7368, 
noisyNet noise sample is [array([-1.0202459], dtype=float32), 0.89522386]. 
=============================================
[2019-04-27 21:08:30,506] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.9651012e-19 1.0000000e+00 1.7796483e-23 1.1121007e-15 1.8954581e-17], sum to 1.0000
[2019-04-27 21:08:30,512] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6876
[2019-04-27 21:08:30,516] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.6, 75.0, 1.0, 2.0, 0.4677825963521917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 578687.4934094183, 578687.4934094183, 138555.9814439075], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4251600.0000, 
sim time next is 4252200.0000, 
raw observation next is [22.33333333333334, 76.33333333333333, 1.0, 2.0, 0.4192248271931635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 518974.2246853504, 518974.2246853504, 131349.9532132567], 
processed observation next is [1.0, 0.21739130434782608, 0.38271604938271625, 0.7633333333333333, 1.0, 1.0, 0.3086009847537661, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18534793738762514, 0.18534793738762514, 0.2525960638716475], 
reward next is 0.7474, 
noisyNet noise sample is [array([-0.1746172], dtype=float32), -1.1173521]. 
=============================================
[2019-04-27 21:08:37,263] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.8291670e-29 1.0000000e+00 1.9413034e-32 1.5601052e-27 1.6905518e-30], sum to 1.0000
[2019-04-27 21:08:37,271] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5214
[2019-04-27 21:08:37,279] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 0.7145278984134438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 814368.4681220273, 814368.4681220273, 178917.4943141649], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4388400.0000, 
sim time next is 4389000.0000, 
raw observation next is [30.46666666666667, 67.16666666666667, 1.0, 2.0, 0.7111352833115415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 810499.7604745197, 810499.7604745197, 178266.1745469242], 
processed observation next is [1.0, 0.8260869565217391, 0.6839506172839507, 0.6716666666666667, 1.0, 1.0, 0.6561134325137399, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28946420016947133, 0.28946420016947133, 0.34281956643639266], 
reward next is 0.6572, 
noisyNet noise sample is [array([1.2465591], dtype=float32), 1.1122345]. 
=============================================
[2019-04-27 21:08:37,298] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[73.15221 ]
 [72.95172 ]
 [72.653786]
 [72.618355]
 [72.7299  ]], R is [[73.08204651]
 [73.00715637]
 [72.93495941]
 [72.8683548 ]
 [72.80766296]].
[2019-04-27 21:08:38,492] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.3643119e-29 1.0000000e+00 8.2349624e-34 2.5893367e-28 1.8878163e-32], sum to 1.0000
[2019-04-27 21:08:38,502] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9034
[2019-04-27 21:08:38,508] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.26666666666667, 92.0, 1.0, 2.0, 0.4909361864062245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 589161.1846985806, 589161.1846985806, 141608.1517673643], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4425600.0000, 
sim time next is 4426200.0000, 
raw observation next is [22.2, 92.5, 1.0, 2.0, 0.4905025441756574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 588683.007064521, 588683.0070645206, 141542.0786474962], 
processed observation next is [0.0, 0.21739130434782608, 0.37777777777777777, 0.925, 1.0, 1.0, 0.3934554097329255, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2102439310944718, 0.21024393109447165, 0.27219630509133885], 
reward next is 0.7278, 
noisyNet noise sample is [array([1.0578078], dtype=float32), 0.867874]. 
=============================================
[2019-04-27 21:08:43,109] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.2597837e-28 1.0000000e+00 5.1540039e-31 1.6844222e-24 6.5030050e-31], sum to 1.0000
[2019-04-27 21:08:43,117] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1211
[2019-04-27 21:08:43,125] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.05, 98.50000000000001, 1.0, 2.0, 0.5844787965345303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 679698.1273429992, 679698.1273429992, 156074.5850456734], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4507800.0000, 
sim time next is 4508400.0000, 
raw observation next is [23.1, 97.0, 1.0, 2.0, 0.5777826922003085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 673775.4256549638, 673775.4256549638, 155019.4372392118], 
processed observation next is [0.0, 0.17391304347826086, 0.41111111111111115, 0.97, 1.0, 1.0, 0.49736034785751015, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2406340805910585, 0.2406340805910585, 0.29811430238309966], 
reward next is 0.7019, 
noisyNet noise sample is [array([0.46718854], dtype=float32), -0.17108324]. 
=============================================
[2019-04-27 21:08:47,267] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.8866410e-28 1.0000000e+00 1.9908541e-31 9.3431200e-26 4.7240621e-31], sum to 1.0000
[2019-04-27 21:08:47,274] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3447
[2019-04-27 21:08:47,279] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.93333333333333, 94.0, 1.0, 2.0, 0.7272356518183154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 828859.6998505639, 828859.6998505634, 181365.6366810458], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5103600.0000, 
sim time next is 5104200.0000, 
raw observation next is [25.91666666666666, 94.0, 1.0, 2.0, 0.7277766804573926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 829476.6656039328, 829476.6656039328, 181470.5269141785], 
processed observation next is [0.0, 0.043478260869565216, 0.5154320987654318, 0.94, 1.0, 1.0, 0.6759246195921341, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29624166628711884, 0.29624166628711884, 0.34898178252726636], 
reward next is 0.6510, 
noisyNet noise sample is [array([-0.94299066], dtype=float32), -0.22241926]. 
=============================================
[2019-04-27 21:08:48,273] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.6488058e-24 1.0000000e+00 3.3004885e-27 1.0114985e-22 1.2757238e-25], sum to 1.0000
[2019-04-27 21:08:48,283] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3882
[2019-04-27 21:08:48,294] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.4, 98.66666666666667, 1.0, 2.0, 0.6275363032009167, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 753316.4406560761, 753316.4406560756, 164544.2050564224], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4587600.0000, 
sim time next is 4588200.0000, 
raw observation next is [21.3, 99.0, 1.0, 2.0, 0.5507665982367732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 661993.7624240194, 661993.7624240194, 151281.7975736746], 
processed observation next is [1.0, 0.08695652173913043, 0.3444444444444445, 0.99, 1.0, 1.0, 0.4651983312342538, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23642634372286406, 0.23642634372286406, 0.2909265337955281], 
reward next is 0.7091, 
noisyNet noise sample is [array([0.25166908], dtype=float32), 0.63113576]. 
=============================================
[2019-04-27 21:08:49,044] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.1843595e-33 1.0000000e+00 4.2033860e-37 2.0850061e-30 3.8093151e-35], sum to 1.0000
[2019-04-27 21:08:49,051] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9352
[2019-04-27 21:08:49,056] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.63333333333333, 98.66666666666666, 1.0, 2.0, 0.5073907680768881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 606235.1628078927, 606235.1628078927, 144099.8712150862], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4578000.0000, 
sim time next is 4578600.0000, 
raw observation next is [21.31666666666667, 99.33333333333334, 1.0, 2.0, 0.4962766267248202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 595537.9283003111, 595537.9283003111, 142441.2958198189], 
processed observation next is [0.0, 1.0, 0.34506172839506183, 0.9933333333333334, 1.0, 1.0, 0.4003293175295478, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2126921172501111, 0.2126921172501111, 0.2739255688842671], 
reward next is 0.7261, 
noisyNet noise sample is [array([-1.6062387], dtype=float32), 0.67938906]. 
=============================================
[2019-04-27 21:08:54,723] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.1850969e-20 1.0000000e+00 1.8878835e-22 2.7551819e-18 8.8638516e-20], sum to 1.0000
[2019-04-27 21:08:54,731] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3276
[2019-04-27 21:08:54,737] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.6135926387105207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 722834.8172535289, 722834.8172535285, 161517.7273571113], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4680000.0000, 
sim time next is 4680600.0000, 
raw observation next is [23.11666666666667, 94.16666666666667, 1.0, 2.0, 0.6608941246285235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 777024.1827716883, 777024.1827716883, 169992.4987213237], 
processed observation next is [1.0, 0.17391304347826086, 0.41172839506172854, 0.9416666666666668, 1.0, 1.0, 0.5963025293196708, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2775086367041744, 0.2775086367041744, 0.32690865138716096], 
reward next is 0.6731, 
noisyNet noise sample is [array([0.09008203], dtype=float32), 0.40168467]. 
=============================================
[2019-04-27 21:08:57,788] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-27 21:08:57,791] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 21:08:57,793] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:08:57,793] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 21:08:57,796] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 21:08:57,796] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:08:57,797] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:08:57,797] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 21:08:57,798] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:08:57,798] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 21:08:57,800] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:08:57,822] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run74
[2019-04-27 21:08:57,844] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run74
[2019-04-27 21:08:57,873] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run74
[2019-04-27 21:08:57,895] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run74
[2019-04-27 21:08:57,918] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run74
[2019-04-27 21:09:52,134] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12644252]
[2019-04-27 21:09:52,135] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.25407799, 79.52154606, 1.0, 2.0, 0.5305046686548902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 631658.4637637547, 631658.4637637547, 147728.606608281]
[2019-04-27 21:09:52,136] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 21:09:52,137] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.9002577e-28 1.0000000e+00 3.8906965e-32 3.6912164e-26 3.6399042e-31], sampled 0.2978395417772628
[2019-04-27 21:09:54,024] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12644252]
[2019-04-27 21:09:54,025] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.11666666666667, 99.16666666666667, 1.0, 2.0, 0.4334526056057796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 531591.9755214382, 531591.9755214378, 133296.1084560525]
[2019-04-27 21:09:54,025] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 21:09:54,029] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.5387854e-28 1.0000000e+00 6.0666223e-32 5.4191533e-26 5.2927574e-31], sampled 0.10555879784765176
[2019-04-27 21:09:54,133] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12644252]
[2019-04-27 21:09:54,135] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.42785914, 91.320595965, 1.0, 2.0, 0.558419505928551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 656298.8028751024, 656298.8028751024, 151987.9235776869]
[2019-04-27 21:09:54,136] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 21:09:54,138] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.9129156e-30 1.0000000e+00 4.5310155e-34 9.3553434e-28 4.5660153e-33], sampled 0.017476826089616093
[2019-04-27 21:09:57,469] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12644252]
[2019-04-27 21:09:57,470] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.5, 94.0, 1.0, 2.0, 0.7857596789531572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426022072, 915341.2048693825, 915341.2048693825, 194009.4582034721]
[2019-04-27 21:09:57,472] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 21:09:57,475] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.9897766e-26 1.0000000e+00 1.0766856e-29 4.3815263e-24 1.3168956e-28], sampled 0.30219167245428113
[2019-04-27 21:10:15,573] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12644252]
[2019-04-27 21:10:15,575] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.15, 84.0, 1.0, 2.0, 0.4325989197289052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 529204.6763012672, 529204.6763012672, 133134.5216575525]
[2019-04-27 21:10:15,579] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 21:10:15,581] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.5441714e-28 1.0000000e+00 1.1328707e-32 1.3968545e-26 1.0856424e-31], sampled 0.15769098680825033
[2019-04-27 21:10:17,334] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12644252]
[2019-04-27 21:10:17,335] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.75, 79.0, 1.0, 2.0, 0.6975199007798861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 794973.9001799974, 794973.9001799974, 175670.6429532153]
[2019-04-27 21:10:17,338] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 21:10:17,341] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.1283080e-26 1.0000000e+00 2.8685162e-30 1.4121414e-24 3.0932060e-29], sampled 0.6478823354530773
[2019-04-27 21:10:23,905] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12644252]
[2019-04-27 21:10:23,906] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.33333333333334, 65.33333333333333, 1.0, 2.0, 0.7509650645674795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 868006.4655411612, 868006.4655411608, 186627.9130953206]
[2019-04-27 21:10:23,907] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 21:10:23,909] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.9825304e-26 1.0000000e+00 2.5418297e-30 1.3475878e-24 3.0817109e-29], sampled 0.035758669641371865
[2019-04-27 21:10:43,042] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12644252]
[2019-04-27 21:10:43,044] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.66666666666667, 62.33333333333334, 1.0, 2.0, 0.3369651672963932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 426296.7423982283, 426296.7423982283, 120240.1594152094]
[2019-04-27 21:10:43,044] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 21:10:43,049] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.8485904e-27 1.0000000e+00 1.9330795e-31 1.6247069e-25 2.2676947e-30], sampled 0.4214728110609115
[2019-04-27 21:10:44,966] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.0852 2170656631.3663 493.0000
[2019-04-27 21:10:45,217] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8582.8795 2248773970.1662 553.0000
[2019-04-27 21:10:45,641] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8098.4495 2445508074.6415 746.0000
[2019-04-27 21:10:45,658] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8700.1130 2195220806.1349 572.0000
[2019-04-27 21:10:45,762] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8922.6628 2120599135.7723 430.0000
[2019-04-27 21:10:46,782] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1825000, evaluation results [1825000.0, 8098.4494892610255, 2445508074.64147, 746.0, 8771.085197215923, 2170656631.3662677, 493.0, 8922.662781171732, 2120599135.7722971, 430.0, 8582.879467926026, 2248773970.1662407, 553.0, 8700.112961499688, 2195220806.134913, 572.0]
[2019-04-27 21:10:47,768] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.9533422e-26 1.0000000e+00 2.9020605e-32 1.4809691e-22 5.9848047e-28], sum to 1.0000
[2019-04-27 21:10:47,775] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7817
[2019-04-27 21:10:47,782] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1938668.661576371 W.
[2019-04-27 21:10:47,792] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.08333333333333, 88.33333333333334, 1.0, 2.0, 0.8498999626710946, 1.0, 2.0, 0.8498999626710946, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260425576532, 1938668.661576371, 1938668.661576371, 364806.1241577757], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4805400.0000, 
sim time next is 4806000.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.7260628226770893, 1.0, 2.0, 0.7260628226770893, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156441, 1655927.479982094, 1655927.479982094, 314150.4305348488], 
processed observation next is [1.0, 0.6521739130434783, 0.5555555555555556, 0.89, 1.0, 1.0, 0.6738843127108206, 1.0, 1.0, 0.6738843127108206, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288200184, 0.5914026714221764, 0.5914026714221764, 0.6041354433362477], 
reward next is 0.3959, 
noisyNet noise sample is [array([0.7781002], dtype=float32), 0.4978813]. 
=============================================
[2019-04-27 21:10:47,828] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[68.388466]
 [68.038574]
 [66.8553  ]
 [66.8031  ]
 [66.579575]], R is [[68.38532257]
 [67.99991608]
 [67.31991577]
 [66.64672089]
 [66.30039215]].
[2019-04-27 21:10:50,585] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.3561974e-28 1.0000000e+00 4.8274429e-32 5.6368372e-25 3.9086279e-29], sum to 1.0000
[2019-04-27 21:10:50,592] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3997
[2019-04-27 21:10:50,599] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2268783.405464745 W.
[2019-04-27 21:10:50,607] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 7.673383005644863, 6.9112, 121.9230902027671, 2268783.405464745, 1878487.034602075, 381399.7747254099], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4807800.0000, 
sim time next is 4808400.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.6014131185073138, 1.0, 1.0, 0.6014131185073138, 1.0, 2.0, 0.9574692713214976, 6.911199999999999, 6.9112, 121.94756008, 2057921.538937337, 2057921.538937337, 396146.0724661155], 
processed observation next is [1.0, 0.6521739130434783, 0.5555555555555556, 0.89, 1.0, 1.0, 0.5254918077468022, 1.0, 0.5, 0.5254918077468022, 1.0, 1.0, 0.9468365891518721, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7349719781919061, 0.7349719781919061, 0.7618193701271453], 
reward next is 0.2382, 
noisyNet noise sample is [array([0.4943611], dtype=float32), -0.106389895]. 
=============================================
[2019-04-27 21:10:50,725] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.7189987e-29 1.0000000e+00 1.2879922e-33 6.7409204e-28 1.0930356e-30], sum to 1.0000
[2019-04-27 21:10:50,732] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5226
[2019-04-27 21:10:50,736] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 93.5, 1.0, 2.0, 0.7176788201727875, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 817961.5826010258, 817961.5826010254, 179519.5176256431], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4829400.0000, 
sim time next is 4830000.0000, 
raw observation next is [26.0, 93.33333333333334, 1.0, 2.0, 0.7161129893294881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 816176.0047484041, 816176.0047484041, 179218.4222270717], 
processed observation next is [1.0, 0.9130434782608695, 0.5185185185185185, 0.9333333333333335, 1.0, 1.0, 0.6620392730112953, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2914914302672872, 0.2914914302672872, 0.34465081197513786], 
reward next is 0.6553, 
noisyNet noise sample is [array([-0.82150316], dtype=float32), 0.53216916]. 
=============================================
[2019-04-27 21:10:50,760] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[74.1672  ]
 [74.15282 ]
 [73.9807  ]
 [74.203255]
 [73.82906 ]], R is [[74.10501862]
 [74.01873779]
 [73.93257904]
 [73.84618378]
 [73.75874329]].
[2019-04-27 21:11:20,172] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.4438697e-19 1.0000000e+00 9.3539756e-23 1.0779872e-16 5.6809590e-18], sum to 1.0000
[2019-04-27 21:11:20,217] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9751
[2019-04-27 21:11:20,224] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.7, 91.0, 1.0, 2.0, 0.7001758612858788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 802808.7307504405, 802808.73075044, 176417.9912776289], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5383200.0000, 
sim time next is 5383800.0000, 
raw observation next is [24.75, 91.0, 1.0, 2.0, 0.7092012842446052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 812274.0718545417, 812274.0718545417, 178092.6799761681], 
processed observation next is [1.0, 0.30434782608695654, 0.4722222222222222, 0.91, 1.0, 1.0, 0.653811052672149, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29009788280519344, 0.29009788280519344, 0.3424859230310925], 
reward next is 0.6575, 
noisyNet noise sample is [array([-1.2285261], dtype=float32), -0.8514087]. 
=============================================
[2019-04-27 21:11:22,722] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4284349e-29 1.0000000e+00 2.5430856e-34 1.2515348e-27 1.1641113e-31], sum to 1.0000
[2019-04-27 21:11:22,733] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9275
[2019-04-27 21:11:22,738] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.53333333333333, 52.33333333333334, 1.0, 2.0, 0.4525548938855883, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 542583.3845449478, 542583.3845449473, 135739.127663593], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5937600.0000, 
sim time next is 5938200.0000, 
raw observation next is [28.4, 53.0, 1.0, 2.0, 0.4441874071019217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 534113.6094879458, 534113.6094879453, 134553.3666657455], 
processed observation next is [1.0, 0.7391304347826086, 0.6074074074074074, 0.53, 1.0, 1.0, 0.338318341788002, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19075486053140922, 0.19075486053140905, 0.2587564743572029], 
reward next is 0.7412, 
noisyNet noise sample is [array([-0.4609245], dtype=float32), 2.8487334]. 
=============================================
[2019-04-27 21:11:24,484] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.99202400e-31 1.00000000e+00 4.28696311e-36 1.11571055e-26
 9.26712506e-33], sum to 1.0000
[2019-04-27 21:11:24,494] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7381
[2019-04-27 21:11:24,499] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.81666666666667, 70.33333333333333, 1.0, 2.0, 0.7178737749471283, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 818183.8974090284, 818183.8974090284, 179558.2774629252], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5669400.0000, 
sim time next is 5670000.0000, 
raw observation next is [29.9, 70.0, 1.0, 2.0, 0.7189754695985917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 819440.2055553322, 819440.2055553318, 179770.4475636678], 
processed observation next is [0.0, 0.6521739130434783, 0.6629629629629629, 0.7, 1.0, 1.0, 0.6654469876173711, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2926572162697615, 0.2926572162697613, 0.34571239916089963], 
reward next is 0.6543, 
noisyNet noise sample is [array([0.2028219], dtype=float32), 0.039711487]. 
=============================================
[2019-04-27 21:11:24,513] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[79.55115]
 [79.49089]
 [79.43398]
 [79.37722]
 [79.31207]], R is [[79.58364868]
 [79.44250488]
 [79.30314636]
 [79.16551971]
 [79.02962494]].
[2019-04-27 21:11:31,605] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.1937932e-17 1.0000000e+00 3.6251788e-21 3.3517295e-15 1.0903900e-17], sum to 1.0000
[2019-04-27 21:11:31,614] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4402
[2019-04-27 21:11:31,619] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.4, 86.33333333333334, 1.0, 2.0, 0.6797845991475631, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 777897.8094845542, 777897.8094845542, 172508.4488456422], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5556000.0000, 
sim time next is 5556600.0000, 
raw observation next is [25.4, 86.0, 1.0, 2.0, 0.7148501511930562, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 818902.4910384824, 818902.4910384824, 179183.4976108393], 
processed observation next is [1.0, 0.30434782608695654, 0.49629629629629624, 0.86, 1.0, 1.0, 0.6605358942774479, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29246517537088657, 0.29246517537088657, 0.344583649251614], 
reward next is 0.6554, 
noisyNet noise sample is [array([-0.6710739], dtype=float32), 0.4919882]. 
=============================================
[2019-04-27 21:11:39,341] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-04-27 21:11:39,341] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 21:11:39,344] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 21:11:39,346] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 21:11:39,346] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:11:39,345] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 21:11:39,349] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:11:39,348] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:11:39,350] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:11:39,347] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 21:11:39,352] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:11:39,375] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run75
[2019-04-27 21:11:39,376] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run75
[2019-04-27 21:11:39,416] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run75
[2019-04-27 21:11:39,447] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run75
[2019-04-27 21:11:39,448] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run75
[2019-04-27 21:12:12,338] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12781282]
[2019-04-27 21:12:12,340] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [32.85, 47.5, 1.0, 2.0, 0.8523940698653228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 971598.2020544359, 971598.2020544359, 206996.5911345533]
[2019-04-27 21:12:12,340] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 21:12:12,342] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.316222e-28 1.000000e+00 3.029014e-32 2.359862e-25 9.904783e-31], sampled 0.7072653059715687
[2019-04-27 21:12:18,787] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12781282]
[2019-04-27 21:12:18,789] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.2, 69.66666666666667, 1.0, 2.0, 0.6303051231710626, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 718907.9505542419, 718907.9505542419, 163397.2404168597]
[2019-04-27 21:12:18,791] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 21:12:18,794] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.1551159e-28 1.0000000e+00 3.0909956e-32 3.3015747e-25 1.3480001e-30], sampled 0.1539095943243578
[2019-04-27 21:12:27,311] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12781282]
[2019-04-27 21:12:27,312] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.08333333333333, 74.0, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 13.64916837925597, 6.9112, 132.9675870789461, 4982587.983445997, 1219676.115189604, 249024.8319868711]
[2019-04-27 21:12:27,313] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 21:12:27,315] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.2554289e-24 1.0000000e+00 2.4449787e-28 4.4642686e-22 1.4875453e-26], sampled 0.46488761672765666
[2019-04-27 21:12:27,315] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 0, 1] for the demand 4982587.983445997 W.
[2019-04-27 21:12:34,981] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12781282]
[2019-04-27 21:12:34,984] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.0, 89.0, 1.0, 2.0, 0.6578733540462628, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 749766.0363493364, 749766.0363493364, 168322.8979552811]
[2019-04-27 21:12:34,988] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 21:12:34,990] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0622599e-29 1.0000000e+00 4.7512903e-34 1.1322175e-26 2.1337970e-32], sampled 0.7373282162728536
[2019-04-27 21:12:56,531] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12781282]
[2019-04-27 21:12:56,532] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.76731951, 63.50007644, 1.0, 2.0, 0.3835329107653025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 477918.8861187752, 477918.8861187752, 126380.2972032509]
[2019-04-27 21:12:56,534] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 21:12:56,536] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.019853e-31 1.000000e+00 2.958899e-35 8.500349e-28 8.209869e-34], sampled 0.5050227924539906
[2019-04-27 21:13:05,684] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12781282]
[2019-04-27 21:13:05,686] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [30.22220225, 49.45522276, 1.0, 2.0, 0.571725105383661, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9124139341512657, 6.911199999999999, 6.9112, 121.9260426156618, 1330010.619111636, 1330010.619111637, 282565.620453415]
[2019-04-27 21:13:05,689] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 21:13:05,693] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.3775268e-28 1.0000000e+00 4.3741937e-32 2.8469714e-25 1.2026924e-30], sampled 0.3986171551119694
[2019-04-27 21:13:05,694] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1330010.619111636 W.
[2019-04-27 21:13:07,007] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12781282]
[2019-04-27 21:13:07,009] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.4, 82.33333333333334, 1.0, 2.0, 0.6761788464347896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 770638.9531386453, 770638.9531386453, 171685.3098657519]
[2019-04-27 21:13:07,009] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 21:13:07,012] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.5787171e-30 1.0000000e+00 3.5662437e-34 8.5010987e-27 1.4219141e-32], sampled 0.5279755581144006
[2019-04-27 21:13:09,767] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12781282]
[2019-04-27 21:13:09,770] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.0, 91.5, 1.0, 2.0, 0.4961829196308246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 588938.408154194, 588938.408154194, 142189.1616740044]
[2019-04-27 21:13:09,771] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 21:13:09,775] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.3296734e-28 1.0000000e+00 2.5489155e-32 2.2302106e-25 8.2382114e-31], sampled 0.8091709039527447
[2019-04-27 21:13:25,835] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12781282]
[2019-04-27 21:13:25,837] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.03333333333333, 81.0, 1.0, 2.0, 0.5199099791998066, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 640159.8248122868, 640159.8248122868, 146692.4315807072]
[2019-04-27 21:13:25,838] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 21:13:25,841] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.2902198e-28 1.0000000e+00 3.4306471e-32 2.7396084e-25 1.0163911e-30], sampled 0.9744925701168061
[2019-04-27 21:13:25,964] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8769.4422 2170768739.9937 493.0000
[2019-04-27 21:13:26,410] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8582.0590 2248830394.8409 553.0000
[2019-04-27 21:13:26,495] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8922.6628 2120599135.7723 430.0000
[2019-04-27 21:13:26,576] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8098.4495 2445508074.6415 746.0000
[2019-04-27 21:13:26,587] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8700.1130 2195220806.1349 572.0000
[2019-04-27 21:13:27,605] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1850000, evaluation results [1850000.0, 8098.4494892610255, 2445508074.64147, 746.0, 8769.442185004564, 2170768739.993712, 493.0, 8922.662781171732, 2120599135.7722971, 430.0, 8582.059032767682, 2248830394.840892, 553.0, 8700.112961499688, 2195220806.134913, 572.0]
[2019-04-27 21:13:33,515] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.8556424e-33 1.0000000e+00 0.0000000e+00 5.4758522e-30 3.7300258e-35], sum to 1.0000
[2019-04-27 21:13:33,524] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5892
[2019-04-27 21:13:33,528] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.53333333333333, 60.33333333333334, 1.0, 2.0, 0.4211558406316827, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 517025.6151074707, 517025.6151074707, 131521.7175244365], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5859600.0000, 
sim time next is 5860200.0000, 
raw observation next is [25.36666666666667, 61.66666666666666, 1.0, 2.0, 0.4249321149630216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 521149.853741879, 521149.853741879, 132054.4962257053], 
processed observation next is [1.0, 0.8260869565217391, 0.49506172839506185, 0.6166666666666666, 1.0, 1.0, 0.31539537495597814, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18612494776495678, 0.18612494776495678, 0.25395095428020253], 
reward next is 0.7460, 
noisyNet noise sample is [array([-0.984798], dtype=float32), 0.8940587]. 
=============================================
[2019-04-27 21:13:41,517] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.8786162e-27 1.0000000e+00 1.9656794e-31 1.7199269e-23 6.2465684e-28], sum to 1.0000
[2019-04-27 21:13:41,524] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0346
[2019-04-27 21:13:41,532] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1409710.356914199 W.
[2019-04-27 21:13:41,539] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.86666666666667, 59.66666666666667, 1.0, 2.0, 0.6129686871807606, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9764825710276804, 6.9112, 6.9112, 121.9256048290879, 1409710.356914199, 1409710.356914199, 298771.796034675], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6180600.0000, 
sim time next is 6181200.0000, 
raw observation next is [29.0, 59.0, 1.0, 2.0, 0.5498293307352179, 1.0, 1.0, 0.5498293307352179, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260424821667, 1255131.747776894, 1255131.747776894, 251294.3013889108], 
processed observation next is [1.0, 0.5652173913043478, 0.6296296296296297, 0.59, 1.0, 1.0, 0.46408253658954507, 1.0, 0.5, 0.46408253658954507, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621279338673, 0.4482613384917478, 0.4482613384917478, 0.4832582719017515], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6006712], dtype=float32), -1.0435212]. 
=============================================
[2019-04-27 21:13:47,693] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.2511914e-34 1.0000000e+00 1.3340758e-37 2.4739099e-30 2.6040088e-34], sum to 1.0000
[2019-04-27 21:13:47,700] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1391
[2019-04-27 21:13:47,707] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.05, 76.0, 1.0, 2.0, 0.5222451428109642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 620250.76306559, 620250.76306559, 146334.0986223144], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6042600.0000, 
sim time next is 6043200.0000, 
raw observation next is [24.93333333333333, 76.66666666666667, 1.0, 2.0, 0.5190610536843985, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 616638.6700522248, 616638.6700522248, 145829.4351436074], 
processed observation next is [1.0, 0.9565217391304348, 0.47901234567901224, 0.7666666666666667, 1.0, 1.0, 0.4274536353385696, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22022809644722313, 0.22022809644722313, 0.28044122143001426], 
reward next is 0.7196, 
noisyNet noise sample is [array([-0.4723655], dtype=float32), 0.5829421]. 
=============================================
[2019-04-27 21:13:52,391] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.3347206e-30 1.0000000e+00 5.8553251e-33 5.5768527e-29 1.0659898e-30], sum to 1.0000
[2019-04-27 21:13:52,399] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0318
[2019-04-27 21:13:52,407] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1926207.842441877 W.
[2019-04-27 21:13:52,415] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.93333333333333, 54.83333333333334, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 7.005091703607254, 6.9112, 121.9255350755983, 1926207.842441877, 1878127.098395686, 383791.2584645532], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6108600.0000, 
sim time next is 6109200.0000, 
raw observation next is [29.9, 55.0, 1.0, 2.0, 0.8133833620958811, 1.0, 1.0, 0.8133833620958811, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9259860757935, 1855285.768579828, 1855285.768579828, 349314.1837543116], 
processed observation next is [1.0, 0.7391304347826086, 0.6629629629629629, 0.55, 1.0, 1.0, 0.77783733582843, 1.0, 0.5, 0.77783733582843, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094617534542078, 0.6626020602070815, 0.6626020602070815, 0.6717580456813684], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8596089], dtype=float32), -1.3315278]. 
=============================================
[2019-04-27 21:14:04,957] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.8915187e-29 1.0000000e+00 1.3076721e-32 2.5593692e-25 8.1564713e-31], sum to 1.0000
[2019-04-27 21:14:04,965] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5887
[2019-04-27 21:14:04,971] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 55.66666666666667, 1.0, 2.0, 0.6699811151173071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 763571.8995823086, 763571.8995823086, 170539.8480111847], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6366000.0000, 
sim time next is 6366600.0000, 
raw observation next is [32.0, 55.5, 1.0, 2.0, 0.6810217057753768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 776161.1395048443, 776161.1395048439, 172582.60536468], 
processed observation next is [0.0, 0.6956521739130435, 0.7407407407407407, 0.555, 1.0, 1.0, 0.6202639354468771, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27720040696601583, 0.27720040696601567, 0.3318896257013077], 
reward next is 0.6681, 
noisyNet noise sample is [array([1.0578479], dtype=float32), 1.2718908]. 
=============================================
[2019-04-27 21:14:05,363] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.4177601e-29 1.0000000e+00 6.5700441e-34 1.4631938e-25 1.7118037e-31], sum to 1.0000
[2019-04-27 21:14:05,374] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1558
[2019-04-27 21:14:05,381] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 55.5, 1.0, 2.0, 0.6810217057753768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 776161.1395048443, 776161.1395048439, 172582.60536468], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6366600.0000, 
sim time next is 6367200.0000, 
raw observation next is [32.0, 55.33333333333333, 1.0, 2.0, 0.6834871869215484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 778972.4787210795, 778972.4787210791, 173041.537843657], 
processed observation next is [0.0, 0.6956521739130435, 0.7407407407407407, 0.5533333333333332, 1.0, 1.0, 0.6231990320494624, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27820445668609983, 0.27820445668609967, 0.33277218816087883], 
reward next is 0.6672, 
noisyNet noise sample is [array([0.38948926], dtype=float32), -1.2597556]. 
=============================================
[2019-04-27 21:14:06,715] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.5362048e-29 1.0000000e+00 7.0901352e-33 2.4539619e-25 3.4931979e-35], sum to 1.0000
[2019-04-27 21:14:06,719] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2109
[2019-04-27 21:14:06,724] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.61666666666667, 61.33333333333334, 1.0, 2.0, 0.6810151467494969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 776153.6603915689, 776153.6603915689, 172580.7461569371], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6375000.0000, 
sim time next is 6375600.0000, 
raw observation next is [30.5, 62.0, 1.0, 2.0, 0.6831113597142169, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 778543.9297498517, 778543.9297498526, 172971.080577509], 
processed observation next is [0.0, 0.8260869565217391, 0.6851851851851852, 0.62, 1.0, 1.0, 0.622751618707401, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.2780514034820899, 0.27805140348209023, 0.33263669341828656], 
reward next is 0.6674, 
noisyNet noise sample is [array([1.043391], dtype=float32), 2.6730933]. 
=============================================
[2019-04-27 21:14:12,677] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.2435495e-26 1.0000000e+00 1.0811670e-30 2.8773076e-21 2.4101727e-25], sum to 1.0000
[2019-04-27 21:14:12,689] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2003
[2019-04-27 21:14:12,693] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 86.66666666666666, 1.0, 2.0, 0.7051666811894376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 803693.6197289325, 803693.6197289325, 177124.8717188428], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6554400.0000, 
sim time next is 6555000.0000, 
raw observation next is [26.63333333333333, 86.33333333333334, 1.0, 2.0, 0.7010688177298479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 799020.762325753, 799020.762325753, 176346.6171541886], 
processed observation next is [1.0, 0.8695652173913043, 0.5419753086419752, 0.8633333333333334, 1.0, 1.0, 0.6441295449164856, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2853645579734832, 0.2853645579734832, 0.3391281099119012], 
reward next is 0.6609, 
noisyNet noise sample is [array([-0.373234], dtype=float32), -1.285399]. 
=============================================
[2019-04-27 21:14:12,707] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[68.16001]
 [67.80099]
 [68.02534]
 [67.70608]
 [67.85533]], R is [[67.94425964]
 [67.92419434]
 [67.90327454]
 [67.88116455]
 [67.8575058 ]].
[2019-04-27 21:14:19,304] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.8176302e-23 1.0000000e+00 1.2720336e-28 1.4969130e-21 1.8623760e-22], sum to 1.0000
[2019-04-27 21:14:19,312] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1172
[2019-04-27 21:14:19,317] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.46666666666667, 41.16666666666666, 1.0, 2.0, 0.737784928338689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 934630.6456138123, 934630.6456138123, 186717.379517668], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6603000.0000, 
sim time next is 6603600.0000, 
raw observation next is [26.63333333333333, 40.33333333333334, 1.0, 2.0, 0.8054625884842693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1020327.648662016, 1020327.648662016, 200767.763243668], 
processed observation next is [1.0, 0.43478260869565216, 0.5419753086419752, 0.40333333333333343, 1.0, 1.0, 0.768407843433654, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3644027316650057, 0.3644027316650057, 0.38609185239166927], 
reward next is 0.6139, 
noisyNet noise sample is [array([-0.23112772], dtype=float32), -0.75522065]. 
=============================================
[2019-04-27 21:14:20,250] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-04-27 21:14:20,255] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 21:14:20,256] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 21:14:20,257] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 21:14:20,258] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 21:14:20,257] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 21:14:20,260] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:14:20,261] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:14:20,261] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:14:20,258] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:14:20,263] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:14:20,277] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run76
[2019-04-27 21:14:20,301] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run76
[2019-04-27 21:14:20,301] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run76
[2019-04-27 21:14:20,337] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run76
[2019-04-27 21:14:20,361] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run76
[2019-04-27 21:14:37,670] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12915617]
[2019-04-27 21:14:37,672] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [18.07903182333333, 84.71249495, 1.0, 2.0, 0.270641530839911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 347406.9125138633, 347406.9125138628, 112023.9102074976]
[2019-04-27 21:14:37,673] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 21:14:37,678] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.187171e-31 1.000000e+00 8.281388e-36 5.823083e-29 5.427487e-35], sampled 0.5345916241243756
[2019-04-27 21:14:38,750] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12915617]
[2019-04-27 21:14:38,753] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [18.08631115833333, 93.50376012333334, 1.0, 2.0, 0.3102378527178833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 394031.6079736178, 394031.6079736178, 116840.4698003095]
[2019-04-27 21:14:38,755] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 21:14:38,759] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.55490415e-30 1.00000000e+00 3.60139011e-35 2.05815587e-28
 2.44833111e-34], sampled 0.8901596491595616
[2019-04-27 21:15:07,004] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12915617]
[2019-04-27 21:15:07,004] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.0, 78.5, 1.0, 2.0, 0.5269781578998758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 633749.9935694169, 633749.9935694169, 147384.9145827124]
[2019-04-27 21:15:07,005] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 21:15:07,007] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.0181233e-29 1.0000000e+00 7.7654791e-34 1.9138449e-27 3.0485450e-33], sampled 0.28874710393543757
[2019-04-27 21:15:12,859] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12915617]
[2019-04-27 21:15:12,859] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.24694559, 41.84283568, 1.0, 2.0, 0.4592268394370091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 562315.9953488715, 562315.9953488715, 137105.5006752996]
[2019-04-27 21:15:12,860] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 21:15:12,863] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [5.3317871e-31 1.0000000e+00 1.3681646e-35 6.0551406e-29 3.7846628e-35], sampled 0.027808621406146483
[2019-04-27 21:15:18,431] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12915617]
[2019-04-27 21:15:18,432] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [34.0, 67.0, 1.0, 2.0, 1.02, 1.0, 2.0, 0.919449235908574, 1.0, 1.0, 0.9977734948820727, 7.208142521895228, 6.9112, 128.1568211785423, 3088266.07429569, 2928434.193644595, 547623.9518768691]
[2019-04-27 21:15:18,435] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 21:15:18,439] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0237609e-23 1.0000000e+00 2.9172298e-27 4.3968007e-22 1.1863998e-26], sampled 0.1923704348896057
[2019-04-27 21:15:18,440] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 0, 1] for the demand 3088266.07429569 W.
[2019-04-27 21:15:18,583] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12915617]
[2019-04-27 21:15:18,584] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.75824357, 75.74760043166665, 1.0, 2.0, 0.6977173383523112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 795199.0394710349, 795199.0394710349, 175720.5076916358]
[2019-04-27 21:15:18,585] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 21:15:18,587] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.4500319e-32 1.0000000e+00 8.4767042e-37 7.2515032e-30 2.3905004e-36], sampled 0.07359501946158364
[2019-04-27 21:15:58,415] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12915617]
[2019-04-27 21:15:58,416] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.64540419666666, 91.46521924999999, 1.0, 2.0, 0.4811273932629885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 575585.0415076294, 575585.0415076294, 140025.1379608406]
[2019-04-27 21:15:58,417] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 21:15:58,421] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.2642543e-30 1.0000000e+00 6.0659882e-35 2.7017441e-28 3.0749275e-34], sampled 0.6152971977400319
[2019-04-27 21:16:03,034] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.12915617]
[2019-04-27 21:16:03,036] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [17.41666666666667, 95.83333333333334, 1.0, 2.0, 0.2860832763168907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 365018.9464763973, 365018.9464763973, 113873.075791091]
[2019-04-27 21:16:03,039] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 21:16:03,042] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [7.4963424e-31 1.0000000e+00 1.3981435e-35 1.1233281e-28 1.4865067e-34], sampled 0.6694229185693281
[2019-04-27 21:16:06,888] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.0852 2170656631.3663 493.0000
[2019-04-27 21:16:07,521] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8098.4495 2445508074.6415 746.0000
[2019-04-27 21:16:07,530] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8700.1130 2195220806.1349 572.0000
[2019-04-27 21:16:07,547] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8583.7021 2248718286.8236 553.0000
[2019-04-27 21:16:07,579] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8923.4199 2120533710.1715 430.0000
[2019-04-27 21:16:08,595] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1875000, evaluation results [1875000.0, 8098.4494892610255, 2445508074.64147, 746.0, 8771.085197215923, 2170656631.3662677, 493.0, 8923.419851553375, 2120533710.171511, 430.0, 8583.702050975664, 2248718286.823596, 553.0, 8700.112961499688, 2195220806.134913, 572.0]
[2019-04-27 21:16:10,330] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4683652e-26 1.0000000e+00 1.2275408e-31 3.0560124e-23 7.9829936e-28], sum to 1.0000
[2019-04-27 21:16:10,339] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6435
[2019-04-27 21:16:10,344] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.95, 44.5, 1.0, 2.0, 0.3027928114173101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 390594.0164774077, 390594.0164774082, 109469.4160924824], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6669000.0000, 
sim time next is 6669600.0000, 
raw observation next is [22.93333333333333, 44.33333333333334, 1.0, 2.0, 0.2946495679940916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 380086.863587001, 380086.863587001, 107873.3022219369], 
processed observation next is [1.0, 0.17391304347826086, 0.40493827160493817, 0.4433333333333334, 1.0, 1.0, 0.16029710475487094, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13574530842392893, 0.13574530842392893, 0.20744865811910942], 
reward next is 0.7926, 
noisyNet noise sample is [array([-1.1966558], dtype=float32), -0.42502078]. 
=============================================
[2019-04-27 21:16:22,074] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.0022435e-32 1.0000000e+00 5.0395751e-36 2.3787028e-28 1.8190071e-35], sum to 1.0000
[2019-04-27 21:16:22,084] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0896
[2019-04-27 21:16:22,090] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.7, 49.33333333333333, 1.0, 2.0, 0.4944197353750281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 590381.864098681, 590381.864098681, 142046.2796247138], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6871200.0000, 
sim time next is 6871800.0000, 
raw observation next is [29.85, 49.16666666666667, 1.0, 2.0, 0.4990312110690504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 594869.120835499, 594869.120835499, 142730.8563653702], 
processed observation next is [0.0, 0.5217391304347826, 0.6611111111111112, 0.4916666666666667, 1.0, 1.0, 0.40360858460601245, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21245325744124965, 0.21245325744124965, 0.2744824160872504], 
reward next is 0.7255, 
noisyNet noise sample is [array([-2.3815866], dtype=float32), -1.676174]. 
=============================================
[2019-04-27 21:16:25,424] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3734294e-29 1.0000000e+00 2.0526387e-33 5.3918316e-26 1.4143898e-31], sum to 1.0000
[2019-04-27 21:16:25,435] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7105
[2019-04-27 21:16:25,439] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.9, 96.0, 1.0, 2.0, 0.4353853393462724, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 530377.1908068433, 530377.1908068433, 133478.5198575778], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7536000.0000, 
sim time next is 7536600.0000, 
raw observation next is [20.9, 96.0, 1.0, 2.0, 0.4355024364617514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 530519.4167798148, 530519.4167798144, 133495.6762826738], 
processed observation next is [0.0, 0.21739130434782608, 0.32962962962962955, 0.96, 1.0, 1.0, 0.32797909102589456, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18947122027850527, 0.18947122027850513, 0.2567224543897573], 
reward next is 0.7433, 
noisyNet noise sample is [array([0.04271854], dtype=float32), 1.1113237]. 
=============================================
[2019-04-27 21:16:31,785] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.7695362e-22 1.0000000e+00 1.5266902e-25 1.3112779e-18 8.4511005e-22], sum to 1.0000
[2019-04-27 21:16:31,794] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6380
[2019-04-27 21:16:31,800] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.68333333333333, 90.66666666666667, 1.0, 2.0, 0.5715613862406655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 705282.2293120772, 705282.2293120772, 155334.9857008482], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7017000.0000, 
sim time next is 7017600.0000, 
raw observation next is [20.76666666666667, 90.33333333333334, 1.0, 2.0, 0.5015671567414179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 618506.8168709342, 618506.8168709342, 143774.6848595672], 
processed observation next is [1.0, 0.21739130434782608, 0.32469135802469146, 0.9033333333333334, 1.0, 1.0, 0.40662756754930707, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22089529173961936, 0.22089529173961936, 0.2764897785760908], 
reward next is 0.7235, 
noisyNet noise sample is [array([0.32228303], dtype=float32), 1.9971468]. 
=============================================
[2019-04-27 21:16:41,975] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.0323205e-32 1.0000000e+00 9.1942272e-35 1.3398955e-29 1.5497069e-35], sum to 1.0000
[2019-04-27 21:16:41,985] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6416
[2019-04-27 21:16:41,990] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.7, 77.0, 1.0, 2.0, 0.4936317440103045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 588701.752657596, 588701.752657596, 141896.0940051146], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7477200.0000, 
sim time next is 7477800.0000, 
raw observation next is [24.81666666666666, 76.5, 1.0, 2.0, 0.4961732542908073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 591187.7101398545, 591187.7101398545, 142272.8472399243], 
processed observation next is [0.0, 0.5652173913043478, 0.4746913580246911, 0.765, 1.0, 1.0, 0.40020625510810387, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21113846790709087, 0.21113846790709087, 0.2736016293075467], 
reward next is 0.7264, 
noisyNet noise sample is [array([0.21157616], dtype=float32), 2.1334212]. 
=============================================
[2019-04-27 21:16:43,649] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.2993723e-32 1.0000000e+00 4.2448303e-37 2.7493801e-30 5.1018868e-33], sum to 1.0000
[2019-04-27 21:16:43,658] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0250
[2019-04-27 21:16:43,670] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.8, 82.0, 1.0, 2.0, 0.3624363340591381, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 453275.3348302474, 453275.3348302474, 123537.2786535113], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7257600.0000, 
sim time next is 7258200.0000, 
raw observation next is [20.78333333333333, 82.33333333333334, 1.0, 2.0, 0.3633274731558391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 454272.1572168372, 454272.1572168372, 123655.0747668453], 
processed observation next is [1.0, 0.0, 0.32530864197530857, 0.8233333333333335, 1.0, 1.0, 0.24205651566171318, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16224005614887044, 0.16224005614887044, 0.2377982207054717], 
reward next is 0.7622, 
noisyNet noise sample is [array([0.41290203], dtype=float32), 0.49494717]. 
=============================================
[2019-04-27 21:16:49,704] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 21:16:49,704] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:16:49,768] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run10
[2019-04-27 21:16:52,299] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 21:16:52,300] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:16:52,359] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run10
[2019-04-27 21:16:52,730] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.9216160e-28 1.0000000e+00 7.9315526e-33 4.2799121e-25 8.5309600e-33], sum to 1.0000
[2019-04-27 21:16:52,737] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8691
[2019-04-27 21:16:52,741] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.06666666666667, 91.33333333333334, 1.0, 2.0, 0.381958393854153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 475001.9825132458, 475001.9825132458, 126143.9455419241], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7431600.0000, 
sim time next is 7432200.0000, 
raw observation next is [20.05, 91.5, 1.0, 2.0, 0.3813333368804351, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 474205.3848525184, 474205.3848525184, 126057.4668245171], 
processed observation next is [0.0, 0.0, 0.29814814814814816, 0.915, 1.0, 1.0, 0.26349206771480366, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16935906601875655, 0.16935906601875655, 0.24241820543176365], 
reward next is 0.7576, 
noisyNet noise sample is [array([0.11767884], dtype=float32), 0.6027644]. 
=============================================
[2019-04-27 21:16:53,159] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.9436301e-32 1.0000000e+00 6.0127641e-37 1.3352376e-28 1.0868109e-31], sum to 1.0000
[2019-04-27 21:16:53,165] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5812
[2019-04-27 21:16:53,170] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.86666666666667, 89.83333333333333, 1.0, 2.0, 0.4102741615323204, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 505670.3312598079, 505670.3312598079, 130012.6519818455], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7408200.0000, 
sim time next is 7408800.0000, 
raw observation next is [20.8, 90.0, 1.0, 2.0, 0.4105364209843029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 506331.3180542391, 506331.3180542391, 130058.3927652255], 
processed observation next is [1.0, 0.782608695652174, 0.32592592592592595, 0.9, 1.0, 1.0, 0.29825764402893196, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18083261359079966, 0.18083261359079966, 0.2501122937792798], 
reward next is 0.7499, 
noisyNet noise sample is [array([-0.20230556], dtype=float32), 1.0991836]. 
=============================================
[2019-04-27 21:16:55,918] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.6447502e-29 1.0000000e+00 8.1395187e-34 1.5732600e-26 1.5555923e-30], sum to 1.0000
[2019-04-27 21:16:55,928] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6331
[2019-04-27 21:16:55,933] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.73333333333333, 75.33333333333334, 1.0, 2.0, 0.5361449239782884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 630402.6490595455, 630402.6490595455, 148332.4383418111], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7559400.0000, 
sim time next is 7560000.0000, 
raw observation next is [26.0, 74.0, 1.0, 2.0, 0.5372088172171822, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 630974.7412826609, 630974.7412826609, 148477.4503091583], 
processed observation next is [0.0, 0.5217391304347826, 0.5185185185185185, 0.74, 1.0, 1.0, 0.44905811573474064, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2253481218866646, 0.2253481218866646, 0.2855335582868429], 
reward next is 0.7145, 
noisyNet noise sample is [array([1.4688213], dtype=float32), -1.4278356]. 
=============================================
[2019-04-27 21:16:55,952] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[74.64944]
 [74.61979]
 [74.62389]
 [74.6666 ]
 [74.70319]], R is [[74.7824707 ]
 [74.74938965]
 [74.71736908]
 [74.68742371]
 [74.65950775]].
[2019-04-27 21:16:58,824] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.5305491e-31 1.0000000e+00 9.6915312e-36 1.5541162e-29 5.9591089e-35], sum to 1.0000
[2019-04-27 21:16:58,832] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0837
[2019-04-27 21:16:58,837] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.75, 95.0, 1.0, 2.0, 0.4744063520471548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 570676.8606803314, 570676.8606803314, 139103.3526541013], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7513800.0000, 
sim time next is 7514400.0000, 
raw observation next is [21.7, 95.0, 1.0, 2.0, 0.4728920929622356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 569347.5924265018, 569347.5924265018, 138888.5736388958], 
processed observation next is [0.0, 1.0, 0.3592592592592592, 0.95, 1.0, 1.0, 0.37249058685980435, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20333842586660777, 0.20333842586660777, 0.2670934108440304], 
reward next is 0.7329, 
noisyNet noise sample is [array([-0.7413601], dtype=float32), -0.7192908]. 
=============================================
[2019-04-27 21:16:59,226] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4655866e-30 1.0000000e+00 6.6815058e-34 1.0195031e-27 1.3638085e-35], sum to 1.0000
[2019-04-27 21:16:59,231] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5180
[2019-04-27 21:16:59,238] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.1, 91.0, 1.0, 2.0, 0.458632685241272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 553482.7959838348, 553482.7959838348, 136771.761848038], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7549200.0000, 
sim time next is 7549800.0000, 
raw observation next is [22.3, 90.16666666666667, 1.0, 2.0, 0.463057879438743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 557904.6555819703, 557904.6555819703, 137408.3051992574], 
processed observation next is [0.0, 0.391304347826087, 0.38148148148148153, 0.9016666666666667, 1.0, 1.0, 0.36078318980802737, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19925166270784656, 0.19925166270784656, 0.2642467407678027], 
reward next is 0.7358, 
noisyNet noise sample is [array([0.44011515], dtype=float32), -0.9640142]. 
=============================================
[2019-04-27 21:17:00,581] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-04-27 21:17:00,582] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 21:17:00,586] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:17:00,586] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 21:17:00,588] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:17:00,588] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 21:17:00,590] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 21:17:00,591] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:17:00,588] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 21:17:00,593] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:17:00,594] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:17:00,613] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run77
[2019-04-27 21:17:00,636] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run77
[2019-04-27 21:17:00,663] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run77
[2019-04-27 21:17:00,683] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run77
[2019-04-27 21:17:00,703] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run77
[2019-04-27 21:17:05,974] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.13224334]
[2019-04-27 21:17:05,975] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.98613061, 33.50966485, 1.0, 2.0, 0.3097809178249564, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 397903.4856656942, 397903.4856656942, 116791.3506657467]
[2019-04-27 21:17:05,977] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 21:17:05,979] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.5751544e-30 1.0000000e+00 3.3674073e-35 1.0918698e-28 8.9690546e-35], sampled 0.07545727902045218
[2019-04-27 21:17:28,132] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.13224334]
[2019-04-27 21:17:28,133] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.971440215, 94.03721140500001, 1.0, 2.0, 0.5000938128732337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 600005.4094869725, 600005.4094869725, 143037.0181051696]
[2019-04-27 21:17:28,136] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 21:17:28,138] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0467969e-29 1.0000000e+00 2.6790953e-34 6.4184562e-28 9.2598061e-34], sampled 0.7434543268097866
[2019-04-27 21:17:37,438] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.13224334]
[2019-04-27 21:17:37,439] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.77978988666667, 84.49133732333334, 1.0, 2.0, 0.4461954750489355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 546341.9242093549, 546341.9242093549, 135152.5544971004]
[2019-04-27 21:17:37,440] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 21:17:37,446] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.1324160e-30 1.0000000e+00 4.2836796e-35 1.4756860e-28 1.3783648e-34], sampled 0.8360109235809546
[2019-04-27 21:17:38,254] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.13224334]
[2019-04-27 21:17:38,255] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.5, 64.0, 1.0, 2.0, 0.6304765692893513, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 718527.7960091268, 718527.7960091264, 163399.5607743489]
[2019-04-27 21:17:38,256] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 21:17:38,261] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.4192004e-32 1.0000000e+00 2.5418693e-37 1.8180196e-30 7.0679230e-37], sampled 0.5845994055972172
[2019-04-27 21:17:41,217] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.13224334]
[2019-04-27 21:17:41,219] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.8, 78.33333333333334, 1.0, 2.0, 0.9831968172893484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.041132908421674, 6.9112, 121.9253153981734, 1187387.810635029, 1120850.945107388, 236691.1116008989]
[2019-04-27 21:17:41,220] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 21:17:41,224] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.7007205e-28 1.0000000e+00 2.9137525e-32 2.6272979e-26 1.0617321e-31], sampled 0.7967946636146147
[2019-04-27 21:18:43,902] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.13224334]
[2019-04-27 21:18:43,903] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [17.5, 94.0, 1.0, 2.0, 0.2937770384842277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 375459.1605087728, 375459.1605087728, 114811.3639392984]
[2019-04-27 21:18:43,904] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 21:18:43,906] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.6113564e-30 1.0000000e+00 1.2512295e-34 3.8262224e-28 4.5036169e-34], sampled 0.0017997733182115727
[2019-04-27 21:18:48,092] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8922.6628 2120599135.7723 430.0000
[2019-04-27 21:18:48,356] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8769.4422 2170768739.9937 493.0000
[2019-04-27 21:18:48,581] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8098.4495 2445508074.6415 746.0000
[2019-04-27 21:18:48,634] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8582.0590 2248830394.8409 553.0000
[2019-04-27 21:18:48,690] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8700.1130 2195220806.1349 572.0000
[2019-04-27 21:18:49,705] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1900000, evaluation results [1900000.0, 8098.4494892610255, 2445508074.64147, 746.0, 8769.442185004564, 2170768739.993712, 493.0, 8922.662781171732, 2120599135.7722971, 430.0, 8582.059032767682, 2248830394.840892, 553.0, 8700.112961499688, 2195220806.134913, 572.0]
[2019-04-27 21:18:52,807] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.7448597e-24 1.0000000e+00 5.5463021e-29 9.2640176e-25 2.4401973e-29], sum to 1.0000
[2019-04-27 21:18:52,813] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7411
[2019-04-27 21:18:52,822] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1428887.713292588 W.
[2019-04-27 21:18:52,827] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.3, 66.0, 1.0, 2.0, 0.9848238197309694, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.387305613987387, 6.9112, 121.9240634931989, 1428887.713292588, 1185083.042633668, 240183.3007723565], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7660800.0000, 
sim time next is 7661400.0000, 
raw observation next is [25.15, 66.0, 1.0, 2.0, 0.5408137060393484, 1.0, 1.0, 0.5408137060393484, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.925755913008, 1290507.702668425, 1290507.702668425, 250809.2667519292], 
processed observation next is [1.0, 0.6956521739130435, 0.487037037037037, 0.66, 1.0, 1.0, 0.45334965004684336, 1.0, 0.5, 0.45334965004684336, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094602254126645, 0.46089560809586605, 0.46089560809586605, 0.4823255129844792], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0916567], dtype=float32), -1.0991232]. 
=============================================
[2019-04-27 21:18:57,842] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.8337362e-28 1.0000000e+00 2.2006505e-31 3.8361206e-26 3.2327191e-32], sum to 1.0000
[2019-04-27 21:18:57,849] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6217
[2019-04-27 21:18:57,853] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.7, 67.5, 1.0, 2.0, 0.2670494191508029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 344300.8392206775, 344300.8392206775, 111589.0530569038], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7693800.0000, 
sim time next is 7694400.0000, 
raw observation next is [19.7, 66.0, 1.0, 2.0, 0.259693239346412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 334976.5147017075, 334976.5147017075, 107456.5754978563], 
processed observation next is [1.0, 0.043478260869565216, 0.28518518518518515, 0.66, 1.0, 1.0, 0.11868242779334759, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.11963446953632412, 0.11963446953632412, 0.20664726057280058], 
reward next is 0.7934, 
noisyNet noise sample is [array([-0.6841386], dtype=float32), -1.2850682]. 
=============================================
[2019-04-27 21:18:58,024] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 21:18:58,025] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:18:58,074] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run10
[2019-04-27 21:19:02,916] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.2854954e-23 1.0000000e+00 3.5780396e-29 3.9835418e-23 1.2230001e-27], sum to 1.0000
[2019-04-27 21:19:02,927] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0124
[2019-04-27 21:19:02,931] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 49.66666666666667, 1.0, 2.0, 0.3823808691693591, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 483337.7153154396, 483337.7153154396, 126327.4001430213], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7803600.0000, 
sim time next is 7804200.0000, 
raw observation next is [25.2, 48.83333333333333, 1.0, 2.0, 0.3782367174018477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 477968.5887327259, 477968.5887327259, 125754.9028828144], 
processed observation next is [1.0, 0.30434782608695654, 0.4888888888888889, 0.4883333333333333, 1.0, 1.0, 0.2598056159545806, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17070306740454497, 0.17070306740454497, 0.24183635169772], 
reward next is 0.7582, 
noisyNet noise sample is [array([-0.8578881], dtype=float32), -0.45705673]. 
=============================================
[2019-04-27 21:19:06,640] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.3274090e-23 1.0000000e+00 2.2753158e-26 1.7910568e-22 1.3586117e-26], sum to 1.0000
[2019-04-27 21:19:06,648] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8454
[2019-04-27 21:19:06,656] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.63333333333333, 77.16666666666667, 1.0, 2.0, 0.4819511108032708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 601203.7125865946, 601203.7125865946, 140846.3854696111], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7888200.0000, 
sim time next is 7888800.0000, 
raw observation next is [21.76666666666667, 76.33333333333334, 1.0, 2.0, 0.470119229811812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 586252.9803463769, 586252.9803463769, 139013.617417027], 
processed observation next is [1.0, 0.30434782608695654, 0.3617283950617285, 0.7633333333333334, 1.0, 1.0, 0.36918955929977615, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20937606440942033, 0.20937606440942033, 0.2673338796481289], 
reward next is 0.7327, 
noisyNet noise sample is [array([-1.1000167], dtype=float32), -0.6375587]. 
=============================================
[2019-04-27 21:19:07,747] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 21:19:07,748] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:19:07,815] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run10
[2019-04-27 21:19:08,518] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.36077048e-32 1.00000000e+00 2.04479678e-36 1.04706845e-29
 1.92009480e-37], sum to 1.0000
[2019-04-27 21:19:08,526] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7389
[2019-04-27 21:19:08,534] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1727087.543871896 W.
[2019-04-27 21:19:08,538] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.1, 50.0, 1.0, 2.0, 0.8762175202768736, 0.0, 1.0, 0.0, 1.0, 2.0, 0.986014320216271, 6.9112, 6.9112, 121.9260426156618, 1727087.543871896, 1727087.543871896, 350001.9596837856], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7923600.0000, 
sim time next is 7924200.0000, 
raw observation next is [29.93333333333334, 50.5, 1.0, 2.0, 0.3509473586171944, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5605129333967952, 6.911199999999999, 6.9112, 121.9260426156618, 819011.6030486826, 819011.603048683, 209018.5086366377], 
processed observation next is [1.0, 0.7391304347826086, 0.6641975308641977, 0.505, 1.0, 1.0, 0.22731828406808857, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.45064116674599397, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2925041439459581, 0.29250414394595825, 0.4019586704550725], 
reward next is 0.5980, 
noisyNet noise sample is [array([-1.5016108], dtype=float32), 1.5630537]. 
=============================================
[2019-04-27 21:19:09,299] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 21:19:09,299] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:19:09,354] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run10
[2019-04-27 21:19:09,564] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 21:19:09,565] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:19:09,598] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run10
[2019-04-27 21:19:10,273] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 21:19:10,273] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:19:10,308] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run10
[2019-04-27 21:19:10,490] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 21:19:10,491] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:19:10,504] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run10
[2019-04-27 21:19:10,535] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 21:19:10,536] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:19:10,548] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run10
[2019-04-27 21:19:10,585] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 21:19:10,589] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:19:10,616] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run10
[2019-04-27 21:19:10,736] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 21:19:10,736] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:19:10,748] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run10
[2019-04-27 21:19:10,769] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 21:19:10,771] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:19:10,789] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run10
[2019-04-27 21:19:11,049] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 21:19:11,049] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:19:11,060] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run10
[2019-04-27 21:19:11,122] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 21:19:11,122] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:19:11,131] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run10
[2019-04-27 21:19:11,200] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 21:19:11,201] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:19:11,207] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run10
[2019-04-27 21:19:11,232] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 21:19:11,233] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:19:11,245] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run10
[2019-04-27 21:19:12,311] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.6769941e-26 1.0000000e+00 4.9235672e-28 1.6055604e-22 5.5884012e-27], sum to 1.0000
[2019-04-27 21:19:12,316] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5116
[2019-04-27 21:19:12,322] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 65.0, 1.0, 2.0, 0.2451251222606318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 316189.0216245713, 316189.0216245713, 100085.5364738854], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 23400.0000, 
sim time next is 24000.0000, 
raw observation next is [19.86666666666667, 62.33333333333334, 1.0, 2.0, 0.2560994534170583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 330347.9552395532, 330347.9552395532, 102374.6996347997], 
processed observation next is [1.0, 0.2608695652173913, 0.2913580246913582, 0.6233333333333334, 1.0, 1.0, 0.1144041112107837, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.11798141258555471, 0.11798141258555471, 0.1968744223746148], 
reward next is 0.8031, 
noisyNet noise sample is [array([0.10423832], dtype=float32), -0.70415306]. 
=============================================
[2019-04-27 21:19:12,329] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[61.537003]
 [61.733124]
 [61.957188]
 [61.975994]
 [62.120037]], R is [[61.44672775]
 [61.63978958]
 [61.83315277]
 [62.02611923]
 [62.2191391 ]].
[2019-04-27 21:19:19,589] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.4297831e-38 1.0000000e+00 0.0000000e+00 3.4385651e-37 0.0000000e+00], sum to 1.0000
[2019-04-27 21:19:19,596] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7208
[2019-04-27 21:19:19,607] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1718988.967734403 W.
[2019-04-27 21:19:19,612] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [37.3, 8.0, 1.0, 2.0, 0.7991643350319848, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9616341891587077, 6.911199999999999, 6.9112, 121.9260426156618, 1718988.967734403, 1718988.967734404, 318630.4051931895], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 145200.0000, 
sim time next is 145800.0000, 
raw observation next is [37.3, 7.5, 1.0, 2.0, 0.7924705759906744, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9649256756612845, 6.9112, 6.9112, 121.9260426156618, 1715149.374541587, 1715149.374541587, 316163.0134065227], 
processed observation next is [1.0, 0.6956521739130435, 0.9370370370370369, 0.075, 1.0, 1.0, 0.75294116189366, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9561570945766057, 0.0, 0.0, 0.8094621288201359, 0.6125533480505668, 0.6125533480505668, 0.6080057950125436], 
reward next is 0.3920, 
noisyNet noise sample is [array([0.43193644], dtype=float32), -1.2626528]. 
=============================================
[2019-04-27 21:19:22,797] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.3740825e-34 1.0000000e+00 0.0000000e+00 6.0966225e-31 3.5669048e-37], sum to 1.0000
[2019-04-27 21:19:22,804] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8010
[2019-04-27 21:19:22,810] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.05, 31.0, 1.0, 2.0, 0.353952385679256, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 445513.3244456212, 445513.3244456212, 122448.1894666981], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 499800.0000, 
sim time next is 500400.0000, 
raw observation next is [29.8, 32.0, 1.0, 2.0, 0.3520439919377784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 442907.6813709488, 442907.6813709484, 122191.7861613775], 
processed observation next is [1.0, 0.8260869565217391, 0.6592592592592593, 0.32, 1.0, 1.0, 0.22862379992592669, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15818131477533887, 0.1581813147753387, 0.2349842041564952], 
reward next is 0.7650, 
noisyNet noise sample is [array([-0.50961834], dtype=float32), -0.33393592]. 
=============================================
[2019-04-27 21:19:23,611] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.0098087e-35 1.0000000e+00 0.0000000e+00 2.2249343e-32 0.0000000e+00], sum to 1.0000
[2019-04-27 21:19:23,619] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9169
[2019-04-27 21:19:23,624] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.5, 21.0, 1.0, 2.0, 0.363461416788231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 464232.3123215236, 464232.3123215231, 123777.1331548994], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 217800.0000, 
sim time next is 218400.0000, 
raw observation next is [31.7, 20.0, 1.0, 2.0, 0.3648332948032827, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 466548.8411511191, 466548.8411511186, 123963.1394443607], 
processed observation next is [0.0, 0.5217391304347826, 0.7296296296296296, 0.2, 1.0, 1.0, 0.24384916048009844, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16662458612539968, 0.16662458612539952, 0.23839065277761673], 
reward next is 0.7616, 
noisyNet noise sample is [array([0.34716815], dtype=float32), -0.9577004]. 
=============================================
[2019-04-27 21:19:31,468] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.2751384e-29 1.0000000e+00 4.2204862e-35 3.9279395e-29 7.6650533e-36], sum to 1.0000
[2019-04-27 21:19:31,474] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7028
[2019-04-27 21:19:31,477] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.8, 26.66666666666667, 1.0, 2.0, 0.5217034517222933, 1.0, 2.0, 0.5217034517222933, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156209, 1291430.614277616, 1291430.614277616, 246041.9742606044], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 405600.0000, 
sim time next is 406200.0000, 
raw observation next is [30.8, 26.83333333333333, 1.0, 2.0, 0.9593092326395332, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.499471491798992, 6.9112, 121.9235894803821, 1507137.210316325, 1205895.688466054, 235602.0533857075], 
processed observation next is [1.0, 0.6956521739130435, 0.6962962962962963, 0.2683333333333333, 1.0, 1.0, 0.9515586102851585, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.058827149179899244, 0.0, 0.8094458425529597, 0.5382632893986875, 0.43067703159501924, 0.4530808718955913], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.00494557], dtype=float32), -0.958591]. 
=============================================
[2019-04-27 21:19:34,714] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.0486981e-31 1.0000000e+00 8.9874028e-37 1.3061392e-28 5.0715556e-34], sum to 1.0000
[2019-04-27 21:19:34,723] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3059
[2019-04-27 21:19:34,728] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.85, 31.5, 1.0, 2.0, 0.3387899122941495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 430147.4844558146, 430147.4844558142, 120491.3588618313], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 414600.0000, 
sim time next is 415200.0000, 
raw observation next is [28.7, 32.0, 1.0, 2.0, 0.3373072181628252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 428288.7450780172, 428288.7450780172, 120298.317217463], 
processed observation next is [1.0, 0.8260869565217391, 0.6185185185185185, 0.32, 1.0, 1.0, 0.211080021622411, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15296026609929184, 0.15296026609929184, 0.23134291772589038], 
reward next is 0.7687, 
noisyNet noise sample is [array([0.9978177], dtype=float32), -1.1632737]. 
=============================================
[2019-04-27 21:19:40,528] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.7917761e-32 1.0000000e+00 8.9073782e-34 2.2724499e-29 3.3505925e-37], sum to 1.0000
[2019-04-27 21:19:40,541] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0806
[2019-04-27 21:19:40,548] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.53333333333333, 25.33333333333334, 1.0, 2.0, 0.3660306133327216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 462091.6017912859, 462091.6017912854, 124085.5627159272], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 496200.0000, 
sim time next is 496800.0000, 
raw observation next is [31.3, 26.0, 1.0, 2.0, 0.365863280074443, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 461875.3182351285, 461875.3182351285, 124062.8732475667], 
processed observation next is [1.0, 0.782608695652174, 0.7148148148148148, 0.26, 1.0, 1.0, 0.24507533342195598, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16495547079826017, 0.16495547079826017, 0.2385824485530129], 
reward next is 0.7614, 
noisyNet noise sample is [array([1.1888373], dtype=float32), 1.1242046]. 
=============================================
[2019-04-27 21:19:41,882] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-04-27 21:19:41,884] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 21:19:41,886] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 21:19:41,887] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:19:41,890] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:19:41,892] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 21:19:41,889] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 21:19:41,894] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 21:19:41,895] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:19:41,895] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:19:41,894] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:19:41,919] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run78
[2019-04-27 21:19:41,941] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run78
[2019-04-27 21:19:41,943] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run78
[2019-04-27 21:19:41,987] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run78
[2019-04-27 21:19:42,012] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run78
[2019-04-27 21:19:44,643] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.13390377]
[2019-04-27 21:19:44,647] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [19.25, 54.5, 1.0, 2.0, 0.220401762829058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 284292.2354053279, 284292.2354053279, 85337.79090063254]
[2019-04-27 21:19:44,649] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 21:19:44,653] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.0150581e-29 1.0000000e+00 8.8050827e-34 1.4511357e-27 1.6987008e-33], sampled 0.9617592333794618
[2019-04-27 21:19:50,610] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.13390377]
[2019-04-27 21:19:50,613] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [15.7, 87.0, 1.0, 2.0, 0.2142735704723537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 276386.16705029, 276386.1670502905, 87877.65525871616]
[2019-04-27 21:19:50,614] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 21:19:50,616] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.72479696e-29 1.00000000e+00 4.23724939e-34 8.46146151e-28
 1.33505595e-33], sampled 0.8735015659411188
[2019-04-27 21:20:30,226] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.13390377]
[2019-04-27 21:20:30,227] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.10018297, 77.84876600666666, 1.0, 2.0, 0.4863473467662137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 583781.2881671091, 583781.2881671096, 140899.1786242604]
[2019-04-27 21:20:30,227] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 21:20:30,228] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.7618588e-29 1.0000000e+00 8.2242884e-34 1.3012114e-27 1.8068233e-33], sampled 0.27248552567036577
[2019-04-27 21:20:31,075] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.13390377]
[2019-04-27 21:20:31,076] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.0, 83.0, 1.0, 2.0, 0.5832277030678458, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9319674359523574, 6.9112, 6.9112, 121.9260426156618, 1364336.617842593, 1364336.617842593, 286748.4103343321]
[2019-04-27 21:20:31,076] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 21:20:31,079] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.3737686e-23 1.0000000e+00 6.4726261e-27 3.8633111e-22 9.3926448e-27], sampled 0.33822068652576187
[2019-04-27 21:20:31,081] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1364336.617842593 W.
[2019-04-27 21:20:54,947] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.13390377]
[2019-04-27 21:20:54,948] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.5, 60.5, 1.0, 2.0, 0.8570180098499319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 976872.1422268854, 976872.1422268854, 208002.6766620023]
[2019-04-27 21:20:54,950] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 21:20:54,953] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.0282600e-26 1.0000000e+00 1.5132865e-30 5.8190093e-25 3.1885580e-30], sampled 0.2853670757853818
[2019-04-27 21:21:29,487] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8922.6628 2120599135.7723 430.0000
[2019-04-27 21:21:29,487] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8770.2626 2170712315.3188 493.0000
[2019-04-27 21:21:29,555] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8582.8795 2248773970.1662 553.0000
[2019-04-27 21:21:29,631] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8700.1130 2195220806.1349 572.0000
[2019-04-27 21:21:29,719] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8099.2132 2445444095.4335 746.0000
[2019-04-27 21:21:30,737] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1925000, evaluation results [1925000.0, 8099.213190057684, 2445444095.433475, 746.0, 8770.262620159681, 2170712315.3187604, 493.0, 8922.662781171732, 2120599135.7722971, 430.0, 8582.879467926026, 2248773970.1662407, 553.0, 8700.112961499688, 2195220806.134913, 572.0]
[2019-04-27 21:21:31,583] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.8449254e-21 1.0000000e+00 4.5719204e-27 2.0414844e-21 5.6813015e-27], sum to 1.0000
[2019-04-27 21:21:31,592] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6613
[2019-04-27 21:21:31,597] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.3, 78.0, 1.0, 2.0, 0.3032750116959846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 387705.05735794, 387705.05735794, 115982.4278117022], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 536400.0000, 
sim time next is 537000.0000, 
raw observation next is [19.5, 77.0, 1.0, 2.0, 0.2951550912612306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 377177.9315004048, 377177.9315004048, 114980.12256691], 
processed observation next is [1.0, 0.21739130434782608, 0.2777777777777778, 0.77, 1.0, 1.0, 0.16089891816813165, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13470640410728743, 0.13470640410728743, 0.22111562032098075], 
reward next is 0.7789, 
noisyNet noise sample is [array([0.8693407], dtype=float32), 0.04222078]. 
=============================================
[2019-04-27 21:21:31,613] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[60.785404]
 [60.94318 ]
 [61.02965 ]
 [61.14302 ]
 [61.225   ]], R is [[60.9380722 ]
 [61.10565186]
 [61.27112961]
 [61.43414307]
 [61.59399414]].
[2019-04-27 21:21:36,035] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.08591025e-26 1.00000000e+00 1.11648800e-29 6.13008279e-25
 2.31865171e-27], sum to 1.0000
[2019-04-27 21:21:36,044] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5941
[2019-04-27 21:21:36,049] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.95, 62.5, 1.0, 2.0, 0.3834577661018769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 488085.1728230429, 488085.1728230434, 126503.8905451277], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 617400.0000, 
sim time next is 618000.0000, 
raw observation next is [21.76666666666667, 63.33333333333333, 1.0, 2.0, 0.3762194495029246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 479118.1205071408, 479118.1205071408, 125507.7593300479], 
processed observation next is [1.0, 0.13043478260869565, 0.3617283950617285, 0.6333333333333333, 1.0, 1.0, 0.2574041065511007, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.171113614466836, 0.171113614466836, 0.24136107563470752], 
reward next is 0.7586, 
noisyNet noise sample is [array([-0.22606026], dtype=float32), 1.5319556]. 
=============================================
[2019-04-27 21:21:36,062] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[62.89498 ]
 [62.9301  ]
 [62.98166 ]
 [63.054077]
 [63.128223]], R is [[62.87668228]
 [63.00463867]
 [63.12810516]
 [63.24036407]
 [63.36737442]].
[2019-04-27 21:21:37,049] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1983119e-34 1.0000000e+00 0.0000000e+00 8.9544411e-31 5.3696129e-37], sum to 1.0000
[2019-04-27 21:21:37,054] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3191
[2019-04-27 21:21:37,062] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.7, 39.0, 1.0, 2.0, 0.3157005385648864, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 401489.0730841113, 401489.0730841113, 117531.3769310648], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 774000.0000, 
sim time next is 774600.0000, 
raw observation next is [26.53333333333333, 39.5, 1.0, 2.0, 0.3137228885461306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 399090.184398965, 399090.184398965, 117282.517355739], 
processed observation next is [1.0, 1.0, 0.5382716049382715, 0.395, 1.0, 1.0, 0.1830034387453936, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14253220871391606, 0.14253220871391606, 0.22554330260719038], 
reward next is 0.7745, 
noisyNet noise sample is [array([0.08087458], dtype=float32), 1.5102762]. 
=============================================
[2019-04-27 21:21:37,138] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9733879e-31 1.0000000e+00 6.3734815e-38 1.2038543e-29 3.3563381e-36], sum to 1.0000
[2019-04-27 21:21:37,146] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9387
[2019-04-27 21:21:37,156] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1619107.352557716 W.
[2019-04-27 21:21:37,161] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [35.6, 17.5, 1.0, 2.0, 0.6637195147193957, 1.0, 2.0, 0.6637195147193957, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1619107.352557716, 1619107.352557717, 295092.9312648317], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 664200.0000, 
sim time next is 664800.0000, 
raw observation next is [35.6, 17.33333333333333, 1.0, 2.0, 0.4460780935690667, 1.0, 2.0, 0.4460780935690667, 1.0, 1.0, 0.7237163385940089, 6.9112, 6.9112, 121.94756008, 1619079.976370977, 1619079.976370977, 317193.2788537001], 
processed observation next is [1.0, 0.6956521739130435, 0.8740740740740741, 0.17333333333333328, 1.0, 1.0, 0.34056915901079365, 1.0, 1.0, 0.34056915901079365, 1.0, 0.5, 0.6546454232425111, 0.0, 0.0, 0.8096049824067558, 0.5782428487039204, 0.5782428487039204, 0.609987074718654], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3690363], dtype=float32), -0.21889108]. 
=============================================
[2019-04-27 21:21:48,964] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.3292283e-34 1.0000000e+00 1.7049036e-37 5.1253952e-32 1.0922189e-37], sum to 1.0000
[2019-04-27 21:21:48,972] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4811
[2019-04-27 21:21:48,978] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.1, 67.0, 1.0, 2.0, 0.3537101096269152, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 446337.0008756739, 446337.0008756739, 122430.4056881893], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 874800.0000, 
sim time next is 875400.0000, 
raw observation next is [22.01666666666667, 66.83333333333334, 1.0, 2.0, 0.3505947980111833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 442942.2229061592, 442942.2229061592, 122023.090321856], 
processed observation next is [0.0, 0.13043478260869565, 0.37098765432098774, 0.6683333333333334, 1.0, 1.0, 0.22689856906093253, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.158193651037914, 0.158193651037914, 0.23465978908049231], 
reward next is 0.7653, 
noisyNet noise sample is [array([-0.9530753], dtype=float32), -0.437685]. 
=============================================
[2019-04-27 21:21:53,387] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.52168922e-33 1.00000000e+00 0.00000000e+00 1.21305555e-29
 1.82129642e-37], sum to 1.0000
[2019-04-27 21:21:53,396] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6219
[2019-04-27 21:21:53,404] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.38333333333333, 43.66666666666667, 1.0, 2.0, 0.4052291522845289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 500877.8844684478, 500877.8844684478, 129330.2385331374], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 922200.0000, 
sim time next is 922800.0000, 
raw observation next is [28.36666666666667, 43.33333333333334, 1.0, 2.0, 0.4018693865085279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 497276.6360656028, 497276.6360656028, 128867.8858197386], 
processed observation next is [0.0, 0.6956521739130435, 0.606172839506173, 0.4333333333333334, 1.0, 1.0, 0.2879397458434856, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17759879859485816, 0.17759879859485816, 0.24782285734565115], 
reward next is 0.7522, 
noisyNet noise sample is [array([-1.5956993], dtype=float32), 0.4258853]. 
=============================================
[2019-04-27 21:21:56,174] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3262356e-23 1.0000000e+00 4.3869172e-29 9.8622949e-23 5.4146461e-27], sum to 1.0000
[2019-04-27 21:21:56,185] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9244
[2019-04-27 21:21:56,191] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.9, 86.0, 1.0, 2.0, 0.3587415359463513, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 450686.5870899601, 450686.5870899605, 123074.9545565197], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1299600.0000, 
sim time next is 1300200.0000, 
raw observation next is [19.83333333333333, 86.0, 1.0, 2.0, 0.3549354648611217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 446289.704179424, 446289.7041794244, 122572.4503673396], 
processed observation next is [1.0, 0.043478260869565216, 0.2901234567901233, 0.86, 1.0, 1.0, 0.23206602959657346, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15938918006407998, 0.15938918006408015, 0.2357162507064223], 
reward next is 0.7643, 
noisyNet noise sample is [array([0.61226165], dtype=float32), -1.2610489]. 
=============================================
[2019-04-27 21:21:59,656] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.1048137e-38 1.0000000e+00 0.0000000e+00 3.1228711e-36 0.0000000e+00], sum to 1.0000
[2019-04-27 21:21:59,664] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1908
[2019-04-27 21:21:59,671] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.5, 34.0, 1.0, 2.0, 0.3527790514025393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 442883.4246774931, 442883.4246774931, 122275.3524351165], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1360800.0000, 
sim time next is 1361400.0000, 
raw observation next is [29.25, 35.0, 1.0, 2.0, 0.3507292272579973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 440170.6259941361, 440170.6259941361, 122001.3752756299], 
processed observation next is [1.0, 0.782608695652174, 0.6388888888888888, 0.35, 1.0, 1.0, 0.22705860387856824, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15720379499790574, 0.15720379499790574, 0.23461802937621137], 
reward next is 0.7654, 
noisyNet noise sample is [array([-0.6370977], dtype=float32), 0.35246164]. 
=============================================
[2019-04-27 21:22:05,147] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.9133743e-38 1.0000000e+00 0.0000000e+00 1.5444914e-33 2.0233326e-38], sum to 1.0000
[2019-04-27 21:22:05,156] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4414
[2019-04-27 21:22:05,161] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 71.0, 1.0, 2.0, 0.4135043326408532, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 509359.9782602221, 509359.9782602221, 130466.7682512844], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1284000.0000, 
sim time next is 1284600.0000, 
raw observation next is [23.3, 72.0, 1.0, 2.0, 0.4118373762853879, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 507627.6089707423, 507627.6089707423, 130236.4732028431], 
processed observation next is [1.0, 0.8695652173913043, 0.41851851851851857, 0.72, 1.0, 1.0, 0.29980640033974754, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18129557463240797, 0.18129557463240797, 0.2504547561593137], 
reward next is 0.7495, 
noisyNet noise sample is [array([0.7239363], dtype=float32), -0.9786182]. 
=============================================
[2019-04-27 21:22:07,147] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.8705151e-35 1.0000000e+00 0.0000000e+00 1.4261358e-31 8.0166478e-37], sum to 1.0000
[2019-04-27 21:22:07,154] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0056
[2019-04-27 21:22:07,157] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.13333333333333, 74.5, 1.0, 2.0, 0.41150106775716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 518369.6714902932, 518369.6714902932, 130404.9824148515], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1185000.0000, 
sim time next is 1185600.0000, 
raw observation next is [21.06666666666667, 75.0, 1.0, 2.0, 0.349302033376883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 440232.0371912596, 440232.0371912596, 121839.0077206635], 
processed observation next is [1.0, 0.7391304347826086, 0.3358024691358026, 0.75, 1.0, 1.0, 0.22535956354390832, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.157225727568307, 0.157225727568307, 0.23430578407819905], 
reward next is 0.7657, 
noisyNet noise sample is [array([0.4755026], dtype=float32), 0.9096977]. 
=============================================
[2019-04-27 21:22:08,406] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.1838675e-34 1.0000000e+00 0.0000000e+00 4.0727200e-32 7.3952691e-35], sum to 1.0000
[2019-04-27 21:22:08,414] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7285
[2019-04-27 21:22:08,421] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.93333333333333, 83.66666666666667, 1.0, 2.0, 0.3451484799911345, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 435069.7337082005, 435069.7337082, 121292.3125538586], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1195800.0000, 
sim time next is 1196400.0000, 
raw observation next is [19.86666666666667, 84.33333333333334, 1.0, 2.0, 0.3453382961650551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 435226.7341702257, 435226.7341702253, 121316.216029151], 
processed observation next is [1.0, 0.8695652173913043, 0.2913580246913582, 0.8433333333333334, 1.0, 1.0, 0.22064082876792276, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15543811934650917, 0.15543811934650903, 0.23330041544067498], 
reward next is 0.7667, 
noisyNet noise sample is [array([-1.2566599], dtype=float32), 0.6715697]. 
=============================================
[2019-04-27 21:22:08,672] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.9465042e-36 1.0000000e+00 0.0000000e+00 9.7966265e-33 9.2423934e-37], sum to 1.0000
[2019-04-27 21:22:08,684] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3774
[2019-04-27 21:22:08,691] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.28333333333333, 89.16666666666667, 1.0, 2.0, 0.4269257928282174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 523701.4883292301, 523701.4883292305, 132346.6982939932], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1879800.0000, 
sim time next is 1880400.0000, 
raw observation next is [21.26666666666667, 89.33333333333334, 1.0, 2.0, 0.4288329418315248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 526006.1069870442, 526006.1069870439, 132623.3051702876], 
processed observation next is [1.0, 0.782608695652174, 0.34320987654320995, 0.8933333333333334, 1.0, 1.0, 0.320039216466101, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18785932392394436, 0.18785932392394425, 0.2550448176351685], 
reward next is 0.7450, 
noisyNet noise sample is [array([1.4901005], dtype=float32), 1.4702872]. 
=============================================
[2019-04-27 21:22:10,905] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3068825e-27 1.0000000e+00 6.7388499e-32 1.7124218e-26 1.2160897e-30], sum to 1.0000
[2019-04-27 21:22:10,911] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7754
[2019-04-27 21:22:10,915] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.7, 84.5, 1.0, 2.0, 0.5515930404577732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 696050.2756260941, 696050.2756260941, 152246.0421906747], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1240200.0000, 
sim time next is 1240800.0000, 
raw observation next is [19.9, 83.33333333333334, 1.0, 2.0, 0.5622896941642285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 709004.7268373884, 709004.7268373884, 154049.5999588493], 
processed observation next is [1.0, 0.34782608695652173, 0.2925925925925925, 0.8333333333333335, 1.0, 1.0, 0.47891630257646245, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2532159738704958, 0.2532159738704958, 0.29624923069009484], 
reward next is 0.7038, 
noisyNet noise sample is [array([0.92079306], dtype=float32), 0.7006954]. 
=============================================
[2019-04-27 21:22:11,398] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.9502673e-27 1.0000000e+00 2.9689549e-32 5.4161569e-26 5.7937660e-30], sum to 1.0000
[2019-04-27 21:22:11,405] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0398
[2019-04-27 21:22:11,413] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.45, 90.16666666666666, 1.0, 2.0, 0.4077251963786606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 505378.1535866513, 505378.1535866513, 129717.1473385541], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1929000.0000, 
sim time next is 1929600.0000, 
raw observation next is [20.5, 90.0, 1.0, 2.0, 0.4210835306724902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 521710.3443778895, 521710.3443778899, 131628.4008476031], 
processed observation next is [1.0, 0.34782608695652173, 0.3148148148148148, 0.9, 1.0, 1.0, 0.3108137269910598, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18632512299210338, 0.18632512299210352, 0.2531315400915444], 
reward next is 0.7469, 
noisyNet noise sample is [array([-1.4550588], dtype=float32), -0.25859925]. 
=============================================
[2019-04-27 21:22:17,139] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.18928716e-32 1.00000000e+00 0.00000000e+00 3.73000485e-31
 5.86636368e-35], sum to 1.0000
[2019-04-27 21:22:17,146] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3481
[2019-04-27 21:22:17,150] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.25, 44.0, 1.0, 2.0, 0.3564463740662208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 446159.4689171151, 446159.4689171151, 122741.8513041417], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1366200.0000, 
sim time next is 1366800.0000, 
raw observation next is [27.0, 45.33333333333334, 1.0, 2.0, 0.3580305171177845, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 447883.6856708577, 447883.6856708577, 122948.8681141288], 
processed observation next is [1.0, 0.8260869565217391, 0.5555555555555556, 0.4533333333333334, 1.0, 1.0, 0.23575061561641011, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15995845916816348, 0.15995845916816348, 0.23644013098870922], 
reward next is 0.7636, 
noisyNet noise sample is [array([0.7713474], dtype=float32), 0.7148941]. 
=============================================
[2019-04-27 21:22:23,285] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-04-27 21:22:23,287] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 21:22:23,287] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 21:22:23,288] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:22:23,288] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:22:23,290] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 21:22:23,291] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 21:22:23,293] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:22:23,293] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:22:23,288] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 21:22:23,295] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:22:23,321] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run79
[2019-04-27 21:22:23,321] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run79
[2019-04-27 21:22:23,373] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run79
[2019-04-27 21:22:23,375] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run79
[2019-04-27 21:22:23,391] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run79
[2019-04-27 21:22:52,426] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.1361304]
[2019-04-27 21:22:52,427] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.60398181, 67.18214262333333, 1.0, 2.0, 0.7081737185775995, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 807122.6093288687, 807122.6093288687, 177696.4679683929]
[2019-04-27 21:22:52,429] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 21:22:52,430] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.3991317e-30 1.0000000e+00 1.0041953e-34 2.0518689e-28 5.2018945e-34], sampled 0.5617649503208685
[2019-04-27 21:22:53,812] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.1361304]
[2019-04-27 21:22:53,813] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.41666666666666, 68.83333333333333, 1.0, 2.0, 0.3918064849423689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 485107.6140195152, 485107.6140195152, 127462.6519696737]
[2019-04-27 21:22:53,815] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 21:22:53,816] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.6955885e-31 1.0000000e+00 6.0041258e-36 1.9649767e-29 3.2657710e-35], sampled 0.9413344910359269
[2019-04-27 21:23:12,745] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.1361304]
[2019-04-27 21:23:12,746] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.1, 97.5, 1.0, 2.0, 0.6602191667759134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 769624.3317524886, 769624.3317524882, 169575.9236896199]
[2019-04-27 21:23:12,748] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 21:23:12,750] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.8475883e-28 1.0000000e+00 7.7701352e-33 7.3064651e-27 3.5971805e-32], sampled 0.7680470548269108
[2019-04-27 21:23:30,707] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.1361304]
[2019-04-27 21:23:30,709] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.11925220333334, 88.06184642666668, 1.0, 2.0, 0.4190048222703976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 517506.526266354, 517506.526266354, 131290.8506841357]
[2019-04-27 21:23:30,710] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 21:23:30,712] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.5531803e-30 1.0000000e+00 5.2646764e-35 1.0712823e-28 2.6151381e-34], sampled 0.039130956662427274
[2019-04-27 21:23:32,206] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.1361304]
[2019-04-27 21:23:32,208] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.66666666666667, 61.33333333333334, 1.0, 2.0, 0.516875979753546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 612777.458854131, 612777.458854131, 145430.9459966501]
[2019-04-27 21:23:32,208] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 21:23:32,210] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.7293470e-31 1.0000000e+00 1.3848626e-35 3.7298950e-29 7.0184400e-35], sampled 0.07269635412670017
[2019-04-27 21:23:32,358] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.1361304]
[2019-04-27 21:23:32,359] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [32.45886337, 70.863463545, 1.0, 2.0, 0.9621147126176223, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911257219426045, 6.9112, 121.9258873079807, 1096781.695624026, 1096752.394201, 231727.4153114927]
[2019-04-27 21:23:32,361] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 21:23:32,365] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.4810652e-28 1.0000000e+00 1.4922466e-32 9.9930034e-27 6.2969410e-32], sampled 0.7081533127726787
[2019-04-27 21:23:52,349] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.1361304]
[2019-04-27 21:23:52,350] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.977210965, 36.64887114666666, 1.0, 2.0, 0.4379752101367423, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 538663.4685569501, 538663.4685569501, 134001.6742875172]
[2019-04-27 21:23:52,352] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 21:23:52,355] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.4400336e-29 1.0000000e+00 4.0688649e-34 5.8555858e-28 1.9710838e-33], sampled 0.21135511403895368
[2019-04-27 21:24:05,370] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.1361304]
[2019-04-27 21:24:05,371] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.545552415, 92.77334272499999, 1.0, 2.0, 0.5409487284196179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 633058.6893040059, 633058.6893040059, 148990.3880831481]
[2019-04-27 21:24:05,373] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 21:24:05,378] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.8377807e-30 1.0000000e+00 3.7341260e-35 9.1751953e-29 1.7278547e-34], sampled 0.27829089179971
[2019-04-27 21:24:05,746] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.1361304]
[2019-04-27 21:24:05,747] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.41666666666666, 62.0, 1.0, 2.0, 0.513592250810987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 609676.6512104865, 609676.6512104865, 144937.6289073688]
[2019-04-27 21:24:05,747] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 21:24:05,749] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.2659330e-31 1.0000000e+00 1.6861614e-35 4.4983913e-29 8.3774446e-35], sampled 0.6523940360684753
[2019-04-27 21:24:09,873] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.1361304]
[2019-04-27 21:24:09,874] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.60158077, 81.43822036166668, 1.0, 2.0, 0.3588532632459062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 451108.9236083261, 451108.9236083261, 123094.6683981116]
[2019-04-27 21:24:09,875] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 21:24:09,879] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.7559462e-29 1.0000000e+00 5.5698440e-34 7.1934321e-28 2.2605311e-33], sampled 0.5099870296854708
[2019-04-27 21:24:10,692] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8770.2626 2170712315.3188 493.0000
[2019-04-27 21:24:10,921] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8099.9706 2445378853.1784 746.0000
[2019-04-27 21:24:10,978] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8922.6628 2120599135.7723 430.0000
[2019-04-27 21:24:11,066] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8582.8795 2248773970.1662 553.0000
[2019-04-27 21:24:11,089] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8700.8700 2195155380.8105 572.0000
[2019-04-27 21:24:12,105] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1950000, evaluation results [1950000.0, 8099.970618414005, 2445378853.1783895, 746.0, 8770.262620159681, 2170712315.3187604, 493.0, 8922.662781171732, 2120599135.7722971, 430.0, 8582.879467926026, 2248773970.1662407, 553.0, 8700.870031992405, 2195155380.8105125, 572.0]
[2019-04-27 21:24:21,204] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.1242415e-33 1.0000000e+00 8.2009631e-38 6.9153919e-31 5.4305640e-38], sum to 1.0000
[2019-04-27 21:24:21,219] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5206
[2019-04-27 21:24:21,225] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 43.5, 1.0, 2.0, 0.3524059308933227, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 441047.7223191443, 441047.7223191443, 122203.4004659572], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1619400.0000, 
sim time next is 1620000.0000, 
raw observation next is [27.2, 44.0, 1.0, 2.0, 0.3571359872148855, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 447043.3988951675, 447043.3988951675, 122834.168477731], 
processed observation next is [1.0, 0.782608695652174, 0.5629629629629629, 0.44, 1.0, 1.0, 0.23468569906533987, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1596583567482741, 0.1596583567482741, 0.2362195547648673], 
reward next is 0.7638, 
noisyNet noise sample is [array([-0.8434732], dtype=float32), 0.6114288]. 
=============================================
[2019-04-27 21:24:21,236] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[81.371   ]
 [80.92962 ]
 [80.26445 ]
 [79.480515]
 [77.32472 ]], R is [[82.34259796]
 [82.28416443]
 [82.2271347 ]
 [82.17137909]
 [82.11508179]].
[2019-04-27 21:24:21,894] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.4173319e-35 1.0000000e+00 3.2013071e-37 6.8712676e-31 6.1153046e-38], sum to 1.0000
[2019-04-27 21:24:21,901] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3146
[2019-04-27 21:24:21,909] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 69.33333333333334, 1.0, 2.0, 0.4034076294891313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156387, 496550.1579494172, 496550.1579494172, 129021.4734255258], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1704000.0000, 
sim time next is 1704600.0000, 
raw observation next is [23.75, 70.0, 1.0, 2.0, 0.4007846839266082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 493183.4229695576, 493183.4229695576, 128648.0167234432], 
processed observation next is [1.0, 0.7391304347826086, 0.4351851851851852, 0.7, 1.0, 1.0, 0.2866484332459622, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.176136936774842, 0.176136936774842, 0.2474000321604677], 
reward next is 0.7526, 
noisyNet noise sample is [array([-0.57196134], dtype=float32), 0.49471626]. 
=============================================
[2019-04-27 21:24:31,326] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.8089273e-25 1.0000000e+00 1.2458976e-30 1.1373960e-24 8.0681148e-25], sum to 1.0000
[2019-04-27 21:24:31,333] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3610
[2019-04-27 21:24:31,342] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.76666666666667, 90.16666666666666, 1.0, 2.0, 0.3489305182739926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 441745.5725488587, 441745.5725488587, 121812.4206625457], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1831800.0000, 
sim time next is 1832400.0000, 
raw observation next is [18.8, 90.0, 1.0, 2.0, 0.3431689288252568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 434387.7372822425, 434387.7372822425, 121052.9307842072], 
processed observation next is [1.0, 0.21739130434782608, 0.2518518518518519, 0.9, 1.0, 1.0, 0.2180582486014962, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1551384776008009, 0.1551384776008009, 0.23279409766193693], 
reward next is 0.7672, 
noisyNet noise sample is [array([0.51327175], dtype=float32), 1.0910712]. 
=============================================
[2019-04-27 21:24:32,621] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.8076117e-23 1.0000000e+00 2.7422483e-29 2.4093227e-21 1.5821932e-24], sum to 1.0000
[2019-04-27 21:24:32,626] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2685
[2019-04-27 21:24:32,632] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 77.66666666666667, 1.0, 2.0, 0.347906797347068, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 436640.6138340661, 436640.6138340661, 121628.5640244995], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1842000.0000, 
sim time next is 1842600.0000, 
raw observation next is [21.25, 76.83333333333333, 1.0, 2.0, 0.3496408414912117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 438628.0898494672, 438628.0898494672, 121854.5935392862], 
processed observation next is [1.0, 0.30434782608695654, 0.3425925925925926, 0.7683333333333333, 1.0, 1.0, 0.2257629065371568, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15665288923195259, 0.15665288923195259, 0.23433575680631963], 
reward next is 0.7657, 
noisyNet noise sample is [array([-0.3671365], dtype=float32), -0.21437189]. 
=============================================
[2019-04-27 21:24:37,819] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.8215780e-33 1.0000000e+00 0.0000000e+00 1.0920353e-30 0.0000000e+00], sum to 1.0000
[2019-04-27 21:24:37,828] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7651
[2019-04-27 21:24:37,833] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.35, 65.33333333333334, 1.0, 2.0, 0.500466627995941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 598922.0960266674, 598922.0960266674, 143041.6198984788], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2585400.0000, 
sim time next is 2586000.0000, 
raw observation next is [26.1, 66.66666666666667, 1.0, 2.0, 0.4986244417339429, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 596896.7386084081, 596896.7386084077, 142758.457562499], 
processed observation next is [1.0, 0.9565217391304348, 0.5222222222222223, 0.6666666666666667, 1.0, 1.0, 0.4031243353975511, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21317740664586005, 0.21317740664585988, 0.2745354953124981], 
reward next is 0.7255, 
noisyNet noise sample is [array([0.12111865], dtype=float32), -0.6008396]. 
=============================================
[2019-04-27 21:24:37,845] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[90.16481 ]
 [89.99768 ]
 [89.65623 ]
 [89.60579 ]
 [89.496086]], R is [[90.10002899]
 [89.9239502 ]
 [89.74938202]
 [89.57675171]
 [89.40612793]].
[2019-04-27 21:24:39,543] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.9103416e-29 1.0000000e+00 4.3926162e-34 9.7779788e-29 1.7709766e-34], sum to 1.0000
[2019-04-27 21:24:39,552] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3707
[2019-04-27 21:24:39,559] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.4, 85.0, 1.0, 2.0, 0.4887164205530263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 584527.3868111529, 584527.3868111534, 141193.0129309034], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2104200.0000, 
sim time next is 2104800.0000, 
raw observation next is [23.63333333333333, 84.0, 1.0, 2.0, 0.4929168746950036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 588539.8682689908, 588539.8682689908, 141810.0191099272], 
processed observation next is [0.0, 0.34782608695652173, 0.430864197530864, 0.84, 1.0, 1.0, 0.39632961273214723, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21019281009606813, 0.21019281009606813, 0.2727115752113985], 
reward next is 0.7273, 
noisyNet noise sample is [array([-1.1534214], dtype=float32), 0.23400393]. 
=============================================
[2019-04-27 21:24:39,596] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.0697655e-24 1.0000000e+00 2.9571605e-28 2.1333520e-22 7.4972517e-25], sum to 1.0000
[2019-04-27 21:24:39,604] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4240
[2019-04-27 21:24:39,609] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.7, 69.0, 1.0, 2.0, 0.8483733173722828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1015422.591663984, 1015422.591663984, 208453.738024591], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1947600.0000, 
sim time next is 1948200.0000, 
raw observation next is [25.95, 67.83333333333333, 1.0, 2.0, 0.7736634322499615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 925102.7868051113, 925102.7868051113, 192574.6615701467], 
processed observation next is [1.0, 0.5652173913043478, 0.5166666666666666, 0.6783333333333332, 1.0, 1.0, 0.730551705059478, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.33039385243039693, 0.33039385243039693, 0.3703358876348975], 
reward next is 0.6297, 
noisyNet noise sample is [array([-0.8747421], dtype=float32), 0.5186268]. 
=============================================
[2019-04-27 21:24:45,322] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.1947407e-23 1.0000000e+00 1.3975580e-26 1.0958253e-21 1.4575831e-26], sum to 1.0000
[2019-04-27 21:24:45,330] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5218
[2019-04-27 21:24:45,337] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 39.5, 1.0, 2.0, 0.4904262652438431, 1.0, 1.0, 0.4904262652438431, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9258719170604, 1198471.435338744, 1198471.435338744, 235641.9743276624], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2370600.0000, 
sim time next is 2371200.0000, 
raw observation next is [29.1, 39.33333333333334, 1.0, 2.0, 0.9163516104471984, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.10104841869863, 6.9112, 121.925199289302, 1229186.53900796, 1131967.852612685, 224960.4835999878], 
processed observation next is [1.0, 0.43478260869565216, 0.6333333333333334, 0.3933333333333334, 1.0, 1.0, 0.9004185838657124, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.018984841869863, 0.0, 0.8094565300101044, 0.4389951925028428, 0.4042742330759589, 0.43261631461536115], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8189364], dtype=float32), -0.05440382]. 
=============================================
[2019-04-27 21:24:49,396] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.0134850e-32 1.0000000e+00 3.2364034e-35 1.0687469e-29 1.2655634e-34], sum to 1.0000
[2019-04-27 21:24:49,403] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2247
[2019-04-27 21:24:49,408] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.63333333333333, 47.33333333333334, 1.0, 2.0, 0.5512038632588466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 643140.5893814862, 643140.5893814862, 150591.186503043], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2136000.0000, 
sim time next is 2136600.0000, 
raw observation next is [31.45, 48.5, 1.0, 2.0, 0.5547390877337749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 646125.8831583613, 646125.8831583618, 151125.2977980903], 
processed observation next is [0.0, 0.7391304347826086, 0.7203703703703703, 0.485, 1.0, 1.0, 0.469927485397351, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23075924398512904, 0.2307592439851292, 0.2906255726886352], 
reward next is 0.7094, 
noisyNet noise sample is [array([1.7676835], dtype=float32), 1.3608457]. 
=============================================
[2019-04-27 21:24:59,154] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.2637285e-35 1.0000000e+00 1.8699923e-38 1.6832399e-32 9.3201740e-38], sum to 1.0000
[2019-04-27 21:24:59,162] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9758
[2019-04-27 21:24:59,166] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.03333333333333, 89.16666666666666, 1.0, 2.0, 0.4617359917306657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 559722.6546571284, 559722.6546571284, 137319.2513683642], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2328600.0000, 
sim time next is 2329200.0000, 
raw observation next is [21.9, 90.0, 1.0, 2.0, 0.4624445150913689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 560829.967364177, 560829.9673641765, 137434.1147027519], 
processed observation next is [1.0, 1.0, 0.36666666666666664, 0.9, 1.0, 1.0, 0.3600529941563916, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2002964169157775, 0.20029641691577732, 0.264296374428369], 
reward next is 0.7357, 
noisyNet noise sample is [array([-0.26944125], dtype=float32), 0.4262553]. 
=============================================
[2019-04-27 21:25:04,597] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-04-27 21:25:04,598] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 21:25:04,598] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 21:25:04,599] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:25:04,600] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 21:25:04,599] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 21:25:04,599] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 21:25:04,601] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:25:04,603] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:25:04,605] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:25:04,603] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:25:04,634] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run80
[2019-04-27 21:25:04,635] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run80
[2019-04-27 21:25:04,685] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run80
[2019-04-27 21:25:04,686] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run80
[2019-04-27 21:25:04,686] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run80
[2019-04-27 21:25:16,702] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.13678324]
[2019-04-27 21:25:16,703] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.95478852666667, 45.90040182333333, 1.0, 2.0, 0.4061069678977295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 491185.3121767322, 491185.3121767322, 129154.6685685511]
[2019-04-27 21:25:16,705] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 21:25:16,708] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.6321377e-32 1.0000000e+00 1.7121846e-36 8.4646171e-30 1.7496956e-35], sampled 0.7751567255331128
[2019-04-27 21:25:23,150] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.13678324]
[2019-04-27 21:25:23,151] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [38.16666666666666, 15.5, 1.0, 2.0, 0.7406162949822342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 916884.9156353105, 916884.9156353105, 186897.550544712]
[2019-04-27 21:25:23,153] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 21:25:23,155] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.3222255e-29 1.0000000e+00 9.2700550e-34 1.2109716e-27 7.5715171e-33], sampled 0.5617857836911037
[2019-04-27 21:25:29,253] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.13678324]
[2019-04-27 21:25:29,254] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.43333333333333, 79.00000000000001, 1.0, 2.0, 0.4203080166084996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 516875.9729995496, 516875.9729995501, 131422.4895205434]
[2019-04-27 21:25:29,258] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 21:25:29,259] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.8652496e-30 1.0000000e+00 2.8665412e-34 5.5256095e-28 2.9610021e-33], sampled 0.7145765943881357
[2019-04-27 21:25:32,963] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.13678324]
[2019-04-27 21:25:32,964] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [19.38333333333333, 92.16666666666667, 1.0, 2.0, 0.3616535648853542, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 453233.5909820479, 453233.5909820479, 123448.1097027919]
[2019-04-27 21:25:32,965] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 21:25:32,967] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.4182489e-29 1.0000000e+00 5.0092204e-34 1.0724890e-27 5.8023169e-33], sampled 0.29721020902505
[2019-04-27 21:25:38,761] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.13678324]
[2019-04-27 21:25:38,763] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.38335229333333, 37.822020775, 1.0, 2.0, 0.3961780371011209, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 488314.0536737014, 488314.0536737014, 128021.7915705752]
[2019-04-27 21:25:38,765] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 21:25:38,767] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.2137458e-28 1.0000000e+00 6.1364218e-33 7.3688006e-27 6.1876447e-32], sampled 0.15524639576706856
[2019-04-27 21:25:50,432] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.13678324]
[2019-04-27 21:25:50,433] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [33.0, 59.0, 1.0, 2.0, 0.7759634986828393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 884428.8293688641, 884428.8293688641, 191030.6348763409]
[2019-04-27 21:25:50,434] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 21:25:50,438] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.8013530e-29 1.0000000e+00 2.1778494e-33 2.7064493e-27 1.9806042e-32], sampled 0.3158567086078372
[2019-04-27 21:25:55,858] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.13678324]
[2019-04-27 21:25:55,859] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.0, 83.0, 1.0, 2.0, 0.5668557632170138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 660984.3747988653, 660984.3747988653, 153175.4378469046]
[2019-04-27 21:25:55,861] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 21:25:55,864] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.4662460e-29 1.0000000e+00 1.8839951e-33 2.8888468e-27 1.8557146e-32], sampled 0.5562889388129869
[2019-04-27 21:26:08,305] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.13678324]
[2019-04-27 21:26:08,308] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.5, 85.5, 1.0, 2.0, 0.4967459584898129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 611268.1712970537, 611268.1712970537, 142978.3639830533]
[2019-04-27 21:26:08,308] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 21:26:08,310] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.5370145e-28 1.0000000e+00 3.9532627e-32 3.3243212e-26 3.7396359e-31], sampled 0.4951786119122761
[2019-04-27 21:26:12,360] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.13678324]
[2019-04-27 21:26:12,362] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.96666666666667, 87.0, 1.0, 2.0, 0.4052720865019264, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 501339.9949923426, 501339.9949923426, 129345.9397529381]
[2019-04-27 21:26:12,364] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 21:26:12,367] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.1479674e-30 1.0000000e+00 3.1680721e-35 9.2946174e-29 3.4049333e-34], sampled 0.7747783902898043
[2019-04-27 21:26:25,292] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.13678324]
[2019-04-27 21:26:25,294] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.0, 60.5, 1.0, 2.0, 0.9727240695303847, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000002, 6.9112, 121.9260425083473, 1824103.805777299, 1824103.805777298, 373127.9329432664]
[2019-04-27 21:26:25,295] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 21:26:25,299] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.0686374e-25 1.0000000e+00 5.6131361e-29 1.2142584e-23 5.0711647e-28], sampled 0.44160653199795985
[2019-04-27 21:26:25,299] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1824103.805777299 W.
[2019-04-27 21:26:45,646] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.13678324]
[2019-04-27 21:26:45,648] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [19.86666666666667, 92.66666666666667, 1.0, 2.0, 0.3797144451492913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 472454.093893419, 472454.093893419, 125840.2092169544]
[2019-04-27 21:26:45,650] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 21:26:45,652] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.5769529e-29 1.0000000e+00 6.0451781e-34 1.1606196e-27 7.2785133e-33], sampled 0.10177634264200752
[2019-04-27 21:26:50,882] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.13678324]
[2019-04-27 21:26:50,883] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.70970132333333, 78.37532947833334, 1.0, 2.0, 0.3512319104444789, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 441810.5492063971, 441810.5492063971, 122082.7271890964]
[2019-04-27 21:26:50,885] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 21:26:50,890] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.6059106e-31 1.0000000e+00 5.4357925e-36 2.2327684e-29 5.9764107e-35], sampled 0.2266769131849653
[2019-04-27 21:26:52,005] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8770.2626 2170712315.3188 493.0000
[2019-04-27 21:26:52,087] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8700.1130 2195220806.1349 572.0000
[2019-04-27 21:26:52,205] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8922.6628 2120599135.7723 430.0000
[2019-04-27 21:26:52,408] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8099.2132 2445444095.4335 746.0000
[2019-04-27 21:26:52,499] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8582.8795 2248773970.1662 553.0000
[2019-04-27 21:26:53,520] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1975000, evaluation results [1975000.0, 8099.213190057684, 2445444095.433475, 746.0, 8770.262620159681, 2170712315.3187604, 493.0, 8922.662781171732, 2120599135.7722971, 430.0, 8582.879467926026, 2248773970.1662407, 553.0, 8700.112961499688, 2195220806.134913, 572.0]
[2019-04-27 21:26:55,976] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.7787855e-24 1.0000000e+00 7.6656947e-29 5.0588889e-23 2.2915064e-28], sum to 1.0000
[2019-04-27 21:26:55,985] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0351
[2019-04-27 21:26:55,992] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1484941.082376209 W.
[2019-04-27 21:26:55,996] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.65, 24.83333333333333, 1.0, 2.0, 0.9634437854479289, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.46765463380785, 6.9112, 121.9237200275602, 1484941.082376209, 1199992.002658416, 236363.8885425528], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2458200.0000, 
sim time next is 2458800.0000, 
raw observation next is [32.9, 24.0, 1.0, 2.0, 0.5509868701536237, 1.0, 1.0, 0.5509868701536237, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9257075280976, 1355326.65547312, 1355326.65547312, 255489.9610762182], 
processed observation next is [1.0, 0.4782608695652174, 0.774074074074074, 0.24, 1.0, 1.0, 0.46546055970669487, 1.0, 0.5, 0.46546055970669487, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094599041871762, 0.48404523409754285, 0.48404523409754285, 0.49132684822349654], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.7869195], dtype=float32), -0.70820284]. 
=============================================
[2019-04-27 21:27:02,604] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.5613021e-29 1.0000000e+00 5.2641312e-36 5.1793155e-29 1.7846914e-32], sum to 1.0000
[2019-04-27 21:27:02,613] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8150
[2019-04-27 21:27:02,617] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.5, 46.0, 1.0, 2.0, 0.493530815460486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 589153.8727813133, 589153.8727813133, 141901.3212037245], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2574000.0000, 
sim time next is 2574600.0000, 
raw observation next is [30.31666666666667, 46.83333333333334, 1.0, 2.0, 0.4956587521160484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 591516.1704381899, 591516.1704381899, 142227.1828225703], 
processed observation next is [1.0, 0.8260869565217391, 0.6783950617283951, 0.46833333333333343, 1.0, 1.0, 0.39959375251910517, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21125577515649638, 0.21125577515649638, 0.27351381312032746], 
reward next is 0.7265, 
noisyNet noise sample is [array([1.0662179], dtype=float32), 0.9809491]. 
=============================================
[2019-04-27 21:27:04,272] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.0757583e-28 1.0000000e+00 1.2542894e-32 2.4966670e-27 3.2127157e-33], sum to 1.0000
[2019-04-27 21:27:04,281] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0802
[2019-04-27 21:27:04,284] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.88333333333333, 100.0, 1.0, 2.0, 0.4676693364123399, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 565766.5096172723, 565766.5096172723, 138182.4981439878], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2616600.0000, 
sim time next is 2617200.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4726837860898848, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 570680.1405569023, 570680.1405569023, 138909.7107633163], 
processed observation next is [0.0, 0.30434782608695654, 0.3333333333333333, 1.0, 1.0, 1.0, 0.3722426024879581, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20381433591317938, 0.20381433591317938, 0.26713405916022365], 
reward next is 0.7329, 
noisyNet noise sample is [array([-1.8361242], dtype=float32), 1.6705198]. 
=============================================
[2019-04-27 21:27:05,333] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.8795719e-29 1.0000000e+00 3.6516626e-35 1.5780617e-27 4.3651402e-33], sum to 1.0000
[2019-04-27 21:27:05,341] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2192
[2019-04-27 21:27:05,347] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.86666666666667, 77.0, 1.0, 2.0, 0.5711014422579751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 666670.673487403, 666670.673487403, 153921.0769450775], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3270000.0000, 
sim time next is 3270600.0000, 
raw observation next is [25.9, 77.5, 1.0, 2.0, 0.5760072263651067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 670948.1348651316, 670948.1348651316, 154685.572800095], 
processed observation next is [0.0, 0.8695652173913043, 0.5148148148148147, 0.775, 1.0, 1.0, 0.4952466980536984, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23962433388040413, 0.23962433388040413, 0.29747225538479805], 
reward next is 0.7025, 
noisyNet noise sample is [array([-1.0519031], dtype=float32), -0.11775118]. 
=============================================
[2019-04-27 21:27:05,415] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.0571423e-29 1.0000000e+00 2.7390617e-35 8.7760737e-27 7.0394156e-33], sum to 1.0000
[2019-04-27 21:27:05,420] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9732
[2019-04-27 21:27:05,430] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 78.83333333333333, 1.0, 2.0, 0.4789178140511588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 576868.1971106707, 576868.1971106703, 139821.3974757766], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3221400.0000, 
sim time next is 3222000.0000, 
raw observation next is [24.0, 78.0, 1.0, 2.0, 0.4809447250016743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 578867.6894265086, 578867.6894265086, 140118.6654689587], 
processed observation next is [0.0, 0.30434782608695654, 0.4444444444444444, 0.78, 1.0, 1.0, 0.38207705357342175, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20673846050946737, 0.20673846050946737, 0.2694589720556898], 
reward next is 0.7305, 
noisyNet noise sample is [array([0.30134955], dtype=float32), 0.38205463]. 
=============================================
[2019-04-27 21:27:05,456] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[74.03857]
 [74.03854]
 [74.05503]
 [74.06369]
 [74.08452]], R is [[74.09794617]
 [74.08807373]
 [74.07887268]
 [74.07028961]
 [74.06233215]].
[2019-04-27 21:27:06,518] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.1542608e-31 1.0000000e+00 7.6430790e-33 2.1566739e-28 1.8424616e-31], sum to 1.0000
[2019-04-27 21:27:06,524] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5391
[2019-04-27 21:27:06,529] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666667, 91.33333333333333, 1.0, 2.0, 0.4478647756472658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 547500.8354499525, 547500.835449952, 135377.0341464873], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2697000.0000, 
sim time next is 2697600.0000, 
raw observation next is [21.13333333333333, 89.66666666666667, 1.0, 2.0, 0.4372240712030313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 536457.5241597111, 536457.5241597111, 133855.9994478117], 
processed observation next is [0.0, 0.21739130434782608, 0.33827160493827146, 0.8966666666666667, 1.0, 1.0, 0.3300286561940849, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19159197291418253, 0.19159197291418253, 0.25741538355348403], 
reward next is 0.7426, 
noisyNet noise sample is [array([-0.1237844], dtype=float32), 0.5897909]. 
=============================================
[2019-04-27 21:27:09,404] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3981144e-31 1.0000000e+00 1.5598405e-38 2.5342864e-31 7.9705078e-38], sum to 1.0000
[2019-04-27 21:27:09,416] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7495
[2019-04-27 21:27:09,420] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.2, 54.0, 1.0, 2.0, 0.6315777933175669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 719783.4042278846, 719783.4042278846, 163597.5494336841], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2828400.0000, 
sim time next is 2829000.0000, 
raw observation next is [32.05, 54.5, 1.0, 2.0, 0.635090834216307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 723788.9635413835, 723788.9635413835, 164221.7730052784], 
processed observation next is [1.0, 0.7391304347826086, 0.7425925925925925, 0.545, 1.0, 1.0, 0.5655843264479845, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25849605840763695, 0.25849605840763695, 0.3158111019332277], 
reward next is 0.6842, 
noisyNet noise sample is [array([-0.782947], dtype=float32), -1.0421411]. 
=============================================
[2019-04-27 21:27:09,437] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[79.3629  ]
 [78.821075]
 [77.67205 ]
 [75.36059 ]
 [72.19137 ]], R is [[79.53942108]
 [79.42941284]
 [79.32090759]
 [79.20882416]
 [78.98605347]].
[2019-04-27 21:27:19,921] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.5147208e-26 1.0000000e+00 4.7514293e-29 2.3571732e-24 2.4304082e-27], sum to 1.0000
[2019-04-27 21:27:19,931] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0670
[2019-04-27 21:27:19,935] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 89.0, 1.0, 2.0, 0.8471165268592843, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 969919.0606205538, 969919.0606205538, 206096.1281287153], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2896800.0000, 
sim time next is 2897400.0000, 
raw observation next is [25.0, 89.0, 1.0, 2.0, 0.833486140236517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 954487.7226167377, 954487.7226167377, 203189.6223980027], 
processed observation next is [1.0, 0.5217391304347826, 0.48148148148148145, 0.89, 1.0, 1.0, 0.8017692145672821, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3408884723631206, 0.3408884723631206, 0.3907492738423129], 
reward next is 0.6093, 
noisyNet noise sample is [array([-0.5125433], dtype=float32), -0.7092305]. 
=============================================
[2019-04-27 21:27:20,038] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.7555996e-32 1.0000000e+00 4.0770641e-36 2.5368120e-30 2.4286480e-34], sum to 1.0000
[2019-04-27 21:27:20,046] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5986
[2019-04-27 21:27:20,050] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666667, 96.0, 1.0, 2.0, 0.6696604098340553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 763206.2124771667, 763206.2124771667, 170478.0468787134], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3014400.0000, 
sim time next is 3015000.0000, 
raw observation next is [24.5, 97.0, 1.0, 2.0, 0.6675610301110462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 760812.3800345018, 760812.3800345018, 170091.8973812267], 
processed observation next is [1.0, 0.9130434782608695, 0.46296296296296297, 0.97, 1.0, 1.0, 0.6042393215607692, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2717187071551792, 0.2717187071551792, 0.3270998026562052], 
reward next is 0.6729, 
noisyNet noise sample is [array([-0.87610704], dtype=float32), 0.2278243]. 
=============================================
[2019-04-27 21:27:20,062] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[76.334984]
 [75.940125]
 [75.6016  ]
 [75.406944]
 [74.99242 ]], R is [[76.25413513]
 [76.16374969]
 [76.07423401]
 [75.98551178]
 [75.89755249]].
[2019-04-27 21:27:20,084] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3514677e-34 1.0000000e+00 0.0000000e+00 1.3894525e-32 0.0000000e+00], sum to 1.0000
[2019-04-27 21:27:20,093] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0630
[2019-04-27 21:27:20,099] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.23333333333333, 32.0, 1.0, 2.0, 0.4632325751736737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 554930.3043398954, 554930.3043398954, 137324.8021749296], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3174000.0000, 
sim time next is 3174600.0000, 
raw observation next is [34.11666666666667, 32.0, 1.0, 2.0, 0.4621070907639241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 554438.0441760552, 554438.0441760552, 137185.1966321612], 
processed observation next is [1.0, 0.7391304347826086, 0.8191358024691359, 0.32, 1.0, 1.0, 0.35965129852848104, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.198013587205734, 0.198013587205734, 0.26381768583107923], 
reward next is 0.7362, 
noisyNet noise sample is [array([1.5642952], dtype=float32), -0.091653496]. 
=============================================
[2019-04-27 21:27:24,124] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.7106212e-21 1.0000000e+00 1.8274180e-25 4.7556035e-20 4.1637696e-25], sum to 1.0000
[2019-04-27 21:27:24,132] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0783
[2019-04-27 21:27:24,140] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1609371.957735179 W.
[2019-04-27 21:27:24,145] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.66666666666667, 87.33333333333334, 1.0, 2.0, 0.4704456221780448, 1.0, 1.0, 0.4704456221780448, 1.0, 2.0, 0.748964751851723, 6.911199999999999, 6.9112, 121.94756008, 1609371.957735179, 1609371.957735179, 329314.4866695225], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2971200.0000, 
sim time next is 2971800.0000, 
raw observation next is [27.0, 86.5, 1.0, 2.0, 0.7442200358480128, 1.0, 2.0, 0.7442200358480128, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1697377.876826156, 1697377.876826156, 321244.8365439083], 
processed observation next is [1.0, 0.391304347826087, 0.5555555555555556, 0.865, 1.0, 1.0, 0.6955000426762057, 1.0, 1.0, 0.6955000426762057, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.60620638458077, 0.60620638458077, 0.6177785318152083], 
reward next is 0.3822, 
noisyNet noise sample is [array([-0.42822927], dtype=float32), 0.62816256]. 
=============================================
[2019-04-27 21:27:25,158] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.9320156e-26 1.0000000e+00 4.2360717e-33 9.8708563e-27 1.4942696e-31], sum to 1.0000
[2019-04-27 21:27:25,167] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1491
[2019-04-27 21:27:25,173] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2169785.364340794 W.
[2019-04-27 21:27:25,177] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.0, 69.83333333333334, 1.0, 2.0, 0.6414004179733154, 1.0, 2.0, 0.6340648709630924, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2169785.364340794, 2169785.364340794, 413864.5629761787], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2987400.0000, 
sim time next is 2988000.0000, 
raw observation next is [30.2, 68.0, 1.0, 2.0, 0.9849371264308934, 1.0, 2.0, 0.9849371264308934, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2247083.453202203, 2247083.453202203, 426099.8878685544], 
processed observation next is [1.0, 0.6086956521739131, 0.674074074074074, 0.68, 1.0, 1.0, 0.9820680076558255, 1.0, 1.0, 0.9820680076558255, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.8025298047150725, 0.8025298047150725, 0.8194228612856815], 
reward next is 0.1806, 
noisyNet noise sample is [array([-1.3941411], dtype=float32), 1.3014756]. 
=============================================
[2019-04-27 21:27:25,196] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[67.28888 ]
 [66.44964 ]
 [65.491875]
 [65.3378  ]
 [66.403915]], R is [[67.22212219]
 [66.75401306]
 [66.26728058]
 [65.64672089]
 [64.99025726]].
[2019-04-27 21:27:32,149] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.3269234e-31 1.0000000e+00 8.2312747e-37 1.7873367e-30 6.5091961e-35], sum to 1.0000
[2019-04-27 21:27:32,156] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3623
[2019-04-27 21:27:32,161] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 58.0, 1.0, 2.0, 0.509812359784565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 607377.6794736056, 607377.6794736056, 144419.8956623308], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3111000.0000, 
sim time next is 3111600.0000, 
raw observation next is [28.0, 58.0, 1.0, 2.0, 0.5082033126191244, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 605491.9333228176, 605491.9333228171, 144165.8066066599], 
processed observation next is [1.0, 0.0, 0.5925925925925926, 0.58, 1.0, 1.0, 0.41452775311800527, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2162471190438634, 0.21624711904386323, 0.27724193578203826], 
reward next is 0.7228, 
noisyNet noise sample is [array([0.5718331], dtype=float32), -0.5008105]. 
=============================================
[2019-04-27 21:27:35,259] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.70905753e-23 1.00000000e+00 1.36210866e-27 2.07525436e-22
 1.07585374e-26], sum to 1.0000
[2019-04-27 21:27:35,266] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3767
[2019-04-27 21:27:35,278] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1411813.925588157 W.
[2019-04-27 21:27:35,283] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.83333333333334, 44.5, 1.0, 2.0, 0.4097407416891731, 1.0, 2.0, 0.4097407416891731, 1.0, 2.0, 0.6526531434998233, 6.9112, 6.9112, 121.94756008, 1411813.925588157, 1411813.925588157, 301435.3666139913], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3145800.0000, 
sim time next is 3146400.0000, 
raw observation next is [31.0, 43.0, 1.0, 2.0, 0.4161168152815843, 1.0, 2.0, 0.4161168152815843, 1.0, 2.0, 0.6630292994156957, 6.9112, 6.9112, 121.94756008, 1438137.208985051, 1438137.208985051, 304291.0885569099], 
processed observation next is [1.0, 0.43478260869565216, 0.7037037037037037, 0.43, 1.0, 1.0, 0.3049009705733146, 1.0, 1.0, 0.3049009705733146, 1.0, 1.0, 0.5787866242696196, 0.0, 0.0, 0.8096049824067558, 0.5136204317803753, 0.5136204317803753, 0.5851751703017498], 
reward next is 0.4148, 
noisyNet noise sample is [array([0.8138281], dtype=float32), 0.28595388]. 
=============================================
[2019-04-27 21:27:36,969] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.38799214e-30 1.00000000e+00 1.25166455e-33 2.02770752e-29
 1.65672475e-34], sum to 1.0000
[2019-04-27 21:27:36,975] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2250
[2019-04-27 21:27:36,981] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.7, 54.0, 1.0, 2.0, 0.5072542613613631, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 605172.1519035485, 605172.1519035485, 144045.4806242872], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3234000.0000, 
sim time next is 3234600.0000, 
raw observation next is [29.05, 52.0, 1.0, 2.0, 0.5042974562456496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 602331.4786813537, 602331.4786813537, 143603.0804662678], 
processed observation next is [0.0, 0.43478260869565216, 0.6314814814814815, 0.52, 1.0, 1.0, 0.4098779241019638, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21511838524334062, 0.21511838524334062, 0.2761597701274381], 
reward next is 0.7238, 
noisyNet noise sample is [array([1.0161307], dtype=float32), -1.3921927]. 
=============================================
[2019-04-27 21:27:39,654] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.0335443e-30 1.0000000e+00 1.1561606e-35 1.1816927e-27 4.2473798e-34], sum to 1.0000
[2019-04-27 21:27:39,659] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7172
[2019-04-27 21:27:39,662] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 47.0, 1.0, 2.0, 0.5301628762868756, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 625768.8442937249, 625768.8442937244, 147460.0673849973], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3245400.0000, 
sim time next is 3246000.0000, 
raw observation next is [31.0, 47.33333333333334, 1.0, 2.0, 0.5327528280550194, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 628005.4418996944, 628005.4418996944, 147846.7277089412], 
processed observation next is [0.0, 0.5652173913043478, 0.7037037037037037, 0.47333333333333344, 1.0, 1.0, 0.443753366732166, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22428765782131943, 0.22428765782131943, 0.2843206302095023], 
reward next is 0.7157, 
noisyNet noise sample is [array([0.10841664], dtype=float32), -0.69573885]. 
=============================================
[2019-04-27 21:27:39,678] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[71.85566]
 [71.87899]
 [71.90064]
 [71.86034]
 [71.72205]], R is [[71.82862854]
 [71.82676697]
 [71.82556915]
 [71.82494354]
 [71.8239212 ]].
[2019-04-27 21:27:46,209] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-04-27 21:27:46,211] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 21:27:46,211] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:27:46,212] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 21:27:46,214] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:27:46,215] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 21:27:46,217] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 21:27:46,217] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:27:46,218] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:27:46,222] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 21:27:46,223] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:27:46,237] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run81
[2019-04-27 21:27:46,256] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run81
[2019-04-27 21:27:46,278] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run81
[2019-04-27 21:27:46,301] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run81
[2019-04-27 21:27:46,302] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run81
[2019-04-27 21:28:25,537] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.13746609]
[2019-04-27 21:28:25,540] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.6, 78.0, 1.0, 2.0, 0.5628041717898149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 657717.5199479532, 657717.5199479532, 152561.2137522935]
[2019-04-27 21:28:25,541] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 21:28:25,543] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.34440022e-29 1.00000000e+00 1.11220078e-33 1.10669385e-27
 6.41097648e-33], sampled 0.9427451138095014
[2019-04-27 21:28:49,389] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.13746609]
[2019-04-27 21:28:49,391] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.33137858333333, 96.24939209333334, 1.0, 2.0, 0.5851854937296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 679907.4172869165, 679907.417286916, 156167.3921870516]
[2019-04-27 21:28:49,392] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 21:28:49,394] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.3997985e-31 1.0000000e+00 3.9379925e-36 8.7229249e-30 2.4278407e-35], sampled 0.724576265618513
[2019-04-27 21:28:55,279] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.13746609]
[2019-04-27 21:28:55,279] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.6, 62.5, 1.0, 2.0, 0.4441685801067395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 541917.2384437072, 541917.2384437077, 134797.6651896042]
[2019-04-27 21:28:55,280] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 21:28:55,285] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.4450294e-31 1.0000000e+00 8.3874492e-36 1.6489045e-29 4.9042238e-35], sampled 0.5533695853860875
[2019-04-27 21:29:19,889] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.13746609]
[2019-04-27 21:29:19,891] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.14623124, 63.59839627, 1.0, 2.0, 0.5039268654970828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 599160.7467736165, 599160.7467736165, 143443.5016440656]
[2019-04-27 21:29:19,892] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 21:29:19,895] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [7.7533849e-31 1.0000000e+00 1.5983268e-35 2.7698776e-29 9.0601130e-35], sampled 0.6370335005735726
[2019-04-27 21:29:34,828] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8700.8700 2195155380.8105 572.0000
[2019-04-27 21:29:35,444] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8923.4199 2120533710.1715 430.0000
[2019-04-27 21:29:35,473] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.0852 2170656631.3663 493.0000
[2019-04-27 21:29:35,499] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8583.7021 2248718286.8236 553.0000
[2019-04-27 21:29:35,596] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8099.2132 2445444095.4335 746.0000
[2019-04-27 21:29:36,613] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 2000000, evaluation results [2000000.0, 8099.213190057684, 2445444095.433475, 746.0, 8771.085197215923, 2170656631.3662677, 493.0, 8923.419851553375, 2120533710.171511, 430.0, 8583.702050975664, 2248718286.823596, 553.0, 8700.870031992405, 2195155380.8105125, 572.0]
[2019-04-27 21:29:36,809] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.4691488e-26 1.0000000e+00 6.2037496e-29 1.2162703e-23 1.7478483e-27], sum to 1.0000
[2019-04-27 21:29:36,816] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5659
[2019-04-27 21:29:36,825] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2033398.561296331 W.
[2019-04-27 21:29:36,835] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.25, 63.0, 1.0, 2.0, 0.8913817201608063, 1.0, 2.0, 0.8913817201608063, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2033398.561296331, 2033398.561296331, 382961.5747935771], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3411000.0000, 
sim time next is 3411600.0000, 
raw observation next is [30.5, 61.66666666666666, 1.0, 2.0, 0.9282448821552906, 1.0, 2.0, 0.9282448821552906, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2117589.62988717, 2117589.62988717, 399596.7560929961], 
processed observation next is [1.0, 0.4782608695652174, 0.6851851851851852, 0.6166666666666666, 1.0, 1.0, 0.9145772406610602, 1.0, 1.0, 0.9145772406610602, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7562820106739894, 0.7562820106739894, 0.7684553001788387], 
reward next is 0.2315, 
noisyNet noise sample is [array([0.36939237], dtype=float32), 0.44216278]. 
=============================================
[2019-04-27 21:29:45,810] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.3082584e-27 1.0000000e+00 7.7192104e-31 1.9587775e-24 8.3170062e-28], sum to 1.0000
[2019-04-27 21:29:45,817] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1714
[2019-04-27 21:29:45,826] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2137182.629109772 W.
[2019-04-27 21:29:45,832] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.08333333333334, 87.33333333333334, 1.0, 2.0, 0.9368232022044675, 1.0, 2.0, 0.9368232022044675, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2137182.629109772, 2137182.629109772, 403537.0687291362], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3509400.0000, 
sim time next is 3510000.0000, 
raw observation next is [28.0, 89.0, 1.0, 2.0, 0.5903516047647271, 1.0, 2.0, 0.5903516047647271, 1.0, 1.0, 0.9398589811949473, 6.911200000000001, 6.9112, 121.94756008, 2020028.335336762, 2020028.335336762, 390143.7152911793], 
processed observation next is [1.0, 0.6521739130434783, 0.5925925925925926, 0.89, 1.0, 1.0, 0.5123233390056275, 1.0, 1.0, 0.5123233390056275, 1.0, 0.5, 0.9248237264936839, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7214386911917007, 0.7214386911917007, 0.7502763755599602], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0797971], dtype=float32), 2.881652]. 
=============================================
[2019-04-27 21:29:45,854] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[61.022015]
 [60.566406]
 [60.22356 ]
 [60.172558]
 [60.00798 ]], R is [[61.29761505]
 [60.68463898]
 [60.07779312]
 [59.73620224]
 [59.38871384]].
[2019-04-27 21:29:46,660] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.3936624e-32 1.0000000e+00 7.6379006e-38 3.6263102e-30 2.2144155e-34], sum to 1.0000
[2019-04-27 21:29:46,668] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7493
[2019-04-27 21:29:46,674] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.6478974133235341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 738391.1661097357, 738391.1661097357, 166513.8502511261], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3522600.0000, 
sim time next is 3523200.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.6501654199926091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 740977.201290164, 740977.201290164, 166923.1140949054], 
processed observation next is [1.0, 0.782608695652174, 0.5555555555555556, 0.79, 1.0, 1.0, 0.5835302618959632, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26463471474648714, 0.26463471474648714, 0.3210059886440489], 
reward next is 0.6790, 
noisyNet noise sample is [array([0.29673457], dtype=float32), -0.09625665]. 
=============================================
[2019-04-27 21:29:55,812] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.6335975e-25 1.0000000e+00 6.1885750e-29 6.7401405e-23 5.7393064e-28], sum to 1.0000
[2019-04-27 21:29:55,821] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3557
[2019-04-27 21:29:55,829] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1722145.463291542 W.
[2019-04-27 21:29:55,834] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.33333333333334, 87.0, 1.0, 2.0, 0.7550689954342836, 1.0, 2.0, 0.7550689954342836, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1722145.463291542, 1722145.463291541, 325537.9519092169], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3680400.0000, 
sim time next is 3681000.0000, 
raw observation next is [26.5, 87.5, 1.0, 2.0, 0.7950822427488137, 1.0, 2.0, 0.7950822427488137, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1813499.474764745, 1813499.474764745, 341726.6897378288], 
processed observation next is [1.0, 0.6086956521739131, 0.5370370370370371, 0.875, 1.0, 1.0, 0.7560502889866829, 1.0, 1.0, 0.7560502889866829, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.6476783838445518, 0.6476783838445518, 0.6571667110342861], 
reward next is 0.3428, 
noisyNet noise sample is [array([-1.0043043], dtype=float32), 0.27709708]. 
=============================================
[2019-04-27 21:29:55,846] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[61.501793]
 [60.819164]
 [60.047302]
 [59.284267]
 [58.646126]], R is [[61.89738464]
 [61.27841187]
 [60.66562653]
 [60.05897141]
 [59.45838165]].
[2019-04-27 21:30:03,161] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.0262048e-27 1.0000000e+00 8.3699232e-31 1.8735810e-26 7.9857228e-31], sum to 1.0000
[2019-04-27 21:30:03,172] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7718
[2019-04-27 21:30:03,178] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.13333333333333, 93.0, 1.0, 2.0, 0.490122371264707, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 588272.6634561362, 588272.6634561362, 141484.4883310192], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4426800.0000, 
sim time next is 4427400.0000, 
raw observation next is [22.06666666666667, 93.5, 1.0, 2.0, 0.4904930150644758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 588766.5316148774, 588766.5316148774, 141543.9065313584], 
processed observation next is [0.0, 0.21739130434782608, 0.3728395061728396, 0.935, 1.0, 1.0, 0.3934440655529474, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21027376129102765, 0.21027376129102765, 0.2721998202526123], 
reward next is 0.7278, 
noisyNet noise sample is [array([-0.31316832], dtype=float32), 0.092537545]. 
=============================================
[2019-04-27 21:30:06,340] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1864507e-24 1.0000000e+00 1.3811632e-29 6.9996525e-25 2.9838902e-29], sum to 1.0000
[2019-04-27 21:30:06,350] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5126
[2019-04-27 21:30:06,353] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 93.0, 1.0, 2.0, 0.7330287616952932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 835465.9386080935, 835465.9386080935, 182492.017938008], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3892800.0000, 
sim time next is 3893400.0000, 
raw observation next is [26.0, 92.5, 1.0, 2.0, 0.7289896456677055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 830859.8806820704, 830859.8806820704, 181705.399668178], 
processed observation next is [0.0, 0.043478260869565216, 0.5185185185185185, 0.925, 1.0, 1.0, 0.6773686257948875, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.296735671672168, 0.296735671672168, 0.34943346090034233], 
reward next is 0.6506, 
noisyNet noise sample is [array([0.81278324], dtype=float32), 0.884567]. 
=============================================
[2019-04-27 21:30:14,741] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.7013406e-29 1.0000000e+00 2.6843332e-34 9.7545078e-29 1.8786701e-33], sum to 1.0000
[2019-04-27 21:30:14,749] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1097
[2019-04-27 21:30:14,756] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2065885.931783428 W.
[2019-04-27 21:30:14,763] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.86666666666667, 68.33333333333334, 1.0, 2.0, 0.9056067667417386, 1.0, 2.0, 0.9056067667417386, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2065885.931783428, 2065885.931783428, 389325.6090807971], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4638000.0000, 
sim time next is 4638600.0000, 
raw observation next is [29.8, 67.5, 1.0, 2.0, 0.5966379999244127, 1.0, 2.0, 0.5966379999244127, 1.0, 1.0, 0.9498671270227639, 6.911200000000001, 6.9112, 121.94756008, 2041563.314708084, 2041563.314708084, 393546.8458957619], 
processed observation next is [1.0, 0.6956521739130435, 0.6592592592592593, 0.675, 1.0, 1.0, 0.5198071427671579, 1.0, 1.0, 0.5198071427671579, 1.0, 0.5, 0.9373339087784549, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7291297552528871, 0.7291297552528871, 0.7568208574918498], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.26420453], dtype=float32), -1.0223776]. 
=============================================
[2019-04-27 21:30:16,490] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.2679158e-28 1.0000000e+00 3.2399287e-32 8.8860251e-28 9.0528971e-34], sum to 1.0000
[2019-04-27 21:30:16,501] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4817
[2019-04-27 21:30:16,515] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2015084.152045071 W.
[2019-04-27 21:30:16,523] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 71.33333333333333, 1.0, 2.0, 0.5889082994285569, 1.0, 2.0, 0.5889082994285569, 1.0, 1.0, 0.9375611920945912, 6.911199999999999, 6.9112, 121.94756008, 2015084.152045071, 2015084.152045071, 389365.3891835116], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4117200.0000, 
sim time next is 4117800.0000, 
raw observation next is [29.0, 70.66666666666667, 1.0, 2.0, 0.8835126718700387, 1.0, 2.0, 0.8835126718700387, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2015427.620866631, 2015427.620866631, 379471.6276460958], 
processed observation next is [1.0, 0.6521739130434783, 0.6296296296296297, 0.7066666666666667, 1.0, 1.0, 0.8613246093690936, 1.0, 1.0, 0.8613246093690936, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7197955788809396, 0.7197955788809396, 0.7297531300886458], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.36662382], dtype=float32), 0.15044704]. 
=============================================
[2019-04-27 21:30:22,117] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1741152e-30 1.0000000e+00 2.9968595e-37 1.4576309e-29 4.9770635e-36], sum to 1.0000
[2019-04-27 21:30:22,127] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3143
[2019-04-27 21:30:22,134] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1654876.223546932 W.
[2019-04-27 21:30:22,138] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.06666666666667, 32.0, 1.0, 2.0, 0.4777766241930697, 1.0, 2.0, 0.4777766241930697, 1.0, 1.0, 0.7614821904724982, 6.911199999999999, 6.9112, 121.94756008, 1654876.223546932, 1654876.223546932, 332916.9345549052], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4202400.0000, 
sim time next is 4203000.0000, 
raw observation next is [34.05, 32.5, 1.0, 2.0, 0.7320447670825232, 1.0, 2.0, 0.7320447670825232, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1703425.237245807, 1703425.237245808, 318166.8784349125], 
processed observation next is [1.0, 0.6521739130434783, 0.8166666666666665, 0.325, 1.0, 1.0, 0.6810056750982418, 1.0, 1.0, 0.6810056750982418, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6083661561592167, 0.6083661561592171, 0.6118593816056009], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.30733457], dtype=float32), 1.2914656]. 
=============================================
[2019-04-27 21:30:22,153] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[75.22883 ]
 [75.366875]
 [74.54032 ]
 [74.026695]
 [73.750435]], R is [[75.35410309]
 [74.60056305]
 [74.2851181 ]
 [73.54226685]
 [73.16261292]].
[2019-04-27 21:30:23,650] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.4409292e-32 1.0000000e+00 0.0000000e+00 1.6785406e-31 1.6645783e-36], sum to 1.0000
[2019-04-27 21:30:23,658] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6619
[2019-04-27 21:30:23,664] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.36666666666667, 97.33333333333333, 1.0, 2.0, 0.7078710132406543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 806777.4272089533, 806777.4272089533, 177640.6275622077], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4837200.0000, 
sim time next is 4837800.0000, 
raw observation next is [25.18333333333334, 98.66666666666667, 1.0, 2.0, 0.7070792773449115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 805874.5926069357, 805874.5926069357, 177489.6666104037], 
processed observation next is [1.0, 1.0, 0.4882716049382719, 0.9866666666666667, 1.0, 1.0, 0.6512848539820375, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.287812354502477, 0.287812354502477, 0.34132628194308406], 
reward next is 0.6587, 
noisyNet noise sample is [array([-0.4131674], dtype=float32), -2.0749571]. 
=============================================
[2019-04-27 21:30:27,671] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0786670e-29 1.0000000e+00 1.1366355e-34 1.1121787e-27 1.9558342e-33], sum to 1.0000
[2019-04-27 21:30:27,677] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5396
[2019-04-27 21:30:27,680] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.3, 49.33333333333333, 1.0, 2.0, 0.5339017556013739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 621799.3009477124, 621799.3009477129, 147713.5444588796], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4297200.0000, 
sim time next is 4297800.0000, 
raw observation next is [31.15, 50.66666666666667, 1.0, 2.0, 0.5509729681433682, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 639795.6786626767, 639795.6786626762, 150417.1331763341], 
processed observation next is [1.0, 0.7391304347826086, 0.7092592592592593, 0.5066666666666667, 1.0, 1.0, 0.4654440096944859, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22849845666524168, 0.22849845666524152, 0.2892637176467963], 
reward next is 0.7107, 
noisyNet noise sample is [array([1.2983838], dtype=float32), -0.35490042]. 
=============================================
[2019-04-27 21:30:29,154] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-04-27 21:30:29,155] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 21:30:29,156] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:30:29,156] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 21:30:29,157] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 21:30:29,157] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:30:29,158] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:30:29,159] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 21:30:29,158] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 21:30:29,161] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:30:29,163] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:30:29,179] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run82
[2019-04-27 21:30:29,201] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run82
[2019-04-27 21:30:29,221] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run82
[2019-04-27 21:30:29,244] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run82
[2019-04-27 21:30:29,267] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run82
[2019-04-27 21:30:40,298] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.13777041]
[2019-04-27 21:30:40,299] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.34237348666667, 55.13236653, 1.0, 2.0, 0.4857957380785133, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8316739275697927, 6.911200000000001, 6.9112, 121.926042615644, 1229053.22698987, 1229053.226989869, 245709.5048673611]
[2019-04-27 21:30:40,300] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 21:30:40,303] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.8072848e-24 1.0000000e+00 1.0208029e-27 8.6374602e-23 5.3589586e-27], sampled 0.4960251492072192
[2019-04-27 21:30:50,058] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.13777041]
[2019-04-27 21:30:50,059] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.49921236, 59.90237846, 1.0, 2.0, 0.4116384152714455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 506366.8341173317, 506366.8341173317, 130182.5280584835]
[2019-04-27 21:30:50,059] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 21:30:50,061] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.9803636e-28 1.0000000e+00 3.6574537e-32 2.2134280e-26 2.3918472e-31], sampled 0.8823687492893852
[2019-04-27 21:31:00,776] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.13777041]
[2019-04-27 21:31:00,778] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [34.1, 38.66666666666667, 1.0, 2.0, 0.9731345530860508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.092554553630911, 6.9112, 121.9252985706554, 1223260.770184994, 1130391.596170888, 235459.8699417093]
[2019-04-27 21:31:00,779] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 21:31:00,781] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.5577219e-25 1.0000000e+00 1.5029671e-28 1.5219351e-23 7.9240428e-28], sampled 0.9990116316506308
[2019-04-27 21:31:25,890] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.13777041]
[2019-04-27 21:31:25,892] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.41666666666667, 79.0, 1.0, 2.0, 0.7921133211654221, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 902846.9404540109, 902846.9404540109, 194323.679733821]
[2019-04-27 21:31:25,894] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 21:31:25,896] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.2428130e-24 1.0000000e+00 5.0166171e-28 3.7384674e-23 2.6308066e-27], sampled 0.49219120900913327
[2019-04-27 21:31:32,117] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.13777041]
[2019-04-27 21:31:32,118] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.0, 71.33333333333334, 1.0, 2.0, 0.9056077261205449, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1032294.445835974, 1032294.445835974, 218724.2048390312]
[2019-04-27 21:31:32,120] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 21:31:32,122] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.2366090e-25 1.0000000e+00 2.9079273e-29 4.9052614e-24 1.8229035e-28], sampled 0.43834343136223053
[2019-04-27 21:32:16,276] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8099.9706 2445378853.1784 746.0000
[2019-04-27 21:32:16,662] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8700.8700 2195155380.8105 572.0000
[2019-04-27 21:32:16,745] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8923.4199 2120533710.1715 430.0000
[2019-04-27 21:32:16,783] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8770.2626 2170712315.3188 493.0000
[2019-04-27 21:32:17,030] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8583.7021 2248718286.8236 553.0000
[2019-04-27 21:32:18,049] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 2025000, evaluation results [2025000.0, 8099.970618414005, 2445378853.1783895, 746.0, 8770.262620159681, 2170712315.3187604, 493.0, 8923.419851553375, 2120533710.171511, 430.0, 8583.702050975664, 2248718286.823596, 553.0, 8700.870031992405, 2195155380.8105125, 572.0]
[2019-04-27 21:32:23,785] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.7008137e-18 1.0000000e+00 9.3457814e-21 1.4016595e-17 4.5820959e-21], sum to 1.0000
[2019-04-27 21:32:23,794] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9778
[2019-04-27 21:32:23,802] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1358400.655941135 W.
[2019-04-27 21:32:23,809] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.83333333333333, 95.0, 1.0, 2.0, 0.5957198235286874, 1.0, 1.0, 0.5957198235286874, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260424334617, 1358400.655941135, 1358400.655941135, 266571.6537731878], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4701000.0000, 
sim time next is 4701600.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.5645550179131661, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8987899747910812, 6.911200000000001, 6.9112, 121.9260426156062, 1287276.841475941, 1287276.841475941, 280321.6509632873], 
processed observation next is [1.0, 0.43478260869565216, 0.4444444444444444, 0.94, 1.0, 1.0, 0.4816131165632929, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.8734874684888516, 8.881784197001253e-17, 0.0, 0.8094621288197669, 0.4597417290985504, 0.4597417290985504, 0.5390800980063217], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.0214264], dtype=float32), -0.39219657]. 
=============================================
[2019-04-27 21:32:33,056] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.78947954e-32 1.00000000e+00 1.90965536e-38 1.11110305e-32
 2.95361834e-37], sum to 1.0000
[2019-04-27 21:32:33,066] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2070
[2019-04-27 21:32:33,070] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 99.00000000000001, 1.0, 2.0, 0.5781636204770572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 672276.0833607245, 672276.0833607245, 154997.6397025083], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4569000.0000, 
sim time next is 4569600.0000, 
raw observation next is [23.0, 98.0, 1.0, 2.0, 0.5751658640217665, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 670466.6535944589, 670466.6535944589, 154565.0748124919], 
processed observation next is [0.0, 0.9130434782608695, 0.4074074074074074, 0.98, 1.0, 1.0, 0.4942450762163887, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23945237628373534, 0.23945237628373534, 0.2972405284855613], 
reward next is 0.7028, 
noisyNet noise sample is [array([0.12516263], dtype=float32), 0.8461194]. 
=============================================
[2019-04-27 21:32:35,294] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4387737e-25 1.0000000e+00 6.1032901e-27 3.7042838e-23 1.3665950e-27], sum to 1.0000
[2019-04-27 21:32:35,303] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7717
[2019-04-27 21:32:35,307] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.4854280010161057, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 585690.8362978075, 585690.8362978075, 140859.4381945489], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4591200.0000, 
sim time next is 4591800.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.4883182726048977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 589190.8895323267, 589190.8895323267, 141308.8042672926], 
processed observation next is [1.0, 0.13043478260869565, 0.3333333333333333, 1.0, 1.0, 1.0, 0.390855086434402, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2104253176901167, 0.2104253176901167, 0.27174770051402425], 
reward next is 0.7283, 
noisyNet noise sample is [array([-0.8767834], dtype=float32), 0.4805151]. 
=============================================
[2019-04-27 21:32:43,767] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.4283707e-32 1.0000000e+00 5.4461472e-37 1.9610572e-32 2.1175681e-35], sum to 1.0000
[2019-04-27 21:32:43,769] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2570
[2019-04-27 21:32:43,775] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.16666666666667, 93.16666666666667, 1.0, 2.0, 0.6759829253545243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 770415.5502711849, 770415.5502711849, 171645.6613856204], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4744200.0000, 
sim time next is 4744800.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.6755061229902269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 769871.8672639655, 769871.8672639655, 171557.1365517173], 
processed observation next is [1.0, 0.9565217391304348, 0.48148148148148145, 0.94, 1.0, 1.0, 0.6136977654645559, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27495423830855914, 0.27495423830855914, 0.32991757029176405], 
reward next is 0.6701, 
noisyNet noise sample is [array([2.27473], dtype=float32), -0.8675707]. 
=============================================
[2019-04-27 21:32:56,326] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.1798725e-20 1.0000000e+00 1.3006788e-22 1.6737571e-17 6.7070098e-21], sum to 1.0000
[2019-04-27 21:32:56,333] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2663
[2019-04-27 21:32:56,336] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.08333333333333, 87.16666666666667, 1.0, 2.0, 0.6438021526785517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 754947.4631619395, 754947.463161939, 166777.6126385206], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4950600.0000, 
sim time next is 4951200.0000, 
raw observation next is [24.16666666666666, 85.33333333333334, 1.0, 2.0, 0.7511099829596853, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 883512.1414498221, 883512.1414498221, 187374.5809879153], 
processed observation next is [1.0, 0.30434782608695654, 0.45061728395061706, 0.8533333333333334, 1.0, 1.0, 0.7037023606662921, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3155400505177936, 0.3155400505177936, 0.3603357326690679], 
reward next is 0.6397, 
noisyNet noise sample is [array([0.43841982], dtype=float32), 0.9920878]. 
=============================================
[2019-04-27 21:32:57,206] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3115757e-29 1.0000000e+00 6.1932587e-34 6.1899302e-26 3.7191339e-32], sum to 1.0000
[2019-04-27 21:32:57,212] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0833
[2019-04-27 21:32:57,215] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 96.0, 1.0, 2.0, 0.5468825048090843, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 641639.5967273446, 641639.5967273446, 150031.8496526493], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5023200.0000, 
sim time next is 5023800.0000, 
raw observation next is [23.0, 97.0, 1.0, 2.0, 0.5532361815882395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 647471.868345012, 647471.868345012, 151011.512273383], 
processed observation next is [0.0, 0.13043478260869565, 0.4074074074074074, 0.97, 1.0, 1.0, 0.4681383114145708, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2312399529803614, 0.2312399529803614, 0.2904067543718904], 
reward next is 0.7096, 
noisyNet noise sample is [array([-1.2976761], dtype=float32), 1.0157033]. 
=============================================
[2019-04-27 21:33:09,169] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.816438e-20 1.000000e+00 7.486599e-23 1.015351e-18 9.879056e-22], sum to 1.0000
[2019-04-27 21:33:09,180] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5820
[2019-04-27 21:33:09,185] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.9, 93.66666666666667, 1.0, 2.0, 0.6693752583658117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 762881.066078263, 762881.066078263, 170425.245682958], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5188200.0000, 
sim time next is 5188800.0000, 
raw observation next is [24.8, 93.33333333333334, 1.0, 2.0, 0.6623702144799474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 754893.5482253545, 754893.5482253545, 169140.0374609145], 
processed observation next is [1.0, 0.043478260869565216, 0.4740740740740741, 0.9333333333333335, 1.0, 1.0, 0.5980597791427945, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2696048386519123, 0.2696048386519123, 0.32526930280945093], 
reward next is 0.6747, 
noisyNet noise sample is [array([0.24429418], dtype=float32), 0.023572585]. 
=============================================
[2019-04-27 21:33:10,625] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-04-27 21:33:10,627] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 21:33:10,627] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:33:10,628] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 21:33:10,629] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:33:10,629] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 21:33:10,629] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 21:33:10,630] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 21:33:10,631] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:33:10,631] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:33:10,632] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:33:10,658] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run83
[2019-04-27 21:33:10,658] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run83
[2019-04-27 21:33:10,679] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run83
[2019-04-27 21:33:10,699] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run83
[2019-04-27 21:33:10,749] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run83
[2019-04-27 21:33:12,287] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.13930495]
[2019-04-27 21:33:12,288] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.68333333333334, 26.83333333333333, 1.0, 2.0, 0.3213928586244224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 414539.7954422063, 414539.7954422063, 115505.4881777415]
[2019-04-27 21:33:12,289] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 21:33:12,297] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.3193286e-31 1.0000000e+00 1.3407401e-35 2.3313322e-29 3.0952976e-35], sampled 0.16100378975912688
[2019-04-27 21:33:23,754] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.13930495]
[2019-04-27 21:33:23,757] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [17.0, 45.0, 1.0, 2.0, 0.2062221630154888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 265999.0553351844, 265999.055335184, 75585.93917992566]
[2019-04-27 21:33:23,758] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 21:33:23,762] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.6763749e-29 1.0000000e+00 1.3145183e-33 1.4730265e-27 3.9946303e-33], sampled 0.8297851560653283
[2019-04-27 21:33:41,807] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.13930495]
[2019-04-27 21:33:41,808] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.43197819, 77.06931393, 1.0, 2.0, 0.5452311656254464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 643496.6883470123, 643496.6883470123, 149917.6182840013]
[2019-04-27 21:33:41,810] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 21:33:41,812] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.3859886e-27 1.0000000e+00 1.4258203e-31 4.8758731e-26 3.6312224e-31], sampled 0.08785226359121623
[2019-04-27 21:34:11,480] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.13930495]
[2019-04-27 21:34:11,481] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.6, 85.0, 1.0, 2.0, 0.6063737387670122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 694112.5099936678, 694112.5099936678, 159329.1739131962]
[2019-04-27 21:34:11,482] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 21:34:11,484] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [4.5282153e-27 1.0000000e+00 5.2776363e-31 1.6212646e-25 1.4704361e-30], sampled 0.6411215107721125
[2019-04-27 21:34:35,957] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.13930495]
[2019-04-27 21:34:35,958] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.8179292, 86.48850924, 1.0, 2.0, 0.5968153076533063, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 690395.7268773206, 690395.7268773206, 158024.6072557293]
[2019-04-27 21:34:35,960] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 21:34:35,963] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.6677428e-28 1.0000000e+00 1.8635606e-32 1.1471905e-26 5.0651029e-32], sampled 0.39842087153025507
[2019-04-27 21:34:44,363] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.13930495]
[2019-04-27 21:34:44,365] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.33506977333334, 89.8916217, 1.0, 2.0, 0.5193632131597586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 613733.5927387662, 613733.5927387662, 145750.2265546003]
[2019-04-27 21:34:44,365] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 21:34:44,369] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.1265553e-28 1.0000000e+00 7.1566006e-33 5.1450564e-27 1.9768453e-32], sampled 0.06859623169580675
[2019-04-27 21:34:50,800] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.13930495]
[2019-04-27 21:34:50,800] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [19.1, 96.33333333333333, 1.0, 2.0, 0.3639984010680145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 454979.6374893068, 454979.6374893068, 123743.0019320785]
[2019-04-27 21:34:50,800] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 21:34:50,804] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.2563040e-29 1.0000000e+00 2.8038483e-33 2.6743569e-27 8.2549385e-33], sampled 0.6245112471747899
[2019-04-27 21:34:57,733] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.0852 2170656631.3663 493.0000
[2019-04-27 21:34:57,845] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8099.2132 2445444095.4335 746.0000
[2019-04-27 21:34:58,009] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8923.4199 2120533710.1715 430.0000
[2019-04-27 21:34:58,097] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8582.8795 2248773970.1662 553.0000
[2019-04-27 21:34:58,141] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8700.1130 2195220806.1349 572.0000
[2019-04-27 21:34:59,159] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 2050000, evaluation results [2050000.0, 8099.213190057684, 2445444095.433475, 746.0, 8771.085197215923, 2170656631.3662677, 493.0, 8923.419851553375, 2120533710.171511, 430.0, 8582.879467926026, 2248773970.1662407, 553.0, 8700.112961499688, 2195220806.134913, 572.0]
[2019-04-27 21:35:01,360] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.77315055e-22 1.00000000e+00 1.03354627e-25 6.72181082e-22
 6.23601014e-24], sum to 1.0000
[2019-04-27 21:35:01,367] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8481
[2019-04-27 21:35:01,371] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.63333333333333, 87.66666666666667, 1.0, 2.0, 0.6584519476229618, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 750425.7714764772, 750425.7714764772, 168425.5723956721], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5272800.0000, 
sim time next is 5273400.0000, 
raw observation next is [25.61666666666667, 87.33333333333333, 1.0, 2.0, 0.6548021054484232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 746264.0875455833, 746264.0875455833, 167761.848516209], 
processed observation next is [1.0, 0.0, 0.5043209876543211, 0.8733333333333333, 1.0, 1.0, 0.5890501255338372, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2665228884091369, 0.2665228884091369, 0.3226189394542481], 
reward next is 0.6774, 
noisyNet noise sample is [array([1.0348891], dtype=float32), -1.5735216]. 
=============================================
[2019-04-27 21:35:01,398] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.9775890e-31 1.0000000e+00 5.0622945e-35 2.3891504e-29 7.7439180e-33], sum to 1.0000
[2019-04-27 21:35:01,405] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8217
[2019-04-27 21:35:01,410] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.45, 79.0, 1.0, 2.0, 0.7129299869823983, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 812546.3161122086, 812546.3161122086, 178609.8480046153], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5250600.0000, 
sim time next is 5251200.0000, 
raw observation next is [28.26666666666667, 80.66666666666667, 1.0, 2.0, 0.7215567044299812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 822383.7028541719, 822383.7028541719, 180268.9503446049], 
processed observation next is [1.0, 0.782608695652174, 0.6024691358024692, 0.8066666666666668, 1.0, 1.0, 0.6685198862261681, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2937084653050614, 0.2937084653050614, 0.34667105835500944], 
reward next is 0.6533, 
noisyNet noise sample is [array([1.0437351], dtype=float32), 0.60702837]. 
=============================================
[2019-04-27 21:35:03,638] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.2326569e-22 1.0000000e+00 1.1225545e-25 3.5259714e-20 1.5631211e-25], sum to 1.0000
[2019-04-27 21:35:03,647] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6666
[2019-04-27 21:35:03,654] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.13333333333333, 92.33333333333334, 1.0, 2.0, 0.5333222047758803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 640648.5271659299, 640648.5271659299, 148392.1895000489], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5298000.0000, 
sim time next is 5298600.0000, 
raw observation next is [22.01666666666667, 92.66666666666666, 1.0, 2.0, 0.5058000232466445, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 608460.7147585601, 608460.7147585601, 143994.0335407533], 
processed observation next is [1.0, 0.30434782608695654, 0.37098765432098774, 0.9266666666666665, 1.0, 1.0, 0.4116666943412435, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21730739812805716, 0.21730739812805716, 0.2769116029629871], 
reward next is 0.7231, 
noisyNet noise sample is [array([0.86624676], dtype=float32), -1.4109602]. 
=============================================
[2019-04-27 21:35:05,025] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.1111950e-25 1.0000000e+00 6.1785355e-26 9.9438934e-23 4.4404648e-26], sum to 1.0000
[2019-04-27 21:35:05,033] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4551
[2019-04-27 21:35:05,039] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.6, 88.66666666666667, 1.0, 2.0, 0.7754533329536198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 896698.4985974324, 896698.4985974324, 191575.6668961981], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5368800.0000, 
sim time next is 5369400.0000, 
raw observation next is [24.55, 89.0, 1.0, 2.0, 0.7800177780294841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 902071.2844874734, 902071.2844874734, 192510.7482531475], 
processed observation next is [1.0, 0.13043478260869565, 0.46481481481481485, 0.89, 1.0, 1.0, 0.7381164024160525, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.32216831588838335, 0.32216831588838335, 0.37021297740989906], 
reward next is 0.6298, 
noisyNet noise sample is [array([0.96665275], dtype=float32), -0.6289963]. 
=============================================
[2019-04-27 21:35:09,215] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.1807755e-26 1.0000000e+00 1.2549702e-30 1.2269745e-23 4.1128351e-29], sum to 1.0000
[2019-04-27 21:35:09,227] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9642
[2019-04-27 21:35:09,239] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2400818.932507336 W.
[2019-04-27 21:35:09,243] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.5, 75.5, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 7.054810746910552, 6.9112, 121.9254733288119, 2400818.932507336, 2327277.737680208, 443048.9686478234], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5416200.0000, 
sim time next is 5416800.0000, 
raw observation next is [29.66666666666667, 74.33333333333334, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 7.241922661712528, 6.9112, 121.9245069083666, 2496760.102206265, 2327402.67290483, 443048.9371582143], 
processed observation next is [1.0, 0.6956521739130435, 0.6543209876543211, 0.7433333333333334, 1.0, 1.0, 1.0238095238095237, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.25, 0.03307226617125281, 0.0, 0.8094519333207189, 0.8917000365022375, 0.8312152403231535, 0.8520171868427198], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.03699127], dtype=float32), 0.7242873]. 
=============================================
[2019-04-27 21:35:14,817] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.7544213e-24 1.0000000e+00 3.4120611e-25 5.6239614e-21 5.7850133e-25], sum to 1.0000
[2019-04-27 21:35:14,827] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4254
[2019-04-27 21:35:14,836] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.4, 93.0, 1.0, 2.0, 0.8142160512704705, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 928054.7794752452, 928054.7794752452, 198891.8407004473], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5541000.0000, 
sim time next is 5541600.0000, 
raw observation next is [25.4, 93.0, 1.0, 2.0, 0.7505333074350388, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 855427.7924735862, 855427.7924735862, 185928.9652656907], 
processed observation next is [1.0, 0.13043478260869565, 0.49629629629629624, 0.93, 1.0, 1.0, 0.7030158421845699, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3055099258834236, 0.3055099258834236, 0.3575557024340206], 
reward next is 0.6424, 
noisyNet noise sample is [array([-0.67728525], dtype=float32), -1.1060108]. 
=============================================
[2019-04-27 21:35:16,276] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.1588984e-24 1.0000000e+00 4.8992860e-28 4.9636914e-23 6.2758542e-27], sum to 1.0000
[2019-04-27 21:35:16,287] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5396
[2019-04-27 21:35:16,290] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1384972.632714827 W.
[2019-04-27 21:35:16,295] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.71666666666667, 79.33333333333334, 1.0, 2.0, 0.4049082677532205, 1.0, 1.0, 0.4049082677532205, 1.0, 2.0, 0.6446271492047795, 6.9112, 6.9112, 121.94756008, 1384972.632714827, 1384972.632714827, 299238.9027690271], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5568600.0000, 
sim time next is 5569200.0000, 
raw observation next is [26.8, 79.0, 1.0, 2.0, 0.6726539270195773, 1.0, 2.0, 0.6726539270195773, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1534006.70360847, 1534006.70360847, 293942.1085932472], 
processed observation next is [1.0, 0.4782608695652174, 0.5481481481481482, 0.79, 1.0, 1.0, 0.6103022940709253, 1.0, 1.0, 0.6103022940709253, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.547859537003025, 0.547859537003025, 0.5652732857562446], 
reward next is 0.4347, 
noisyNet noise sample is [array([-0.85982716], dtype=float32), 1.3711817]. 
=============================================
[2019-04-27 21:35:22,942] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6972646e-31 1.0000000e+00 3.3309446e-35 3.9773177e-30 5.8521033e-35], sum to 1.0000
[2019-04-27 21:35:22,948] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0320
[2019-04-27 21:35:22,956] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.43333333333333, 86.66666666666667, 1.0, 2.0, 0.7543656034468768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 859798.1399504445, 859798.1399504445, 186695.3230278221], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5689200.0000, 
sim time next is 5689800.0000, 
raw observation next is [27.2, 87.0, 1.0, 2.0, 0.7344450467274705, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 837081.0240200238, 837081.0240200233, 182770.4272254035], 
processed observation next is [0.0, 0.8695652173913043, 0.5629629629629629, 0.87, 1.0, 1.0, 0.6838631508660362, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2989575085785799, 0.2989575085785797, 0.3514815908180836], 
reward next is 0.6485, 
noisyNet noise sample is [array([-0.43548104], dtype=float32), 2.1198153]. 
=============================================
[2019-04-27 21:35:24,616] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.0735386e-28 1.0000000e+00 9.7328656e-31 8.6737386e-25 3.4676606e-31], sum to 1.0000
[2019-04-27 21:35:24,623] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3315
[2019-04-27 21:35:24,629] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.85, 79.0, 1.0, 2.0, 0.6417951382813794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 731433.2501939355, 731433.2501939351, 165416.4292208121], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6340200.0000, 
sim time next is 6340800.0000, 
raw observation next is [27.1, 78.0, 1.0, 2.0, 0.6541449564695797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 745514.7845746785, 745514.7845746785, 167643.1314047589], 
processed observation next is [0.0, 0.391304347826087, 0.5592592592592593, 0.78, 1.0, 1.0, 0.5882678053209283, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2662552802052423, 0.2662552802052423, 0.32239063731684403], 
reward next is 0.6776, 
noisyNet noise sample is [array([-0.14795862], dtype=float32), -1.4828255]. 
=============================================
[2019-04-27 21:35:38,098] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.0904916e-29 1.0000000e+00 1.3647317e-32 1.8064214e-28 2.7492394e-33], sum to 1.0000
[2019-04-27 21:35:38,104] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2392
[2019-04-27 21:35:38,110] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.93333333333334, 50.33333333333334, 1.0, 2.0, 0.7530513754970157, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 914694.4872720413, 914694.4872720409, 188895.5059222113], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5919600.0000, 
sim time next is 5920200.0000, 
raw observation next is [28.1, 49.5, 1.0, 2.0, 0.7268003388940154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 886045.2962024913, 886045.2962024913, 183741.5704642984], 
processed observation next is [1.0, 0.5217391304347826, 0.5962962962962963, 0.495, 1.0, 1.0, 0.6747623082071612, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3164447486437469, 0.3164447486437469, 0.3533491739698046], 
reward next is 0.6467, 
noisyNet noise sample is [array([-0.58926576], dtype=float32), -0.650082]. 
=============================================
[2019-04-27 21:35:45,652] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5052897e-22 1.0000000e+00 5.1935484e-26 4.1731601e-21 7.3720172e-24], sum to 1.0000
[2019-04-27 21:35:45,662] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8909
[2019-04-27 21:35:45,666] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 83.0, 1.0, 2.0, 0.5126235108985875, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 609231.5549521815, 609231.5549521815, 144810.5617840939], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6071400.0000, 
sim time next is 6072000.0000, 
raw observation next is [24.06666666666667, 82.66666666666667, 1.0, 2.0, 0.5718375886006896, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 679337.4781324554, 679337.4781324558, 154532.7647036214], 
processed observation next is [1.0, 0.2608695652173913, 0.4469135802469137, 0.8266666666666667, 1.0, 1.0, 0.49028284357224944, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24262052790444835, 0.24262052790444852, 0.2971783936608104], 
reward next is 0.7028, 
noisyNet noise sample is [array([0.14892215], dtype=float32), -0.4577058]. 
=============================================
[2019-04-27 21:35:45,684] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[57.128483]
 [56.98238 ]
 [56.987694]
 [56.866177]
 [57.03916 ]], R is [[56.99127579]
 [57.1428833 ]
 [57.2905426 ]
 [57.42270279]
 [57.55720139]].
[2019-04-27 21:35:47,929] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.1976937e-27 1.0000000e+00 1.2681743e-32 1.3172889e-26 4.3666770e-31], sum to 1.0000
[2019-04-27 21:35:47,934] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0979
[2019-04-27 21:35:47,943] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2005431.67806378 W.
[2019-04-27 21:35:47,949] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.46666666666667, 52.33333333333333, 1.0, 2.0, 0.8791356172221788, 1.0, 2.0, 0.8791356172221788, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 2005431.67806378, 2005431.678063779, 377538.0620893778], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6100800.0000, 
sim time next is 6101400.0000, 
raw observation next is [30.43333333333333, 52.66666666666667, 1.0, 2.0, 0.8793549627378335, 1.0, 2.0, 0.8793549627378335, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2005932.597917139, 2005932.59791714, 377634.7501725414], 
processed observation next is [1.0, 0.6086956521739131, 0.6827160493827159, 0.5266666666666667, 1.0, 1.0, 0.856374955640278, 1.0, 1.0, 0.856374955640278, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.716404499256121, 0.7164044992561214, 0.7262206734087335], 
reward next is 0.2738, 
noisyNet noise sample is [array([0.1316543], dtype=float32), 0.27331007]. 
=============================================
[2019-04-27 21:35:51,707] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-04-27 21:35:51,708] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 21:35:51,708] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 21:35:51,711] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:35:51,711] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 21:35:51,713] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 21:35:51,712] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 21:35:51,714] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:35:51,713] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:35:51,716] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:35:51,714] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:35:51,736] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run84
[2019-04-27 21:35:51,755] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run84
[2019-04-27 21:35:51,774] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run84
[2019-04-27 21:35:51,775] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run84
[2019-04-27 21:35:51,819] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run84
[2019-04-27 21:36:19,423] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.14112854]
[2019-04-27 21:36:19,424] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.63675090333333, 94.38949014166667, 1.0, 2.0, 0.4159623126503655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 511040.717423538, 511040.717423538, 130784.9482036787]
[2019-04-27 21:36:19,424] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 21:36:19,428] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.4728107e-31 1.0000000e+00 2.3173512e-35 7.1832005e-29 5.2392725e-35], sampled 0.3545641434068587
[2019-04-27 21:36:41,729] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.14112854]
[2019-04-27 21:36:41,730] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [31.3, 67.66666666666667, 1.0, 2.0, 0.7756763180455708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 884101.317397923, 884101.317397923, 190972.8971063178]
[2019-04-27 21:36:41,730] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 21:36:41,733] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.4005492e-31 1.0000000e+00 8.3087275e-36 2.4825613e-29 1.8297804e-35], sampled 0.5458000724866019
[2019-04-27 21:37:01,429] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.14112854]
[2019-04-27 21:37:01,431] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.31070960333333, 61.99764356999999, 1.0, 2.0, 0.7700604147171802, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 906759.9391382448, 906759.9391382448, 191248.2778712585]
[2019-04-27 21:37:01,431] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 21:37:01,434] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.1431615e-28 1.0000000e+00 9.7061604e-33 8.1647681e-27 2.2143672e-32], sampled 0.6762276290693005
[2019-04-27 21:37:15,866] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.14112854]
[2019-04-27 21:37:15,868] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [31.06643842166667, 70.08649307166667, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 7.913489140432787, 6.9112, 121.9223657466605, 2391862.530316252, 1878616.385028493, 380537.2005043503]
[2019-04-27 21:37:15,869] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 21:37:15,873] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.3153419e-24 1.0000000e+00 4.7812684e-28 4.7276507e-23 9.6808920e-28], sampled 0.8066504736807888
[2019-04-27 21:37:15,876] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2391862.530316252 W.
[2019-04-27 21:37:37,002] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.0852 2170656631.3663 493.0000
[2019-04-27 21:37:37,344] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.6127 2195087804.9157 572.0000
[2019-04-27 21:37:37,458] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.1625 2120466133.0938 430.0000
[2019-04-27 21:37:37,545] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8099.9706 2445378853.1784 746.0000
[2019-04-27 21:37:37,546] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8583.7021 2248718286.8236 553.0000
[2019-04-27 21:37:38,564] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 2075000, evaluation results [2075000.0, 8099.970618414005, 2445378853.1783895, 746.0, 8771.085197215923, 2170656631.3662677, 493.0, 8924.162528137549, 2120466133.0938108, 430.0, 8583.702050975664, 2248718286.823596, 553.0, 8701.61270960664, 2195087804.9156528, 572.0]
[2019-04-27 21:37:39,112] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.7251728e-28 1.0000000e+00 4.4126400e-32 2.6132029e-27 8.0631671e-31], sum to 1.0000
[2019-04-27 21:37:39,120] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8472
[2019-04-27 21:37:39,127] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.8, 75.0, 1.0, 2.0, 0.6632009443893638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 755840.7856186043, 755840.7856186043, 169293.4168550111], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6480000.0000, 
sim time next is 6480600.0000, 
raw observation next is [27.71666666666667, 75.5, 1.0, 2.0, 0.6638850341686595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 756620.8179035079, 756620.8179035079, 169418.5746398434], 
processed observation next is [1.0, 0.0, 0.5820987654320988, 0.755, 1.0, 1.0, 0.5998631359150708, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27022172067982425, 0.27022172067982425, 0.3258049512304681], 
reward next is 0.6742, 
noisyNet noise sample is [array([-1.1912371], dtype=float32), -0.72591436]. 
=============================================
[2019-04-27 21:37:47,370] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.4414920e-31 1.0000000e+00 2.5985003e-35 9.8220494e-30 9.0264432e-35], sum to 1.0000
[2019-04-27 21:37:47,380] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9445
[2019-04-27 21:37:47,385] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.7, 84.0, 1.0, 2.0, 0.5676207622377275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 663858.251045723, 663858.251045723, 153390.069447801], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6307200.0000, 
sim time next is 6307800.0000, 
raw observation next is [24.66666666666666, 84.33333333333333, 1.0, 2.0, 0.5676646365629173, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 663814.5876128008, 663814.5876128008, 153393.3632568787], 
processed observation next is [0.0, 0.0, 0.4691358024691356, 0.8433333333333333, 1.0, 1.0, 0.4853150435272825, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23707663843314314, 0.23707663843314314, 0.29498723703245905], 
reward next is 0.7050, 
noisyNet noise sample is [array([-0.8598976], dtype=float32), -0.4783182]. 
=============================================
[2019-04-27 21:37:48,827] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.2893559e-34 1.0000000e+00 3.5909881e-37 1.7994104e-31 0.0000000e+00], sum to 1.0000
[2019-04-27 21:37:48,837] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4074
[2019-04-27 21:37:48,844] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.93333333333333, 74.0, 1.0, 2.0, 0.6629795501798713, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 755588.3413926923, 755588.3413926918, 169252.7824381839], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6478800.0000, 
sim time next is 6479400.0000, 
raw observation next is [27.86666666666667, 74.5, 1.0, 2.0, 0.66256337265155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 755113.7961713052, 755113.7961713048, 169176.7654311855], 
processed observation next is [1.0, 1.0, 0.5876543209876545, 0.745, 1.0, 1.0, 0.5982897293470832, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.269683498632609, 0.2696834986326088, 0.3253399335215105], 
reward next is 0.6747, 
noisyNet noise sample is [array([-1.8693128], dtype=float32), 0.25920814]. 
=============================================
[2019-04-27 21:37:49,029] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.8507230e-31 1.0000000e+00 4.4094194e-35 1.1404523e-28 8.1339669e-33], sum to 1.0000
[2019-04-27 21:37:49,037] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3551
[2019-04-27 21:37:49,040] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 56.0, 1.0, 2.0, 0.6886154639175399, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 784820.1842241301, 784820.1842241301, 174000.4632279169], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6364800.0000, 
sim time next is 6365400.0000, 
raw observation next is [32.0, 55.83333333333334, 1.0, 2.0, 0.677905864892625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 772608.2227392163, 772608.2227392163, 172004.2384542454], 
processed observation next is [0.0, 0.6956521739130435, 0.7407407407407407, 0.5583333333333335, 1.0, 1.0, 0.6165546010626488, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2759315081211487, 0.2759315081211487, 0.33077738164277964], 
reward next is 0.6692, 
noisyNet noise sample is [array([-2.174599], dtype=float32), 0.36853102]. 
=============================================
[2019-04-27 21:37:55,223] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0583468e-25 1.0000000e+00 2.7036823e-28 6.6332371e-24 1.7857378e-27], sum to 1.0000
[2019-04-27 21:37:55,231] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3033
[2019-04-27 21:37:55,243] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1811578.626766495 W.
[2019-04-27 21:37:55,247] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.56666666666667, 59.0, 1.0, 2.0, 0.7942409494417574, 1.0, 2.0, 0.7942409494417574, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1811578.626766495, 1811578.626766495, 341380.7921437183], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6441000.0000, 
sim time next is 6441600.0000, 
raw observation next is [31.73333333333333, 58.00000000000001, 1.0, 2.0, 0.9065417115283956, 1.0, 2.0, 0.9065417115283956, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2068021.213825451, 2068021.213825452, 389746.15496395], 
processed observation next is [1.0, 0.5652173913043478, 0.7308641975308641, 0.5800000000000001, 1.0, 1.0, 0.8887401327718994, 1.0, 1.0, 0.8887401327718994, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.738579004937661, 0.7385790049376614, 0.7495118364691346], 
reward next is 0.2505, 
noisyNet noise sample is [array([0.9428161], dtype=float32), -0.8423395]. 
=============================================
[2019-04-27 21:37:56,802] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.4647559e-21 1.0000000e+00 1.6755024e-23 5.7135097e-20 1.3437187e-22], sum to 1.0000
[2019-04-27 21:37:56,810] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6665
[2019-04-27 21:37:56,816] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.6, 83.5, 1.0, 2.0, 0.9018253614475811, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426022197, 1027980.068838014, 1027980.068838013, 217872.6786687733], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6492600.0000, 
sim time next is 6493200.0000, 
raw observation next is [26.56666666666666, 83.66666666666667, 1.0, 2.0, 0.8810939485090248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156577, 1004333.089517471, 1004333.089517471, 213260.8461819395], 
processed observation next is [1.0, 0.13043478260869565, 0.5395061728395059, 0.8366666666666667, 1.0, 1.0, 0.858445176796458, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201088, 0.3586903891133825, 0.3586903891133825, 0.4101170118883452], 
reward next is 0.5899, 
noisyNet noise sample is [array([1.3582677], dtype=float32), -0.18453227]. 
=============================================
[2019-04-27 21:38:12,011] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.6861237e-29 1.0000000e+00 2.7580392e-35 1.7435853e-28 5.0252424e-33], sum to 1.0000
[2019-04-27 21:38:12,021] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9571
[2019-04-27 21:38:12,026] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.93333333333333, 78.33333333333334, 1.0, 2.0, 0.4374223446472367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 534613.8740519426, 534613.8740519426, 133828.0884666478], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6828000.0000, 
sim time next is 6828600.0000, 
raw observation next is [22.86666666666667, 78.16666666666666, 1.0, 2.0, 0.4332177326816992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 530189.3394483243, 530189.3394483243, 133231.1694607488], 
processed observation next is [0.0, 0.0, 0.4024691358024693, 0.7816666666666666, 1.0, 1.0, 0.3252592055734515, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18935333551725866, 0.18935333551725866, 0.2562137874245169], 
reward next is 0.7438, 
noisyNet noise sample is [array([0.30314466], dtype=float32), 0.24778499]. 
=============================================
[2019-04-27 21:38:14,048] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.9671152e-28 1.0000000e+00 3.5245802e-31 5.8593961e-24 4.3600234e-29], sum to 1.0000
[2019-04-27 21:38:14,054] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7633
[2019-04-27 21:38:14,058] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.71666666666667, 82.33333333333334, 1.0, 2.0, 0.4596261441407749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 574753.5027468394, 574753.5027468394, 137441.8054367985], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7113000.0000, 
sim time next is 7113600.0000, 
raw observation next is [20.7, 82.0, 1.0, 2.0, 0.4115855673059406, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 515088.4594402257, 515088.4594402257, 130365.2713013608], 
processed observation next is [1.0, 0.34782608695652173, 0.3222222222222222, 0.82, 1.0, 1.0, 0.2995066277451674, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18396016408579488, 0.18396016408579488, 0.25070244481030923], 
reward next is 0.7493, 
noisyNet noise sample is [array([-0.05120346], dtype=float32), 0.7058228]. 
=============================================
[2019-04-27 21:38:14,118] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.2790337e-28 1.0000000e+00 1.0563947e-32 2.6468751e-25 5.4097390e-32], sum to 1.0000
[2019-04-27 21:38:14,127] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5419
[2019-04-27 21:38:14,138] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1495703.014565028 W.
[2019-04-27 21:38:14,143] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.55, 48.5, 1.0, 2.0, 0.6432094945775093, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9573168336876513, 6.9112, 6.9112, 121.9256678913788, 1495703.014565028, 1495703.014565028, 296131.8957992466], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6787800.0000, 
sim time next is 6788400.0000, 
raw observation next is [27.66666666666666, 48.33333333333334, 1.0, 2.0, 0.4055417574545185, 1.0, 1.0, 0.4055417574545185, 1.0, 2.0, 0.6523930924217841, 6.911200000000001, 6.9112, 121.94756008, 1450005.51932592, 1450005.519325919, 299268.6148994149], 
processed observation next is [1.0, 0.5652173913043478, 0.5802469135802467, 0.48333333333333345, 1.0, 1.0, 0.2923116160172839, 1.0, 0.5, 0.2923116160172839, 1.0, 1.0, 0.5654913655272301, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5178591140449714, 0.5178591140449711, 0.5755165671142594], 
reward next is 0.4245, 
noisyNet noise sample is [array([-0.6536889], dtype=float32), -0.35176712]. 
=============================================
[2019-04-27 21:38:18,788] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.5468448e-32 1.0000000e+00 2.9942542e-37 1.9309863e-31 1.3304471e-37], sum to 1.0000
[2019-04-27 21:38:18,796] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0792
[2019-04-27 21:38:18,800] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 74.0, 1.0, 2.0, 0.5372088172171822, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 630974.7412826609, 630974.7412826609, 148477.4503091583], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7560000.0000, 
sim time next is 7560600.0000, 
raw observation next is [26.33333333333334, 72.66666666666667, 1.0, 2.0, 0.540629908564869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 633781.2510972472, 633781.2510972472, 148984.7976213914], 
processed observation next is [0.0, 0.5217391304347826, 0.5308641975308644, 0.7266666666666667, 1.0, 1.0, 0.453130843529606, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22635044682044544, 0.22635044682044544, 0.2865092261949834], 
reward next is 0.7135, 
noisyNet noise sample is [array([0.6264276], dtype=float32), -0.80800307]. 
=============================================
[2019-04-27 21:38:20,191] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.4133934e-30 1.0000000e+00 1.4882885e-34 6.8836576e-29 1.8068354e-35], sum to 1.0000
[2019-04-27 21:38:20,200] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3928
[2019-04-27 21:38:20,204] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.9, 96.0, 1.0, 2.0, 0.4377585527517444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 533265.4717438206, 533265.471743821, 133826.8733552294], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7531200.0000, 
sim time next is 7531800.0000, 
raw observation next is [20.9, 96.0, 1.0, 2.0, 0.4374252703043596, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 532859.6530138631, 532859.6530138631, 133777.8860587587], 
processed observation next is [0.0, 0.17391304347826086, 0.32962962962962955, 0.96, 1.0, 1.0, 0.3302681789337614, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19030701893352256, 0.19030701893352256, 0.2572651654976129], 
reward next is 0.7427, 
noisyNet noise sample is [array([0.02121906], dtype=float32), -0.09877154]. 
=============================================
[2019-04-27 21:38:21,107] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.9169737e-28 1.0000000e+00 2.3129807e-34 4.8212484e-29 5.0388497e-34], sum to 1.0000
[2019-04-27 21:38:21,119] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4643
[2019-04-27 21:38:21,124] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.68333333333333, 85.33333333333334, 1.0, 2.0, 0.4230378501635422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 519743.6915571488, 519743.6915571484, 131804.4223390517], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6933000.0000, 
sim time next is 6933600.0000, 
raw observation next is [21.8, 85.0, 1.0, 2.0, 0.4263057827410488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 523189.1246388198, 523189.1246388198, 132263.310878885], 
processed observation next is [0.0, 0.2608695652173913, 0.362962962962963, 0.85, 1.0, 1.0, 0.3170306937393438, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18685325879957848, 0.18685325879957848, 0.2543525209209327], 
reward next is 0.7456, 
noisyNet noise sample is [array([-1.8464208], dtype=float32), 0.38188162]. 
=============================================
[2019-04-27 21:38:24,160] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.0649829e-31 1.0000000e+00 4.3639517e-36 7.3280623e-29 6.8915415e-36], sum to 1.0000
[2019-04-27 21:38:24,171] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2380
[2019-04-27 21:38:24,176] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 49.5, 1.0, 2.0, 0.5712726140773856, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 667550.7551293118, 667550.7551293123, 153979.5547549176], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6963000.0000, 
sim time next is 6963600.0000, 
raw observation next is [31.0, 50.0, 1.0, 2.0, 0.5627000913184996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 656211.5062457508, 656211.5062457508, 152483.7038550086], 
processed observation next is [0.0, 0.6086956521739131, 0.7037037037037037, 0.5, 1.0, 1.0, 0.47940487061726145, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2343612522306253, 0.2343612522306253, 0.29323789202886275], 
reward next is 0.7068, 
noisyNet noise sample is [array([0.7180814], dtype=float32), 0.097694054]. 
=============================================
[2019-04-27 21:38:24,256] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.1815236e-31 1.0000000e+00 3.6585626e-36 6.2937085e-29 5.6967488e-36], sum to 1.0000
[2019-04-27 21:38:24,266] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6598
[2019-04-27 21:38:24,276] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 51.5, 1.0, 2.0, 0.5765040498830505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 668204.6193994812, 668204.6193994812, 154620.1215589724], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6965400.0000, 
sim time next is 6966000.0000, 
raw observation next is [31.0, 52.0, 1.0, 2.0, 0.5822471924000937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 673463.8641686036, 673463.864168604, 155528.9911550448], 
processed observation next is [0.0, 0.6521739130434783, 0.7037037037037037, 0.52, 1.0, 1.0, 0.5026752290477305, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24052280863164413, 0.2405228086316443, 0.2990942137597015], 
reward next is 0.7009, 
noisyNet noise sample is [array([0.7180814], dtype=float32), 0.097694054]. 
=============================================
[2019-04-27 21:38:24,292] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[79.45409]
 [79.42808]
 [79.38916]
 [79.34678]
 [79.28814]], R is [[79.4797821 ]
 [79.38763428]
 [79.29802704]
 [79.21092224]
 [79.12557983]].
[2019-04-27 21:38:27,468] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.6005956e-21 1.0000000e+00 2.3536868e-24 3.3958514e-20 7.6464755e-22], sum to 1.0000
[2019-04-27 21:38:27,476] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3199
[2019-04-27 21:38:27,482] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.65, 82.0, 1.0, 2.0, 0.8216458693522122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1000805.540499863, 1000805.540499863, 203311.4632532453], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7029000.0000, 
sim time next is 7029600.0000, 
raw observation next is [22.83333333333333, 81.33333333333333, 1.0, 2.0, 0.8542419107353447, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1038810.681990577, 1038810.681990577, 210355.0978676282], 
processed observation next is [1.0, 0.34782608695652173, 0.4012345679012344, 0.8133333333333332, 1.0, 1.0, 0.8264784651611247, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.37100381499663465, 0.37100381499663465, 0.4045290343608235], 
reward next is 0.5955, 
noisyNet noise sample is [array([-0.28780445], dtype=float32), 1.8839904]. 
=============================================
[2019-04-27 21:38:27,524] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.1330730e-21 1.0000000e+00 4.8630798e-24 7.5213336e-20 3.5078048e-21], sum to 1.0000
[2019-04-27 21:38:27,536] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1248
[2019-04-27 21:38:27,540] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.01666666666667, 80.66666666666667, 1.0, 2.0, 0.8686843987365739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1054787.728149049, 1054787.728149049, 213504.8998487096], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7030200.0000, 
sim time next is 7030800.0000, 
raw observation next is [23.2, 80.0, 1.0, 2.0, 0.9013134368917247, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9259959713014, 1092843.41677925, 1092843.41677925, 220823.0624745169], 
processed observation next is [1.0, 0.391304347826087, 0.4148148148148148, 0.8, 1.0, 1.0, 0.8825159962996723, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094618191500896, 0.39030122027830355, 0.39030122027830355, 0.4246597355279171], 
reward next is 0.5753, 
noisyNet noise sample is [array([-0.28780445], dtype=float32), 1.8839904]. 
=============================================
[2019-04-27 21:38:31,019] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-04-27 21:38:31,021] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 21:38:31,021] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 21:38:31,021] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:38:31,022] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 21:38:31,022] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:38:31,024] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 21:38:31,026] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 21:38:31,028] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:38:31,029] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:38:31,025] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:38:31,050] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run85
[2019-04-27 21:38:31,051] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run85
[2019-04-27 21:38:31,072] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run85
[2019-04-27 21:38:31,126] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run85
[2019-04-27 21:38:31,151] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run85
[2019-04-27 21:39:02,921] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.14313091]
[2019-04-27 21:39:02,922] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [31.12608063, 32.58526692, 1.0, 2.0, 0.6423292430741556, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 796999.3949365587, 796999.3949365591, 168004.4237615867]
[2019-04-27 21:39:02,924] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 21:39:02,927] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [8.9520496e-31 1.0000000e+00 2.6665022e-35 7.8853512e-29 7.4434403e-35], sampled 0.6335340983028496
[2019-04-27 21:39:18,134] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.14313091]
[2019-04-27 21:39:18,138] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.06666666666667, 84.66666666666666, 1.0, 2.0, 0.5873024311488101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 707265.8140526327, 707265.8140526327, 157528.0518444523]
[2019-04-27 21:39:18,138] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 21:39:18,140] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.2821514e-29 1.0000000e+00 5.6752812e-34 9.6382220e-28 1.5635322e-33], sampled 0.400072745526718
[2019-04-27 21:39:23,733] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.14313091]
[2019-04-27 21:39:23,733] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [32.26666666666667, 60.0, 1.0, 2.0, 0.9957440532818382, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.118438834210047, 6.9112, 121.9250821483902, 1241318.776464621, 1135194.806545955, 239705.7284818091]
[2019-04-27 21:39:23,734] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 21:39:23,737] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [4.1005445e-33 1.0000000e+00 4.7471502e-38 3.9969817e-31 1.2588254e-37], sampled 0.817229101772132
[2019-04-27 21:39:25,085] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.14313091]
[2019-04-27 21:39:25,086] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.5, 79.5, 1.0, 2.0, 0.7782783254103633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 887068.7529335463, 887068.7529335459, 191501.6704932524]
[2019-04-27 21:39:25,088] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 21:39:25,092] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.5780569e-33 1.0000000e+00 1.8479525e-38 2.7382941e-31 1.0644947e-37], sampled 0.4645163298858105
[2019-04-27 21:39:37,255] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.14313091]
[2019-04-27 21:39:37,256] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.20331542333334, 88.90654717666668, 1.0, 2.0, 0.8033291687150257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 915638.3462148795, 915638.3462148795, 196638.3295742725]
[2019-04-27 21:39:37,258] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 21:39:37,260] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.490412e-32 1.000000e+00 7.186899e-37 4.568165e-30 2.890476e-36], sampled 0.9176719258374223
[2019-04-27 21:39:41,638] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.14313091]
[2019-04-27 21:39:41,640] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.65, 89.66666666666667, 1.0, 2.0, 0.5294178172581884, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8489960210820549, 6.911200000000001, 6.9112, 121.9257869267908, 1252382.194603386, 1252382.194603386, 266375.8701371627]
[2019-04-27 21:39:41,641] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 21:39:41,643] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.9271848e-28 1.0000000e+00 1.1632451e-32 1.1593856e-26 3.9797114e-32], sampled 0.9441049625049628
[2019-04-27 21:40:04,600] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.14313091]
[2019-04-27 21:40:04,602] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.0, 87.33333333333334, 1.0, 2.0, 0.6735405702627412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 775405.801936256, 775405.801936256, 171580.9250769065]
[2019-04-27 21:40:04,605] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 21:40:04,607] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.67464276e-30 1.00000000e+00 4.02087807e-34 7.27359125e-28
 1.09060575e-33], sampled 0.2707361037897513
[2019-04-27 21:40:17,937] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.0852 2170656631.3663 493.0000
[2019-04-27 21:40:18,276] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8583.7021 2248718286.8236 553.0000
[2019-04-27 21:40:18,766] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8700.8700 2195155380.8105 572.0000
[2019-04-27 21:40:18,798] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8099.9706 2445378853.1784 746.0000
[2019-04-27 21:40:18,866] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8923.4199 2120533710.1715 430.0000
[2019-04-27 21:40:19,885] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 2100000, evaluation results [2100000.0, 8099.970618414005, 2445378853.1783895, 746.0, 8771.085197215923, 2170656631.3662677, 493.0, 8923.419851553375, 2120533710.171511, 430.0, 8583.702050975664, 2248718286.823596, 553.0, 8700.870031992405, 2195155380.8105125, 572.0]
[2019-04-27 21:40:21,655] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.2492972e-33 1.0000000e+00 0.0000000e+00 4.4588681e-32 0.0000000e+00], sum to 1.0000
[2019-04-27 21:40:21,661] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8172
[2019-04-27 21:40:21,668] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.46666666666667, 86.66666666666667, 1.0, 2.0, 0.3790081806421055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 472419.8146216884, 472419.8146216884, 125760.097313411], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7269600.0000, 
sim time next is 7270200.0000, 
raw observation next is [20.45, 87.0, 1.0, 2.0, 0.377824482356769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 470804.9671626744, 470804.9671626744, 125594.9737258816], 
processed observation next is [1.0, 0.13043478260869565, 0.31296296296296294, 0.87, 1.0, 1.0, 0.25931485994853454, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16814463112952657, 0.16814463112952657, 0.24152879562669538], 
reward next is 0.7585, 
noisyNet noise sample is [array([0.5152878], dtype=float32), -0.9265912]. 
=============================================
[2019-04-27 21:40:25,703] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.4711617e-27 1.0000000e+00 4.3967406e-34 4.4675520e-24 2.2254554e-29], sum to 1.0000
[2019-04-27 21:40:25,717] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1948
[2019-04-27 21:40:25,724] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.7, 93.5, 1.0, 2.0, 0.3741352488826688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 465938.7995226177, 465938.7995226177, 125085.0817495343], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7183800.0000, 
sim time next is 7184400.0000, 
raw observation next is [19.7, 93.33333333333334, 1.0, 2.0, 0.3736977770528331, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 465517.0349470371, 465517.0349470371, 125027.8672305782], 
processed observation next is [1.0, 0.13043478260869565, 0.28518518518518515, 0.9333333333333335, 1.0, 1.0, 0.254402115539087, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1662560839096561, 0.1662560839096561, 0.24043820621265038], 
reward next is 0.7596, 
noisyNet noise sample is [array([-1.218181], dtype=float32), 0.583308]. 
=============================================
[2019-04-27 21:40:27,526] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.2006422e-31 1.0000000e+00 2.6056842e-37 4.4478009e-28 7.8409003e-36], sum to 1.0000
[2019-04-27 21:40:27,535] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1003
[2019-04-27 21:40:27,544] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1758577.614907826 W.
[2019-04-27 21:40:27,546] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.65, 47.5, 1.0, 2.0, 0.749727267992702, 1.0, 1.0, 0.749727267992702, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9250808742337, 1758577.614907826, 1758577.614907826, 325815.8138993171], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7911000.0000, 
sim time next is 7911600.0000, 
raw observation next is [29.8, 47.0, 1.0, 2.0, 0.768003766714326, 0.0, 1.0, 0.0, 1.0, 1.0, 0.972101826809309, 6.911199999999999, 6.9112, 121.9260423223871, 1618458.351672116, 1618458.351672117, 325014.2059096295], 
processed observation next is [1.0, 0.5652173913043478, 0.6592592592592593, 0.47, 1.0, 1.0, 0.7238140079932452, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9651272835116361, -8.881784197001253e-17, 0.0, 0.8094621268730969, 0.5780208398828985, 0.5780208398828989, 0.6250273190569798], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2024826], dtype=float32), -0.8414483]. 
=============================================
[2019-04-27 21:40:30,770] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 21:40:30,770] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:40:30,834] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run11
[2019-04-27 21:40:32,514] A3C_AGENT_WORKER-Thread-22 INFO:Local step 132500, global step 2106142: loss 1.6403
[2019-04-27 21:40:32,516] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 132500, global step 2106143: learning rate 0.0000
[2019-04-27 21:40:33,437] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 21:40:33,438] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:40:33,495] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run11
[2019-04-27 21:40:34,572] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.0315387e-28 1.0000000e+00 8.4167972e-31 1.1777883e-24 2.5674339e-27], sum to 1.0000
[2019-04-27 21:40:34,582] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8430
[2019-04-27 21:40:34,587] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.56666666666667, 95.33333333333333, 1.0, 2.0, 0.3872829305736215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 481852.8108919589, 481852.8108919589, 126884.7502137723], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7361400.0000, 
sim time next is 7362000.0000, 
raw observation next is [19.5, 96.0, 1.0, 2.0, 0.3824758139311042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 475811.9773171494, 475811.977317149, 126218.6865010711], 
processed observation next is [1.0, 0.21739130434782608, 0.2777777777777778, 0.96, 1.0, 1.0, 0.2648521594417907, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16993284904183908, 0.16993284904183892, 0.24272824327129058], 
reward next is 0.7573, 
noisyNet noise sample is [array([0.21828908], dtype=float32), 1.5483974]. 
=============================================
[2019-04-27 21:40:34,598] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[71.30601 ]
 [71.427666]
 [71.47042 ]
 [71.586494]
 [71.63885 ]], R is [[71.31916809]
 [71.36196899]
 [71.40486145]
 [71.44863892]
 [71.49171448]].
[2019-04-27 21:40:35,231] A3C_AGENT_WORKER-Thread-13 INFO:Local step 132500, global step 2107550: loss 1.6477
[2019-04-27 21:40:35,235] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 132500, global step 2107552: learning rate 0.0000
[2019-04-27 21:40:49,166] A3C_AGENT_WORKER-Thread-22 INFO:Local step 133000, global step 2114188: loss 0.0009
[2019-04-27 21:40:49,169] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 133000, global step 2114191: learning rate 0.0000
[2019-04-27 21:40:50,160] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 21:40:50,160] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:40:50,237] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run11
[2019-04-27 21:40:51,877] A3C_AGENT_WORKER-Thread-13 INFO:Local step 133000, global step 2115605: loss 0.0208
[2019-04-27 21:40:51,880] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 133000, global step 2115605: learning rate 0.0000
[2019-04-27 21:40:51,912] A3C_AGENT_WORKER-Thread-3 INFO:Local step 132500, global step 2115622: loss 0.8201
[2019-04-27 21:40:51,920] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 132500, global step 2115623: learning rate 0.0000
[2019-04-27 21:40:58,426] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3351079e-24 1.0000000e+00 1.4791917e-28 6.1010942e-22 1.6940429e-24], sum to 1.0000
[2019-04-27 21:40:58,436] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0864
[2019-04-27 21:40:58,446] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.35, 68.5, 1.0, 2.0, 0.3396336853333465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 431074.0248266142, 431074.0248266142, 120600.3735329521], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7788600.0000, 
sim time next is 7789200.0000, 
raw observation next is [21.4, 68.0, 1.0, 2.0, 0.3315389003896583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 420922.128984884, 420922.128984884, 119550.0104851678], 
processed observation next is [1.0, 0.13043478260869565, 0.3481481481481481, 0.68, 1.0, 1.0, 0.2042129766543551, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1503293317803157, 0.1503293317803157, 0.2299038663176304], 
reward next is 0.7701, 
noisyNet noise sample is [array([-0.32766223], dtype=float32), 0.16346657]. 
=============================================
[2019-04-27 21:40:59,489] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.8242547e-29 1.0000000e+00 5.0344087e-35 2.8142081e-27 4.6634000e-31], sum to 1.0000
[2019-04-27 21:40:59,495] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9363
[2019-04-27 21:40:59,503] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1621215.499903298 W.
[2019-04-27 21:40:59,508] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [37.3, 9.0, 1.0, 2.0, 0.7219995647149272, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9611557051865152, 6.9112, 6.9112, 121.9260426156618, 1621215.499903298, 1621215.499903298, 303485.2629086601], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 144000.0000, 
sim time next is 144600.0000, 
raw observation next is [37.3, 8.5, 1.0, 2.0, 0.457148953051791, 1.0, 1.0, 0.457148953051791, 1.0, 2.0, 0.7591851248438684, 6.9112, 6.9112, 121.94756008, 1701742.595250513, 1701742.595250513, 320879.5913592306], 
processed observation next is [1.0, 0.6956521739130435, 0.9370370370370369, 0.085, 1.0, 1.0, 0.35374875363308456, 1.0, 0.5, 0.35374875363308456, 1.0, 1.0, 0.6989814060548355, 0.0, 0.0, 0.8096049824067558, 0.6077652125894689, 0.6077652125894689, 0.6170761372292896], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2122898], dtype=float32), -0.8582161]. 
=============================================
[2019-04-27 21:40:59,771] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 21:40:59,771] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:40:59,825] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run11
[2019-04-27 21:41:01,559] A3C_AGENT_WORKER-Thread-21 INFO:Local step 132500, global step 2120282: loss 0.6746
[2019-04-27 21:41:01,562] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 132500, global step 2120282: learning rate 0.0000
[2019-04-27 21:41:03,044] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 21:41:03,045] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:41:03,105] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run11
[2019-04-27 21:41:04,672] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 21:41:04,672] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:41:04,713] A3C_AGENT_WORKER-Thread-22 INFO:Local step 133500, global step 2121898: loss 0.0438
[2019-04-27 21:41:04,716] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 133500, global step 2121898: learning rate 0.0000
[2019-04-27 21:41:04,750] A3C_AGENT_WORKER-Thread-9 INFO:Local step 132500, global step 2121912: loss 1.5495
[2019-04-27 21:41:04,753] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 132500, global step 2121912: learning rate 0.0000
[2019-04-27 21:41:04,755] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run11
[2019-04-27 21:41:05,536] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.4195616e-33 1.0000000e+00 2.5425566e-38 3.4937264e-30 4.2921669e-36], sum to 1.0000
[2019-04-27 21:41:05,537] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2004
[2019-04-27 21:41:05,545] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.96666666666667, 64.33333333333334, 1.0, 2.0, 0.4750508168262238, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 573439.3853359406, 573439.3853359402, 139268.5506149639], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7937400.0000, 
sim time next is 7938000.0000, 
raw observation next is [25.8, 65.0, 1.0, 2.0, 0.4726978886126599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 571043.3898741233, 571043.3898741233, 138922.9817274841], 
processed observation next is [1.0, 0.9130434782608695, 0.5111111111111112, 0.65, 1.0, 1.0, 0.3722593912055475, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20394406781218688, 0.20394406781218688, 0.26715958024516173], 
reward next is 0.7328, 
noisyNet noise sample is [array([-1.0704654], dtype=float32), 0.7938993]. 
=============================================
[2019-04-27 21:41:05,564] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[77.38938]
 [77.4026 ]
 [77.30809]
 [77.7076 ]
 [77.73881]], R is [[77.31551361]
 [77.27453613]
 [77.23330688]
 [77.19185638]
 [77.15023041]].
[2019-04-27 21:41:05,597] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 21:41:05,597] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:41:05,656] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run11
[2019-04-27 21:41:05,905] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 21:41:05,906] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:41:05,945] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 21:41:05,947] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:41:05,961] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run11
[2019-04-27 21:41:06,015] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run11
[2019-04-27 21:41:06,119] A3C_AGENT_WORKER-Thread-15 INFO:Local step 132500, global step 2122639: loss 0.4102
[2019-04-27 21:41:06,121] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 132500, global step 2122639: learning rate 0.0000
[2019-04-27 21:41:06,171] A3C_AGENT_WORKER-Thread-13 INFO:Local step 133500, global step 2122675: loss 0.0844
[2019-04-27 21:41:06,173] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 133500, global step 2122675: learning rate 0.0000
[2019-04-27 21:41:06,218] A3C_AGENT_WORKER-Thread-3 INFO:Local step 133000, global step 2122704: loss 0.0010
[2019-04-27 21:41:06,220] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 133000, global step 2122704: learning rate 0.0000
[2019-04-27 21:41:06,286] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 21:41:06,286] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:41:06,326] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run11
[2019-04-27 21:41:06,502] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 21:41:06,503] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:41:06,529] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run11
[2019-04-27 21:41:06,549] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 21:41:06,557] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:41:06,606] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run11
[2019-04-27 21:41:06,638] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 21:41:06,639] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:41:06,662] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run11
[2019-04-27 21:41:06,783] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 21:41:06,784] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:41:06,788] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run11
[2019-04-27 21:41:06,851] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 21:41:06,852] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:41:06,870] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 21:41:06,870] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:41:06,872] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run11
[2019-04-27 21:41:06,918] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run11
[2019-04-27 21:41:07,328] A3C_AGENT_WORKER-Thread-10 INFO:Local step 132500, global step 2123101: loss 0.1881
[2019-04-27 21:41:07,329] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 132500, global step 2123101: learning rate 0.0000
[2019-04-27 21:41:07,562] A3C_AGENT_WORKER-Thread-19 INFO:Local step 132500, global step 2123223: loss 0.9687
[2019-04-27 21:41:07,565] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 132500, global step 2123225: learning rate 0.0000
[2019-04-27 21:41:07,604] A3C_AGENT_WORKER-Thread-17 INFO:Local step 132500, global step 2123250: loss 1.3957
[2019-04-27 21:41:07,607] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 132500, global step 2123250: learning rate 0.0000
[2019-04-27 21:41:07,929] A3C_AGENT_WORKER-Thread-20 INFO:Local step 132500, global step 2123439: loss 0.4658
[2019-04-27 21:41:07,931] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 132500, global step 2123440: learning rate 0.0000
[2019-04-27 21:41:08,209] A3C_AGENT_WORKER-Thread-16 INFO:Local step 132500, global step 2123616: loss 0.0626
[2019-04-27 21:41:08,210] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 132500, global step 2123616: learning rate 0.0000
[2019-04-27 21:41:08,424] A3C_AGENT_WORKER-Thread-14 INFO:Local step 132500, global step 2123730: loss 0.1236
[2019-04-27 21:41:08,427] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 132500, global step 2123730: learning rate 0.0000
[2019-04-27 21:41:08,502] A3C_AGENT_WORKER-Thread-12 INFO:Local step 132500, global step 2123771: loss 0.0389
[2019-04-27 21:41:08,506] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 132500, global step 2123771: learning rate 0.0000
[2019-04-27 21:41:08,768] A3C_AGENT_WORKER-Thread-11 INFO:Local step 132500, global step 2123893: loss 0.9106
[2019-04-27 21:41:08,773] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 132500, global step 2123895: learning rate 0.0000
[2019-04-27 21:41:08,834] A3C_AGENT_WORKER-Thread-18 INFO:Local step 132500, global step 2123926: loss 1.6785
[2019-04-27 21:41:08,838] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 132500, global step 2123927: learning rate 0.0000
[2019-04-27 21:41:08,846] A3C_AGENT_WORKER-Thread-2 INFO:Local step 132500, global step 2123930: loss 1.2974
[2019-04-27 21:41:08,851] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 132500, global step 2123930: learning rate 0.0000
[2019-04-27 21:41:11,179] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-04-27 21:41:11,180] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 21:41:11,181] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 21:41:11,182] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 21:41:11,182] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:41:11,184] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:41:11,187] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 21:41:11,188] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 21:41:11,191] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:41:11,187] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:41:11,192] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:41:11,221] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run86
[2019-04-27 21:41:11,242] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run86
[2019-04-27 21:41:11,267] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run86
[2019-04-27 21:41:11,290] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run86
[2019-04-27 21:41:11,307] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run86
[2019-04-27 21:41:54,820] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.14565124]
[2019-04-27 21:41:54,822] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.67318797, 79.88661779333333, 1.0, 2.0, 0.5242759965839683, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 620409.3168839727, 620409.3168839723, 146573.2886243165]
[2019-04-27 21:41:54,823] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 21:41:54,825] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.2495546e-33 1.0000000e+00 1.9889114e-38 7.2160095e-32 0.0000000e+00], sampled 0.32271303654000094
[2019-04-27 21:42:06,317] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.14565124]
[2019-04-27 21:42:06,318] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [33.0, 71.0, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 7.411628883525729, 6.9112, 123.8632471660072, 2587804.413127759, 2327468.477873302, 443349.4640319061]
[2019-04-27 21:42:06,320] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 21:42:06,327] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.6597938e-27 1.0000000e+00 3.4658355e-31 5.3641155e-26 1.2810453e-31], sampled 0.45849004784297
[2019-04-27 21:42:06,329] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2587804.413127759 W.
[2019-04-27 21:42:11,397] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.14565124]
[2019-04-27 21:42:11,397] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.08333333333334, 82.33333333333333, 1.0, 2.0, 0.603354173769184, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 689511.930302744, 689511.930302744, 158750.2962587411]
[2019-04-27 21:42:11,400] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 21:42:11,403] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.09680866e-31 1.00000000e+00 1.18031385e-35 1.53575249e-29
 4.91667767e-36], sampled 0.16366348759905947
[2019-04-27 21:42:25,311] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.14565124]
[2019-04-27 21:42:25,312] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.88333333333333, 90.16666666666667, 1.0, 2.0, 0.6887497913108003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 784973.3565493103, 784973.3565493098, 174024.7013023535]
[2019-04-27 21:42:25,315] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 21:42:25,318] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.7990183e-32 1.0000000e+00 2.1803554e-37 5.2364056e-31 8.0332052e-38], sampled 0.041569381303727115
[2019-04-27 21:42:29,652] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.14565124]
[2019-04-27 21:42:29,654] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.85601586833333, 58.405110465, 1.0, 2.0, 0.4214392081261235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 517312.498737134, 517312.498737134, 131560.8768034035]
[2019-04-27 21:42:29,656] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 21:42:29,660] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.1493947e-32 1.0000000e+00 1.2796835e-37 3.5870285e-31 4.9063304e-38], sampled 0.42707889672052035
[2019-04-27 21:42:31,245] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.14565124]
[2019-04-27 21:42:31,247] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.0, 94.0, 1.0, 2.0, 0.5425186556098279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 638491.2322460276, 638491.2322460276, 149397.3407123181]
[2019-04-27 21:42:31,248] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 21:42:31,250] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.1569887e-30 1.0000000e+00 2.8325060e-35 2.8354768e-29 1.0602406e-35], sampled 0.05476355942135358
[2019-04-27 21:42:52,201] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.14565124]
[2019-04-27 21:42:52,202] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.17862854666667, 107.5010720666667, 1.0, 2.0, 0.4419839225226141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 541506.9943998617, 541506.9943998617, 134538.0577283654]
[2019-04-27 21:42:52,205] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 21:42:52,208] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.9858091e-33 1.0000000e+00 9.1307750e-38 3.3134120e-31 4.5060476e-38], sampled 0.23591190875610812
[2019-04-27 21:42:57,818] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-04-27 21:42:58,256] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-04-27 21:42:58,582] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-04-27 21:42:58,664] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-04-27 21:42:58,715] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8099.9706 2445378853.1784 746.0000
[2019-04-27 21:42:59,733] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 2125000, evaluation results [2125000.0, 8099.970618414005, 2445378853.1783895, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-04-27 21:43:03,088] A3C_AGENT_WORKER-Thread-21 INFO:Local step 133000, global step 2126610: loss 0.0032
[2019-04-27 21:43:03,091] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 133000, global step 2126612: learning rate 0.0000
[2019-04-27 21:43:03,998] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.2394238e-31 1.0000000e+00 7.0845274e-36 4.1769334e-29 1.1194480e-36], sum to 1.0000
[2019-04-27 21:43:04,006] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4153
[2019-04-27 21:43:04,012] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1572331.786000021 W.
[2019-04-27 21:43:04,018] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [37.4, 15.0, 1.0, 2.0, 0.6995648285111402, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9557910412051369, 6.9112, 6.9112, 121.9260426156618, 1572331.786000021, 1572331.786000021, 304442.2023835517], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 136800.0000, 
sim time next is 137400.0000, 
raw observation next is [37.4, 14.5, 1.0, 2.0, 0.7026563005850626, 1.0, 1.0, 0.7026563005850626, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1714641.260415463, 1714641.260415463, 309945.4579318578], 
processed observation next is [1.0, 0.6086956521739131, 0.9407407407407407, 0.145, 1.0, 1.0, 0.6460194054584079, 1.0, 0.5, 0.6460194054584079, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6123718787198082, 0.6123718787198082, 0.596048957561265], 
reward next is 0.4040, 
noisyNet noise sample is [array([-0.8934474], dtype=float32), 0.75507456]. 
=============================================
[2019-04-27 21:43:06,408] A3C_AGENT_WORKER-Thread-22 INFO:Local step 134000, global step 2128193: loss 0.0168
[2019-04-27 21:43:06,409] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 134000, global step 2128194: learning rate 0.0000
[2019-04-27 21:43:06,499] A3C_AGENT_WORKER-Thread-9 INFO:Local step 133000, global step 2128240: loss 0.0201
[2019-04-27 21:43:06,501] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 133000, global step 2128241: learning rate 0.0000
[2019-04-27 21:43:07,673] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.7368586e-30 1.0000000e+00 4.5002998e-35 5.4353378e-28 9.5547229e-35], sum to 1.0000
[2019-04-27 21:43:07,686] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3448
[2019-04-27 21:43:07,689] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 65.83333333333333, 1.0, 2.0, 0.3294035413151205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 418988.8651334846, 418988.8651334851, 119279.724321584], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 879000.0000, 
sim time next is 879600.0000, 
raw observation next is [21.4, 65.66666666666667, 1.0, 2.0, 0.3254084445679589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 414404.7320090329, 414404.7320090333, 118769.2720458409], 
processed observation next is [0.0, 0.17391304347826086, 0.3481481481481481, 0.6566666666666667, 1.0, 1.0, 0.19691481496185587, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14800169000322605, 0.1480016900032262, 0.22840244624200173], 
reward next is 0.7716, 
noisyNet noise sample is [array([2.5568123], dtype=float32), 0.026276415]. 
=============================================
[2019-04-27 21:43:09,416] A3C_AGENT_WORKER-Thread-15 INFO:Local step 133000, global step 2129631: loss 0.0363
[2019-04-27 21:43:09,419] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 133000, global step 2129632: learning rate 0.0000
[2019-04-27 21:43:09,424] A3C_AGENT_WORKER-Thread-13 INFO:Local step 134000, global step 2129634: loss 0.0199
[2019-04-27 21:43:09,426] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 134000, global step 2129634: learning rate 0.0000
[2019-04-27 21:43:09,856] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.0399028e-31 1.0000000e+00 3.6393932e-37 4.1239088e-30 2.1645340e-38], sum to 1.0000
[2019-04-27 21:43:09,868] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3853
[2019-04-27 21:43:09,874] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.4, 45.33333333333334, 1.0, 2.0, 0.4204080620220236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 517123.7906500443, 517123.7906500443, 131440.1415985631], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 919200.0000, 
sim time next is 919800.0000, 
raw observation next is [28.4, 45.0, 1.0, 2.0, 0.4175386056424212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 514084.2288425536, 514084.2288425536, 131039.3490048871], 
processed observation next is [0.0, 0.6521739130434783, 0.6074074074074074, 0.45, 1.0, 1.0, 0.30659357814573945, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.183601510300912, 0.183601510300912, 0.25199874808632133], 
reward next is 0.7480, 
noisyNet noise sample is [array([-0.26385936], dtype=float32), 0.31206733]. 
=============================================
[2019-04-27 21:43:09,880] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.5198519e-31 1.0000000e+00 9.5321736e-38 3.4367623e-33 2.5562105e-38], sum to 1.0000
[2019-04-27 21:43:09,888] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1827
[2019-04-27 21:43:09,894] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.48333333333333, 15.5, 1.0, 2.0, 0.3848619138747487, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 492886.2030643176, 492886.2030643176, 126705.7155248914], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 234600.0000, 
sim time next is 235200.0000, 
raw observation next is [33.26666666666667, 16.0, 1.0, 2.0, 0.3814577846746978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 488467.9608543933, 488467.9608543938, 126234.5876607838], 
processed observation next is [0.0, 0.7391304347826086, 0.7876543209876545, 0.16, 1.0, 1.0, 0.26364021985083075, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17445284316228332, 0.1744528431622835, 0.24275882242458424], 
reward next is 0.7572, 
noisyNet noise sample is [array([-1.5076479], dtype=float32), -0.22689898]. 
=============================================
[2019-04-27 21:43:09,941] A3C_AGENT_WORKER-Thread-3 INFO:Local step 133500, global step 2129878: loss 1.0648
[2019-04-27 21:43:09,946] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 133500, global step 2129878: learning rate 0.0000
[2019-04-27 21:43:11,992] A3C_AGENT_WORKER-Thread-10 INFO:Local step 133000, global step 2130835: loss 0.0252
[2019-04-27 21:43:11,992] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 133000, global step 2130835: learning rate 0.0000
[2019-04-27 21:43:12,532] A3C_AGENT_WORKER-Thread-19 INFO:Local step 133000, global step 2131098: loss 0.0111
[2019-04-27 21:43:12,534] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 133000, global step 2131098: learning rate 0.0000
[2019-04-27 21:43:12,593] A3C_AGENT_WORKER-Thread-17 INFO:Local step 133000, global step 2131118: loss 0.0013
[2019-04-27 21:43:12,596] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 133000, global step 2131119: learning rate 0.0000
[2019-04-27 21:43:13,091] A3C_AGENT_WORKER-Thread-20 INFO:Local step 133000, global step 2131353: loss 0.0049
[2019-04-27 21:43:13,093] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 133000, global step 2131353: learning rate 0.0000
[2019-04-27 21:43:13,799] A3C_AGENT_WORKER-Thread-16 INFO:Local step 133000, global step 2131688: loss 0.0006
[2019-04-27 21:43:13,801] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 133000, global step 2131688: learning rate 0.0000
[2019-04-27 21:43:13,888] A3C_AGENT_WORKER-Thread-14 INFO:Local step 133000, global step 2131727: loss 0.0018
[2019-04-27 21:43:13,890] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 133000, global step 2131727: learning rate 0.0000
[2019-04-27 21:43:14,155] A3C_AGENT_WORKER-Thread-12 INFO:Local step 133000, global step 2131855: loss 0.0157
[2019-04-27 21:43:14,158] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 133000, global step 2131855: learning rate 0.0000
[2019-04-27 21:43:14,191] A3C_AGENT_WORKER-Thread-18 INFO:Local step 133000, global step 2131870: loss 0.0021
[2019-04-27 21:43:14,192] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 133000, global step 2131870: learning rate 0.0000
[2019-04-27 21:43:14,223] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.1518199e-33 1.0000000e+00 4.9062929e-38 6.9379275e-32 0.0000000e+00], sum to 1.0000
[2019-04-27 21:43:14,233] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6006
[2019-04-27 21:43:14,239] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.21666666666667, 27.66666666666666, 1.0, 2.0, 0.3565305263224004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 452090.0485100799, 452090.0485100794, 122829.0539543142], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 681000.0000, 
sim time next is 681600.0000, 
raw observation next is [30.03333333333333, 28.33333333333334, 1.0, 2.0, 0.3549437989720486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 449969.3936065601, 449969.3936065601, 122616.3635201407], 
processed observation next is [1.0, 0.9130434782608695, 0.6679012345679012, 0.2833333333333334, 1.0, 1.0, 0.2320759511572007, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16070335485948575, 0.16070335485948575, 0.23580069907719364], 
reward next is 0.7642, 
noisyNet noise sample is [array([-0.6337728], dtype=float32), -2.143083]. 
=============================================
[2019-04-27 21:43:14,385] A3C_AGENT_WORKER-Thread-11 INFO:Local step 133000, global step 2131969: loss 0.0030
[2019-04-27 21:43:14,387] A3C_AGENT_WORKER-Thread-2 INFO:Local step 133000, global step 2131970: loss 0.0113
[2019-04-27 21:43:14,388] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 133000, global step 2131970: learning rate 0.0000
[2019-04-27 21:43:14,392] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 133000, global step 2131970: learning rate 0.0000
[2019-04-27 21:43:15,605] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0795779e-27 1.0000000e+00 3.3909632e-32 1.8770568e-27 1.1186733e-32], sum to 1.0000
[2019-04-27 21:43:15,618] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7935
[2019-04-27 21:43:15,627] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1304754.074442327 W.
[2019-04-27 21:43:15,633] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.16666666666667, 37.5, 1.0, 2.0, 0.5331028860879985, 1.0, 1.0, 0.5331028860879985, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.925736819186, 1304754.074442327, 1304754.074442327, 249375.379548398], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 472200.0000, 
sim time next is 472800.0000, 
raw observation next is [29.33333333333334, 37.0, 1.0, 2.0, 0.5189311827432589, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8511702169348971, 6.911199999999999, 6.9112, 121.9260425224154, 1272640.748221528, 1272640.748221528, 260444.2111052393], 
processed observation next is [1.0, 0.4782608695652174, 0.6419753086419755, 0.37, 1.0, 1.0, 0.4272990270753082, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.8139627711686215, -8.881784197001253e-17, 0.0, 0.8094621282010768, 0.45451455293626003, 0.45451455293626003, 0.5008542521254602], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.289616], dtype=float32), -0.5704626]. 
=============================================
[2019-04-27 21:43:18,910] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7249245e-26 1.0000000e+00 7.0732852e-31 1.1764861e-24 4.4111780e-31], sum to 1.0000
[2019-04-27 21:43:18,919] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3629
[2019-04-27 21:43:18,926] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333333, 46.33333333333334, 1.0, 2.0, 0.8275573808543658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1047983.722436666, 1047983.722436666, 205528.0925790938], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1080600.0000, 
sim time next is 1081200.0000, 
raw observation next is [25.46666666666667, 45.66666666666667, 1.0, 2.0, 0.6900406171025352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 873795.9744029912, 873795.9744029912, 177292.632377884], 
processed observation next is [1.0, 0.5217391304347826, 0.4987654320987655, 0.4566666666666667, 1.0, 1.0, 0.6310007346458751, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31206999085821113, 0.31206999085821113, 0.3409473699574692], 
reward next is 0.6591, 
noisyNet noise sample is [array([0.5591433], dtype=float32), 0.33030513]. 
=============================================
[2019-04-27 21:43:19,268] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.3211597e-29 1.0000000e+00 4.0529000e-31 6.3114827e-27 2.0028418e-33], sum to 1.0000
[2019-04-27 21:43:19,273] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0533
[2019-04-27 21:43:19,286] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1377679.688975174 W.
[2019-04-27 21:43:19,288] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.71666666666667, 25.16666666666667, 1.0, 2.0, 0.9270548533378004, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.313902252895346, 6.9112, 121.9243406018567, 1377679.688975174, 1171463.021073956, 228023.8059016564], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 400200.0000, 
sim time next is 400800.0000, 
raw observation next is [30.73333333333333, 25.33333333333334, 1.0, 2.0, 0.5195668928073021, 1.0, 1.0, 0.5195668928073021, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9258001153602, 1297175.818339141, 1297175.818339141, 245589.05698468], 
processed observation next is [1.0, 0.6521739130434783, 0.6938271604938271, 0.2533333333333334, 1.0, 1.0, 0.42805582477059767, 1.0, 0.5, 0.42805582477059767, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094605188703159, 0.4632770779782647, 0.4632770779782647, 0.47228664804746157], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.15299118], dtype=float32), -0.9034036]. 
=============================================
[2019-04-27 21:43:20,014] A3C_AGENT_WORKER-Thread-21 INFO:Local step 133500, global step 2134650: loss 0.0958
[2019-04-27 21:43:20,017] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 133500, global step 2134650: learning rate 0.0000
[2019-04-27 21:43:20,936] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.4877857e-27 1.0000000e+00 1.7786908e-31 2.8183688e-25 2.9721536e-30], sum to 1.0000
[2019-04-27 21:43:20,943] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1880
[2019-04-27 21:43:20,947] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.53333333333333, 63.0, 1.0, 2.0, 0.3867193633809118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 489310.0803654932, 489310.0803654932, 126933.724894175], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 627600.0000, 
sim time next is 628200.0000, 
raw observation next is [22.8, 62.0, 1.0, 2.0, 0.3872971690262406, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 489518.838767883, 489518.838767883, 127008.5429461852], 
processed observation next is [1.0, 0.2608695652173913, 0.4, 0.62, 1.0, 1.0, 0.2705918678883817, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17482815670281537, 0.17482815670281537, 0.24424719797343308], 
reward next is 0.7558, 
noisyNet noise sample is [array([0.40657812], dtype=float32), 2.198873]. 
=============================================
[2019-04-27 21:43:20,972] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.7639679e-30 1.0000000e+00 1.3792951e-35 6.5820768e-29 1.3437669e-34], sum to 1.0000
[2019-04-27 21:43:20,977] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0740
[2019-04-27 21:43:20,988] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333333, 49.66666666666667, 1.0, 2.0, 0.2812480034565267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 360744.083524652, 360744.083524652, 113289.824296186], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 433200.0000, 
sim time next is 433800.0000, 
raw observation next is [23.05, 51.0, 1.0, 2.0, 0.2787998161871898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 357691.9115703003, 357691.9115703003, 112995.7509274331], 
processed observation next is [1.0, 0.0, 0.40925925925925927, 0.51, 1.0, 1.0, 0.14142835260379738, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.12774711127510724, 0.12774711127510724, 0.21729952101429442], 
reward next is 0.7827, 
noisyNet noise sample is [array([0.9060772], dtype=float32), -0.57264614]. 
=============================================
[2019-04-27 21:43:21,046] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.8928085e-27 1.0000000e+00 1.9485084e-31 3.0834458e-25 1.1032953e-29], sum to 1.0000
[2019-04-27 21:43:21,048] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0819
[2019-04-27 21:43:21,060] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.7, 69.0, 1.0, 2.0, 0.2636041792007336, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 339514.0225898687, 339514.0225898687, 111188.3166364702], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 453600.0000, 
sim time next is 454200.0000, 
raw observation next is [20.0, 67.5, 1.0, 2.0, 0.3401558826894251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 437747.5854680617, 437747.5854680617, 120674.7863844145], 
processed observation next is [1.0, 0.2608695652173913, 0.2962962962962963, 0.675, 1.0, 1.0, 0.21447128891598224, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1563384233814506, 0.1563384233814506, 0.2320668968931048], 
reward next is 0.7679, 
noisyNet noise sample is [array([1.3154914], dtype=float32), 0.81785333]. 
=============================================
[2019-04-27 21:43:21,629] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3640312e-29 1.0000000e+00 2.8623170e-31 4.3730227e-26 5.3304625e-32], sum to 1.0000
[2019-04-27 21:43:21,639] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3925
[2019-04-27 21:43:21,643] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.85, 68.33333333333333, 1.0, 2.0, 0.3079863453742018, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 396275.6906325419, 396275.6906325419, 116562.2024900874], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 442200.0000, 
sim time next is 442800.0000, 
raw observation next is [19.7, 69.0, 1.0, 2.0, 0.3004680300315976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 386785.8214356052, 386785.8214356057, 115626.2495167364], 
processed observation next is [1.0, 0.13043478260869565, 0.28518518518518515, 0.69, 1.0, 1.0, 0.16722384527571144, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13813779336985899, 0.13813779336985918, 0.22235817214757], 
reward next is 0.7776, 
noisyNet noise sample is [array([0.76060706], dtype=float32), 0.25951302]. 
=============================================
[2019-04-27 21:43:22,982] A3C_AGENT_WORKER-Thread-22 INFO:Local step 134500, global step 2136064: loss 45.8458
[2019-04-27 21:43:22,984] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 134500, global step 2136064: learning rate 0.0000
[2019-04-27 21:43:23,490] A3C_AGENT_WORKER-Thread-9 INFO:Local step 133500, global step 2136314: loss 0.0202
[2019-04-27 21:43:23,494] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 133500, global step 2136315: learning rate 0.0000
[2019-04-27 21:43:25,978] A3C_AGENT_WORKER-Thread-13 INFO:Local step 134500, global step 2137507: loss 41.6064
[2019-04-27 21:43:25,983] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 134500, global step 2137508: learning rate 0.0000
[2019-04-27 21:43:26,562] A3C_AGENT_WORKER-Thread-15 INFO:Local step 133500, global step 2137793: loss 0.0106
[2019-04-27 21:43:26,565] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 133500, global step 2137793: learning rate 0.0000
[2019-04-27 21:43:26,834] A3C_AGENT_WORKER-Thread-3 INFO:Local step 134000, global step 2137926: loss 0.0178
[2019-04-27 21:43:26,839] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 134000, global step 2137927: learning rate 0.0000
[2019-04-27 21:43:28,818] A3C_AGENT_WORKER-Thread-10 INFO:Local step 133500, global step 2138858: loss 0.0086
[2019-04-27 21:43:28,818] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 133500, global step 2138858: learning rate 0.0000
[2019-04-27 21:43:29,325] A3C_AGENT_WORKER-Thread-17 INFO:Local step 133500, global step 2139098: loss 0.0210
[2019-04-27 21:43:29,326] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 133500, global step 2139098: learning rate 0.0000
[2019-04-27 21:43:29,374] A3C_AGENT_WORKER-Thread-19 INFO:Local step 133500, global step 2139116: loss 0.0585
[2019-04-27 21:43:29,377] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 133500, global step 2139117: learning rate 0.0000
[2019-04-27 21:43:29,890] A3C_AGENT_WORKER-Thread-20 INFO:Local step 133500, global step 2139355: loss 0.0296
[2019-04-27 21:43:29,894] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 133500, global step 2139356: learning rate 0.0000
[2019-04-27 21:43:30,654] A3C_AGENT_WORKER-Thread-16 INFO:Local step 133500, global step 2139727: loss 0.0426
[2019-04-27 21:43:30,656] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 133500, global step 2139728: learning rate 0.0000
[2019-04-27 21:43:30,690] A3C_AGENT_WORKER-Thread-14 INFO:Local step 133500, global step 2139744: loss 0.0345
[2019-04-27 21:43:30,696] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 133500, global step 2139746: learning rate 0.0000
[2019-04-27 21:43:30,961] A3C_AGENT_WORKER-Thread-18 INFO:Local step 133500, global step 2139868: loss 0.0581
[2019-04-27 21:43:30,962] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 133500, global step 2139868: learning rate 0.0000
[2019-04-27 21:43:31,008] A3C_AGENT_WORKER-Thread-12 INFO:Local step 133500, global step 2139890: loss 0.0781
[2019-04-27 21:43:31,014] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 133500, global step 2139891: learning rate 0.0000
[2019-04-27 21:43:31,060] A3C_AGENT_WORKER-Thread-11 INFO:Local step 133500, global step 2139914: loss 0.0326
[2019-04-27 21:43:31,063] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 133500, global step 2139914: learning rate 0.0000
[2019-04-27 21:43:31,249] A3C_AGENT_WORKER-Thread-2 INFO:Local step 133500, global step 2140003: loss 0.0073
[2019-04-27 21:43:31,253] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 133500, global step 2140004: learning rate 0.0000
[2019-04-27 21:43:31,530] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.6571661e-29 1.0000000e+00 2.1037767e-34 5.7983487e-28 1.2009896e-33], sum to 1.0000
[2019-04-27 21:43:31,536] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3449
[2019-04-27 21:43:31,542] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 45.0, 1.0, 2.0, 0.4265774384908095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 521824.0932029079, 521824.0932029075, 132256.6130783901], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 817200.0000, 
sim time next is 817800.0000, 
raw observation next is [29.33333333333334, 43.83333333333334, 1.0, 2.0, 0.4297496797301832, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 525214.684342132, 525214.684342132, 132704.2934745398], 
processed observation next is [0.0, 0.4782608695652174, 0.6419753086419755, 0.4383333333333334, 1.0, 1.0, 0.32113057110736093, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18757667297933284, 0.18757667297933284, 0.255200564374115], 
reward next is 0.7448, 
noisyNet noise sample is [array([-0.22680953], dtype=float32), 0.72533965]. 
=============================================
[2019-04-27 21:43:34,290] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.8611335e-28 1.0000000e+00 3.2545886e-36 3.9966065e-28 3.2651729e-35], sum to 1.0000
[2019-04-27 21:43:34,296] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5002
[2019-04-27 21:43:34,300] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.2, 58.5, 1.0, 2.0, 0.3246328439728607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 411211.0444537684, 411211.0444537684, 118654.5233008022], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 801000.0000, 
sim time next is 801600.0000, 
raw observation next is [23.26666666666667, 58.66666666666666, 1.0, 2.0, 0.3279840193785036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 415059.6748664608, 415059.6748664608, 119080.3052634779], 
processed observation next is [0.0, 0.2608695652173913, 0.41728395061728407, 0.5866666666666666, 1.0, 1.0, 0.1999809754505995, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14823559816659315, 0.14823559816659315, 0.2290005870451498], 
reward next is 0.7710, 
noisyNet noise sample is [array([0.23891614], dtype=float32), 1.8616182]. 
=============================================
[2019-04-27 21:43:36,675] A3C_AGENT_WORKER-Thread-21 INFO:Local step 134000, global step 2142564: loss 0.0043
[2019-04-27 21:43:36,677] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 134000, global step 2142564: learning rate 0.0000
[2019-04-27 21:43:39,423] A3C_AGENT_WORKER-Thread-22 INFO:Local step 135000, global step 2143875: loss 0.1665
[2019-04-27 21:43:39,427] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 135000, global step 2143876: learning rate 0.0000
[2019-04-27 21:43:40,386] A3C_AGENT_WORKER-Thread-9 INFO:Local step 134000, global step 2144340: loss 0.0111
[2019-04-27 21:43:40,388] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 134000, global step 2144340: learning rate 0.0000
[2019-04-27 21:43:42,542] A3C_AGENT_WORKER-Thread-13 INFO:Local step 135000, global step 2145392: loss 0.0864
[2019-04-27 21:43:42,544] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 135000, global step 2145392: learning rate 0.0000
[2019-04-27 21:43:42,602] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1352659e-27 1.0000000e+00 4.5068030e-31 6.7275915e-27 6.5791296e-32], sum to 1.0000
[2019-04-27 21:43:42,608] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5786
[2019-04-27 21:43:42,617] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.53333333333333, 52.66666666666667, 1.0, 2.0, 0.278378856662198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 357700.4883364897, 357700.4883364897, 112942.9616577176], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 951600.0000, 
sim time next is 952200.0000, 
raw observation next is [22.4, 53.0, 1.0, 2.0, 0.2770048396285905, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 356135.8522003017, 356135.8522003017, 112777.5107758631], 
processed observation next is [1.0, 0.0, 0.38518518518518513, 0.53, 1.0, 1.0, 0.13929147574832204, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.12719137578582204, 0.12719137578582204, 0.21687982841512135], 
reward next is 0.7831, 
noisyNet noise sample is [array([-0.10792799], dtype=float32), 0.20043318]. 
=============================================
[2019-04-27 21:43:43,194] A3C_AGENT_WORKER-Thread-15 INFO:Local step 134000, global step 2145699: loss 0.0048
[2019-04-27 21:43:43,197] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 134000, global step 2145699: learning rate 0.0000
[2019-04-27 21:43:43,235] A3C_AGENT_WORKER-Thread-3 INFO:Local step 134500, global step 2145716: loss 137.6609
[2019-04-27 21:43:43,237] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 134500, global step 2145716: learning rate 0.0000
[2019-04-27 21:43:45,738] A3C_AGENT_WORKER-Thread-10 INFO:Local step 134000, global step 2146909: loss 0.0078
[2019-04-27 21:43:45,740] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 134000, global step 2146909: learning rate 0.0000
[2019-04-27 21:43:46,260] A3C_AGENT_WORKER-Thread-19 INFO:Local step 134000, global step 2147153: loss 0.0094
[2019-04-27 21:43:46,262] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 134000, global step 2147153: learning rate 0.0000
[2019-04-27 21:43:46,285] A3C_AGENT_WORKER-Thread-17 INFO:Local step 134000, global step 2147161: loss 0.0063
[2019-04-27 21:43:46,289] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 134000, global step 2147162: learning rate 0.0000
[2019-04-27 21:43:46,819] A3C_AGENT_WORKER-Thread-20 INFO:Local step 134000, global step 2147429: loss 0.0013
[2019-04-27 21:43:46,823] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 134000, global step 2147432: learning rate 0.0000
[2019-04-27 21:43:47,277] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.4375918e-31 1.0000000e+00 4.5939949e-37 2.1760268e-29 1.4977526e-36], sum to 1.0000
[2019-04-27 21:43:47,286] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7596
[2019-04-27 21:43:47,290] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.3, 64.33333333333334, 1.0, 2.0, 0.3659421541361879, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 458111.4296373353, 458111.4296373348, 124017.5790771113], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 897600.0000, 
sim time next is 898200.0000, 
raw observation next is [23.45, 64.0, 1.0, 2.0, 0.3704828104529171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 463277.4087245807, 463277.4087245811, 124623.7059617012], 
processed observation next is [0.0, 0.391304347826087, 0.42407407407407405, 0.64, 1.0, 1.0, 0.25057477434871084, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16545621740163596, 0.1654562174016361, 0.23966097300327152], 
reward next is 0.7603, 
noisyNet noise sample is [array([-0.2771927], dtype=float32), -0.94036514]. 
=============================================
[2019-04-27 21:43:47,493] A3C_AGENT_WORKER-Thread-16 INFO:Local step 134000, global step 2147746: loss 0.0085
[2019-04-27 21:43:47,496] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 134000, global step 2147747: learning rate 0.0000
[2019-04-27 21:43:47,760] A3C_AGENT_WORKER-Thread-11 INFO:Local step 134000, global step 2147878: loss 0.0054
[2019-04-27 21:43:47,763] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 134000, global step 2147880: learning rate 0.0000
[2019-04-27 21:43:47,798] A3C_AGENT_WORKER-Thread-18 INFO:Local step 134000, global step 2147899: loss 0.0020
[2019-04-27 21:43:47,801] A3C_AGENT_WORKER-Thread-14 INFO:Local step 134000, global step 2147900: loss 0.0051
[2019-04-27 21:43:47,804] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 134000, global step 2147900: learning rate 0.0000
[2019-04-27 21:43:47,805] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 134000, global step 2147901: learning rate 0.0000
[2019-04-27 21:43:48,078] A3C_AGENT_WORKER-Thread-12 INFO:Local step 134000, global step 2148025: loss 0.0032
[2019-04-27 21:43:48,080] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 134000, global step 2148026: learning rate 0.0000
[2019-04-27 21:43:48,134] A3C_AGENT_WORKER-Thread-2 INFO:Local step 134000, global step 2148058: loss 0.0013
[2019-04-27 21:43:48,135] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 134000, global step 2148058: learning rate 0.0000
[2019-04-27 21:43:49,210] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.6682464e-35 1.0000000e+00 4.8420929e-37 6.5298015e-31 3.6428222e-38], sum to 1.0000
[2019-04-27 21:43:49,217] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3820
[2019-04-27 21:43:49,221] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.3, 51.33333333333334, 1.0, 2.0, 0.3290477666639587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 417255.702238796, 417255.702238796, 119224.7393516998], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 942000.0000, 
sim time next is 942600.0000, 
raw observation next is [24.2, 51.16666666666666, 1.0, 2.0, 0.3245500724884466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 412058.7820993796, 412058.7820993796, 118651.7229307718], 
processed observation next is [0.0, 0.9130434782608695, 0.45185185185185184, 0.5116666666666666, 1.0, 1.0, 0.1958929434386269, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14716385074977842, 0.14716385074977842, 0.22817639025148423], 
reward next is 0.7718, 
noisyNet noise sample is [array([1.2507578], dtype=float32), -0.26660338]. 
=============================================
[2019-04-27 21:43:52,226] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-04-27 21:43:52,229] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 21:43:52,230] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 21:43:52,231] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 21:43:52,233] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:43:52,231] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:43:52,233] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 21:43:52,233] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:43:52,238] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:43:52,233] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 21:43:52,240] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:43:52,259] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run87
[2019-04-27 21:43:52,281] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run87
[2019-04-27 21:43:52,282] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run87
[2019-04-27 21:43:52,328] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run87
[2019-04-27 21:43:52,355] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run87
[2019-04-27 21:43:55,817] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.14717107]
[2019-04-27 21:43:55,818] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.53333333333333, 41.5, 1.0, 2.0, 0.2631969107847023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 339505.1379254797, 339505.1379254797, 91923.77616648245]
[2019-04-27 21:43:55,819] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 21:43:55,821] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.8947498e-32 1.0000000e+00 6.4046568e-37 1.8040368e-30 4.9440783e-37], sampled 0.8299848775127492
[2019-04-27 21:44:17,607] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.14717107]
[2019-04-27 21:44:17,609] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [20.66666666666667, 96.0, 1.0, 2.0, 0.6666195564187367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 814448.0279717417, 814448.0279717417, 172186.1069366152]
[2019-04-27 21:44:17,610] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 21:44:17,614] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.3364287e-30 1.0000000e+00 2.2800146e-35 3.8665409e-29 2.4719320e-35], sampled 0.23169554686077254
[2019-04-27 21:44:23,722] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.14717107]
[2019-04-27 21:44:23,725] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.8, 39.83333333333334, 1.0, 2.0, 0.9110307718903473, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.104791824746558, 6.9112, 121.9251229067273, 1231798.218088783, 1132662.648579744, 223918.9139325148]
[2019-04-27 21:44:23,727] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 21:44:23,729] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.2508157e-29 1.0000000e+00 2.4101445e-33 1.6551893e-27 2.4109722e-33], sampled 0.6629676847349257
[2019-04-27 21:44:38,003] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.14717107]
[2019-04-27 21:44:38,004] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.30827682666666, 79.22705422666667, 1.0, 2.0, 0.8286696221518963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 944539.313162217, 944539.3131622178, 201941.946675063]
[2019-04-27 21:44:38,005] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 21:44:38,008] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.8533897e-30 1.0000000e+00 5.5573407e-35 7.4072626e-29 5.2445513e-35], sampled 0.8966093006799719
[2019-04-27 21:44:52,251] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.14717107]
[2019-04-27 21:44:52,253] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.85319134, 111.8292429, 1.0, 2.0, 0.5903436015469407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 688870.5292806124, 688870.5292806124, 157183.1545504756]
[2019-04-27 21:44:52,254] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 21:44:52,259] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.7573727e-30 1.0000000e+00 3.1785551e-35 4.7716639e-29 3.0810433e-35], sampled 0.5359263667415137
[2019-04-27 21:44:59,441] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.14717107]
[2019-04-27 21:44:59,443] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.21059015, 103.76046015, 1.0, 2.0, 0.7935295210357025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 904462.0707426126, 904462.0707426126, 194613.574858094]
[2019-04-27 21:44:59,444] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 21:44:59,447] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.0142536e-30 1.0000000e+00 3.8520428e-35 5.4004484e-29 3.2230480e-35], sampled 0.9328078316081241
[2019-04-27 21:45:23,877] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.14717107]
[2019-04-27 21:45:23,879] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.73333333333333, 91.0, 1.0, 2.0, 0.5553667361010637, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 649804.4860388489, 649804.4860388484, 151357.3542492856]
[2019-04-27 21:45:23,881] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 21:45:23,883] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.8965684e-33 1.0000000e+00 4.2628564e-38 2.2333624e-31 4.6775119e-38], sampled 0.20784400116297996
[2019-04-27 21:45:24,211] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.14717107]
[2019-04-27 21:45:24,212] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.1, 61.0, 1.0, 2.0, 0.477452444162532, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 571601.1077584027, 571601.1077584027, 139474.748574163]
[2019-04-27 21:45:24,213] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 21:45:24,216] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.2322528e-33 1.0000000e+00 1.4765119e-38 8.3818366e-32 0.0000000e+00], sampled 0.3863494892566559
[2019-04-27 21:45:25,244] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.14717107]
[2019-04-27 21:45:25,246] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.53719590666666, 85.61220099666667, 1.0, 2.0, 0.43763157005358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 536850.3507372133, 536850.3507372133, 133912.6625827912]
[2019-04-27 21:45:25,247] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 21:45:25,251] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.8966451e-31 1.0000000e+00 2.4861444e-36 5.6183390e-30 1.9721111e-36], sampled 0.523959474076797
[2019-04-27 21:45:29,890] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.14717107]
[2019-04-27 21:45:29,891] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.41666666666667, 84.66666666666667, 1.0, 2.0, 0.6600979212589597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 752302.5783862873, 752302.5783862878, 168727.2071018192]
[2019-04-27 21:45:29,894] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 21:45:29,896] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.6482695e-32 1.0000000e+00 2.4622173e-37 8.4591573e-31 2.1701490e-37], sampled 0.5361076630152941
[2019-04-27 21:45:39,626] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-04-27 21:45:39,767] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.0852 2170656631.3663 493.0000
[2019-04-27 21:45:39,803] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-04-27 21:45:39,930] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-04-27 21:45:39,962] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-04-27 21:45:40,979] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 2150000, evaluation results [2150000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.085197215923, 2170656631.3662677, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-04-27 21:45:42,134] A3C_AGENT_WORKER-Thread-21 INFO:Local step 134500, global step 2150561: loss 67.8076
[2019-04-27 21:45:42,137] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 134500, global step 2150562: learning rate 0.0000
[2019-04-27 21:45:45,000] A3C_AGENT_WORKER-Thread-22 INFO:Local step 135500, global step 2151917: loss 0.0524
[2019-04-27 21:45:45,003] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 135500, global step 2151917: learning rate 0.0000
[2019-04-27 21:45:45,984] A3C_AGENT_WORKER-Thread-9 INFO:Local step 134500, global step 2152394: loss 113.3882
[2019-04-27 21:45:45,986] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 134500, global step 2152395: learning rate 0.0000
[2019-04-27 21:45:48,356] A3C_AGENT_WORKER-Thread-13 INFO:Local step 135500, global step 2153523: loss 0.1488
[2019-04-27 21:45:48,358] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 135500, global step 2153524: learning rate 0.0000
[2019-04-27 21:45:48,728] A3C_AGENT_WORKER-Thread-15 INFO:Local step 134500, global step 2153708: loss 52.0005
[2019-04-27 21:45:48,729] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 134500, global step 2153708: learning rate 0.0000
[2019-04-27 21:45:48,945] A3C_AGENT_WORKER-Thread-3 INFO:Local step 135000, global step 2153814: loss 0.0324
[2019-04-27 21:45:48,949] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 135000, global step 2153815: learning rate 0.0000
[2019-04-27 21:45:51,269] A3C_AGENT_WORKER-Thread-10 INFO:Local step 134500, global step 2154924: loss 81.3984
[2019-04-27 21:45:51,271] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 134500, global step 2154924: learning rate 0.0000
[2019-04-27 21:45:51,643] A3C_AGENT_WORKER-Thread-19 INFO:Local step 134500, global step 2155112: loss 74.7961
[2019-04-27 21:45:51,646] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 134500, global step 2155114: learning rate 0.0000
[2019-04-27 21:45:51,667] A3C_AGENT_WORKER-Thread-17 INFO:Local step 134500, global step 2155120: loss 66.5238
[2019-04-27 21:45:51,668] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 134500, global step 2155120: learning rate 0.0000
[2019-04-27 21:45:52,080] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.0161929e-28 1.0000000e+00 3.1350248e-34 1.7045351e-27 9.8478090e-33], sum to 1.0000
[2019-04-27 21:45:52,091] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8177
[2019-04-27 21:45:52,094] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.86666666666667, 81.83333333333333, 1.0, 2.0, 0.3695342025741535, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 462107.2071783562, 462107.2071783566, 124495.2287621833], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1320600.0000, 
sim time next is 1321200.0000, 
raw observation next is [21.1, 81.0, 1.0, 2.0, 0.3677332372885538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 459138.6487449835, 459138.6487449835, 124238.1400699036], 
processed observation next is [1.0, 0.30434782608695654, 0.3370370370370371, 0.81, 1.0, 1.0, 0.24730147296256402, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1639780888374941, 0.1639780888374941, 0.23891950013443], 
reward next is 0.7611, 
noisyNet noise sample is [array([-1.4920422], dtype=float32), -1.6273634]. 
=============================================
[2019-04-27 21:45:52,346] A3C_AGENT_WORKER-Thread-20 INFO:Local step 134500, global step 2155439: loss 62.5735
[2019-04-27 21:45:52,351] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 134500, global step 2155439: learning rate 0.0000
[2019-04-27 21:45:53,103] A3C_AGENT_WORKER-Thread-11 INFO:Local step 134500, global step 2155797: loss 74.1694
[2019-04-27 21:45:53,106] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 134500, global step 2155798: learning rate 0.0000
[2019-04-27 21:45:53,117] A3C_AGENT_WORKER-Thread-16 INFO:Local step 134500, global step 2155802: loss 74.1306
[2019-04-27 21:45:53,119] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 134500, global step 2155803: learning rate 0.0000
[2019-04-27 21:45:53,245] A3C_AGENT_WORKER-Thread-14 INFO:Local step 134500, global step 2155867: loss 77.0688
[2019-04-27 21:45:53,248] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 134500, global step 2155868: learning rate 0.0000
[2019-04-27 21:45:53,344] A3C_AGENT_WORKER-Thread-18 INFO:Local step 134500, global step 2155909: loss 68.8445
[2019-04-27 21:45:53,347] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 134500, global step 2155909: learning rate 0.0000
[2019-04-27 21:45:53,449] A3C_AGENT_WORKER-Thread-12 INFO:Local step 134500, global step 2155957: loss 70.9599
[2019-04-27 21:45:53,454] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 134500, global step 2155957: learning rate 0.0000
[2019-04-27 21:45:53,559] A3C_AGENT_WORKER-Thread-2 INFO:Local step 134500, global step 2156007: loss 53.1891
[2019-04-27 21:45:53,563] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 134500, global step 2156009: learning rate 0.0000
[2019-04-27 21:45:58,249] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.0063396e-30 1.0000000e+00 1.2121452e-35 2.2758083e-28 3.9911839e-35], sum to 1.0000
[2019-04-27 21:45:58,257] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4645
[2019-04-27 21:45:58,262] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 63.0, 1.0, 2.0, 0.5932034718064171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 682340.0506407066, 682340.0506407066, 157221.1496194667], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2047200.0000, 
sim time next is 2047800.0000, 
raw observation next is [29.05, 63.0, 1.0, 2.0, 0.5948281381996406, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 683537.6413546926, 683537.6413546926, 157467.6369226745], 
processed observation next is [0.0, 0.6956521739130435, 0.6314814814814815, 0.63, 1.0, 1.0, 0.5176525454757627, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2441205861981045, 0.2441205861981045, 0.30282237869745093], 
reward next is 0.6972, 
noisyNet noise sample is [array([2.4951158], dtype=float32), 0.6791166]. 
=============================================
[2019-04-27 21:45:58,895] A3C_AGENT_WORKER-Thread-21 INFO:Local step 135000, global step 2158552: loss 0.2271
[2019-04-27 21:45:58,896] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 135000, global step 2158552: learning rate 0.0000
[2019-04-27 21:46:01,766] A3C_AGENT_WORKER-Thread-22 INFO:Local step 136000, global step 2159909: loss 0.0259
[2019-04-27 21:46:01,769] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 136000, global step 2159910: learning rate 0.0000
[2019-04-27 21:46:02,814] A3C_AGENT_WORKER-Thread-9 INFO:Local step 135000, global step 2160401: loss 0.2025
[2019-04-27 21:46:02,816] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 135000, global step 2160401: learning rate 0.0000
[2019-04-27 21:46:03,873] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.3784154e-33 1.0000000e+00 2.8123051e-37 1.8480808e-29 9.4458476e-37], sum to 1.0000
[2019-04-27 21:46:03,880] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7037
[2019-04-27 21:46:03,886] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.9, 21.0, 1.0, 2.0, 0.3894955942341312, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 489061.5905530727, 489061.5905530727, 127271.9646288523], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1432800.0000, 
sim time next is 1433400.0000, 
raw observation next is [33.91666666666666, 21.33333333333333, 1.0, 2.0, 0.3904776892963361, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 489913.3261845792, 489913.3261845787, 127403.0903846096], 
processed observation next is [0.0, 0.6086956521739131, 0.811728395061728, 0.2133333333333333, 1.0, 1.0, 0.27437820154325726, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17496904506592112, 0.17496904506592095, 0.24500594304732617], 
reward next is 0.7550, 
noisyNet noise sample is [array([-0.9613102], dtype=float32), -1.662284]. 
=============================================
[2019-04-27 21:46:04,894] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4953693e-32 1.0000000e+00 2.3052422e-38 1.3365453e-31 1.7942290e-38], sum to 1.0000
[2019-04-27 21:46:04,906] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2843
[2019-04-27 21:46:04,910] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.18333333333333, 30.33333333333334, 1.0, 2.0, 0.351888994592794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 443238.9488481022, 443238.9488481022, 122178.3775342906], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1419000.0000, 
sim time next is 1419600.0000, 
raw observation next is [30.36666666666667, 29.66666666666667, 1.0, 2.0, 0.3537902271993167, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 445721.8107554903, 445721.8107554903, 122432.1204821631], 
processed observation next is [0.0, 0.43478260869565216, 0.680246913580247, 0.2966666666666667, 1.0, 1.0, 0.23070265142775798, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1591863609841037, 0.1591863609841037, 0.23544638554262134], 
reward next is 0.7646, 
noisyNet noise sample is [array([-1.4671671], dtype=float32), -1.4505528]. 
=============================================
[2019-04-27 21:46:05,013] A3C_AGENT_WORKER-Thread-13 INFO:Local step 136000, global step 2161469: loss 0.1260
[2019-04-27 21:46:05,016] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 136000, global step 2161469: learning rate 0.0000
[2019-04-27 21:46:05,416] A3C_AGENT_WORKER-Thread-15 INFO:Local step 135000, global step 2161660: loss 0.1993
[2019-04-27 21:46:05,420] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 135000, global step 2161661: learning rate 0.0000
[2019-04-27 21:46:05,890] A3C_AGENT_WORKER-Thread-3 INFO:Local step 135500, global step 2161887: loss 0.1116
[2019-04-27 21:46:05,892] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 135500, global step 2161887: learning rate 0.0000
[2019-04-27 21:46:08,024] A3C_AGENT_WORKER-Thread-10 INFO:Local step 135000, global step 2162907: loss 0.1816
[2019-04-27 21:46:08,029] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 135000, global step 2162907: learning rate 0.0000
[2019-04-27 21:46:08,235] A3C_AGENT_WORKER-Thread-17 INFO:Local step 135000, global step 2163013: loss 0.2189
[2019-04-27 21:46:08,237] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 135000, global step 2163013: learning rate 0.0000
[2019-04-27 21:46:08,263] A3C_AGENT_WORKER-Thread-19 INFO:Local step 135000, global step 2163025: loss 0.2042
[2019-04-27 21:46:08,264] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 135000, global step 2163025: learning rate 0.0000
[2019-04-27 21:46:09,163] A3C_AGENT_WORKER-Thread-20 INFO:Local step 135000, global step 2163448: loss 0.1222
[2019-04-27 21:46:09,165] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 135000, global step 2163448: learning rate 0.0000
[2019-04-27 21:46:09,987] A3C_AGENT_WORKER-Thread-16 INFO:Local step 135000, global step 2163842: loss 0.1519
[2019-04-27 21:46:09,989] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 135000, global step 2163842: learning rate 0.0000
[2019-04-27 21:46:10,035] A3C_AGENT_WORKER-Thread-14 INFO:Local step 135000, global step 2163862: loss 0.1145
[2019-04-27 21:46:10,037] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 135000, global step 2163862: learning rate 0.0000
[2019-04-27 21:46:10,085] A3C_AGENT_WORKER-Thread-11 INFO:Local step 135000, global step 2163889: loss 0.0995
[2019-04-27 21:46:10,087] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 135000, global step 2163889: learning rate 0.0000
[2019-04-27 21:46:10,088] A3C_AGENT_WORKER-Thread-18 INFO:Local step 135000, global step 2163889: loss 0.0830
[2019-04-27 21:46:10,097] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 135000, global step 2163891: learning rate 0.0000
[2019-04-27 21:46:10,182] A3C_AGENT_WORKER-Thread-12 INFO:Local step 135000, global step 2163933: loss 0.0664
[2019-04-27 21:46:10,185] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 135000, global step 2163933: learning rate 0.0000
[2019-04-27 21:46:10,209] A3C_AGENT_WORKER-Thread-2 INFO:Local step 135000, global step 2163944: loss 0.0536
[2019-04-27 21:46:10,211] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 135000, global step 2163945: learning rate 0.0000
[2019-04-27 21:46:15,763] A3C_AGENT_WORKER-Thread-21 INFO:Local step 135500, global step 2166604: loss 0.1587
[2019-04-27 21:46:15,765] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 135500, global step 2166604: learning rate 0.0000
[2019-04-27 21:46:18,890] A3C_AGENT_WORKER-Thread-22 INFO:Local step 136500, global step 2168088: loss 0.0217
[2019-04-27 21:46:18,896] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 136500, global step 2168090: learning rate 0.0000
[2019-04-27 21:46:19,468] A3C_AGENT_WORKER-Thread-9 INFO:Local step 135500, global step 2168368: loss 0.0132
[2019-04-27 21:46:19,471] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 135500, global step 2168368: learning rate 0.0000
[2019-04-27 21:46:19,520] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.5957969e-31 1.0000000e+00 9.7459882e-37 4.3561812e-30 3.2864556e-34], sum to 1.0000
[2019-04-27 21:46:19,531] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8799
[2019-04-27 21:46:19,534] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 63.0, 1.0, 2.0, 0.3181550113512155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 404564.438648834, 404564.438648834, 117841.6251642741], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2422800.0000, 
sim time next is 2423400.0000, 
raw observation next is [21.85, 62.83333333333333, 1.0, 2.0, 0.3127259019829188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 398282.6655142977, 398282.6655142977, 117159.28415824], 
processed observation next is [1.0, 0.043478260869565216, 0.36481481481481487, 0.6283333333333333, 1.0, 1.0, 0.1818165499796652, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14224380911224918, 0.14224380911224918, 0.22530631568892306], 
reward next is 0.7747, 
noisyNet noise sample is [array([-0.01314532], dtype=float32), -0.40871224]. 
=============================================
[2019-04-27 21:46:22,165] A3C_AGENT_WORKER-Thread-13 INFO:Local step 136500, global step 2169665: loss 0.0132
[2019-04-27 21:46:22,170] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 136500, global step 2169665: learning rate 0.0000
[2019-04-27 21:46:22,242] A3C_AGENT_WORKER-Thread-15 INFO:Local step 135500, global step 2169700: loss 0.0351
[2019-04-27 21:46:22,246] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 135500, global step 2169700: learning rate 0.0000
[2019-04-27 21:46:22,496] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9325737e-28 1.0000000e+00 1.0463942e-28 2.8658984e-25 1.2161269e-30], sum to 1.0000
[2019-04-27 21:46:22,503] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1514
[2019-04-27 21:46:22,508] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.83333333333334, 67.66666666666667, 1.0, 2.0, 0.5392576405813951, 1.0, 1.0, 0.5392576405813951, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9256963615383, 1283409.953674653, 1283409.953674653, 250169.5840242211], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1768800.0000, 
sim time next is 1769400.0000, 
raw observation next is [24.9, 67.5, 1.0, 2.0, 0.9738139913148879, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.349496764451253, 6.9112, 121.9241948458791, 1402511.349728091, 1178067.633269145, 237766.4787582649], 
processed observation next is [1.0, 0.4782608695652174, 0.47777777777777775, 0.675, 1.0, 1.0, 0.9688261801367712, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.043829676445125275, 0.0, 0.809449861550324, 0.5008969106171753, 0.420738440453266, 0.4572432283812786], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.44634187], dtype=float32), -0.60932964]. 
=============================================
[2019-04-27 21:46:22,681] A3C_AGENT_WORKER-Thread-3 INFO:Local step 136000, global step 2169905: loss 0.0182
[2019-04-27 21:46:22,685] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 136000, global step 2169905: learning rate 0.0000
[2019-04-27 21:46:23,809] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.4435314e-22 1.0000000e+00 5.6070642e-27 2.1643463e-21 3.6026863e-25], sum to 1.0000
[2019-04-27 21:46:23,818] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7514
[2019-04-27 21:46:23,829] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.6, 71.33333333333334, 1.0, 2.0, 0.8026163119941679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9259912919383, 985590.4937552037, 985590.4937552037, 199501.9998354639], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1761600.0000, 
sim time next is 1762200.0000, 
raw observation next is [23.7, 71.0, 1.0, 2.0, 0.8438112084797657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426000119, 1035676.397492775, 1035676.397492775, 208372.078562974], 
processed observation next is [1.0, 0.391304347826087, 0.4333333333333333, 0.71, 1.0, 1.0, 0.8140609624759115, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621287162369, 0.36988442767599106, 0.36988442767599106, 0.4007155356980269], 
reward next is 0.5993, 
noisyNet noise sample is [array([-1.4540877], dtype=float32), 0.41233304]. 
=============================================
[2019-04-27 21:46:24,776] A3C_AGENT_WORKER-Thread-10 INFO:Local step 135500, global step 2170901: loss 0.1585
[2019-04-27 21:46:24,784] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 135500, global step 2170902: learning rate 0.0000
[2019-04-27 21:46:24,981] A3C_AGENT_WORKER-Thread-19 INFO:Local step 135500, global step 2170997: loss 0.2537
[2019-04-27 21:46:24,982] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 135500, global step 2170997: learning rate 0.0000
[2019-04-27 21:46:25,187] A3C_AGENT_WORKER-Thread-17 INFO:Local step 135500, global step 2171097: loss 0.1249
[2019-04-27 21:46:25,189] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 135500, global step 2171097: learning rate 0.0000
[2019-04-27 21:46:25,784] A3C_AGENT_WORKER-Thread-20 INFO:Local step 135500, global step 2171381: loss 0.0696
[2019-04-27 21:46:25,785] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 135500, global step 2171381: learning rate 0.0000
[2019-04-27 21:46:26,618] A3C_AGENT_WORKER-Thread-16 INFO:Local step 135500, global step 2171783: loss 0.0980
[2019-04-27 21:46:26,622] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 135500, global step 2171784: learning rate 0.0000
[2019-04-27 21:46:26,666] A3C_AGENT_WORKER-Thread-14 INFO:Local step 135500, global step 2171806: loss 0.0574
[2019-04-27 21:46:26,672] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 135500, global step 2171807: learning rate 0.0000
[2019-04-27 21:46:26,765] A3C_AGENT_WORKER-Thread-11 INFO:Local step 135500, global step 2171850: loss 0.0435
[2019-04-27 21:46:26,769] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 135500, global step 2171850: learning rate 0.0000
[2019-04-27 21:46:26,831] A3C_AGENT_WORKER-Thread-18 INFO:Local step 135500, global step 2171881: loss 0.0454
[2019-04-27 21:46:26,833] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 135500, global step 2171883: learning rate 0.0000
[2019-04-27 21:46:26,889] A3C_AGENT_WORKER-Thread-12 INFO:Local step 135500, global step 2171905: loss 0.0366
[2019-04-27 21:46:26,890] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 135500, global step 2171905: learning rate 0.0000
[2019-04-27 21:46:26,999] A3C_AGENT_WORKER-Thread-2 INFO:Local step 135500, global step 2171960: loss 0.0536
[2019-04-27 21:46:27,002] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 135500, global step 2171961: learning rate 0.0000
[2019-04-27 21:46:32,503] A3C_AGENT_WORKER-Thread-21 INFO:Local step 136000, global step 2174584: loss 0.0012
[2019-04-27 21:46:32,509] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 136000, global step 2174585: learning rate 0.0000
[2019-04-27 21:46:33,347] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-04-27 21:46:33,347] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 21:46:33,348] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:46:33,348] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 21:46:33,349] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 21:46:33,349] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 21:46:33,350] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 21:46:33,351] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:46:33,354] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:46:33,352] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:46:33,355] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:46:33,377] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run88
[2019-04-27 21:46:33,378] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run88
[2019-04-27 21:46:33,379] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run88
[2019-04-27 21:46:33,379] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run88
[2019-04-27 21:46:33,422] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run88
[2019-04-27 21:46:37,850] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.14868999]
[2019-04-27 21:46:37,851] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.76683422833333, 35.63240246666666, 1.0, 2.0, 0.3069056094537156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 394712.1688478306, 394712.1688478302, 116427.844196647]
[2019-04-27 21:46:37,851] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 21:46:37,854] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.4787629e-32 1.0000000e+00 3.0049415e-37 6.0751711e-31 1.4659336e-37], sampled 0.14320923139862707
[2019-04-27 21:46:52,036] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.14868999]
[2019-04-27 21:46:52,037] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [32.8, 25.66666666666667, 1.0, 2.0, 0.3713093679418087, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 463290.5001542497, 463290.5001542493, 124717.2233148981]
[2019-04-27 21:46:52,038] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 21:46:52,042] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.5433725e-32 1.0000000e+00 1.2214139e-36 1.8436508e-30 5.3782230e-37], sampled 0.6442619939017143
[2019-04-27 21:47:10,336] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.14868999]
[2019-04-27 21:47:10,336] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.0, 62.0, 1.0, 2.0, 0.905107549461496, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1746914.836187199, 1746914.8361872, 358073.322692138]
[2019-04-27 21:47:10,337] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 21:47:10,340] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.5823123e-26 1.0000000e+00 1.5335796e-30 1.9862103e-25 7.9369482e-31], sampled 0.4298186988447348
[2019-04-27 21:47:10,342] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1746914.836187199 W.
[2019-04-27 21:47:47,479] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.14868999]
[2019-04-27 21:47:47,481] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.70883152666666, 89.40664276666666, 1.0, 2.0, 0.5926802158262622, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 682667.9582233914, 682667.9582233914, 157175.7368439063]
[2019-04-27 21:47:47,482] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 21:47:47,485] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [4.4320256e-31 1.0000000e+00 7.8809621e-36 1.0224621e-29 4.9493456e-36], sampled 0.5188878775361292
[2019-04-27 21:47:55,230] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.14868999]
[2019-04-27 21:47:55,232] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.23273905, 77.35017235, 1.0, 2.0, 0.4909937370745493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 589190.5981775054, 589190.5981775054, 141615.6416470403]
[2019-04-27 21:47:55,233] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 21:47:55,235] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.9242968e-29 1.0000000e+00 6.5514736e-34 3.6967221e-28 3.6874576e-34], sampled 0.7576819415413549
[2019-04-27 21:48:00,800] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.14868999]
[2019-04-27 21:48:00,801] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.66234303166667, 55.24345531333334, 1.0, 2.0, 0.6168090264050448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 717487.3732823605, 717487.3732823605, 161686.8931960481]
[2019-04-27 21:48:00,802] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 21:48:00,804] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.9386358e-28 1.0000000e+00 9.1201111e-33 3.1386618e-27 4.9219583e-33], sampled 0.6826926580571415
[2019-04-27 21:48:16,722] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.14868999]
[2019-04-27 21:48:16,724] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.2, 84.0, 1.0, 2.0, 0.915489300444128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.932633391255504, 6.9112, 121.925889803163, 1111694.238688794, 1100718.440427423, 223727.4941547404]
[2019-04-27 21:48:16,725] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 21:48:16,729] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.3064987e-27 1.0000000e+00 7.8211399e-32 2.2945526e-26 6.5722565e-32], sampled 0.6903618042907723
[2019-04-27 21:48:21,041] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-04-27 21:48:21,171] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-04-27 21:48:21,428] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-04-27 21:48:21,471] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-04-27 21:48:21,591] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-04-27 21:48:22,607] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 2175000, evaluation results [2175000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-04-27 21:48:25,042] A3C_AGENT_WORKER-Thread-22 INFO:Local step 137000, global step 2176162: loss 0.0042
[2019-04-27 21:48:25,043] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 137000, global step 2176162: learning rate 0.0000
[2019-04-27 21:48:25,319] A3C_AGENT_WORKER-Thread-9 INFO:Local step 136000, global step 2176296: loss 0.0035
[2019-04-27 21:48:25,321] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 136000, global step 2176297: learning rate 0.0000
[2019-04-27 21:48:26,689] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.3314849e-30 1.0000000e+00 8.7423525e-36 1.1135239e-28 1.7538656e-35], sum to 1.0000
[2019-04-27 21:48:26,697] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1021
[2019-04-27 21:48:26,704] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.26666666666667, 73.33333333333334, 1.0, 2.0, 0.4069130703034758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 500677.0201241608, 500677.0201241603, 129513.195835374], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2020800.0000, 
sim time next is 2021400.0000, 
raw observation next is [23.5, 72.5, 1.0, 2.0, 0.4103744066947488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 504167.8965916109, 504167.8965916104, 129985.5978662684], 
processed observation next is [0.0, 0.391304347826087, 0.42592592592592593, 0.725, 1.0, 1.0, 0.29806476987470093, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18005996306843247, 0.18005996306843228, 0.2499723035889777], 
reward next is 0.7500, 
noisyNet noise sample is [array([-0.6638236], dtype=float32), 1.1028277]. 
=============================================
[2019-04-27 21:48:27,913] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.6206786e-28 1.0000000e+00 2.6830139e-33 1.4300439e-28 3.9107508e-34], sum to 1.0000
[2019-04-27 21:48:27,928] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8679
[2019-04-27 21:48:27,937] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.06666666666667, 86.33333333333333, 1.0, 2.0, 0.414749215886862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 512500.1260645965, 512500.1260645965, 130684.1048587889], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2698800.0000, 
sim time next is 2699400.0000, 
raw observation next is [21.03333333333333, 84.66666666666667, 1.0, 2.0, 0.4036481447708115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 500493.2848324688, 500493.2848324693, 129142.0752542292], 
processed observation next is [0.0, 0.21739130434782608, 0.3345679012345678, 0.8466666666666667, 1.0, 1.0, 0.29005731520334704, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1787476017258817, 0.1787476017258819, 0.24835014471967154], 
reward next is 0.7516, 
noisyNet noise sample is [array([-0.6972591], dtype=float32), 0.68195724]. 
=============================================
[2019-04-27 21:48:28,087] A3C_AGENT_WORKER-Thread-15 INFO:Local step 136000, global step 2177611: loss 0.0006
[2019-04-27 21:48:28,089] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 136000, global step 2177612: learning rate 0.0000
[2019-04-27 21:48:28,632] A3C_AGENT_WORKER-Thread-13 INFO:Local step 137000, global step 2177870: loss 0.0018
[2019-04-27 21:48:28,633] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 137000, global step 2177870: learning rate 0.0000
[2019-04-27 21:48:28,931] A3C_AGENT_WORKER-Thread-3 INFO:Local step 136500, global step 2178018: loss 0.0867
[2019-04-27 21:48:28,935] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 136500, global step 2178019: learning rate 0.0000
[2019-04-27 21:48:29,025] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.5855056e-26 1.0000000e+00 8.3662839e-31 3.5168263e-26 6.7269620e-31], sum to 1.0000
[2019-04-27 21:48:29,037] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2538
[2019-04-27 21:48:29,043] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666667, 93.16666666666667, 1.0, 2.0, 0.602058610235636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 708639.8387568385, 708639.8387568385, 159469.4931400312], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2783400.0000, 
sim time next is 2784000.0000, 
raw observation next is [23.33333333333334, 92.33333333333334, 1.0, 2.0, 0.5919033845115177, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 695883.2625586883, 695883.2625586883, 157674.5175870403], 
processed observation next is [1.0, 0.21739130434782608, 0.4197530864197533, 0.9233333333333335, 1.0, 1.0, 0.5141706958470449, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24852973662810296, 0.24852973662810296, 0.30322022612892363], 
reward next is 0.6968, 
noisyNet noise sample is [array([-0.6967196], dtype=float32), 0.40950826]. 
=============================================
[2019-04-27 21:48:29,052] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[64.57934]
 [64.49438]
 [64.49806]
 [64.30603]
 [63.97722]], R is [[64.63873291]
 [64.68567657]
 [64.73641968]
 [64.77843475]
 [64.8146286 ]].
[2019-04-27 21:48:30,652] A3C_AGENT_WORKER-Thread-10 INFO:Local step 136000, global step 2178836: loss 0.0578
[2019-04-27 21:48:30,654] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 136000, global step 2178837: learning rate 0.0000
[2019-04-27 21:48:30,794] A3C_AGENT_WORKER-Thread-19 INFO:Local step 136000, global step 2178909: loss 0.0291
[2019-04-27 21:48:30,798] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 136000, global step 2178910: learning rate 0.0000
[2019-04-27 21:48:30,846] A3C_AGENT_WORKER-Thread-17 INFO:Local step 136000, global step 2178935: loss 0.0060
[2019-04-27 21:48:30,848] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 136000, global step 2178935: learning rate 0.0000
[2019-04-27 21:48:31,818] A3C_AGENT_WORKER-Thread-20 INFO:Local step 136000, global step 2179406: loss 0.0338
[2019-04-27 21:48:31,822] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 136000, global step 2179406: learning rate 0.0000
[2019-04-27 21:48:32,443] A3C_AGENT_WORKER-Thread-16 INFO:Local step 136000, global step 2179695: loss 0.0528
[2019-04-27 21:48:32,444] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 136000, global step 2179696: learning rate 0.0000
[2019-04-27 21:48:32,641] A3C_AGENT_WORKER-Thread-11 INFO:Local step 136000, global step 2179788: loss 0.0011
[2019-04-27 21:48:32,643] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 136000, global step 2179788: learning rate 0.0000
[2019-04-27 21:48:32,689] A3C_AGENT_WORKER-Thread-14 INFO:Local step 136000, global step 2179812: loss 0.0020
[2019-04-27 21:48:32,691] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 136000, global step 2179812: learning rate 0.0000
[2019-04-27 21:48:32,715] A3C_AGENT_WORKER-Thread-18 INFO:Local step 136000, global step 2179822: loss 0.0068
[2019-04-27 21:48:32,721] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 136000, global step 2179826: learning rate 0.0000
[2019-04-27 21:48:32,803] A3C_AGENT_WORKER-Thread-2 INFO:Local step 136000, global step 2179864: loss 0.0053
[2019-04-27 21:48:32,805] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 136000, global step 2179864: learning rate 0.0000
[2019-04-27 21:48:32,887] A3C_AGENT_WORKER-Thread-12 INFO:Local step 136000, global step 2179901: loss 0.0044
[2019-04-27 21:48:32,888] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 136000, global step 2179901: learning rate 0.0000
[2019-04-27 21:48:35,354] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.3230564e-25 1.0000000e+00 4.4025753e-29 2.2486223e-23 1.3226191e-29], sum to 1.0000
[2019-04-27 21:48:35,362] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7729
[2019-04-27 21:48:35,366] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.7, 85.5, 1.0, 2.0, 0.3516123815953018, 1.0, 1.0, 0.3516123815953018, 1.0, 1.0, 0.5603611255054818, 6.911199999999999, 6.9112, 121.94756008, 1216908.03937534, 1216908.039375341, 276588.2335114465], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2287800.0000, 
sim time next is 2288400.0000, 
raw observation next is [23.8, 85.0, 1.0, 2.0, 0.9601716189770386, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.089610874821409, 6.9112, 121.9252384080163, 1221207.349611499, 1129845.63813333, 233113.8948281321], 
processed observation next is [1.0, 0.4782608695652174, 0.43703703703703706, 0.85, 1.0, 1.0, 0.9525852606869507, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.01784108748214086, 0.0, 0.8094567897176869, 0.4361454820041068, 0.40351629933333216, 0.4482959515925617], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2142259], dtype=float32), 0.88596433]. 
=============================================
[2019-04-27 21:48:38,822] A3C_AGENT_WORKER-Thread-21 INFO:Local step 136500, global step 2182726: loss 0.0572
[2019-04-27 21:48:38,823] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 136500, global step 2182727: learning rate 0.0000
[2019-04-27 21:48:42,121] A3C_AGENT_WORKER-Thread-22 INFO:Local step 137500, global step 2184304: loss 0.2581
[2019-04-27 21:48:42,121] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 137500, global step 2184304: learning rate 0.0000
[2019-04-27 21:48:42,150] A3C_AGENT_WORKER-Thread-9 INFO:Local step 136500, global step 2184312: loss 0.1427
[2019-04-27 21:48:42,151] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 136500, global step 2184312: learning rate 0.0000
[2019-04-27 21:48:45,037] A3C_AGENT_WORKER-Thread-15 INFO:Local step 136500, global step 2185684: loss 0.0710
[2019-04-27 21:48:45,041] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 136500, global step 2185685: learning rate 0.0000
[2019-04-27 21:48:45,756] A3C_AGENT_WORKER-Thread-3 INFO:Local step 137000, global step 2186030: loss 0.0082
[2019-04-27 21:48:45,760] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 137000, global step 2186031: learning rate 0.0000
[2019-04-27 21:48:45,773] A3C_AGENT_WORKER-Thread-13 INFO:Local step 137500, global step 2186037: loss 0.2040
[2019-04-27 21:48:45,774] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 137500, global step 2186037: learning rate 0.0000
[2019-04-27 21:48:47,408] A3C_AGENT_WORKER-Thread-10 INFO:Local step 136500, global step 2186824: loss 0.2188
[2019-04-27 21:48:47,414] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 136500, global step 2186825: learning rate 0.0000
[2019-04-27 21:48:47,518] A3C_AGENT_WORKER-Thread-19 INFO:Local step 136500, global step 2186879: loss 0.1775
[2019-04-27 21:48:47,519] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 136500, global step 2186879: learning rate 0.0000
[2019-04-27 21:48:47,616] A3C_AGENT_WORKER-Thread-17 INFO:Local step 136500, global step 2186922: loss 0.1147
[2019-04-27 21:48:47,621] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 136500, global step 2186926: learning rate 0.0000
[2019-04-27 21:48:47,668] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.08995243e-25 1.00000000e+00 1.00485744e-28 1.65345170e-22
 1.42194342e-29], sum to 1.0000
[2019-04-27 21:48:47,676] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9933
[2019-04-27 21:48:47,685] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.8, 52.00000000000001, 1.0, 2.0, 0.3740782967175675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 466789.5037554429, 466789.5037554429, 125095.2281408949], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2510400.0000, 
sim time next is 2511000.0000, 
raw observation next is [25.7, 52.5, 1.0, 2.0, 0.3740608859485603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 466770.3559294539, 466770.3559294543, 125092.9007008643], 
processed observation next is [1.0, 0.043478260869565216, 0.5074074074074074, 0.525, 1.0, 1.0, 0.2548343880340004, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16670369854623354, 0.16670369854623368, 0.24056327057858518], 
reward next is 0.7594, 
noisyNet noise sample is [array([0.29314208], dtype=float32), 0.25397277]. 
=============================================
[2019-04-27 21:48:47,696] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[60.665985]
 [60.97102 ]
 [61.20689 ]
 [61.30174 ]
 [61.759182]], R is [[60.72878265]
 [60.88092804]
 [61.03139114]
 [61.18003082]
 [61.32674026]].
[2019-04-27 21:48:48,629] A3C_AGENT_WORKER-Thread-20 INFO:Local step 136500, global step 2187404: loss 0.1261
[2019-04-27 21:48:48,631] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 136500, global step 2187404: learning rate 0.0000
[2019-04-27 21:48:49,262] A3C_AGENT_WORKER-Thread-16 INFO:Local step 136500, global step 2187696: loss 0.0820
[2019-04-27 21:48:49,264] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 136500, global step 2187696: learning rate 0.0000
[2019-04-27 21:48:49,332] A3C_AGENT_WORKER-Thread-14 INFO:Local step 136500, global step 2187729: loss 0.1517
[2019-04-27 21:48:49,337] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 136500, global step 2187729: learning rate 0.0000
[2019-04-27 21:48:49,419] A3C_AGENT_WORKER-Thread-11 INFO:Local step 136500, global step 2187766: loss 0.1534
[2019-04-27 21:48:49,420] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 136500, global step 2187767: learning rate 0.0000
[2019-04-27 21:48:49,525] A3C_AGENT_WORKER-Thread-2 INFO:Local step 136500, global step 2187816: loss 0.1331
[2019-04-27 21:48:49,526] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 136500, global step 2187817: learning rate 0.0000
[2019-04-27 21:48:49,600] A3C_AGENT_WORKER-Thread-12 INFO:Local step 136500, global step 2187854: loss 0.2157
[2019-04-27 21:48:49,603] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 136500, global step 2187854: learning rate 0.0000
[2019-04-27 21:48:49,616] A3C_AGENT_WORKER-Thread-18 INFO:Local step 136500, global step 2187860: loss 0.1235
[2019-04-27 21:48:49,617] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 136500, global step 2187860: learning rate 0.0000
[2019-04-27 21:48:52,494] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3001530e-22 1.0000000e+00 1.2110335e-24 9.9262433e-21 1.9502619e-25], sum to 1.0000
[2019-04-27 21:48:52,498] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6858
[2019-04-27 21:48:52,512] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1490571.189726881 W.
[2019-04-27 21:48:52,519] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [33.95, 23.5, 1.0, 2.0, 0.6354884425007004, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9562317051071282, 6.9112, 6.9112, 121.9260426156618, 1490571.189726881, 1490571.189726881, 293678.232696486], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2464200.0000, 
sim time next is 2464800.0000, 
raw observation next is [34.06666666666666, 23.33333333333333, 1.0, 2.0, 0.5150427284596735, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8432835276196957, 6.9112, 6.9112, 121.9260426156618, 1260625.831618571, 1260625.831618571, 259231.0922136954], 
processed observation next is [1.0, 0.5217391304347826, 0.8172839506172838, 0.23333333333333328, 1.0, 1.0, 0.4226699148329446, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8041044095246197, 0.0, 0.0, 0.8094621288201359, 0.4502235112923468, 0.4502235112923468, 0.4985213311801835], 
reward next is 0.5015, 
noisyNet noise sample is [array([0.11066675], dtype=float32), -0.46659708]. 
=============================================
[2019-04-27 21:48:55,138] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.5341517e-24 1.0000000e+00 1.0158417e-28 6.9398915e-23 2.0946224e-28], sum to 1.0000
[2019-04-27 21:48:55,147] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5095
[2019-04-27 21:48:55,160] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1543217.924123429 W.
[2019-04-27 21:48:55,165] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.40000000000001, 30.0, 1.0, 2.0, 0.6425211728751621, 1.0, 2.0, 0.6425211728751621, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1543217.924123429, 1543217.924123429, 286421.7842554185], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2547600.0000, 
sim time next is 2548200.0000, 
raw observation next is [32.5, 30.0, 1.0, 2.0, 0.6483938841104416, 1.0, 2.0, 0.6483938841104416, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1558333.288602389, 1558333.288602389, 288608.7161107429], 
processed observation next is [1.0, 0.4782608695652174, 0.7592592592592593, 0.3, 1.0, 1.0, 0.5814212906076686, 1.0, 1.0, 0.5814212906076686, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5565476030722818, 0.5565476030722818, 0.5550167617514287], 
reward next is 0.4450, 
noisyNet noise sample is [array([1.6492357], dtype=float32), -0.18352062]. 
=============================================
[2019-04-27 21:48:55,482] A3C_AGENT_WORKER-Thread-21 INFO:Local step 137000, global step 2190661: loss 0.0118
[2019-04-27 21:48:55,484] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 137000, global step 2190661: learning rate 0.0000
[2019-04-27 21:48:56,665] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2255621e-30 1.0000000e+00 9.5116749e-33 8.1365013e-28 6.7736077e-35], sum to 1.0000
[2019-04-27 21:48:56,673] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9258
[2019-04-27 21:48:56,679] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.83333333333334, 40.16666666666666, 1.0, 2.0, 0.4756446973415326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 569371.4441434431, 569371.4441434427, 139195.6147071548], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2571000.0000, 
sim time next is 2571600.0000, 
raw observation next is [31.56666666666667, 41.33333333333334, 1.0, 2.0, 0.4800587950808564, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 574221.8983990037, 574221.8983990037, 139857.1430373239], 
processed observation next is [1.0, 0.782608695652174, 0.7246913580246915, 0.41333333333333344, 1.0, 1.0, 0.3810223750962577, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2050792494282156, 0.2050792494282156, 0.26895604430254594], 
reward next is 0.7310, 
noisyNet noise sample is [array([-1.0145818], dtype=float32), 0.20323911]. 
=============================================
[2019-04-27 21:48:58,709] A3C_AGENT_WORKER-Thread-9 INFO:Local step 137000, global step 2192198: loss 0.0006
[2019-04-27 21:48:58,712] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 137000, global step 2192199: learning rate 0.0000
[2019-04-27 21:48:58,714] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.9996724e-30 1.0000000e+00 9.6288530e-35 6.7230763e-27 1.1323770e-34], sum to 1.0000
[2019-04-27 21:48:58,729] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0467
[2019-04-27 21:48:58,735] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.73333333333333, 93.33333333333334, 1.0, 2.0, 0.5307454941935716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 629505.7521772458, 629505.7521772454, 147674.923468966], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3310800.0000, 
sim time next is 3311400.0000, 
raw observation next is [22.91666666666667, 91.66666666666666, 1.0, 2.0, 0.5283611796627021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 626987.9529033051, 626987.9529033051, 147300.6103292744], 
processed observation next is [0.0, 0.30434782608695654, 0.4043209876543212, 0.9166666666666665, 1.0, 1.0, 0.4385252138841692, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22392426889403752, 0.22392426889403752, 0.28327040447937385], 
reward next is 0.7167, 
noisyNet noise sample is [array([0.6827211], dtype=float32), 0.96533036]. 
=============================================
[2019-04-27 21:48:58,769] A3C_AGENT_WORKER-Thread-22 INFO:Local step 138000, global step 2192226: loss 0.0105
[2019-04-27 21:48:58,774] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 138000, global step 2192226: learning rate 0.0000
[2019-04-27 21:49:01,588] A3C_AGENT_WORKER-Thread-15 INFO:Local step 137000, global step 2193578: loss 0.0151
[2019-04-27 21:49:01,590] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 137000, global step 2193578: learning rate 0.0000
[2019-04-27 21:49:02,627] A3C_AGENT_WORKER-Thread-13 INFO:Local step 138000, global step 2194081: loss 0.0036
[2019-04-27 21:49:02,630] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 138000, global step 2194082: learning rate 0.0000
[2019-04-27 21:49:02,828] A3C_AGENT_WORKER-Thread-3 INFO:Local step 137500, global step 2194174: loss 0.1068
[2019-04-27 21:49:02,831] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 137500, global step 2194175: learning rate 0.0000
[2019-04-27 21:49:04,121] A3C_AGENT_WORKER-Thread-10 INFO:Local step 137000, global step 2194805: loss 0.0010
[2019-04-27 21:49:04,123] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 137000, global step 2194805: learning rate 0.0000
[2019-04-27 21:49:04,234] A3C_AGENT_WORKER-Thread-17 INFO:Local step 137000, global step 2194860: loss 0.0076
[2019-04-27 21:49:04,236] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 137000, global step 2194860: learning rate 0.0000
[2019-04-27 21:49:04,263] A3C_AGENT_WORKER-Thread-19 INFO:Local step 137000, global step 2194872: loss 0.0006
[2019-04-27 21:49:04,265] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 137000, global step 2194873: learning rate 0.0000
[2019-04-27 21:49:04,608] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3790641e-27 1.0000000e+00 2.1316238e-33 3.9829088e-28 2.9610218e-35], sum to 1.0000
[2019-04-27 21:49:04,617] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8041
[2019-04-27 21:49:04,625] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 95.0, 1.0, 2.0, 0.5562835667111733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 653352.4441937996, 653352.4441937996, 151614.2824598191], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2681400.0000, 
sim time next is 2682000.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.5489646878266121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 646354.8074278297, 646354.8074278297, 150468.9682860523], 
processed observation next is [0.0, 0.043478260869565216, 0.4074074074074074, 0.94, 1.0, 1.0, 0.46305319979358583, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23084100265279633, 0.23084100265279633, 0.28936340055010057], 
reward next is 0.7106, 
noisyNet noise sample is [array([1.7369547], dtype=float32), 3.0113323]. 
=============================================
[2019-04-27 21:49:04,645] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[71.02615 ]
 [70.73157 ]
 [70.38607 ]
 [69.838005]
 [69.51031 ]], R is [[71.27942657]
 [71.27507019]
 [71.26878357]
 [71.26100922]
 [71.25183868]].
[2019-04-27 21:49:05,328] A3C_AGENT_WORKER-Thread-20 INFO:Local step 137000, global step 2195371: loss 0.0006
[2019-04-27 21:49:05,331] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 137000, global step 2195372: learning rate 0.0000
[2019-04-27 21:49:06,129] A3C_AGENT_WORKER-Thread-16 INFO:Local step 137000, global step 2195752: loss 0.0114
[2019-04-27 21:49:06,130] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 137000, global step 2195752: learning rate 0.0000
[2019-04-27 21:49:06,162] A3C_AGENT_WORKER-Thread-14 INFO:Local step 137000, global step 2195765: loss 0.0109
[2019-04-27 21:49:06,169] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 137000, global step 2195766: learning rate 0.0000
[2019-04-27 21:49:06,193] A3C_AGENT_WORKER-Thread-11 INFO:Local step 137000, global step 2195779: loss 0.0010
[2019-04-27 21:49:06,195] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 137000, global step 2195781: learning rate 0.0000
[2019-04-27 21:49:06,276] A3C_AGENT_WORKER-Thread-12 INFO:Local step 137000, global step 2195820: loss 0.0013
[2019-04-27 21:49:06,280] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 137000, global step 2195821: learning rate 0.0000
[2019-04-27 21:49:06,297] A3C_AGENT_WORKER-Thread-18 INFO:Local step 137000, global step 2195829: loss 0.0033
[2019-04-27 21:49:06,300] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 137000, global step 2195829: learning rate 0.0000
[2019-04-27 21:49:06,374] A3C_AGENT_WORKER-Thread-2 INFO:Local step 137000, global step 2195862: loss 0.0199
[2019-04-27 21:49:06,377] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 137000, global step 2195862: learning rate 0.0000
[2019-04-27 21:49:12,564] A3C_AGENT_WORKER-Thread-21 INFO:Local step 137500, global step 2198851: loss 1.1830
[2019-04-27 21:49:12,566] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 137500, global step 2198852: learning rate 0.0000
[2019-04-27 21:49:12,614] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.180952e-22 1.000000e+00 6.233985e-25 1.393325e-20 8.178715e-24], sum to 1.0000
[2019-04-27 21:49:12,621] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2836
[2019-04-27 21:49:12,627] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.06666666666667, 84.66666666666667, 1.0, 2.0, 0.5123284281197534, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 615583.6811216474, 615583.6811216474, 145007.3634543359], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3558000.0000, 
sim time next is 3558600.0000, 
raw observation next is [23.1, 82.5, 1.0, 2.0, 0.4951853033610343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 597636.1841620754, 597636.1841620754, 142386.3215946755], 
processed observation next is [1.0, 0.17391304347826086, 0.41111111111111115, 0.825, 1.0, 1.0, 0.3990301230488503, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21344149434359835, 0.21344149434359835, 0.2738198492205298], 
reward next is 0.7262, 
noisyNet noise sample is [array([-2.5279653], dtype=float32), -0.31665492]. 
=============================================
[2019-04-27 21:49:12,789] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.2232922e-21 1.0000000e+00 1.8596481e-24 1.6371040e-20 1.0406039e-25], sum to 1.0000
[2019-04-27 21:49:12,796] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7137
[2019-04-27 21:49:12,802] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1934198.963358859 W.
[2019-04-27 21:49:12,807] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.25, 83.0, 1.0, 2.0, 0.5652951712833417, 1.0, 2.0, 0.5652951712833417, 1.0, 2.0, 0.8999683230615133, 6.911200000000001, 6.9112, 121.94756008, 1934198.963358859, 1934198.963358858, 376791.1148419406], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3493800.0000, 
sim time next is 3494400.0000, 
raw observation next is [27.33333333333334, 81.0, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 7.158169872684875, 6.9112, 121.9249499691121, 2004679.048610937, 1878209.533252815, 383248.1046121641], 
processed observation next is [1.0, 0.43478260869565216, 0.5679012345679014, 0.81, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 0.024696987268487458, 0.0, 0.8094548747833183, 0.7159568030753347, 0.6707891190188625, 0.7370155857926233], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.67926824], dtype=float32), 1.3820953]. 
=============================================
[2019-04-27 21:49:14,844] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-04-27 21:49:14,845] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 21:49:14,846] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:49:14,846] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 21:49:14,846] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 21:49:14,847] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:49:14,847] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 21:49:14,847] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:49:14,849] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 21:49:14,851] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:49:14,852] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:49:14,882] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run89
[2019-04-27 21:49:14,883] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run89
[2019-04-27 21:49:14,926] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run89
[2019-04-27 21:49:14,947] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run89
[2019-04-27 21:49:14,968] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run89
[2019-04-27 21:49:16,873] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.14990485]
[2019-04-27 21:49:16,875] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.64994369, 46.86142576, 1.0, 2.0, 0.3303802082029677, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 417215.5634027979, 417215.5634027979, 119378.9719627113]
[2019-04-27 21:49:16,876] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 21:49:16,878] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.9786222e-31 1.0000000e+00 2.0114152e-35 2.2258970e-29 1.3099517e-35], sampled 0.09657517265274818
[2019-04-27 21:49:20,681] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.14990485]
[2019-04-27 21:49:20,682] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.6, 54.33333333333334, 1.0, 2.0, 0.3324400429177207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 428848.7857002047, 428848.7857002047, 109047.4011104464]
[2019-04-27 21:49:20,685] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 21:49:20,689] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.4191080e-30 1.0000000e+00 2.9256222e-34 2.4333663e-28 2.1819145e-34], sampled 0.7213138357807051
[2019-04-27 21:49:28,103] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.14990485]
[2019-04-27 21:49:28,104] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.94158839166667, 54.46733565833333, 1.0, 2.0, 0.3915426796978366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 483397.4591866956, 483397.4591866956, 127392.8416725102]
[2019-04-27 21:49:28,104] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 21:49:28,108] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.2295510e-29 1.0000000e+00 4.0711803e-33 1.8276112e-27 2.8671879e-33], sampled 0.3317919745448129
[2019-04-27 21:49:44,345] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.14990485]
[2019-04-27 21:49:44,346] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [33.33333333333334, 36.0, 1.0, 2.0, 0.6855340188879837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 816108.3893370836, 816108.3893370831, 175013.2735719048]
[2019-04-27 21:49:44,347] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 21:49:44,349] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.8186111e-28 1.0000000e+00 1.2343347e-32 4.1569411e-27 8.1020698e-33], sampled 0.029571213604208224
[2019-04-27 21:49:48,174] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.14990485]
[2019-04-27 21:49:48,176] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.21346251, 59.79930207, 1.0, 2.0, 0.8544629759816089, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9259061131006, 1078069.992222817, 1078069.992222817, 211395.2158070649]
[2019-04-27 21:49:48,178] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 21:49:48,180] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.5875312e-27 1.0000000e+00 2.6344770e-31 5.3915851e-26 1.6583777e-31], sampled 0.1654033513789721
[2019-04-27 21:49:57,059] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.14990485]
[2019-04-27 21:49:57,060] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.43063585833333, 89.24792496666667, 1.0, 2.0, 0.5458979581675557, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 644386.5729853204, 644386.5729853204, 150030.3550001634]
[2019-04-27 21:49:57,061] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 21:49:57,064] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.4993579e-30 1.0000000e+00 4.7064607e-35 5.0971505e-29 3.2137665e-35], sampled 0.07414893360425345
[2019-04-27 21:51:02,429] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-04-27 21:51:02,810] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-04-27 21:51:03,071] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.1625 2120466133.0938 430.0000
[2019-04-27 21:51:03,125] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8099.9706 2445378853.1784 746.0000
[2019-04-27 21:51:03,214] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-04-27 21:51:04,230] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 2200000, evaluation results [2200000.0, 8099.970618414005, 2445378853.1783895, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.162528137549, 2120466133.0938108, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-04-27 21:51:04,838] A3C_AGENT_WORKER-Thread-9 INFO:Local step 137500, global step 2200288: loss 0.2675
[2019-04-27 21:51:04,842] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 137500, global step 2200291: learning rate 0.0000
[2019-04-27 21:51:04,869] A3C_AGENT_WORKER-Thread-22 INFO:Local step 138500, global step 2200301: loss 0.7739
[2019-04-27 21:51:04,872] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 138500, global step 2200301: learning rate 0.0000
[2019-04-27 21:51:07,681] A3C_AGENT_WORKER-Thread-15 INFO:Local step 137500, global step 2201648: loss 0.3564
[2019-04-27 21:51:07,685] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 137500, global step 2201649: learning rate 0.0000
[2019-04-27 21:51:08,604] A3C_AGENT_WORKER-Thread-3 INFO:Local step 138000, global step 2202084: loss 0.0445
[2019-04-27 21:51:08,606] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 138000, global step 2202085: learning rate 0.0000
[2019-04-27 21:51:08,838] A3C_AGENT_WORKER-Thread-13 INFO:Local step 138500, global step 2202191: loss 0.3348
[2019-04-27 21:51:08,842] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 138500, global step 2202192: learning rate 0.0000
[2019-04-27 21:51:10,190] A3C_AGENT_WORKER-Thread-10 INFO:Local step 137500, global step 2202836: loss 0.0663
[2019-04-27 21:51:10,193] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 137500, global step 2202838: learning rate 0.0000
[2019-04-27 21:51:10,284] A3C_AGENT_WORKER-Thread-19 INFO:Local step 137500, global step 2202879: loss 0.1759
[2019-04-27 21:51:10,287] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 137500, global step 2202879: learning rate 0.0000
[2019-04-27 21:51:10,343] A3C_AGENT_WORKER-Thread-17 INFO:Local step 137500, global step 2202909: loss 0.0170
[2019-04-27 21:51:10,344] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 137500, global step 2202909: learning rate 0.0000
[2019-04-27 21:51:11,388] A3C_AGENT_WORKER-Thread-20 INFO:Local step 137500, global step 2203407: loss 0.2905
[2019-04-27 21:51:11,390] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 137500, global step 2203407: learning rate 0.0000
[2019-04-27 21:51:12,134] A3C_AGENT_WORKER-Thread-16 INFO:Local step 137500, global step 2203776: loss 0.5491
[2019-04-27 21:51:12,137] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 137500, global step 2203776: learning rate 0.0000
[2019-04-27 21:51:12,164] A3C_AGENT_WORKER-Thread-14 INFO:Local step 137500, global step 2203791: loss 0.9567
[2019-04-27 21:51:12,168] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 137500, global step 2203793: learning rate 0.0000
[2019-04-27 21:51:12,201] A3C_AGENT_WORKER-Thread-18 INFO:Local step 137500, global step 2203806: loss 0.5970
[2019-04-27 21:51:12,204] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 137500, global step 2203807: learning rate 0.0000
[2019-04-27 21:51:12,211] A3C_AGENT_WORKER-Thread-11 INFO:Local step 137500, global step 2203810: loss 0.6201
[2019-04-27 21:51:12,215] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 137500, global step 2203810: learning rate 0.0000
[2019-04-27 21:51:12,261] A3C_AGENT_WORKER-Thread-2 INFO:Local step 137500, global step 2203835: loss 0.5289
[2019-04-27 21:51:12,265] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 137500, global step 2203836: learning rate 0.0000
[2019-04-27 21:51:12,289] A3C_AGENT_WORKER-Thread-12 INFO:Local step 137500, global step 2203849: loss 0.8547
[2019-04-27 21:51:12,290] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 137500, global step 2203849: learning rate 0.0000
[2019-04-27 21:51:18,160] A3C_AGENT_WORKER-Thread-21 INFO:Local step 138000, global step 2206663: loss 0.0039
[2019-04-27 21:51:18,161] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 138000, global step 2206663: learning rate 0.0000
[2019-04-27 21:51:20,071] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.4811944e-30 1.0000000e+00 8.5585734e-32 5.9068075e-27 3.7347281e-33], sum to 1.0000
[2019-04-27 21:51:20,077] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0714
[2019-04-27 21:51:20,085] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2205378.718527478 W.
[2019-04-27 21:51:20,089] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.73333333333333, 32.0, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9830319858931628, 7.511495128215286, 6.9112, 121.9237609977909, 2205378.718527478, 1897979.711616711, 379869.6820595493], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3165600.0000, 
sim time next is 3166200.0000, 
raw observation next is [34.8, 32.0, 1.0, 2.0, 0.8723749395518693, 1.0, 1.0, 0.8723749395518693, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9256811279848, 2010802.3203118, 2010802.3203118, 375694.3441523599], 
processed observation next is [1.0, 0.6521739130434783, 0.8444444444444443, 0.32, 1.0, 1.0, 0.8480654042284158, 1.0, 0.5, 0.8480654042284158, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094597289178813, 0.7181436858256429, 0.7181436858256429, 0.7224891233699229], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.43816245], dtype=float32), 0.5086727]. 
=============================================
[2019-04-27 21:51:20,571] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.5953275e-30 1.0000000e+00 1.7128004e-34 2.2515435e-28 1.4641929e-33], sum to 1.0000
[2019-04-27 21:51:20,576] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8286
[2019-04-27 21:51:20,583] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.4975013624193814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 597232.7543458953, 597232.7543458953, 142641.5825532521], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3297600.0000, 
sim time next is 3298200.0000, 
raw observation next is [21.95, 93.83333333333334, 1.0, 2.0, 0.4955509371695133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 595427.8531604705, 595427.8531604705, 142354.280115095], 
processed observation next is [0.0, 0.17391304347826086, 0.36851851851851847, 0.9383333333333335, 1.0, 1.0, 0.3994654013922778, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21265280470016804, 0.21265280470016804, 0.2737582309905673], 
reward next is 0.7262, 
noisyNet noise sample is [array([-1.2363015], dtype=float32), 0.7021541]. 
=============================================
[2019-04-27 21:51:21,184] A3C_AGENT_WORKER-Thread-22 INFO:Local step 139000, global step 2208085: loss 0.0583
[2019-04-27 21:51:21,185] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 139000, global step 2208086: learning rate 0.0000
[2019-04-27 21:51:21,309] A3C_AGENT_WORKER-Thread-9 INFO:Local step 138000, global step 2208144: loss 0.0061
[2019-04-27 21:51:21,312] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 138000, global step 2208145: learning rate 0.0000
[2019-04-27 21:51:24,175] A3C_AGENT_WORKER-Thread-15 INFO:Local step 138000, global step 2209508: loss 0.0151
[2019-04-27 21:51:24,176] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 138000, global step 2209508: learning rate 0.0000
[2019-04-27 21:51:25,436] A3C_AGENT_WORKER-Thread-13 INFO:Local step 139000, global step 2210103: loss 0.0360
[2019-04-27 21:51:25,439] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 139000, global step 2210104: learning rate 0.0000
[2019-04-27 21:51:25,484] A3C_AGENT_WORKER-Thread-3 INFO:Local step 138500, global step 2210128: loss 0.0895
[2019-04-27 21:51:25,486] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 138500, global step 2210128: learning rate 0.0000
[2019-04-27 21:51:26,740] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6034528e-32 1.0000000e+00 6.9723970e-38 1.5551821e-31 1.5448250e-36], sum to 1.0000
[2019-04-27 21:51:26,748] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2738
[2019-04-27 21:51:26,751] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.96666666666667, 83.16666666666666, 1.0, 2.0, 0.6928554004809137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 789654.9607325121, 789654.9607325121, 174795.6478156993], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3358200.0000, 
sim time next is 3358800.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.6979569764497696, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 795472.3003719143, 795472.3003719138, 175757.9735903208], 
processed observation next is [0.0, 0.9130434782608695, 0.5555555555555556, 0.84, 1.0, 1.0, 0.6404249719640114, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.28409725013282655, 0.2840972501328264, 0.33799610305830924], 
reward next is 0.6620, 
noisyNet noise sample is [array([0.7816263], dtype=float32), -1.7561024]. 
=============================================
[2019-04-27 21:51:26,943] A3C_AGENT_WORKER-Thread-10 INFO:Local step 138000, global step 2210834: loss 0.0030
[2019-04-27 21:51:26,946] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 138000, global step 2210835: learning rate 0.0000
[2019-04-27 21:51:26,990] A3C_AGENT_WORKER-Thread-17 INFO:Local step 138000, global step 2210859: loss 0.0033
[2019-04-27 21:51:26,993] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 138000, global step 2210861: learning rate 0.0000
[2019-04-27 21:51:26,998] A3C_AGENT_WORKER-Thread-19 INFO:Local step 138000, global step 2210862: loss 0.0071
[2019-04-27 21:51:27,002] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 138000, global step 2210863: learning rate 0.0000
[2019-04-27 21:51:28,151] A3C_AGENT_WORKER-Thread-20 INFO:Local step 138000, global step 2211417: loss 0.0041
[2019-04-27 21:51:28,152] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 138000, global step 2211417: learning rate 0.0000
[2019-04-27 21:51:28,904] A3C_AGENT_WORKER-Thread-16 INFO:Local step 138000, global step 2211778: loss 0.0026
[2019-04-27 21:51:28,907] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 138000, global step 2211778: learning rate 0.0000
[2019-04-27 21:51:29,010] A3C_AGENT_WORKER-Thread-11 INFO:Local step 138000, global step 2211825: loss 0.0147
[2019-04-27 21:51:29,012] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 138000, global step 2211826: learning rate 0.0000
[2019-04-27 21:51:29,071] A3C_AGENT_WORKER-Thread-2 INFO:Local step 138000, global step 2211859: loss 0.0138
[2019-04-27 21:51:29,075] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 138000, global step 2211860: learning rate 0.0000
[2019-04-27 21:51:29,081] A3C_AGENT_WORKER-Thread-14 INFO:Local step 138000, global step 2211864: loss 0.0162
[2019-04-27 21:51:29,083] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 138000, global step 2211865: learning rate 0.0000
[2019-04-27 21:51:29,093] A3C_AGENT_WORKER-Thread-12 INFO:Local step 138000, global step 2211870: loss 0.0084
[2019-04-27 21:51:29,095] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 138000, global step 2211870: learning rate 0.0000
[2019-04-27 21:51:29,119] A3C_AGENT_WORKER-Thread-18 INFO:Local step 138000, global step 2211880: loss 0.0028
[2019-04-27 21:51:29,121] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 138000, global step 2211881: learning rate 0.0000
[2019-04-27 21:51:35,175] A3C_AGENT_WORKER-Thread-21 INFO:Local step 138500, global step 2214743: loss 0.1136
[2019-04-27 21:51:35,176] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 138500, global step 2214743: learning rate 0.0000
[2019-04-27 21:51:36,221] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1499970e-22 1.0000000e+00 5.5972153e-26 1.6353929e-21 2.3656022e-26], sum to 1.0000
[2019-04-27 21:51:36,229] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1373
[2019-04-27 21:51:36,235] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1611769.568562078 W.
[2019-04-27 21:51:36,239] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.26666666666667, 74.66666666666666, 1.0, 2.0, 0.4711458513401572, 1.0, 2.0, 0.4711458513401572, 1.0, 2.0, 0.7500795394826776, 6.911199999999999, 6.9112, 121.94756008, 1611769.568562078, 1611769.568562079, 329648.6431269949], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4178400.0000, 
sim time next is 4179000.0000, 
raw observation next is [26.63333333333333, 74.33333333333334, 1.0, 2.0, 0.4924537016731803, 1.0, 2.0, 0.4924537016731803, 1.0, 2.0, 0.7840023311610886, 6.911200000000001, 6.9112, 121.94756008, 1684731.521250158, 1684731.521250157, 339900.6576808676], 
processed observation next is [1.0, 0.34782608695652173, 0.5419753086419752, 0.7433333333333334, 1.0, 1.0, 0.39577821627759563, 1.0, 1.0, 0.39577821627759563, 1.0, 1.0, 0.7300029139513609, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6016898290179136, 0.6016898290179132, 0.6536551109247454], 
reward next is 0.3463, 
noisyNet noise sample is [array([0.13231967], dtype=float32), 0.14387096]. 
=============================================
[2019-04-27 21:51:36,259] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[52.25761 ]
 [51.303226]
 [51.015682]
 [51.877895]
 [52.18327 ]], R is [[53.56369019]
 [53.39411545]
 [53.26385117]
 [52.73121262]
 [52.84955215]].
[2019-04-27 21:51:38,307] A3C_AGENT_WORKER-Thread-22 INFO:Local step 139500, global step 2216253: loss 0.3625
[2019-04-27 21:51:38,308] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 139500, global step 2216253: learning rate 0.0000
[2019-04-27 21:51:38,507] A3C_AGENT_WORKER-Thread-9 INFO:Local step 138500, global step 2216343: loss 0.5725
[2019-04-27 21:51:38,509] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 138500, global step 2216343: learning rate 0.0000
[2019-04-27 21:51:41,217] A3C_AGENT_WORKER-Thread-15 INFO:Local step 138500, global step 2217624: loss 0.4601
[2019-04-27 21:51:41,218] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 138500, global step 2217624: learning rate 0.0000
[2019-04-27 21:51:42,027] A3C_AGENT_WORKER-Thread-3 INFO:Local step 139000, global step 2218021: loss 0.0589
[2019-04-27 21:51:42,029] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 139000, global step 2218021: learning rate 0.0000
[2019-04-27 21:51:42,342] A3C_AGENT_WORKER-Thread-13 INFO:Local step 139500, global step 2218174: loss 0.0828
[2019-04-27 21:51:42,345] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 139500, global step 2218174: learning rate 0.0000
[2019-04-27 21:51:43,601] A3C_AGENT_WORKER-Thread-10 INFO:Local step 138500, global step 2218775: loss 0.2626
[2019-04-27 21:51:43,607] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 138500, global step 2218776: learning rate 0.0000
[2019-04-27 21:51:43,882] A3C_AGENT_WORKER-Thread-17 INFO:Local step 138500, global step 2218908: loss 0.0958
[2019-04-27 21:51:43,887] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 138500, global step 2218908: learning rate 0.0000
[2019-04-27 21:51:43,896] A3C_AGENT_WORKER-Thread-19 INFO:Local step 138500, global step 2218911: loss 0.0441
[2019-04-27 21:51:43,903] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 138500, global step 2218912: learning rate 0.0000
[2019-04-27 21:51:45,037] A3C_AGENT_WORKER-Thread-20 INFO:Local step 138500, global step 2219452: loss 0.0653
[2019-04-27 21:51:45,038] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 138500, global step 2219452: learning rate 0.0000
[2019-04-27 21:51:45,573] A3C_AGENT_WORKER-Thread-16 INFO:Local step 138500, global step 2219708: loss 0.0763
[2019-04-27 21:51:45,577] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 138500, global step 2219710: learning rate 0.0000
[2019-04-27 21:51:45,846] A3C_AGENT_WORKER-Thread-12 INFO:Local step 138500, global step 2219840: loss 0.0051
[2019-04-27 21:51:45,852] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 138500, global step 2219840: learning rate 0.0000
[2019-04-27 21:51:45,894] A3C_AGENT_WORKER-Thread-11 INFO:Local step 138500, global step 2219860: loss 0.0342
[2019-04-27 21:51:45,896] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 138500, global step 2219860: learning rate 0.0000
[2019-04-27 21:51:45,914] A3C_AGENT_WORKER-Thread-18 INFO:Local step 138500, global step 2219867: loss 0.0160
[2019-04-27 21:51:45,915] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 138500, global step 2219867: learning rate 0.0000
[2019-04-27 21:51:45,919] A3C_AGENT_WORKER-Thread-14 INFO:Local step 138500, global step 2219870: loss 0.0137
[2019-04-27 21:51:45,922] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 138500, global step 2219870: learning rate 0.0000
[2019-04-27 21:51:46,133] A3C_AGENT_WORKER-Thread-2 INFO:Local step 138500, global step 2219970: loss 0.0544
[2019-04-27 21:51:46,135] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 138500, global step 2219970: learning rate 0.0000
[2019-04-27 21:51:51,189] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1063275e-33 1.0000000e+00 2.2622076e-38 1.2681605e-31 2.7173079e-37], sum to 1.0000
[2019-04-27 21:51:51,195] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1896
[2019-04-27 21:51:51,199] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.8, 91.33333333333334, 1.0, 2.0, 0.6968489582287243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 794208.8207127714, 794208.8207127709, 175547.9829762611], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3702000.0000, 
sim time next is 3702600.0000, 
raw observation next is [25.6, 92.0, 1.0, 2.0, 0.6922598227231861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 788975.8248268866, 788975.8248268862, 174683.1402571915], 
processed observation next is [1.0, 0.8695652173913043, 0.5037037037037038, 0.92, 1.0, 1.0, 0.6336426460990311, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2817770802953167, 0.2817770802953165, 0.3359291158792144], 
reward next is 0.6641, 
noisyNet noise sample is [array([-0.30092847], dtype=float32), 1.0315953]. 
=============================================
[2019-04-27 21:51:51,406] A3C_AGENT_WORKER-Thread-21 INFO:Local step 139000, global step 2222500: loss 0.0124
[2019-04-27 21:51:51,407] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 139000, global step 2222500: learning rate 0.0000
[2019-04-27 21:51:54,514] A3C_AGENT_WORKER-Thread-22 INFO:Local step 140000, global step 2224069: loss 0.0058
[2019-04-27 21:51:54,516] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 140000, global step 2224069: learning rate 0.0000
[2019-04-27 21:51:54,884] A3C_AGENT_WORKER-Thread-9 INFO:Local step 139000, global step 2224208: loss 0.0319
[2019-04-27 21:51:54,886] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 139000, global step 2224208: learning rate 0.0000
[2019-04-27 21:51:56,299] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.8018737e-30 1.0000000e+00 1.2169411e-34 1.0533502e-29 3.3845759e-34], sum to 1.0000
[2019-04-27 21:51:56,308] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1911
[2019-04-27 21:51:56,317] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 80.66666666666667, 1.0, 2.0, 0.6309695370669983, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 721121.8955817649, 721121.8955817653, 163588.0578404977], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3804000.0000, 
sim time next is 3804600.0000, 
raw observation next is [26.16666666666667, 82.33333333333333, 1.0, 2.0, 0.6371217921849336, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 726818.5871893178, 726818.5871893173, 164616.2822000471], 
processed observation next is [0.0, 0.0, 0.5246913580246916, 0.8233333333333333, 1.0, 1.0, 0.5680021335534924, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2595780668533278, 0.2595780668533276, 0.31656977346162907], 
reward next is 0.6834, 
noisyNet noise sample is [array([0.36219943], dtype=float32), -1.4212359]. 
=============================================
[2019-04-27 21:51:56,464] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-04-27 21:51:56,469] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 21:51:56,469] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:51:56,470] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 21:51:56,470] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 21:51:56,472] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:51:56,472] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 21:51:56,473] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:51:56,472] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 21:51:56,474] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:51:56,475] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:51:56,485] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run90
[2019-04-27 21:51:56,508] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run90
[2019-04-27 21:51:56,530] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run90
[2019-04-27 21:51:56,553] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run90
[2019-04-27 21:51:56,579] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run90
[2019-04-27 21:52:05,515] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.15099335]
[2019-04-27 21:52:05,517] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.58333333333334, 70.0, 1.0, 2.0, 0.3420175202503838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 436627.382288394, 436627.3822883936, 120925.3866494345]
[2019-04-27 21:52:05,517] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 21:52:05,519] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.4749657e-28 1.0000000e+00 9.1309727e-33 1.8245253e-27 3.0821043e-33], sampled 0.8379872967428799
[2019-04-27 21:52:20,574] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.15099335]
[2019-04-27 21:52:20,575] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.85, 77.5, 1.0, 2.0, 0.386199104802645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 480256.0989662796, 480256.0989662796, 126729.4013042635]
[2019-04-27 21:52:20,575] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 21:52:20,578] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.4280512e-29 1.0000000e+00 4.7655783e-33 1.0963111e-27 1.6202068e-33], sampled 0.3846389249179607
[2019-04-27 21:52:35,747] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.15099335]
[2019-04-27 21:52:35,985] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.86666666666667, 89.33333333333333, 1.0, 2.0, 0.5786750145180158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 664440.3667314214, 664440.3667314214, 154693.0717425154]
[2019-04-27 21:52:35,987] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 21:52:35,990] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.8764673e-28 1.0000000e+00 2.7774810e-32 4.4939707e-27 9.3785098e-33], sampled 0.415537827350011
[2019-04-27 21:52:48,271] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.15099335]
[2019-04-27 21:52:48,271] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.33333333333334, 90.0, 1.0, 2.0, 0.7003492928937821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 798200.279910559, 798200.279910559, 176211.4680798831]
[2019-04-27 21:52:48,273] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 21:52:48,278] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.3560887e-28 1.0000000e+00 8.2424150e-33 1.6681265e-27 2.7325105e-33], sampled 0.5171759963174047
[2019-04-27 21:52:55,463] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.15099335]
[2019-04-27 21:52:55,465] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.3, 95.33333333333334, 1.0, 2.0, 0.5690254354328407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 663660.737477852, 663660.737477852, 153545.7809565193]
[2019-04-27 21:52:55,467] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 21:52:55,470] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.9471958e-29 1.0000000e+00 2.0220029e-33 5.1204810e-28 6.6288018e-34], sampled 0.08428155908869639
[2019-04-27 21:53:08,142] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.15099335]
[2019-04-27 21:53:08,143] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.85820747333333, 82.09719229333334, 1.0, 2.0, 0.9058611798065381, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1032583.550174722, 1032583.550174722, 218779.3451441898]
[2019-04-27 21:53:08,144] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 21:53:08,146] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [3.4219005e-26 1.0000000e+00 4.9679739e-30 2.8457662e-25 1.4649158e-30], sampled 0.7569339235904302
[2019-04-27 21:53:44,557] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-04-27 21:53:44,887] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-04-27 21:53:45,022] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-04-27 21:53:45,126] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-04-27 21:53:45,227] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-04-27 21:53:46,248] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 2225000, evaluation results [2225000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-04-27 21:53:47,339] A3C_AGENT_WORKER-Thread-15 INFO:Local step 139000, global step 2225530: loss 0.0281
[2019-04-27 21:53:47,342] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 139000, global step 2225531: learning rate 0.0000
[2019-04-27 21:53:47,808] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.0259884e-30 1.0000000e+00 7.7135690e-36 1.7519986e-29 8.7010683e-35], sum to 1.0000
[2019-04-27 21:53:47,815] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5051
[2019-04-27 21:53:47,828] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.9, 69.0, 1.0, 2.0, 0.7462053212910059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 850492.1903086734, 850492.190308673, 185077.3237900074], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3873600.0000, 
sim time next is 3874200.0000, 
raw observation next is [29.75, 69.83333333333333, 1.0, 2.0, 0.7334928087174218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 835995.122372612, 835995.122372612, 182583.3093882906], 
processed observation next is [0.0, 0.8695652173913043, 0.6574074074074074, 0.6983333333333333, 1.0, 1.0, 0.6827295341874069, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2985696865616471, 0.2985696865616471, 0.3511217488236358], 
reward next is 0.6489, 
noisyNet noise sample is [array([-0.84192115], dtype=float32), -0.7703704]. 
=============================================
[2019-04-27 21:53:48,694] A3C_AGENT_WORKER-Thread-3 INFO:Local step 139500, global step 2226172: loss 0.2240
[2019-04-27 21:53:48,697] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 139500, global step 2226172: learning rate 0.0000
[2019-04-27 21:53:48,743] A3C_AGENT_WORKER-Thread-13 INFO:Local step 140000, global step 2226193: loss 0.0064
[2019-04-27 21:53:48,748] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 140000, global step 2226194: learning rate 0.0000
[2019-04-27 21:53:49,892] A3C_AGENT_WORKER-Thread-10 INFO:Local step 139000, global step 2226735: loss 0.0407
[2019-04-27 21:53:49,894] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 139000, global step 2226735: learning rate 0.0000
[2019-04-27 21:53:50,168] A3C_AGENT_WORKER-Thread-17 INFO:Local step 139000, global step 2226864: loss 0.0004
[2019-04-27 21:53:50,171] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 139000, global step 2226866: learning rate 0.0000
[2019-04-27 21:53:50,229] A3C_AGENT_WORKER-Thread-19 INFO:Local step 139000, global step 2226895: loss 0.0016
[2019-04-27 21:53:50,232] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 139000, global step 2226896: learning rate 0.0000
[2019-04-27 21:53:51,407] A3C_AGENT_WORKER-Thread-20 INFO:Local step 139000, global step 2227449: loss 0.0004
[2019-04-27 21:53:51,409] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 139000, global step 2227450: learning rate 0.0000
[2019-04-27 21:53:51,956] A3C_AGENT_WORKER-Thread-16 INFO:Local step 139000, global step 2227718: loss 0.0553
[2019-04-27 21:53:51,959] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 139000, global step 2227720: learning rate 0.0000
[2019-04-27 21:53:51,994] A3C_AGENT_WORKER-Thread-11 INFO:Local step 139000, global step 2227736: loss 0.0398
[2019-04-27 21:53:52,000] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 139000, global step 2227737: learning rate 0.0000
[2019-04-27 21:53:52,272] A3C_AGENT_WORKER-Thread-14 INFO:Local step 139000, global step 2227864: loss 0.0555
[2019-04-27 21:53:52,274] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 139000, global step 2227864: learning rate 0.0000
[2019-04-27 21:53:52,293] A3C_AGENT_WORKER-Thread-12 INFO:Local step 139000, global step 2227873: loss 0.0317
[2019-04-27 21:53:52,293] A3C_AGENT_WORKER-Thread-18 INFO:Local step 139000, global step 2227873: loss 0.0345
[2019-04-27 21:53:52,298] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 139000, global step 2227874: learning rate 0.0000
[2019-04-27 21:53:52,302] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 139000, global step 2227874: learning rate 0.0000
[2019-04-27 21:53:52,337] A3C_AGENT_WORKER-Thread-2 INFO:Local step 139000, global step 2227895: loss 0.0404
[2019-04-27 21:53:52,344] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 139000, global step 2227895: learning rate 0.0000
[2019-04-27 21:53:58,106] A3C_AGENT_WORKER-Thread-21 INFO:Local step 139500, global step 2230656: loss 7.1424
[2019-04-27 21:53:58,107] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 139500, global step 2230656: learning rate 0.0000
[2019-04-27 21:54:01,349] A3C_AGENT_WORKER-Thread-22 INFO:Local step 140500, global step 2232202: loss -25.5697
[2019-04-27 21:54:01,351] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 140500, global step 2232202: learning rate 0.0000
[2019-04-27 21:54:01,862] A3C_AGENT_WORKER-Thread-9 INFO:Local step 139500, global step 2232458: loss 0.5805
[2019-04-27 21:54:01,864] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 139500, global step 2232458: learning rate 0.0000
[2019-04-27 21:54:03,742] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.1604858e-31 1.0000000e+00 2.9699004e-36 2.5341813e-30 3.1422742e-38], sum to 1.0000
[2019-04-27 21:54:03,749] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2962
[2019-04-27 21:54:03,756] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.56666666666667, 74.0, 1.0, 2.0, 0.5899988754972725, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 684571.4675860454, 684571.4675860454, 156948.5376398306], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4314000.0000, 
sim time next is 4314600.0000, 
raw observation next is [26.35, 74.0, 1.0, 2.0, 0.5786501439915542, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 674267.1877573403, 674267.1877573398, 155143.5010751116], 
processed observation next is [1.0, 0.9565217391304348, 0.5314814814814816, 0.74, 1.0, 1.0, 0.4983930285613741, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2408097099133358, 0.24080970991333564, 0.2983528866829069], 
reward next is 0.7016, 
noisyNet noise sample is [array([-0.9007884], dtype=float32), -1.156236]. 
=============================================
[2019-04-27 21:54:04,201] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.9479894e-30 1.0000000e+00 2.0930184e-34 1.3932708e-29 3.0103960e-34], sum to 1.0000
[2019-04-27 21:54:04,208] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2882
[2019-04-27 21:54:04,216] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 80.66666666666667, 1.0, 2.0, 0.5097264892286206, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 603134.700091263, 603134.700091263, 144246.590938415], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4124400.0000, 
sim time next is 4125000.0000, 
raw observation next is [23.2, 84.33333333333334, 1.0, 2.0, 0.4860469379718651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 582091.909508787, 582091.9095087865, 140805.2784372108], 
processed observation next is [1.0, 0.7391304347826086, 0.4148148148148148, 0.8433333333333334, 1.0, 1.0, 0.38815111663317275, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20788996768170964, 0.20788996768170948, 0.27077938161002074], 
reward next is 0.7292, 
noisyNet noise sample is [array([-0.6888896], dtype=float32), -0.5663786]. 
=============================================
[2019-04-27 21:54:04,237] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[72.14055 ]
 [70.969124]
 [69.52244 ]
 [67.81018 ]
 [65.700775]], R is [[73.16389465]
 [73.15486145]
 [73.13999939]
 [73.11368561]
 [72.97296906]].
[2019-04-27 21:54:04,245] A3C_AGENT_WORKER-Thread-15 INFO:Local step 139500, global step 2233566: loss 8.3931
[2019-04-27 21:54:04,246] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 139500, global step 2233567: learning rate 0.0000
[2019-04-27 21:54:05,413] A3C_AGENT_WORKER-Thread-3 INFO:Local step 140000, global step 2234119: loss 0.0082
[2019-04-27 21:54:05,414] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 140000, global step 2234119: learning rate 0.0000
[2019-04-27 21:54:05,755] A3C_AGENT_WORKER-Thread-13 INFO:Local step 140500, global step 2234279: loss 28.2609
[2019-04-27 21:54:05,760] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 140500, global step 2234280: learning rate 0.0000
[2019-04-27 21:54:06,891] A3C_AGENT_WORKER-Thread-10 INFO:Local step 139500, global step 2234835: loss 0.3651
[2019-04-27 21:54:06,893] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 139500, global step 2234835: learning rate 0.0000
[2019-04-27 21:54:07,068] A3C_AGENT_WORKER-Thread-19 INFO:Local step 139500, global step 2234918: loss 0.2561
[2019-04-27 21:54:07,070] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 139500, global step 2234919: learning rate 0.0000
[2019-04-27 21:54:07,071] A3C_AGENT_WORKER-Thread-17 INFO:Local step 139500, global step 2234919: loss 0.4561
[2019-04-27 21:54:07,074] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 139500, global step 2234919: learning rate 0.0000
[2019-04-27 21:54:08,171] A3C_AGENT_WORKER-Thread-20 INFO:Local step 139500, global step 2235446: loss 0.1740
[2019-04-27 21:54:08,175] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 139500, global step 2235447: learning rate 0.0000
[2019-04-27 21:54:08,742] A3C_AGENT_WORKER-Thread-11 INFO:Local step 139500, global step 2235721: loss 0.1407
[2019-04-27 21:54:08,747] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 139500, global step 2235722: learning rate 0.0000
[2019-04-27 21:54:08,787] A3C_AGENT_WORKER-Thread-16 INFO:Local step 139500, global step 2235741: loss 0.6798
[2019-04-27 21:54:08,795] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 139500, global step 2235742: learning rate 0.0000
[2019-04-27 21:54:09,139] A3C_AGENT_WORKER-Thread-12 INFO:Local step 139500, global step 2235907: loss 0.2821
[2019-04-27 21:54:09,142] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 139500, global step 2235908: learning rate 0.0000
[2019-04-27 21:54:09,147] A3C_AGENT_WORKER-Thread-14 INFO:Local step 139500, global step 2235909: loss 0.3921
[2019-04-27 21:54:09,149] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 139500, global step 2235910: learning rate 0.0000
[2019-04-27 21:54:09,178] A3C_AGENT_WORKER-Thread-2 INFO:Local step 139500, global step 2235925: loss 0.2490
[2019-04-27 21:54:09,180] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 139500, global step 2235925: learning rate 0.0000
[2019-04-27 21:54:09,203] A3C_AGENT_WORKER-Thread-18 INFO:Local step 139500, global step 2235935: loss 0.4020
[2019-04-27 21:54:09,205] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 139500, global step 2235935: learning rate 0.0000
[2019-04-27 21:54:10,310] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.1200422e-23 1.0000000e+00 7.0141860e-27 1.8095029e-22 4.2741830e-26], sum to 1.0000
[2019-04-27 21:54:10,321] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9407
[2019-04-27 21:54:10,332] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1602555.08287819 W.
[2019-04-27 21:54:10,336] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.26666666666667, 39.33333333333334, 1.0, 2.0, 0.7479988336314002, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9667820201044613, 6.911199999999999, 6.9112, 121.9260426156618, 1602555.08287819, 1602555.082878191, 319668.2332500184], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4272000.0000, 
sim time next is 4272600.0000, 
raw observation next is [31.58333333333333, 37.66666666666666, 1.0, 2.0, 0.4562638440448587, 1.0, 1.0, 0.4562638440448587, 1.0, 2.0, 0.7286923612233507, 6.911199999999999, 6.9112, 121.94756008, 1597754.851332471, 1597754.851332471, 322707.8867687354], 
processed observation next is [1.0, 0.43478260869565216, 0.7253086419753084, 0.3766666666666666, 1.0, 1.0, 0.3526950524343556, 1.0, 0.5, 0.3526950524343556, 1.0, 1.0, 0.6608654515291884, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5706267326187396, 0.5706267326187396, 0.6205920899398758], 
reward next is 0.3794, 
noisyNet noise sample is [array([-0.09940509], dtype=float32), -1.0314862]. 
=============================================
[2019-04-27 21:54:13,903] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.0880017e-32 1.0000000e+00 4.0081060e-34 2.8517479e-29 2.7809951e-36], sum to 1.0000
[2019-04-27 21:54:13,915] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0478
[2019-04-27 21:54:13,921] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 97.0, 1.0, 2.0, 0.525160428178715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 621362.4872059821, 621362.4872059821, 146712.4712905357], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4429800.0000, 
sim time next is 4430400.0000, 
raw observation next is [22.66666666666666, 98.0, 1.0, 2.0, 0.5400534006777605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 635370.080430419, 635370.080430419, 148985.4546041971], 
processed observation next is [0.0, 0.2608695652173913, 0.3950617283950615, 0.98, 1.0, 1.0, 0.45244452461638157, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22691788586800676, 0.22691788586800676, 0.28651048962345593], 
reward next is 0.7135, 
noisyNet noise sample is [array([-0.47190958], dtype=float32), 0.91344845]. 
=============================================
[2019-04-27 21:54:14,618] A3C_AGENT_WORKER-Thread-21 INFO:Local step 140000, global step 2238521: loss 0.0296
[2019-04-27 21:54:14,621] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 140000, global step 2238521: learning rate 0.0000
[2019-04-27 21:54:17,753] A3C_AGENT_WORKER-Thread-22 INFO:Local step 141000, global step 2240018: loss 0.2805
[2019-04-27 21:54:17,754] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 141000, global step 2240019: learning rate 0.0000
[2019-04-27 21:54:18,184] A3C_AGENT_WORKER-Thread-9 INFO:Local step 140000, global step 2240224: loss 0.0066
[2019-04-27 21:54:18,186] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 140000, global step 2240224: learning rate 0.0000
[2019-04-27 21:54:20,831] A3C_AGENT_WORKER-Thread-15 INFO:Local step 140000, global step 2241478: loss 0.0388
[2019-04-27 21:54:20,833] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 140000, global step 2241478: learning rate 0.0000
[2019-04-27 21:54:21,733] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.3743433e-27 1.0000000e+00 3.5429670e-31 8.0778078e-27 6.5254123e-33], sum to 1.0000
[2019-04-27 21:54:21,741] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6577
[2019-04-27 21:54:21,748] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 96.0, 1.0, 2.0, 0.754939488117123, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 860452.5997402449, 860452.5997402449, 186808.6023960677], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5100000.0000, 
sim time next is 5100600.0000, 
raw observation next is [26.0, 95.0, 1.0, 2.0, 0.7352794052313276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 838032.5009286641, 838032.5009286641, 182932.8899805176], 
processed observation next is [0.0, 0.0, 0.5185185185185185, 0.95, 1.0, 1.0, 0.6848564347991996, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29929732176023716, 0.29929732176023716, 0.35179401919330305], 
reward next is 0.6482, 
noisyNet noise sample is [array([-0.38917732], dtype=float32), 0.7346549]. 
=============================================
[2019-04-27 21:54:22,139] A3C_AGENT_WORKER-Thread-3 INFO:Local step 140500, global step 2242111: loss 27.6099
[2019-04-27 21:54:22,143] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 140500, global step 2242111: learning rate 0.0000
[2019-04-27 21:54:22,407] A3C_AGENT_WORKER-Thread-13 INFO:Local step 141000, global step 2242239: loss 0.3061
[2019-04-27 21:54:22,409] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 141000, global step 2242239: learning rate 0.0000
[2019-04-27 21:54:23,412] A3C_AGENT_WORKER-Thread-10 INFO:Local step 140000, global step 2242718: loss 0.0847
[2019-04-27 21:54:23,414] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 140000, global step 2242720: learning rate 0.0000
[2019-04-27 21:54:23,680] A3C_AGENT_WORKER-Thread-19 INFO:Local step 140000, global step 2242850: loss 0.0251
[2019-04-27 21:54:23,683] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 140000, global step 2242850: learning rate 0.0000
[2019-04-27 21:54:23,683] A3C_AGENT_WORKER-Thread-17 INFO:Local step 140000, global step 2242851: loss 0.0106
[2019-04-27 21:54:23,690] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 140000, global step 2242853: learning rate 0.0000
[2019-04-27 21:54:24,959] A3C_AGENT_WORKER-Thread-20 INFO:Local step 140000, global step 2243449: loss 0.0037
[2019-04-27 21:54:24,960] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 140000, global step 2243449: learning rate 0.0000
[2019-04-27 21:54:25,516] A3C_AGENT_WORKER-Thread-11 INFO:Local step 140000, global step 2243713: loss 0.0475
[2019-04-27 21:54:25,519] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 140000, global step 2243713: learning rate 0.0000
[2019-04-27 21:54:25,570] A3C_AGENT_WORKER-Thread-16 INFO:Local step 140000, global step 2243738: loss 0.0464
[2019-04-27 21:54:25,574] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 140000, global step 2243740: learning rate 0.0000
[2019-04-27 21:54:25,911] A3C_AGENT_WORKER-Thread-18 INFO:Local step 140000, global step 2243905: loss 0.0032
[2019-04-27 21:54:25,913] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 140000, global step 2243906: learning rate 0.0000
[2019-04-27 21:54:25,925] A3C_AGENT_WORKER-Thread-2 INFO:Local step 140000, global step 2243912: loss 0.0024
[2019-04-27 21:54:25,931] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 140000, global step 2243912: learning rate 0.0000
[2019-04-27 21:54:25,959] A3C_AGENT_WORKER-Thread-14 INFO:Local step 140000, global step 2243929: loss 0.0026
[2019-04-27 21:54:25,961] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 140000, global step 2243930: learning rate 0.0000
[2019-04-27 21:54:26,070] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.0587213e-29 1.0000000e+00 4.9231930e-35 1.4220039e-28 2.1895927e-35], sum to 1.0000
[2019-04-27 21:54:26,078] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5319
[2019-04-27 21:54:26,087] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 95.0, 1.0, 2.0, 0.6054446582943405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 698554.4250720291, 698554.4250720287, 159433.355846398], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4554000.0000, 
sim time next is 4554600.0000, 
raw observation next is [23.91666666666667, 94.83333333333334, 1.0, 2.0, 0.6047597434497026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 697631.6595992418, 697631.6595992418, 159308.1157656058], 
processed observation next is [0.0, 0.7391304347826086, 0.4413580246913582, 0.9483333333333335, 1.0, 1.0, 0.5294758850591698, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24915416414258637, 0.24915416414258637, 0.30636176108770347], 
reward next is 0.6936, 
noisyNet noise sample is [array([-0.2225173], dtype=float32), 1.3136445]. 
=============================================
[2019-04-27 21:54:26,107] A3C_AGENT_WORKER-Thread-12 INFO:Local step 140000, global step 2244000: loss 0.0089
[2019-04-27 21:54:26,109] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 140000, global step 2244000: learning rate 0.0000
[2019-04-27 21:54:26,518] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.2955065e-32 1.0000000e+00 1.6364546e-35 1.0140829e-30 0.0000000e+00], sum to 1.0000
[2019-04-27 21:54:26,527] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9089
[2019-04-27 21:54:26,532] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.95, 90.0, 1.0, 2.0, 0.6970723638055253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 794463.5712312438, 794463.5712312438, 175589.9969296917], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5265000.0000, 
sim time next is 5265600.0000, 
raw observation next is [25.9, 90.0, 1.0, 2.0, 0.6943389435803018, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 791346.644029029, 791346.6440290285, 175074.4022322376], 
processed observation next is [1.0, 0.9565217391304348, 0.5148148148148147, 0.9, 1.0, 1.0, 0.6361177899765498, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2826238014389389, 0.2826238014389387, 0.33668154275430306], 
reward next is 0.6633, 
noisyNet noise sample is [array([-1.6091552], dtype=float32), -0.15492603]. 
=============================================
[2019-04-27 21:54:27,361] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.2398810e-31 1.0000000e+00 1.9144358e-35 3.0001433e-29 1.1693072e-35], sum to 1.0000
[2019-04-27 21:54:27,371] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6022
[2019-04-27 21:54:27,377] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.93333333333333, 94.66666666666667, 1.0, 2.0, 0.6036917398531136, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 696462.2650096394, 696462.2650096394, 159125.8063437651], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4555200.0000, 
sim time next is 4555800.0000, 
raw observation next is [23.95, 94.5, 1.0, 2.0, 0.6028433258252563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 695553.1391525086, 695553.1391525086, 158982.056730945], 
processed observation next is [0.0, 0.7391304347826086, 0.4425925925925926, 0.945, 1.0, 1.0, 0.5271944355062576, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24841183541161022, 0.24841183541161022, 0.30573472448258654], 
reward next is 0.6943, 
noisyNet noise sample is [array([-0.13357477], dtype=float32), 0.027935028]. 
=============================================
[2019-04-27 21:54:29,949] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8064131e-22 1.0000000e+00 2.0745772e-26 4.4234488e-22 7.1871786e-28], sum to 1.0000
[2019-04-27 21:54:29,958] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5480
[2019-04-27 21:54:29,961] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.9, 94.5, 1.0, 2.0, 0.6647910966818737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 757653.9554678148, 757653.9554678148, 169584.2214464859], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4671000.0000, 
sim time next is 4671600.0000, 
raw observation next is [24.86666666666667, 94.66666666666666, 1.0, 2.0, 0.6635041865116785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 756186.5568692551, 756186.5568692551, 169348.5695985363], 
processed observation next is [1.0, 0.043478260869565216, 0.47654320987654336, 0.9466666666666665, 1.0, 1.0, 0.5994097458472363, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2700666274533054, 0.2700666274533054, 0.32567032615103136], 
reward next is 0.6743, 
noisyNet noise sample is [array([-0.855903], dtype=float32), 0.9307154]. 
=============================================
[2019-04-27 21:54:31,672] A3C_AGENT_WORKER-Thread-21 INFO:Local step 140500, global step 2246693: loss 0.1097
[2019-04-27 21:54:31,676] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 140500, global step 2246695: learning rate 0.0000
[2019-04-27 21:54:34,228] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2180025e-30 1.0000000e+00 1.3867445e-35 4.4738121e-31 4.8448437e-38], sum to 1.0000
[2019-04-27 21:54:34,241] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6457
[2019-04-27 21:54:34,246] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1843698.420533613 W.
[2019-04-27 21:54:34,251] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.45, 66.5, 1.0, 2.0, 0.8083085439337568, 1.0, 2.0, 0.8083085439337568, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1843698.420533613, 1843698.420533614, 347198.6256338661], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5329800.0000, 
sim time next is 5330400.0000, 
raw observation next is [28.46666666666667, 66.66666666666667, 1.0, 2.0, 0.5377653531234192, 1.0, 2.0, 0.5377653531234192, 1.0, 1.0, 0.8561399559673329, 6.9112, 6.9112, 121.94756008, 1839906.661755844, 1839906.661755844, 362511.185292968], 
processed observation next is [1.0, 0.6956521739130435, 0.6098765432098766, 0.6666666666666667, 1.0, 1.0, 0.44972065848026094, 1.0, 1.0, 0.44972065848026094, 1.0, 0.5, 0.8201749449591661, 0.0, 0.0, 0.8096049824067558, 0.6571095220556585, 0.6571095220556585, 0.6971368947941692], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5268922], dtype=float32), -0.09207036]. 
=============================================
[2019-04-27 21:54:34,548] A3C_AGENT_WORKER-Thread-22 INFO:Local step 141500, global step 2248162: loss -17.8177
[2019-04-27 21:54:34,549] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 141500, global step 2248162: learning rate 0.0000
[2019-04-27 21:54:35,020] A3C_AGENT_WORKER-Thread-9 INFO:Local step 140500, global step 2248400: loss 57.6351
[2019-04-27 21:54:35,023] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 140500, global step 2248401: learning rate 0.0000
[2019-04-27 21:54:37,433] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.1520678e-26 1.0000000e+00 5.5265948e-30 4.6329317e-26 1.7014726e-30], sum to 1.0000
[2019-04-27 21:54:37,442] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7538
[2019-04-27 21:54:37,443] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1825212.153073379 W.
[2019-04-27 21:54:37,447] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.8, 86.5, 1.0, 2.0, 0.8002121242783784, 1.0, 2.0, 0.8002121242783784, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1825212.153073379, 1825212.15307338, 343843.3067556635], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4811400.0000, 
sim time next is 4812000.0000, 
raw observation next is [28.06666666666667, 85.66666666666667, 1.0, 2.0, 0.8122420200972658, 1.0, 2.0, 0.8122420200972658, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1852679.725060119, 1852679.72506012, 348840.3324101623], 
processed observation next is [1.0, 0.6956521739130435, 0.5950617283950619, 0.8566666666666667, 1.0, 1.0, 0.7764785953538877, 1.0, 1.0, 0.7764785953538877, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6616713303786139, 0.6616713303786143, 0.670846793096466], 
reward next is 0.3292, 
noisyNet noise sample is [array([0.22874649], dtype=float32), 1.8734881]. 
=============================================
[2019-04-27 21:54:37,456] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[58.9385  ]
 [58.26557 ]
 [57.893272]
 [57.258423]
 [56.319138]], R is [[59.00440216]
 [58.75312424]
 [58.16559219]
 [57.92651749]
 [57.64046478]].
[2019-04-27 21:54:37,457] A3C_AGENT_WORKER-Thread-15 INFO:Local step 140500, global step 2249631: loss 52.4850
[2019-04-27 21:54:37,460] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 140500, global step 2249632: learning rate 0.0000
[2019-04-27 21:54:38,205] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-04-27 21:54:38,207] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 21:54:38,207] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:54:38,209] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 21:54:38,210] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 21:54:38,211] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:54:38,211] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:54:38,212] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 21:54:38,213] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:54:38,213] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 21:54:38,216] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:54:38,237] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run91
[2019-04-27 21:54:38,257] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run91
[2019-04-27 21:54:38,288] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run91
[2019-04-27 21:54:38,289] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run91
[2019-04-27 21:54:38,334] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run91
[2019-04-27 21:54:42,236] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.15143251]
[2019-04-27 21:54:42,238] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [33.33333333333333, 13.33333333333333, 1.0, 2.0, 0.3768583626498536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 485775.5694201395, 485775.5694201395, 125586.4697225247]
[2019-04-27 21:54:42,239] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 21:54:42,242] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.6496297e-30 1.0000000e+00 4.1184611e-34 1.0165705e-28 9.7142991e-35], sampled 0.23919902379878832
[2019-04-27 21:54:47,621] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.15143251]
[2019-04-27 21:54:47,622] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [34.21319234, 25.78862378, 1.0, 2.0, 0.5803241126482236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 714183.1281190541, 714183.1281190541, 156793.229602395]
[2019-04-27 21:54:47,623] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 21:54:47,628] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0248563e-28 1.0000000e+00 6.9270016e-33 1.0936671e-27 1.7345323e-33], sampled 0.7517884008465361
[2019-04-27 21:54:53,141] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.15143251]
[2019-04-27 21:54:53,142] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.6, 49.66666666666667, 1.0, 2.0, 0.7309433882101711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 926247.6950631535, 926247.695063153, 185345.3833767014]
[2019-04-27 21:54:53,143] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 21:54:53,145] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.6137234e-26 1.0000000e+00 5.8145345e-30 3.1353861e-25 1.7804500e-30], sampled 0.040682136124390866
[2019-04-27 21:56:07,796] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.15143251]
[2019-04-27 21:56:07,798] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.76888746, 67.70808452, 1.0, 2.0, 0.5680920576534142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 666427.8809428706, 666427.8809428706, 153554.2230698503]
[2019-04-27 21:56:07,799] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 21:56:07,802] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.8800017e-26 1.0000000e+00 5.3425601e-30 2.5063171e-25 1.5083300e-30], sampled 0.08793191596246919
[2019-04-27 21:56:20,380] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.15143251]
[2019-04-27 21:56:20,381] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.7, 54.66666666666666, 1.0, 2.0, 0.2900206988386422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 371145.8290333722, 371145.8290333722, 114352.7123686264]
[2019-04-27 21:56:20,383] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 21:56:20,386] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.6366101e-29 1.0000000e+00 3.6489927e-33 6.6819851e-28 9.2161081e-34], sampled 0.438634442704425
[2019-04-27 21:56:26,392] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-04-27 21:56:26,917] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-04-27 21:56:27,117] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-04-27 21:56:27,141] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-04-27 21:56:27,184] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-04-27 21:56:28,203] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 2250000, evaluation results [2250000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-04-27 21:56:28,345] A3C_AGENT_WORKER-Thread-3 INFO:Local step 141000, global step 2250073: loss 0.1059
[2019-04-27 21:56:28,346] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 141000, global step 2250073: learning rate 0.0000
[2019-04-27 21:56:28,549] A3C_AGENT_WORKER-Thread-13 INFO:Local step 141500, global step 2250163: loss 3.7291
[2019-04-27 21:56:28,551] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 141500, global step 2250163: learning rate 0.0000
[2019-04-27 21:56:29,853] A3C_AGENT_WORKER-Thread-10 INFO:Local step 140500, global step 2250775: loss 51.6578
[2019-04-27 21:56:29,855] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 140500, global step 2250776: learning rate 0.0000
[2019-04-27 21:56:30,087] A3C_AGENT_WORKER-Thread-17 INFO:Local step 140500, global step 2250887: loss -1.8511
[2019-04-27 21:56:30,090] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 140500, global step 2250887: learning rate 0.0000
[2019-04-27 21:56:30,231] A3C_AGENT_WORKER-Thread-19 INFO:Local step 140500, global step 2250959: loss -27.6438
[2019-04-27 21:56:30,235] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 140500, global step 2250959: learning rate 0.0000
[2019-04-27 21:56:31,188] A3C_AGENT_WORKER-Thread-20 INFO:Local step 140500, global step 2251410: loss 59.7888
[2019-04-27 21:56:31,194] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 140500, global step 2251412: learning rate 0.0000
[2019-04-27 21:56:31,392] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.7310249e-30 1.0000000e+00 1.3562753e-35 3.8231985e-30 9.8035603e-37], sum to 1.0000
[2019-04-27 21:56:31,401] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6763
[2019-04-27 21:56:31,410] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.55, 96.0, 1.0, 2.0, 0.709096297140216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 808174.6486404609, 808174.6486404605, 177874.4124614904], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4836600.0000, 
sim time next is 4837200.0000, 
raw observation next is [25.36666666666667, 97.33333333333333, 1.0, 2.0, 0.7078710132406543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 806777.4272089533, 806777.4272089533, 177640.6275622077], 
processed observation next is [1.0, 1.0, 0.49506172839506185, 0.9733333333333333, 1.0, 1.0, 0.6522273967150646, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28813479543176906, 0.28813479543176906, 0.34161659146578405], 
reward next is 0.6584, 
noisyNet noise sample is [array([-0.7291757], dtype=float32), 1.3805064]. 
=============================================
[2019-04-27 21:56:31,873] A3C_AGENT_WORKER-Thread-16 INFO:Local step 140500, global step 2251739: loss -18.4426
[2019-04-27 21:56:31,875] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 140500, global step 2251739: learning rate 0.0000
[2019-04-27 21:56:31,921] A3C_AGENT_WORKER-Thread-11 INFO:Local step 140500, global step 2251760: loss 17.5899
[2019-04-27 21:56:31,923] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 140500, global step 2251761: learning rate 0.0000
[2019-04-27 21:56:32,227] A3C_AGENT_WORKER-Thread-14 INFO:Local step 140500, global step 2251910: loss -26.0328
[2019-04-27 21:56:32,229] A3C_AGENT_WORKER-Thread-18 INFO:Local step 140500, global step 2251910: loss -10.1655
[2019-04-27 21:56:32,231] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 140500, global step 2251910: learning rate 0.0000
[2019-04-27 21:56:32,232] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 140500, global step 2251910: learning rate 0.0000
[2019-04-27 21:56:32,270] A3C_AGENT_WORKER-Thread-2 INFO:Local step 140500, global step 2251928: loss 41.2783
[2019-04-27 21:56:32,273] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 140500, global step 2251928: learning rate 0.0000
[2019-04-27 21:56:32,435] A3C_AGENT_WORKER-Thread-12 INFO:Local step 140500, global step 2252005: loss 81.2639
[2019-04-27 21:56:32,439] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 140500, global step 2252007: learning rate 0.0000
[2019-04-27 21:56:34,956] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.9281478e-30 1.0000000e+00 1.2255650e-33 3.9153434e-29 1.4893498e-35], sum to 1.0000
[2019-04-27 21:56:34,964] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0871
[2019-04-27 21:56:34,971] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2853286.790690227 W.
[2019-04-27 21:56:34,981] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.8, 77.5, 1.0, 2.0, 1.02, 1.0, 2.0, 0.8334821656272994, 1.0, 1.0, 0.9977734948820727, 6.956282585943041, 6.9112, 121.94756008, 2853286.790690227, 2830196.402987254, 528192.6552493176], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4897800.0000, 
sim time next is 4898400.0000, 
raw observation next is [31.06666666666667, 73.66666666666667, 1.0, 2.0, 0.8918966719568391, 1.0, 2.0, 0.7593129979548543, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2599011.339116615, 2599011.339116615, 484786.5090102948], 
processed observation next is [1.0, 0.6956521739130435, 0.7061728395061729, 0.7366666666666667, 1.0, 1.0, 0.8713055618533798, 1.0, 1.0, 0.7134678547081599, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8096049824067558, 0.928218335398791, 0.928218335398791, 0.9322817480967208], 
reward next is 0.0677, 
noisyNet noise sample is [array([0.04256353], dtype=float32), 0.6167089]. 
=============================================
[2019-04-27 21:56:37,812] A3C_AGENT_WORKER-Thread-21 INFO:Local step 141000, global step 2254520: loss 0.1624
[2019-04-27 21:56:37,817] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 141000, global step 2254521: learning rate 0.0000
[2019-04-27 21:56:40,897] A3C_AGENT_WORKER-Thread-22 INFO:Local step 142000, global step 2255982: loss 0.0316
[2019-04-27 21:56:40,900] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 142000, global step 2255983: learning rate 0.0000
[2019-04-27 21:56:41,416] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2474753e-32 1.0000000e+00 0.0000000e+00 6.4441053e-32 0.0000000e+00], sum to 1.0000
[2019-04-27 21:56:41,426] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5589
[2019-04-27 21:56:41,430] A3C_AGENT_WORKER-Thread-9 INFO:Local step 141000, global step 2256232: loss 0.0567
[2019-04-27 21:56:41,430] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.31666666666666, 74.33333333333334, 1.0, 2.0, 0.6267917534622638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 715940.8744332732, 715940.8744332737, 162827.6415798493], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5346600.0000, 
sim time next is 5347200.0000, 
raw observation next is [27.23333333333333, 74.66666666666667, 1.0, 2.0, 0.6223710949060081, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 711330.9323446238, 711330.9323446234, 162069.9800174295], 
processed observation next is [1.0, 0.9130434782608695, 0.5641975308641974, 0.7466666666666667, 1.0, 1.0, 0.5504417796500096, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.25404676155165135, 0.2540467615516512, 0.31167303849505673], 
reward next is 0.6883, 
noisyNet noise sample is [array([-1.3849251], dtype=float32), 0.43509477]. 
=============================================
[2019-04-27 21:56:41,433] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 141000, global step 2256232: learning rate 0.0000
[2019-04-27 21:56:44,036] A3C_AGENT_WORKER-Thread-15 INFO:Local step 141000, global step 2257475: loss 0.0083
[2019-04-27 21:56:44,038] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 141000, global step 2257475: learning rate 0.0000
[2019-04-27 21:56:44,345] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.6497269e-29 1.0000000e+00 9.3919706e-33 7.8260505e-28 1.2812492e-33], sum to 1.0000
[2019-04-27 21:56:44,354] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6626
[2019-04-27 21:56:44,362] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1879249.536741809 W.
[2019-04-27 21:56:44,365] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.5, 80.0, 1.0, 2.0, 0.8238783743345542, 1.0, 2.0, 0.8238783743345542, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156495, 1879249.536741809, 1879249.536741808, 353720.2336915999], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5398200.0000, 
sim time next is 5398800.0000, 
raw observation next is [27.33333333333334, 81.33333333333334, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.945641430087564, 6.9112, 121.925713744294, 1895732.129256515, 1878095.086284153, 384009.1536745031], 
processed observation next is [1.0, 0.4782608695652174, 0.5679012345679014, 0.8133333333333335, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, 0.003444143008756395, 0.0, 0.8094599454562559, 0.6770471890201839, 0.6707482451014832, 0.7384791416817367], 
reward next is 0.0893, 
noisyNet noise sample is [array([2.3727462], dtype=float32), 0.27523082]. 
=============================================
[2019-04-27 21:56:45,211] A3C_AGENT_WORKER-Thread-3 INFO:Local step 141500, global step 2258024: loss -84.9265
[2019-04-27 21:56:45,213] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 141500, global step 2258025: learning rate 0.0000
[2019-04-27 21:56:45,417] A3C_AGENT_WORKER-Thread-13 INFO:Local step 142000, global step 2258124: loss 0.0145
[2019-04-27 21:56:45,420] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 142000, global step 2258125: learning rate 0.0000
[2019-04-27 21:56:45,981] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.4178848e-29 1.0000000e+00 2.1890321e-36 1.0986791e-30 6.9400151e-33], sum to 1.0000
[2019-04-27 21:56:45,992] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3119
[2019-04-27 21:56:46,000] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 69.0, 1.0, 2.0, 0.8117256801840731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 925214.5063828866, 925214.5063828861, 198381.4075003505], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5146800.0000, 
sim time next is 5147400.0000, 
raw observation next is [31.0, 67.5, 1.0, 2.0, 0.7929503983211317, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 903801.5995483065, 903801.5995483061, 194493.1899441177], 
processed observation next is [0.0, 0.5652173913043478, 0.7037037037037037, 0.675, 1.0, 1.0, 0.7535123789537281, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3227862855529666, 0.32278628555296646, 0.3740253652771494], 
reward next is 0.6260, 
noisyNet noise sample is [array([-0.20202054], dtype=float32), -0.42238903]. 
=============================================
[2019-04-27 21:56:46,865] A3C_AGENT_WORKER-Thread-17 INFO:Local step 141000, global step 2258815: loss 0.0213
[2019-04-27 21:56:46,866] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 141000, global step 2258815: learning rate 0.0000
[2019-04-27 21:56:46,880] A3C_AGENT_WORKER-Thread-10 INFO:Local step 141000, global step 2258819: loss 0.0219
[2019-04-27 21:56:46,884] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 141000, global step 2258820: learning rate 0.0000
[2019-04-27 21:56:47,015] A3C_AGENT_WORKER-Thread-19 INFO:Local step 141000, global step 2258886: loss 0.0031
[2019-04-27 21:56:47,016] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 141000, global step 2258886: learning rate 0.0000
[2019-04-27 21:56:48,132] A3C_AGENT_WORKER-Thread-20 INFO:Local step 141000, global step 2259408: loss 0.0436
[2019-04-27 21:56:48,135] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 141000, global step 2259409: learning rate 0.0000
[2019-04-27 21:56:48,184] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.9464529e-27 1.0000000e+00 2.2165425e-29 1.1413767e-25 4.5343794e-30], sum to 1.0000
[2019-04-27 21:56:48,189] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7880
[2019-04-27 21:56:48,197] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1983436.543829883 W.
[2019-04-27 21:56:48,208] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.66666666666666, 71.5, 1.0, 2.0, 0.5796695445557699, 1.0, 1.0, 0.5796695445557699, 1.0, 2.0, 0.922852793451874, 6.9112, 6.9112, 121.94756008, 1983436.543829883, 1983436.543829883, 384409.8328830493], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5230200.0000, 
sim time next is 5230800.0000, 
raw observation next is [30.0, 70.0, 1.0, 2.0, 0.6264540330440184, 1.0, 2.0, 0.6264540330440184, 1.0, 2.0, 0.9973352227895829, 6.9112, 6.9112, 121.94756008, 2143709.632608454, 2143709.632608454, 409977.3916699849], 
processed observation next is [1.0, 0.5652173913043478, 0.6666666666666666, 0.7, 1.0, 1.0, 0.555302420290498, 1.0, 1.0, 0.555302420290498, 1.0, 1.0, 0.9966690284869786, 0.0, 0.0, 0.8096049824067558, 0.765610583074448, 0.765610583074448, 0.7884180609038172], 
reward next is 0.2116, 
noisyNet noise sample is [array([-1.7100405], dtype=float32), 1.5262904]. 
=============================================
[2019-04-27 21:56:48,724] A3C_AGENT_WORKER-Thread-11 INFO:Local step 141000, global step 2259695: loss 0.0084
[2019-04-27 21:56:48,727] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 141000, global step 2259695: learning rate 0.0000
[2019-04-27 21:56:48,790] A3C_AGENT_WORKER-Thread-16 INFO:Local step 141000, global step 2259725: loss 0.0070
[2019-04-27 21:56:48,796] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 141000, global step 2259725: learning rate 0.0000
[2019-04-27 21:56:49,292] A3C_AGENT_WORKER-Thread-18 INFO:Local step 141000, global step 2259965: loss 0.0243
[2019-04-27 21:56:49,294] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 141000, global step 2259965: learning rate 0.0000
[2019-04-27 21:56:49,301] A3C_AGENT_WORKER-Thread-14 INFO:Local step 141000, global step 2259969: loss 0.0216
[2019-04-27 21:56:49,302] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 141000, global step 2259969: learning rate 0.0000
[2019-04-27 21:56:49,359] A3C_AGENT_WORKER-Thread-2 INFO:Local step 141000, global step 2259999: loss 0.0151
[2019-04-27 21:56:49,362] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 141000, global step 2260000: learning rate 0.0000
[2019-04-27 21:56:49,409] A3C_AGENT_WORKER-Thread-12 INFO:Local step 141000, global step 2260021: loss 0.0090
[2019-04-27 21:56:49,410] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 141000, global step 2260021: learning rate 0.0000
[2019-04-27 21:56:51,035] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.1566937e-25 1.0000000e+00 5.8068900e-29 2.3601526e-23 1.1236441e-30], sum to 1.0000
[2019-04-27 21:56:51,045] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3143
[2019-04-27 21:56:51,051] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2133520.603060705 W.
[2019-04-27 21:56:51,056] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.75, 68.5, 1.0, 2.0, 0.9352198871183837, 1.0, 2.0, 0.9352198871183837, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2133520.603060705, 2133520.603060705, 402797.7858112949], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5232600.0000, 
sim time next is 5233200.0000, 
raw observation next is [29.66666666666666, 68.0, 1.0, 2.0, 0.6502547000605021, 1.0, 2.0, 0.6384920120066858, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2184953.682109945, 2184953.682109946, 416140.1607758427], 
processed observation next is [1.0, 0.5652173913043478, 0.6543209876543208, 0.68, 1.0, 1.0, 0.583636547691074, 1.0, 1.0, 0.5696333476270069, 1.0, 0.5, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7803406007535518, 0.7803406007535522, 0.8002695399535437], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5026975], dtype=float32), -0.101031154]. 
=============================================
[2019-04-27 21:56:51,078] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.16019911e-24 1.00000000e+00 9.81034355e-27 1.65968809e-23
 1.13148346e-26], sum to 1.0000
[2019-04-27 21:56:51,086] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2201
[2019-04-27 21:56:51,091] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.6748876867928476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 769166.6841465341, 769166.6841465341, 171442.7296825626], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5185800.0000, 
sim time next is 5186400.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.6750413076304544, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 769341.8530389302, 769341.8530389302, 171471.1410374106], 
processed observation next is [1.0, 0.0, 0.48148148148148145, 0.94, 1.0, 1.0, 0.6131444138457791, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2747649475139036, 0.2747649475139036, 0.3297521943027127], 
reward next is 0.6702, 
noisyNet noise sample is [array([-0.33190364], dtype=float32), -1.180322]. 
=============================================
[2019-04-27 21:56:53,438] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.8485644e-21 1.0000000e+00 1.3148904e-24 8.9112484e-20 2.6603804e-24], sum to 1.0000
[2019-04-27 21:56:53,445] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8509
[2019-04-27 21:56:53,447] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.6748494630513809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 769123.0988516951, 769123.0988516951, 171435.6612174352], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5187000.0000, 
sim time next is 5187600.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.6746178602351648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 768859.0097118813, 768859.0097118813, 171392.8369413446], 
processed observation next is [1.0, 0.043478260869565216, 0.48148148148148145, 0.94, 1.0, 1.0, 0.6126403098037676, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27459250346852904, 0.27459250346852904, 0.32960160950258577], 
reward next is 0.6704, 
noisyNet noise sample is [array([1.1180625], dtype=float32), 0.80564654]. 
=============================================
[2019-04-27 21:56:54,959] A3C_AGENT_WORKER-Thread-21 INFO:Local step 141500, global step 2262665: loss -87.1582
[2019-04-27 21:56:54,965] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 141500, global step 2262665: learning rate 0.0000
[2019-04-27 21:56:57,212] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1941581e-36 1.0000000e+00 0.0000000e+00 6.3805007e-34 0.0000000e+00], sum to 1.0000
[2019-04-27 21:56:57,220] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3001
[2019-04-27 21:56:57,225] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.18333333333334, 89.66666666666666, 1.0, 2.0, 0.7077715180608061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 806663.9705148208, 806663.9705148208, 177620.5459297388], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5262600.0000, 
sim time next is 5263200.0000, 
raw observation next is [26.1, 90.0, 1.0, 2.0, 0.7050904251628956, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 803606.6635363535, 803606.663536353, 177109.8975146885], 
processed observation next is [1.0, 0.9565217391304348, 0.5222222222222223, 0.9, 1.0, 1.0, 0.6489171728129709, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.28700237983441196, 0.2870023798344118, 0.3405959567590163], 
reward next is 0.6594, 
noisyNet noise sample is [array([0.45037827], dtype=float32), 1.8183018]. 
=============================================
[2019-04-27 21:56:57,695] A3C_AGENT_WORKER-Thread-22 INFO:Local step 142500, global step 2263934: loss 38.9204
[2019-04-27 21:56:57,698] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 142500, global step 2263937: learning rate 0.0000
[2019-04-27 21:56:58,685] A3C_AGENT_WORKER-Thread-9 INFO:Local step 141500, global step 2264406: loss -59.0780
[2019-04-27 21:56:58,686] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 141500, global step 2264406: learning rate 0.0000
[2019-04-27 21:56:59,427] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.6799743e-23 1.0000000e+00 3.3053281e-26 2.6414627e-22 1.1439136e-25], sum to 1.0000
[2019-04-27 21:56:59,436] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2277
[2019-04-27 21:56:59,442] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.18333333333333, 89.33333333333334, 1.0, 2.0, 0.5659052294827277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 671747.0455049993, 671747.0455049993, 153508.8366969374], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5292600.0000, 
sim time next is 5293200.0000, 
raw observation next is [23.06666666666667, 89.66666666666667, 1.0, 2.0, 0.5485001657191325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 651962.1146004068, 651962.1146004064, 150637.176696953], 
processed observation next is [1.0, 0.2608695652173913, 0.40987654320987665, 0.8966666666666667, 1.0, 1.0, 0.46250019728468156, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23284361235728815, 0.23284361235728798, 0.2896868782633712], 
reward next is 0.7103, 
noisyNet noise sample is [array([0.39890802], dtype=float32), 1.1697152]. 
=============================================
[2019-04-27 21:57:01,294] A3C_AGENT_WORKER-Thread-15 INFO:Local step 141500, global step 2265638: loss -1.6782
[2019-04-27 21:57:01,297] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 141500, global step 2265640: learning rate 0.0000
[2019-04-27 21:57:01,903] A3C_AGENT_WORKER-Thread-13 INFO:Local step 142500, global step 2265940: loss 126.3477
[2019-04-27 21:57:01,906] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 142500, global step 2265940: learning rate 0.0000
[2019-04-27 21:57:02,131] A3C_AGENT_WORKER-Thread-3 INFO:Local step 142000, global step 2266043: loss 0.0832
[2019-04-27 21:57:02,133] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 142000, global step 2266043: learning rate 0.0000
[2019-04-27 21:57:03,847] A3C_AGENT_WORKER-Thread-10 INFO:Local step 141500, global step 2266855: loss -34.7271
[2019-04-27 21:57:03,851] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 141500, global step 2266855: learning rate 0.0000
[2019-04-27 21:57:03,860] A3C_AGENT_WORKER-Thread-17 INFO:Local step 141500, global step 2266861: loss -54.4530
[2019-04-27 21:57:03,863] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 141500, global step 2266863: learning rate 0.0000
[2019-04-27 21:57:04,117] A3C_AGENT_WORKER-Thread-19 INFO:Local step 141500, global step 2266981: loss 1.6768
[2019-04-27 21:57:04,121] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 141500, global step 2266981: learning rate 0.0000
[2019-04-27 21:57:05,056] A3C_AGENT_WORKER-Thread-20 INFO:Local step 141500, global step 2267432: loss 31.9813
[2019-04-27 21:57:05,059] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 141500, global step 2267433: learning rate 0.0000
[2019-04-27 21:57:05,633] A3C_AGENT_WORKER-Thread-16 INFO:Local step 141500, global step 2267704: loss -38.2787
[2019-04-27 21:57:05,637] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 141500, global step 2267704: learning rate 0.0000
[2019-04-27 21:57:05,670] A3C_AGENT_WORKER-Thread-11 INFO:Local step 141500, global step 2267722: loss -19.9335
[2019-04-27 21:57:05,673] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 141500, global step 2267722: learning rate 0.0000
[2019-04-27 21:57:06,065] A3C_AGENT_WORKER-Thread-14 INFO:Local step 141500, global step 2267918: loss -41.1887
[2019-04-27 21:57:06,066] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 141500, global step 2267918: learning rate 0.0000
[2019-04-27 21:57:06,181] A3C_AGENT_WORKER-Thread-2 INFO:Local step 141500, global step 2267972: loss -73.1091
[2019-04-27 21:57:06,182] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 141500, global step 2267973: learning rate 0.0000
[2019-04-27 21:57:06,208] A3C_AGENT_WORKER-Thread-18 INFO:Local step 141500, global step 2267985: loss -6.5963
[2019-04-27 21:57:06,209] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 141500, global step 2267985: learning rate 0.0000
[2019-04-27 21:57:06,258] A3C_AGENT_WORKER-Thread-12 INFO:Local step 141500, global step 2268005: loss 22.6011
[2019-04-27 21:57:06,260] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 141500, global step 2268005: learning rate 0.0000
[2019-04-27 21:57:09,617] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.2934305e-21 1.0000000e+00 4.3140085e-24 1.5694285e-20 1.9689661e-24], sum to 1.0000
[2019-04-27 21:57:09,623] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2663
[2019-04-27 21:57:09,632] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1897853.080812766 W.
[2019-04-27 21:57:09,637] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.85, 90.0, 1.0, 2.0, 0.5546838799367033, 1.0, 1.0, 0.5546838799367033, 1.0, 2.0, 0.8830748016520324, 6.9112, 6.9112, 121.94756008, 1897853.080812766, 1897853.080812766, 371238.4581317172], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5473800.0000, 
sim time next is 5474400.0000, 
raw observation next is [28.0, 89.33333333333334, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 7.496168129366939, 6.9112, 121.923766354453, 2177941.947842719, 1878391.574217827, 382040.3924272811], 
processed observation next is [1.0, 0.34782608695652173, 0.5925925925925926, 0.8933333333333334, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 0.05849681293669393, 0.0, 0.8094470168128542, 0.7778364099438282, 0.670854133649224, 0.734693062360156], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.51666975], dtype=float32), 1.7090042]. 
=============================================
[2019-04-27 21:57:10,524] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.3673403e-22 1.0000000e+00 2.3418011e-25 1.2282830e-20 5.2233088e-27], sum to 1.0000
[2019-04-27 21:57:10,528] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7045
[2019-04-27 21:57:10,535] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1895800.525359807 W.
[2019-04-27 21:57:10,542] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.48333333333333, 68.0, 1.0, 2.0, 0.8311267703621088, 1.0, 2.0, 0.8311267703621088, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1895800.525359807, 1895800.525359807, 356786.9649225206], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5490600.0000, 
sim time next is 5491200.0000, 
raw observation next is [32.66666666666667, 67.0, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 9.328556183927109, 6.9112, 121.9164654705674, 3117184.292744104, 1879379.101487294, 375459.5989495083], 
processed observation next is [1.0, 0.5652173913043478, 0.7654320987654323, 0.67, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, 0.2417356183927109, 0.0, 0.8093985465362381, 1.1132801045514658, 0.6712068219597479, 0.722037690287516], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.4697994], dtype=float32), 0.39565277]. 
=============================================
[2019-04-27 21:57:10,997] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.2641299e-29 1.0000000e+00 3.1576717e-35 2.3001239e-28 2.7261295e-32], sum to 1.0000
[2019-04-27 21:57:11,009] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0268
[2019-04-27 21:57:11,015] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 97.0, 1.0, 2.0, 0.5851781625409374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 677183.3846719526, 677183.3846719526, 156042.5433568091], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5632200.0000, 
sim time next is 5632800.0000, 
raw observation next is [23.5, 97.0, 1.0, 2.0, 0.5847347191477948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 676671.177473789, 676671.177473789, 155967.0633027043], 
processed observation next is [0.0, 0.17391304347826086, 0.42592592592592593, 0.97, 1.0, 1.0, 0.5056365704140414, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24166827766921034, 0.24166827766921034, 0.2999366601975083], 
reward next is 0.7001, 
noisyNet noise sample is [array([0.01948475], dtype=float32), -0.4386897]. 
=============================================
[2019-04-27 21:57:11,052] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2859718e-22 1.0000000e+00 8.0651446e-29 1.7607072e-23 1.4045213e-27], sum to 1.0000
[2019-04-27 21:57:11,060] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5495
[2019-04-27 21:57:11,069] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2264263.323546294 W.
[2019-04-27 21:57:11,077] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.2, 72.0, 1.0, 2.0, 0.6965480861244011, 1.0, 2.0, 0.6616387050386352, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2264263.323546294, 2264263.323546294, 428313.773554351], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5499000.0000, 
sim time next is 5499600.0000, 
raw observation next is [29.83333333333334, 73.0, 1.0, 2.0, 0.8982603203990227, 1.0, 2.0, 0.8982603203990227, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2049107.862054211, 2049107.862054211, 386031.1242572802], 
processed observation next is [1.0, 0.6521739130434783, 0.6604938271604941, 0.73, 1.0, 1.0, 0.8788813338083603, 1.0, 1.0, 0.8788813338083603, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.7318242364479325, 0.7318242364479325, 0.7423675466486158], 
reward next is 0.2576, 
noisyNet noise sample is [array([1.1483321], dtype=float32), 0.39445454]. 
=============================================
[2019-04-27 21:57:11,497] A3C_AGENT_WORKER-Thread-21 INFO:Local step 142000, global step 2270518: loss 0.1086
[2019-04-27 21:57:11,498] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 142000, global step 2270518: learning rate 0.0000
[2019-04-27 21:57:13,942] A3C_AGENT_WORKER-Thread-22 INFO:Local step 143000, global step 2271765: loss 0.0190
[2019-04-27 21:57:13,946] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 143000, global step 2271768: learning rate 0.0000
[2019-04-27 21:57:15,029] A3C_AGENT_WORKER-Thread-9 INFO:Local step 142000, global step 2272320: loss 0.0562
[2019-04-27 21:57:15,031] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 142000, global step 2272320: learning rate 0.0000
[2019-04-27 21:57:17,601] A3C_AGENT_WORKER-Thread-15 INFO:Local step 142000, global step 2273623: loss 0.0705
[2019-04-27 21:57:17,603] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 142000, global step 2273623: learning rate 0.0000
[2019-04-27 21:57:17,882] A3C_AGENT_WORKER-Thread-3 INFO:Local step 142500, global step 2273769: loss 21.3511
[2019-04-27 21:57:17,885] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 142500, global step 2273769: learning rate 0.0000
[2019-04-27 21:57:18,221] A3C_AGENT_WORKER-Thread-13 INFO:Local step 143000, global step 2273875: loss 0.2366
[2019-04-27 21:57:18,222] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 143000, global step 2273875: learning rate 0.0000
[2019-04-27 21:57:18,780] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.89528360e-29 1.00000000e+00 7.82072261e-32 1.02493215e-25
 4.09666325e-35], sum to 1.0000
[2019-04-27 21:57:18,787] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9181
[2019-04-27 21:57:18,794] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 96.0, 1.0, 2.0, 0.6061968031043733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 695966.023321951, 695966.0233219514, 159398.8328567443], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5638800.0000, 
sim time next is 5639400.0000, 
raw observation next is [24.05, 96.0, 1.0, 2.0, 0.6121615250262679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 702025.5131238446, 702025.5131238446, 160398.4367725984], 
processed observation next is [0.0, 0.2608695652173913, 0.4462962962962963, 0.96, 1.0, 1.0, 0.538287529793176, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.25072339754423023, 0.25072339754423023, 0.3084585322549969], 
reward next is 0.6915, 
noisyNet noise sample is [array([1.0927817], dtype=float32), -0.31840745]. 
=============================================
[2019-04-27 21:57:20,098] A3C_AGENT_WORKER-Thread-17 INFO:Local step 142000, global step 2274820: loss 0.1325
[2019-04-27 21:57:20,100] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 142000, global step 2274820: learning rate 0.0000
[2019-04-27 21:57:20,188] A3C_AGENT_WORKER-Thread-10 INFO:Local step 142000, global step 2274864: loss 0.1853
[2019-04-27 21:57:20,192] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 142000, global step 2274864: learning rate 0.0000
[2019-04-27 21:57:20,456] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-04-27 21:57:20,458] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 21:57:20,459] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:57:20,460] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 21:57:20,464] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 21:57:20,465] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 21:57:20,466] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:57:20,466] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 21:57:20,469] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:57:20,470] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:57:20,466] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 21:57:20,492] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run92
[2019-04-27 21:57:20,516] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run92
[2019-04-27 21:57:20,517] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run92
[2019-04-27 21:57:20,537] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run92
[2019-04-27 21:57:20,562] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run92
[2019-04-27 21:57:22,851] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.1540732]
[2019-04-27 21:57:22,852] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.00748162666667, 84.03532328, 1.0, 2.0, 0.5145157918525229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 607764.4384096016, 607764.4384096016, 144966.2170576468]
[2019-04-27 21:57:22,853] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 21:57:22,857] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [6.5155407e-32 1.0000000e+00 1.6907787e-36 2.4134144e-30 6.5943648e-37], sampled 0.006450439760868232
[2019-04-27 21:58:01,567] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.1540732]
[2019-04-27 21:58:01,569] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [32.229518925, 30.96106024666667, 1.0, 2.0, 0.4159375032042517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 513171.6686315282, 513171.6686315282, 130835.9674309609]
[2019-04-27 21:58:01,572] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 21:58:01,577] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.7402469e-37 1.0000000e+00 0.0000000e+00 5.6706255e-35 0.0000000e+00], sampled 0.010168606596091534
[2019-04-27 21:58:40,950] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.1540732]
[2019-04-27 21:58:40,951] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.3, 55.33333333333333, 1.0, 2.0, 0.597907292357404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 681393.4557081372, 681393.4557081372, 157719.0598866108]
[2019-04-27 21:58:40,953] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 21:58:40,956] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.05404636e-35 1.00000000e+00 0.00000000e+00 6.10562005e-34
 0.00000000e+00], sampled 0.21549732083448725
[2019-04-27 21:58:44,977] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.1540732]
[2019-04-27 21:58:44,978] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.36666666666667, 92.0, 1.0, 2.0, 0.5382727373956105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 632621.7370476087, 632621.7370476082, 148667.2045645312]
[2019-04-27 21:58:44,978] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 21:58:44,981] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.6961350e-34 1.0000000e+00 0.0000000e+00 1.2739442e-32 0.0000000e+00], sampled 0.9577731081303243
[2019-04-27 21:59:08,729] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-04-27 21:59:09,005] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-04-27 21:59:09,189] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-04-27 21:59:09,225] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-04-27 21:59:09,287] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-04-27 21:59:10,306] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 2275000, evaluation results [2275000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-04-27 21:59:10,326] A3C_AGENT_WORKER-Thread-19 INFO:Local step 142000, global step 2275011: loss 0.0520
[2019-04-27 21:59:10,328] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 142000, global step 2275011: learning rate 0.0000
[2019-04-27 21:59:11,242] A3C_AGENT_WORKER-Thread-20 INFO:Local step 142000, global step 2275450: loss 0.0437
[2019-04-27 21:59:11,244] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 142000, global step 2275450: learning rate 0.0000
[2019-04-27 21:59:11,908] A3C_AGENT_WORKER-Thread-11 INFO:Local step 142000, global step 2275772: loss 0.1406
[2019-04-27 21:59:11,912] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 142000, global step 2275772: learning rate 0.0000
[2019-04-27 21:59:11,993] A3C_AGENT_WORKER-Thread-16 INFO:Local step 142000, global step 2275814: loss 0.1543
[2019-04-27 21:59:11,996] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 142000, global step 2275814: learning rate 0.0000
[2019-04-27 21:59:12,482] A3C_AGENT_WORKER-Thread-14 INFO:Local step 142000, global step 2276045: loss 0.0744
[2019-04-27 21:59:12,486] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 142000, global step 2276048: learning rate 0.0000
[2019-04-27 21:59:12,520] A3C_AGENT_WORKER-Thread-18 INFO:Local step 142000, global step 2276066: loss 0.0749
[2019-04-27 21:59:12,522] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 142000, global step 2276066: learning rate 0.0000
[2019-04-27 21:59:12,529] A3C_AGENT_WORKER-Thread-2 INFO:Local step 142000, global step 2276068: loss 0.0513
[2019-04-27 21:59:12,532] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 142000, global step 2276069: learning rate 0.0000
[2019-04-27 21:59:12,629] A3C_AGENT_WORKER-Thread-12 INFO:Local step 142000, global step 2276115: loss 0.0461
[2019-04-27 21:59:12,632] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 142000, global step 2276115: learning rate 0.0000
[2019-04-27 21:59:13,529] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.7904858e-34 1.0000000e+00 0.0000000e+00 6.6412610e-32 0.0000000e+00], sum to 1.0000
[2019-04-27 21:59:13,537] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5045
[2019-04-27 21:59:13,544] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.13333333333333, 54.33333333333334, 1.0, 2.0, 0.4588926929563215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 551760.5064526057, 551760.5064526057, 136742.4541496319], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5939400.0000, 
sim time next is 5940000.0000, 
raw observation next is [28.0, 55.0, 1.0, 2.0, 0.4648816048791133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 558920.9004996613, 558920.9004996613, 137643.9986970713], 
processed observation next is [1.0, 0.782608695652174, 0.5925925925925926, 0.55, 1.0, 1.0, 0.36295429152275394, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.19961460732130762, 0.19961460732130762, 0.2646999974943679], 
reward next is 0.7353, 
noisyNet noise sample is [array([-0.393857], dtype=float32), 0.9110004]. 
=============================================
[2019-04-27 21:59:13,566] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[84.69626 ]
 [85.26848 ]
 [85.69125 ]
 [85.33246 ]
 [84.744415]], R is [[84.57419586]
 [84.46548462]
 [84.36035919]
 [84.25799561]
 [84.1543808 ]].
[2019-04-27 21:59:17,603] A3C_AGENT_WORKER-Thread-21 INFO:Local step 142500, global step 2278481: loss 52.6495
[2019-04-27 21:59:17,605] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 142500, global step 2278482: learning rate 0.0000
[2019-04-27 21:59:17,993] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.7294314e-32 1.0000000e+00 2.1743015e-36 1.0879652e-29 9.6707025e-36], sum to 1.0000
[2019-04-27 21:59:18,003] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4133
[2019-04-27 21:59:18,012] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.7, 51.0, 1.0, 2.0, 0.3873136888658628, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 479378.4566022526, 479378.4566022526, 126834.5414231736], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5855400.0000, 
sim time next is 5856000.0000, 
raw observation next is [26.53333333333333, 52.33333333333333, 1.0, 2.0, 0.3916736507608528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 484144.8105067955, 484144.810506796, 127425.8460713066], 
processed observation next is [1.0, 0.782608695652174, 0.5382716049382715, 0.5233333333333333, 1.0, 1.0, 0.27580196519149147, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1729088608952841, 0.1729088608952843, 0.24504970398328194], 
reward next is 0.7550, 
noisyNet noise sample is [array([-0.18841891], dtype=float32), 2.1854482]. 
=============================================
[2019-04-27 21:59:18,029] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[76.288635]
 [76.29205 ]
 [76.07904 ]
 [76.05971 ]
 [75.800476]], R is [[76.54249573]
 [76.53315735]
 [76.52482605]
 [76.51796722]
 [76.51288605]].
[2019-04-27 21:59:20,737] A3C_AGENT_WORKER-Thread-22 INFO:Local step 143500, global step 2279962: loss -20.2259
[2019-04-27 21:59:20,737] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 143500, global step 2279962: learning rate 0.0000
[2019-04-27 21:59:21,633] A3C_AGENT_WORKER-Thread-9 INFO:Local step 142500, global step 2280345: loss -14.7899
[2019-04-27 21:59:21,636] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 142500, global step 2280345: learning rate 0.0000
[2019-04-27 21:59:24,359] A3C_AGENT_WORKER-Thread-15 INFO:Local step 142500, global step 2281659: loss 100.5929
[2019-04-27 21:59:24,361] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 142500, global step 2281660: learning rate 0.0000
[2019-04-27 21:59:24,838] A3C_AGENT_WORKER-Thread-3 INFO:Local step 143000, global step 2281886: loss 0.0077
[2019-04-27 21:59:24,841] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 143000, global step 2281886: learning rate 0.0000
[2019-04-27 21:59:25,160] A3C_AGENT_WORKER-Thread-13 INFO:Local step 143500, global step 2282037: loss -28.4716
[2019-04-27 21:59:25,164] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 143500, global step 2282037: learning rate 0.0000
[2019-04-27 21:59:26,102] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.6568275e-32 1.0000000e+00 0.0000000e+00 1.1196370e-34 0.0000000e+00], sum to 1.0000
[2019-04-27 21:59:26,109] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5395
[2019-04-27 21:59:26,113] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.2, 71.0, 1.0, 2.0, 0.4912622727484668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 589847.3569530859, 589847.3569530859, 141669.2684141638], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5950800.0000, 
sim time next is 5951400.0000, 
raw observation next is [24.98333333333333, 72.16666666666667, 1.0, 2.0, 0.4895213811556143, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 587936.2764403995, 587936.2764403995, 141404.3203550857], 
processed observation next is [1.0, 0.9130434782608695, 0.4808641975308641, 0.7216666666666667, 1.0, 1.0, 0.3922873585185884, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20997724158585696, 0.20997724158585696, 0.27193138529824173], 
reward next is 0.7281, 
noisyNet noise sample is [array([-0.48364732], dtype=float32), -1.3544947]. 
=============================================
[2019-04-27 21:59:26,728] A3C_AGENT_WORKER-Thread-17 INFO:Local step 142500, global step 2282786: loss 94.5568
[2019-04-27 21:59:26,729] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 142500, global step 2282787: learning rate 0.0000
[2019-04-27 21:59:26,872] A3C_AGENT_WORKER-Thread-10 INFO:Local step 142500, global step 2282857: loss 67.2598
[2019-04-27 21:59:26,875] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 142500, global step 2282858: learning rate 0.0000
[2019-04-27 21:59:27,109] A3C_AGENT_WORKER-Thread-19 INFO:Local step 142500, global step 2282972: loss 42.0166
[2019-04-27 21:59:27,111] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 142500, global step 2282972: learning rate 0.0000
[2019-04-27 21:59:28,073] A3C_AGENT_WORKER-Thread-20 INFO:Local step 142500, global step 2283429: loss 76.9338
[2019-04-27 21:59:28,075] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 142500, global step 2283430: learning rate 0.0000
[2019-04-27 21:59:28,649] A3C_AGENT_WORKER-Thread-11 INFO:Local step 142500, global step 2283695: loss 57.4968
[2019-04-27 21:59:28,653] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 142500, global step 2283696: learning rate 0.0000
[2019-04-27 21:59:28,702] A3C_AGENT_WORKER-Thread-16 INFO:Local step 142500, global step 2283718: loss 79.6821
[2019-04-27 21:59:28,704] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 142500, global step 2283718: learning rate 0.0000
[2019-04-27 21:59:29,184] A3C_AGENT_WORKER-Thread-14 INFO:Local step 142500, global step 2283952: loss 20.3680
[2019-04-27 21:59:29,186] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 142500, global step 2283952: learning rate 0.0000
[2019-04-27 21:59:29,251] A3C_AGENT_WORKER-Thread-2 INFO:Local step 142500, global step 2283983: loss 55.4476
[2019-04-27 21:59:29,252] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 142500, global step 2283984: learning rate 0.0000
[2019-04-27 21:59:29,328] A3C_AGENT_WORKER-Thread-18 INFO:Local step 142500, global step 2284016: loss 31.8797
[2019-04-27 21:59:29,332] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 142500, global step 2284017: learning rate 0.0000
[2019-04-27 21:59:29,530] A3C_AGENT_WORKER-Thread-12 INFO:Local step 142500, global step 2284117: loss 70.9672
[2019-04-27 21:59:29,531] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 142500, global step 2284117: learning rate 0.0000
[2019-04-27 21:59:34,450] A3C_AGENT_WORKER-Thread-21 INFO:Local step 143000, global step 2286465: loss 0.0046
[2019-04-27 21:59:34,452] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 143000, global step 2286465: learning rate 0.0000
[2019-04-27 21:59:37,001] A3C_AGENT_WORKER-Thread-22 INFO:Local step 144000, global step 2287675: loss 38.0347
[2019-04-27 21:59:37,003] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 144000, global step 2287676: learning rate 0.0000
[2019-04-27 21:59:38,282] A3C_AGENT_WORKER-Thread-9 INFO:Local step 143000, global step 2288282: loss 0.8211
[2019-04-27 21:59:38,283] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 143000, global step 2288282: learning rate 0.0000
[2019-04-27 21:59:39,255] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.0462396e-32 1.0000000e+00 2.5535510e-37 5.1539864e-30 9.7907042e-37], sum to 1.0000
[2019-04-27 21:59:39,261] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3860
[2019-04-27 21:59:39,267] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.16666666666666, 48.83333333333334, 1.0, 2.0, 0.507783598663727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 603097.0513937526, 603097.0513937526, 144027.8340835352], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6873000.0000, 
sim time next is 6873600.0000, 
raw observation next is [30.33333333333334, 48.66666666666667, 1.0, 2.0, 0.5129985590177474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 608064.3328104336, 608064.3328104331, 144808.282825858], 
processed observation next is [0.0, 0.5652173913043478, 0.6790123456790126, 0.4866666666666667, 1.0, 1.0, 0.4202363797830326, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21716583314658341, 0.21716583314658325, 0.27847746697280384], 
reward next is 0.7215, 
noisyNet noise sample is [array([0.9998283], dtype=float32), -2.2311285]. 
=============================================
[2019-04-27 21:59:41,044] A3C_AGENT_WORKER-Thread-15 INFO:Local step 143000, global step 2289606: loss 0.0446
[2019-04-27 21:59:41,049] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 143000, global step 2289607: learning rate 0.0000
[2019-04-27 21:59:41,380] A3C_AGENT_WORKER-Thread-13 INFO:Local step 144000, global step 2289772: loss 39.5673
[2019-04-27 21:59:41,384] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 144000, global step 2289772: learning rate 0.0000
[2019-04-27 21:59:41,805] A3C_AGENT_WORKER-Thread-3 INFO:Local step 143500, global step 2289981: loss 1.1051
[2019-04-27 21:59:41,808] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 143500, global step 2289981: learning rate 0.0000
[2019-04-27 21:59:43,440] A3C_AGENT_WORKER-Thread-17 INFO:Local step 143000, global step 2290744: loss 0.1425
[2019-04-27 21:59:43,445] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 143000, global step 2290748: learning rate 0.0000
[2019-04-27 21:59:43,771] A3C_AGENT_WORKER-Thread-10 INFO:Local step 143000, global step 2290907: loss 0.3922
[2019-04-27 21:59:43,774] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 143000, global step 2290907: learning rate 0.0000
[2019-04-27 21:59:43,946] A3C_AGENT_WORKER-Thread-19 INFO:Local step 143000, global step 2290990: loss 0.1408
[2019-04-27 21:59:43,948] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 143000, global step 2290990: learning rate 0.0000
[2019-04-27 21:59:45,126] A3C_AGENT_WORKER-Thread-20 INFO:Local step 143000, global step 2291551: loss 0.3976
[2019-04-27 21:59:45,129] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 143000, global step 2291552: learning rate 0.0000
[2019-04-27 21:59:45,546] A3C_AGENT_WORKER-Thread-11 INFO:Local step 143000, global step 2291745: loss 0.1776
[2019-04-27 21:59:45,548] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 143000, global step 2291746: learning rate 0.0000
[2019-04-27 21:59:45,637] A3C_AGENT_WORKER-Thread-16 INFO:Local step 143000, global step 2291787: loss 0.1877
[2019-04-27 21:59:45,643] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 143000, global step 2291789: learning rate 0.0000
[2019-04-27 21:59:46,095] A3C_AGENT_WORKER-Thread-2 INFO:Local step 143000, global step 2292007: loss 0.2047
[2019-04-27 21:59:46,097] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 143000, global step 2292007: learning rate 0.0000
[2019-04-27 21:59:46,153] A3C_AGENT_WORKER-Thread-14 INFO:Local step 143000, global step 2292030: loss 0.2443
[2019-04-27 21:59:46,155] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 143000, global step 2292030: learning rate 0.0000
[2019-04-27 21:59:46,303] A3C_AGENT_WORKER-Thread-18 INFO:Local step 143000, global step 2292109: loss 0.1368
[2019-04-27 21:59:46,304] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 143000, global step 2292109: learning rate 0.0000
[2019-04-27 21:59:46,324] A3C_AGENT_WORKER-Thread-12 INFO:Local step 143000, global step 2292115: loss 0.1624
[2019-04-27 21:59:46,326] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 143000, global step 2292117: learning rate 0.0000
[2019-04-27 21:59:51,450] A3C_AGENT_WORKER-Thread-21 INFO:Local step 143500, global step 2294627: loss -19.7889
[2019-04-27 21:59:51,454] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 143500, global step 2294627: learning rate 0.0000
[2019-04-27 21:59:52,323] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.9810572e-34 1.0000000e+00 0.0000000e+00 1.5308026e-31 5.4156279e-38], sum to 1.0000
[2019-04-27 21:59:52,330] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1318
[2019-04-27 21:59:52,334] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.31666666666667, 71.5, 1.0, 2.0, 0.6608800867646907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 753194.437310878, 753194.4373108775, 168869.0684668426], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6475800.0000, 
sim time next is 6476400.0000, 
raw observation next is [28.2, 72.0, 1.0, 2.0, 0.6592427036458807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 751327.4234782578, 751327.4234782578, 168570.3303488005], 
processed observation next is [1.0, 1.0, 0.6, 0.72, 1.0, 1.0, 0.5943365519593817, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2683312226708064, 0.2683312226708064, 0.3241737122092317], 
reward next is 0.6758, 
noisyNet noise sample is [array([0.67614704], dtype=float32), -0.4599821]. 
=============================================
[2019-04-27 21:59:53,140] A3C_AGENT_WORKER-Thread-22 INFO:Local step 144500, global step 2295576: loss 0.0377
[2019-04-27 21:59:53,143] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 144500, global step 2295576: learning rate 0.0000
[2019-04-27 21:59:53,716] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0022216e-32 1.0000000e+00 0.0000000e+00 2.1889959e-31 0.0000000e+00], sum to 1.0000
[2019-04-27 21:59:53,722] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5078
[2019-04-27 21:59:53,727] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.2, 68.0, 1.0, 2.0, 0.6730435517253472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 767063.8794604953, 767063.8794604953, 171102.9612840949], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6471000.0000, 
sim time next is 6471600.0000, 
raw observation next is [29.1, 68.33333333333334, 1.0, 2.0, 0.6715352287084476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 765343.9941575972, 765343.9941575972, 170824.528098556], 
processed observation next is [1.0, 0.9130434782608695, 0.6333333333333334, 0.6833333333333335, 1.0, 1.0, 0.6089705103671995, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2733371407705704, 0.2733371407705704, 0.3285087078818385], 
reward next is 0.6715, 
noisyNet noise sample is [array([-0.6978681], dtype=float32), -0.89937776]. 
=============================================
[2019-04-27 21:59:54,752] A3C_AGENT_WORKER-Thread-9 INFO:Local step 143500, global step 2296395: loss -7.6187
[2019-04-27 21:59:54,753] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 143500, global step 2296395: learning rate 0.0000
[2019-04-27 21:59:57,075] A3C_AGENT_WORKER-Thread-13 INFO:Local step 144500, global step 2297583: loss 0.2671
[2019-04-27 21:59:57,078] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 144500, global step 2297585: learning rate 0.0000
[2019-04-27 21:59:57,255] A3C_AGENT_WORKER-Thread-15 INFO:Local step 143500, global step 2297673: loss 34.6565
[2019-04-27 21:59:57,256] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 143500, global step 2297673: learning rate 0.0000
[2019-04-27 21:59:57,491] A3C_AGENT_WORKER-Thread-3 INFO:Local step 144000, global step 2297789: loss 45.9153
[2019-04-27 21:59:57,493] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 144000, global step 2297789: learning rate 0.0000
[2019-04-27 21:59:58,355] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.2760087e-31 1.0000000e+00 1.2032996e-35 2.3315634e-29 9.1855333e-35], sum to 1.0000
[2019-04-27 21:59:58,362] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6226
[2019-04-27 21:59:58,369] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.21666666666667, 51.16666666666667, 1.0, 2.0, 0.376815483784276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 482693.0523720703, 482693.0523720703, 125595.3107556165], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6682200.0000, 
sim time next is 6682800.0000, 
raw observation next is [23.43333333333334, 50.33333333333334, 1.0, 2.0, 0.4705817381555523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 602336.7627038907, 602336.7627038902, 139251.9643351559], 
processed observation next is [1.0, 0.34782608695652173, 0.42345679012345705, 0.5033333333333334, 1.0, 1.0, 0.36974016447089564, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21512027239424666, 0.2151202723942465, 0.26779223910606903], 
reward next is 0.7322, 
noisyNet noise sample is [array([0.59297067], dtype=float32), 1.3087834]. 
=============================================
[2019-04-27 21:59:59,287] A3C_AGENT_WORKER-Thread-17 INFO:Local step 143500, global step 2298691: loss -23.0989
[2019-04-27 21:59:59,288] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 143500, global step 2298691: learning rate 0.0000
[2019-04-27 21:59:59,675] A3C_AGENT_WORKER-Thread-10 INFO:Local step 143500, global step 2298885: loss 25.1242
[2019-04-27 21:59:59,677] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 143500, global step 2298887: learning rate 0.0000
[2019-04-27 21:59:59,902] A3C_AGENT_WORKER-Thread-19 INFO:Local step 143500, global step 2299000: loss -28.3343
[2019-04-27 21:59:59,905] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 143500, global step 2299000: learning rate 0.0000
[2019-04-27 22:00:00,093] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.4329314e-27 1.0000000e+00 2.5109603e-31 4.3156808e-27 2.6803568e-31], sum to 1.0000
[2019-04-27 22:00:00,101] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1716
[2019-04-27 22:00:00,108] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1455954.874927332 W.
[2019-04-27 22:00:00,117] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.7, 49.83333333333334, 1.0, 2.0, 0.961939512033374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.426104948160101, 6.9112, 121.9240374862811, 1455954.874927332, 1192281.856081689, 235853.6068350162], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6783000.0000, 
sim time next is 6783600.0000, 
raw observation next is [26.8, 49.66666666666667, 1.0, 2.0, 0.4104893088504898, 1.0, 1.0, 0.4104893088504898, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9257325421836, 998961.3677688004, 998961.3677687999, 211638.4180459459], 
processed observation next is [1.0, 0.5217391304347826, 0.5481481481481482, 0.4966666666666667, 1.0, 1.0, 0.29820155815534505, 1.0, 0.5, 0.29820155815534505, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094600702546944, 0.3567719170602858, 0.35677191706028566, 0.4069969577806652], 
reward next is 0.5930, 
noisyNet noise sample is [array([0.5775597], dtype=float32), -0.58904904]. 
=============================================
[2019-04-27 22:00:01,224] A3C_AGENT_WORKER-Thread-20 INFO:Local step 143500, global step 2299667: loss -9.1122
[2019-04-27 22:00:01,228] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 143500, global step 2299667: learning rate 0.0000
[2019-04-27 22:00:01,501] A3C_AGENT_WORKER-Thread-16 INFO:Local step 143500, global step 2299811: loss -11.7987
[2019-04-27 22:00:01,505] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 143500, global step 2299811: learning rate 0.0000
[2019-04-27 22:00:01,527] A3C_AGENT_WORKER-Thread-11 INFO:Local step 143500, global step 2299823: loss 8.9136
[2019-04-27 22:00:01,528] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 143500, global step 2299823: learning rate 0.0000
[2019-04-27 22:00:01,864] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-04-27 22:00:01,866] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 22:00:01,867] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 22:00:01,868] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 22:00:01,869] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:00:01,868] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:00:01,873] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 22:00:01,875] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 22:00:01,872] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:00:01,877] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:00:01,879] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:00:01,907] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run93
[2019-04-27 22:00:01,928] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run93
[2019-04-27 22:00:01,951] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run93
[2019-04-27 22:00:01,970] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run93
[2019-04-27 22:00:01,989] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run93
[2019-04-27 22:00:07,064] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.15458702]
[2019-04-27 22:00:07,065] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.33333333333334, 25.66666666666666, 1.0, 2.0, 0.3316447058545079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 425038.7878057866, 425038.7878057866, 119576.0097100669]
[2019-04-27 22:00:07,065] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 22:00:07,066] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [8.0308048e-33 1.0000000e+00 2.0040911e-37 2.2636227e-31 3.4213576e-38], sampled 0.604665255661411
[2019-04-27 22:00:35,341] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.15458702]
[2019-04-27 22:00:35,342] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [31.45, 32.0, 1.0, 2.0, 0.6002470012462553, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9568491941964253, 6.911199999999999, 6.9112, 121.9260426156618, 1444981.030567732, 1444981.030567732, 288322.9431411255]
[2019-04-27 22:00:35,343] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 22:00:35,344] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.9530463e-27 1.0000000e+00 6.1327308e-31 4.8347556e-26 1.1223970e-31], sampled 0.7527497538611625
[2019-04-27 22:00:35,346] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1444981.030567732 W.
[2019-04-27 22:00:38,891] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.15458702]
[2019-04-27 22:00:38,894] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.0, 60.5, 1.0, 2.0, 0.8166590807577857, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1645954.813320834, 1645954.813320834, 339567.2446351812]
[2019-04-27 22:00:38,894] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 22:00:38,897] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.5674111e-28 1.0000000e+00 3.7777882e-32 4.9656699e-27 6.9560238e-33], sampled 0.7316863090330623
[2019-04-27 22:00:38,899] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1645954.813320834 W.
[2019-04-27 22:01:15,079] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.15458702]
[2019-04-27 22:01:15,080] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.70946781, 76.96287031, 1.0, 2.0, 0.498956366099682, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 593747.8652031585, 593747.8652031585, 142680.0041658973]
[2019-04-27 22:01:15,081] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 22:01:15,082] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [8.5099803e-29 1.0000000e+00 7.9643577e-33 1.4948656e-27 1.7621832e-33], sampled 0.9704990035661885
[2019-04-27 22:01:43,808] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.15458702]
[2019-04-27 22:01:43,809] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [32.0, 23.66666666666666, 1.0, 2.0, 0.905348746649485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.161800936318166, 6.9112, 121.9248030768162, 1271569.788152653, 1143241.014944529, 222950.3620947638]
[2019-04-27 22:01:43,810] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 22:01:43,817] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.0417430e-27 1.0000000e+00 2.9634008e-31 2.8732749e-26 6.7160612e-32], sampled 0.7020288778262915
[2019-04-27 22:01:50,537] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-04-27 22:01:50,897] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-04-27 22:01:51,057] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-04-27 22:01:51,186] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-04-27 22:01:51,200] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-04-27 22:01:52,217] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 2300000, evaluation results [2300000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-04-27 22:01:52,243] A3C_AGENT_WORKER-Thread-2 INFO:Local step 143500, global step 2300019: loss 18.3940
[2019-04-27 22:01:52,247] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 143500, global step 2300019: learning rate 0.0000
[2019-04-27 22:01:52,516] A3C_AGENT_WORKER-Thread-14 INFO:Local step 143500, global step 2300142: loss 30.7121
[2019-04-27 22:01:52,518] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 143500, global step 2300143: learning rate 0.0000
[2019-04-27 22:01:52,637] A3C_AGENT_WORKER-Thread-18 INFO:Local step 143500, global step 2300202: loss -12.8274
[2019-04-27 22:01:52,639] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 143500, global step 2300203: learning rate 0.0000
[2019-04-27 22:01:52,690] A3C_AGENT_WORKER-Thread-12 INFO:Local step 143500, global step 2300224: loss 13.5643
[2019-04-27 22:01:52,691] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 143500, global step 2300224: learning rate 0.0000
[2019-04-27 22:01:57,387] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2977601e-29 1.0000000e+00 3.3461145e-34 1.0670824e-26 2.0754565e-33], sum to 1.0000
[2019-04-27 22:01:57,393] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8405
[2019-04-27 22:01:57,396] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.41666666666667, 83.33333333333334, 1.0, 2.0, 0.3769921223279845, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 482822.4138636118, 482822.4138636118, 125619.549212766], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6754200.0000, 
sim time next is 6754800.0000, 
raw observation next is [18.33333333333334, 83.66666666666667, 1.0, 2.0, 0.3494749944081897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 447732.0881857208, 447732.0881857208, 121908.5751187706], 
processed observation next is [1.0, 0.17391304347826086, 0.2345679012345681, 0.8366666666666667, 1.0, 1.0, 0.22556546953355916, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.159904317209186, 0.159904317209186, 0.23443956753609732], 
reward next is 0.7656, 
noisyNet noise sample is [array([0.39687854], dtype=float32), -0.27656105]. 
=============================================
[2019-04-27 22:01:57,560] A3C_AGENT_WORKER-Thread-21 INFO:Local step 144000, global step 2302554: loss 31.5136
[2019-04-27 22:01:57,563] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 144000, global step 2302554: learning rate 0.0000
[2019-04-27 22:01:59,228] A3C_AGENT_WORKER-Thread-22 INFO:Local step 145000, global step 2303340: loss 0.0190
[2019-04-27 22:01:59,230] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 145000, global step 2303340: learning rate 0.0000
[2019-04-27 22:02:01,232] A3C_AGENT_WORKER-Thread-9 INFO:Local step 144000, global step 2304298: loss 32.1465
[2019-04-27 22:02:01,233] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 144000, global step 2304298: learning rate 0.0000
[2019-04-27 22:02:02,568] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.1285720e-29 1.0000000e+00 1.5021829e-34 7.1907912e-30 1.2965345e-34], sum to 1.0000
[2019-04-27 22:02:02,576] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8264
[2019-04-27 22:02:02,582] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 76.0, 1.0, 2.0, 0.3844480109396565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 478299.2709896212, 478299.2709896208, 126491.5799831973], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6838800.0000, 
sim time next is 6839400.0000, 
raw observation next is [21.95, 76.0, 1.0, 2.0, 0.3822108519619408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 475824.0148855845, 475824.0148855841, 126189.0426615683], 
processed observation next is [0.0, 0.13043478260869565, 0.36851851851851847, 0.76, 1.0, 1.0, 0.26453672852612004, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16993714817342304, 0.1699371481734229, 0.24267123588763134], 
reward next is 0.7573, 
noisyNet noise sample is [array([1.0409945], dtype=float32), -0.4528622]. 
=============================================
[2019-04-27 22:02:03,709] A3C_AGENT_WORKER-Thread-13 INFO:Local step 145000, global step 2305489: loss 0.0034
[2019-04-27 22:02:03,710] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 145000, global step 2305489: learning rate 0.0000
[2019-04-27 22:02:04,028] A3C_AGENT_WORKER-Thread-15 INFO:Local step 144000, global step 2305637: loss 33.4965
[2019-04-27 22:02:04,031] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 144000, global step 2305637: learning rate 0.0000
[2019-04-27 22:02:04,240] A3C_AGENT_WORKER-Thread-3 INFO:Local step 144500, global step 2305741: loss 0.1964
[2019-04-27 22:02:04,244] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 144500, global step 2305741: learning rate 0.0000
[2019-04-27 22:02:06,126] A3C_AGENT_WORKER-Thread-17 INFO:Local step 144000, global step 2306648: loss 26.5764
[2019-04-27 22:02:06,128] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 144000, global step 2306648: learning rate 0.0000
[2019-04-27 22:02:06,603] A3C_AGENT_WORKER-Thread-10 INFO:Local step 144000, global step 2306870: loss 25.0708
[2019-04-27 22:02:06,607] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 144000, global step 2306870: learning rate 0.0000
[2019-04-27 22:02:06,987] A3C_AGENT_WORKER-Thread-19 INFO:Local step 144000, global step 2307061: loss 39.9061
[2019-04-27 22:02:06,991] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 144000, global step 2307062: learning rate 0.0000
[2019-04-27 22:02:08,271] A3C_AGENT_WORKER-Thread-20 INFO:Local step 144000, global step 2307674: loss 37.4347
[2019-04-27 22:02:08,273] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 144000, global step 2307675: learning rate 0.0000
[2019-04-27 22:02:08,523] A3C_AGENT_WORKER-Thread-11 INFO:Local step 144000, global step 2307791: loss 30.4882
[2019-04-27 22:02:08,527] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 144000, global step 2307793: learning rate 0.0000
[2019-04-27 22:02:08,617] A3C_AGENT_WORKER-Thread-16 INFO:Local step 144000, global step 2307839: loss 32.5994
[2019-04-27 22:02:08,619] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 144000, global step 2307839: learning rate 0.0000
[2019-04-27 22:02:08,924] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4647977e-31 1.0000000e+00 9.6630321e-36 7.1028494e-28 2.3994744e-34], sum to 1.0000
[2019-04-27 22:02:08,934] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9463
[2019-04-27 22:02:08,943] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.9, 75.0, 1.0, 2.0, 0.4168259855270609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 513497.7399163669, 513497.7399163673, 130944.3274223465], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6918000.0000, 
sim time next is 6918600.0000, 
raw observation next is [22.85, 75.5, 1.0, 2.0, 0.4176529276692133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 514351.767464844, 514351.767464844, 131059.0789590144], 
processed observation next is [0.0, 0.043478260869565216, 0.4018518518518519, 0.755, 1.0, 1.0, 0.30672967579668253, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18369705980887285, 0.18369705980887285, 0.2520366903057969], 
reward next is 0.7480, 
noisyNet noise sample is [array([0.02814019], dtype=float32), 0.09350618]. 
=============================================
[2019-04-27 22:02:09,050] A3C_AGENT_WORKER-Thread-2 INFO:Local step 144000, global step 2308040: loss 37.2208
[2019-04-27 22:02:09,057] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 144000, global step 2308042: learning rate 0.0000
[2019-04-27 22:02:09,337] A3C_AGENT_WORKER-Thread-14 INFO:Local step 144000, global step 2308177: loss 33.8802
[2019-04-27 22:02:09,341] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 144000, global step 2308178: learning rate 0.0000
[2019-04-27 22:02:09,574] A3C_AGENT_WORKER-Thread-18 INFO:Local step 144000, global step 2308290: loss 40.2079
[2019-04-27 22:02:09,576] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 144000, global step 2308291: learning rate 0.0000
[2019-04-27 22:02:09,599] A3C_AGENT_WORKER-Thread-12 INFO:Local step 144000, global step 2308301: loss 39.6048
[2019-04-27 22:02:09,600] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 144000, global step 2308301: learning rate 0.0000
[2019-04-27 22:02:10,680] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.7033908e-32 1.0000000e+00 0.0000000e+00 9.7563909e-32 9.4814018e-38], sum to 1.0000
[2019-04-27 22:02:10,688] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6680
[2019-04-27 22:02:10,691] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.66666666666666, 56.0, 1.0, 2.0, 0.5166993386318283, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 612900.6754924705, 612900.6754924705, 145415.6310619299], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6954000.0000, 
sim time next is 6954600.0000, 
raw observation next is [28.83333333333334, 55.5, 1.0, 2.0, 0.5197673693967947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 615891.9346960632, 615891.9346960632, 145881.4586976531], 
processed observation next is [0.0, 0.4782608695652174, 0.623456790123457, 0.555, 1.0, 1.0, 0.4282944873771365, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21996140524859398, 0.21996140524859398, 0.280541266726256], 
reward next is 0.7195, 
noisyNet noise sample is [array([-0.99358845], dtype=float32), 0.40571693]. 
=============================================
[2019-04-27 22:02:14,395] A3C_AGENT_WORKER-Thread-21 INFO:Local step 144500, global step 2310599: loss 0.2214
[2019-04-27 22:02:14,397] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 144500, global step 2310599: learning rate 0.0000
[2019-04-27 22:02:15,939] A3C_AGENT_WORKER-Thread-22 INFO:Local step 145500, global step 2311323: loss 0.0549
[2019-04-27 22:02:15,942] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 145500, global step 2311323: learning rate 0.0000
[2019-04-27 22:02:17,869] A3C_AGENT_WORKER-Thread-9 INFO:Local step 144500, global step 2312255: loss 0.8836
[2019-04-27 22:02:17,875] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 144500, global step 2312257: learning rate 0.0000
[2019-04-27 22:02:20,614] A3C_AGENT_WORKER-Thread-13 INFO:Local step 145500, global step 2313557: loss 0.2281
[2019-04-27 22:02:20,614] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 145500, global step 2313557: learning rate 0.0000
[2019-04-27 22:02:20,792] A3C_AGENT_WORKER-Thread-15 INFO:Local step 144500, global step 2313647: loss 0.0759
[2019-04-27 22:02:20,800] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 144500, global step 2313649: learning rate 0.0000
[2019-04-27 22:02:20,888] A3C_AGENT_WORKER-Thread-3 INFO:Local step 145000, global step 2313692: loss 0.0051
[2019-04-27 22:02:20,891] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 145000, global step 2313692: learning rate 0.0000
[2019-04-27 22:02:22,807] A3C_AGENT_WORKER-Thread-17 INFO:Local step 144500, global step 2314613: loss 0.0087
[2019-04-27 22:02:22,809] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 144500, global step 2314613: learning rate 0.0000
[2019-04-27 22:02:23,426] A3C_AGENT_WORKER-Thread-10 INFO:Local step 144500, global step 2314908: loss 0.0209
[2019-04-27 22:02:23,427] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 144500, global step 2314908: learning rate 0.0000
[2019-04-27 22:02:23,690] A3C_AGENT_WORKER-Thread-19 INFO:Local step 144500, global step 2315031: loss 0.0065
[2019-04-27 22:02:23,693] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 144500, global step 2315031: learning rate 0.0000
[2019-04-27 22:02:24,846] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 22:02:24,847] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:02:24,867] A3C_AGENT_WORKER-Thread-20 INFO:Local step 144500, global step 2315590: loss 0.0753
[2019-04-27 22:02:24,870] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 144500, global step 2315590: learning rate 0.0000
[2019-04-27 22:02:24,902] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run12
[2019-04-27 22:02:25,170] A3C_AGENT_WORKER-Thread-11 INFO:Local step 144500, global step 2315733: loss 0.0111
[2019-04-27 22:02:25,171] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 144500, global step 2315734: learning rate 0.0000
[2019-04-27 22:02:25,174] A3C_AGENT_WORKER-Thread-16 INFO:Local step 144500, global step 2315735: loss 0.0152
[2019-04-27 22:02:25,177] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 144500, global step 2315735: learning rate 0.0000
[2019-04-27 22:02:25,615] A3C_AGENT_WORKER-Thread-2 INFO:Local step 144500, global step 2315980: loss 0.0366
[2019-04-27 22:02:25,618] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 144500, global step 2315981: learning rate 0.0000
[2019-04-27 22:02:25,708] A3C_AGENT_WORKER-Thread-14 INFO:Local step 144500, global step 2316033: loss 0.0055
[2019-04-27 22:02:25,711] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 144500, global step 2316033: learning rate 0.0000
[2019-04-27 22:02:26,028] A3C_AGENT_WORKER-Thread-18 INFO:Local step 144500, global step 2316231: loss 0.0272
[2019-04-27 22:02:26,030] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 144500, global step 2316231: learning rate 0.0000
[2019-04-27 22:02:26,120] A3C_AGENT_WORKER-Thread-12 INFO:Local step 144500, global step 2316281: loss 0.0559
[2019-04-27 22:02:26,123] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 144500, global step 2316282: learning rate 0.0000
[2019-04-27 22:02:29,236] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 22:02:29,236] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:02:29,312] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run12
[2019-04-27 22:02:29,362] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.0334807e-30 1.0000000e+00 6.2338376e-34 2.5244799e-26 2.0672320e-32], sum to 1.0000
[2019-04-27 22:02:29,372] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6114
[2019-04-27 22:02:29,377] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.36666666666667, 82.66666666666667, 1.0, 2.0, 0.7365897910081004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 899706.6556966226, 899706.6556966226, 185745.1352080615], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7293000.0000, 
sim time next is 7293600.0000, 
raw observation next is [22.5, 82.0, 1.0, 2.0, 0.742124758414991, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 905871.8541652694, 905871.854165269, 186836.59658759], 
processed observation next is [1.0, 0.43478260869565216, 0.3888888888888889, 0.82, 1.0, 1.0, 0.6930056647797512, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.32352566220188195, 0.3235256622018818, 0.35930114728382695], 
reward next is 0.6407, 
noisyNet noise sample is [array([0.75719273], dtype=float32), -0.18074134]. 
=============================================
[2019-04-27 22:02:30,276] A3C_AGENT_WORKER-Thread-21 INFO:Local step 145000, global step 2318340: loss 0.0157
[2019-04-27 22:02:30,278] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 145000, global step 2318341: learning rate 0.0000
[2019-04-27 22:02:33,666] A3C_AGENT_WORKER-Thread-9 INFO:Local step 145000, global step 2320097: loss 0.0252
[2019-04-27 22:02:33,670] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 145000, global step 2320098: learning rate 0.0000
[2019-04-27 22:02:34,289] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.4510622e-32 1.0000000e+00 9.8108928e-37 6.8083121e-30 1.2011939e-36], sum to 1.0000
[2019-04-27 22:02:34,300] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1684
[2019-04-27 22:02:34,310] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.6, 95.0, 1.0, 2.0, 0.7019765394769917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 872664.1796039644, 872664.1796039644, 179333.9751909305], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7381800.0000, 
sim time next is 7382400.0000, 
raw observation next is [19.63333333333333, 95.0, 1.0, 2.0, 0.6554380369071395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 814491.5402921325, 814491.5402921325, 170459.5007462053], 
processed observation next is [1.0, 0.43478260869565216, 0.2827160493827159, 0.95, 1.0, 1.0, 0.5898071867942137, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29088983581861877, 0.29088983581861877, 0.32780673220424095], 
reward next is 0.6722, 
noisyNet noise sample is [array([-0.84800106], dtype=float32), 0.17547604]. 
=============================================
[2019-04-27 22:02:35,894] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.1917437e-32 1.0000000e+00 1.3227608e-36 2.9560297e-30 5.9141984e-36], sum to 1.0000
[2019-04-27 22:02:35,903] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6868
[2019-04-27 22:02:35,908] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.2, 90.0, 1.0, 2.0, 0.836787159252744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9259471227492, 1024645.926452411, 1024645.92645241, 206761.7152974361], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7401600.0000, 
sim time next is 7402200.0000, 
raw observation next is [21.2, 89.83333333333333, 1.0, 2.0, 0.8761845660644688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260425865436, 1073463.822164229, 1073463.822164229, 215504.1866956083], 
processed observation next is [1.0, 0.6956521739130435, 0.34074074074074073, 0.8983333333333333, 1.0, 1.0, 0.8526006738862724, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621286268214, 0.3833799364872246, 0.3833799364872246, 0.4144311282607852], 
reward next is 0.5856, 
noisyNet noise sample is [array([-0.18563433], dtype=float32), 0.46995145]. 
=============================================
[2019-04-27 22:02:36,549] A3C_AGENT_WORKER-Thread-15 INFO:Local step 145000, global step 2321563: loss 0.0397
[2019-04-27 22:02:36,553] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 145000, global step 2321564: learning rate 0.0000
[2019-04-27 22:02:36,655] A3C_AGENT_WORKER-Thread-3 INFO:Local step 145500, global step 2321620: loss 0.5923
[2019-04-27 22:02:36,661] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 145500, global step 2321622: learning rate 0.0000
[2019-04-27 22:02:38,217] A3C_AGENT_WORKER-Thread-17 INFO:Local step 145000, global step 2322418: loss 0.0473
[2019-04-27 22:02:38,223] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 145000, global step 2322420: learning rate 0.0000
[2019-04-27 22:02:38,796] A3C_AGENT_WORKER-Thread-10 INFO:Local step 145000, global step 2322714: loss 0.0248
[2019-04-27 22:02:38,797] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 145000, global step 2322715: learning rate 0.0000
[2019-04-27 22:02:39,217] A3C_AGENT_WORKER-Thread-19 INFO:Local step 145000, global step 2322928: loss 0.0057
[2019-04-27 22:02:39,220] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 145000, global step 2322930: learning rate 0.0000
[2019-04-27 22:02:40,164] A3C_AGENT_WORKER-Thread-20 INFO:Local step 145000, global step 2323408: loss 0.0056
[2019-04-27 22:02:40,166] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 145000, global step 2323408: learning rate 0.0000
[2019-04-27 22:02:40,453] A3C_AGENT_WORKER-Thread-11 INFO:Local step 145000, global step 2323557: loss 0.0089
[2019-04-27 22:02:40,456] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 145000, global step 2323557: learning rate 0.0000
[2019-04-27 22:02:40,491] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.1567364e-31 1.0000000e+00 2.6483363e-35 3.9915748e-30 9.2974472e-38], sum to 1.0000
[2019-04-27 22:02:40,499] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0551
[2019-04-27 22:02:40,507] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 84.66666666666667, 1.0, 2.0, 0.4944272570502453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 589003.7397275171, 589003.7397275171, 141996.2653553995], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7554000.0000, 
sim time next is 7554600.0000, 
raw observation next is [23.85, 84.0, 1.0, 2.0, 0.4987379226910527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 593153.3766666291, 593153.3766666291, 142633.6857086556], 
processed observation next is [0.0, 0.43478260869565216, 0.43888888888888894, 0.84, 1.0, 1.0, 0.4032594317750628, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21184049166665325, 0.21184049166665325, 0.2742955494397223], 
reward next is 0.7257, 
noisyNet noise sample is [array([-0.74227357], dtype=float32), -0.6397928]. 
=============================================
[2019-04-27 22:02:40,532] A3C_AGENT_WORKER-Thread-16 INFO:Local step 145000, global step 2323594: loss 0.0043
[2019-04-27 22:02:40,533] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 145000, global step 2323594: learning rate 0.0000
[2019-04-27 22:02:40,985] A3C_AGENT_WORKER-Thread-2 INFO:Local step 145000, global step 2323822: loss 0.0055
[2019-04-27 22:02:40,987] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 145000, global step 2323824: learning rate 0.0000
[2019-04-27 22:02:41,116] A3C_AGENT_WORKER-Thread-14 INFO:Local step 145000, global step 2323891: loss 0.0081
[2019-04-27 22:02:41,120] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 145000, global step 2323891: learning rate 0.0000
[2019-04-27 22:02:41,533] A3C_AGENT_WORKER-Thread-18 INFO:Local step 145000, global step 2324100: loss 0.0040
[2019-04-27 22:02:41,535] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 145000, global step 2324100: learning rate 0.0000
[2019-04-27 22:02:41,663] A3C_AGENT_WORKER-Thread-12 INFO:Local step 145000, global step 2324162: loss 0.0041
[2019-04-27 22:02:41,668] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 145000, global step 2324162: learning rate 0.0000
[2019-04-27 22:02:41,910] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.6253031e-36 1.0000000e+00 0.0000000e+00 1.8049951e-36 0.0000000e+00], sum to 1.0000
[2019-04-27 22:02:41,920] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7956
[2019-04-27 22:02:41,925] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 95.0, 1.0, 2.0, 0.4680579868914188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 564505.8088021441, 564505.8088021441, 138184.879489176], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7515600.0000, 
sim time next is 7516200.0000, 
raw observation next is [21.55, 95.0, 1.0, 2.0, 0.4653259475771761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 561694.9564563504, 561694.9564563499, 137786.2826875444], 
processed observation next is [0.0, 1.0, 0.35370370370370374, 0.95, 1.0, 1.0, 0.3634832709252097, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20060534159155372, 0.20060534159155355, 0.26497362055296997], 
reward next is 0.7350, 
noisyNet noise sample is [array([-0.5875742], dtype=float32), -1.0535439]. 
=============================================
[2019-04-27 22:02:43,146] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2026397e-26 1.0000000e+00 1.1841096e-30 1.9870450e-24 4.2566480e-31], sum to 1.0000
[2019-04-27 22:02:43,157] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4808
[2019-04-27 22:02:43,164] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.1, 86.33333333333333, 1.0, 2.0, 0.4494104977753856, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 547108.9795020476, 547108.9795020476, 135541.517905049], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7605600.0000, 
sim time next is 7606200.0000, 
raw observation next is [22.0, 86.16666666666667, 1.0, 2.0, 0.4438736098574696, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 541403.6652583255, 541403.6652583255, 134749.2888338913], 
processed observation next is [1.0, 0.0, 0.37037037037037035, 0.8616666666666667, 1.0, 1.0, 0.3379447736398447, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1933584518779734, 0.1933584518779734, 0.25913324775748325], 
reward next is 0.7409, 
noisyNet noise sample is [array([0.28535137], dtype=float32), 0.83434004]. 
=============================================
[2019-04-27 22:02:43,321] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-04-27 22:02:43,323] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 22:02:43,323] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 22:02:43,324] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:02:43,324] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:02:43,325] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 22:02:43,326] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 22:02:43,327] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:02:43,328] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:02:43,328] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 22:02:43,330] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:02:43,358] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run94
[2019-04-27 22:02:43,380] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run94
[2019-04-27 22:02:43,404] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run94
[2019-04-27 22:02:43,426] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run94
[2019-04-27 22:02:43,426] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run94
[2019-04-27 22:02:55,372] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.15812464]
[2019-04-27 22:02:55,374] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.72120291666667, 56.34704476333334, 1.0, 2.0, 0.4064803760521721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 501926.1235912066, 501926.1235912066, 129495.6807328036]
[2019-04-27 22:02:55,375] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 22:02:55,377] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.9576237e-35 1.0000000e+00 0.0000000e+00 9.5676029e-34 0.0000000e+00], sampled 0.2282027013847604
[2019-04-27 22:02:55,696] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.15812464]
[2019-04-27 22:02:55,697] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [17.0, 45.0, 1.0, 2.0, 0.208632388113524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 269108.4692747743, 269108.4692747747, 75926.63321967192]
[2019-04-27 22:02:55,698] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 22:02:55,701] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0196911e-32 1.0000000e+00 3.3422439e-37 4.1304403e-31 4.9368574e-38], sampled 0.14705010757781523
[2019-04-27 22:03:08,432] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.15812464]
[2019-04-27 22:03:08,433] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.68600792166667, 75.26764719833334, 1.0, 2.0, 0.6312487310859332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 779781.7875440099, 779781.7875440099, 165893.3012526439]
[2019-04-27 22:03:08,434] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 22:03:08,436] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.6319584e-31 1.0000000e+00 5.9831629e-35 2.8919752e-29 9.5631409e-36], sampled 0.9966995538049231
[2019-04-27 22:03:25,968] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.15812464]
[2019-04-27 22:03:25,970] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.73910309333333, 69.12852313333333, 1.0, 2.0, 0.6157925353599881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 707276.0504886942, 707276.0504886938, 161084.9445685658]
[2019-04-27 22:03:25,970] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 22:03:25,975] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.6056125e-31 1.0000000e+00 1.3686449e-35 8.3417187e-30 1.9074876e-36], sampled 0.2853750989406517
[2019-04-27 22:03:51,710] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.15812464]
[2019-04-27 22:03:51,711] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.0, 94.0, 1.0, 2.0, 0.4413991539888484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 538372.5536553881, 538372.5536553885, 134382.743652641]
[2019-04-27 22:03:51,711] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 22:03:51,713] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.4955385e-32 1.0000000e+00 2.8725151e-36 2.1539010e-30 3.9284929e-37], sampled 0.9832332138936906
[2019-04-27 22:04:05,005] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.15812464]
[2019-04-27 22:04:05,007] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.16666666666667, 92.66666666666667, 1.0, 2.0, 0.4284357276938519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 523053.8584889029, 523053.8584889024, 132497.1308744214]
[2019-04-27 22:04:05,007] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 22:04:05,011] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.1733521e-31 1.0000000e+00 1.7061675e-35 9.8107406e-30 2.5633805e-36], sampled 0.574616823100703
[2019-04-27 22:04:32,432] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-04-27 22:04:32,684] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-04-27 22:04:32,717] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-04-27 22:04:32,740] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-04-27 22:04:32,787] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-04-27 22:04:33,805] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 2325000, evaluation results [2325000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-04-27 22:04:35,665] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 22:04:35,666] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:04:35,721] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run12
[2019-04-27 22:04:36,585] A3C_AGENT_WORKER-Thread-21 INFO:Local step 145500, global step 2326384: loss 0.4189
[2019-04-27 22:04:36,592] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 145500, global step 2326386: learning rate 0.0000
[2019-04-27 22:04:37,187] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1091474e-23 1.0000000e+00 2.0358944e-27 9.1164704e-23 6.5484054e-25], sum to 1.0000
[2019-04-27 22:04:37,196] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9691
[2019-04-27 22:04:37,199] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.63333333333333, 75.0, 1.0, 2.0, 0.2692745886661091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 347346.6718483305, 347346.6718483309, 111197.957303708], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6000.0000, 
sim time next is 6600.0000, 
raw observation next is [18.61666666666667, 75.0, 1.0, 2.0, 0.2676749722897935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 345282.8161442537, 345282.8161442537, 110722.939811034], 
processed observation next is [1.0, 0.043478260869565216, 0.24506172839506188, 0.75, 1.0, 1.0, 0.12818449082118272, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.12331529148009061, 0.12331529148009061, 0.2129287304058346], 
reward next is 0.7871, 
noisyNet noise sample is [array([1.0842553], dtype=float32), -0.097791836]. 
=============================================
[2019-04-27 22:04:39,950] A3C_AGENT_WORKER-Thread-9 INFO:Local step 145500, global step 2328042: loss 0.0217
[2019-04-27 22:04:39,952] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 145500, global step 2328042: learning rate 0.0000
[2019-04-27 22:04:41,136] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.4611026e-29 1.0000000e+00 5.4277641e-32 1.1648282e-28 6.2626100e-33], sum to 1.0000
[2019-04-27 22:04:41,141] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6557
[2019-04-27 22:04:41,146] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.26666666666667, 90.33333333333334, 1.0, 2.0, 0.30752376547701, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 391551.9362631745, 391551.9362631745, 116506.9253880441], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7706400.0000, 
sim time next is 7707000.0000, 
raw observation next is [18.18333333333334, 92.16666666666667, 1.0, 2.0, 0.3103585014018716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 394639.0130860892, 394639.0130860892, 116858.779770845], 
processed observation next is [1.0, 0.17391304347826086, 0.22901234567901263, 0.9216666666666667, 1.0, 1.0, 0.17899821595460905, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14094250467360328, 0.14094250467360328, 0.22472842263624038], 
reward next is 0.7753, 
noisyNet noise sample is [array([-0.17384578], dtype=float32), -2.0490377]. 
=============================================
[2019-04-27 22:04:41,166] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[68.234886]
 [68.42052 ]
 [68.56545 ]
 [68.68203 ]
 [69.10808 ]], R is [[68.15541077]
 [68.24980164]
 [68.34314728]
 [68.43643188]
 [68.52465057]].
[2019-04-27 22:04:43,011] A3C_AGENT_WORKER-Thread-15 INFO:Local step 145500, global step 2329496: loss 0.0269
[2019-04-27 22:04:43,013] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 145500, global step 2329497: learning rate 0.0000
[2019-04-27 22:04:44,726] A3C_AGENT_WORKER-Thread-17 INFO:Local step 145500, global step 2330309: loss 0.0220
[2019-04-27 22:04:44,730] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 145500, global step 2330310: learning rate 0.0000
[2019-04-27 22:04:45,075] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 22:04:45,077] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:04:45,130] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run12
[2019-04-27 22:04:45,385] A3C_AGENT_WORKER-Thread-10 INFO:Local step 145500, global step 2330625: loss 0.0312
[2019-04-27 22:04:45,388] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 145500, global step 2330626: learning rate 0.0000
[2019-04-27 22:04:45,617] A3C_AGENT_WORKER-Thread-19 INFO:Local step 145500, global step 2330750: loss 0.0409
[2019-04-27 22:04:45,618] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 145500, global step 2330750: learning rate 0.0000
[2019-04-27 22:04:45,894] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.2301517e-32 1.0000000e+00 1.6921152e-35 1.3373525e-29 1.1743932e-37], sum to 1.0000
[2019-04-27 22:04:45,900] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0419
[2019-04-27 22:04:45,905] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.53333333333333, 70.66666666666667, 1.0, 2.0, 0.3758581387554833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 469047.4860167538, 469047.4860167534, 125338.9934704163], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7768200.0000, 
sim time next is 7768800.0000, 
raw observation next is [22.4, 71.0, 1.0, 2.0, 0.3722607891271273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 465030.2284631637, 465030.2284631633, 124856.9039798499], 
processed observation next is [1.0, 0.9565217391304348, 0.38518518518518513, 0.71, 1.0, 1.0, 0.2526914156275325, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1660822244511299, 0.16608222445112975, 0.24010943073048058], 
reward next is 0.7599, 
noisyNet noise sample is [array([0.37030682], dtype=float32), -1.3369058]. 
=============================================
[2019-04-27 22:04:46,444] A3C_AGENT_WORKER-Thread-20 INFO:Local step 145500, global step 2331224: loss 0.0175
[2019-04-27 22:04:46,448] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 145500, global step 2331224: learning rate 0.0000
[2019-04-27 22:04:46,626] A3C_AGENT_WORKER-Thread-11 INFO:Local step 145500, global step 2331306: loss 0.0100
[2019-04-27 22:04:46,628] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 145500, global step 2331306: learning rate 0.0000
[2019-04-27 22:04:46,751] A3C_AGENT_WORKER-Thread-16 INFO:Local step 145500, global step 2331373: loss 0.0200
[2019-04-27 22:04:46,753] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 145500, global step 2331373: learning rate 0.0000
[2019-04-27 22:04:47,364] A3C_AGENT_WORKER-Thread-2 INFO:Local step 145500, global step 2331668: loss 0.0869
[2019-04-27 22:04:47,367] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 145500, global step 2331670: learning rate 0.0000
[2019-04-27 22:04:47,378] A3C_AGENT_WORKER-Thread-14 INFO:Local step 145500, global step 2331673: loss 0.0635
[2019-04-27 22:04:47,380] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 145500, global step 2331673: learning rate 0.0000
[2019-04-27 22:04:47,660] A3C_AGENT_WORKER-Thread-18 INFO:Local step 145500, global step 2331812: loss 0.1665
[2019-04-27 22:04:47,663] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 145500, global step 2331812: learning rate 0.0000
[2019-04-27 22:04:48,025] A3C_AGENT_WORKER-Thread-12 INFO:Local step 145500, global step 2331982: loss 0.0072
[2019-04-27 22:04:48,028] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 145500, global step 2331983: learning rate 0.0000
[2019-04-27 22:04:48,348] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 22:04:48,348] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:04:48,393] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run12
[2019-04-27 22:04:49,184] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.1603472e-27 1.0000000e+00 4.8942324e-32 1.0581847e-26 1.0536546e-31], sum to 1.0000
[2019-04-27 22:04:49,190] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9197
[2019-04-27 22:04:49,195] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.76666666666667, 63.33333333333333, 1.0, 2.0, 0.3762194495029246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 479118.1205071408, 479118.1205071408, 125507.7593300479], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 618000.0000, 
sim time next is 618600.0000, 
raw observation next is [21.58333333333333, 64.16666666666667, 1.0, 2.0, 0.3677192594262543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 468535.1334868283, 468535.1334868283, 124349.5147853625], 
processed observation next is [1.0, 0.13043478260869565, 0.35493827160493807, 0.6416666666666667, 1.0, 1.0, 0.2472848326503027, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.16733397624529583, 0.16733397624529583, 0.23913368227954326], 
reward next is 0.7609, 
noisyNet noise sample is [array([-1.5902125], dtype=float32), 1.4790688]. 
=============================================
[2019-04-27 22:04:51,237] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 22:04:51,239] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:04:51,307] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run12
[2019-04-27 22:04:51,543] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1489925e-30 1.0000000e+00 0.0000000e+00 1.2327966e-31 0.0000000e+00], sum to 1.0000
[2019-04-27 22:04:51,546] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3585
[2019-04-27 22:04:51,552] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1658842.366801876 W.
[2019-04-27 22:04:51,558] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [35.7, 19.16666666666667, 1.0, 2.0, 0.6860361033588472, 1.0, 2.0, 0.6860361033588472, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1658842.366801876, 1658842.366801876, 303041.1222615813], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 658200.0000, 
sim time next is 658800.0000, 
raw observation next is [35.7, 19.0, 1.0, 2.0, 0.6784756581442454, 1.0, 2.0, 0.6784756581442454, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1645241.073358166, 1645241.073358166, 300330.2780103658], 
processed observation next is [1.0, 0.6521739130434783, 0.8777777777777779, 0.19, 1.0, 1.0, 0.6172329263621968, 1.0, 1.0, 0.6172329263621968, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5875860976279165, 0.5875860976279165, 0.5775582269430112], 
reward next is 0.4224, 
noisyNet noise sample is [array([-0.29087257], dtype=float32), -0.47381213]. 
=============================================
[2019-04-27 22:04:52,940] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 22:04:52,940] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:04:52,998] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run12
[2019-04-27 22:04:53,350] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 22:04:53,352] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:04:53,399] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run12
[2019-04-27 22:04:53,488] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 22:04:53,488] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:04:53,526] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run12
[2019-04-27 22:04:54,397] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 22:04:54,397] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:04:54,446] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run12
[2019-04-27 22:04:54,520] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 22:04:54,521] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:04:54,543] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run12
[2019-04-27 22:04:54,562] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 22:04:54,563] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:04:54,588] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run12
[2019-04-27 22:04:54,898] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 22:04:54,900] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:04:54,914] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 22:04:54,915] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:04:54,950] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run12
[2019-04-27 22:04:54,978] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run12
[2019-04-27 22:04:55,076] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 22:04:55,077] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:04:55,099] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run12
[2019-04-27 22:04:55,125] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-04-27 22:04:55,126] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:04:55,131] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run12
[2019-04-27 22:04:56,425] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.8515073e-17 1.0000000e+00 6.4458064e-23 8.8339031e-14 3.8154080e-09], sum to 1.0000
[2019-04-27 22:04:56,431] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5077
[2019-04-27 22:04:56,436] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.4, 71.5, 1.0, 2.0, 0.3569965125773017, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 449772.5575231512, 449772.5575231512, 122859.0502372902], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1800.0000, 
sim time next is 2400.0000, 
raw observation next is [20.5, 72.66666666666667, 1.0, 2.0, 0.3319025418188325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 421423.9842119759, 421423.9842119759, 119596.6424619486], 
processed observation next is [1.0, 0.0, 0.3148148148148148, 0.7266666666666667, 1.0, 1.0, 0.20464588311765775, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1505085657899914, 0.1505085657899914, 0.229993543196055], 
reward next is 0.7700, 
noisyNet noise sample is [array([-0.990561], dtype=float32), -1.3706539]. 
=============================================
[2019-04-27 22:04:58,366] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.11186885e-35 1.00000000e+00 0.00000000e+00 6.87466859e-33
 0.00000000e+00], sum to 1.0000
[2019-04-27 22:04:58,377] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6071
[2019-04-27 22:04:58,382] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 14.5, 1.0, 2.0, 0.3622545630422657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 467321.3374159851, 467321.3374159851, 119365.2699088465], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 160200.0000, 
sim time next is 160800.0000, 
raw observation next is [31.93333333333334, 14.33333333333333, 1.0, 2.0, 0.362772418080954, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 467989.5927878644, 467989.5927878649, 118595.2440882957], 
processed observation next is [1.0, 0.8695652173913043, 0.7382716049382719, 0.1433333333333333, 1.0, 1.0, 0.24139573581065954, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16713914028138013, 0.16713914028138033, 0.22806777709287634], 
reward next is 0.7719, 
noisyNet noise sample is [array([-1.4990761], dtype=float32), -0.23832703]. 
=============================================
[2019-04-27 22:04:59,256] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.0724700e-29 1.0000000e+00 3.2449364e-33 4.4032136e-29 4.4491153e-32], sum to 1.0000
[2019-04-27 22:04:59,264] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3322
[2019-04-27 22:04:59,272] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1652807.191870834 W.
[2019-04-27 22:04:59,277] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.16666666666667, 36.16666666666666, 1.0, 2.0, 1.010481260083617, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.708282015269453, 6.9112, 121.9227368056944, 1652807.191870834, 1244641.024677784, 247516.6044113593], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 51000.0000, 
sim time next is 51600.0000, 
raw observation next is [30.13333333333334, 36.33333333333334, 1.0, 2.0, 0.5792394905184974, 1.0, 1.0, 0.5792394905184974, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9255626258009, 1405960.070748422, 1405960.070748422, 264530.7593887866], 
processed observation next is [1.0, 0.6086956521739131, 0.6716049382716052, 0.36333333333333345, 1.0, 1.0, 0.4990946315696398, 1.0, 0.5, 0.4990946315696398, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094589421866137, 0.5021285966958651, 0.5021285966958651, 0.5087129988245896], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.32804674], dtype=float32), 0.7419932]. 
=============================================
[2019-04-27 22:05:02,349] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.6036102e-34 1.0000000e+00 0.0000000e+00 4.3020577e-33 0.0000000e+00], sum to 1.0000
[2019-04-27 22:05:02,357] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0549
[2019-04-27 22:05:02,362] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.71666666666667, 13.66666666666667, 1.0, 2.0, 0.3651903129889456, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 471109.7231940877, 471109.7231940872, 116206.5387123522], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 162600.0000, 
sim time next is 163200.0000, 
raw observation next is [31.63333333333334, 13.33333333333333, 1.0, 2.0, 0.3616518672560241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 466543.6017816181, 466543.6017816185, 114575.6067989921], 
processed observation next is [1.0, 0.9130434782608695, 0.7271604938271607, 0.1333333333333333, 1.0, 1.0, 0.24006174673336203, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16662271492200645, 0.16662271492200662, 0.2203377053826771], 
reward next is 0.7797, 
noisyNet noise sample is [array([-0.3361305], dtype=float32), -0.74517095]. 
=============================================
[2019-04-27 22:05:02,687] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.3534564e-29 1.0000000e+00 1.9289799e-35 4.5919837e-28 4.1323233e-35], sum to 1.0000
[2019-04-27 22:05:02,698] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6523
[2019-04-27 22:05:02,703] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 73.16666666666667, 1.0, 2.0, 0.4178222339831941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 517475.190015716, 517475.190015716, 131153.3163112382], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 114600.0000, 
sim time next is 115200.0000, 
raw observation next is [22.9, 73.0, 1.0, 2.0, 0.4355331579305156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 538860.0367576529, 538860.0367576524, 133719.629624014], 
processed observation next is [1.0, 0.34782608695652173, 0.4037037037037037, 0.73, 1.0, 1.0, 0.32801566420299477, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19245001312773316, 0.192450013127733, 0.25715313389233463], 
reward next is 0.7428, 
noisyNet noise sample is [array([-0.33788916], dtype=float32), -0.6498285]. 
=============================================
[2019-04-27 22:05:06,765] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.0933719e-32 1.0000000e+00 2.1984550e-36 5.9075809e-32 0.0000000e+00], sum to 1.0000
[2019-04-27 22:05:06,772] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2632
[2019-04-27 22:05:06,779] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 26.0, 1.0, 2.0, 0.2893874703225723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 373297.3034100671, 373297.3034100666, 93365.71763252997], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 183600.0000, 
sim time next is 184200.0000, 
raw observation next is [23.81666666666667, 28.16666666666667, 1.0, 2.0, 0.2856030375659437, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 368414.3764858582, 368414.3764858582, 93240.5314386408], 
processed observation next is [0.0, 0.13043478260869565, 0.43765432098765444, 0.28166666666666673, 1.0, 1.0, 0.14952742567374247, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13157656303066365, 0.13157656303066365, 0.17930871430507847], 
reward next is 0.8207, 
noisyNet noise sample is [array([-0.20442276], dtype=float32), -0.047416825]. 
=============================================
[2019-04-27 22:05:13,922] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.3792739e-36 1.0000000e+00 0.0000000e+00 2.2064220e-34 0.0000000e+00], sum to 1.0000
[2019-04-27 22:05:13,931] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0425
[2019-04-27 22:05:13,934] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 40.0, 1.0, 2.0, 0.303167304810273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 389778.7678291199, 389778.7678291199, 115963.8980081198], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 336000.0000, 
sim time next is 336600.0000, 
raw observation next is [24.85, 40.5, 1.0, 2.0, 0.3014614846650128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 387686.8572358489, 387686.8572358489, 115751.8048616694], 
processed observation next is [0.0, 0.9130434782608695, 0.475925925925926, 0.405, 1.0, 1.0, 0.1684065293631105, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13845959186994602, 0.13845959186994602, 0.22259962473397962], 
reward next is 0.7774, 
noisyNet noise sample is [array([0.9925842], dtype=float32), -0.2187445]. 
=============================================
[2019-04-27 22:05:24,071] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-04-27 22:05:24,074] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 22:05:24,075] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:05:24,076] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 22:05:24,077] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 22:05:24,077] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:05:24,079] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:05:24,081] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 22:05:24,078] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 22:05:24,084] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:05:24,085] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:05:24,104] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run95
[2019-04-27 22:05:24,104] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run95
[2019-04-27 22:05:24,147] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run95
[2019-04-27 22:05:24,148] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run95
[2019-04-27 22:05:24,188] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run95
[2019-04-27 22:05:27,957] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16046372]
[2019-04-27 22:05:27,958] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [33.36666666666667, 13.66666666666667, 1.0, 2.0, 0.3782787623170034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 487123.8338677238, 487123.8338677238, 125785.6340415473]
[2019-04-27 22:05:27,959] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 22:05:27,960] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [7.2557182e-35 1.0000000e+00 0.0000000e+00 2.0418146e-33 0.0000000e+00], sampled 0.6239194766941744
[2019-04-27 22:05:29,168] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16046372]
[2019-04-27 22:05:29,169] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.96666666666667, 31.0, 1.0, 2.0, 0.3330331224214904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 426119.9960390076, 426119.9960390081, 119756.2165729614]
[2019-04-27 22:05:29,170] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 22:05:29,172] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.4046395e-34 1.0000000e+00 0.0000000e+00 4.0400529e-33 0.0000000e+00], sampled 0.024709237192585998
[2019-04-27 22:05:50,283] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16046372]
[2019-04-27 22:05:50,284] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.06477769333333, 90.39597722333333, 1.0, 2.0, 0.4359455817340762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 534908.7535660653, 534908.7535660653, 133668.6035140302]
[2019-04-27 22:05:50,288] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 22:05:50,290] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [5.1664166e-34 1.0000000e+00 1.5591267e-38 1.3128102e-32 0.0000000e+00], sampled 0.4288078095267962
[2019-04-27 22:05:58,605] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16046372]
[2019-04-27 22:05:58,606] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.0, 56.0, 1.0, 2.0, 0.7195912346570794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 820142.3889112349, 820142.3889112349, 179890.4205249414]
[2019-04-27 22:05:58,607] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 22:05:58,611] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.5983283e-33 1.0000000e+00 5.4914348e-38 3.6498715e-32 0.0000000e+00], sampled 0.9680840739138564
[2019-04-27 22:06:05,582] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16046372]
[2019-04-27 22:06:05,583] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [33.104359595, 44.726414415, 1.0, 2.0, 0.7244960198095154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 832964.2448316817, 832964.2448316817, 181197.8626321035]
[2019-04-27 22:06:05,584] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 22:06:05,586] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.4501379e-31 1.0000000e+00 1.6512032e-35 4.4666694e-30 4.5399537e-37], sampled 0.3323418387537246
[2019-04-27 22:06:28,073] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16046372]
[2019-04-27 22:06:28,076] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.33333333333334, 64.83333333333333, 1.0, 2.0, 0.8927524046885663, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1031880.249099066, 1031880.249099066, 216612.1070812216]
[2019-04-27 22:06:28,077] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 22:06:28,080] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.6342621e-31 1.0000000e+00 9.9535056e-36 2.8988992e-30 2.6669268e-37], sampled 0.8038157100101018
[2019-04-27 22:06:28,282] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16046372]
[2019-04-27 22:06:28,283] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.0, 68.66666666666667, 1.0, 2.0, 0.9865926413054267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.062058018084514, 6.9112, 121.9254362781335, 1201985.318323137, 1124732.913704899, 237504.2226772407]
[2019-04-27 22:06:28,283] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 22:06:28,287] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.1610470e-31 1.0000000e+00 3.7429109e-35 8.9081445e-30 1.1329203e-36], sampled 0.8676023587005908
[2019-04-27 22:06:56,949] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16046372]
[2019-04-27 22:06:56,949] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.5, 91.5, 1.0, 2.0, 0.5476969763573925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 642794.6607872177, 642794.6607872177, 150174.0227420988]
[2019-04-27 22:06:56,951] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 22:06:56,953] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [5.8836459e-34 1.0000000e+00 1.7790849e-38 1.4514419e-32 0.0000000e+00], sampled 0.18294444745136296
[2019-04-27 22:07:03,283] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16046372]
[2019-04-27 22:07:03,285] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.51091917, 88.53928752833335, 1.0, 2.0, 0.5561297496668182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 677730.4514214797, 677730.4514214793, 152478.2422363236]
[2019-04-27 22:07:03,286] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 22:07:03,291] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.8583781e-32 1.0000000e+00 8.8114867e-37 3.9259581e-31 2.2891532e-38], sampled 0.09002913023389869
[2019-04-27 22:07:10,549] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16046372]
[2019-04-27 22:07:10,550] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [19.16666666666667, 91.33333333333334, 1.0, 2.0, 0.3558324050363399, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 447712.3778960381, 447712.3778960381, 122696.2885626371]
[2019-04-27 22:07:10,552] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 22:07:10,555] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.0530039e-33 1.0000000e+00 2.6960588e-37 1.5632356e-31 0.0000000e+00], sampled 0.5205141407782181
[2019-04-27 22:07:13,170] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16046372]
[2019-04-27 22:07:13,173] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.5, 65.5, 1.0, 2.0, 0.5236360695830193, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 625241.2029701852, 625241.2029701852, 146683.6975984401]
[2019-04-27 22:07:13,173] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 22:07:13,176] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.4460831e-33 1.0000000e+00 4.1682257e-37 2.1559796e-31 0.0000000e+00], sampled 0.6801311198994396
[2019-04-27 22:07:13,482] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-04-27 22:07:13,700] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-04-27 22:07:13,746] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-04-27 22:07:13,851] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-04-27 22:07:13,984] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-04-27 22:07:15,003] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 2350000, evaluation results [2350000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-04-27 22:07:28,490] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.2347555e-35 1.0000000e+00 0.0000000e+00 4.8475523e-34 0.0000000e+00], sum to 1.0000
[2019-04-27 22:07:28,497] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4184
[2019-04-27 22:07:28,505] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.2, 40.5, 1.0, 2.0, 0.3096715006519642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 394251.8835190028, 394251.8835190028, 116775.2368598392], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 775800.0000, 
sim time next is 776400.0000, 
raw observation next is [26.03333333333333, 41.0, 1.0, 2.0, 0.3077377748939292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 391954.3853854141, 391954.3853854141, 116534.1171507278], 
processed observation next is [1.0, 1.0, 0.519753086419753, 0.41, 1.0, 1.0, 0.1758783034451538, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.13998370906621932, 0.13998370906621932, 0.2241040714437073], 
reward next is 0.7759, 
noisyNet noise sample is [array([0.22353183], dtype=float32), -0.72327965]. 
=============================================
[2019-04-27 22:07:34,806] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.5225763e-35 1.0000000e+00 0.0000000e+00 3.5766135e-33 0.0000000e+00], sum to 1.0000
[2019-04-27 22:07:34,815] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3297
[2019-04-27 22:07:34,821] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.1, 51.0, 1.0, 2.0, 0.3203365468104594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 407200.8523281922, 407200.8523281922, 118117.770592783], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 943200.0000, 
sim time next is 943800.0000, 
raw observation next is [24.0, 50.66666666666666, 1.0, 2.0, 0.3155582554593788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 401685.9050461983, 401685.9050461983, 117515.3837797811], 
processed observation next is [0.0, 0.9565217391304348, 0.4444444444444444, 0.5066666666666666, 1.0, 1.0, 0.18518839935640335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.14345925180221367, 0.14345925180221367, 0.2259911226534252], 
reward next is 0.7740, 
noisyNet noise sample is [array([0.7673905], dtype=float32), 0.4202255]. 
=============================================
[2019-04-27 22:07:39,540] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.7301764e-34 1.0000000e+00 0.0000000e+00 2.1667121e-33 0.0000000e+00], sum to 1.0000
[2019-04-27 22:07:39,549] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2921
[2019-04-27 22:07:39,555] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.65, 46.5, 1.0, 2.0, 0.2835979524466106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 364564.3301331811, 364564.3301331811, 113569.3236691056], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1027800.0000, 
sim time next is 1028400.0000, 
raw observation next is [23.6, 46.66666666666667, 1.0, 2.0, 0.2830587515776933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 363916.1781013479, 363916.1781013479, 113504.0363684698], 
processed observation next is [1.0, 0.9130434782608695, 0.4296296296296297, 0.46666666666666673, 1.0, 1.0, 0.1464985137829682, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.12997006360762425, 0.12997006360762425, 0.21827699301628806], 
reward next is 0.7817, 
noisyNet noise sample is [array([-0.704231], dtype=float32), -0.28194502]. 
=============================================
[2019-04-27 22:07:40,855] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.2664756e-27 1.0000000e+00 2.0479861e-32 1.1925117e-26 2.0458377e-33], sum to 1.0000
[2019-04-27 22:07:40,868] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3113
[2019-04-27 22:07:40,874] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.63333333333333, 60.66666666666667, 1.0, 2.0, 0.2588584172150412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 333907.5741308543, 333907.5741308543, 109453.434273958], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 969600.0000, 
sim time next is 970200.0000, 
raw observation next is [20.75, 60.5, 1.0, 2.0, 0.2595513449419527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 334777.3806723494, 334777.3806723494, 110710.4662628514], 
processed observation next is [1.0, 0.21739130434782608, 0.32407407407407407, 0.605, 1.0, 1.0, 0.11851350588327703, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1195633502401248, 0.1195633502401248, 0.21290474281317578], 
reward next is 0.7871, 
noisyNet noise sample is [array([0.99632615], dtype=float32), -1.4327239]. 
=============================================
[2019-04-27 22:07:42,642] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.6918425e-37 1.0000000e+00 0.0000000e+00 2.5024172e-34 0.0000000e+00], sum to 1.0000
[2019-04-27 22:07:42,651] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5303
[2019-04-27 22:07:42,658] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.53333333333333, 87.5, 1.0, 2.0, 0.3486061527907758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 439025.5540117469, 439025.5540117469, 121742.7293303875], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1199400.0000, 
sim time next is 1200000.0000, 
raw observation next is [19.46666666666667, 88.0, 1.0, 2.0, 0.3475120740163314, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 437680.3695988001, 437680.3695987997, 121598.7523322635], 
processed observation next is [1.0, 0.9130434782608695, 0.2765432098765433, 0.88, 1.0, 1.0, 0.22322865954325166, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15631441771385718, 0.15631441771385704, 0.2338437544851221], 
reward next is 0.7662, 
noisyNet noise sample is [array([-0.7819972], dtype=float32), 1.0713344]. 
=============================================
[2019-04-27 22:07:42,672] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[83.35635 ]
 [83.329056]
 [83.02107 ]
 [83.053825]
 [82.98725 ]], R is [[83.4220047 ]
 [83.35366058]
 [83.28573608]
 [83.21844482]
 [83.15201569]].
[2019-04-27 22:07:51,019] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.2474789e-33 1.0000000e+00 0.0000000e+00 8.1364494e-33 7.9304132e-38], sum to 1.0000
[2019-04-27 22:07:51,030] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8248
[2019-04-27 22:07:51,036] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 65.33333333333333, 1.0, 2.0, 0.6055311541032572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 773839.952954892, 773839.952954892, 161658.7845663418], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1161600.0000, 
sim time next is 1162200.0000, 
raw observation next is [21.05, 65.16666666666667, 1.0, 2.0, 0.6071226026806424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 775702.411103266, 775702.411103266, 161942.0536296495], 
processed observation next is [1.0, 0.43478260869565216, 0.3351851851851852, 0.6516666666666667, 1.0, 1.0, 0.5322888127150505, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27703657539402354, 0.27703657539402354, 0.31142702621086443], 
reward next is 0.6886, 
noisyNet noise sample is [array([0.14999919], dtype=float32), -0.32847524]. 
=============================================
[2019-04-27 22:07:56,796] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.1696815e-34 1.0000000e+00 5.4318902e-38 8.3031410e-31 1.5277811e-38], sum to 1.0000
[2019-04-27 22:07:56,806] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5328
[2019-04-27 22:07:56,810] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.53333333333334, 36.33333333333334, 1.0, 2.0, 0.5003196066633016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 594454.5911940134, 594454.5911940129, 142859.9657322529], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1527000.0000, 
sim time next is 1527600.0000, 
raw observation next is [33.36666666666667, 37.66666666666667, 1.0, 2.0, 0.5077270821579545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 601149.620111681, 601149.620111681, 143946.1929375094], 
processed observation next is [0.0, 0.6956521739130435, 0.7913580246913581, 0.3766666666666667, 1.0, 1.0, 0.41396081209280294, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.21469629289702896, 0.21469629289702896, 0.27681960180290266], 
reward next is 0.7232, 
noisyNet noise sample is [array([0.18539494], dtype=float32), 0.59125775]. 
=============================================
[2019-04-27 22:08:02,931] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.7150378e-31 1.0000000e+00 4.6999659e-35 2.5270569e-30 1.1607288e-37], sum to 1.0000
[2019-04-27 22:08:02,937] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9494
[2019-04-27 22:08:02,945] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.8, 64.0, 1.0, 2.0, 0.2835325650198129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 363959.7611884105, 363959.7611884105, 113563.9102683237], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1395000.0000, 
sim time next is 1395600.0000, 
raw observation next is [20.76666666666667, 63.66666666666667, 1.0, 2.0, 0.2804720131479989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 360282.7635492733, 360282.7635492733, 113194.4452493282], 
processed observation next is [0.0, 0.13043478260869565, 0.32469135802469146, 0.6366666666666667, 1.0, 1.0, 0.14341906327142728, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1286724155533119, 0.1286724155533119, 0.2176816254794773], 
reward next is 0.7823, 
noisyNet noise sample is [array([-0.9664977], dtype=float32), -2.0322726]. 
=============================================
[2019-04-27 22:08:03,991] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.2346241e-26 1.0000000e+00 1.6485468e-28 1.4759762e-24 1.5224713e-28], sum to 1.0000
[2019-04-27 22:08:03,998] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1158
[2019-04-27 22:08:04,003] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.86666666666667, 77.33333333333334, 1.0, 2.0, 0.7129550189896506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 885942.467518155, 885942.4675181545, 181473.5637528335], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1851600.0000, 
sim time next is 1852200.0000, 
raw observation next is [21.9, 77.5, 1.0, 2.0, 0.7131363732294191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 885519.9339120357, 885519.9339120357, 181494.2885604014], 
processed observation next is [1.0, 0.43478260869565216, 0.36666666666666664, 0.775, 1.0, 1.0, 0.6584956824159751, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31625711925429845, 0.31625711925429845, 0.3490274780007719], 
reward next is 0.6510, 
noisyNet noise sample is [array([0.779796], dtype=float32), 0.762451]. 
=============================================
[2019-04-27 22:08:05,388] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.9838235e-34 1.0000000e+00 0.0000000e+00 1.9592861e-31 0.0000000e+00], sum to 1.0000
[2019-04-27 22:08:05,398] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1853
[2019-04-27 22:08:05,403] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.96666666666667, 22.33333333333333, 1.0, 2.0, 0.3934504081526381, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 491757.1052785917, 491757.1052785917, 127786.6932127103], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1435200.0000, 
sim time next is 1435800.0000, 
raw observation next is [33.98333333333333, 22.66666666666667, 1.0, 2.0, 0.3946664621727603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 492628.9445419093, 492628.9445419089, 127945.1057815075], 
processed observation next is [0.0, 0.6086956521739131, 0.8141975308641973, 0.2266666666666667, 1.0, 1.0, 0.27936483591995276, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17593890876496762, 0.17593890876496748, 0.24604828034905288], 
reward next is 0.7540, 
noisyNet noise sample is [array([-0.2581276], dtype=float32), 0.31596723]. 
=============================================
[2019-04-27 22:08:05,426] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1380027e-33 1.0000000e+00 1.5879139e-38 2.5866462e-32 0.0000000e+00], sum to 1.0000
[2019-04-27 22:08:05,438] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3125
[2019-04-27 22:08:05,447] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.7, 25.0, 1.0, 2.0, 0.4115146387352607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 505273.9342128329, 505273.9342128329, 130140.2626642844], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1514400.0000, 
sim time next is 1515000.0000, 
raw observation next is [34.85, 24.5, 1.0, 2.0, 0.4105297618612624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 504312.722909889, 504312.722909889, 130006.3562935641], 
processed observation next is [0.0, 0.5217391304347826, 0.8462962962962963, 0.245, 1.0, 1.0, 0.2982497165015029, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18011168675353179, 0.18011168675353179, 0.2500122236414694], 
reward next is 0.7500, 
noisyNet noise sample is [array([1.2316693], dtype=float32), 0.92490214]. 
=============================================
[2019-04-27 22:08:05,471] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[83.1766 ]
 [83.09016]
 [83.01898]
 [82.94146]
 [82.87165]], R is [[83.16577148]
 [83.08384705]
 [83.00256348]
 [82.92162323]
 [82.84098816]].
[2019-04-27 22:08:06,003] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-04-27 22:08:06,005] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 22:08:06,006] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:08:06,007] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 22:08:06,007] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 22:08:06,008] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 22:08:06,008] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:08:06,009] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:08:06,009] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 22:08:06,009] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:08:06,011] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:08:06,032] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run96
[2019-04-27 22:08:06,053] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run96
[2019-04-27 22:08:06,077] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run96
[2019-04-27 22:08:06,078] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run96
[2019-04-27 22:08:06,118] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run96
[2019-04-27 22:08:15,668] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16203265]
[2019-04-27 22:08:15,670] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [34.8394326, 20.26648937, 1.0, 2.0, 0.7175711566276163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 893398.4948883785, 893398.4948883781, 182420.9220759097]
[2019-04-27 22:08:15,671] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 22:08:15,674] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.2849101e-33 1.0000000e+00 7.6675016e-38 7.5031763e-32 0.0000000e+00], sampled 0.3823120325887376
[2019-04-27 22:08:17,160] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16203265]
[2019-04-27 22:08:17,161] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.26666666666667, 15.33333333333334, 1.0, 2.0, 0.3113176084260792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 401593.6387241265, 401593.638724127, 96218.2311160746]
[2019-04-27 22:08:17,162] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 22:08:17,165] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [3.10816089e-34 1.00000000e+00 0.00000000e+00 1.19585634e-32
 0.00000000e+00], sampled 0.38667913121388187
[2019-04-27 22:08:34,677] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16203265]
[2019-04-27 22:08:34,678] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.76025312, 58.36657461333334, 1.0, 2.0, 0.5896777956294477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 678987.196484882, 678987.1964848817, 156651.0364120796]
[2019-04-27 22:08:34,678] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 22:08:34,682] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.8454700e-35 1.0000000e+00 0.0000000e+00 3.9399367e-33 0.0000000e+00], sampled 0.5987578551009879
[2019-04-27 22:09:00,782] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16203265]
[2019-04-27 22:09:00,783] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.89241397, 107.3470596, 1.0, 2.0, 0.5823309483591107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 687818.1007654947, 687818.1007654947, 156161.8339926247]
[2019-04-27 22:09:00,783] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 22:09:00,787] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.0150189e-35 1.0000000e+00 0.0000000e+00 3.5915705e-33 0.0000000e+00], sampled 0.9985298569248985
[2019-04-27 22:09:29,896] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16203265]
[2019-04-27 22:09:29,897] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.0, 89.0, 1.0, 2.0, 0.5428663492217721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 634902.5480540915, 634902.5480540915, 149286.3734582047]
[2019-04-27 22:09:29,898] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 22:09:29,899] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.7124371e-32 1.0000000e+00 1.4657945e-36 8.1441587e-31 4.1679215e-38], sampled 0.12202343887192457
[2019-04-27 22:09:33,172] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16203265]
[2019-04-27 22:09:33,173] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.01666666666667, 88.0, 1.0, 2.0, 0.5589769519272273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 655443.3117704917, 655443.3117704917, 152017.4523975722]
[2019-04-27 22:09:33,174] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 22:09:33,178] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.8295710e-33 1.0000000e+00 1.6193385e-37 1.2537207e-31 0.0000000e+00], sampled 0.7123869461699704
[2019-04-27 22:09:34,888] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16203265]
[2019-04-27 22:09:34,890] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [30.07162964333333, 60.39903222, 1.0, 2.0, 0.622980663258562, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9918055049713798, 6.911199999999999, 6.9112, 121.9260426156618, 1420620.31854468, 1420620.318544681, 302907.3485022619]
[2019-04-27 22:09:34,892] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 22:09:34,894] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.2989438e-32 1.0000000e+00 8.3909331e-37 5.5487095e-31 2.3777471e-38], sampled 0.20956819199339505
[2019-04-27 22:09:34,896] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1420620.31854468 W.
[2019-04-27 22:09:35,998] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16203265]
[2019-04-27 22:09:36,000] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.36666666666667, 79.66666666666666, 1.0, 2.0, 0.8974615158906255, 1.0, 2.0, 0.8974615158906255, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2047283.543530888, 2047283.543530888, 385673.6426837728]
[2019-04-27 22:09:36,001] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 22:09:36,004] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.2327881e-28 1.0000000e+00 1.4118348e-31 1.1395968e-26 5.3877619e-33], sampled 0.5185576910181374
[2019-04-27 22:09:36,007] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2047283.543530888 W.
[2019-04-27 22:09:55,855] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-04-27 22:09:55,937] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-04-27 22:09:56,157] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-04-27 22:09:56,282] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-04-27 22:09:56,481] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-04-27 22:09:57,502] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 2375000, evaluation results [2375000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-04-27 22:09:59,680] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.2670485e-33 1.0000000e+00 2.1907675e-38 2.9408555e-31 2.5286583e-37], sum to 1.0000
[2019-04-27 22:09:59,694] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6517
[2019-04-27 22:09:59,699] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.55, 71.0, 1.0, 2.0, 0.345769746031844, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 436438.9862401783, 436438.9862401788, 121381.3203260584], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1485000.0000, 
sim time next is 1485600.0000, 
raw observation next is [21.46666666666667, 72.0, 1.0, 2.0, 0.3476502162423747, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 438511.4853813046, 438511.4853813046, 121625.4960600424], 
processed observation next is [0.0, 0.17391304347826086, 0.35061728395061736, 0.72, 1.0, 1.0, 0.2233931145742556, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.15661124477903735, 0.15661124477903735, 0.23389518473085075], 
reward next is 0.7661, 
noisyNet noise sample is [array([0.20461096], dtype=float32), -0.81575763]. 
=============================================
[2019-04-27 22:10:03,951] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.4198998e-34 1.0000000e+00 1.9543171e-36 5.0474734e-32 0.0000000e+00], sum to 1.0000
[2019-04-27 22:10:03,961] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7416
[2019-04-27 22:10:03,964] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.4, 49.66666666666667, 1.0, 2.0, 0.3454245985517511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 434869.6162634756, 434869.6162634756, 121321.2874963965], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1628400.0000, 
sim time next is 1629000.0000, 
raw observation next is [25.25, 50.0, 1.0, 2.0, 0.3429021233500136, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 432053.774165769, 432053.7741657685, 120994.9128240408], 
processed observation next is [1.0, 0.8695652173913043, 0.49074074074074076, 0.5, 1.0, 1.0, 0.21774062303573044, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1543049193449175, 0.15430491934491733, 0.23268252466161693], 
reward next is 0.7673, 
noisyNet noise sample is [array([1.374758], dtype=float32), -0.9318802]. 
=============================================
[2019-04-27 22:10:03,979] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[77.81604 ]
 [77.65824 ]
 [77.43269 ]
 [77.171486]
 [77.05016 ]], R is [[77.8996048 ]
 [77.88730621]
 [77.87467957]
 [77.86160278]
 [77.84799957]].
[2019-04-27 22:10:07,889] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.8839785e-28 1.0000000e+00 7.8715106e-33 6.4028542e-28 5.9171573e-35], sum to 1.0000
[2019-04-27 22:10:07,901] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2129
[2019-04-27 22:10:07,906] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.06666666666667, 89.16666666666667, 1.0, 2.0, 0.3133562012825212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 400163.3611603021, 400163.3611603025, 117242.4705473398], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1662600.0000, 
sim time next is 1663200.0000, 
raw observation next is [18.1, 89.0, 1.0, 2.0, 0.313130379202553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 399820.4350039175, 399820.4350039175, 117213.916416967], 
processed observation next is [1.0, 0.2608695652173913, 0.22592592592592597, 0.89, 1.0, 1.0, 0.18229807047922975, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.1427930125013991, 0.1427930125013991, 0.22541137772493652], 
reward next is 0.7746, 
noisyNet noise sample is [array([-0.34897876], dtype=float32), -1.0635834]. 
=============================================
[2019-04-27 22:10:11,604] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.6582714e-33 1.0000000e+00 1.7793234e-37 9.3649960e-33 7.7941403e-36], sum to 1.0000
[2019-04-27 22:10:11,615] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2644
[2019-04-27 22:10:11,621] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.03333333333333, 90.83333333333334, 1.0, 2.0, 0.4231051435619206, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 519320.3118002451, 519320.3118002447, 131800.7473331296], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1885800.0000, 
sim time next is 1886400.0000, 
raw observation next is [21.0, 91.0, 1.0, 2.0, 0.4225686768681827, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 518762.935848996, 518762.935848996, 131725.8206348486], 
processed observation next is [1.0, 0.8695652173913043, 0.3333333333333333, 0.91, 1.0, 1.0, 0.31258175817640804, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.18527247708892713, 0.18527247708892713, 0.25331888583624734], 
reward next is 0.7467, 
noisyNet noise sample is [array([0.30592206], dtype=float32), -0.46984825]. 
=============================================
[2019-04-27 22:10:18,771] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0792328e-33 1.0000000e+00 0.0000000e+00 4.6002322e-32 0.0000000e+00], sum to 1.0000
[2019-04-27 22:10:18,777] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2405
[2019-04-27 22:10:18,784] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.53333333333333, 85.66666666666667, 1.0, 2.0, 0.3706126362848038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 462342.7359038572, 462342.7359038572, 124621.1169477777], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2011200.0000, 
sim time next is 2011800.0000, 
raw observation next is [20.66666666666667, 84.83333333333333, 1.0, 2.0, 0.3716151298074654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 463422.1618892945, 463422.161889294, 124754.0957452766], 
processed observation next is [0.0, 0.2608695652173913, 0.3209876543209878, 0.8483333333333333, 1.0, 1.0, 0.25192277358031595, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16550791496046233, 0.16550791496046213, 0.2399117225870704], 
reward next is 0.7601, 
noisyNet noise sample is [array([-1.5276873], dtype=float32), 0.3943122]. 
=============================================
[2019-04-27 22:10:20,013] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.2190922e-35 1.0000000e+00 3.2789854e-38 1.6222618e-31 0.0000000e+00], sum to 1.0000
[2019-04-27 22:10:20,021] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4793
[2019-04-27 22:10:20,024] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.55, 85.5, 1.0, 2.0, 0.5706164043608215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 666573.2345178629, 666573.2345178629, 153859.6922281325], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2665800.0000, 
sim time next is 2666400.0000, 
raw observation next is [24.36666666666667, 86.66666666666666, 1.0, 2.0, 0.571763745039895, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 668196.9893764633, 668196.9893764633, 154065.3249149621], 
processed observation next is [0.0, 0.8695652173913043, 0.4580246913580248, 0.8666666666666666, 1.0, 1.0, 0.4901949345713036, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23864178192016547, 0.23864178192016547, 0.29627947099031177], 
reward next is 0.7037, 
noisyNet noise sample is [array([-0.7046381], dtype=float32), -0.15503065]. 
=============================================
[2019-04-27 22:10:25,846] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.1555684e-31 1.0000000e+00 2.9398145e-37 1.7221876e-28 5.5445874e-37], sum to 1.0000
[2019-04-27 22:10:25,853] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6719
[2019-04-27 22:10:25,856] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.4, 66.0, 1.0, 2.0, 0.485104031963238, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 579452.9529284044, 579452.9529284044, 140606.0896046109], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2030400.0000, 
sim time next is 2031000.0000, 
raw observation next is [26.53333333333333, 65.83333333333333, 1.0, 2.0, 0.4904929376530188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 584752.217192639, 584752.217192639, 141399.7486653175], 
processed observation next is [0.0, 0.5217391304347826, 0.5382716049382715, 0.6583333333333333, 1.0, 1.0, 0.393443973396451, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.20884007756879966, 0.20884007756879966, 0.271922593587149], 
reward next is 0.7281, 
noisyNet noise sample is [array([0.38887894], dtype=float32), 2.5309684]. 
=============================================
[2019-04-27 22:10:25,873] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[73.17639]
 [73.1662 ]
 [73.22246]
 [73.2713 ]
 [73.33352]], R is [[73.09823608]
 [73.09686279]
 [73.09729004]
 [73.09941101]
 [73.1031723 ]].
[2019-04-27 22:10:30,192] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.6308167e-29 1.0000000e+00 1.9765029e-35 2.0317746e-27 8.4211203e-34], sum to 1.0000
[2019-04-27 22:10:30,208] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2540
[2019-04-27 22:10:30,213] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.65, 64.0, 1.0, 2.0, 0.5293240005611272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 622437.6532588879, 622437.6532588875, 147228.900813311], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2035800.0000, 
sim time next is 2036400.0000, 
raw observation next is [27.8, 63.66666666666667, 1.0, 2.0, 0.533749635227806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 626644.3342059597, 626644.3342059592, 147904.0501298031], 
processed observation next is [0.0, 0.5652173913043478, 0.5851851851851853, 0.6366666666666667, 1.0, 1.0, 0.44494004193786435, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2238015479306999, 0.22380154793069973, 0.28443086563423675], 
reward next is 0.7156, 
noisyNet noise sample is [array([-1.473877], dtype=float32), -0.11761262]. 
=============================================
[2019-04-27 22:10:30,359] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.8871002e-31 1.0000000e+00 2.3305094e-33 9.5755918e-28 3.6458007e-36], sum to 1.0000
[2019-04-27 22:10:30,367] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2526
[2019-04-27 22:10:30,371] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.35, 63.0, 1.0, 2.0, 0.5570105229722229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 648744.0206666612, 648744.0206666607, 151500.2607495496], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2040600.0000, 
sim time next is 2041200.0000, 
raw observation next is [28.4, 63.0, 1.0, 2.0, 0.5604053109397028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 652087.342275512, 652087.3422755116, 152037.1697527372], 
processed observation next is [0.0, 0.6521739130434783, 0.6074074074074074, 0.63, 1.0, 1.0, 0.4766729892139319, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23288833652696858, 0.23288833652696841, 0.29237917260141766], 
reward next is 0.7076, 
noisyNet noise sample is [array([1.4409665], dtype=float32), 0.5193075]. 
=============================================
[2019-04-27 22:10:31,939] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.5373074e-30 1.0000000e+00 7.1209809e-33 2.2897685e-27 1.7953299e-32], sum to 1.0000
[2019-04-27 22:10:31,946] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4693
[2019-04-27 22:10:31,952] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.96666666666667, 98.0, 1.0, 2.0, 0.5602658493573598, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 654186.4281930837, 654186.4281930837, 152113.4158843067], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2249400.0000, 
sim time next is 2250000.0000, 
raw observation next is [23.0, 98.0, 1.0, 2.0, 0.562134134269458, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 655913.0320072607, 655913.0320072607, 152405.0274246492], 
processed observation next is [1.0, 0.043478260869565216, 0.4074074074074074, 0.98, 1.0, 1.0, 0.47873111222554526, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23425465428830738, 0.23425465428830738, 0.29308659120124847], 
reward next is 0.7069, 
noisyNet noise sample is [array([1.5227941], dtype=float32), 1.2393069]. 
=============================================
[2019-04-27 22:10:31,971] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[65.93877 ]
 [66.23497 ]
 [66.647224]
 [66.98151 ]
 [67.929794]], R is [[65.86792755]
 [65.91672516]
 [65.96554565]
 [66.01430511]
 [66.06299591]].
[2019-04-27 22:10:32,266] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.44954487e-31 1.00000000e+00 1.02881276e-35 2.50213602e-30
 1.40678763e-37], sum to 1.0000
[2019-04-27 22:10:32,270] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7600
[2019-04-27 22:10:32,273] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.03333333333333, 78.0, 1.0, 2.0, 0.5837010496313119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 676337.5188218128, 676337.5188218132, 155830.6876802297], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2155200.0000, 
sim time next is 2155800.0000, 
raw observation next is [25.86666666666667, 78.5, 1.0, 2.0, 0.5788280871580881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 671910.7123257823, 671910.7123257823, 155059.0090658607], 
processed observation next is [0.0, 0.9565217391304348, 0.5135802469135804, 0.785, 1.0, 1.0, 0.49860486566439055, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23996811154492223, 0.23996811154492223, 0.29819040204973213], 
reward next is 0.7018, 
noisyNet noise sample is [array([0.3858258], dtype=float32), -1.8105694]. 
=============================================
[2019-04-27 22:10:32,574] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.1157346e-34 1.0000000e+00 0.0000000e+00 5.6552130e-31 0.0000000e+00], sum to 1.0000
[2019-04-27 22:10:32,589] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6606
[2019-04-27 22:10:32,594] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.08333333333333, 50.83333333333334, 1.0, 2.0, 0.5647441972343634, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 655601.7109051317, 655601.7109051317, 152691.9813807503], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2137800.0000, 
sim time next is 2138400.0000, 
raw observation next is [30.9, 52.0, 1.0, 2.0, 0.5703371119338457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 661069.2286146615, 661069.2286146615, 153582.1347182315], 
processed observation next is [0.0, 0.782608695652174, 0.7, 0.52, 1.0, 1.0, 0.4884965618260068, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23609615307666482, 0.23609615307666482, 0.29535025907352214], 
reward next is 0.7046, 
noisyNet noise sample is [array([0.12889045], dtype=float32), 1.3085223]. 
=============================================
[2019-04-27 22:10:37,386] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.7660715e-25 1.0000000e+00 1.3267888e-28 6.3897402e-24 2.0637673e-30], sum to 1.0000
[2019-04-27 22:10:37,395] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2957
[2019-04-27 22:10:37,397] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.9, 98.0, 1.0, 2.0, 0.5571014409257439, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 651388.710388164, 651388.710388164, 151626.1217789419], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2248200.0000, 
sim time next is 2248800.0000, 
raw observation next is [22.93333333333333, 98.0, 1.0, 2.0, 0.5585620526580397, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 652647.4863142942, 652647.4863142942, 151849.4647594361], 
processed observation next is [1.0, 0.0, 0.40493827160493817, 0.98, 1.0, 1.0, 0.4744786341167139, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.23308838796939077, 0.23308838796939077, 0.292018201460454], 
reward next is 0.7080, 
noisyNet noise sample is [array([-0.698829], dtype=float32), -1.8738484]. 
=============================================
[2019-04-27 22:10:44,404] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.1268139e-33 1.0000000e+00 0.0000000e+00 2.0042503e-31 0.0000000e+00], sum to 1.0000
[2019-04-27 22:10:44,414] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4266
[2019-04-27 22:10:44,418] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.25, 67.66666666666667, 1.0, 2.0, 0.9373717514937079, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.990851439276316, 6.9112, 121.9256055981996, 1152309.446244437, 1111520.936368199, 228153.2820296292], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2307000.0000, 
sim time next is 2307600.0000, 
raw observation next is [26.3, 67.0, 1.0, 2.0, 0.9327859960589006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.988603202293345, 6.9112, 121.9255522379366, 1150741.181157124, 1111103.9827818, 227307.6007051071], 
processed observation next is [1.0, 0.7391304347826086, 0.5296296296296297, 0.67, 1.0, 1.0, 0.9199833286415483, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.007740320229334507, 0.0, 0.8094588732219975, 0.41097899327040144, 0.3968228509935, 0.4371300013559752], 
reward next is 0.1759, 
noisyNet noise sample is [array([0.8556358], dtype=float32), 0.02917627]. 
=============================================
[2019-04-27 22:10:45,107] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.6966488e-33 1.0000000e+00 1.1896296e-36 7.9773805e-31 2.3921501e-37], sum to 1.0000
[2019-04-27 22:10:45,122] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0854
[2019-04-27 22:10:45,130] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.96666666666667, 83.33333333333334, 1.0, 2.0, 0.468475655081486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 566399.445040213, 566399.445040213, 138293.9376769062], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2324400.0000, 
sim time next is 2325000.0000, 
raw observation next is [22.83333333333333, 84.16666666666667, 1.0, 2.0, 0.4672008526479182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 565040.0534650126, 565040.0534650121, 138105.9675418639], 
processed observation next is [1.0, 0.9130434782608695, 0.4012345679012344, 0.8416666666666667, 1.0, 1.0, 0.3657153007713312, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20180001909464734, 0.20180001909464718, 0.26558839911896903], 
reward next is 0.7344, 
noisyNet noise sample is [array([0.01556713], dtype=float32), 1.3207775]. 
=============================================
[2019-04-27 22:10:45,145] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[76.739395]
 [76.70016 ]
 [76.624084]
 [76.58806 ]
 [76.595   ]], R is [[76.70742798]
 [76.67440033]
 [76.64136505]
 [76.60839844]
 [76.57556152]].
[2019-04-27 22:10:45,446] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.2010589e-32 1.0000000e+00 4.2596424e-36 2.2216702e-31 1.8927571e-38], sum to 1.0000
[2019-04-27 22:10:45,453] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6618
[2019-04-27 22:10:45,459] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.3, 87.5, 1.0, 2.0, 0.4637369753140788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 561675.1328872836, 561675.1328872836, 137607.0020323604], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2327400.0000, 
sim time next is 2328000.0000, 
raw observation next is [22.16666666666666, 88.33333333333334, 1.0, 2.0, 0.4619771256219356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 559774.63105754, 559774.6310575395, 137348.1302403738], 
processed observation next is [1.0, 0.9565217391304348, 0.376543209876543, 0.8833333333333334, 1.0, 1.0, 0.3594965781213519, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19991951109197856, 0.1999195110919784, 0.26413101969302655], 
reward next is 0.7359, 
noisyNet noise sample is [array([-0.14288422], dtype=float32), 0.6410676]. 
=============================================
[2019-04-27 22:10:45,479] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[76.650116]
 [76.572815]
 [76.492325]
 [76.39209 ]
 [76.0683  ]], R is [[76.64979553]
 [76.61867523]
 [76.58751678]
 [76.5565567 ]
 [76.52573395]].
[2019-04-27 22:10:45,675] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.6441235e-35 1.0000000e+00 0.0000000e+00 6.0315419e-34 0.0000000e+00], sum to 1.0000
[2019-04-27 22:10:45,686] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6062
[2019-04-27 22:10:45,693] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.26666666666667, 47.0, 1.0, 2.0, 0.3850827243764589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 478378.6094021452, 478378.6094021452, 126564.6113445009], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2406000.0000, 
sim time next is 2406600.0000, 
raw observation next is [27.05, 48.0, 1.0, 2.0, 0.38504556434815, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 478308.411445769, 478308.411445769, 126558.959703931], 
processed observation next is [1.0, 0.8695652173913043, 0.5574074074074075, 0.48, 1.0, 1.0, 0.26791138612875004, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17082443265920322, 0.17082443265920322, 0.24338261481525192], 
reward next is 0.7566, 
noisyNet noise sample is [array([-0.7808261], dtype=float32), -0.6440374]. 
=============================================
[2019-04-27 22:10:48,850] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-04-27 22:10:48,851] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 22:10:48,852] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 22:10:48,853] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 22:10:48,853] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:10:48,854] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:10:48,857] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 22:10:48,856] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 22:10:48,860] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:10:48,861] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:10:48,853] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:10:48,885] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run97
[2019-04-27 22:10:48,886] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run97
[2019-04-27 22:10:48,907] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run97
[2019-04-27 22:10:48,954] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run97
[2019-04-27 22:10:48,954] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run97
[2019-04-27 22:10:57,924] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16165906]
[2019-04-27 22:10:57,924] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [19.62390587833334, 73.25809786333333, 1.0, 2.0, 0.4924459611805934, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 631359.7033296612, 631359.7033296612, 142661.2437617914]
[2019-04-27 22:10:57,925] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 22:10:57,928] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.5783146e-27 1.0000000e+00 4.3556636e-31 3.3230026e-26 2.0624588e-32], sampled 0.46014867319083685
[2019-04-27 22:11:32,267] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16165906]
[2019-04-27 22:11:32,269] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.0, 57.0, 1.0, 2.0, 0.5500750789812728, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 646643.6022451231, 646643.6022451231, 150610.3799314334]
[2019-04-27 22:11:32,271] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 22:11:32,274] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.4017316e-31 1.0000000e+00 2.9164055e-35 1.0647427e-29 8.9799322e-37], sampled 0.04026785091514906
[2019-04-27 22:11:38,483] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16165906]
[2019-04-27 22:11:38,485] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.59120852333334, 86.71310761, 1.0, 2.0, 0.8823188163546001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000003, 6.9112, 121.9260426156618, 1026087.864169026, 1026087.864169024, 214606.496244334]
[2019-04-27 22:11:38,485] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 22:11:38,488] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [7.9873799e-28 1.0000000e+00 1.8571532e-31 1.5834595e-26 8.7609609e-33], sampled 0.6372156687757606
[2019-04-27 22:11:55,114] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16165906]
[2019-04-27 22:11:55,115] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.80706514166667, 103.4630424283333, 1.0, 2.0, 0.7527726002868417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 857981.4773236248, 857981.477323624, 186380.1242927414]
[2019-04-27 22:11:55,115] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 22:11:55,117] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.3788221e-27 1.0000000e+00 3.6094572e-31 2.6492476e-26 1.5737714e-32], sampled 0.6770642568366315
[2019-04-27 22:12:16,587] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16165906]
[2019-04-27 22:12:16,588] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.32102092, 80.52658513, 1.0, 2.0, 0.6280741846371541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 717504.575453853, 717504.575453853, 163059.3051154597]
[2019-04-27 22:12:16,590] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 22:12:16,594] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [3.2054016e-29 1.0000000e+00 5.6335034e-33 8.7473254e-28 2.1023328e-34], sampled 0.7165978279489182
[2019-04-27 22:12:38,670] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-04-27 22:12:38,988] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-04-27 22:12:39,293] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-04-27 22:12:39,421] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-04-27 22:12:39,472] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-04-27 22:12:40,488] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 2400000, evaluation results [2400000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-04-27 22:12:43,904] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.27376373e-29 1.00000000e+00 2.10427448e-34 1.60509626e-28
 1.12636645e-35], sum to 1.0000
[2019-04-27 22:12:43,917] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9994
[2019-04-27 22:12:43,923] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 90.66666666666666, 1.0, 2.0, 0.5282786477449464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 624329.4816665682, 624329.4816665687, 147186.9939813909], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2626800.0000, 
sim time next is 2627400.0000, 
raw observation next is [23.66666666666666, 89.83333333333333, 1.0, 2.0, 0.5395357577532224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 634859.4340804506, 634859.4340804506, 148904.8401706192], 
processed observation next is [0.0, 0.391304347826087, 0.4320987654320985, 0.8983333333333333, 1.0, 1.0, 0.4518282830395504, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2267355121715895, 0.2267355121715895, 0.2863554618665754], 
reward next is 0.7136, 
noisyNet noise sample is [array([-2.0556087], dtype=float32), -0.674822]. 
=============================================
[2019-04-27 22:12:50,646] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.9321294e-30 1.0000000e+00 3.3443278e-34 3.1878940e-27 6.1422969e-34], sum to 1.0000
[2019-04-27 22:12:50,655] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4795
[2019-04-27 22:12:50,664] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.26666666666667, 92.66666666666666, 1.0, 2.0, 0.5109196523147407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 611514.9687537698, 611514.9687537698, 144698.8087238302], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3289200.0000, 
sim time next is 3289800.0000, 
raw observation next is [22.08333333333333, 92.33333333333333, 1.0, 2.0, 0.4999507040368711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 600775.8536863801, 600775.8536863796, 143047.2407411883], 
processed observation next is [0.0, 0.043478260869565216, 0.3734567901234566, 0.9233333333333333, 1.0, 1.0, 0.40470321909151324, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2145628048879929, 0.21456280488799273, 0.27509084757920826], 
reward next is 0.7249, 
noisyNet noise sample is [array([-0.04580738], dtype=float32), -0.6664656]. 
=============================================
[2019-04-27 22:12:50,876] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.6276590e-36 1.0000000e+00 0.0000000e+00 1.7678794e-33 0.0000000e+00], sum to 1.0000
[2019-04-27 22:12:50,883] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1374
[2019-04-27 22:12:50,891] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.86666666666667, 73.33333333333333, 1.0, 2.0, 0.4910403685640933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 589214.7691414302, 589214.7691414302, 141621.8626499233], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2589000.0000, 
sim time next is 2589600.0000, 
raw observation next is [24.63333333333334, 74.66666666666667, 1.0, 2.0, 0.4898410610667229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 588035.9275519641, 588035.9275519641, 141444.193092926], 
processed observation next is [1.0, 1.0, 0.4679012345679015, 0.7466666666666667, 1.0, 1.0, 0.39266792984133686, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2100128312685586, 0.2100128312685586, 0.2720080636402423], 
reward next is 0.7280, 
noisyNet noise sample is [array([-0.71000165], dtype=float32), 1.9722432]. 
=============================================
[2019-04-27 22:12:57,166] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.7386931e-22 1.0000000e+00 2.1644080e-25 5.8233485e-22 1.5010492e-26], sum to 1.0000
[2019-04-27 22:12:57,172] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7311
[2019-04-27 22:12:57,175] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 100.0, 1.0, 2.0, 0.6652779014475324, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 787748.5570661663, 787748.5570661672, 171037.294900121], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2865000.0000, 
sim time next is 2865600.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.6545075319853798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 775051.8067091184, 775051.8067091184, 169048.9449167483], 
processed observation next is [1.0, 0.17391304347826086, 0.37037037037037035, 1.0, 1.0, 1.0, 0.5886994428397379, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27680421668182803, 0.27680421668182803, 0.3250941248399006], 
reward next is 0.6749, 
noisyNet noise sample is [array([0.52639306], dtype=float32), 0.09320567]. 
=============================================
[2019-04-27 22:12:58,468] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.5241382e-29 1.0000000e+00 1.1520636e-32 2.1395792e-29 5.6504632e-33], sum to 1.0000
[2019-04-27 22:12:58,475] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7993
[2019-04-27 22:12:58,482] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.75, 57.0, 1.0, 2.0, 0.6256299210206616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 713001.7047462807, 713001.7047462807, 162541.9234581148], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2728200.0000, 
sim time next is 2728800.0000, 
raw observation next is [30.7, 58.0, 1.0, 2.0, 0.635431283857734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 724177.1443737465, 724177.144373746, 164279.8615856651], 
processed observation next is [0.0, 0.6086956521739131, 0.6925925925925925, 0.58, 1.0, 1.0, 0.5659896236401595, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2586346944191952, 0.258634694419195, 0.3159228107416636], 
reward next is 0.6841, 
noisyNet noise sample is [array([0.48593298], dtype=float32), -0.3626765]. 
=============================================
[2019-04-27 22:13:00,823] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.7014002e-31 1.0000000e+00 3.7331451e-34 1.9599096e-28 1.3230794e-35], sum to 1.0000
[2019-04-27 22:13:00,831] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1358
[2019-04-27 22:13:00,839] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 84.0, 1.0, 2.0, 0.6518209374643252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 742864.8672195461, 742864.8672195461, 167221.2449869135], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2757600.0000, 
sim time next is 2758200.0000, 
raw observation next is [25.91666666666667, 84.83333333333333, 1.0, 2.0, 0.6449019684677452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 734975.7019669173, 734975.7019669173, 165973.6906181919], 
processed observation next is [0.0, 0.9565217391304348, 0.5154320987654323, 0.8483333333333333, 1.0, 1.0, 0.5772642481758871, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26249132213104187, 0.26249132213104187, 0.3191801742657537], 
reward next is 0.6808, 
noisyNet noise sample is [array([-1.1565878], dtype=float32), -1.4581754]. 
=============================================
[2019-04-27 22:13:05,008] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.0446965e-35 1.0000000e+00 0.0000000e+00 1.9358246e-31 0.0000000e+00], sum to 1.0000
[2019-04-27 22:13:05,020] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7934
[2019-04-27 22:13:05,025] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.83333333333334, 70.66666666666667, 1.0, 2.0, 0.6795815737279838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 774518.9902854369, 774518.9902854369, 172314.1513497765], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2841000.0000, 
sim time next is 2841600.0000, 
raw observation next is [28.66666666666667, 71.33333333333334, 1.0, 2.0, 0.6778806273293413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 772579.4450334242, 772579.4450334242, 171998.2318263067], 
processed observation next is [1.0, 0.9130434782608695, 0.6172839506172841, 0.7133333333333334, 1.0, 1.0, 0.6165245563444539, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27592123036908006, 0.27592123036908006, 0.3307658304352052], 
reward next is 0.6692, 
noisyNet noise sample is [array([0.6570585], dtype=float32), -0.88063353]. 
=============================================
[2019-04-27 22:13:14,622] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.8710455e-30 1.0000000e+00 9.1311724e-35 2.9162365e-29 1.8796062e-36], sum to 1.0000
[2019-04-27 22:13:14,629] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2142
[2019-04-27 22:13:14,634] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 58.33333333333334, 1.0, 2.0, 0.6157414133320024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 706157.5011715004, 706157.5011715004, 161025.0634570064], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3259200.0000, 
sim time next is 3259800.0000, 
raw observation next is [30.25, 56.0, 1.0, 2.0, 0.6064319214239654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 698631.9362909428, 698631.9362909428, 159554.2818894814], 
processed observation next is [0.0, 0.7391304347826086, 0.6759259259259259, 0.56, 1.0, 1.0, 0.5314665731237683, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24951140581819387, 0.24951140581819387, 0.30683515747977197], 
reward next is 0.6932, 
noisyNet noise sample is [array([-0.07454225], dtype=float32), -0.68233985]. 
=============================================
[2019-04-27 22:13:20,365] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.1905639e-31 1.0000000e+00 3.4499468e-35 3.2433358e-28 9.9749434e-36], sum to 1.0000
[2019-04-27 22:13:20,374] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9810
[2019-04-27 22:13:20,378] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.33333333333334, 42.0, 1.0, 2.0, 0.5283448949852511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 623741.504249622, 623741.504249622, 147171.049162721], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3252000.0000, 
sim time next is 3252600.0000, 
raw observation next is [32.5, 42.5, 1.0, 2.0, 0.5378371488195902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 631953.3831294867, 631953.3831294867, 148590.0775396554], 
processed observation next is [0.0, 0.6521739130434783, 0.7592592592592593, 0.425, 1.0, 1.0, 0.4498061295471312, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.22569763683195954, 0.22569763683195954, 0.28575014911472196], 
reward next is 0.7142, 
noisyNet noise sample is [array([0.2862839], dtype=float32), 0.26394466]. 
=============================================
[2019-04-27 22:13:26,926] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.0450901e-24 1.0000000e+00 1.8427325e-27 2.1713473e-24 2.3063369e-27], sum to 1.0000
[2019-04-27 22:13:26,935] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6336
[2019-04-27 22:13:26,945] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1571093.854487532 W.
[2019-04-27 22:13:26,950] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.33333333333333, 92.66666666666667, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.68666979789913, 6.9112, 121.9230466173268, 1571093.854487532, 1173993.765145277, 246208.7703798978], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3676200.0000, 
sim time next is 3676800.0000, 
raw observation next is [24.66666666666666, 91.33333333333334, 1.0, 2.0, 0.6549738931941056, 1.0, 1.0, 0.6549738931941056, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9255756027201, 1493647.559024154, 1493647.559024155, 287470.4501846927], 
processed observation next is [1.0, 0.5652173913043478, 0.4691358024691356, 0.9133333333333334, 1.0, 1.0, 0.5892546347548876, 1.0, 0.5, 0.5892546347548876, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094590283398623, 0.5334455567943407, 0.533445556794341, 0.5528277888167167], 
reward next is 0.4472, 
noisyNet noise sample is [array([-0.85580575], dtype=float32), -0.62358004]. 
=============================================
[2019-04-27 22:13:31,440] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-04-27 22:13:31,444] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 22:13:31,445] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:13:31,445] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 22:13:31,446] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:13:31,447] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 22:13:31,448] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 22:13:31,449] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:13:31,450] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:13:31,451] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 22:13:31,453] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:13:31,478] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run98
[2019-04-27 22:13:31,478] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run98
[2019-04-27 22:13:31,479] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run98
[2019-04-27 22:13:31,537] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run98
[2019-04-27 22:13:31,556] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run98
[2019-04-27 22:14:08,604] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.1622847]
[2019-04-27 22:14:08,606] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [31.25, 54.33333333333334, 1.0, 2.0, 0.6340838284104612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 722640.7762249318, 722640.7762249318, 164039.0241477551]
[2019-04-27 22:14:08,607] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 22:14:08,610] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [3.7056150e-29 1.0000000e+00 5.1660449e-33 9.3315341e-28 2.9620965e-34], sampled 0.6579858557343394
[2019-04-27 22:14:16,076] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.1622847]
[2019-04-27 22:14:16,078] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [31.79119000666667, 34.85152803666666, 1.0, 2.0, 0.4090218640908441, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 500423.108001238, 500423.108001238, 129737.2324771877]
[2019-04-27 22:14:16,079] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 22:14:16,083] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.8430540e-30 1.0000000e+00 1.2304556e-33 2.9237121e-28 6.2124452e-35], sampled 0.4109057825757736
[2019-04-27 22:14:16,730] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.1622847]
[2019-04-27 22:14:16,730] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.33336688, 63.72879265500001, 1.0, 2.0, 0.727855564670036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 829566.6218033122, 829566.6218033122, 181488.5796404477]
[2019-04-27 22:14:16,731] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 22:14:16,737] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0482560e-28 1.0000000e+00 1.6321242e-32 2.4295647e-27 1.0045291e-33], sampled 0.5312903601739071
[2019-04-27 22:15:21,922] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-04-27 22:15:21,924] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-04-27 22:15:22,181] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-04-27 22:15:22,183] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-04-27 22:15:22,274] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-04-27 22:15:23,294] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 2425000, evaluation results [2425000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-04-27 22:15:34,975] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.1838289e-25 1.0000000e+00 6.3375594e-28 1.7744142e-24 2.3136561e-30], sum to 1.0000
[2019-04-27 22:15:34,983] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9105
[2019-04-27 22:15:34,987] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 85.5, 1.0, 2.0, 0.4779677947699353, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 576311.7512919304, 576311.7512919304, 139694.800353021], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3547800.0000, 
sim time next is 3548400.0000, 
raw observation next is [23.06666666666667, 82.66666666666666, 1.0, 2.0, 0.4734158445142892, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 571902.7455483205, 571902.7455483209, 139032.4385529073], 
processed observation next is [1.0, 0.043478260869565216, 0.40987654320987665, 0.8266666666666665, 1.0, 1.0, 0.37311410061224903, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20425098055297158, 0.20425098055297175, 0.2673700741402063], 
reward next is 0.7326, 
noisyNet noise sample is [array([0.39648932], dtype=float32), 1.2989314]. 
=============================================
[2019-04-27 22:15:36,206] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.9035687e-20 1.0000000e+00 3.4455488e-23 2.2320815e-19 8.7050959e-25], sum to 1.0000
[2019-04-27 22:15:36,218] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4703
[2019-04-27 22:15:36,222] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 98.0, 1.0, 2.0, 0.6561638034941218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 747816.7429647124, 747816.7429647124, 168010.0463514858], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3733200.0000, 
sim time next is 3733800.0000, 
raw observation next is [24.33333333333333, 98.33333333333334, 1.0, 2.0, 0.8106723571637998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 924013.1925869104, 924013.1925869104, 198150.1580527461], 
processed observation next is [1.0, 0.21739130434782608, 0.45679012345678993, 0.9833333333333334, 1.0, 1.0, 0.7746099490045236, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3300047116381823, 0.3300047116381823, 0.3810579962552809], 
reward next is 0.6189, 
noisyNet noise sample is [array([0.43373245], dtype=float32), 2.1615381]. 
=============================================
[2019-04-27 22:15:45,799] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.7121371e-23 1.0000000e+00 2.2115205e-26 5.8179746e-22 5.1561378e-27], sum to 1.0000
[2019-04-27 22:15:45,806] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7970
[2019-04-27 22:15:45,810] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 91.0, 1.0, 2.0, 0.9477319438876503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9257003583027, 1080345.33204974, 1080345.332049741, 228347.1466985897], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3988800.0000, 
sim time next is 3989400.0000, 
raw observation next is [24.95, 91.16666666666667, 1.0, 2.0, 1.012836178901844, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.223757211722019, 6.9112, 121.9248678088211, 1314791.65000955, 1154735.963777567, 243831.7608136735], 
processed observation next is [1.0, 0.17391304347826086, 0.47962962962962963, 0.9116666666666667, 1.0, 1.0, 1.015281165359338, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.03125572117220186, 0.0, 0.8094543293244267, 0.4695684464319821, 0.41240570134913107, 0.4689072323339875], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.30890527], dtype=float32), -3.2054374]. 
=============================================
[2019-04-27 22:15:54,829] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.7105283e-26 1.0000000e+00 1.8977824e-30 3.1313459e-25 1.1069317e-32], sum to 1.0000
[2019-04-27 22:15:54,837] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8166
[2019-04-27 22:15:54,842] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666667, 93.16666666666667, 1.0, 2.0, 0.7402414823906375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 843691.1262958779, 843691.1262958779, 183904.118692452], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3901800.0000, 
sim time next is 3902400.0000, 
raw observation next is [26.0, 94.0, 1.0, 2.0, 0.7365721423684509, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 839506.7011383262, 839506.7011383262, 183184.8507221237], 
processed observation next is [0.0, 0.17391304347826086, 0.5185185185185185, 0.94, 1.0, 1.0, 0.6863954075814892, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2998238218351165, 0.2998238218351165, 0.3522785590810071], 
reward next is 0.6477, 
noisyNet noise sample is [array([0.22126321], dtype=float32), 0.5340238]. 
=============================================
[2019-04-27 22:16:07,995] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.6097951e-27 1.0000000e+00 8.9397262e-32 1.4875694e-24 6.4841231e-33], sum to 1.0000
[2019-04-27 22:16:08,003] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1369
[2019-04-27 22:16:08,007] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.7, 97.0, 1.0, 2.0, 0.4438754586426082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 541472.8789749192, 541472.8789749197, 134751.6725356173], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4154400.0000, 
sim time next is 4155000.0000, 
raw observation next is [20.58333333333333, 97.5, 1.0, 2.0, 0.599814376827198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 732046.9172706469, 732046.9172706469, 160019.9919539138], 
processed observation next is [1.0, 0.08695652173913043, 0.31790123456790104, 0.975, 1.0, 1.0, 0.5235885438419023, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2614453275966596, 0.2614453275966596, 0.3077307537575265], 
reward next is 0.6923, 
noisyNet noise sample is [array([-1.633556], dtype=float32), 0.012683887]. 
=============================================
[2019-04-27 22:16:08,027] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[63.79094 ]
 [63.821373]
 [64.003716]
 [64.24885 ]
 [64.38445 ]], R is [[64.75535583]
 [64.84866333]
 [64.9408493 ]
 [65.03211975]
 [65.12285614]].
[2019-04-27 22:16:14,665] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-04-27 22:16:14,665] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 22:16:14,666] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 22:16:14,666] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:16:14,667] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:16:14,668] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 22:16:14,667] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 22:16:14,669] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:16:14,670] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:16:14,668] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 22:16:14,671] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:16:14,697] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run99
[2019-04-27 22:16:14,722] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run99
[2019-04-27 22:16:14,723] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run99
[2019-04-27 22:16:14,743] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run99
[2019-04-27 22:16:14,744] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run99
[2019-04-27 22:16:35,100] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16271667]
[2019-04-27 22:16:35,101] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [36.73282337, 12.70838558, 1.0, 2.0, 0.4037512233721431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 511594.7180166735, 511594.7180166735, 129333.2967345593]
[2019-04-27 22:16:35,102] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 22:16:35,104] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.1399617e-30 1.0000000e+00 2.1849797e-34 5.4920258e-29 9.2721680e-36], sampled 0.40760459249971925
[2019-04-27 22:16:55,481] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16271667]
[2019-04-27 22:16:55,485] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.95, 87.0, 1.0, 2.0, 0.8723548479683614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1006669.366976978, 1006669.366976978, 211998.3361055853]
[2019-04-27 22:16:55,486] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 22:16:55,489] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [6.8645258e-26 1.0000000e+00 2.8386805e-29 1.0371092e-24 2.1496982e-30], sampled 0.24672082017559016
[2019-04-27 22:17:05,282] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16271667]
[2019-04-27 22:17:05,283] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [33.66666666666667, 65.66666666666667, 1.0, 2.0, 0.8995564991271823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1025392.089051466, 1025392.089051466, 217385.2615989515]
[2019-04-27 22:17:05,286] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 22:17:05,290] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.3187684e-33 1.0000000e+00 8.9324039e-38 8.7047002e-32 0.0000000e+00], sampled 0.932408713765601
[2019-04-27 22:17:31,132] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16271667]
[2019-04-27 22:17:31,133] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.88585234, 103.8575160333333, 1.0, 2.0, 0.6082356811355897, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9683310132210653, 6.911199999999999, 6.9112, 121.9256309889349, 1386966.006525059, 1386966.00652506, 297083.8624355916]
[2019-04-27 22:17:31,134] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 22:17:31,139] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.6099081e-25 1.0000000e+00 1.2059738e-28 3.4613426e-24 9.1161253e-30], sampled 0.4331152435491522
[2019-04-27 22:17:31,140] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1386966.006525059 W.
[2019-04-27 22:17:32,614] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16271667]
[2019-04-27 22:17:32,615] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.53307095, 81.66131872666666, 1.0, 2.0, 0.7552730358108435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 860832.9787819084, 860832.9787819084, 186877.608749536]
[2019-04-27 22:17:32,618] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 22:17:32,621] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [4.1284598e-29 1.0000000e+00 6.0663186e-33 8.7440561e-28 2.9306711e-34], sampled 0.3049725418974065
[2019-04-27 22:17:46,260] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16271667]
[2019-04-27 22:17:46,261] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.75, 89.0, 1.0, 2.0, 0.5782401835175391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 665860.0876535934, 665860.0876535929, 154710.9912127707]
[2019-04-27 22:17:46,262] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 22:17:46,265] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.9180611e-28 1.0000000e+00 3.6042132e-32 3.8184088e-27 1.7178856e-33], sampled 0.3327353228387544
[2019-04-27 22:18:04,525] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-04-27 22:18:04,678] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-04-27 22:18:05,089] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-04-27 22:18:05,114] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-04-27 22:18:05,383] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-04-27 22:18:06,405] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 2450000, evaluation results [2450000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-04-27 22:18:06,544] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.1495626e-28 1.0000000e+00 7.7711693e-34 2.7979470e-28 1.2283440e-35], sum to 1.0000
[2019-04-27 22:18:06,555] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0102
[2019-04-27 22:18:06,561] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.83333333333334, 70.83333333333334, 1.0, 2.0, 0.7758058220970323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 884249.0088389845, 884249.0088389842, 190999.7918336705], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5073000.0000, 
sim time next is 5073600.0000, 
raw observation next is [30.66666666666667, 71.66666666666667, 1.0, 2.0, 0.7764247673474751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 884954.8783917081, 884954.8783917081, 191125.0235837742], 
processed observation next is [0.0, 0.7391304347826086, 0.6913580246913582, 0.7166666666666667, 1.0, 1.0, 0.7338390087469941, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31605531371132434, 0.31605531371132434, 0.3675481222764888], 
reward next is 0.6325, 
noisyNet noise sample is [array([0.860142], dtype=float32), 1.0088669]. 
=============================================
[2019-04-27 22:18:12,923] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.5387114e-32 1.0000000e+00 5.2938948e-36 2.6318137e-32 2.4332344e-37], sum to 1.0000
[2019-04-27 22:18:12,930] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2008
[2019-04-27 22:18:12,935] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 63.66666666666667, 1.0, 2.0, 0.6959154953220626, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 793144.3891161422, 793144.3891161422, 175375.2857435367], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4387200.0000, 
sim time next is 4387800.0000, 
raw observation next is [31.0, 64.83333333333333, 1.0, 2.0, 0.7092420488968203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 808340.8531305204, 808340.8531305204, 177904.9076526361], 
processed observation next is [1.0, 0.782608695652174, 0.7037037037037037, 0.6483333333333333, 1.0, 1.0, 0.6538595820200241, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28869316183232874, 0.28869316183232874, 0.34212482240891556], 
reward next is 0.6579, 
noisyNet noise sample is [array([1.4643706], dtype=float32), -0.049136735]. 
=============================================
[2019-04-27 22:18:24,009] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.8436745e-25 1.0000000e+00 8.2176022e-28 5.2909390e-24 4.6681239e-28], sum to 1.0000
[2019-04-27 22:18:24,017] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1190
[2019-04-27 22:18:24,024] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 88.33333333333333, 1.0, 2.0, 0.5640684128343817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 667300.9630467423, 667300.9630467423, 153110.3343689359], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5290800.0000, 
sim time next is 5291400.0000, 
raw observation next is [23.4, 88.66666666666667, 1.0, 2.0, 0.5555690286505225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 657943.4551882119, 657943.4551882119, 151716.8572907148], 
processed observation next is [1.0, 0.21739130434782608, 0.42222222222222217, 0.8866666666666667, 1.0, 1.0, 0.470915510298241, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2349798054243614, 0.2349798054243614, 0.29176318709752846], 
reward next is 0.7082, 
noisyNet noise sample is [array([-0.6921725], dtype=float32), 1.9509267]. 
=============================================
[2019-04-27 22:18:26,795] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.9818392e-29 1.0000000e+00 1.9239469e-34 2.7461215e-29 1.5640249e-36], sum to 1.0000
[2019-04-27 22:18:26,804] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1174
[2019-04-27 22:18:26,808] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.16666666666667, 69.33333333333333, 1.0, 2.0, 0.6136554353717119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 701129.8838804301, 701129.8838804297, 160530.7633946779], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5337600.0000, 
sim time next is 5338200.0000, 
raw observation next is [28.13333333333333, 69.66666666666667, 1.0, 2.0, 0.6168987647281118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 704465.0311161361, 704465.0311161361, 161079.0827697629], 
processed observation next is [1.0, 0.782608695652174, 0.5975308641975308, 0.6966666666666668, 1.0, 1.0, 0.5439271008667997, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2515946539700486, 0.2515946539700486, 0.3097674668649287], 
reward next is 0.6902, 
noisyNet noise sample is [array([-0.09595978], dtype=float32), 0.62865144]. 
=============================================
[2019-04-27 22:18:27,671] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.7980043e-23 1.0000000e+00 6.8581657e-26 4.4890305e-22 2.7905827e-27], sum to 1.0000
[2019-04-27 22:18:27,680] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8405
[2019-04-27 22:18:27,688] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1700084.51457309 W.
[2019-04-27 22:18:27,694] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.1, 89.0, 1.0, 2.0, 0.7454056342632333, 1.0, 1.0, 0.7454056342632333, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9249668584507, 1700084.51457309, 1700084.51457309, 321710.5633754408], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4702800.0000, 
sim time next is 4703400.0000, 
raw observation next is [25.65, 86.5, 1.0, 2.0, 0.7753388864156395, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260422876168, 1598793.545233149, 1598793.54523315, 331383.7113742623], 
processed observation next is [1.0, 0.43478260869565216, 0.5055555555555555, 0.865, 1.0, 1.0, 0.7325462933519518, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621266422583, 0.5709976947261247, 0.570997694726125, 0.6372763680274275], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7179385], dtype=float32), -0.3123676]. 
=============================================
[2019-04-27 22:18:30,376] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.2015726e-23 1.0000000e+00 1.8187803e-25 1.3697523e-20 1.9145915e-25], sum to 1.0000
[2019-04-27 22:18:30,385] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0624
[2019-04-27 22:18:30,394] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 93.33333333333334, 1.0, 2.0, 0.9703848140883723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.017243403194886, 6.9112, 121.9256659165402, 1170720.938626603, 1116417.405914114, 234226.8310128337], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4695600.0000, 
sim time next is 4696200.0000, 
raw observation next is [23.9, 95.0, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.587467659765186, 6.9112, 121.9233223230012, 1521916.836901416, 1175615.077497092, 246301.5754806661], 
processed observation next is [1.0, 0.34782608695652173, 0.4407407407407407, 0.95, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.06762676597651858, 0.0, 0.8094440689057746, 0.5435417274647915, 0.4198625276775329, 0.4736568759243579], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.65261394], dtype=float32), 0.8735857]. 
=============================================
[2019-04-27 22:18:34,204] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.7570818e-20 1.0000000e+00 4.0092471e-22 1.2136450e-19 1.4911155e-23], sum to 1.0000
[2019-04-27 22:18:34,217] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7211
[2019-04-27 22:18:34,224] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 93.16666666666667, 1.0, 2.0, 0.8175998988630628, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 947715.3183001331, 947715.3183001326, 200418.6832311638], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4781400.0000, 
sim time next is 4782000.0000, 
raw observation next is [23.9, 93.33333333333334, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.615890172909142, 6.9112, 121.9237209840415, 1542743.239548811, 1181885.757856536, 246646.8589371103], 
processed observation next is [1.0, 0.34782608695652173, 0.4407407407407407, 0.9333333333333335, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.07046901729091423, 0.0, 0.8094467156005039, 0.5509797284102896, 0.4221020563773343, 0.47432088257136595], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9462503], dtype=float32), -0.48488784]. 
=============================================
[2019-04-27 22:18:34,240] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[47.33719 ]
 [47.514015]
 [47.647102]
 [47.757065]
 [47.827877]], R is [[46.07774734]
 [46.23154831]
 [46.43247223]
 [46.64655304]
 [46.85015106]].
[2019-04-27 22:18:36,665] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.0261820e-20 1.0000000e+00 6.9507839e-22 1.6085421e-19 2.1306103e-23], sum to 1.0000
[2019-04-27 22:18:36,672] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9907
[2019-04-27 22:18:36,679] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2039534.102730919 W.
[2019-04-27 22:18:36,684] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.38333333333333, 84.83333333333333, 1.0, 2.0, 0.8940682918713887, 1.0, 2.0, 0.8940682918713887, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156278, 2039534.102730919, 2039534.102730919, 384159.609468576], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4877400.0000, 
sim time next is 4878000.0000, 
raw observation next is [28.6, 84.0, 1.0, 2.0, 0.6102384272435099, 1.0, 2.0, 0.6102384272435099, 1.0, 1.0, 0.9715194502497614, 6.911200000000001, 6.9112, 121.94756008, 2088155.37341943, 2088155.373419429, 400982.2325015814], 
processed observation next is [1.0, 0.4782608695652174, 0.6148148148148148, 0.84, 1.0, 1.0, 0.5359981276708451, 1.0, 1.0, 0.5359981276708451, 1.0, 0.5, 0.9643993128122016, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7457697762212251, 0.7457697762212246, 0.7711196778876566], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.57494336], dtype=float32), 0.73270464]. 
=============================================
[2019-04-27 22:18:36,694] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[45.57841 ]
 [45.135372]
 [44.82213 ]
 [44.6004  ]
 [44.809162]], R is [[45.03810501]
 [44.84895325]
 [44.65193558]
 [44.20541763]
 [43.76336288]].
[2019-04-27 22:18:38,727] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.2198344e-23 1.0000000e+00 9.8424357e-26 1.0915488e-21 1.2932641e-27], sum to 1.0000
[2019-04-27 22:18:38,735] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7098
[2019-04-27 22:18:38,738] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 95.66666666666666, 1.0, 2.0, 0.7025306588959171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 800687.7192626997, 800687.7192626997, 176622.0261513401], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4855800.0000, 
sim time next is 4856400.0000, 
raw observation next is [25.0, 96.0, 1.0, 2.0, 0.7021144409393014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 800213.1000182705, 800213.1000182705, 176543.2888369532], 
processed observation next is [1.0, 0.21739130434782608, 0.48148148148148145, 0.96, 1.0, 1.0, 0.6453743344515493, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28579039286366803, 0.28579039286366803, 0.3395063246864485], 
reward next is 0.6605, 
noisyNet noise sample is [array([1.6601571], dtype=float32), -0.513175]. 
=============================================
[2019-04-27 22:18:39,021] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.1149227e-29 1.0000000e+00 8.1925456e-32 1.3175647e-27 1.5923468e-32], sum to 1.0000
[2019-04-27 22:18:39,028] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0709
[2019-04-27 22:18:39,032] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.96666666666667, 94.0, 1.0, 2.0, 0.731234648775543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 833419.9954414936, 833419.9954414931, 182143.0222054921], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5102400.0000, 
sim time next is 5103000.0000, 
raw observation next is [25.95, 94.0, 1.0, 2.0, 0.7194613122688525, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 819994.232775568, 819994.232775568, 179862.7444372409], 
processed observation next is [0.0, 0.043478260869565216, 0.5166666666666666, 0.94, 1.0, 1.0, 0.6660253717486339, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29285508313413144, 0.29285508313413144, 0.3458898931485402], 
reward next is 0.6541, 
noisyNet noise sample is [array([0.2970338], dtype=float32), 0.70995194]. 
=============================================
[2019-04-27 22:18:39,044] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[67.22718 ]
 [67.231705]
 [67.329506]
 [67.12367 ]
 [66.694   ]], R is [[67.01422119]
 [66.99380493]
 [66.97187042]
 [66.94975281]
 [66.9284668 ]].
[2019-04-27 22:18:40,976] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.3236242e-28 1.0000000e+00 3.4289723e-32 4.9102552e-26 5.8659670e-33], sum to 1.0000
[2019-04-27 22:18:40,987] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7204
[2019-04-27 22:18:40,991] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.45, 70.5, 1.0, 2.0, 0.7760533694795886, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 884531.321550477, 884531.321550477, 191047.5375970332], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5059800.0000, 
sim time next is 5060400.0000, 
raw observation next is [30.6, 69.0, 1.0, 2.0, 0.7740356275453253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 882230.2128074856, 882230.2128074856, 190638.7156037066], 
processed observation next is [0.0, 0.5652173913043478, 0.688888888888889, 0.69, 1.0, 1.0, 0.7309947946968158, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3150822188598163, 0.3150822188598163, 0.3666129146225127], 
reward next is 0.6334, 
noisyNet noise sample is [array([0.7593298], dtype=float32), 0.1224219]. 
=============================================
[2019-04-27 22:18:49,225] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.3266870e-30 1.0000000e+00 1.7924130e-34 2.0948850e-29 1.8785596e-36], sum to 1.0000
[2019-04-27 22:18:49,234] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4846
[2019-04-27 22:18:49,242] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 94.0, 1.0, 2.0, 0.5759187350202328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 667774.7509243641, 667774.7509243641, 154532.6901724344], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5035800.0000, 
sim time next is 5036400.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.5862278675085912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 677304.3316806833, 677304.3316806833, 156170.9610214636], 
processed observation next is [0.0, 0.30434782608695654, 0.4444444444444444, 0.94, 1.0, 1.0, 0.5074141279864182, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2418944041716726, 0.2418944041716726, 0.3003287711951223], 
reward next is 0.6997, 
noisyNet noise sample is [array([0.71199775], dtype=float32), -0.36949962]. 
=============================================
[2019-04-27 22:18:53,687] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.6865451e-30 1.0000000e+00 2.3108313e-32 1.3385788e-27 5.6201766e-32], sum to 1.0000
[2019-04-27 22:18:53,691] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7183
[2019-04-27 22:18:53,695] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 75.0, 1.0, 2.0, 0.8737342131254636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 995938.4917961443, 995938.4917961443, 211657.7653503143], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5144400.0000, 
sim time next is 5145000.0000, 
raw observation next is [31.0, 73.5, 1.0, 2.0, 0.838538983849669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000003, 6.9112, 121.9260426156618, 955795.6851281378, 955795.6851281364, 204042.4058404203], 
processed observation next is [0.0, 0.5652173913043478, 0.7037037037037037, 0.735, 1.0, 1.0, 0.8077845045829393, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 2.6645352591003756e-16, 0.0, 0.8094621288201359, 0.3413556018314778, 0.3413556018314773, 0.39238924200080827], 
reward next is 0.6076, 
noisyNet noise sample is [array([0.89739573], dtype=float32), -0.5053669]. 
=============================================
[2019-04-27 22:18:53,720] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[67.24655 ]
 [67.223785]
 [67.2769  ]
 [67.33148 ]
 [67.22056 ]], R is [[67.28253174]
 [67.20267487]
 [67.12725067]
 [67.05984497]
 [67.01055908]].
[2019-04-27 22:18:57,836] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-04-27 22:18:57,836] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 22:18:57,837] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 22:18:57,838] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:18:57,838] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:18:57,839] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 22:18:57,839] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 22:18:57,841] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:18:57,840] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 22:18:57,842] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:18:57,844] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:18:57,871] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run100
[2019-04-27 22:18:57,890] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run100
[2019-04-27 22:18:57,913] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run100
[2019-04-27 22:18:57,933] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run100
[2019-04-27 22:18:57,949] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run100
[2019-04-27 22:19:23,597] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16361092]
[2019-04-27 22:19:23,598] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.08333333333334, 91.66666666666667, 1.0, 2.0, 0.4273413773285402, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 523264.6111227982, 523264.6111227977, 132381.4082546496]
[2019-04-27 22:19:23,600] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 22:19:23,604] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.4393039e-29 1.0000000e+00 4.8959663e-33 5.7450014e-28 1.8406394e-34], sampled 0.9419871006453716
[2019-04-27 22:19:29,772] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16361092]
[2019-04-27 22:19:29,772] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.6, 54.0, 1.0, 2.0, 0.4214216082804845, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 524731.2009297631, 524731.2009297631, 131732.6862286552]
[2019-04-27 22:19:29,773] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 22:19:29,775] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [5.21773037e-28 1.00000000e+00 1.50969351e-31 1.05082335e-26
 6.97095260e-33], sampled 0.7372143561400675
[2019-04-27 22:19:55,225] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16361092]
[2019-04-27 22:19:55,225] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.57805074, 88.61130159999999, 1.0, 2.0, 0.5430798250071533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 640421.3584963224, 640421.358496322, 149541.2362902129]
[2019-04-27 22:19:55,226] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 22:19:55,230] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [8.5234311e-29 1.0000000e+00 1.9937792e-32 1.8754465e-27 8.2196461e-34], sampled 0.8068646491373493
[2019-04-27 22:20:16,291] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16361092]
[2019-04-27 22:20:16,293] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.064114, 86.71977459666667, 1.0, 2.0, 0.4504029060277002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 548195.8283061648, 548195.8283061653, 135685.9571249864]
[2019-04-27 22:20:16,295] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 22:20:16,297] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [2.1977742e-30 1.0000000e+00 3.2184668e-34 6.2721381e-29 1.3974610e-35], sampled 0.2846117503143871
[2019-04-27 22:20:33,740] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16361092]
[2019-04-27 22:20:33,741] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.103280845, 50.22745881333334, 1.0, 2.0, 0.3001089841844172, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 385866.9376731722, 385866.9376731722, 115585.4939265908]
[2019-04-27 22:20:33,742] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-04-27 22:20:33,745] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.5421252e-29 1.0000000e+00 1.4185011e-32 1.5162878e-27 6.4605900e-34], sampled 0.6773279865712151
[2019-04-27 22:20:35,463] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16361092]
[2019-04-27 22:20:35,466] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.66666666666667, 81.50000000000001, 1.0, 2.0, 0.584687997253114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 675707.0294885781, 675707.0294885781, 155917.0096853383]
[2019-04-27 22:20:35,466] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 22:20:35,469] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.5459495e-26 1.0000000e+00 1.5457912e-29 4.9718353e-25 1.0135956e-30], sampled 0.007872583209871498
[2019-04-27 22:20:38,885] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16361092]
[2019-04-27 22:20:38,890] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.8, 95.0, 1.0, 2.0, 0.4757083540945921, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 571851.8609978136, 571851.8609978132, 139289.3804290401]
[2019-04-27 22:20:38,891] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 22:20:38,893] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.9557817e-30 1.0000000e+00 4.6484561e-34 8.5356649e-29 1.9272735e-35], sampled 0.8393835610915648
[2019-04-27 22:20:42,404] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16361092]
[2019-04-27 22:20:42,405] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [18.61666666666667, 73.83333333333334, 1.0, 2.0, 0.2415738014405625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 311604.7610607097, 311604.7610607097, 105139.3810141112]
[2019-04-27 22:20:42,406] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 22:20:42,408] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.3986005e-30 1.0000000e+00 2.0206218e-34 4.1866645e-29 7.7039822e-36], sampled 0.20386516906086127
[2019-04-27 22:20:43,720] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-04-27 22:20:43,764] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-04-27 22:20:43,821] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-04-27 22:20:44,205] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-04-27 22:20:44,216] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-04-27 22:20:45,234] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 2475000, evaluation results [2475000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
[2019-04-27 22:20:51,219] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.6342709e-25 1.0000000e+00 8.9886738e-29 1.5391873e-24 3.4608188e-29], sum to 1.0000
[2019-04-27 22:20:51,226] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0074
[2019-04-27 22:20:51,229] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 69.0, 1.0, 2.0, 0.5288970007823697, 1.0, 2.0, 0.5288970007823697, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260423022275, 1209837.503465715, 1209837.503465715, 244655.789504851], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5317200.0000, 
sim time next is 5317800.0000, 
raw observation next is [27.2, 68.0, 1.0, 2.0, 0.9311072198061997, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260334571442, 1082676.666576689, 1082676.666576689, 225660.5549687957], 
processed observation next is [1.0, 0.5652173913043478, 0.5629629629629629, 0.68, 1.0, 1.0, 0.9179847854835711, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094620680171033, 0.38667023806310324, 0.38667023806310324, 0.4339626057092225], 
reward next is 0.5660, 
noisyNet noise sample is [array([1.9579864], dtype=float32), 0.51589406]. 
=============================================
[2019-04-27 22:21:01,885] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.0020630e-23 1.0000000e+00 1.0399248e-26 1.5114695e-22 3.4413496e-28], sum to 1.0000
[2019-04-27 22:21:01,891] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3058
[2019-04-27 22:21:01,899] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1391917.863364641 W.
[2019-04-27 22:21:01,904] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.38333333333333, 80.66666666666667, 1.0, 2.0, 0.4069369206002521, 1.0, 2.0, 0.4069369206002521, 1.0, 2.0, 0.6478568306058645, 6.911200000000001, 6.9112, 121.94756008, 1391917.863364641, 1391917.863364641, 300134.2227968049], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5566200.0000, 
sim time next is 5566800.0000, 
raw observation next is [26.46666666666667, 80.33333333333334, 1.0, 2.0, 0.6582806759682267, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1465185.42905562, 1465185.429055621, 309811.5883701527], 
processed observation next is [1.0, 0.43478260869565216, 0.5358024691358025, 0.8033333333333335, 1.0, 1.0, 0.5931912809145555, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5232805103770072, 0.5232805103770075, 0.5957915160964475], 
reward next is 0.4042, 
noisyNet noise sample is [array([0.72017765], dtype=float32), -0.71392304]. 
=============================================
[2019-04-27 22:21:03,211] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.3039918e-32 1.0000000e+00 4.9799882e-36 6.1016479e-31 1.7755477e-36], sum to 1.0000
[2019-04-27 22:21:03,217] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3322
[2019-04-27 22:21:03,221] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.33333333333334, 63.66666666666667, 1.0, 2.0, 0.6924264831407843, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 789165.8672454584, 789165.8672454584, 174715.2504776011], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6351600.0000, 
sim time next is 6352200.0000, 
raw observation next is [30.5, 62.5, 1.0, 2.0, 0.6934148345098675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 790292.882577947, 790292.882577947, 174900.8381789582], 
processed observation next is [0.0, 0.5217391304347826, 0.6851851851851852, 0.625, 1.0, 1.0, 0.6350176601307946, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2822474580635525, 0.2822474580635525, 0.33634776572876574], 
reward next is 0.6637, 
noisyNet noise sample is [array([1.7053335], dtype=float32), -1.592892]. 
=============================================
[2019-04-27 22:21:06,623] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.1777583e-33 1.0000000e+00 1.5430580e-36 6.6488001e-29 7.0399917e-37], sum to 1.0000
[2019-04-27 22:21:06,632] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1081
[2019-04-27 22:21:06,639] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.55, 92.16666666666667, 1.0, 2.0, 0.676753817508171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 771294.5755963159, 771294.5755963159, 171789.6314080244], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5598600.0000, 
sim time next is 5599200.0000, 
raw observation next is [25.6, 92.33333333333334, 1.0, 2.0, 0.6818652924545818, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 777123.0634912108, 777123.0634912113, 172739.1697887163], 
processed observation next is [1.0, 0.8260869565217391, 0.5037037037037038, 0.9233333333333335, 1.0, 1.0, 0.6212682053030736, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.277543951246861, 0.27754395124686115, 0.3321907111321467], 
reward next is 0.6678, 
noisyNet noise sample is [array([1.5897299], dtype=float32), -1.4024845]. 
=============================================
[2019-04-27 22:21:08,319] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.1496681e-35 1.0000000e+00 0.0000000e+00 5.4851472e-33 0.0000000e+00], sum to 1.0000
[2019-04-27 22:21:08,325] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3901
[2019-04-27 22:21:08,331] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.65, 98.0, 1.0, 2.0, 0.6090040143692838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 700454.9358553117, 700454.9358553117, 159947.533409252], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5614200.0000, 
sim time next is 5614800.0000, 
raw observation next is [23.63333333333333, 98.0, 1.0, 2.0, 0.6067728058296021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 698148.8618809205, 698148.8618809205, 159571.9738876311], 
processed observation next is [1.0, 1.0, 0.430864197530864, 0.98, 1.0, 1.0, 0.5318723878923834, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24933887924318587, 0.24933887924318587, 0.3068691805531367], 
reward next is 0.6931, 
noisyNet noise sample is [array([-1.6814945], dtype=float32), -1.2743119]. 
=============================================
[2019-04-27 22:21:13,657] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4487551e-30 1.0000000e+00 1.3997779e-33 1.1442174e-28 2.6230396e-35], sum to 1.0000
[2019-04-27 22:21:13,667] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3902
[2019-04-27 22:21:13,674] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2103266.488899862 W.
[2019-04-27 22:21:13,679] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.15000000000001, 54.0, 1.0, 2.0, 0.6146492760912784, 1.0, 2.0, 0.6146492760912784, 1.0, 1.0, 0.978541665266727, 6.911199999999999, 6.9112, 121.94756008, 2103266.488899862, 2103266.488899863, 403415.0296508675], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6447000.0000, 
sim time next is 6447600.0000, 
raw observation next is [32.1, 54.0, 1.0, 2.0, 0.65306829855799, 1.0, 2.0, 0.6398988112554296, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2189773.726614949, 2189773.726614949, 416866.8192652275], 
processed observation next is [1.0, 0.6521739130434783, 0.7444444444444445, 0.54, 1.0, 1.0, 0.5869860697118928, 1.0, 1.0, 0.5713081086374161, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8096049824067558, 0.7820620452196246, 0.7820620452196246, 0.8016669601254375], 
reward next is 0.1983, 
noisyNet noise sample is [array([-1.7751647], dtype=float32), -0.26790565]. 
=============================================
[2019-04-27 22:21:29,214] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.5622725e-36 1.0000000e+00 0.0000000e+00 3.3605326e-33 0.0000000e+00], sum to 1.0000
[2019-04-27 22:21:29,221] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4686
[2019-04-27 22:21:29,229] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.06666666666667, 62.66666666666667, 1.0, 2.0, 0.547135042701675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 640934.2636662526, 640934.2636662526, 150030.8473904137], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6117000.0000, 
sim time next is 6117600.0000, 
raw observation next is [27.93333333333333, 63.33333333333334, 1.0, 2.0, 0.5472582810507356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 641187.9420892854, 641187.9420892854, 150055.7589128242], 
processed observation next is [1.0, 0.8260869565217391, 0.5901234567901233, 0.6333333333333334, 1.0, 1.0, 0.4610217631556376, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2289956936033162, 0.2289956936033162, 0.28856876714004653], 
reward next is 0.7114, 
noisyNet noise sample is [array([-0.8637643], dtype=float32), -0.6336369]. 
=============================================
[2019-04-27 22:21:33,465] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.86916014e-35 1.00000000e+00 0.00000000e+00 1.22789135e-32
 0.00000000e+00], sum to 1.0000
[2019-04-27 22:21:33,473] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6487
[2019-04-27 22:21:33,479] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.23333333333333, 77.16666666666666, 1.0, 2.0, 0.5343480859753537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 630514.3072786106, 630514.3072786102, 148131.1735287312], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6133800.0000, 
sim time next is 6134400.0000, 
raw observation next is [25.1, 78.0, 1.0, 2.0, 0.5340327065148606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 630228.9520058807, 630228.9520058807, 148083.4022729097], 
processed observation next is [1.0, 0.0, 0.4851851851851852, 0.78, 1.0, 1.0, 0.4452770315653102, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2250817685735288, 0.2250817685735288, 0.28477577360174944], 
reward next is 0.7152, 
noisyNet noise sample is [array([-0.34071425], dtype=float32), -0.5694339]. 
=============================================
[2019-04-27 22:21:34,066] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-04-27 22:21:34,067] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-04-27 22:21:34,069] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-04-27 22:21:34,070] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:21:34,071] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-04-27 22:21:34,073] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-04-27 22:21:34,074] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-04-27 22:21:34,071] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:21:34,076] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:21:34,074] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:21:34,076] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-04-27 22:21:34,654] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run101
[2019-04-27 22:21:34,754] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run101
[2019-04-27 22:21:35,029] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run101
[2019-04-27 22:21:35,030] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run101
[2019-04-27 22:21:35,302] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/34/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run101
[2019-04-27 22:21:36,404] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16474876]
[2019-04-27 22:21:36,405] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [30.1, 36.5, 1.0, 2.0, 0.5338168273018792, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8709193672752635, 6.911199999999999, 6.9112, 121.9260424692972, 1301167.156065471, 1301167.156065472, 266228.8053749148]
[2019-04-27 22:21:36,405] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 22:21:36,407] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.2550966e-27 1.0000000e+00 3.2988829e-31 1.8272844e-26 1.7620294e-32], sampled 0.6167783947379576
[2019-04-27 22:21:36,407] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1301167.156065471 W.
[2019-04-27 22:21:58,681] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16474876]
[2019-04-27 22:21:58,682] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.36666666666667, 67.0, 1.0, 2.0, 0.3750694497297377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 466655.887168479, 466655.887168479, 125203.5868788224]
[2019-04-27 22:21:58,684] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-04-27 22:21:58,687] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [5.8236741e-32 1.0000000e+00 5.4704070e-36 1.8009702e-30 1.4561467e-37], sampled 0.7582718982934653
[2019-04-27 22:22:09,933] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16474876]
[2019-04-27 22:22:09,935] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.2, 94.0, 1.0, 2.0, 0.5305051270056265, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 634281.1623141796, 634281.1623141796, 147826.3930934278]
[2019-04-27 22:22:09,937] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 22:22:09,941] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0635539e-28 1.0000000e+00 2.4261132e-32 2.0881452e-27 9.2530259e-34], sampled 0.4458175803591753
[2019-04-27 22:22:11,138] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16474876]
[2019-04-27 22:22:11,139] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.875099095, 93.78085294166667, 1.0, 2.0, 0.772542470255129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 880527.3645584072, 880527.3645584072, 190344.014957645]
[2019-04-27 22:22:11,140] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-04-27 22:22:11,142] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [2.4010542e-30 1.0000000e+00 3.1636897e-34 5.6486213e-29 1.2464602e-35], sampled 0.6617043398134816
[2019-04-27 22:22:16,403] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16474876]
[2019-04-27 22:22:16,404] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [37.0, 27.0, 1.0, 2.0, 0.5416541750660249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 638535.5877678337, 638535.5877678337, 149298.4371135634]
[2019-04-27 22:22:16,405] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 22:22:16,408] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [2.4566144e-31 1.0000000e+00 2.4955619e-35 6.3014171e-30 6.7951846e-37], sampled 0.7394486034333483
[2019-04-27 22:22:20,236] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16474876]
[2019-04-27 22:22:20,238] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.25, 79.66666666666667, 1.0, 2.0, 0.5786691376063448, 0.0, 2.0, 0.0, 1.0, 2.0, 0.922085932821304, 6.9112, 6.9112, 121.9260426156618, 1333782.215060976, 1333782.215060976, 285441.5373717314]
[2019-04-27 22:22:20,239] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 22:22:20,242] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.12027276e-28 1.00000000e+00 2.70580227e-32 2.02136131e-27
 1.02873535e-33], sampled 0.1970939472268658
[2019-04-27 22:22:20,243] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1333782.215060976 W.
[2019-04-27 22:22:21,166] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16474876]
[2019-04-27 22:22:21,167] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [34.66666666666666, 63.0, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 1.0, 1.0, 0.9977734948820727, 9.157777165214204, 6.9112, 128.5233534501409, 4257753.414827687, 3045055.364384755, 569733.3119138896]
[2019-04-27 22:22:21,168] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 22:22:21,170] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [3.86859761e-26 1.00000000e+00 1.19764315e-29 3.70839444e-25
 7.69780328e-31], sampled 0.8134279665736648
[2019-04-27 22:22:21,171] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 0, 1] for the demand 4257753.414827687 W.
[2019-04-27 22:22:21,486] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16474876]
[2019-04-27 22:22:21,487] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [33.33333333333334, 68.66666666666667, 1.0, 2.0, 0.949248010197066, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260232821825, 1082074.755452402, 1082074.755452401, 228724.3983982106]
[2019-04-27 22:22:21,488] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-04-27 22:22:21,491] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.242527e-33 1.000000e+00 3.770393e-37 1.905638e-31 0.000000e+00], sampled 0.3925858672412972
[2019-04-27 22:23:17,060] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([4.490006e-06], dtype=float32), 0.16474876]
[2019-04-27 22:23:17,063] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.3, 66.0, 1.0, 2.0, 0.9698822791764355, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.315839323962846, 6.9112, 121.9246051562317, 1379030.555527314, 1171821.498346925, 236761.5206933717]
[2019-04-27 22:23:17,064] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-04-27 22:23:17,066] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [4.8853264e-28 1.0000000e+00 1.1678831e-31 8.6250954e-27 6.1967830e-33], sampled 0.27545658569251696
[2019-04-27 22:23:17,067] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1379030.555527314 W.
[2019-04-27 22:23:20,125] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8771.9095 2170601483.0346 493.0000
[2019-04-27 22:23:20,301] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8584.5265 2248663206.3456 553.0000
[2019-04-27 22:23:20,349] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8701.7435 2195019782.1641 572.0000
[2019-04-27 22:23:20,565] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 8100.7222 2445312557.4025 746.0000
[2019-04-27 22:23:20,708] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8924.2933 2120398140.2949 430.0000
[2019-04-27 22:23:21,726] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 2500000, evaluation results [2500000.0, 8100.722247181571, 2445312557.402538, 746.0, 8771.90946536216, 2170601483.03465, 493.0, 8924.293283520115, 2120398140.2948759, 430.0, 8584.526542641555, 2248663206.345631, 553.0, 8701.74352259033, 2195019782.1641326, 572.0]
