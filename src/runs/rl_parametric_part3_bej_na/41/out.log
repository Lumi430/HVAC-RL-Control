Using TensorFlow backend.
[2019-03-24 04:39:35,765] A3C_AGENT_MAIN INFO:Namespace(action_repeat_n=1, action_space='part3_v1', activation='relu', agent_num=5, check_args_only=False, clip_norm=5.0, debug_log_prob=0.0005, decay_steps=1000000, dropout_prob=0.0, end_e=0.0, env='Part3-NA-Bej-Train-v1', eval_act_func='part3_bej_det_v1', eval_env_res_max_keep=50, eval_epi_num=1, eval_freq=25000, forecast_dim=0, gamma=0.99, h_decay_bounds=[], h_regu_frac=[0.0], init_e=0.0, isNoisyNet=True, isNoisyNetEval_rmNoise=True, is_greedy_policy=False, is_learning_rate_decay_staircase=False, is_warm_start=False, job_mode='Train', learning_rate=1e-05, learning_rate_decay_rate=1.0, learning_rate_decay_steps=100000, max_interactions=2500000, metric_func='part3_v1', model_dir='None', model_param=[256, 8], model_type='nn', num_threads=16, output='./Part3-NA-Bej-Train-v1-res1', p_loss_frac=1.0, raw_state_prcs_func='cslDx_1', reward_func='part3_v3', rmsprop_decay=0.99, rmsprop_epsil=1e-10, rmsprop_momet=0.0, rwd_e_para=1.0, rwd_p_para=1.0, save_freq=500000, save_max_to_keep=5, save_scope='all', sharedNet_type='Dense', state_dim=17, test_env=['Part3-NA-Bej-Test-v1', 'Part3-NA-Bej-Test-v2', 'Part3-NA-Bej-Test-v3', 'Part3-NA-Bej-Test-v4'], test_mode='Multiple', train_act_func='part3_bej_sto_v1', train_freq=5, v_loss_frac=0.5, violation_penalty_scl=50.0, weight_initer='glorot_uniform', window_len=26)
[2019-03-24 04:39:35,766] A3C_AGENT_MAIN INFO:Start compiling...
2019-03-24 04:39:35.855633: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[2019-03-24 04:40:08,094] A3C_AGENT_MAIN INFO:Start the learning...
[2019-03-24 04:40:08,095] A3C_AGENT_MAIN INFO:Prepare the evaluation environments ['Part3-NA-Bej-Train-v1', 'Part3-NA-Bej-Test-v1', 'Part3-NA-Bej-Test-v2', 'Part3-NA-Bej-Test-v3', 'Part3-NA-Bej-Test-v4'] ...
[2019-03-24 04:40:08,108] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation worker starts!
[2019-03-24 04:40:08,111] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation worker starts!
[2019-03-24 04:40:08,114] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation worker starts!
[2019-03-24 04:40:08,117] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation worker starts!
[2019-03-24 04:40:08,123] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation worker starts!
[2019-03-24 04:40:08,123] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 04:40:08,124] A3C_AGENT_WORKER-Thread-2 INFO:Local worker starts!
[2019-03-24 04:40:08,210] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:40:08,211] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run1
[2019-03-24 04:40:09,125] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 04:40:09,128] A3C_AGENT_WORKER-Thread-3 INFO:Local worker starts!
[2019-03-24 04:40:09,294] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:40:09,295] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run1
[2019-03-24 04:40:09,677] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-24 04:40:09,677] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:40:09,678] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:40:09,678] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:40:09,678] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:40:09,678] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:40:09,679] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:40:09,679] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:40:09,680] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:40:09,680] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:40:09,680] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:40:09,684] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run1
[2019-03-24 04:40:09,695] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run1
[2019-03-24 04:40:09,707] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run1
[2019-03-24 04:40:09,708] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run1
[2019-03-24 04:40:09,708] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run1
[2019-03-24 04:40:10,129] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 04:40:10,130] A3C_AGENT_WORKER-Thread-9 INFO:Local worker starts!
[2019-03-24 04:40:10,260] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:40:10,261] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run1
[2019-03-24 04:40:11,131] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 04:40:11,135] A3C_AGENT_WORKER-Thread-10 INFO:Local worker starts!
[2019-03-24 04:40:11,540] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:40:11,541] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run1
[2019-03-24 04:40:12,135] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 04:40:12,144] A3C_AGENT_WORKER-Thread-11 INFO:Local worker starts!
[2019-03-24 04:40:12,261] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:40:12,288] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run1
[2019-03-24 04:40:13,140] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 04:40:13,143] A3C_AGENT_WORKER-Thread-12 INFO:Local worker starts!
[2019-03-24 04:40:13,259] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:40:13,263] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run1
[2019-03-24 04:40:14,142] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 04:40:14,145] A3C_AGENT_WORKER-Thread-13 INFO:Local worker starts!
[2019-03-24 04:40:14,272] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:40:14,273] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run1
[2019-03-24 04:40:15,145] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 04:40:15,150] A3C_AGENT_WORKER-Thread-14 INFO:Local worker starts!
[2019-03-24 04:40:15,267] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:40:15,273] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run1
[2019-03-24 04:40:16,149] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 04:40:16,153] A3C_AGENT_WORKER-Thread-15 INFO:Local worker starts!
[2019-03-24 04:40:16,278] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:40:16,279] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run1
[2019-03-24 04:40:17,154] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 04:40:17,159] A3C_AGENT_WORKER-Thread-16 INFO:Local worker starts!
[2019-03-24 04:40:17,276] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:40:17,298] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run1
[2019-03-24 04:40:18,159] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 04:40:18,161] A3C_AGENT_WORKER-Thread-17 INFO:Local worker starts!
[2019-03-24 04:40:18,291] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:40:18,302] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run1
[2019-03-24 04:40:19,161] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 04:40:19,165] A3C_AGENT_WORKER-Thread-18 INFO:Local worker starts!
[2019-03-24 04:40:19,298] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:40:19,303] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run1
[2019-03-24 04:40:20,165] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 04:40:20,170] A3C_AGENT_WORKER-Thread-19 INFO:Local worker starts!
[2019-03-24 04:40:20,281] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:40:20,294] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run1
[2019-03-24 04:40:21,169] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 04:40:21,174] A3C_AGENT_WORKER-Thread-20 INFO:Local worker starts!
[2019-03-24 04:40:21,287] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:40:21,298] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run1
[2019-03-24 04:40:22,174] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 04:40:22,177] A3C_AGENT_WORKER-Thread-21 INFO:Local worker starts!
[2019-03-24 04:40:22,314] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:40:22,316] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run1
[2019-03-24 04:40:23,177] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-24 04:40:23,181] A3C_AGENT_WORKER-Thread-22 INFO:Local worker starts!
[2019-03-24 04:40:23,306] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:40:23,309] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run1
[2019-03-24 04:40:27,437] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-24 04:40:27,439] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.42724686333334, 54.60263876666667, 1.0, 1.0, 0.160855164619843, 1.0, 1.0, 0.160855164619843, 1.0, 2.0, 0.2592457465007409, 6.911200000000001, 6.9112, 121.94756008, 576976.6089840344, 576976.6089840339, 207688.1992935993]
[2019-03-24 04:40:27,439] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:40:27,449] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [0.20498163 0.19651602 0.1853014  0.1967118  0.21648915], sampled 0.6896609392559968
[2019-03-24 04:40:30,369] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-24 04:40:30,370] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.24399632333333, 53.40386271666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6207906308053194, 6.9112, 6.9112, 121.9260426156618, 462464.880885012, 462464.880885012, 133739.5043710189]
[2019-03-24 04:40:30,371] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:40:30,374] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0.20868073 0.19343726 0.18787968 0.19644552 0.21355681], sampled 0.8522041247228508
[2019-03-24 04:41:02,510] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-24 04:41:02,513] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.39349015, 106.6474478333333, 1.0, 2.0, 0.3211396175568631, 1.0, 1.0, 0.3211396175568631, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 731991.1150643107, 731991.1150643107, 185610.9919573133]
[2019-03-24 04:41:02,513] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:41:02,516] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [0.21006851 0.19378679 0.18675469 0.19397059 0.21541944], sampled 0.4012132517120661
[2019-03-24 04:41:26,342] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-24 04:41:26,344] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.0, 65.0, 1.0, 2.0, 0.16, 1.0, 1.0, 0.16, 1.0, 2.0, 0.2405327433820103, 6.9112, 6.9112, 121.94756008, 537277.3773704491, 537277.3773704491, 201684.5778324411]
[2019-03-24 04:41:26,344] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:41:26,348] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [0.20546217 0.19492677 0.18954816 0.19574687 0.21431601], sampled 0.21953782894200957
[2019-03-24 04:41:40,675] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-24 04:41:40,677] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.121137705, 60.52553549166667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7678738964034009, 6.9112, 6.9112, 121.9260426156618, 568076.0094429303, 568076.0094429303, 157316.9759488169]
[2019-03-24 04:41:40,678] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:41:40,681] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0.20254377 0.19812137 0.18727542 0.1975507  0.2145087 ], sampled 0.15680060864571987
[2019-03-24 04:41:45,629] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-24 04:41:45,630] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.810110345, 72.16263982500001, 1.0, 2.0, 0.3201807861914246, 1.0, 1.0, 0.3201807861914246, 1.0, 2.0, 0.5097382391769684, 6.9112, 6.9112, 121.94756008, 1094958.565248506, 1094958.565248506, 263884.8896456409]
[2019-03-24 04:41:45,632] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:41:45,635] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0.2043655  0.19798194 0.18775618 0.19337112 0.21652532], sampled 0.7656671734112812
[2019-03-24 04:41:53,734] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-24 04:41:53,736] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.402752845, 91.70566474999998, 1.0, 1.0, 0.2185158026737089, 1.0, 1.0, 0.2185158026737089, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 526987.5721940529, 526987.5721940529, 163414.8165289123]
[2019-03-24 04:41:53,737] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:41:53,741] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0.20462134 0.19601566 0.1855071  0.19539942 0.21845648], sampled 0.21191713867648954
[2019-03-24 04:41:53,982] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-24 04:41:53,982] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.03391392666667, 80.17373589833335, 1.0, 1.0, 0.1763912411862159, 1.0, 1.0, 0.1763912411862159, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 439018.1269027623, 439018.1269027628, 155052.5716898941]
[2019-03-24 04:41:53,983] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:41:53,987] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [0.21036223 0.19520912 0.18519181 0.19886395 0.21037287], sampled 0.4741225737394208
[2019-03-24 04:42:01,031] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 3813.2564 2540619295.9342 309.0000
[2019-03-24 04:42:01,155] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 3849.8460 2473062915.1032 257.0000
[2019-03-24 04:42:01,282] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 3924.2975 2503211309.4473 319.0000
[2019-03-24 04:42:01,351] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 3858.0049 2721210116.7971 427.0000
[2019-03-24 04:42:01,586] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 3976.2695 2443162660.8485 232.0000
[2019-03-24 04:42:02,600] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 0, evaluation results [0.0, 3858.0049259310263, 2721210116.797073, 427.0, 3849.846018694403, 2473062915.1032414, 257.0, 3976.2695287729634, 2443162660.848511, 232.0, 3813.2564479707225, 2540619295.934153, 309.0, 3924.297471232635, 2503211309.4473248, 319.0]
[2019-03-24 04:42:18,039] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [0.16337313 0.03531918 0.35218173 0.19779928 0.2513268 ], sum to 1.0000
[2019-03-24 04:42:18,047] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7215
[2019-03-24 04:42:18,219] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.48333333333333, 15.5, 1.0, 2.0, 0.1934291595285689, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3367169686389495, 6.911199999999999, 6.9112, 121.9260426156618, 492886.2030643172, 492886.2030643176, 163425.7857646092], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 234600.0000, 
sim time next is 235200.0000, 
raw observation next is [33.26666666666667, 16.0, 1.0, 2.0, 0.1919810017259481, 1.0, 1.0, 0.1919810017259481, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 488467.9608543928, 488467.9608543928, 158470.9409214988], 
processed observation next is [0.0, 0.7391304347826086, 0.7876543209876545, 0.16, 1.0, 1.0, 0.038072621102319154, 1.0, 0.5, 0.038072621102319154, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.17445284316228313, 0.17445284316228313, 0.30475180946442076], 
reward next is 0.6952, 
noisyNet noise sample is [array([0.5024731], dtype=float32), -0.8467533]. 
=============================================
[2019-03-24 04:42:21,175] A3C_AGENT_WORKER-Thread-3 INFO:Local step 500, global step 7807: loss -1.8825
[2019-03-24 04:42:21,262] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 500, global step 7808: learning rate 0.0000
[2019-03-24 04:42:21,331] A3C_AGENT_WORKER-Thread-16 INFO:Local step 500, global step 7846: loss 7.9964
[2019-03-24 04:42:21,334] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 500, global step 7846: learning rate 0.0000
[2019-03-24 04:42:21,378] A3C_AGENT_WORKER-Thread-22 INFO:Local step 500, global step 7875: loss 0.2306
[2019-03-24 04:42:21,380] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 500, global step 7875: learning rate 0.0000
[2019-03-24 04:42:21,446] A3C_AGENT_WORKER-Thread-11 INFO:Local step 500, global step 7907: loss -2.0501
[2019-03-24 04:42:21,447] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 500, global step 7908: learning rate 0.0000
[2019-03-24 04:42:21,541] A3C_AGENT_WORKER-Thread-10 INFO:Local step 500, global step 7961: loss 0.4637
[2019-03-24 04:42:21,543] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 500, global step 7961: learning rate 0.0000
[2019-03-24 04:42:21,582] A3C_AGENT_WORKER-Thread-15 INFO:Local step 500, global step 7982: loss -1.2173
[2019-03-24 04:42:21,585] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 500, global step 7982: learning rate 0.0000
[2019-03-24 04:42:21,596] A3C_AGENT_WORKER-Thread-13 INFO:Local step 500, global step 7988: loss 2.3001
[2019-03-24 04:42:21,600] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 500, global step 7988: learning rate 0.0000
[2019-03-24 04:42:21,615] A3C_AGENT_WORKER-Thread-2 INFO:Local step 500, global step 7997: loss 10.4281
[2019-03-24 04:42:21,617] A3C_AGENT_WORKER-Thread-9 INFO:Local step 500, global step 7998: loss 5.0711
[2019-03-24 04:42:21,617] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 500, global step 7998: learning rate 0.0000
[2019-03-24 04:42:21,619] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 500, global step 7998: learning rate 0.0000
[2019-03-24 04:42:21,644] A3C_AGENT_WORKER-Thread-17 INFO:Local step 500, global step 8006: loss -0.0086
[2019-03-24 04:42:21,646] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 500, global step 8006: learning rate 0.0000
[2019-03-24 04:42:21,699] A3C_AGENT_WORKER-Thread-14 INFO:Local step 500, global step 8038: loss 4.9786
[2019-03-24 04:42:21,702] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 500, global step 8039: learning rate 0.0000
[2019-03-24 04:42:21,725] A3C_AGENT_WORKER-Thread-20 INFO:Local step 500, global step 8056: loss 3.8696
[2019-03-24 04:42:21,728] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 500, global step 8057: learning rate 0.0000
[2019-03-24 04:42:21,747] A3C_AGENT_WORKER-Thread-19 INFO:Local step 500, global step 8068: loss 15.6524
[2019-03-24 04:42:21,750] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 500, global step 8069: learning rate 0.0000
[2019-03-24 04:42:21,759] A3C_AGENT_WORKER-Thread-12 INFO:Local step 500, global step 8073: loss -0.5145
[2019-03-24 04:42:21,760] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 500, global step 8073: learning rate 0.0000
[2019-03-24 04:42:21,782] A3C_AGENT_WORKER-Thread-21 INFO:Local step 500, global step 8081: loss 4.2938
[2019-03-24 04:42:21,785] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 500, global step 8082: learning rate 0.0000
[2019-03-24 04:42:21,928] A3C_AGENT_WORKER-Thread-18 INFO:Local step 500, global step 8160: loss 4.0357
[2019-03-24 04:42:21,933] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 500, global step 8162: learning rate 0.0000
[2019-03-24 04:42:23,763] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.19622539 0.00135567 0.72732615 0.03700997 0.0380828 ], sum to 1.0000
[2019-03-24 04:42:23,774] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9775
[2019-03-24 04:42:23,952] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.26666666666667, 42.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5269413582628683, 6.9112, 6.9112, 121.9260426156618, 379568.8507007383, 379568.8507007383, 118322.4118723702], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 339000.0000, 
sim time next is 339600.0000, 
raw observation next is [24.13333333333334, 43.0, 1.0, 1.0, 0.16, 1.0, 1.0, 0.16, 1.0, 2.0, 0.2, 6.9112, 6.9112, 121.94756008, 377619.7602620036, 377619.7602620036, 171560.0118655232], 
processed observation next is [0.0, 0.9565217391304348, 0.44938271604938296, 0.43, 1.0, 0.5, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.8096049824067558, 0.1348642000935727, 0.1348642000935727, 0.3299230997413908], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5541939], dtype=float32), 0.8666593]. 
=============================================
[2019-03-24 04:42:24,872] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.8980848e-01 2.6436448e-05 6.9818906e-02 1.0010574e-02 3.0335667e-02], sum to 1.0000
[2019-03-24 04:42:24,873] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0674
[2019-03-24 04:42:25,043] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.8, 58.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5680904491923605, 6.911200000000001, 6.9112, 121.9260426156618, 405634.9395326413, 405634.9395326408, 109345.5064592305], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 356400.0000, 
sim time next is 357000.0000, 
raw observation next is [19.63333333333333, 58.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5541328076994242, 6.9112, 6.9112, 121.9260426156618, 395666.1614399616, 395666.1614399616, 107715.9930143147], 
processed observation next is [1.0, 0.13043478260869565, 0.2827160493827159, 0.5883333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4426660096242802, 0.0, 0.0, 0.8094621288201359, 0.14130934337141485, 0.14130934337141485, 0.20714614041214366], 
reward next is 0.7929, 
noisyNet noise sample is [array([-0.8923679], dtype=float32), 2.1223934]. 
=============================================
[2019-03-24 04:42:25,062] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[20.12605 ]
 [20.217602]
 [20.477936]
 [20.769945]
 [20.420174]], R is [[20.4630146 ]
 [21.04810524]
 [21.62020874]
 [22.18126297]
 [22.73140335]].
[2019-03-24 04:42:28,735] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.5054823e-01 8.9272215e-13 4.9241737e-02 4.7574431e-06 2.0527239e-04], sum to 1.0000
[2019-03-24 04:42:28,743] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0716
[2019-03-24 04:42:28,914] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.2, 55.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5004984244561627, 6.911200000000001, 6.9112, 121.9260426156618, 360207.8975131399, 360207.8975131395, 116135.9243928478], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 435600.0000, 
sim time next is 436200.0000, 
raw observation next is [21.93333333333333, 56.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.501489069501265, 6.911200000000001, 6.9112, 121.9260426156618, 360887.1799558208, 360887.1799558203, 116200.4767859805], 
processed observation next is [1.0, 0.043478260869565216, 0.36790123456790114, 0.5666666666666668, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.37686133687658124, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12888827855565027, 0.1288882785556501, 0.2234624553576548], 
reward next is 0.7765, 
noisyNet noise sample is [array([0.31981328], dtype=float32), -0.8360101]. 
=============================================
[2019-03-24 04:42:29,726] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9848938e-01 1.6087364e-12 1.4995098e-03 5.6575840e-07 1.0526850e-05], sum to 1.0000
[2019-03-24 04:42:29,736] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3003
[2019-03-24 04:42:29,913] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.7, 69.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4750342098237311, 6.911199999999999, 6.9112, 121.9260426156618, 339514.0225898682, 339514.0225898687, 113367.8732168282], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 453600.0000, 
sim time next is 454200.0000, 
raw observation next is [20.0, 67.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6113921259744363, 6.9112, 6.9112, 121.9260426156618, 437747.5854680617, 437747.5854680617, 124405.1251231637], 
processed observation next is [1.0, 0.2608695652173913, 0.2962962962962963, 0.675, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5142401574680453, 0.0, 0.0, 0.8094621288201359, 0.1563384233814506, 0.1563384233814506, 0.23924062523685327], 
reward next is 0.7608, 
noisyNet noise sample is [array([-1.5253742], dtype=float32), -0.28925705]. 
=============================================
[2019-03-24 04:42:32,482] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.9142133e-16 1.6655898e-08 9.6881433e-11 6.4201102e-09], sum to 1.0000
[2019-03-24 04:42:32,490] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0286
[2019-03-24 04:42:32,495] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.55, 29.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6123655690456583, 6.911199999999999, 6.9112, 121.9260426156618, 452962.0783216755, 452962.078321676, 130547.7877642914], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 498600.0000, 
sim time next is 499200.0000, 
raw observation next is [30.3, 30.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6061150396174482, 6.911200000000001, 6.9112, 121.9260426156618, 448567.9705709944, 448567.9705709939, 130100.4194113835], 
processed observation next is [1.0, 0.782608695652174, 0.6777777777777778, 0.3, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5076437995218102, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.160202846632498, 0.16020284663249781, 0.25019311425266055], 
reward next is 0.7498, 
noisyNet noise sample is [array([-1.7498611], dtype=float32), 1.2953008]. 
=============================================
[2019-03-24 04:42:36,024] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.9999988e-01 5.3698361e-15 1.4851412e-07 8.9246235e-11 1.8484096e-09], sum to 1.0000
[2019-03-24 04:42:36,031] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1447
[2019-03-24 04:42:36,039] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1723269.869255389 W.
[2019-03-24 04:42:36,191] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.06666666666667, 37.66666666666667, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.832014727357656, 6.9112, 121.9226984164366, 1723269.869255389, 1251743.360791018, 249745.8317200425], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 566400.0000, 
sim time next is 567000.0000, 
raw observation next is [30.2, 37.0, 1.0, 2.0, 0.6604850967979111, 1.0, 1.0, 0.6604850967979111, 0.0, 2.0, 0.0, 6.911200000000003, 6.9112, 121.925488115631, 1594629.33246738, 1594629.332467379, 293333.9882215044], 
processed observation next is [1.0, 0.5652173913043478, 0.674074074074074, 0.37, 1.0, 1.0, 0.5958155914260846, 1.0, 0.5, 0.5958155914260846, 0.0, 1.0, -0.25, 2.6645352591003756e-16, 0.0, 0.8094584475165708, 0.5695104758812072, 0.5695104758812068, 0.564103823502893], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0017469], dtype=float32), 0.040599015]. 
=============================================
[2019-03-24 04:42:36,204] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[57.87821 ]
 [56.798485]
 [57.237984]
 [57.074093]
 [56.330166]], R is [[57.06777573]
 [56.49709702]
 [55.93212509]
 [55.96888351]
 [55.9678688 ]].
[2019-03-24 04:42:37,266] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1000, global step 15776: loss 0.1816
[2019-03-24 04:42:37,267] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1000, global step 15776: learning rate 0.0000
[2019-03-24 04:42:37,387] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1000, global step 15835: loss 0.1852
[2019-03-24 04:42:37,392] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1000, global step 15836: learning rate 0.0000
[2019-03-24 04:42:37,398] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1000, global step 15842: loss 0.1353
[2019-03-24 04:42:37,402] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1000, global step 15843: learning rate 0.0000
[2019-03-24 04:42:37,404] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1000, global step 15844: loss 0.1163
[2019-03-24 04:42:37,408] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1000, global step 15844: learning rate 0.0000
[2019-03-24 04:42:37,552] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1000, global step 15917: loss 0.0520
[2019-03-24 04:42:37,557] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1000, global step 15917: learning rate 0.0000
[2019-03-24 04:42:37,672] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1000, global step 15974: loss 0.0618
[2019-03-24 04:42:37,677] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1000, global step 15975: loss 0.1353
[2019-03-24 04:42:37,679] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1000, global step 15975: learning rate 0.0000
[2019-03-24 04:42:37,680] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1000, global step 15975: learning rate 0.0000
[2019-03-24 04:42:37,778] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1000, global step 16030: loss 0.0264
[2019-03-24 04:42:37,781] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1000, global step 16030: learning rate 0.0000
[2019-03-24 04:42:37,782] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1000, global step 16031: loss 0.0993
[2019-03-24 04:42:37,786] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1000, global step 16032: learning rate 0.0000
[2019-03-24 04:42:37,789] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1000, global step 16033: loss 0.0499
[2019-03-24 04:42:37,792] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1000, global step 16033: learning rate 0.0000
[2019-03-24 04:42:37,804] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1000, global step 16040: loss 0.0699
[2019-03-24 04:42:37,805] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1000, global step 16040: learning rate 0.0000
[2019-03-24 04:42:37,834] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1000, global step 16052: loss 0.0440
[2019-03-24 04:42:37,835] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1000, global step 16052: learning rate 0.0000
[2019-03-24 04:42:37,934] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1000, global step 16105: loss 0.1222
[2019-03-24 04:42:37,938] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1000, global step 16105: learning rate 0.0000
[2019-03-24 04:42:37,939] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1000, global step 16107: loss 0.0897
[2019-03-24 04:42:37,946] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1000, global step 16109: learning rate 0.0000
[2019-03-24 04:42:37,988] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1000, global step 16128: loss 0.0117
[2019-03-24 04:42:37,991] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1000, global step 16128: learning rate 0.0000
[2019-03-24 04:42:38,024] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1000, global step 16146: loss 0.0071
[2019-03-24 04:42:38,028] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1000, global step 16146: learning rate 0.0000
[2019-03-24 04:42:43,608] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 3.7203401e-17 5.2076340e-11 1.2796266e-12 4.2371291e-11], sum to 1.0000
[2019-03-24 04:42:43,622] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2769
[2019-03-24 04:42:43,628] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.2, 50.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5265463445094227, 6.911200000000001, 6.9112, 121.9260426156618, 379998.5811926209, 379998.5811926204, 118548.7738899325], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 707400.0000, 
sim time next is 708000.0000, 
raw observation next is [23.03333333333333, 51.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5159969448055939, 6.9112, 6.9112, 121.9260426156618, 372312.824367952, 372312.824367952, 117684.4343516891], 
processed observation next is [1.0, 0.17391304347826086, 0.4086419753086419, 0.5133333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3949961810069923, 0.0, 0.0, 0.8094621288201359, 0.13296886584569714, 0.13296886584569714, 0.2263162199070944], 
reward next is 0.7737, 
noisyNet noise sample is [array([-1.5454804], dtype=float32), 1.5152395]. 
=============================================
[2019-03-24 04:42:43,650] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[60.280827]
 [60.769535]
 [60.241016]
 [60.08754 ]
 [60.6168  ]], R is [[60.43748474]
 [60.60513306]
 [60.76888657]
 [60.92243958]
 [61.06295776]].
[2019-03-24 04:42:43,869] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 2.2130740e-18 7.0133205e-11 2.0504917e-13 1.7776616e-14], sum to 1.0000
[2019-03-24 04:42:43,878] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3177
[2019-03-24 04:42:44,034] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.8, 54.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.786042862997888, 6.9112, 6.9112, 121.9260426156618, 577216.9097882496, 577216.9097882496, 145917.1917354672], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 715800.0000, 
sim time next is 716400.0000, 
raw observation next is [23.9, 54.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7355335417727469, 6.911200000000001, 6.9112, 121.9260426156618, 540741.3823138986, 540741.3823138983, 140981.7631589803], 
processed observation next is [1.0, 0.30434782608695654, 0.4407407407407407, 0.54, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6694169272159336, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1931219222549638, 0.1931219222549637, 0.2711187753057313], 
reward next is 0.7289, 
noisyNet noise sample is [array([0.02855801], dtype=float32), -0.9432298]. 
=============================================
[2019-03-24 04:42:46,634] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 3.4217987e-17 1.4173768e-12 1.4823677e-11 2.2858512e-11], sum to 1.0000
[2019-03-24 04:42:46,641] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5558
[2019-03-24 04:42:46,797] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.8, 26.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.615806111237328, 6.911199999999999, 6.9112, 121.9260426156618, 452708.7242764321, 452708.7242764326, 129382.9217357907], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 757800.0000, 
sim time next is 758400.0000, 
raw observation next is [30.66666666666666, 26.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.610714896458778, 6.9112, 6.9112, 121.9260426156618, 448887.5094102835, 448887.5094102835, 128878.4032221878], 
processed observation next is [1.0, 0.782608695652174, 0.6913580246913578, 0.2633333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5133936205734724, 0.0, 0.0, 0.8094621288201359, 0.16031696764652983, 0.16031696764652983, 0.2478430831195919], 
reward next is 0.7522, 
noisyNet noise sample is [array([0.55400157], dtype=float32), -0.16988839]. 
=============================================
[2019-03-24 04:42:51,502] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 1.3040461e-16 4.9914441e-11 2.8872894e-11 1.7657509e-09], sum to 1.0000
[2019-03-24 04:42:51,508] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4543
[2019-03-24 04:42:51,667] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.8, 49.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6591486317621668, 6.9112, 6.9112, 121.9260426156618, 491770.6676159407, 491770.6676159407, 138387.2699300622], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 855600.0000, 
sim time next is 856200.0000, 
raw observation next is [26.65, 50.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6588379479483861, 6.911200000000001, 6.9112, 121.9260426156618, 491583.2046836598, 491583.2046836594, 138414.931589701], 
processed observation next is [0.0, 0.9130434782608695, 0.5425925925925925, 0.5016666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5735474349354827, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1755654302441642, 0.17556543024416407, 0.26618256074942503], 
reward next is 0.7338, 
noisyNet noise sample is [array([-2.1209502], dtype=float32), -1.8066301]. 
=============================================
[2019-03-24 04:42:52,683] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 2.1595685e-16 2.9087208e-10 2.7925049e-12 3.5348726e-13], sum to 1.0000
[2019-03-24 04:42:52,689] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0784
[2019-03-24 04:42:52,692] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.5, 67.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6248055368509583, 6.9112, 6.9112, 121.9260426156618, 463737.376401687, 463737.376401687, 132727.8494392695], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 872400.0000, 
sim time next is 873000.0000, 
raw observation next is [22.4, 67.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.619820935603245, 6.911200000000001, 6.9112, 121.9260426156618, 459572.1962164844, 459572.1962164839, 131931.9963405076], 
processed observation next is [0.0, 0.08695652173913043, 0.38518518518518513, 0.675, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5247761695040563, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.164132927220173, 0.1641329272201728, 0.25371537757789925], 
reward next is 0.7463, 
noisyNet noise sample is [array([-0.6462454], dtype=float32), 1.4178796]. 
=============================================
[2019-03-24 04:42:52,702] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[68.467804]
 [68.42515 ]
 [68.63291 ]
 [68.762924]
 [69.06175 ]], R is [[68.39186096]
 [68.45269775]
 [68.51177216]
 [68.56925964]
 [68.62559509]].
[2019-03-24 04:42:53,703] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1500, global step 23744: loss 0.0355
[2019-03-24 04:42:53,705] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1500, global step 23744: learning rate 0.0000
[2019-03-24 04:42:53,746] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1500, global step 23762: loss 0.0332
[2019-03-24 04:42:53,747] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1500, global step 23762: learning rate 0.0000
[2019-03-24 04:42:53,821] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1500, global step 23798: loss 0.1327
[2019-03-24 04:42:53,832] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1500, global step 23799: learning rate 0.0000
[2019-03-24 04:42:54,062] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1500, global step 23923: loss 0.1104
[2019-03-24 04:42:54,064] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1500, global step 23923: learning rate 0.0000
[2019-03-24 04:42:54,114] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1500, global step 23947: loss 0.0530
[2019-03-24 04:42:54,117] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1500, global step 23948: learning rate 0.0000
[2019-03-24 04:42:54,130] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1500, global step 23955: loss 0.0524
[2019-03-24 04:42:54,134] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1500, global step 23956: learning rate 0.0000
[2019-03-24 04:42:54,207] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1500, global step 23996: loss 0.0215
[2019-03-24 04:42:54,211] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1500, global step 23997: learning rate 0.0000
[2019-03-24 04:42:54,223] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1500, global step 24000: loss 0.0030
[2019-03-24 04:42:54,224] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1500, global step 24000: learning rate 0.0000
[2019-03-24 04:42:54,283] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1500, global step 24034: loss 0.0063
[2019-03-24 04:42:54,284] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1500, global step 24034: learning rate 0.0000
[2019-03-24 04:42:54,338] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1500, global step 24057: loss 0.0233
[2019-03-24 04:42:54,339] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1500, global step 24058: learning rate 0.0000
[2019-03-24 04:42:54,367] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1500, global step 24072: loss 0.0136
[2019-03-24 04:42:54,369] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1500, global step 24072: learning rate 0.0000
[2019-03-24 04:42:54,395] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1500, global step 24089: loss 0.0026
[2019-03-24 04:42:54,398] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1500, global step 24090: learning rate 0.0000
[2019-03-24 04:42:54,420] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1500, global step 24102: loss 0.0031
[2019-03-24 04:42:54,423] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1500, global step 24103: learning rate 0.0000
[2019-03-24 04:42:54,429] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1500, global step 24107: loss 0.0016
[2019-03-24 04:42:54,432] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1500, global step 24107: learning rate 0.0000
[2019-03-24 04:42:54,433] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1500, global step 24108: loss 0.0020
[2019-03-24 04:42:54,441] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1500, global step 24109: learning rate 0.0000
[2019-03-24 04:42:54,484] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1500, global step 24131: loss 0.0129
[2019-03-24 04:42:54,486] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1500, global step 24132: learning rate 0.0000
[2019-03-24 04:42:55,970] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 4.3148258e-19 4.2492143e-10 6.5633100e-14 1.8178386e-12], sum to 1.0000
[2019-03-24 04:42:55,976] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5185
[2019-03-24 04:42:55,980] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.3, 45.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6366484209494095, 6.9112, 6.9112, 121.9260426156618, 474163.3835065859, 474163.3835065859, 135192.8762611819], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 928800.0000, 
sim time next is 929400.0000, 
raw observation next is [27.13333333333333, 45.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6388087615452308, 6.911200000000001, 6.9112, 121.9260426156618, 475704.5825204935, 475704.582520493, 135343.2760236423], 
processed observation next is [0.0, 0.782608695652174, 0.5604938271604937, 0.45666666666666655, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5485109519315384, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1698944937573191, 0.16989449375731894, 0.26027553081469673], 
reward next is 0.7397, 
noisyNet noise sample is [array([-0.7731228], dtype=float32), -0.0070398403]. 
=============================================
[2019-03-24 04:42:56,221] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-24 04:42:56,222] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:42:56,223] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:42:56,223] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:42:56,224] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:42:56,224] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:42:56,226] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:42:56,227] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:42:56,229] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:42:56,227] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:42:56,231] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:42:56,239] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run2
[2019-03-24 04:42:56,262] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run2
[2019-03-24 04:42:56,290] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run2
[2019-03-24 04:42:56,313] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run2
[2019-03-24 04:42:56,336] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run2
[2019-03-24 04:43:47,871] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00441334], dtype=float32), 0.007428903]
[2019-03-24 04:43:47,872] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.96666666666667, 87.33333333333334, 1.0, 2.0, 0.8861775658221164, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1725306.135730237, 1725306.135730238, 353999.6117959986]
[2019-03-24 04:43:47,875] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 04:43:47,877] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 4.0340231e-22 3.7721077e-13 1.0188095e-15 8.2252778e-15], sampled 0.17590398584432454
[2019-03-24 04:43:47,878] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1725306.135730237 W.
[2019-03-24 04:43:53,113] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00441334], dtype=float32), 0.007428903]
[2019-03-24 04:43:53,114] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.58333333333333, 95.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9557225793219511, 7.421630754825197, 6.9112, 122.0184049471481, 975960.9465008144, 714376.7710339089, 174930.9423214271]
[2019-03-24 04:43:53,116] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 04:43:53,119] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.5845451e-21 8.3529353e-13 2.6736184e-15 2.0889239e-14], sampled 0.9117340401384557
[2019-03-24 04:43:53,120] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 975960.9465008144 W.
[2019-03-24 04:44:23,735] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00441334], dtype=float32), 0.007428903]
[2019-03-24 04:44:23,736] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.38759323, 81.49270774, 1.0, 2.0, 0.6518175515676564, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 742861.0065235734, 742861.0065235734, 167220.7307097044]
[2019-03-24 04:44:23,737] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:44:23,739] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.0804021e-19 9.2939710e-12 5.0045729e-14 3.2101511e-13], sampled 0.6468780025052222
[2019-03-24 04:44:23,741] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 742861.0065235734 W.
[2019-03-24 04:44:38,022] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00441334], dtype=float32), 0.007428903]
[2019-03-24 04:44:38,023] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [19.03267377, 59.61242416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4329207591277678, 6.911200000000001, 6.9112, 121.9260426156618, 309117.8160255534, 309117.8160255529, 94127.31969617779]
[2019-03-24 04:44:38,024] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:44:38,026] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 2.0590820e-21 9.9676051e-13 3.2315755e-15 2.5405224e-14], sampled 0.2815910711478994
[2019-03-24 04:44:40,762] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8559.5106 2258278767.0965 536.0000
[2019-03-24 04:44:40,917] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 04:44:40,953] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 04:44:40,970] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 04:44:41,155] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.4716 2529798096.8055 831.0000
[2019-03-24 04:44:42,170] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 25000, evaluation results [25000.0, 7841.471632967488, 2529798096.8055396, 831.0, 8559.510645911187, 2258278767.096507, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 04:44:49,263] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.8690035e-13 5.2747566e-09 1.4607010e-10 5.8874000e-10], sum to 1.0000
[2019-03-24 04:44:49,269] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1773
[2019-03-24 04:44:49,282] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 928419.7557294902 W.
[2019-03-24 04:44:49,468] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.21666666666667, 51.5, 1.0, 2.0, 0.3715944143623501, 1.0, 2.0, 0.3715944143623501, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 928419.7557294902, 928419.7557294902, 201456.4261827319], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1075800.0000, 
sim time next is 1076400.0000, 
raw observation next is [24.3, 51.0, 1.0, 2.0, 0.3912155070717278, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6600795513110629, 6.911199999999997, 6.9112, 121.9260426156618, 981511.7070982086, 981511.7070982099, 216571.2305528735], 
processed observation next is [1.0, 0.4782608695652174, 0.4555555555555556, 0.51, 1.0, 1.0, 0.2752565560377712, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.5750994391388285, -2.6645352591003756e-16, 0.0, 0.8094621288201359, 0.35053989539221736, 0.3505398953922178, 0.41648313567860284], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.87982345], dtype=float32), 0.73191494]. 
=============================================
[2019-03-24 04:44:51,779] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.9824068e-21 7.9597838e-15 2.3296309e-13 1.3035012e-13], sum to 1.0000
[2019-03-24 04:44:51,784] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6606
[2019-03-24 04:44:51,787] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.25, 71.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5344202360498681, 6.911199999999999, 6.9112, 121.9260426156618, 388762.3817956125, 388762.381795613, 120357.5089457656], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1115400.0000, 
sim time next is 1116000.0000, 
raw observation next is [20.1, 72.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5315772902899881, 6.9112, 6.9112, 121.9260426156618, 386194.8814941525, 386194.8814941525, 119924.228689637], 
processed observation next is [1.0, 0.9565217391304348, 0.30000000000000004, 0.72, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.41447161286248513, 0.0, 0.0, 0.8094621288201359, 0.13792674339076874, 0.13792674339076874, 0.2306235167108404], 
reward next is 0.7694, 
noisyNet noise sample is [array([0.15860061], dtype=float32), -0.32351506]. 
=============================================
[2019-03-24 04:44:51,803] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[78.11922 ]
 [78.07342 ]
 [77.828995]
 [77.69553 ]
 [77.69578 ]], R is [[78.19710541]
 [78.1836853 ]
 [78.1696167 ]
 [78.15496063]
 [78.1397934 ]].
[2019-03-24 04:44:52,911] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 2.8044646e-21 1.5840257e-13 1.2816520e-15 8.3361717e-14], sum to 1.0000
[2019-03-24 04:44:52,917] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8738
[2019-03-24 04:44:53,093] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.11666666666667, 74.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4818463309963799, 6.911200000000001, 6.9112, 121.9260426156618, 345703.9545943809, 345703.9545943805, 114325.9121406562], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1144200.0000, 
sim time next is 1144800.0000, 
raw observation next is [19.2, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4826531103518159, 6.9112, 6.9112, 121.9260426156618, 346402.2059179708, 346402.2059179708, 114428.3021393298], 
processed observation next is [1.0, 0.2608695652173913, 0.26666666666666666, 0.74, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3533163879397698, 0.0, 0.0, 0.8094621288201359, 0.12371507354213243, 0.12371507354213243, 0.22005442719101884], 
reward next is 0.7799, 
noisyNet noise sample is [array([0.12452977], dtype=float32), 0.70771945]. 
=============================================
[2019-03-24 04:44:55,167] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2000, global step 31645: loss 0.2911
[2019-03-24 04:44:55,169] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2000, global step 31646: learning rate 0.0000
[2019-03-24 04:44:55,255] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2000, global step 31698: loss 0.0756
[2019-03-24 04:44:55,256] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2000, global step 31698: learning rate 0.0000
[2019-03-24 04:44:55,412] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2000, global step 31777: loss 0.2268
[2019-03-24 04:44:55,418] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2000, global step 31777: learning rate 0.0000
[2019-03-24 04:44:55,461] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2000, global step 31796: loss 0.0875
[2019-03-24 04:44:55,462] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2000, global step 31797: learning rate 0.0000
[2019-03-24 04:44:55,477] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 2.6026879e-19 1.9027980e-12 3.1159327e-14 2.9453074e-12], sum to 1.0000
[2019-03-24 04:44:55,482] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8093
[2019-03-24 04:44:55,652] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.86666666666667, 93.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5938681126709487, 6.9112, 6.9112, 121.9260426156618, 439595.796725734, 439595.796725734, 129017.9347640877], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1205400.0000, 
sim time next is 1206000.0000, 
raw observation next is [18.8, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5927611118586197, 6.9112, 6.9112, 121.9260426156618, 438816.0934933135, 438816.0934933135, 128939.930960829], 
processed observation next is [1.0, 1.0, 0.2518518518518519, 0.94, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4909513898232746, 0.0, 0.0, 0.8094621288201359, 0.1567200333904691, 0.1567200333904691, 0.24796140569390193], 
reward next is 0.7520, 
noisyNet noise sample is [array([1.1939305], dtype=float32), -0.05704358]. 
=============================================
[2019-03-24 04:44:55,674] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[69.27451]
 [69.21897]
 [69.16794]
 [69.14106]
 [69.09783]], R is [[69.42663574]
 [69.48426056]
 [69.5410614 ]
 [69.59708405]
 [69.652565  ]].
[2019-03-24 04:44:55,845] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2000, global step 31916: loss 0.1144
[2019-03-24 04:44:55,847] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2000, global step 31916: learning rate 0.0000
[2019-03-24 04:44:55,960] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2000, global step 31979: loss 0.4030
[2019-03-24 04:44:55,961] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2000, global step 31980: learning rate 0.0000
[2019-03-24 04:44:55,983] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2000, global step 31993: loss 0.2975
[2019-03-24 04:44:55,983] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2000, global step 31993: loss 0.1046
[2019-03-24 04:44:55,984] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2000, global step 31993: learning rate 0.0000
[2019-03-24 04:44:55,991] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2000, global step 31993: learning rate 0.0000
[2019-03-24 04:44:56,043] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2000, global step 32019: loss 0.0852
[2019-03-24 04:44:56,051] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2000, global step 32022: learning rate 0.0000
[2019-03-24 04:44:56,090] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2000, global step 32044: loss 0.5350
[2019-03-24 04:44:56,092] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2000, global step 32044: learning rate 0.0000
[2019-03-24 04:44:56,148] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2000, global step 32074: loss 0.1853
[2019-03-24 04:44:56,150] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2000, global step 32074: learning rate 0.0000
[2019-03-24 04:44:56,176] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2000, global step 32088: loss 0.9656
[2019-03-24 04:44:56,178] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2000, global step 32088: learning rate 0.0000
[2019-03-24 04:44:56,220] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2000, global step 32111: loss 0.0955
[2019-03-24 04:44:56,220] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2000, global step 32111: learning rate 0.0000
[2019-03-24 04:44:56,318] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2000, global step 32164: loss 0.1957
[2019-03-24 04:44:56,322] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2000, global step 32164: learning rate 0.0000
[2019-03-24 04:44:56,366] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2000, global step 32186: loss 2.9850
[2019-03-24 04:44:56,369] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2000, global step 32187: learning rate 0.0000
[2019-03-24 04:44:56,512] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2000, global step 32263: loss 0.0694
[2019-03-24 04:44:56,515] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2000, global step 32263: learning rate 0.0000
[2019-03-24 04:44:59,958] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.8375376e-20 9.9157054e-13 2.3771414e-14 4.1094810e-13], sum to 1.0000
[2019-03-24 04:44:59,965] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6224
[2019-03-24 04:44:59,967] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.1, 68.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6885312158437941, 6.911200000000001, 6.9112, 121.9260426156618, 514506.4474928582, 514506.4474928577, 143208.0114564261], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1282200.0000, 
sim time next is 1282800.0000, 
raw observation next is [23.9, 69.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6855357695681693, 6.9112, 6.9112, 121.9260426156618, 512253.3476040929, 512253.3476040929, 142795.4831823905], 
processed observation next is [1.0, 0.8695652173913043, 0.4407407407407407, 0.69, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6069197119602115, 0.0, 0.0, 0.8094621288201359, 0.1829476241443189, 0.1829476241443189, 0.27460669842767405], 
reward next is 0.7254, 
noisyNet noise sample is [array([0.9281255], dtype=float32), 1.7409486]. 
=============================================
[2019-03-24 04:45:01,730] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 8.9706373e-18 4.7135772e-12 4.4450446e-13 5.8292455e-12], sum to 1.0000
[2019-03-24 04:45:01,745] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6066
[2019-03-24 04:45:01,752] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.76666666666667, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7446201912964996, 6.9112, 6.9112, 121.9260426156618, 555831.9127046054, 555831.9127046054, 147892.5474782771], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1325400.0000, 
sim time next is 1326000.0000, 
raw observation next is [23.03333333333333, 71.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9568312998309786, 7.211948369998607, 6.9112, 121.9250785668654, 868335.8159534484, 714326.9876615135, 172600.6984132394], 
processed observation next is [1.0, 0.34782608695652173, 0.4086419753086419, 0.71, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9460391247887231, 0.030074836999860733, 0.0, 0.8094557285386679, 0.31011993426908874, 0.2551167813076834, 0.3319244200254604], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3091528], dtype=float32), 0.31530055]. 
=============================================
[2019-03-24 04:45:01,771] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[71.93681 ]
 [71.93325 ]
 [71.79342 ]
 [71.80461 ]
 [71.732956]], R is [[71.217659  ]
 [71.22107697]
 [71.23028564]
 [71.25301361]
 [71.27680969]].
[2019-03-24 04:45:08,290] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.4428486e-22 1.0675771e-11 3.8994649e-16 4.4932143e-13], sum to 1.0000
[2019-03-24 04:45:08,300] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7837
[2019-03-24 04:45:08,305] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [34.76666666666667, 20.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7065583841379396, 6.911199999999999, 6.9112, 121.9260426156618, 525804.1380672759, 525804.1380672763, 141959.4892390765], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1440600.0000, 
sim time next is 1441200.0000, 
raw observation next is [34.53333333333333, 21.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6755113701821037, 6.9112, 6.9112, 121.9260426156618, 502653.7160788787, 502653.7160788787, 138706.5563451725], 
processed observation next is [0.0, 0.6956521739130435, 0.8345679012345678, 0.21, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5943892127276296, 0.0, 0.0, 0.8094621288201359, 0.17951918431388525, 0.17951918431388525, 0.26674337758687017], 
reward next is 0.7333, 
noisyNet noise sample is [array([0.20963117], dtype=float32), 0.5427266]. 
=============================================
[2019-03-24 04:45:08,820] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.9584313e-19 1.0236603e-10 4.4401316e-16 1.5200970e-14], sum to 1.0000
[2019-03-24 04:45:08,828] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9677
[2019-03-24 04:45:08,834] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.56666666666667, 29.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6191111445255096, 6.9112, 6.9112, 121.9260426156618, 458234.6516159342, 458234.6516159342, 131351.4573511134], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1455600.0000, 
sim time next is 1456200.0000, 
raw observation next is [30.4, 30.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6164461124690148, 6.911200000000001, 6.9112, 121.9260426156618, 456410.5533895554, 456410.553389555, 131190.3019453592], 
processed observation next is [0.0, 0.8695652173913043, 0.6814814814814815, 0.3, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5205576405862685, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16300376906769837, 0.16300376906769823, 0.2522890422026139], 
reward next is 0.7477, 
noisyNet noise sample is [array([-2.0975819], dtype=float32), 1.3344467]. 
=============================================
[2019-03-24 04:45:10,271] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.00000000e+00 8.20842858e-19 1.17704145e-11 3.52848664e-13
 3.72143705e-11], sum to 1.0000
[2019-03-24 04:45:10,278] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6585
[2019-03-24 04:45:10,282] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 66.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.582139108139568, 6.9112, 6.9112, 121.9260426156618, 428853.0606733223, 428853.0606733223, 126786.0208648141], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1482000.0000, 
sim time next is 1482600.0000, 
raw observation next is [21.9, 67.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5824456673953191, 6.911200000000001, 6.9112, 121.9260426156618, 429217.0298702572, 429217.0298702568, 126885.1441628305], 
processed observation next is [0.0, 0.13043478260869565, 0.36666666666666664, 0.6716666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.47805708424414883, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15329179638223472, 0.15329179638223456, 0.2440098926208279], 
reward next is 0.7560, 
noisyNet noise sample is [array([0.43514448], dtype=float32), 0.648798]. 
=============================================
[2019-03-24 04:45:10,539] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2500, global step 39742: loss 0.0029
[2019-03-24 04:45:10,540] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2500, global step 39743: learning rate 0.0000
[2019-03-24 04:45:10,562] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2500, global step 39761: loss 0.0423
[2019-03-24 04:45:10,567] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2500, global step 39762: learning rate 0.0000
[2019-03-24 04:45:10,600] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2500, global step 39776: loss 0.1302
[2019-03-24 04:45:10,604] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2500, global step 39776: learning rate 0.0000
[2019-03-24 04:45:10,886] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2500, global step 39951: loss 0.0140
[2019-03-24 04:45:10,891] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2500, global step 39951: learning rate 0.0000
[2019-03-24 04:45:10,901] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2500, global step 39955: loss 0.0072
[2019-03-24 04:45:10,904] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2500, global step 39956: loss 0.0063
[2019-03-24 04:45:10,905] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2500, global step 39956: learning rate 0.0000
[2019-03-24 04:45:10,908] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2500, global step 39956: learning rate 0.0000
[2019-03-24 04:45:10,926] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2500, global step 39968: loss 0.0046
[2019-03-24 04:45:10,928] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2500, global step 39968: learning rate 0.0000
[2019-03-24 04:45:10,945] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2500, global step 39981: loss 0.0312
[2019-03-24 04:45:10,947] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2500, global step 39981: learning rate 0.0000
[2019-03-24 04:45:10,985] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2500, global step 40001: loss 0.0022
[2019-03-24 04:45:10,989] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2500, global step 40002: learning rate 0.0000
[2019-03-24 04:45:11,018] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.7191302e-19 1.1804769e-11 3.2421979e-13 1.1660114e-12], sum to 1.0000
[2019-03-24 04:45:11,024] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1802
[2019-03-24 04:45:11,028] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.78333333333333, 52.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6775568075136456, 6.911200000000001, 6.9112, 121.9260426156618, 506180.8026779687, 506180.8026779682, 141515.4843127279], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1497000.0000, 
sim time next is 1497600.0000, 
raw observation next is [27.1, 51.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6810672757417513, 6.9112, 6.9112, 121.9260426156618, 508856.9253882226, 508856.9253882226, 142062.7117053291], 
processed observation next is [0.0, 0.34782608695652173, 0.5592592592592593, 0.51, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6013340946771891, 0.0, 0.0, 0.8094621288201359, 0.1817346162100795, 0.1817346162100795, 0.27319752251024826], 
reward next is 0.7268, 
noisyNet noise sample is [array([0.12588143], dtype=float32), -0.5867869]. 
=============================================
[2019-03-24 04:45:11,045] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2500, global step 40027: loss 0.0041
[2019-03-24 04:45:11,048] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2500, global step 40028: learning rate 0.0000
[2019-03-24 04:45:11,142] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2500, global step 40078: loss 0.0186
[2019-03-24 04:45:11,144] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2500, global step 40078: loss 0.0008
[2019-03-24 04:45:11,144] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2500, global step 40078: learning rate 0.0000
[2019-03-24 04:45:11,147] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2500, global step 40081: learning rate 0.0000
[2019-03-24 04:45:11,165] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2500, global step 40089: loss 0.0011
[2019-03-24 04:45:11,167] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2500, global step 40089: learning rate 0.0000
[2019-03-24 04:45:11,168] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2500, global step 40089: loss 0.0008
[2019-03-24 04:45:11,171] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2500, global step 40089: learning rate 0.0000
[2019-03-24 04:45:11,182] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2500, global step 40094: loss 0.0029
[2019-03-24 04:45:11,186] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2500, global step 40095: learning rate 0.0000
[2019-03-24 04:45:11,505] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2500, global step 40258: loss 0.0204
[2019-03-24 04:45:11,507] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2500, global step 40258: learning rate 0.0000
[2019-03-24 04:45:18,387] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9999976e-01 1.2727995e-14 1.9356318e-07 2.6274310e-12 8.9716012e-09], sum to 1.0000
[2019-03-24 04:45:18,396] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0299
[2019-03-24 04:45:18,403] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.13333333333333, 53.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5772290245006313, 6.911199999999999, 6.9112, 121.9260426156618, 425212.2801154729, 425212.2801154733, 126334.1484009014], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1633800.0000, 
sim time next is 1634400.0000, 
raw observation next is [24.0, 54.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5735799660882492, 6.911200000000001, 6.9112, 121.9260426156618, 422344.1303396787, 422344.1303396783, 125916.3724080973], 
processed observation next is [1.0, 0.9565217391304348, 0.4444444444444444, 0.54, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4669749576103115, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15083718940702812, 0.15083718940702798, 0.24214687001557175], 
reward next is 0.7579, 
noisyNet noise sample is [array([-1.0119588], dtype=float32), -0.12877896]. 
=============================================
[2019-03-24 04:45:26,504] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3000, global step 47671: loss 0.1802
[2019-03-24 04:45:26,505] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3000, global step 47671: learning rate 0.0000
[2019-03-24 04:45:26,719] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3000, global step 47782: loss 0.4872
[2019-03-24 04:45:26,723] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3000, global step 47783: learning rate 0.0000
[2019-03-24 04:45:26,767] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3000, global step 47802: loss 0.0714
[2019-03-24 04:45:26,768] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3000, global step 47802: learning rate 0.0000
[2019-03-24 04:45:26,927] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3000, global step 47881: loss 0.3114
[2019-03-24 04:45:26,929] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3000, global step 47881: learning rate 0.0000
[2019-03-24 04:45:26,946] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3000, global step 47891: loss 0.2467
[2019-03-24 04:45:26,947] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3000, global step 47891: learning rate 0.0000
[2019-03-24 04:45:27,063] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3000, global step 47953: loss 0.5567
[2019-03-24 04:45:27,064] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3000, global step 47953: learning rate 0.0000
[2019-03-24 04:45:27,124] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3000, global step 47977: loss 0.1864
[2019-03-24 04:45:27,127] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3000, global step 47979: learning rate 0.0000
[2019-03-24 04:45:27,255] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3000, global step 48047: loss 0.1779
[2019-03-24 04:45:27,257] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3000, global step 48047: loss 0.3742
[2019-03-24 04:45:27,258] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3000, global step 48047: learning rate 0.0000
[2019-03-24 04:45:27,263] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3000, global step 48047: learning rate 0.0000
[2019-03-24 04:45:27,272] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3000, global step 48053: loss 0.2081
[2019-03-24 04:45:27,274] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3000, global step 48053: learning rate 0.0000
[2019-03-24 04:45:27,305] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3000, global step 48066: loss 0.5330
[2019-03-24 04:45:27,309] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3000, global step 48067: loss 0.8175
[2019-03-24 04:45:27,309] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3000, global step 48067: learning rate 0.0000
[2019-03-24 04:45:27,312] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3000, global step 48069: learning rate 0.0000
[2019-03-24 04:45:27,339] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3000, global step 48083: loss 2.7344
[2019-03-24 04:45:27,341] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3000, global step 48084: learning rate 0.0000
[2019-03-24 04:45:27,375] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3000, global step 48102: loss 0.9853
[2019-03-24 04:45:27,376] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3000, global step 48102: learning rate 0.0000
[2019-03-24 04:45:27,563] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3000, global step 48197: loss 0.7833
[2019-03-24 04:45:27,566] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3000, global step 48198: learning rate 0.0000
[2019-03-24 04:45:27,654] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3000, global step 48244: loss 0.7540
[2019-03-24 04:45:27,657] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3000, global step 48244: learning rate 0.0000
[2019-03-24 04:45:31,187] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-24 04:45:31,188] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:45:31,189] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:45:31,189] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:45:31,190] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:45:31,191] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:45:31,190] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:45:31,193] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:45:31,195] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:45:31,194] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:45:31,197] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:45:31,206] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run3
[2019-03-24 04:45:31,229] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run3
[2019-03-24 04:45:31,249] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run3
[2019-03-24 04:45:31,251] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run3
[2019-03-24 04:45:31,251] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run3
[2019-03-24 04:45:34,747] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00431488], dtype=float32), 0.0070576677]
[2019-03-24 04:45:34,749] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [14.1, 68.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3152107747978006, 6.911199999999999, 6.9112, 121.9260426156618, 225044.1889918557, 225044.1889918562, 72605.54278851542]
[2019-03-24 04:45:34,750] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:45:34,752] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.9999070e-01 8.0383974e-13 9.2122355e-06 3.7543349e-10 8.0286881e-08], sampled 0.20182843131096162
[2019-03-24 04:46:42,260] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00431488], dtype=float32), 0.0070576677]
[2019-03-24 04:46:42,262] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.83333333333334, 49.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8645065496448879, 6.911200000000001, 6.9112, 121.9260426156618, 634140.3310621771, 634140.3310621767, 170974.6907981457]
[2019-03-24 04:46:42,263] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:46:42,267] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.9999642e-01 8.0131052e-14 3.6333479e-06 6.3181113e-11 2.0788827e-08], sampled 0.47057547095567387
[2019-03-24 04:47:15,863] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8363.4461 2339454707.5110 616.0000
[2019-03-24 04:47:16,010] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 04:47:16,116] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.0619 2219195608.6820 543.0000
[2019-03-24 04:47:16,192] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5295 2529767993.6091 831.0000
[2019-03-24 04:47:16,338] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8402.7964 2292991226.4384 697.0000
[2019-03-24 04:47:17,353] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 50000, evaluation results [50000.0, 7841.529523729852, 2529767993.609111, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.061850958873, 2219195608.6819544, 543.0, 8363.446078711597, 2339454707.511047, 616.0, 8402.796369036923, 2292991226.4383693, 697.0]
[2019-03-24 04:47:20,808] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.5165639e-14 3.1059677e-08 7.8299069e-12 6.1184835e-10], sum to 1.0000
[2019-03-24 04:47:20,812] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5224
[2019-03-24 04:47:20,821] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1184907.104046252 W.
[2019-03-24 04:47:20,828] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.85, 84.5, 1.0, 2.0, 0.3362470533669561, 1.0, 2.0, 0.3362470533669561, 1.0, 2.0, 0.5379649032131323, 6.9112, 6.9112, 121.94756008, 1184907.104046252, 1184907.104046252, 270219.5473661553], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1941000.0000, 
sim time next is 1941600.0000, 
raw observation next is [23.1, 83.0, 1.0, 2.0, 0.507663038647197, 1.0, 2.0, 0.507663038647197, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1199440.993351794, 1199440.993351794, 239646.3051645031], 
processed observation next is [1.0, 0.4782608695652174, 0.41111111111111115, 0.83, 1.0, 1.0, 0.41388456981809163, 1.0, 1.0, 0.41388456981809163, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4283717833399265, 0.4283717833399265, 0.460858279162506], 
reward next is 0.5391, 
noisyNet noise sample is [array([-0.70525116], dtype=float32), 0.20027415]. 
=============================================
[2019-03-24 04:47:22,645] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.0962236e-19 2.2870659e-09 3.4147429e-14 1.9535025e-12], sum to 1.0000
[2019-03-24 04:47:22,645] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9228
[2019-03-24 04:47:22,840] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.51666666666667, 90.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6125229048356146, 6.9112, 6.9112, 121.9260426156618, 454900.6736348627, 454900.6736348627, 131751.8257811827], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1986600.0000, 
sim time next is 1987200.0000, 
raw observation next is [19.5, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6125538666154928, 6.911199999999999, 6.9112, 121.9260426156618, 454934.7871474361, 454934.7871474365, 131762.9280738588], 
processed observation next is [0.0, 0.0, 0.2777777777777778, 0.91, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.515692333269366, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1624767096955129, 0.16247670969551303, 0.25339024629588236], 
reward next is 0.7466, 
noisyNet noise sample is [array([0.11879358], dtype=float32), 0.66528106]. 
=============================================
[2019-03-24 04:47:28,504] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3500, global step 55756: loss 0.0234
[2019-03-24 04:47:28,505] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3500, global step 55756: learning rate 0.0000
[2019-03-24 04:47:28,546] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3500, global step 55775: loss 0.0131
[2019-03-24 04:47:28,549] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3500, global step 55776: learning rate 0.0000
[2019-03-24 04:47:28,564] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3500, global step 55782: loss 0.0005
[2019-03-24 04:47:28,567] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3500, global step 55783: learning rate 0.0000
[2019-03-24 04:47:28,621] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3500, global step 55817: loss 0.0017
[2019-03-24 04:47:28,622] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3500, global step 55817: learning rate 0.0000
[2019-03-24 04:47:28,782] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3500, global step 55900: loss 0.0114
[2019-03-24 04:47:28,783] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3500, global step 55900: learning rate 0.0000
[2019-03-24 04:47:28,909] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3500, global step 55962: loss 0.0238
[2019-03-24 04:47:28,911] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3500, global step 55963: learning rate 0.0000
[2019-03-24 04:47:28,960] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3500, global step 55988: loss 0.0017
[2019-03-24 04:47:28,962] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3500, global step 55989: learning rate 0.0000
[2019-03-24 04:47:28,963] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3500, global step 55990: loss 0.0041
[2019-03-24 04:47:28,966] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3500, global step 55990: learning rate 0.0000
[2019-03-24 04:47:28,977] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3500, global step 55997: loss 0.0259
[2019-03-24 04:47:28,979] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3500, global step 55997: learning rate 0.0000
[2019-03-24 04:47:28,987] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3500, global step 55999: loss 0.0006
[2019-03-24 04:47:28,988] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3500, global step 55999: learning rate 0.0000
[2019-03-24 04:47:29,000] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3500, global step 56003: loss 0.0028
[2019-03-24 04:47:29,002] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3500, global step 56004: learning rate 0.0000
[2019-03-24 04:47:29,059] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3500, global step 56038: loss 0.0003
[2019-03-24 04:47:29,061] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3500, global step 56038: learning rate 0.0000
[2019-03-24 04:47:29,250] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3500, global step 56138: loss 0.0013
[2019-03-24 04:47:29,251] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3500, global step 56138: learning rate 0.0000
[2019-03-24 04:47:29,344] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3500, global step 56185: loss 0.0243
[2019-03-24 04:47:29,347] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3500, global step 56186: learning rate 0.0000
[2019-03-24 04:47:29,454] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3500, global step 56240: loss 0.0134
[2019-03-24 04:47:29,456] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3500, global step 56241: learning rate 0.0000
[2019-03-24 04:47:29,471] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3500, global step 56250: loss 0.0880
[2019-03-24 04:47:29,471] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3500, global step 56250: learning rate 0.0000
[2019-03-24 04:47:29,566] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 3.9170920e-21 2.4177618e-09 8.0791121e-17 9.2328029e-12], sum to 1.0000
[2019-03-24 04:47:29,574] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7933
[2019-03-24 04:47:29,577] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.3, 74.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8850661316473067, 6.911200000000001, 6.9112, 121.9260426156618, 647345.8511845021, 647345.8511845017, 174048.484018046], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2111400.0000, 
sim time next is 2112000.0000, 
raw observation next is [26.53333333333333, 73.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8936721554039492, 6.9112, 6.9112, 121.9260426156618, 652679.2293577581, 652679.2293577581, 175369.8581024993], 
processed observation next is [0.0, 0.43478260869565216, 0.5382716049382715, 0.7366666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8670901942549364, 0.0, 0.0, 0.8094621288201359, 0.23309972477062788, 0.23309972477062788, 0.33724972712019097], 
reward next is 0.6628, 
noisyNet noise sample is [array([-1.1815784], dtype=float32), 0.21805154]. 
=============================================
[2019-03-24 04:47:29,597] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[70.67445]
 [70.65755]
 [70.63165]
 [70.60852]
 [70.53581]], R is [[70.65711975]
 [70.6158371 ]
 [70.57739258]
 [70.54154205]
 [70.50827789]].
[2019-03-24 04:47:43,071] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.9821162e-01 3.8143913e-10 1.7879094e-03 1.2338303e-09 4.4122504e-07], sum to 1.0000
[2019-03-24 04:47:43,082] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6011
[2019-03-24 04:47:43,090] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1330511.180619865 W.
[2019-03-24 04:47:43,094] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.0, 37.0, 1.0, 2.0, 0.5554264683753986, 1.0, 2.0, 0.5554264683753986, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156403, 1330511.180619865, 1330511.180619864, 255838.5462375012], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2382600.0000, 
sim time next is 2383200.0000, 
raw observation next is [31.1, 37.0, 1.0, 2.0, 0.3860687414981361, 1.0, 2.0, 0.3860687414981361, 1.0, 1.0, 0.6194334051006213, 6.911200000000001, 6.9112, 121.94756008, 1371854.059792762, 1371854.059792761, 290891.1791078543], 
processed observation next is [1.0, 0.6086956521739131, 0.7074074074074075, 0.37, 1.0, 1.0, 0.2691294541644477, 1.0, 1.0, 0.2691294541644477, 1.0, 0.5, 0.5242917563757765, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.48994787849741495, 0.4899478784974146, 0.5594061136689507], 
reward next is 0.4406, 
noisyNet noise sample is [array([0.27082166], dtype=float32), -0.3729911]. 
=============================================
[2019-03-24 04:47:43,871] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4000, global step 63744: loss 4.9938
[2019-03-24 04:47:43,874] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4000, global step 63744: learning rate 0.0000
[2019-03-24 04:47:43,907] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4000, global step 63762: loss 9.2240
[2019-03-24 04:47:43,908] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4000, global step 63762: learning rate 0.0000
[2019-03-24 04:47:43,925] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4000, global step 63770: loss 9.8542
[2019-03-24 04:47:43,928] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4000, global step 63771: learning rate 0.0000
[2019-03-24 04:47:44,078] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4000, global step 63851: loss 4.2740
[2019-03-24 04:47:44,079] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4000, global step 63852: learning rate 0.0000
[2019-03-24 04:47:44,224] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4000, global step 63928: loss 12.6222
[2019-03-24 04:47:44,225] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4000, global step 63928: learning rate 0.0000
[2019-03-24 04:47:44,306] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4000, global step 63972: loss 6.3515
[2019-03-24 04:47:44,310] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4000, global step 63973: learning rate 0.0000
[2019-03-24 04:47:44,319] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4000, global step 63977: loss 4.2411
[2019-03-24 04:47:44,321] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4000, global step 63977: learning rate 0.0000
[2019-03-24 04:47:44,325] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4000, global step 63979: loss 12.3115
[2019-03-24 04:47:44,326] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4000, global step 63979: learning rate 0.0000
[2019-03-24 04:47:44,350] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4000, global step 63994: loss 9.5615
[2019-03-24 04:47:44,351] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4000, global step 63994: learning rate 0.0000
[2019-03-24 04:47:44,414] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4000, global step 64021: loss 5.7334
[2019-03-24 04:47:44,417] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4000, global step 64023: learning rate 0.0000
[2019-03-24 04:47:44,466] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4000, global step 64055: loss 6.1764
[2019-03-24 04:47:44,470] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4000, global step 64055: learning rate 0.0000
[2019-03-24 04:47:44,516] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4000, global step 64076: loss 13.9867
[2019-03-24 04:47:44,520] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4000, global step 64077: learning rate 0.0000
[2019-03-24 04:47:44,541] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4000, global step 64086: loss 5.7475
[2019-03-24 04:47:44,542] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4000, global step 64086: learning rate 0.0000
[2019-03-24 04:47:44,755] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4000, global step 64201: loss 4.7934
[2019-03-24 04:47:44,756] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4000, global step 64201: learning rate 0.0000
[2019-03-24 04:47:44,766] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4000, global step 64207: loss 15.9350
[2019-03-24 04:47:44,767] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4000, global step 64207: learning rate 0.0000
[2019-03-24 04:47:44,824] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4000, global step 64236: loss 5.4059
[2019-03-24 04:47:44,825] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4000, global step 64236: learning rate 0.0000
[2019-03-24 04:47:56,293] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9999964e-01 7.3527632e-20 4.0706735e-07 8.1524114e-19 1.5650380e-11], sum to 1.0000
[2019-03-24 04:47:56,298] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3290
[2019-03-24 04:47:56,304] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.2, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7393415045845095, 6.9112, 6.9112, 121.9260426156618, 552208.2167029851, 552208.2167029851, 150417.5943619242], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2620800.0000, 
sim time next is 2621400.0000, 
raw observation next is [21.33333333333334, 93.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7421374555607081, 6.9112, 6.9112, 121.9260426156618, 554212.8298835364, 554212.8298835364, 150893.0370739358], 
processed observation next is [0.0, 0.34782608695652173, 0.3456790123456792, 0.9316666666666668, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6776718194508852, 0.0, 0.0, 0.8094621288201359, 0.19793315352983445, 0.19793315352983445, 0.2901789174498765], 
reward next is 0.7098, 
noisyNet noise sample is [array([1.4072665], dtype=float32), -0.99732]. 
=============================================
[2019-03-24 04:47:56,590] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9998426e-01 2.7750225e-17 1.5691405e-05 2.2216596e-17 1.5923760e-10], sum to 1.0000
[2019-03-24 04:47:56,596] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1708
[2019-03-24 04:47:56,599] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.5, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8234041449486944, 6.911200000000001, 6.9112, 121.9260426156618, 610414.210572402, 610414.2105724015, 163798.9019511378], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2631600.0000, 
sim time next is 2632200.0000, 
raw observation next is [23.75, 84.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8271163499521562, 6.911199999999999, 6.9112, 121.9260426156618, 612785.6027734432, 612785.6027734437, 164411.9422394065], 
processed observation next is [0.0, 0.4782608695652174, 0.4351851851851852, 0.8466666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7838954374401952, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21885200099051544, 0.2188520009905156, 0.3161768119988586], 
reward next is 0.6838, 
noisyNet noise sample is [array([-1.4172543], dtype=float32), 0.92116106]. 
=============================================
[2019-03-24 04:47:59,524] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4500, global step 71713: loss 0.1014
[2019-03-24 04:47:59,526] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4500, global step 71715: learning rate 0.0000
[2019-03-24 04:47:59,596] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4500, global step 71752: loss 0.0838
[2019-03-24 04:47:59,597] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4500, global step 71752: learning rate 0.0000
[2019-03-24 04:47:59,601] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4500, global step 71752: loss 0.1479
[2019-03-24 04:47:59,601] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4500, global step 71752: learning rate 0.0000
[2019-03-24 04:47:59,650] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4500, global step 71779: loss 0.1351
[2019-03-24 04:47:59,654] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4500, global step 71779: learning rate 0.0000
[2019-03-24 04:47:59,781] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4500, global step 71845: loss 0.0692
[2019-03-24 04:47:59,783] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4500, global step 71845: learning rate 0.0000
[2019-03-24 04:47:59,976] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4500, global step 71939: loss 0.0174
[2019-03-24 04:47:59,977] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4500, global step 71939: learning rate 0.0000
[2019-03-24 04:48:00,025] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4500, global step 71962: loss 0.0163
[2019-03-24 04:48:00,026] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4500, global step 71963: learning rate 0.0000
[2019-03-24 04:48:00,096] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4500, global step 72000: loss 0.0168
[2019-03-24 04:48:00,097] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4500, global step 72000: learning rate 0.0000
[2019-03-24 04:48:00,130] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4500, global step 72016: loss 0.0376
[2019-03-24 04:48:00,134] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4500, global step 72017: learning rate 0.0000
[2019-03-24 04:48:00,175] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4500, global step 72037: loss 0.0654
[2019-03-24 04:48:00,178] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4500, global step 72037: learning rate 0.0000
[2019-03-24 04:48:00,180] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4500, global step 72038: loss 0.0278
[2019-03-24 04:48:00,183] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4500, global step 72038: learning rate 0.0000
[2019-03-24 04:48:00,278] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4500, global step 72088: loss 0.0271
[2019-03-24 04:48:00,283] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4500, global step 72089: learning rate 0.0000
[2019-03-24 04:48:00,306] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4500, global step 72100: loss 0.0278
[2019-03-24 04:48:00,309] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4500, global step 72101: learning rate 0.0000
[2019-03-24 04:48:00,552] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4500, global step 72224: loss 0.0158
[2019-03-24 04:48:00,552] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4500, global step 72224: learning rate 0.0000
[2019-03-24 04:48:00,567] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4500, global step 72229: loss 0.0757
[2019-03-24 04:48:00,569] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4500, global step 72230: learning rate 0.0000
[2019-03-24 04:48:00,831] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4500, global step 72367: loss 0.0237
[2019-03-24 04:48:00,832] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4500, global step 72367: learning rate 0.0000
[2019-03-24 04:48:04,596] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.9204296e-01 2.1240897e-10 7.9567851e-03 3.6460962e-10 2.1692199e-07], sum to 1.0000
[2019-03-24 04:48:04,602] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9813
[2019-03-24 04:48:04,613] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 872321.4364184964 W.
[2019-03-24 04:48:04,620] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.0, 94.0, 1.0, 2.0, 0.3826734921579277, 0.0, 1.0, 0.0, 1.0, 2.0, 0.6092286623209867, 6.9112, 6.9112, 121.9260426156618, 872321.4364184964, 872321.4364184964, 218811.245575503], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2778600.0000, 
sim time next is 2779200.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.2496197822548726, 1.0, 1.0, 0.2496197822548726, 1.0, 2.0, 0.3974028228985119, 6.9112, 6.9112, 121.94756008, 853518.7329518218, 853518.7329518218, 237490.6646777563], 
processed observation next is [1.0, 0.17391304347826086, 0.4444444444444444, 0.94, 1.0, 1.0, 0.10669021697008643, 1.0, 0.5, 0.10669021697008643, 1.0, 1.0, 0.24675352862313987, 0.0, 0.0, 0.8096049824067558, 0.3048281189113649, 0.3048281189113649, 0.45671281668799285], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2745379], dtype=float32), 1.8471987]. 
=============================================
[2019-03-24 04:48:05,676] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.5587612e-01 5.5183818e-08 2.4397828e-01 1.2376425e-07 1.4547011e-04], sum to 1.0000
[2019-03-24 04:48:05,681] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8191
[2019-03-24 04:48:05,685] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.1, 61.66666666666666, 1.0, 2.0, 0.8294577419320867, 1.0, 2.0, 0.8294577419320867, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426155695, 1891989.438401789, 1891989.438401788, 356078.4173547011], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2812200.0000, 
sim time next is 2812800.0000, 
raw observation next is [32.2, 60.33333333333334, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 8.049621729246399, 6.9112, 121.9218573620104, 2461643.397239201, 1878689.732137032, 380043.5765887281], 
processed observation next is [1.0, 0.5652173913043478, 0.7481481481481482, 0.6033333333333334, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, 0.11384217292463986, 0.0, 0.8094343430882477, 0.8791583561568574, 0.6709606186203686, 0.7308530319014003], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.8585792], dtype=float32), 0.9269291]. 
=============================================
[2019-03-24 04:48:06,124] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-24 04:48:06,125] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:48:06,126] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:48:06,127] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:48:06,129] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:48:06,129] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:48:06,130] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:48:06,130] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:48:06,131] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:48:06,132] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:48:06,132] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:48:06,145] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run4
[2019-03-24 04:48:06,173] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run4
[2019-03-24 04:48:06,195] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run4
[2019-03-24 04:48:06,199] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run4
[2019-03-24 04:48:06,219] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run4
[2019-03-24 04:48:16,046] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00423779], dtype=float32), 0.0067613507]
[2019-03-24 04:48:16,047] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.17100053, 53.78031212666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6416992903535547, 6.9112, 6.9112, 121.9260426156618, 479096.168016032, 479096.168016032, 137131.1557456606]
[2019-03-24 04:48:16,049] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:48:16,051] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.8970830e-01 3.0081609e-10 1.0290385e-02 1.1750619e-10 1.3036082e-06], sampled 0.23755165824861446
[2019-03-24 04:48:21,917] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00423779], dtype=float32), 0.0067613507]
[2019-03-24 04:48:21,920] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.5, 43.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5369604749125293, 6.9112, 6.9112, 121.9260426156618, 391392.2320867009, 391392.2320867009, 120886.8023701558]
[2019-03-24 04:48:21,920] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:48:21,924] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.93773282e-01 3.65377069e-11 6.22638967e-03 1.27658535e-11
 3.43739288e-07], sampled 0.36868433467365
[2019-03-24 04:48:27,224] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00423779], dtype=float32), 0.0067613507]
[2019-03-24 04:48:27,226] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.02895126, 38.11921450333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5582390008158827, 6.911200000000001, 6.9112, 121.9260426156618, 412539.054126378, 412539.0541263776, 125369.7547265127]
[2019-03-24 04:48:27,227] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:48:27,229] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.9330115e-01 5.3442327e-11 6.6984203e-03 1.8846348e-11 4.3375238e-07], sampled 0.5892961549843628
[2019-03-24 04:48:42,245] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00423779], dtype=float32), 0.0067613507]
[2019-03-24 04:48:42,246] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.95, 95.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7380817990937999, 6.911199999999999, 6.9112, 121.9260426156618, 551224.5205304349, 551224.5205304354, 150352.6612278192]
[2019-03-24 04:48:42,248] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 04:48:42,252] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.9496859e-01 1.4239008e-11 5.0312164e-03 4.7627527e-12 1.8912044e-07], sampled 0.8555423817442013
[2019-03-24 04:48:44,153] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00423779], dtype=float32), 0.0067613507]
[2019-03-24 04:48:44,155] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.73843815666667, 51.69439222833333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6534182669667347, 6.9112, 6.9112, 121.9260426156618, 487973.4380627929, 487973.4380627929, 138568.8220127212]
[2019-03-24 04:48:44,155] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:48:44,156] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.9427009e-01 2.5614641e-11 5.7297181e-03 8.7944261e-12 2.7379946e-07], sampled 0.12823273880459063
[2019-03-24 04:49:00,333] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00423779], dtype=float32), 0.0067613507]
[2019-03-24 04:49:00,335] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.00086899, 89.63545110833334, 1.0, 2.0, 0.8201420315798446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 934813.4139300073, 934813.4139300073, 200139.9799089111]
[2019-03-24 04:49:00,336] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:49:00,339] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.7953004e-01 9.4516315e-09 2.0458972e-02 4.1262620e-09 1.0952626e-05], sampled 0.7769121667637959
[2019-03-24 04:49:00,341] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 934813.4139300073 W.
[2019-03-24 04:49:32,502] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00423779], dtype=float32), 0.0067613507]
[2019-03-24 04:49:32,503] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8529261670979932, 6.9112, 6.9112, 121.9260426156618, 627972.7275296398, 627972.7275296398, 168912.4244288526]
[2019-03-24 04:49:32,504] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:49:32,507] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.9485576e-01 1.3632424e-11 5.1439810e-03 4.5605108e-12 1.8701181e-07], sampled 0.5862492757332585
[2019-03-24 04:49:41,155] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00423779], dtype=float32), 0.0067613507]
[2019-03-24 04:49:41,156] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.66666666666667, 67.33333333333333, 1.0, 2.0, 0.6090070923916621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 694048.8539731909, 694048.8539731909, 159633.4261941095]
[2019-03-24 04:49:41,156] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:49:41,158] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.8908257e-01 5.4640414e-10 1.0915607e-02 2.0903337e-10 1.8311188e-06], sampled 0.5807210579133422
[2019-03-24 04:49:41,159] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 694048.8539731909 W.
[2019-03-24 04:49:51,366] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7748.6073 2533659101.5800 822.0000
[2019-03-24 04:49:51,598] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8510.8297 2223885974.3285 537.0000
[2019-03-24 04:49:51,727] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8457.2512 2262465434.5047 527.0000
[2019-03-24 04:49:51,782] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8291.7604 2297088605.4639 688.0000
[2019-03-24 04:49:51,867] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8262.5916 2343291494.0312 609.0000
[2019-03-24 04:49:52,881] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 75000, evaluation results [75000.0, 7748.60728037525, 2533659101.579982, 822.0, 8457.251222139574, 2262465434.5047307, 527.0, 8510.82970195204, 2223885974.3284802, 537.0, 8262.591606330287, 2343291494.0311513, 609.0, 8291.760409528788, 2297088605.4639044, 688.0]
[2019-03-24 04:50:01,898] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5000, global step 79688: loss 7.7628
[2019-03-24 04:50:01,900] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5000, global step 79688: learning rate 0.0000
[2019-03-24 04:50:02,221] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5000, global step 79786: loss 3.1496
[2019-03-24 04:50:02,228] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5000, global step 79788: learning rate 0.0000
[2019-03-24 04:50:02,449] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5000, global step 79836: loss 9.1646
[2019-03-24 04:50:02,451] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5000, global step 79837: learning rate 0.0000
[2019-03-24 04:50:02,609] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5000, global step 79852: loss 9.4884
[2019-03-24 04:50:02,611] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5000, global step 79852: learning rate 0.0000
[2019-03-24 04:50:02,815] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5000, global step 79894: loss 5.3747
[2019-03-24 04:50:02,816] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5000, global step 79894: learning rate 0.0000
[2019-03-24 04:50:02,966] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5000, global step 79909: loss 2.8955
[2019-03-24 04:50:02,972] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5000, global step 79910: learning rate 0.0000
[2019-03-24 04:50:02,975] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5000, global step 79912: loss 12.5440
[2019-03-24 04:50:03,110] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5000, global step 79913: learning rate 0.0000
[2019-03-24 04:50:03,125] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5000, global step 79925: loss 1.3373
[2019-03-24 04:50:03,254] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5000, global step 79925: learning rate 0.0000
[2019-03-24 04:50:03,462] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5000, global step 79956: loss 19.6436
[2019-03-24 04:50:03,466] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5000, global step 79959: learning rate 0.0000
[2019-03-24 04:50:03,753] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5000, global step 80042: loss 3.4104
[2019-03-24 04:50:03,755] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5000, global step 80042: learning rate 0.0000
[2019-03-24 04:50:03,923] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5000, global step 80068: loss 12.2420
[2019-03-24 04:50:03,924] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5000, global step 80069: loss 7.5919
[2019-03-24 04:50:03,932] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5000, global step 80070: learning rate 0.0000
[2019-03-24 04:50:03,932] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5000, global step 80070: learning rate 0.0000
[2019-03-24 04:50:04,234] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5000, global step 80089: loss 10.7677
[2019-03-24 04:50:04,237] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5000, global step 80090: learning rate 0.0000
[2019-03-24 04:50:04,402] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5000, global step 80108: loss 3.1175
[2019-03-24 04:50:04,405] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5000, global step 80109: learning rate 0.0000
[2019-03-24 04:50:04,703] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5000, global step 80203: loss -60.9665
[2019-03-24 04:50:04,706] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5000, global step 80204: learning rate 0.0000
[2019-03-24 04:50:05,206] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5000, global step 80396: loss -47.9283
[2019-03-24 04:50:05,207] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5000, global step 80396: learning rate 0.0000
[2019-03-24 04:50:08,934] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1631548e-01 1.8364215e-11 8.8368446e-01 7.9541018e-13 1.4261207e-07], sum to 1.0000
[2019-03-24 04:50:08,946] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1073
[2019-03-24 04:50:08,954] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 832124.1000003926 W.
[2019-03-24 04:50:08,957] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.8, 82.33333333333334, 1.0, 2.0, 0.3650491297623889, 1.0, 1.0, 0.3650491297623889, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 832124.1000003926, 832124.1000003926, 196805.4140521891], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3086400.0000, 
sim time next is 3087000.0000, 
raw observation next is [29.1, 80.5, 1.0, 2.0, 0.2418763579062504, 1.0, 2.0, 0.2418763579062504, 1.0, 1.0, 0.3850750391497803, 6.911200000000001, 6.9112, 121.94756008, 827027.5515910961, 827027.5515910956, 234763.3106601801], 
processed observation next is [1.0, 0.7391304347826086, 0.6333333333333334, 0.805, 1.0, 1.0, 0.09747185465029809, 1.0, 1.0, 0.09747185465029809, 1.0, 0.5, 0.23134379893722537, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.29536698271110573, 0.29536698271110556, 0.451467905115731], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6396294], dtype=float32), 1.3226817]. 
=============================================
[2019-03-24 04:50:08,976] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[35.229713]
 [36.062115]
 [34.13847 ]
 [34.272083]
 [34.264015]], R is [[34.98622894]
 [35.25789642]
 [35.44444656]
 [35.39776993]
 [35.04379272]].
[2019-03-24 04:50:09,922] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.1933491e-01 3.1452067e-16 4.8066506e-01 7.7484311e-17 5.5359789e-10], sum to 1.0000
[2019-03-24 04:50:09,929] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1028
[2019-03-24 04:50:09,937] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 715176.2322249389 W.
[2019-03-24 04:50:10,107] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 63.33333333333334, 1.0, 2.0, 0.3137685452755852, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4995297428068446, 6.911199999999999, 6.9112, 121.9260426156618, 715176.2322249389, 715176.2322249394, 198980.602415741], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3100800.0000, 
sim time next is 3101400.0000, 
raw observation next is [29.0, 62.0, 1.0, 2.0, 0.6088226659054361, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 700300.4287062406, 700300.4287062406, 159917.7601893683], 
processed observation next is [1.0, 0.9130434782608695, 0.6296296296296297, 0.62, 1.0, 1.0, 0.5343126975064715, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2501072959665145, 0.2501072959665145, 0.30753415421032365], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.59383035], dtype=float32), 1.0416106]. 
=============================================
[2019-03-24 04:50:18,809] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.99884248e-01 3.85988158e-18 1.15773306e-04 9.05729348e-22
 2.62304437e-14], sum to 1.0000
[2019-03-24 04:50:18,818] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9442
[2019-03-24 04:50:18,830] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 696652.1463172544 W.
[2019-03-24 04:50:18,833] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 86.5, 1.0, 2.0, 0.2037634716630488, 1.0, 1.0, 0.2037634716630488, 1.0, 2.0, 0.3243980830005546, 6.911199999999999, 6.9112, 121.94756008, 696652.1463172544, 696652.1463172549, 221827.8986888637], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3274200.0000, 
sim time next is 3274800.0000, 
raw observation next is [24.66666666666667, 89.0, 1.0, 2.0, 0.3060940136105501, 1.0, 2.0, 0.3060940136105501, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 697675.6242316364, 697675.6242316369, 181929.3313216919], 
processed observation next is [0.0, 0.9130434782608695, 0.469135802469136, 0.89, 1.0, 1.0, 0.17392144477446442, 1.0, 1.0, 0.17392144477446442, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.249169865797013, 0.24916986579701317, 0.34986409869556134], 
reward next is 0.6501, 
noisyNet noise sample is [array([-0.91902304], dtype=float32), -0.7338923]. 
=============================================
[2019-03-24 04:50:19,061] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5500, global step 87461: loss 0.0299
[2019-03-24 04:50:19,062] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5500, global step 87461: learning rate 0.0000
[2019-03-24 04:50:19,409] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5500, global step 87646: loss 0.0608
[2019-03-24 04:50:19,411] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5500, global step 87646: learning rate 0.0000
[2019-03-24 04:50:19,760] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5500, global step 87826: loss 0.0488
[2019-03-24 04:50:19,763] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5500, global step 87827: learning rate 0.0000
[2019-03-24 04:50:19,790] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5500, global step 87844: loss 0.0439
[2019-03-24 04:50:19,793] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5500, global step 87845: learning rate 0.0000
[2019-03-24 04:50:19,807] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5500, global step 87852: loss 0.0291
[2019-03-24 04:50:19,810] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5500, global step 87853: learning rate 0.0000
[2019-03-24 04:50:19,989] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5500, global step 87943: loss 0.0110
[2019-03-24 04:50:19,993] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5500, global step 87945: learning rate 0.0000
[2019-03-24 04:50:20,065] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5500, global step 87984: loss 0.0242
[2019-03-24 04:50:20,067] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5500, global step 87985: loss 0.0220
[2019-03-24 04:50:20,068] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5500, global step 87985: learning rate 0.0000
[2019-03-24 04:50:20,069] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5500, global step 87985: learning rate 0.0000
[2019-03-24 04:50:20,087] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5500, global step 87996: loss 0.0294
[2019-03-24 04:50:20,092] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5500, global step 87996: learning rate 0.0000
[2019-03-24 04:50:20,154] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5500, global step 88025: loss 0.0911
[2019-03-24 04:50:20,159] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5500, global step 88027: learning rate 0.0000
[2019-03-24 04:50:20,209] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5500, global step 88058: loss 0.1948
[2019-03-24 04:50:20,211] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5500, global step 88058: learning rate 0.0000
[2019-03-24 04:50:20,262] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5500, global step 88083: loss 0.0186
[2019-03-24 04:50:20,265] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5500, global step 88083: learning rate 0.0000
[2019-03-24 04:50:20,509] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5500, global step 88211: loss 0.0126
[2019-03-24 04:50:20,514] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5500, global step 88212: learning rate 0.0000
[2019-03-24 04:50:20,515] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5500, global step 88212: loss 0.0104
[2019-03-24 04:50:20,519] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5500, global step 88213: learning rate 0.0000
[2019-03-24 04:50:20,555] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5500, global step 88233: loss 0.0486
[2019-03-24 04:50:20,556] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5500, global step 88233: learning rate 0.0000
[2019-03-24 04:50:20,979] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5500, global step 88454: loss 0.0076
[2019-03-24 04:50:20,982] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5500, global step 88454: learning rate 0.0000
[2019-03-24 04:50:25,480] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.9656343e-02 1.7951855e-11 9.7034353e-01 7.8245917e-13 6.6221062e-08], sum to 1.0000
[2019-03-24 04:50:25,485] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8062
[2019-03-24 04:50:25,493] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 2 has been changed to 4 for the demand 2115694.451212338 W.
[2019-03-24 04:50:25,670] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.75, 65.66666666666667, 1.0, 2.0, 0.9274151141008373, 1.0, 2.0, 0.9274151141008373, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2115694.451212338, 2115694.451212339, 399217.1519327596], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3409800.0000, 
sim time next is 3410400.0000, 
raw observation next is [30.0, 64.33333333333334, 1.0, 2.0, 0.59673561636542, 1.0, 2.0, 0.59673561636542, 1.0, 1.0, 0.950022535575993, 6.9112, 6.9112, 121.94756008, 2041897.718404749, 2041897.718404749, 393599.8582390898], 
processed observation next is [1.0, 0.4782608695652174, 0.6666666666666666, 0.6433333333333334, 1.0, 1.0, 0.5199233528159762, 1.0, 1.0, 0.5199233528159762, 1.0, 0.5, 0.9375281694699913, 0.0, 0.0, 0.8096049824067558, 0.7292491851445532, 0.7292491851445532, 0.7569228043059418], 
reward next is 0.2431, 
noisyNet noise sample is [array([2.5058818], dtype=float32), 2.063508]. 
=============================================
[2019-03-24 04:50:26,199] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.3041037e-02 2.2103689e-11 9.2695898e-01 8.1661327e-13 2.3057781e-08], sum to 1.0000
[2019-03-24 04:50:26,204] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5595
[2019-03-24 04:50:26,209] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 2 has been changed to 4 for the demand 2000343.193941684 W.
[2019-03-24 04:50:26,214] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.5, 59.83333333333333, 1.0, 2.0, 0.5846050734576054, 1.0, 2.0, 0.5846050734576054, 1.0, 1.0, 0.9307103162025504, 6.911200000000001, 6.9112, 121.94756008, 2000343.193941684, 2000343.193941684, 387051.4667907222], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3420600.0000, 
sim time next is 3421200.0000, 
raw observation next is [30.8, 59.66666666666667, 1.0, 2.0, 0.5965103072207847, 1.0, 2.0, 0.5965103072207847, 1.0, 2.0, 0.949663836079927, 6.911200000000001, 6.9112, 121.94756008, 2041125.879238823, 2041125.879238822, 393477.5078503782], 
processed observation next is [1.0, 0.6086956521739131, 0.6962962962962963, 0.5966666666666667, 1.0, 1.0, 0.5196551276437913, 1.0, 1.0, 0.5196551276437913, 1.0, 1.0, 0.9370797950999088, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7289735282995796, 0.7289735282995793, 0.7566875150968813], 
reward next is 0.2433, 
noisyNet noise sample is [array([-0.14827295], dtype=float32), -0.7549887]. 
=============================================
[2019-03-24 04:50:27,331] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.52487932e-02 1.20703355e-14 9.44751143e-01 7.66210503e-15
 2.01958694e-09], sum to 1.0000
[2019-03-24 04:50:27,339] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6190
[2019-03-24 04:50:27,343] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.45, 78.5, 1.0, 2.0, 0.3415709598758103, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5437920923118331, 6.9112, 6.9112, 121.9260426156618, 778578.7767991646, 778578.7767991646, 206755.6520987406], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3439800.0000, 
sim time next is 3440400.0000, 
raw observation next is [27.26666666666667, 78.33333333333334, 1.0, 2.0, 0.3366126403905184, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5358982862100563, 6.911199999999999, 6.9112, 121.9260426156618, 767271.0986843529, 767271.0986843534, 205346.2584182722], 
processed observation next is [1.0, 0.8260869565217391, 0.5654320987654322, 0.7833333333333334, 1.0, 1.0, 0.21025314332204573, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.41987285776257033, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2740253923872689, 0.2740253923872691, 0.3948966508043696], 
reward next is 0.6051, 
noisyNet noise sample is [array([-0.13587438], dtype=float32), -0.32582155]. 
=============================================
[2019-03-24 04:50:33,643] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.6561251e-01 3.2337885e-14 7.3438752e-01 1.3082374e-17 1.8663348e-12], sum to 1.0000
[2019-03-24 04:50:33,652] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7405
[2019-03-24 04:50:33,661] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.53333333333333, 92.33333333333333, 1.0, 2.0, 0.2753563075252768, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4419306287140855, 6.9112, 6.9112, 121.9260426156618, 652482.8226426454, 652482.8226426454, 187935.1220252479], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3552000.0000, 
sim time next is 3552600.0000, 
raw observation next is [22.26666666666667, 96.16666666666667, 1.0, 2.0, 0.2775556278244817, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4448084240777627, 6.911199999999999, 6.9112, 121.9260426156618, 655155.4545426702, 655155.4545426706, 188627.2463391582], 
processed observation next is [1.0, 0.08695652173913043, 0.38024691358024704, 0.9616666666666667, 1.0, 1.0, 0.1399471759815258, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.30601053009720336, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2339840909080965, 0.23398409090809666, 0.3627447044983812], 
reward next is 0.6373, 
noisyNet noise sample is [array([-0.41302902], dtype=float32), 0.46431303]. 
=============================================
[2019-03-24 04:50:34,032] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.7086532e-01 4.2617171e-15 6.2913465e-01 9.6028506e-18 1.9157540e-12], sum to 1.0000
[2019-03-24 04:50:34,039] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1875
[2019-03-24 04:50:34,043] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.26666666666667, 96.16666666666667, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8858617180809727, 6.9112, 6.9112, 121.9260426156618, 655155.4559327817, 655155.4559327817, 172264.3255789564], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3552600.0000, 
sim time next is 3553200.0000, 
raw observation next is [22.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8910217756731048, 6.9112, 6.9112, 121.9260426156618, 658815.4632077446, 658815.4632077446, 172987.9963943582], 
processed observation next is [1.0, 0.13043478260869565, 0.37037037037037035, 1.0, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8637772195913809, 0.0, 0.0, 0.8094621288201359, 0.2352912368599088, 0.2352912368599088, 0.33266922383530423], 
reward next is 0.6673, 
noisyNet noise sample is [array([0.8945259], dtype=float32), -0.093318574]. 
=============================================
[2019-03-24 04:50:34,988] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6000, global step 95470: loss -52.9573
[2019-03-24 04:50:34,991] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6000, global step 95471: learning rate 0.0000
[2019-03-24 04:50:35,485] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6000, global step 95713: loss -2.8327
[2019-03-24 04:50:35,488] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6000, global step 95713: learning rate 0.0000
[2019-03-24 04:50:35,499] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6000, global step 95720: loss -7.0410
[2019-03-24 04:50:35,501] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6000, global step 95721: learning rate 0.0000
[2019-03-24 04:50:35,820] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6000, global step 95875: loss 10.7673
[2019-03-24 04:50:35,822] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6000, global step 95876: learning rate 0.0000
[2019-03-24 04:50:35,915] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6000, global step 95917: loss 12.9417
[2019-03-24 04:50:35,915] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6000, global step 95917: learning rate 0.0000
[2019-03-24 04:50:36,009] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6000, global step 95968: loss 0.8645
[2019-03-24 04:50:36,015] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6000, global step 95968: learning rate 0.0000
[2019-03-24 04:50:36,047] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6000, global step 95983: loss -46.5493
[2019-03-24 04:50:36,049] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6000, global step 95984: learning rate 0.0000
[2019-03-24 04:50:36,202] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6000, global step 96062: loss 10.2509
[2019-03-24 04:50:36,208] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6000, global step 96062: learning rate 0.0000
[2019-03-24 04:50:36,218] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6000, global step 96065: loss 27.5149
[2019-03-24 04:50:36,219] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6000, global step 96066: learning rate 0.0000
[2019-03-24 04:50:36,237] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6000, global step 96074: loss -50.6272
[2019-03-24 04:50:36,237] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6000, global step 96074: loss -42.7313
[2019-03-24 04:50:36,240] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6000, global step 96074: learning rate 0.0000
[2019-03-24 04:50:36,243] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6000, global step 96074: learning rate 0.0000
[2019-03-24 04:50:36,273] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6000, global step 96090: loss -8.3024
[2019-03-24 04:50:36,275] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6000, global step 96090: learning rate 0.0000
[2019-03-24 04:50:36,291] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6000, global step 96098: loss 14.3803
[2019-03-24 04:50:36,297] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6000, global step 96099: learning rate 0.0000
[2019-03-24 04:50:36,327] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6000, global step 96120: loss -99.0475
[2019-03-24 04:50:36,330] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6000, global step 96121: learning rate 0.0000
[2019-03-24 04:50:36,527] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6000, global step 96215: loss -105.8340
[2019-03-24 04:50:36,528] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6000, global step 96215: learning rate 0.0000
[2019-03-24 04:50:37,132] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6000, global step 96520: loss -18.9637
[2019-03-24 04:50:37,137] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6000, global step 96522: learning rate 0.0000
[2019-03-24 04:50:37,301] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.1387314e-01 2.3050745e-19 8.6126834e-02 4.4193639e-19 3.1954395e-13], sum to 1.0000
[2019-03-24 04:50:37,307] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6941
[2019-03-24 04:50:37,312] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.5, 94.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9023106666893111, 6.911200000000001, 6.9112, 121.9260426156618, 659498.7813577596, 659498.7813577591, 176422.440368675], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3619800.0000, 
sim time next is 3620400.0000, 
raw observation next is [23.33333333333333, 96.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9131790264910875, 6.911200000000001, 6.9112, 121.9260426156618, 666760.5378339073, 666760.5378339068, 178005.8491668568], 
processed observation next is [1.0, 0.9130434782608695, 0.4197530864197529, 0.9633333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8914737831138594, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23812876351210974, 0.23812876351210957, 0.34231894070549385], 
reward next is 0.6577, 
noisyNet noise sample is [array([-0.921631], dtype=float32), -0.72668976]. 
=============================================
[2019-03-24 04:50:44,169] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-24 04:50:44,170] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:50:44,171] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:50:44,171] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:50:44,172] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:50:44,173] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:50:44,173] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:50:44,174] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:50:44,174] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:50:44,176] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:50:44,179] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:50:44,189] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run5
[2019-03-24 04:50:44,211] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run5
[2019-03-24 04:50:44,237] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run5
[2019-03-24 04:50:44,238] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run5
[2019-03-24 04:50:44,288] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run5
[2019-03-24 04:50:45,651] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00439223], dtype=float32), 0.006710694]
[2019-03-24 04:50:45,652] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.91666666666667, 38.16666666666666, 1.0, 2.0, 0.363523545821648, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6007713518931176, 6.911199999999999, 6.9112, 121.9260426156618, 897914.8041308036, 897914.804130804, 209846.1312717568]
[2019-03-24 04:50:45,652] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 04:50:45,656] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [8.3050422e-02 9.2592026e-15 9.1694963e-01 1.1777281e-15 2.4159297e-10], sampled 0.06961211823699587
[2019-03-24 04:50:45,658] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 897914.8041308036 W.
[2019-03-24 04:51:26,093] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00439223], dtype=float32), 0.006710694]
[2019-03-24 04:51:26,095] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.0, 89.0, 1.0, 2.0, 0.8818773081525892, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426156618, 1720397.436259245, 1720397.436259245, 353080.5560303149]
[2019-03-24 04:51:26,096] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 04:51:26,099] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [6.6800319e-02 2.1792438e-15 9.3319964e-01 2.6604254e-16 9.1903547e-11], sampled 0.8619084728608664
[2019-03-24 04:51:28,928] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00439223], dtype=float32), 0.006710694]
[2019-03-24 04:51:28,928] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.0, 58.5, 1.0, 2.0, 0.3250873024688936, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5175495728847783, 6.911199999999999, 6.9112, 121.9260426156618, 740987.6742009863, 740987.6742009867, 202109.8277492691]
[2019-03-24 04:51:28,932] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:51:28,937] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [6.4297706e-02 1.2343374e-16 9.3570232e-01 1.1876254e-17 1.2607618e-11], sampled 0.5199019612497064
[2019-03-24 04:51:53,662] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00439223], dtype=float32), 0.006710694]
[2019-03-24 04:51:53,663] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.0, 74.0, 1.0, 2.0, 0.2715206560997476, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4335882263550985, 6.911199999999999, 6.9112, 121.9260426156618, 633147.9749682565, 633147.974968257, 187397.6708060922]
[2019-03-24 04:51:53,664] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:51:53,667] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [8.1051141e-02 8.6843509e-16 9.1894883e-01 9.0721735e-17 4.7857499e-11], sampled 0.46424885463899046
[2019-03-24 04:52:29,889] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 6496.4002 2574221761.4268 114.0000
[2019-03-24 04:52:30,036] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 7077.3569 2540149423.5232 89.0000
[2019-03-24 04:52:30,057] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 6772.7368 2598197001.5294 169.0000
[2019-03-24 04:52:30,081] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 6811.3940 2809312321.1800 269.0000
[2019-03-24 04:52:30,154] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 6320.6534 2637514057.5603 137.0000
[2019-03-24 04:52:31,170] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 100000, evaluation results [100000.0, 6811.393972488135, 2809312321.1799536, 269.0, 6496.400197702423, 2574221761.426826, 114.0, 7077.356858017928, 2540149423.523212, 89.0, 6320.653437232352, 2637514057.5602894, 137.0, 6772.736827775844, 2598197001.529365, 169.0]
[2019-03-24 04:52:32,411] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.0029089e-01 9.2568375e-10 7.9970556e-01 3.9622090e-11 3.5014045e-06], sum to 1.0000
[2019-03-24 04:52:32,416] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7375
[2019-03-24 04:52:32,422] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 2 has been changed to 3 for the demand 2223488.749257802 W.
[2019-03-24 04:52:32,426] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [35.0, 42.0, 1.0, 2.0, 0.6727483015575602, 1.0, 2.0, 0.649738812755215, 1.0, 1.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2223488.749257802, 2223488.749257802, 421997.3576885232], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3772800.0000, 
sim time next is 3773400.0000, 
raw observation next is [34.56666666666667, 46.83333333333333, 1.0, 2.0, 0.9232099781054265, 1.0, 2.0, 0.9232099781054265, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2106090.041037421, 2106090.041037422, 397297.3734948034], 
processed observation next is [1.0, 0.6956521739130435, 0.8358024691358026, 0.46833333333333327, 1.0, 1.0, 0.9085833072683649, 1.0, 1.0, 0.9085833072683649, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7521750146562218, 0.7521750146562222, 0.7640334105669295], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.4799891], dtype=float32), -0.093230784]. 
=============================================
[2019-03-24 04:52:35,526] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.1664350e-01 8.3318430e-14 8.3356455e-02 2.6094097e-17 2.0631889e-10], sum to 1.0000
[2019-03-24 04:52:35,537] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4941
[2019-03-24 04:52:35,540] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.16666666666667, 58.16666666666667, 1.0, 2.0, 0.283588193114521, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4522543760282015, 6.911199999999999, 6.9112, 121.9260426156618, 656939.894823, 656939.8948230004, 190660.9777979982], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3831000.0000, 
sim time next is 3831600.0000, 
raw observation next is [29.33333333333334, 58.33333333333334, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9110737308175171, 6.911200000000001, 6.9112, 121.9260426156618, 663608.8540287412, 663608.8540287408, 178007.7478651316], 
processed observation next is [0.0, 0.34782608695652173, 0.6419753086419755, 0.5833333333333335, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8888421635218963, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23700316215312187, 0.2370031621531217, 0.34232259204833], 
reward next is 0.6577, 
noisyNet noise sample is [array([-0.21829389], dtype=float32), -0.8774285]. 
=============================================
[2019-03-24 04:52:37,760] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6500, global step 103423: loss 0.1670
[2019-03-24 04:52:37,762] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6500, global step 103424: learning rate 0.0000
[2019-03-24 04:52:38,296] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6500, global step 103704: loss 0.6831
[2019-03-24 04:52:38,300] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6500, global step 103704: learning rate 0.0000
[2019-03-24 04:52:38,386] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6500, global step 103750: loss 0.2100
[2019-03-24 04:52:38,390] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6500, global step 103750: learning rate 0.0000
[2019-03-24 04:52:38,680] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6500, global step 103899: loss -268.5052
[2019-03-24 04:52:38,684] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6500, global step 103899: learning rate 0.0000
[2019-03-24 04:52:38,781] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6500, global step 103949: loss 1.7770
[2019-03-24 04:52:38,784] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6500, global step 103949: learning rate 0.0000
[2019-03-24 04:52:38,849] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6500, global step 103987: loss 0.3477
[2019-03-24 04:52:38,852] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6500, global step 103987: learning rate 0.0000
[2019-03-24 04:52:38,865] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6500, global step 103996: loss 0.0202
[2019-03-24 04:52:38,866] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6500, global step 103996: learning rate 0.0000
[2019-03-24 04:52:38,895] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6500, global step 104012: loss -88.6849
[2019-03-24 04:52:38,901] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6500, global step 104013: learning rate 0.0000
[2019-03-24 04:52:38,917] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6500, global step 104020: loss 0.8203
[2019-03-24 04:52:38,919] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6500, global step 104020: learning rate 0.0000
[2019-03-24 04:52:38,945] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6500, global step 104033: loss -29.0615
[2019-03-24 04:52:38,946] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6500, global step 104033: learning rate 0.0000
[2019-03-24 04:52:38,959] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6500, global step 104041: loss -103.1759
[2019-03-24 04:52:38,960] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6500, global step 104042: learning rate 0.0000
[2019-03-24 04:52:39,053] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6500, global step 104088: loss 0.0544
[2019-03-24 04:52:39,057] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6500, global step 104088: learning rate 0.0000
[2019-03-24 04:52:39,097] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6500, global step 104114: loss -62.1476
[2019-03-24 04:52:39,098] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6500, global step 104115: learning rate 0.0000
[2019-03-24 04:52:39,181] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6500, global step 104155: loss 1.4597
[2019-03-24 04:52:39,185] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6500, global step 104157: loss 0.0704
[2019-03-24 04:52:39,185] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6500, global step 104156: learning rate 0.0000
[2019-03-24 04:52:39,186] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6500, global step 104157: learning rate 0.0000
[2019-03-24 04:52:39,755] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6500, global step 104458: loss -26.5266
[2019-03-24 04:52:39,759] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6500, global step 104459: learning rate 0.0000
[2019-03-24 04:52:41,674] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.0043552e-01 5.3243933e-18 7.9956442e-01 1.5968061e-20 6.8958333e-12], sum to 1.0000
[2019-03-24 04:52:41,682] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1348
[2019-03-24 04:52:41,692] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 928656.3734865106 W.
[2019-03-24 04:52:41,695] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 0.4073717659373685, 0.0, 2.0, 0.0, 1.0, 1.0, 0.6485491185444777, 6.911199999999999, 6.9112, 121.9260426156618, 928656.3734865106, 928656.3734865111, 226393.0482711431], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3945600.0000, 
sim time next is 3946200.0000, 
raw observation next is [30.98333333333333, 69.0, 1.0, 2.0, 0.7889111893861713, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 899195.0249574006, 899195.0249574002, 193666.3595639783], 
processed observation next is [0.0, 0.6956521739130435, 0.7030864197530863, 0.69, 1.0, 1.0, 0.7487037968882992, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3211410803419288, 0.3211410803419286, 0.37243530685380444], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3386313], dtype=float32), 0.98794526]. 
=============================================
[2019-03-24 04:52:51,363] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.9982065e-01 3.6306090e-18 1.7938715e-04 3.0370505e-20 1.0973816e-13], sum to 1.0000
[2019-03-24 04:52:51,369] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5859
[2019-03-24 04:52:51,371] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.16666666666666, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7394642329662244, 6.911200000000001, 6.9112, 121.9260426156618, 552376.1558561234, 552376.155856123, 150272.1208538637], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4139400.0000, 
sim time next is 4140000.0000, 
raw observation next is [21.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7358536471271956, 6.9112, 6.9112, 121.9260426156618, 549727.6890730134, 549727.6890730134, 149738.9515290742], 
processed observation next is [1.0, 0.9565217391304348, 0.3333333333333333, 0.94, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6698170589089943, 0.0, 0.0, 0.8094621288201359, 0.19633131752607622, 0.19633131752607622, 0.28795952217129656], 
reward next is 0.7120, 
noisyNet noise sample is [array([0.18592393], dtype=float32), 0.895311]. 
=============================================
[2019-03-24 04:52:51,386] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[49.512268]
 [49.417393]
 [49.31968 ]
 [49.345142]
 [49.767864]], R is [[49.81216431]
 [50.02505875]
 [50.23506546]
 [50.44267654]
 [50.64775467]].
[2019-03-24 04:52:51,800] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9999976e-01 1.5288909e-20 2.8750591e-07 1.2475603e-25 1.0434183e-17], sum to 1.0000
[2019-03-24 04:52:51,807] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5440
[2019-03-24 04:52:51,813] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7454100301991899, 6.911200000000001, 6.9112, 121.9260426156618, 556480.3954353754, 556480.3954353749, 151543.9278321353], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4147200.0000, 
sim time next is 4147800.0000, 
raw observation next is [21.83333333333334, 89.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7406270800945249, 6.9112, 6.9112, 121.9260426156618, 553008.0292841583, 553008.0292841583, 150843.149507785], 
processed observation next is [1.0, 0.0, 0.36419753086419776, 0.8900000000000001, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6757838501181562, 0.0, 0.0, 0.8094621288201359, 0.19750286760148508, 0.19750286760148508, 0.2900829798226635], 
reward next is 0.7099, 
noisyNet noise sample is [array([-0.2318192], dtype=float32), -1.1091549]. 
=============================================
[2019-03-24 04:52:52,123] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9965417e-01 7.6305866e-19 3.4583002e-04 2.9281909e-21 3.9344904e-14], sum to 1.0000
[2019-03-24 04:52:52,131] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6403
[2019-03-24 04:52:52,138] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1346353.1191754 W.
[2019-03-24 04:52:52,141] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.53333333333333, 75.33333333333334, 1.0, 1.0, 0.580705986302159, 1.0, 1.0, 0.580705986302159, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.925583246394, 1346353.1191754, 1346353.1191754, 262537.158239917], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4177200.0000, 
sim time next is 4177800.0000, 
raw observation next is [25.9, 75.0, 1.0, 2.0, 0.416938028513406, 1.0, 2.0, 0.416938028513406, 1.0, 1.0, 0.6637789201169509, 6.911199999999998, 6.9112, 121.94756008, 1426158.255273852, 1426158.255273853, 304581.4034318088], 
processed observation next is [1.0, 0.34782608695652173, 0.5148148148148147, 0.75, 1.0, 1.0, 0.30587860537310235, 1.0, 1.0, 0.30587860537310235, 1.0, 0.5, 0.5797236501461887, -1.7763568394002506e-16, 0.0, 0.8096049824067558, 0.5093422340263757, 0.509342234026376, 0.5857334681380939], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.88639796], dtype=float32), -0.4165169]. 
=============================================
[2019-03-24 04:52:53,392] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7000, global step 111525: loss -78.6044
[2019-03-24 04:52:53,393] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7000, global step 111526: learning rate 0.0000
[2019-03-24 04:52:53,693] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7000, global step 111677: loss -81.5546
[2019-03-24 04:52:53,696] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7000, global step 111677: learning rate 0.0000
[2019-03-24 04:52:53,816] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7000, global step 111739: loss -129.7726
[2019-03-24 04:52:53,819] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7000, global step 111739: learning rate 0.0000
[2019-03-24 04:52:54,141] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7000, global step 111902: loss -91.2840
[2019-03-24 04:52:54,142] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7000, global step 111902: learning rate 0.0000
[2019-03-24 04:52:54,201] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7000, global step 111932: loss -111.7483
[2019-03-24 04:52:54,203] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7000, global step 111932: learning rate 0.0000
[2019-03-24 04:52:54,218] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7000, global step 111945: loss -123.8663
[2019-03-24 04:52:54,220] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7000, global step 111945: learning rate 0.0000
[2019-03-24 04:52:54,243] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7000, global step 111956: loss -73.1257
[2019-03-24 04:52:54,245] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7000, global step 111957: learning rate 0.0000
[2019-03-24 04:52:54,315] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7000, global step 111987: loss 43.7914
[2019-03-24 04:52:54,318] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7000, global step 111987: learning rate 0.0000
[2019-03-24 04:52:54,419] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7000, global step 112044: loss 23.3455
[2019-03-24 04:52:54,423] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7000, global step 112045: learning rate 0.0000
[2019-03-24 04:52:54,448] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7000, global step 112060: loss 53.3347
[2019-03-24 04:52:54,452] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7000, global step 112060: learning rate 0.0000
[2019-03-24 04:52:54,467] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7000, global step 112069: loss 2.1689
[2019-03-24 04:52:54,468] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7000, global step 112069: learning rate 0.0000
[2019-03-24 04:52:54,474] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7000, global step 112069: loss -40.7607
[2019-03-24 04:52:54,477] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7000, global step 112069: learning rate 0.0000
[2019-03-24 04:52:54,531] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7000, global step 112099: loss 6.2972
[2019-03-24 04:52:54,533] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7000, global step 112099: learning rate 0.0000
[2019-03-24 04:52:54,627] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7000, global step 112147: loss -31.2302
[2019-03-24 04:52:54,631] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7000, global step 112148: learning rate 0.0000
[2019-03-24 04:52:54,958] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7000, global step 112317: loss -53.6600
[2019-03-24 04:52:54,959] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7000, global step 112317: learning rate 0.0000
[2019-03-24 04:52:55,324] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7000, global step 112505: loss -73.3979
[2019-03-24 04:52:55,326] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7000, global step 112505: learning rate 0.0000
[2019-03-24 04:52:58,318] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9775344e-01 4.7598000e-14 2.2465161e-03 2.5436644e-17 1.0047883e-09], sum to 1.0000
[2019-03-24 04:52:58,324] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6679
[2019-03-24 04:52:58,330] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1391310.839011762 W.
[2019-03-24 04:52:58,336] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.0, 38.0, 1.0, 2.0, 0.5935917356464823, 1.0, 2.0, 0.5935917356464823, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1391310.839011762, 1391310.839011762, 267613.0320816986], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4278000.0000, 
sim time next is 4278600.0000, 
raw observation next is [32.0, 38.0, 1.0, 2.0, 0.5479818453452467, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8789882032892077, 6.911199999999999, 6.9112, 121.9260426156618, 1297196.290901313, 1297196.290901313, 273088.0943983324], 
processed observation next is [1.0, 0.5217391304347826, 0.7407407407407407, 0.38, 1.0, 1.0, 0.4618831492205318, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.8487352541115095, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4632843896076118, 0.4632843896076118, 0.5251694123044854], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.7795291], dtype=float32), 0.53723484]. 
=============================================
[2019-03-24 04:52:59,804] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9999928e-01 1.6856981e-19 7.7012396e-07 1.8989537e-23 7.0772779e-15], sum to 1.0000
[2019-03-24 04:52:59,809] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3805
[2019-03-24 04:52:59,998] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.75, 75.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8823458801160428, 6.911200000000001, 6.9112, 121.9260426156618, 649187.8237337559, 649187.8237337554, 172822.582068716], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4317000.0000, 
sim time next is 4317600.0000, 
raw observation next is [25.8, 77.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8986131731373952, 6.911200000000001, 6.9112, 121.9260426156618, 658612.8718541508, 658612.8718541503, 175558.8329295903], 
processed observation next is [1.0, 1.0, 0.5111111111111112, 0.7733333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.873266466421744, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23521888280505385, 0.23521888280505368, 0.33761314024921213], 
reward next is 0.6624, 
noisyNet noise sample is [array([2.2640264], dtype=float32), 0.5675224]. 
=============================================
[2019-03-24 04:53:02,943] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9909937e-01 1.8183508e-08 9.0032973e-04 3.3154932e-10 3.5384085e-07], sum to 1.0000
[2019-03-24 04:53:02,951] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9400
[2019-03-24 04:53:02,958] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1851295.571519775 W.
[2019-03-24 04:53:02,962] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.2, 76.83333333333334, 1.0, 2.0, 0.9965423055352198, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9259928514814, 1851295.571519775, 1851295.571519775, 378626.5195032623], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4356600.0000, 
sim time next is 4357200.0000, 
raw observation next is [28.4, 74.66666666666667, 1.0, 2.0, 0.5597694747518254, 1.0, 1.0, 0.5597694747518254, 1.0, 2.0, 0.8911712342239668, 6.911200000000001, 6.9112, 121.94756008, 1915272.117533477, 1915272.117533476, 373892.0513947092], 
processed observation next is [1.0, 0.43478260869565216, 0.6074074074074074, 0.7466666666666667, 1.0, 1.0, 0.4759160413712207, 1.0, 0.5, 0.4759160413712207, 1.0, 1.0, 0.8639640427799585, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.684025756261956, 0.6840257562619557, 0.7190231757590562], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1629007], dtype=float32), -0.9848903]. 
=============================================
[2019-03-24 04:53:08,961] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7500, global step 119439: loss 185.1646
[2019-03-24 04:53:08,963] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7500, global step 119439: learning rate 0.0000
[2019-03-24 04:53:09,577] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7500, global step 119741: loss 205.4728
[2019-03-24 04:53:09,579] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7500, global step 119741: learning rate 0.0000
[2019-03-24 04:53:09,607] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7500, global step 119752: loss 122.5183
[2019-03-24 04:53:09,612] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7500, global step 119754: learning rate 0.0000
[2019-03-24 04:53:09,760] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7500, global step 119827: loss 155.6849
[2019-03-24 04:53:09,761] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7500, global step 119827: learning rate 0.0000
[2019-03-24 04:53:09,871] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7500, global step 119879: loss 172.8149
[2019-03-24 04:53:09,873] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7500, global step 119881: learning rate 0.0000
[2019-03-24 04:53:09,939] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7500, global step 119910: loss 157.4273
[2019-03-24 04:53:09,940] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7500, global step 119910: learning rate 0.0000
[2019-03-24 04:53:10,004] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7500, global step 119942: loss 154.6347
[2019-03-24 04:53:10,005] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7500, global step 119942: learning rate 0.0000
[2019-03-24 04:53:10,141] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7500, global step 120012: loss 164.8468
[2019-03-24 04:53:10,142] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7500, global step 120012: loss 258.1838
[2019-03-24 04:53:10,145] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7500, global step 120013: learning rate 0.0000
[2019-03-24 04:53:10,146] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7500, global step 120013: learning rate 0.0000
[2019-03-24 04:53:10,361] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7500, global step 120116: loss 81.2873
[2019-03-24 04:53:10,362] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7500, global step 120116: learning rate 0.0000
[2019-03-24 04:53:10,385] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7500, global step 120129: loss 190.1105
[2019-03-24 04:53:10,388] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7500, global step 120129: learning rate 0.0000
[2019-03-24 04:53:10,415] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7500, global step 120144: loss 246.6712
[2019-03-24 04:53:10,417] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7500, global step 120144: learning rate 0.0000
[2019-03-24 04:53:10,420] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7500, global step 120146: loss 148.4516
[2019-03-24 04:53:10,421] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7500, global step 120146: learning rate 0.0000
[2019-03-24 04:53:10,461] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7500, global step 120167: loss 122.5675
[2019-03-24 04:53:10,466] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7500, global step 120168: learning rate 0.0000
[2019-03-24 04:53:10,530] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7500, global step 120201: loss 293.7023
[2019-03-24 04:53:10,531] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7500, global step 120201: learning rate 0.0000
[2019-03-24 04:53:10,789] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.9998307e-01 4.2389624e-16 1.6942617e-05 1.0665391e-19 2.4848454e-10], sum to 1.0000
[2019-03-24 04:53:10,797] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7196
[2019-03-24 04:53:10,806] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 690431.5105216868 W.
[2019-03-24 04:53:10,814] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.33333333333333, 98.0, 1.0, 2.0, 0.5975276474075455, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 690431.5105216868, 690431.5105216868, 158110.4981678117], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4506000.0000, 
sim time next is 4506600.0000, 
raw observation next is [23.16666666666667, 99.0, 1.0, 2.0, 0.2009968364676143, 1.0, 1.0, 0.2009968364676143, 1.0, 1.0, 0.3199935096664049, 6.9112, 6.9112, 121.94756008, 687188.9876015836, 687188.9876015836, 220920.5486045003], 
processed observation next is [0.0, 0.13043478260869565, 0.4135802469135804, 0.99, 1.0, 1.0, 0.04880575769954082, 1.0, 0.5, 0.04880575769954082, 1.0, 0.5, 0.1499918870830061, 0.0, 0.0, 0.8096049824067558, 0.245424638429137, 0.245424638429137, 0.42484720885480826], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0415776], dtype=float32), 0.84787524]. 
=============================================
[2019-03-24 04:53:11,345] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9999702e-01 8.5197063e-20 2.9518087e-06 8.4073766e-22 3.4065539e-15], sum to 1.0000
[2019-03-24 04:53:11,361] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4978
[2019-03-24 04:53:11,369] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 714339.1764628425 W.
[2019-03-24 04:53:11,372] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 89.0, 1.0, 2.0, 0.6245892807425102, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 714339.1764628425, 714339.176462842, 162483.9658716959], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4528800.0000, 
sim time next is 4529400.0000, 
raw observation next is [24.95, 88.5, 1.0, 2.0, 0.3123826423430058, 0.0, 2.0, 0.0, 1.0, 1.0, 0.4973233402024708, 6.9112, 6.9112, 121.9260426156618, 712015.860770217, 712015.860770217, 198601.3261435183], 
processed observation next is [0.0, 0.43478260869565216, 0.47962962962962963, 0.885, 1.0, 1.0, 0.18140790755119734, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.37165417525308847, 0.0, 0.0, 0.8094621288201359, 0.2542913788465061, 0.2542913788465061, 0.38192562719907364], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2008352], dtype=float32), 1.7478434]. 
=============================================
[2019-03-24 04:53:11,433] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7500, global step 120639: loss 202.1543
[2019-03-24 04:53:11,435] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7500, global step 120639: learning rate 0.0000
[2019-03-24 04:53:11,677] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 3.3147402e-23 3.0387364e-09 4.6426270e-26 1.1644710e-16], sum to 1.0000
[2019-03-24 04:53:11,688] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9562
[2019-03-24 04:53:11,698] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 707364.4757201148 W.
[2019-03-24 04:53:11,706] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.86666666666667, 89.33333333333333, 1.0, 2.0, 0.3103428817895358, 1.0, 2.0, 0.3103428817895358, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 707364.4757201148, 707364.4757201148, 182961.1578548415], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4528200.0000, 
sim time next is 4528800.0000, 
raw observation next is [25.0, 89.0, 1.0, 2.0, 0.6251779235072709, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 714339.1812542675, 714339.181254267, 162554.1567715893], 
processed observation next is [0.0, 0.43478260869565216, 0.48148148148148145, 0.89, 1.0, 1.0, 0.5537832422705605, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.25512113616223836, 0.2551211361622382, 0.31260414763767175], 
reward next is 0.6874, 
noisyNet noise sample is [array([-1.8039418], dtype=float32), -0.83381164]. 
=============================================
[2019-03-24 04:53:20,289] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-24 04:53:20,290] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:53:20,290] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:53:20,292] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:53:20,294] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:53:20,295] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:53:20,295] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:53:20,296] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:53:20,297] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:53:20,295] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:53:20,301] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:53:20,311] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run6
[2019-03-24 04:53:20,334] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run6
[2019-03-24 04:53:20,334] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run6
[2019-03-24 04:53:20,392] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run6
[2019-03-24 04:53:20,412] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run6
[2019-03-24 04:53:55,887] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00438544], dtype=float32), 0.006283778]
[2019-03-24 04:53:55,889] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.56666666666666, 66.66666666666667, 1.0, 2.0, 0.8413366487468945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 982216.3560418737, 982216.3560418737, 205819.5665364996]
[2019-03-24 04:53:55,889] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:53:55,892] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.4721776e-01 6.3371564e-10 5.2781377e-02 1.3293077e-11 7.8727231e-07], sampled 0.7501346396680962
[2019-03-24 04:53:55,894] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 982216.3560418737 W.
[2019-03-24 04:54:46,373] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00438544], dtype=float32), 0.006283778]
[2019-03-24 04:54:46,373] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.83333333333334, 94.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7675210228057827, 6.911200000000001, 6.9112, 121.9260426156618, 571270.273961828, 571270.2739618275, 155675.2750319871]
[2019-03-24 04:54:46,374] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:54:46,378] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.8518604e-01 1.0556787e-12 1.4813983e-02 6.4843443e-15 9.1818899e-09], sampled 0.5163530362426823
[2019-03-24 04:54:48,808] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00438544], dtype=float32), 0.006283778]
[2019-03-24 04:54:48,810] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.98356057, 83.70978184, 1.0, 2.0, 0.6798932450970969, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9924040275136965, 6.911199999999999, 6.9112, 121.9260426156618, 1494337.42410233, 1494337.42410233, 312700.2433693567]
[2019-03-24 04:54:48,811] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 04:54:48,814] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.4327801e-01 1.8332116e-10 5.6721713e-02 3.2361240e-12 3.8793388e-07], sampled 0.6279544443854438
[2019-03-24 04:54:48,815] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1494337.42410233 W.
[2019-03-24 04:54:56,794] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00438544], dtype=float32), 0.006283778]
[2019-03-24 04:54:56,794] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.63333333333333, 75.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6156998064912361, 6.9112, 6.9112, 121.9260426156618, 457716.8219946094, 457716.8219946094, 132402.6436983734]
[2019-03-24 04:54:56,795] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 04:54:56,797] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.7946578e-01 3.2091369e-12 2.0534273e-02 2.5415891e-14 2.0928629e-08], sampled 0.21338066139087097
[2019-03-24 04:54:58,088] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00438544], dtype=float32), 0.006283778]
[2019-03-24 04:54:58,089] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.0, 61.0, 1.0, 2.0, 0.699603108349164, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 824197.4608548142, 824197.4608548142, 177339.8302095242]
[2019-03-24 04:54:58,090] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:54:58,092] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.3042719e-01 1.3999896e-09 6.9571391e-02 3.5214231e-11 1.4188604e-06], sampled 0.3386013837848477
[2019-03-24 04:54:58,093] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 824197.4608548142 W.
[2019-03-24 04:55:05,717] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7611.7315 2540192264.3681 801.0000
[2019-03-24 04:55:06,257] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8288.2666 2269376120.8191 510.0000
[2019-03-24 04:55:06,271] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8143.9473 2303914611.8530 661.0000
[2019-03-24 04:55:06,360] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8078.4520 2351177120.7415 595.0000
[2019-03-24 04:55:06,363] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8384.8048 2230487826.2151 509.0000
[2019-03-24 04:55:07,378] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 125000, evaluation results [125000.0, 7611.731523480899, 2540192264.368089, 801.0, 8288.266562330198, 2269376120.81914, 510.0, 8384.804792659525, 2230487826.21509, 509.0, 8078.452007383199, 2351177120.741534, 595.0, 8143.947275095577, 2303914611.852993, 661.0]
[2019-03-24 04:55:11,984] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8000, global step 127412: loss 0.7455
[2019-03-24 04:55:11,986] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8000, global step 127413: learning rate 0.0000
[2019-03-24 04:55:12,521] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.7483436e-01 2.2989503e-11 1.2516524e-01 1.1883142e-13 4.6549468e-07], sum to 1.0000
[2019-03-24 04:55:12,528] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9053
[2019-03-24 04:55:12,531] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 88.33333333333333, 1.0, 2.0, 0.7601679388442625, 1.0, 1.0, 0.7601679388442625, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1733786.311833072, 1733786.311833072, 327569.933173017], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4794000.0000, 
sim time next is 4794600.0000, 
raw observation next is [26.0, 88.66666666666667, 1.0, 2.0, 0.9107245479954393, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1753326.777411447, 1753326.777411447, 359292.7068314896], 
processed observation next is [1.0, 0.4782608695652174, 0.5185185185185185, 0.8866666666666667, 1.0, 1.0, 0.8937196999945707, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6261881347898025, 0.6261881347898025, 0.6909475131374799], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.23730822], dtype=float32), -0.057632104]. 
=============================================
[2019-03-24 04:55:12,753] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8000, global step 127804: loss -39.4526
[2019-03-24 04:55:12,756] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8000, global step 127804: learning rate 0.0000
[2019-03-24 04:55:12,771] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8000, global step 127811: loss -125.9217
[2019-03-24 04:55:12,773] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8000, global step 127812: learning rate 0.0000
[2019-03-24 04:55:12,780] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8000, global step 127816: loss 12.6149
[2019-03-24 04:55:12,782] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8000, global step 127817: learning rate 0.0000
[2019-03-24 04:55:12,864] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8000, global step 127852: loss -13.5644
[2019-03-24 04:55:12,866] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8000, global step 127852: learning rate 0.0000
[2019-03-24 04:55:12,971] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8000, global step 127913: loss -93.7764
[2019-03-24 04:55:12,973] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8000, global step 127914: learning rate 0.0000
[2019-03-24 04:55:12,998] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8000, global step 127924: loss -25.0436
[2019-03-24 04:55:13,003] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8000, global step 127924: learning rate 0.0000
[2019-03-24 04:55:13,016] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8000, global step 127931: loss -62.1914
[2019-03-24 04:55:13,018] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8000, global step 127931: learning rate 0.0000
[2019-03-24 04:55:13,207] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8000, global step 128032: loss 52.9964
[2019-03-24 04:55:13,208] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8000, global step 128032: learning rate 0.0000
[2019-03-24 04:55:13,223] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8000, global step 128038: loss -129.3425
[2019-03-24 04:55:13,224] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8000, global step 128038: learning rate 0.0000
[2019-03-24 04:55:13,248] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8000, global step 128054: loss 5.0274
[2019-03-24 04:55:13,250] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8000, global step 128054: learning rate 0.0000
[2019-03-24 04:55:13,328] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8000, global step 128093: loss -52.8140
[2019-03-24 04:55:13,331] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8000, global step 128093: learning rate 0.0000
[2019-03-24 04:55:13,432] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8000, global step 128150: loss -68.4749
[2019-03-24 04:55:13,433] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8000, global step 128151: learning rate 0.0000
[2019-03-24 04:55:13,482] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8000, global step 128173: loss 39.6756
[2019-03-24 04:55:13,484] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8000, global step 128173: learning rate 0.0000
[2019-03-24 04:55:13,620] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8000, global step 128248: loss 68.4276
[2019-03-24 04:55:13,622] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8000, global step 128248: learning rate 0.0000
[2019-03-24 04:55:14,282] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8000, global step 128587: loss 0.9103
[2019-03-24 04:55:14,284] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8000, global step 128587: learning rate 0.0000
[2019-03-24 04:55:16,373] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.2934829e-02 9.3347862e-14 9.2706519e-01 8.7886005e-16 1.7349824e-10], sum to 1.0000
[2019-03-24 04:55:16,380] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0732
[2019-03-24 04:55:16,385] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 95.33333333333334, 1.0, 2.0, 0.3510665347230505, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5589093567179224, 6.911199999999999, 6.9112, 121.9260426156618, 800234.342362736, 800234.3423627365, 209481.1193573014], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4855200.0000, 
sim time next is 4855800.0000, 
raw observation next is [25.0, 95.66666666666666, 1.0, 2.0, 0.3512653294479579, 0.0, 2.0, 0.0, 1.0, 2.0, 0.559225844394267, 6.911199999999999, 6.9112, 121.9260426156618, 800687.7192626979, 800687.7192626983, 209538.6831680029], 
processed observation next is [1.0, 0.17391304347826086, 0.48148148148148145, 0.9566666666666666, 1.0, 1.0, 0.22769682077137846, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.44903230549283374, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2859598997366778, 0.28595989973667796, 0.4029590060923133], 
reward next is 0.5970, 
noisyNet noise sample is [array([1.0262496], dtype=float32), 0.39448303]. 
=============================================
[2019-03-24 04:55:17,832] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.2846135e-01 1.7471335e-08 6.7153531e-01 9.7771302e-10 3.3461140e-06], sum to 1.0000
[2019-03-24 04:55:17,848] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2511
[2019-03-24 04:55:17,859] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2721712.963556121 W.
[2019-03-24 04:55:17,862] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.53333333333333, 77.66666666666667, 1.0, 2.0, 0.9634831986928819, 1.0, 2.0, 0.7951062613228755, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2721712.963556121, 2721712.963556121, 507546.8343512014], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4890000.0000, 
sim time next is 4890600.0000, 
raw observation next is [31.4, 78.0, 1.0, 2.0, 0.9265981378460154, 1.0, 2.0, 0.7766637308994425, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2658488.668495093, 2658488.668495093, 495681.1856213032], 
processed observation next is [1.0, 0.6086956521739131, 0.7185185185185184, 0.78, 1.0, 1.0, 0.912616830769066, 1.0, 1.0, 0.734123489166003, 1.0, 1.0, 0.9972168686025908, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.9494602387482475, 0.9494602387482475, 0.9532330492717369], 
reward next is 0.0468, 
noisyNet noise sample is [array([-1.5390408], dtype=float32), -1.1988658]. 
=============================================
[2019-03-24 04:55:20,737] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.2275921e-01 4.4180279e-17 1.7724079e-01 3.4884158e-20 1.4676568e-10], sum to 1.0000
[2019-03-24 04:55:20,749] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6038
[2019-03-24 04:55:20,755] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 975271.4707164097 W.
[2019-03-24 04:55:20,759] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.66666666666667, 79.66666666666667, 1.0, 2.0, 0.4160390496809793, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6652295548472001, 6.911200000000001, 6.9112, 121.9260426060443, 975271.4707164097, 975271.4707164094, 228508.2815729508], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4954800.0000, 
sim time next is 4955400.0000, 
raw observation next is [24.75, 80.5, 1.0, 2.0, 0.4540469489335976, 1.0, 1.0, 0.4540469489335976, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156589, 1054297.786971946, 1054297.786971946, 222432.7336557625], 
processed observation next is [1.0, 0.34782608695652173, 0.4722222222222222, 0.805, 1.0, 1.0, 0.35005589158761624, 1.0, 0.5, 0.35005589158761624, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201167, 0.37653492391855214, 0.37653492391855214, 0.42775525703031253], 
reward next is 0.5722, 
noisyNet noise sample is [array([1.4923397], dtype=float32), -1.9931061]. 
=============================================
[2019-03-24 04:55:27,123] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8500, global step 135279: loss -59.9302
[2019-03-24 04:55:27,125] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8500, global step 135279: learning rate 0.0000
[2019-03-24 04:55:28,061] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8500, global step 135762: loss -19.6934
[2019-03-24 04:55:28,063] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8500, global step 135763: learning rate 0.0000
[2019-03-24 04:55:28,106] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8500, global step 135784: loss 1.4053
[2019-03-24 04:55:28,109] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8500, global step 135784: learning rate 0.0000
[2019-03-24 04:55:28,217] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8500, global step 135840: loss 0.3428
[2019-03-24 04:55:28,226] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8500, global step 135842: learning rate 0.0000
[2019-03-24 04:55:28,237] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8500, global step 135848: loss 0.8217
[2019-03-24 04:55:28,240] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8500, global step 135848: learning rate 0.0000
[2019-03-24 04:55:28,303] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8500, global step 135887: loss -22.7379
[2019-03-24 04:55:28,304] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8500, global step 135887: learning rate 0.0000
[2019-03-24 04:55:28,391] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8500, global step 135930: loss 0.1147
[2019-03-24 04:55:28,392] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8500, global step 135930: learning rate 0.0000
[2019-03-24 04:55:28,449] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8500, global step 135959: loss 0.0791
[2019-03-24 04:55:28,451] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8500, global step 135960: learning rate 0.0000
[2019-03-24 04:55:28,487] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8500, global step 135976: loss -53.3973
[2019-03-24 04:55:28,488] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8500, global step 135977: learning rate 0.0000
[2019-03-24 04:55:28,556] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8500, global step 136016: loss -206.4259
[2019-03-24 04:55:28,562] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8500, global step 136017: learning rate 0.0000
[2019-03-24 04:55:28,808] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8500, global step 136146: loss -32.1024
[2019-03-24 04:55:28,810] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8500, global step 136146: learning rate 0.0000
[2019-03-24 04:55:28,877] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8500, global step 136181: loss 0.1346
[2019-03-24 04:55:28,879] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8500, global step 136181: learning rate 0.0000
[2019-03-24 04:55:28,879] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8500, global step 136182: loss -0.3400
[2019-03-24 04:55:28,880] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8500, global step 136182: learning rate 0.0000
[2019-03-24 04:55:28,981] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8500, global step 136237: loss -126.5323
[2019-03-24 04:55:28,985] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8500, global step 136237: learning rate 0.0000
[2019-03-24 04:55:28,990] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8500, global step 136238: loss 0.7443
[2019-03-24 04:55:28,992] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8500, global step 136239: learning rate 0.0000
[2019-03-24 04:55:29,622] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8500, global step 136566: loss 41.1876
[2019-03-24 04:55:29,624] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8500, global step 136566: learning rate 0.0000
[2019-03-24 04:55:29,943] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.2619972e-01 4.9970620e-15 7.7380031e-01 4.3748018e-17 1.5917607e-09], sum to 1.0000
[2019-03-24 04:55:29,951] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0467
[2019-03-24 04:55:29,957] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 970508.9529259333 W.
[2019-03-24 04:55:29,960] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.1, 87.0, 1.0, 2.0, 0.4257195320273214, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6777593597047076, 6.911199999999999, 6.9112, 121.9260426156618, 970508.9529259333, 970508.9529259338, 232179.7622822075], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5134200.0000, 
sim time next is 5134800.0000, 
raw observation next is [29.2, 85.0, 1.0, 2.0, 0.4328913401855141, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6891771118620356, 6.9112, 6.9112, 121.9260426156618, 986868.9866265227, 986868.9866265227, 234476.75379438], 
processed observation next is [0.0, 0.43478260869565216, 0.637037037037037, 0.85, 1.0, 1.0, 0.32487064307799296, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6114713898275445, 0.0, 0.0, 0.8094621288201359, 0.3524532095094724, 0.3524532095094724, 0.45091683421996154], 
reward next is 0.5491, 
noisyNet noise sample is [array([-0.6510367], dtype=float32), 0.34913364]. 
=============================================
[2019-03-24 04:55:32,605] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.0030701e-01 2.0424755e-24 7.9969293e-01 9.8682439e-27 6.3564292e-15], sum to 1.0000
[2019-03-24 04:55:32,613] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5200
[2019-03-24 04:55:32,616] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.96666666666667, 69.66666666666667, 1.0, 2.0, 0.3819573343115409, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6080885157059063, 6.911199999999999, 6.9112, 121.9260426156618, 870687.9950775777, 870687.9950775781, 218604.4257285618], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5156400.0000, 
sim time next is 5157000.0000, 
raw observation next is [30.95, 69.5, 1.0, 2.0, 0.3857386851669254, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6141085494176781, 6.9112, 6.9112, 121.9260426156618, 879312.6900591075, 879312.6900591075, 219746.655430288], 
processed observation next is [0.0, 0.6956521739130435, 0.7018518518518518, 0.695, 1.0, 1.0, 0.26873652996062547, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5176356867720976, 0.0, 0.0, 0.8094621288201359, 0.31404024644968126, 0.31404024644968126, 0.42258972198132305], 
reward next is 0.5774, 
noisyNet noise sample is [array([-0.18278499], dtype=float32), -1.097919]. 
=============================================
[2019-03-24 04:55:32,633] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[77.91927 ]
 [77.203316]
 [76.52969 ]
 [76.22968 ]
 [75.83503 ]], R is [[77.91556549]
 [77.71601868]
 [77.51102448]
 [77.2999115 ]
 [77.08716583]].
[2019-03-24 04:55:39,631] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.25916576e-01 1.99433070e-09 4.74082291e-01 1.08529144e-10
 1.04939079e-06], sum to 1.0000
[2019-03-24 04:55:39,656] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3636
[2019-03-24 04:55:39,664] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1378856.781630758 W.
[2019-03-24 04:55:39,669] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.26666666666667, 73.0, 1.0, 2.0, 0.5987778882741819, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9540174464125436, 6.911199999999998, 6.9112, 121.9260426156618, 1378856.781630758, 1378856.781630759, 293190.2765734508], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5314800.0000, 
sim time next is 5315400.0000, 
raw observation next is [26.45, 72.0, 1.0, 2.0, 0.3727157149728165, 1.0, 1.0, 0.3727157149728165, 1.0, 2.0, 0.5933755567401275, 6.9112, 6.9112, 121.94756008, 1274767.671217326, 1274767.671217326, 285336.4850736374], 
processed observation next is [1.0, 0.5217391304347826, 0.5351851851851852, 0.72, 1.0, 1.0, 0.2532329940152578, 1.0, 0.5, 0.2532329940152578, 1.0, 1.0, 0.49171944592515937, 0.0, 0.0, 0.8096049824067558, 0.45527416829190215, 0.45527416829190215, 0.548724009756995], 
reward next is 0.4513, 
noisyNet noise sample is [array([-0.04520657], dtype=float32), 1.2074295]. 
=============================================
[2019-03-24 04:55:42,654] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9000, global step 143386: loss -6.4417
[2019-03-24 04:55:42,656] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9000, global step 143386: learning rate 0.0000
[2019-03-24 04:55:43,202] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9000, global step 143658: loss -22.4183
[2019-03-24 04:55:43,204] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9000, global step 143659: learning rate 0.0000
[2019-03-24 04:55:43,476] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9000, global step 143794: loss -8.5762
[2019-03-24 04:55:43,479] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9000, global step 143794: learning rate 0.0000
[2019-03-24 04:55:43,491] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9000, global step 143800: loss -6.7041
[2019-03-24 04:55:43,493] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9000, global step 143800: learning rate 0.0000
[2019-03-24 04:55:43,573] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9000, global step 143838: loss -27.3328
[2019-03-24 04:55:43,577] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9000, global step 143839: learning rate 0.0000
[2019-03-24 04:55:43,674] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9000, global step 143890: loss -14.3038
[2019-03-24 04:55:43,677] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9000, global step 143891: learning rate 0.0000
[2019-03-24 04:55:43,723] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9000, global step 143913: loss -4.9065
[2019-03-24 04:55:43,724] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9000, global step 143913: learning rate 0.0000
[2019-03-24 04:55:43,834] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9000, global step 143965: loss -2.0838
[2019-03-24 04:55:43,836] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9000, global step 143966: learning rate 0.0000
[2019-03-24 04:55:43,926] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9000, global step 144005: loss -7.2694
[2019-03-24 04:55:43,928] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9000, global step 144005: loss -13.1283
[2019-03-24 04:55:43,930] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9000, global step 144005: learning rate 0.0000
[2019-03-24 04:55:43,931] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9000, global step 144005: learning rate 0.0000
[2019-03-24 04:55:44,161] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9000, global step 144126: loss -8.8653
[2019-03-24 04:55:44,164] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9000, global step 144126: learning rate 0.0000
[2019-03-24 04:55:44,237] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9000, global step 144159: loss -36.9735
[2019-03-24 04:55:44,238] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9000, global step 144159: learning rate 0.0000
[2019-03-24 04:55:44,306] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9000, global step 144197: loss -4.6075
[2019-03-24 04:55:44,310] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9000, global step 144198: learning rate 0.0000
[2019-03-24 04:55:44,342] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9000, global step 144213: loss 15.6331
[2019-03-24 04:55:44,345] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9000, global step 144213: learning rate 0.0000
[2019-03-24 04:55:44,364] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9000, global step 144221: loss 43.5249
[2019-03-24 04:55:44,369] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9000, global step 144221: learning rate 0.0000
[2019-03-24 04:55:45,197] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9000, global step 144622: loss 89.5423
[2019-03-24 04:55:45,198] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9000, global step 144622: learning rate 0.0000
[2019-03-24 04:55:49,527] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.3994693e-02 2.8869116e-13 9.6600527e-01 1.3429888e-14 1.0399397e-09], sum to 1.0000
[2019-03-24 04:55:49,533] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2514
[2019-03-24 04:55:49,542] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 2 has been changed to 3 for the demand 2028897.937309913 W.
[2019-03-24 04:55:49,554] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.4, 77.0, 1.0, 2.0, 0.8894110181418937, 1.0, 2.0, 0.8894110181418937, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9259874313015, 2028897.937309913, 2028897.937309913, 382086.0640071247], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5502000.0000, 
sim time next is 5502600.0000, 
raw observation next is [28.05, 78.0, 1.0, 2.0, 0.8452633538372383, 1.0, 2.0, 0.8452633538372383, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260425988347, 1928080.884713823, 1928080.884713823, 362813.2459165794], 
processed observation next is [1.0, 0.6956521739130435, 0.5944444444444444, 0.78, 1.0, 1.0, 0.8157897069490931, 1.0, 1.0, 0.8157897069490931, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621287084215, 0.6886003159692224, 0.6886003159692224, 0.6977177806088065], 
reward next is 0.3023, 
noisyNet noise sample is [array([-0.10760075], dtype=float32), 1.8607314]. 
=============================================
[2019-03-24 04:55:49,702] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.8898942e-01 7.0511142e-14 2.1101055e-01 9.8883717e-16 1.2227915e-08], sum to 1.0000
[2019-03-24 04:55:49,710] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0597
[2019-03-24 04:55:49,722] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 743801.091059455 W.
[2019-03-24 04:55:49,727] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.63333333333333, 81.0, 1.0, 2.0, 0.2175473590635096, 1.0, 1.0, 0.2175473590635096, 1.0, 2.0, 0.3463424806519609, 6.9112, 6.9112, 121.94756008, 743801.091059455, 743801.091059455, 226412.3263620078], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5514000.0000, 
sim time next is 5514600.0000, 
raw observation next is [26.61666666666667, 81.0, 1.0, 2.0, 0.2175928158133139, 1.0, 2.0, 0.2175928158133139, 1.0, 2.0, 0.3464148492780721, 6.911199999999999, 6.9112, 121.94756008, 743956.5844875796, 743956.58448758, 226427.6208473934], 
processed observation next is [1.0, 0.8260869565217391, 0.5413580246913582, 0.81, 1.0, 1.0, 0.06856287596823085, 1.0, 1.0, 0.06856287596823085, 1.0, 1.0, 0.18301856159759008, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.26569878017413556, 0.26569878017413573, 0.4354377323988335], 
reward next is 0.5646, 
noisyNet noise sample is [array([0.31010175], dtype=float32), -0.44932413]. 
=============================================
[2019-03-24 04:55:56,107] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-24 04:55:56,109] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:55:56,111] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:55:56,111] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:55:56,112] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:55:56,111] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:55:56,113] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:55:56,114] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:55:56,114] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:55:56,117] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:55:56,120] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:55:56,132] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run7
[2019-03-24 04:55:56,133] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run7
[2019-03-24 04:55:56,133] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run7
[2019-03-24 04:55:56,205] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run7
[2019-03-24 04:55:56,205] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run7
[2019-03-24 04:56:30,286] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00481706], dtype=float32), 0.0064328997]
[2019-03-24 04:56:30,287] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.2, 72.66666666666667, 1.0, 2.0, 0.5436853702911427, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8700626098156947, 6.911200000000001, 6.9112, 121.9260426156618, 1278377.495226062, 1278377.495226061, 271790.7748542915]
[2019-03-24 04:56:30,289] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:56:30,293] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [2.0479752e-01 3.2424245e-14 7.9520243e-01 3.5468409e-16 1.3723618e-09], sampled 0.23753864286271997
[2019-03-24 04:57:24,991] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00481706], dtype=float32), 0.0064328997]
[2019-03-24 04:57:24,993] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.55, 76.5, 1.0, 2.0, 0.3326535137204053, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5295952276114824, 6.911199999999999, 6.9112, 121.9260426156618, 758242.2460146851, 758242.2460146856, 204228.3565130556]
[2019-03-24 04:57:24,995] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 04:57:24,998] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [2.2353245e-01 1.5787665e-15 7.7646756e-01 9.8992757e-18 1.7175614e-10], sampled 0.3552081485154046
[2019-03-24 04:57:42,213] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 5921.4303 2585246213.5428 252.0000
[2019-03-24 04:57:42,357] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 6138.3121 2755352879.7457 381.0000
[2019-03-24 04:57:42,467] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 6231.0740 2542819640.0898 262.0000
[2019-03-24 04:57:42,584] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 6457.8828 2480958590.2600 156.0000
[2019-03-24 04:57:42,762] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 6010.9320 2519509252.7287 178.0000
[2019-03-24 04:57:43,842] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 150000, evaluation results [150000.0, 6138.312099668018, 2755352879.745671, 381.0, 6010.931969400017, 2519509252.7287045, 178.0, 6457.8828470981625, 2480958590.2600436, 156.0, 5921.430260736976, 2585246213.542835, 252.0, 6231.074004828671, 2542819640.0897503, 262.0]
[2019-03-24 04:57:46,764] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9500, global step 151523: loss 55.6506
[2019-03-24 04:57:46,765] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9500, global step 151523: learning rate 0.0000
[2019-03-24 04:57:46,954] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9500, global step 151618: loss 39.6240
[2019-03-24 04:57:46,957] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9500, global step 151618: learning rate 0.0000
[2019-03-24 04:57:47,271] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9500, global step 151786: loss 62.2605
[2019-03-24 04:57:47,273] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9500, global step 151786: learning rate 0.0000
[2019-03-24 04:57:47,421] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9500, global step 151862: loss 30.6705
[2019-03-24 04:57:47,422] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9500, global step 151862: learning rate 0.0000
[2019-03-24 04:57:47,445] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9500, global step 151872: loss -0.8041
[2019-03-24 04:57:47,446] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9500, global step 151872: learning rate 0.0000
[2019-03-24 04:57:47,453] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9500, global step 151874: loss -0.1840
[2019-03-24 04:57:47,455] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9500, global step 151874: learning rate 0.0000
[2019-03-24 04:57:47,462] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9500, global step 151878: loss 26.0938
[2019-03-24 04:57:47,463] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9500, global step 151878: learning rate 0.0000
[2019-03-24 04:57:47,538] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9500, global step 151917: loss 27.7639
[2019-03-24 04:57:47,541] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9500, global step 151919: learning rate 0.0000
[2019-03-24 04:57:47,736] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9500, global step 152020: loss 0.0315
[2019-03-24 04:57:47,739] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9500, global step 152022: learning rate 0.0000
[2019-03-24 04:57:47,765] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9500, global step 152032: loss 0.3049
[2019-03-24 04:57:47,769] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9500, global step 152033: learning rate 0.0000
[2019-03-24 04:57:47,955] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9500, global step 152132: loss 26.7769
[2019-03-24 04:57:47,958] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9500, global step 152133: learning rate 0.0000
[2019-03-24 04:57:47,989] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9500, global step 152153: loss 93.0283
[2019-03-24 04:57:47,991] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9500, global step 152154: learning rate 0.0000
[2019-03-24 04:57:48,020] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9500, global step 152168: loss 25.2496
[2019-03-24 04:57:48,023] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9500, global step 152169: learning rate 0.0000
[2019-03-24 04:57:48,068] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9500, global step 152191: loss -3.8218
[2019-03-24 04:57:48,071] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9500, global step 152191: learning rate 0.0000
[2019-03-24 04:57:48,224] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9500, global step 152272: loss 1.6569
[2019-03-24 04:57:48,224] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9500, global step 152272: learning rate 0.0000
[2019-03-24 04:57:48,504] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.4198778e-01 2.6631049e-18 7.5801229e-01 6.3937158e-20 2.4221202e-12], sum to 1.0000
[2019-03-24 04:57:48,513] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0533
[2019-03-24 04:57:48,521] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.43333333333333, 88.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7045481321345646, 6.9112, 6.9112, 121.9260426156618, 526416.3970499751, 526416.3970499751, 145955.6254082201], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5730000.0000, 
sim time next is 5730600.0000, 
raw observation next is [21.46666666666667, 87.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7024327598928888, 6.9112, 6.9112, 121.9260426156618, 524921.4351576674, 524921.4351576674, 145154.5849737779], 
processed observation next is [0.0, 0.30434782608695654, 0.35061728395061736, 0.875, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.628040949866111, 0.0, 0.0, 0.8094621288201359, 0.18747194112773835, 0.18747194112773835, 0.2791434326418806], 
reward next is 0.7209, 
noisyNet noise sample is [array([-0.29358646], dtype=float32), -0.05382558]. 
=============================================
[2019-03-24 04:57:49,019] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9881846e-01 2.1982565e-19 1.1814844e-03 2.1843604e-22 2.2731950e-15], sum to 1.0000
[2019-03-24 04:57:49,027] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9500, global step 152689: loss 25.6881
[2019-03-24 04:57:49,031] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9500, global step 152689: learning rate 0.0000
[2019-03-24 04:57:49,032] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8890
[2019-03-24 04:57:49,037] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.5, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6999147148637079, 6.911200000000001, 6.9112, 121.9260426156618, 523040.1732337791, 523040.1732337786, 144760.1975736799], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5731200.0000, 
sim time next is 5731800.0000, 
raw observation next is [21.71666666666667, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7013868311502134, 6.911199999999999, 6.9112, 121.9260426156618, 524139.6132709371, 524139.6132709375, 145037.9325674905], 
processed observation next is [0.0, 0.34782608695652173, 0.3598765432098766, 0.86, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6267335389377667, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1871927190253347, 0.18719271902533482, 0.2789191010913279], 
reward next is 0.7211, 
noisyNet noise sample is [array([1.3504183], dtype=float32), -0.71021473]. 
=============================================
[2019-03-24 04:57:49,903] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9999475e-01 1.5605771e-22 5.3043891e-06 1.9462532e-25 2.3294673e-17], sum to 1.0000
[2019-03-24 04:57:49,910] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7931
[2019-03-24 04:57:49,913] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.15, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8002579253850558, 6.911199999999999, 6.9112, 121.9260426156618, 593759.5009906864, 593759.5009906868, 160663.1481515953], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5749800.0000, 
sim time next is 5750400.0000, 
raw observation next is [27.3, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8091655354718458, 6.9112, 6.9112, 121.9260426156618, 599644.6440619748, 599644.6440619748, 162085.1529338203], 
processed observation next is [0.0, 0.5652173913043478, 0.5666666666666667, 0.62, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7614569193398071, 0.0, 0.0, 0.8094621288201359, 0.2141588014507053, 0.2141588014507053, 0.3117022171804236], 
reward next is 0.6883, 
noisyNet noise sample is [array([-1.0219053], dtype=float32), 0.6134479]. 
=============================================
[2019-03-24 04:57:52,235] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 2.4123964e-27 5.8417504e-10 2.2596025e-31 1.1888272e-20], sum to 1.0000
[2019-03-24 04:57:52,240] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0130
[2019-03-24 04:57:52,246] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.35, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8024209547312307, 6.911200000000001, 6.9112, 121.9260426156618, 595781.1116374742, 595781.1116374737, 160742.8356592832], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5787000.0000, 
sim time next is 5787600.0000, 
raw observation next is [23.26666666666667, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7967418148794997, 6.911200000000001, 6.9112, 121.9260426156618, 591954.3429061988, 591954.3429061983, 159843.4323786888], 
processed observation next is [0.0, 1.0, 0.41728395061728407, 0.85, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7459272685993745, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21141226532364243, 0.21141226532364227, 0.3073912161128631], 
reward next is 0.6926, 
noisyNet noise sample is [array([-0.36176816], dtype=float32), 0.54010934]. 
=============================================
[2019-03-24 04:57:53,388] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9962413e-01 7.6886190e-19 3.7586078e-04 7.4460502e-24 1.7403579e-14], sum to 1.0000
[2019-03-24 04:57:53,393] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4257
[2019-03-24 04:57:53,397] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.23333333333333, 79.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7775908499133057, 6.911199999999999, 6.9112, 121.9260426156618, 580352.3454525676, 580352.345452568, 155541.867388561], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5816400.0000, 
sim time next is 5817000.0000, 
raw observation next is [23.36666666666667, 78.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7858274873278025, 6.9112, 6.9112, 121.9260426156618, 586468.9733059745, 586468.9733059745, 156569.5674088393], 
processed observation next is [1.0, 0.30434782608695654, 0.4209876543209878, 0.7883333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.732284359159753, 0.0, 0.0, 0.8094621288201359, 0.20945320475213375, 0.20945320475213375, 0.3010953219400756], 
reward next is 0.6989, 
noisyNet noise sample is [array([1.5132617], dtype=float32), -1.3444303]. 
=============================================
[2019-03-24 04:57:53,417] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[60.897484]
 [60.852932]
 [60.881706]
 [60.651894]
 [60.840813]], R is [[60.6772728 ]
 [60.77138138]
 [60.86673737]
 [60.95490265]
 [61.01639938]].
[2019-03-24 04:57:55,717] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.7412369e-23 6.2292460e-09 5.8159155e-28 4.5673042e-18], sum to 1.0000
[2019-03-24 04:57:55,724] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6264
[2019-03-24 04:57:55,728] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.36666666666667, 61.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6973875345128246, 6.911199999999999, 6.9112, 121.9260426156618, 521149.8537418785, 521149.853741879, 144602.7653961116], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5860200.0000, 
sim time next is 5860800.0000, 
raw observation next is [25.2, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7020920984098361, 6.911199999999999, 6.9112, 121.9260426156618, 524656.1705694987, 524656.1705694991, 145277.4832912645], 
processed observation next is [1.0, 0.8695652173913043, 0.4888888888888889, 0.63, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.627615123012295, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18737720377482095, 0.18737720377482112, 0.27937977556012406], 
reward next is 0.7206, 
noisyNet noise sample is [array([0.8272836], dtype=float32), -2.482465]. 
=============================================
[2019-03-24 04:57:56,583] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 9.7873282e-25 2.6870553e-10 1.3427609e-29 3.0531857e-20], sum to 1.0000
[2019-03-24 04:57:56,589] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9638
[2019-03-24 04:57:56,593] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.91666666666667, 69.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6923326153529296, 6.9112, 6.9112, 121.9260426156618, 517346.2829370839, 517346.2829370839, 143607.0259339023], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5865000.0000, 
sim time next is 5865600.0000, 
raw observation next is [23.73333333333333, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6896082417117704, 6.911199999999999, 6.9112, 121.9260426156618, 515299.8323312071, 515299.8323312075, 143248.3611513418], 
processed observation next is [1.0, 0.9130434782608695, 0.4345679012345678, 0.7, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.612010302139713, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18403565440400255, 0.18403565440400269, 0.27547761759873424], 
reward next is 0.7245, 
noisyNet noise sample is [array([-0.29840806], dtype=float32), -0.2293037]. 
=============================================
[2019-03-24 04:58:02,185] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10000, global step 159528: loss -96.1198
[2019-03-24 04:58:02,187] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10000, global step 159528: learning rate 0.0000
[2019-03-24 04:58:02,239] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10000, global step 159554: loss -19.4552
[2019-03-24 04:58:02,242] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10000, global step 159555: learning rate 0.0000
[2019-03-24 04:58:02,515] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10000, global step 159694: loss -66.8610
[2019-03-24 04:58:02,516] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10000, global step 159694: learning rate 0.0000
[2019-03-24 04:58:02,647] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10000, global step 159761: loss 7.6003
[2019-03-24 04:58:02,649] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10000, global step 159761: learning rate 0.0000
[2019-03-24 04:58:02,757] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10000, global step 159817: loss -17.6198
[2019-03-24 04:58:02,759] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10000, global step 159819: learning rate 0.0000
[2019-03-24 04:58:02,839] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10000, global step 159859: loss -2.1979
[2019-03-24 04:58:02,841] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10000, global step 159859: learning rate 0.0000
[2019-03-24 04:58:02,908] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10000, global step 159893: loss -222.9388
[2019-03-24 04:58:02,910] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10000, global step 159893: learning rate 0.0000
[2019-03-24 04:58:02,978] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10000, global step 159925: loss 53.2788
[2019-03-24 04:58:02,978] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10000, global step 159925: learning rate 0.0000
[2019-03-24 04:58:03,160] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10000, global step 160022: loss -125.8038
[2019-03-24 04:58:03,162] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10000, global step 160023: learning rate 0.0000
[2019-03-24 04:58:03,326] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10000, global step 160106: loss 49.0135
[2019-03-24 04:58:03,329] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10000, global step 160108: learning rate 0.0000
[2019-03-24 04:58:03,400] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10000, global step 160141: loss -66.5451
[2019-03-24 04:58:03,403] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10000, global step 160141: learning rate 0.0000
[2019-03-24 04:58:03,411] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10000, global step 160148: loss 24.5892
[2019-03-24 04:58:03,413] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10000, global step 160151: learning rate 0.0000
[2019-03-24 04:58:03,447] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10000, global step 160162: loss 25.5086
[2019-03-24 04:58:03,448] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10000, global step 160162: learning rate 0.0000
[2019-03-24 04:58:03,482] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10000, global step 160179: loss -53.6439
[2019-03-24 04:58:03,483] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10000, global step 160179: learning rate 0.0000
[2019-03-24 04:58:03,716] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10000, global step 160301: loss -39.7561
[2019-03-24 04:58:03,717] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10000, global step 160301: learning rate 0.0000
[2019-03-24 04:58:04,290] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10000, global step 160598: loss -34.7227
[2019-03-24 04:58:04,292] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10000, global step 160599: learning rate 0.0000
[2019-03-24 04:58:05,434] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 5.9267782e-21 2.7282149e-10 4.7765493e-27 1.8757923e-17], sum to 1.0000
[2019-03-24 04:58:05,442] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1063
[2019-03-24 04:58:05,446] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.4, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7976887647098094, 6.911199999999999, 6.9112, 121.9260426156618, 593097.8772030988, 593097.8772030993, 159727.9762329609], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6055200.0000, 
sim time next is 6055800.0000, 
raw observation next is [22.45, 90.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9604811777884174, 8.363399634003477, 6.9112, 122.2750155939985, 1460385.377723375, 714600.899571204, 176678.9365453564], 
processed observation next is [1.0, 0.08695652173913043, 0.387037037037037, 0.9066666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9506014722355216, 0.14521996340034765, 0.0, 0.8117789464899718, 0.5215662063297768, 0.2552146069897157, 0.33976718566414693], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.36098582], dtype=float32), -0.47133136]. 
=============================================
[2019-03-24 04:58:12,401] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 3.7266768e-16 1.8919739e-08 8.9379049e-20 4.3062063e-13], sum to 1.0000
[2019-03-24 04:58:12,407] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7898
[2019-03-24 04:58:12,414] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1561612.444098659 W.
[2019-03-24 04:58:12,419] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.4, 67.0, 1.0, 2.0, 0.7385649440244946, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9924894328176781, 6.9112, 6.9112, 121.9260426156618, 1561612.444098659, 1561612.444098659, 323477.0911200346], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6174000.0000, 
sim time next is 6174600.0000, 
raw observation next is [27.53333333333333, 66.33333333333334, 1.0, 2.0, 0.5300070721840833, 1.0, 1.0, 0.5300070721840833, 1.0, 2.0, 0.8437885200423398, 6.911199999999999, 6.9112, 121.94756008, 1813335.593389787, 1813335.593389788, 358560.907620964], 
processed observation next is [1.0, 0.4782608695652174, 0.5753086419753086, 0.6633333333333334, 1.0, 1.0, 0.4404846097429563, 1.0, 0.5, 0.4404846097429563, 1.0, 1.0, 0.8047356500529248, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6476198547820667, 0.6476198547820671, 0.6895402069633922], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.3316476], dtype=float32), -1.089584]. 
=============================================
[2019-03-24 04:58:14,697] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 1.3052333e-27 2.3636093e-18 3.1186462e-35 6.6413066e-26], sum to 1.0000
[2019-03-24 04:58:14,704] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1701
[2019-03-24 04:58:14,708] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.78333333333333, 87.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7805837418622092, 6.911199999999999, 6.9112, 121.9260426156618, 580924.4625643286, 580924.462564329, 157301.5013304281], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6241800.0000, 
sim time next is 6242400.0000, 
raw observation next is [22.9, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7850174327224897, 6.911199999999999, 6.9112, 121.9260426156618, 583938.0493559403, 583938.0493559408, 158016.1546423661], 
processed observation next is [0.0, 0.2608695652173913, 0.4037037037037037, 0.87, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7312717909031121, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20854930334140726, 0.20854930334140742, 0.30387722046608867], 
reward next is 0.6961, 
noisyNet noise sample is [array([-2.172881], dtype=float32), 1.4552352]. 
=============================================
[2019-03-24 04:58:16,866] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 2.6812328e-26 2.0234479e-16 1.2464396e-30 1.8232279e-23], sum to 1.0000
[2019-03-24 04:58:16,883] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5068
[2019-03-24 04:58:16,888] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 734424.0154998346 W.
[2019-03-24 04:58:16,895] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.95, 61.0, 1.0, 2.0, 0.3222090624046554, 1.0, 1.0, 0.3222090624046554, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 734424.0154998346, 734424.015499835, 185875.822474523], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6283800.0000, 
sim time next is 6284400.0000, 
raw observation next is [29.83333333333334, 61.33333333333333, 1.0, 2.0, 0.643796197094471, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 733714.883912336, 733714.883912336, 165774.8804787751], 
processed observation next is [0.0, 0.7391304347826086, 0.6604938271604941, 0.6133333333333333, 1.0, 1.0, 0.575947853683894, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26204102996869144, 0.26204102996869144, 0.3187978470745675], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.64476764], dtype=float32), -1.7103659]. 
=============================================
[2019-03-24 04:58:17,656] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10500, global step 167524: loss 1.4822
[2019-03-24 04:58:17,659] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10500, global step 167525: learning rate 0.0000
[2019-03-24 04:58:17,832] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10500, global step 167617: loss 0.3216
[2019-03-24 04:58:17,835] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10500, global step 167618: learning rate 0.0000
[2019-03-24 04:58:17,857] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 8.9325921e-19 2.1177938e-13 5.3809883e-24 3.9853171e-17], sum to 1.0000
[2019-03-24 04:58:17,865] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9756
[2019-03-24 04:58:17,872] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 745232.733027583 W.
[2019-03-24 04:58:17,875] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.3, 60.0, 1.0, 2.0, 0.3269487966146412, 1.0, 2.0, 0.3269487966146412, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 745232.733027583, 745232.7330275835, 187053.5901227421], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6282000.0000, 
sim time next is 6282600.0000, 
raw observation next is [30.18333333333333, 60.33333333333333, 1.0, 2.0, 0.6521165981723992, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 743201.9880683129, 743201.9880683129, 167275.408189967], 
processed observation next is [0.0, 0.7391304347826086, 0.6734567901234567, 0.6033333333333333, 1.0, 1.0, 0.58585309306238, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2654292814529689, 0.2654292814529689, 0.3216834772883981], 
reward next is 0.6783, 
noisyNet noise sample is [array([-0.9158109], dtype=float32), 1.2055694]. 
=============================================
[2019-03-24 04:58:17,936] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10500, global step 167662: loss 1.0215
[2019-03-24 04:58:17,939] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10500, global step 167663: learning rate 0.0000
[2019-03-24 04:58:17,984] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10500, global step 167693: loss 1.0559
[2019-03-24 04:58:17,985] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10500, global step 167693: learning rate 0.0000
[2019-03-24 04:58:18,157] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10500, global step 167783: loss 0.1647
[2019-03-24 04:58:18,159] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10500, global step 167783: learning rate 0.0000
[2019-03-24 04:58:18,243] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10500, global step 167822: loss 1.3767
[2019-03-24 04:58:18,248] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10500, global step 167822: learning rate 0.0000
[2019-03-24 04:58:18,314] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10500, global step 167860: loss 0.9067
[2019-03-24 04:58:18,317] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10500, global step 167860: learning rate 0.0000
[2019-03-24 04:58:18,406] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10500, global step 167904: loss 0.4217
[2019-03-24 04:58:18,407] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10500, global step 167904: learning rate 0.0000
[2019-03-24 04:58:18,638] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10500, global step 168030: loss 0.0505
[2019-03-24 04:58:18,640] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10500, global step 168031: learning rate 0.0000
[2019-03-24 04:58:18,730] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10500, global step 168078: loss 0.3568
[2019-03-24 04:58:18,732] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10500, global step 168079: learning rate 0.0000
[2019-03-24 04:58:18,974] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10500, global step 168206: loss 0.1146
[2019-03-24 04:58:18,978] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10500, global step 168206: learning rate 0.0000
[2019-03-24 04:58:19,015] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10500, global step 168224: loss 0.1278
[2019-03-24 04:58:19,017] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10500, global step 168224: learning rate 0.0000
[2019-03-24 04:58:19,191] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10500, global step 168324: loss 0.2352
[2019-03-24 04:58:19,193] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10500, global step 168324: learning rate 0.0000
[2019-03-24 04:58:19,206] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10500, global step 168332: loss 0.1358
[2019-03-24 04:58:19,209] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10500, global step 168333: learning rate 0.0000
[2019-03-24 04:58:19,369] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10500, global step 168426: loss 2.1167
[2019-03-24 04:58:19,375] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10500, global step 168427: learning rate 0.0000
[2019-03-24 04:58:19,651] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10500, global step 168581: loss 0.0779
[2019-03-24 04:58:19,652] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10500, global step 168581: learning rate 0.0000
[2019-03-24 04:58:19,723] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.2546814e-25 3.5330067e-16 5.7154119e-33 6.8364398e-24], sum to 1.0000
[2019-03-24 04:58:19,731] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7184
[2019-03-24 04:58:19,735] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.4, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9084491633511532, 6.9112, 6.9112, 121.9260426156618, 664742.6879426183, 664742.6879426183, 177093.0737671663], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6328800.0000, 
sim time next is 6329400.0000, 
raw observation next is [24.46666666666667, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9136168126468145, 6.911200000000001, 6.9112, 121.9260426156618, 667934.2820802875, 667934.282080287, 177902.4512983353], 
processed observation next is [0.0, 0.2608695652173913, 0.46172839506172847, 0.87, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8920210158085181, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23854795788581695, 0.23854795788581679, 0.3421200986506448], 
reward next is 0.6579, 
noisyNet noise sample is [array([0.5180242], dtype=float32), -0.6070315]. 
=============================================
[2019-03-24 04:58:27,610] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 6.1646391e-13 1.1636853e-08 1.0264516e-15 7.1809065e-12], sum to 1.0000
[2019-03-24 04:58:27,611] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2972
[2019-03-24 04:58:27,622] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 765428.4846351668 W.
[2019-03-24 04:58:27,626] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.3, 67.66666666666667, 1.0, 2.0, 0.3358046630654842, 1.0, 1.0, 0.3358046630654842, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 765428.4846351668, 765428.4846351673, 189275.24566002], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6470400.0000, 
sim time next is 6471000.0000, 
raw observation next is [29.2, 68.0, 1.0, 2.0, 0.2243535420459588, 1.0, 2.0, 0.2243535420459588, 1.0, 1.0, 0.3571781456219246, 6.911199999999999, 6.9112, 121.94756008, 767083.2810818809, 767083.2810818813, 228715.2204851354], 
processed observation next is [1.0, 0.9130434782608695, 0.637037037037037, 0.68, 1.0, 1.0, 0.07661135957852239, 1.0, 1.0, 0.07661135957852239, 1.0, 0.5, 0.19647268202740575, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2739583146721003, 0.27395831467210047, 0.4398369624714142], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.861835], dtype=float32), 0.054203827]. 
=============================================
[2019-03-24 04:58:27,638] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[28.040644]
 [27.932074]
 [27.073015]
 [26.645329]
 [27.14619 ]], R is [[27.60030746]
 [27.9603138 ]
 [28.28799438]
 [28.00511551]
 [27.72506523]].
[2019-03-24 04:58:29,128] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9999046e-01 4.3309671e-09 9.5833366e-06 5.9610802e-11 1.8308702e-08], sum to 1.0000
[2019-03-24 04:58:29,136] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6614
[2019-03-24 04:58:29,145] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2027581.642483628 W.
[2019-03-24 04:58:29,152] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.36666666666667, 84.0, 1.0, 2.0, 0.5925565497672398, 1.0, 2.0, 0.5925565497672398, 1.0, 1.0, 0.9433693254489929, 6.911200000000001, 6.9112, 121.94756008, 2027581.642483628, 2027581.642483627, 391334.9351050279], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6513600.0000, 
sim time next is 6514200.0000, 
raw observation next is [27.5, 83.5, 1.0, 2.0, 0.6075753012244058, 1.0, 2.0, 0.6075753012244058, 1.0, 2.0, 0.9672796668953884, 6.911199999999999, 6.9112, 121.94756008, 2079031.900772361, 2079031.900772361, 399518.4566952737], 
processed observation next is [1.0, 0.391304347826087, 0.5740740740740741, 0.835, 1.0, 1.0, 0.5328277395528641, 1.0, 1.0, 0.5328277395528641, 1.0, 1.0, 0.9590995836192353, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7425113931329861, 0.7425113931329861, 0.7683047244139879], 
reward next is 0.2317, 
noisyNet noise sample is [array([-0.39003918], dtype=float32), -0.7790048]. 
=============================================
[2019-03-24 04:58:32,480] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 7.9481510e-18 7.7106583e-13 3.6148496e-21 1.6186032e-15], sum to 1.0000
[2019-03-24 04:58:32,488] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1593
[2019-03-24 04:58:32,493] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 770900.0328325939 W.
[2019-03-24 04:58:32,501] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.46666666666667, 84.0, 1.0, 2.0, 0.6764078094740283, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 770900.0328325939, 770900.0328325939, 171724.4190032276], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6558000.0000, 
sim time next is 6558600.0000, 
raw observation next is [26.43333333333333, 83.5, 1.0, 2.0, 0.2238972633164858, 1.0, 1.0, 0.2238972633164858, 1.0, 1.0, 0.3564517350246428, 6.911199999999999, 6.9112, 121.94756008, 765522.4475570236, 765522.4475570241, 228560.0268303018], 
processed observation next is [1.0, 0.9130434782608695, 0.5345679012345678, 0.835, 1.0, 1.0, 0.07606817061486404, 1.0, 0.5, 0.07606817061486404, 1.0, 0.5, 0.19556466878080345, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2734008741275084, 0.2734008741275086, 0.43953851313519576], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8772978], dtype=float32), 0.20609118]. 
=============================================
[2019-03-24 04:58:32,580] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-24 04:58:32,581] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 04:58:32,582] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 04:58:32,582] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:58:32,583] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:58:32,583] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 04:58:32,584] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 04:58:32,586] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:58:32,584] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:58:32,586] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 04:58:32,591] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 04:58:32,606] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run8
[2019-03-24 04:58:32,629] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run8
[2019-03-24 04:58:32,629] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run8
[2019-03-24 04:58:32,649] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run8
[2019-03-24 04:58:32,682] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run8
[2019-03-24 04:58:33,661] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00438106], dtype=float32), 0.006262126]
[2019-03-24 04:58:33,661] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.1, 68.0, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2296008533326587, 6.9112, 6.9112, 121.94756008, 513744.1100460557, 513744.1100460557, 198025.1244941232]
[2019-03-24 04:58:33,662] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 04:58:33,663] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [0.6624441  0.06861485 0.1359059  0.03913595 0.09389922], sampled 0.7036616939354661
[2019-03-24 04:58:44,184] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00438106], dtype=float32), 0.006262126]
[2019-03-24 04:58:44,186] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.0, 32.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4783211178641208, 6.9112, 6.9112, 121.9260426156618, 341522.4636353748, 341522.4636353748, 91140.79649510518]
[2019-03-24 04:58:44,187] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:58:44,190] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.1672094e-18 7.8926530e-13 1.3713035e-22 1.5576105e-16], sampled 0.7607931165982466
[2019-03-24 04:58:46,789] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00438106], dtype=float32), 0.006262126]
[2019-03-24 04:58:46,790] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.08333333333333, 36.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5096358926840562, 6.9112, 6.9112, 121.9260426156618, 363886.5948095016, 363886.5948095016, 92482.40810453708]
[2019-03-24 04:58:46,794] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:58:46,796] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.2291332e-17 3.7366846e-12 2.4524883e-21 1.2255247e-15], sampled 0.14946631492967022
[2019-03-24 04:58:51,817] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00438106], dtype=float32), 0.006262126]
[2019-03-24 04:58:51,819] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.33333333333334, 58.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5635904005189969, 6.911200000000001, 6.9112, 121.9260426156618, 410512.800880548, 410512.8008805476, 123006.0222341747]
[2019-03-24 04:58:51,820] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 04:58:51,827] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 6.3770972e-18 2.4104507e-12 1.0952903e-21 6.8683324e-16], sampled 0.6425633552235123
[2019-03-24 04:59:00,163] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00438106], dtype=float32), 0.006262126]
[2019-03-24 04:59:00,166] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.75305102666667, 100.9643766133333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8050561358024474, 6.911200000000001, 6.9112, 121.9260426156618, 596131.1654054086, 596131.1654054081, 161748.1529799266]
[2019-03-24 04:59:00,167] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 04:59:00,174] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 7.9436000e-19 6.0880213e-13 8.5877519e-23 1.1021752e-16], sampled 0.8838400692552084
[2019-03-24 04:59:13,884] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00438106], dtype=float32), 0.006262126]
[2019-03-24 04:59:13,887] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.5, 94.0, 1.0, 2.0, 0.763542565802379, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 870445.5516825326, 870445.5516825326, 188525.8763935277]
[2019-03-24 04:59:13,888] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:59:13,891] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 4.6814023e-16 5.7327917e-11 1.9802245e-19 3.4878825e-14], sampled 0.8511572493891322
[2019-03-24 04:59:13,892] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 870445.5516825326 W.
[2019-03-24 04:59:18,082] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00438106], dtype=float32), 0.006262126]
[2019-03-24 04:59:18,084] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8013117160181586, 6.9112, 6.9112, 121.9260426156618, 596000.4285940874, 596000.4285940874, 160059.6366103563]
[2019-03-24 04:59:18,085] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 04:59:18,087] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.000000e+00 7.159874e-19 5.502304e-13 7.595683e-23 9.809496e-17], sampled 0.003780988275729036
[2019-03-24 04:59:25,938] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00438106], dtype=float32), 0.006262126]
[2019-03-24 04:59:25,940] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.16666666666666, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8937967265280283, 6.9112, 6.9112, 121.9260426156618, 654898.5756324475, 654898.5756324475, 174961.0558887557]
[2019-03-24 04:59:25,942] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 04:59:25,944] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.2073517e-18 8.1341737e-13 1.4229958e-22 1.5976289e-16], sampled 0.6349684400545261
[2019-03-24 04:59:55,348] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00438106], dtype=float32), 0.006262126]
[2019-03-24 04:59:55,349] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.0, 58.0, 1.0, 2.0, 0.812001194915257, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9910849536404436, 6.911199999999999, 6.9112, 121.9260426156618, 1647360.923813853, 1647360.923813854, 337557.0637779768]
[2019-03-24 04:59:55,350] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 04:59:55,353] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.1479060e-15 1.1580756e-10 5.6803278e-19 8.1671899e-14], sampled 0.7630908550088447
[2019-03-24 04:59:55,354] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1647360.923813853 W.
[2019-03-24 05:00:06,907] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00438106], dtype=float32), 0.006262126]
[2019-03-24 05:00:06,908] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.58333333333333, 91.50000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8899164085238821, 6.911200000000001, 6.9112, 121.9260426156618, 652909.9762274082, 652909.9762274078, 174260.6011453012]
[2019-03-24 05:00:06,910] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:00:06,913] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 4.9230073e-19 4.6346331e-13 4.6386154e-23 7.5394422e-17], sampled 0.38893028110923644
[2019-03-24 05:00:19,425] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7840.8665 2529728167.2382 831.0000
[2019-03-24 05:00:19,440] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 05:00:19,624] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8402.0561 2292996080.2537 697.0000
[2019-03-24 05:00:19,653] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 05:00:19,745] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 05:00:20,760] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 175000, evaluation results [175000.0, 7840.866545472483, 2529728167.2382045, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8402.056146055233, 2292996080.2537203, 697.0]
[2019-03-24 05:00:21,853] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11000, global step 175570: loss -286.1976
[2019-03-24 05:00:21,855] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11000, global step 175571: learning rate 0.0000
[2019-03-24 05:00:21,903] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11000, global step 175588: loss -124.7795
[2019-03-24 05:00:21,904] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11000, global step 175588: learning rate 0.0000
[2019-03-24 05:00:21,961] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11000, global step 175617: loss -142.8115
[2019-03-24 05:00:21,963] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11000, global step 175617: learning rate 0.0000
[2019-03-24 05:00:22,079] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11000, global step 175678: loss -141.7024
[2019-03-24 05:00:22,083] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11000, global step 175679: learning rate 0.0000
[2019-03-24 05:00:22,217] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11000, global step 175748: loss -145.9348
[2019-03-24 05:00:22,221] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11000, global step 175749: learning rate 0.0000
[2019-03-24 05:00:22,341] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11000, global step 175813: loss -175.2521
[2019-03-24 05:00:22,342] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11000, global step 175813: learning rate 0.0000
[2019-03-24 05:00:22,407] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11000, global step 175850: loss -265.5275
[2019-03-24 05:00:22,409] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11000, global step 175850: learning rate 0.0000
[2019-03-24 05:00:22,497] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11000, global step 175894: loss -208.5789
[2019-03-24 05:00:22,500] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11000, global step 175894: learning rate 0.0000
[2019-03-24 05:00:22,760] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11000, global step 176031: loss -271.5801
[2019-03-24 05:00:22,762] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11000, global step 176031: learning rate 0.0000
[2019-03-24 05:00:22,796] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11000, global step 176046: loss -125.4386
[2019-03-24 05:00:22,800] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11000, global step 176049: learning rate 0.0000
[2019-03-24 05:00:23,043] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11000, global step 176176: loss -313.7212
[2019-03-24 05:00:23,044] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11000, global step 176176: learning rate 0.0000
[2019-03-24 05:00:23,069] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11000, global step 176190: loss -203.8168
[2019-03-24 05:00:23,070] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11000, global step 176190: learning rate 0.0000
[2019-03-24 05:00:23,197] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11000, global step 176254: loss -211.5373
[2019-03-24 05:00:23,199] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11000, global step 176254: learning rate 0.0000
[2019-03-24 05:00:23,213] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11000, global step 176262: loss -114.5653
[2019-03-24 05:00:23,215] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11000, global step 176263: learning rate 0.0000
[2019-03-24 05:00:23,376] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11000, global step 176345: loss -280.2148
[2019-03-24 05:00:23,379] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11000, global step 176346: learning rate 0.0000
[2019-03-24 05:00:23,681] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11000, global step 176499: loss -201.6121
[2019-03-24 05:00:23,681] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11000, global step 176499: learning rate 0.0000
[2019-03-24 05:00:25,418] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 3.2356661e-33 1.9243222e-18 2.5799091e-37 6.5245831e-28], sum to 1.0000
[2019-03-24 05:00:25,425] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8815
[2019-03-24 05:00:25,430] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.98333333333333, 39.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5258097027953731, 6.9112, 6.9112, 121.9260426156618, 376875.9549859988, 376875.9549859988, 117578.9768183861], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6648600.0000, 
sim time next is 6649200.0000, 
raw observation next is [25.0, 38.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.526544809997822, 6.9112, 6.9112, 121.9260426156618, 376281.6026334618, 376281.6026334618, 115571.4000770713], 
processed observation next is [1.0, 1.0, 0.48148148148148145, 0.38, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4081810124972775, 0.0, 0.0, 0.8094621288201359, 0.13438628665480779, 0.13438628665480779, 0.22225269245590634], 
reward next is 0.7777, 
noisyNet noise sample is [array([0.51972216], dtype=float32), 1.9102947]. 
=============================================
[2019-03-24 05:00:28,374] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 6.6229632e-19 6.5939240e-11 1.4384206e-20 6.4755800e-15], sum to 1.0000
[2019-03-24 05:00:28,380] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2865
[2019-03-24 05:00:28,389] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1178885.211176006 W.
[2019-03-24 05:00:28,392] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.6, 35.0, 1.0, 2.0, 0.880671799479694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.028945477452145, 6.9112, 121.9254457602503, 1178885.211176006, 1118589.29791266, 217370.3087501789], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6694800.0000, 
sim time next is 6695400.0000, 
raw observation next is [27.75, 34.5, 1.0, 2.0, 0.3049798382401397, 1.0, 1.0, 0.3049798382401397, 1.0, 1.0, 0.5097065462747642, 6.911200000000001, 6.9112, 121.94756008, 1140487.209337712, 1140487.209337712, 255403.9348075884], 
processed observation next is [1.0, 0.4782608695652174, 0.5833333333333334, 0.345, 1.0, 1.0, 0.1725950455239758, 1.0, 0.5, 0.1725950455239758, 1.0, 0.5, 0.3871331828434552, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.4073168604777543, 0.4073168604777543, 0.4911614130915162], 
reward next is 0.5088, 
noisyNet noise sample is [array([-1.3452358], dtype=float32), -0.82626474]. 
=============================================
[2019-03-24 05:00:30,520] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 1.0114736e-33 3.5484768e-21 0.0000000e+00 2.3394726e-31], sum to 1.0000
[2019-03-24 05:00:30,526] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5438
[2019-03-24 05:00:30,533] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.85, 69.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5921888015755555, 6.911200000000001, 6.9112, 121.9260426156618, 437542.7277545527, 437542.7277545522, 128386.2173692774], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6733800.0000, 
sim time next is 6734400.0000, 
raw observation next is [21.56666666666667, 71.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5893935537123697, 6.911200000000001, 6.9112, 121.9260426156618, 435544.6218905249, 435544.6218905244, 128168.6325050234], 
processed observation next is [1.0, 0.9565217391304348, 0.35432098765432113, 0.71, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.48674194214046207, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15555165067518748, 0.15555165067518728, 0.2464781394327373], 
reward next is 0.7535, 
noisyNet noise sample is [array([-1.5838373], dtype=float32), -1.7142441]. 
=============================================
[2019-03-24 05:00:37,031] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11500, global step 183514: loss 0.0147
[2019-03-24 05:00:37,032] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11500, global step 183514: learning rate 0.0000
[2019-03-24 05:00:37,100] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11500, global step 183552: loss 0.0011
[2019-03-24 05:00:37,101] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11500, global step 183552: learning rate 0.0000
[2019-03-24 05:00:37,329] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11500, global step 183670: loss 0.0070
[2019-03-24 05:00:37,332] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11500, global step 183672: learning rate 0.0000
[2019-03-24 05:00:37,423] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11500, global step 183718: loss 0.0330
[2019-03-24 05:00:37,429] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11500, global step 183719: learning rate 0.0000
[2019-03-24 05:00:37,477] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11500, global step 183751: loss 0.0209
[2019-03-24 05:00:37,478] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11500, global step 183751: learning rate 0.0000
[2019-03-24 05:00:37,510] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11500, global step 183766: loss 0.0049
[2019-03-24 05:00:37,511] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11500, global step 183766: learning rate 0.0000
[2019-03-24 05:00:37,532] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11500, global step 183773: loss 0.0622
[2019-03-24 05:00:37,534] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11500, global step 183773: learning rate 0.0000
[2019-03-24 05:00:37,760] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11500, global step 183891: loss 0.0167
[2019-03-24 05:00:37,761] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11500, global step 183892: learning rate 0.0000
[2019-03-24 05:00:37,819] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11500, global step 183927: loss 0.0289
[2019-03-24 05:00:37,820] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11500, global step 183927: learning rate 0.0000
[2019-03-24 05:00:38,068] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11500, global step 184053: loss 0.0669
[2019-03-24 05:00:38,071] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11500, global step 184054: learning rate 0.0000
[2019-03-24 05:00:38,273] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11500, global step 184163: loss 0.0084
[2019-03-24 05:00:38,276] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11500, global step 184164: learning rate 0.0000
[2019-03-24 05:00:38,502] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11500, global step 184286: loss 0.0485
[2019-03-24 05:00:38,502] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11500, global step 184286: learning rate 0.0000
[2019-03-24 05:00:38,622] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11500, global step 184351: loss 0.0022
[2019-03-24 05:00:38,624] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11500, global step 184352: learning rate 0.0000
[2019-03-24 05:00:38,690] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11500, global step 184380: loss 0.0021
[2019-03-24 05:00:38,691] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11500, global step 184381: learning rate 0.0000
[2019-03-24 05:00:38,799] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11500, global step 184440: loss 0.0334
[2019-03-24 05:00:38,801] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11500, global step 184441: learning rate 0.0000
[2019-03-24 05:00:39,166] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11500, global step 184627: loss 0.0011
[2019-03-24 05:00:39,169] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11500, global step 184628: learning rate 0.0000
[2019-03-24 05:00:41,986] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.00000000e+00 4.18777809e-31 1.35652575e-17 6.85691997e-38
 2.20184853e-26], sum to 1.0000
[2019-03-24 05:00:41,995] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1085
[2019-03-24 05:00:42,002] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.63333333333334, 71.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7007709293532202, 6.9112, 6.9112, 121.9260426156618, 523659.1316748961, 523659.1316748961, 144562.2518666239], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6996000.0000, 
sim time next is 6996600.0000, 
raw observation next is [23.55, 71.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.700319640585885, 6.911200000000001, 6.9112, 121.9260426156618, 523319.7025098918, 523319.7025098914, 144497.250212586], 
processed observation next is [0.0, 1.0, 0.4277777777777778, 0.715, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6253995507323562, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1868998937535328, 0.18689989375353264, 0.27787932733189613], 
reward next is 0.7221, 
noisyNet noise sample is [array([0.46983045], dtype=float32), 1.1954468]. 
=============================================
[2019-03-24 05:00:48,970] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 2.6807304e-27 9.3771646e-15 4.2929941e-32 1.1031687e-22], sum to 1.0000
[2019-03-24 05:00:48,971] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6844
[2019-03-24 05:00:48,988] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.86666666666667, 84.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6899462489516905, 6.911199999999999, 6.9112, 121.9260426156618, 514432.6439959545, 514432.6439959549, 141201.181909327], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7107600.0000, 
sim time next is 7108200.0000, 
raw observation next is [20.85, 84.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6870483404605401, 6.911199999999999, 6.9112, 121.9260426156618, 512177.3611633233, 512177.3611633237, 140792.1676111344], 
processed observation next is [1.0, 0.2608695652173913, 0.32777777777777783, 0.845, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6088104255756751, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1829204861297583, 0.18292048612975845, 0.2707541684829508], 
reward next is 0.7292, 
noisyNet noise sample is [array([-1.0334125], dtype=float32), -0.81099635]. 
=============================================
[2019-03-24 05:00:49,742] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.3508987e-22 8.9047464e-15 3.3930442e-26 1.6977605e-19], sum to 1.0000
[2019-03-24 05:00:49,756] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5370
[2019-03-24 05:00:49,779] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 971106.6971150609 W.
[2019-03-24 05:00:49,786] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.16666666666667, 69.16666666666667, 1.0, 2.0, 0.3964887326137938, 1.0, 1.0, 0.3964887326137938, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 971106.6971150609, 971106.6971150612, 207875.8064041349], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7128600.0000, 
sim time next is 7129200.0000, 
raw observation next is [23.23333333333333, 68.33333333333334, 1.0, 2.0, 0.1962744791816129, 1.0, 2.0, 0.1962744791816129, 1.0, 1.0, 0.3203170217510482, 6.9112, 6.9112, 121.94756008, 717613.8003161944, 717613.8003161944, 218162.6174689446], 
processed observation next is [1.0, 0.5217391304347826, 0.4160493827160493, 0.6833333333333335, 1.0, 1.0, 0.04318390378763439, 1.0, 1.0, 0.04318390378763439, 1.0, 0.5, 0.15039627718881024, 0.0, 0.0, 0.8096049824067558, 0.2562906429700694, 0.2562906429700694, 0.41954349513258576], 
reward next is 0.5805, 
noisyNet noise sample is [array([-0.9080686], dtype=float32), -0.74552613]. 
=============================================
[2019-03-24 05:00:49,866] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 3.1179192e-21 1.9127146e-11 3.8878063e-23 1.4998884e-17], sum to 1.0000
[2019-03-24 05:00:49,875] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9909
[2019-03-24 05:00:49,879] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 997062.6849520699 W.
[2019-03-24 05:00:49,884] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 60.0, 1.0, 2.0, 0.7996767745897015, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 997062.6849520699, 997062.6849520699, 199268.5090573738], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7135200.0000, 
sim time next is 7135800.0000, 
raw observation next is [23.95, 60.33333333333333, 1.0, 2.0, 0.7981036108432508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 997710.9841895412, 997710.9841895417, 198990.5819354245], 
processed observation next is [1.0, 0.6086956521739131, 0.4425925925925926, 0.6033333333333333, 1.0, 1.0, 0.7596471557657747, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3563253514962647, 0.3563253514962649, 0.3826741960296625], 
reward next is 0.6173, 
noisyNet noise sample is [array([0.8853445], dtype=float32), -0.17641394]. 
=============================================
[2019-03-24 05:00:52,240] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12000, global step 191367: loss 0.1434
[2019-03-24 05:00:52,244] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12000, global step 191368: learning rate 0.0000
[2019-03-24 05:00:52,313] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12000, global step 191401: loss 0.0309
[2019-03-24 05:00:52,314] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12000, global step 191401: learning rate 0.0000
[2019-03-24 05:00:52,929] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12000, global step 191689: loss 0.0014
[2019-03-24 05:00:52,933] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12000, global step 191689: learning rate 0.0000
[2019-03-24 05:00:52,941] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12000, global step 191695: loss 0.0498
[2019-03-24 05:00:52,943] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12000, global step 191695: learning rate 0.0000
[2019-03-24 05:00:53,016] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12000, global step 191732: loss 0.0020
[2019-03-24 05:00:53,021] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12000, global step 191732: learning rate 0.0000
[2019-03-24 05:00:53,052] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12000, global step 191753: loss 0.0031
[2019-03-24 05:00:53,054] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12000, global step 191753: learning rate 0.0000
[2019-03-24 05:00:53,294] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12000, global step 191872: loss 0.0216
[2019-03-24 05:00:53,298] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12000, global step 191873: learning rate 0.0000
[2019-03-24 05:00:53,415] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12000, global step 191938: loss 0.0071
[2019-03-24 05:00:53,416] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12000, global step 191938: learning rate 0.0000
[2019-03-24 05:00:53,455] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12000, global step 191954: loss 0.0249
[2019-03-24 05:00:53,458] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12000, global step 191956: learning rate 0.0000
[2019-03-24 05:00:53,676] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12000, global step 192069: loss 0.0135
[2019-03-24 05:00:53,677] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12000, global step 192069: learning rate 0.0000
[2019-03-24 05:00:53,815] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12000, global step 192142: loss 0.0249
[2019-03-24 05:00:53,818] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12000, global step 192142: learning rate 0.0000
[2019-03-24 05:00:53,833] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12000, global step 192147: loss 0.0297
[2019-03-24 05:00:53,834] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12000, global step 192147: learning rate 0.0000
[2019-03-24 05:00:53,978] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12000, global step 192222: loss 0.0351
[2019-03-24 05:00:53,979] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12000, global step 192222: learning rate 0.0000
[2019-03-24 05:00:54,222] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12000, global step 192347: loss 0.0406
[2019-03-24 05:00:54,226] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12000, global step 192348: learning rate 0.0000
[2019-03-24 05:00:54,443] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12000, global step 192458: loss 0.0257
[2019-03-24 05:00:54,445] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12000, global step 192458: learning rate 0.0000
[2019-03-24 05:00:54,861] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12000, global step 192675: loss 0.0045
[2019-03-24 05:00:54,865] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12000, global step 192676: learning rate 0.0000
[2019-03-24 05:00:56,940] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 4.1752589e-30 1.8923874e-17 5.3085644e-33 1.7003311e-22], sum to 1.0000
[2019-03-24 05:00:56,950] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1701
[2019-03-24 05:00:56,956] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.61666666666667, 84.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6224193459329661, 6.911199999999999, 6.9112, 121.9260426156618, 463442.769738181, 463442.7697381815, 133673.8978624782], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7264200.0000, 
sim time next is 7264800.0000, 
raw observation next is [20.6, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6221482829931408, 6.9112, 6.9112, 121.9260426156618, 463253.4410386451, 463253.4410386451, 133658.9835736838], 
processed observation next is [1.0, 0.08695652173913043, 0.3185185185185186, 0.85, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.527685353741426, 0.0, 0.0, 0.8094621288201359, 0.16544765751380183, 0.16544765751380183, 0.2570365068724689], 
reward next is 0.7430, 
noisyNet noise sample is [array([-0.0121673], dtype=float32), -0.4271246]. 
=============================================
[2019-03-24 05:01:01,350] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.3628869e-29 7.0790923e-15 1.0319347e-33 1.2838054e-22], sum to 1.0000
[2019-03-24 05:01:01,361] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4562
[2019-03-24 05:01:01,366] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.4, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6334001612969297, 6.9112, 6.9112, 121.9260426156618, 471995.052106226, 471995.052106226, 135120.3098000503], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7363800.0000, 
sim time next is 7364400.0000, 
raw observation next is [19.36666666666667, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6380039828107333, 6.911199999999999, 6.9112, 121.9260426156618, 475338.084300661, 475338.0843006615, 135489.1574444173], 
processed observation next is [1.0, 0.21739130434782608, 0.27283950617283964, 0.96, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5475049785134166, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16976360153595035, 0.16976360153595055, 0.2605560720084948], 
reward next is 0.7394, 
noisyNet noise sample is [array([-0.10460068], dtype=float32), -0.45972764]. 
=============================================
[2019-03-24 05:01:03,016] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 2.0646219e-26 1.6346970e-14 9.8924506e-28 5.1409300e-22], sum to 1.0000
[2019-03-24 05:01:03,024] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1194
[2019-03-24 05:01:03,031] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.06666666666667, 89.33333333333334, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6772832492197867, 6.911200000000001, 6.9112, 121.9260426156618, 506085.2626539136, 506085.2626539132, 142758.9008693038], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7406400.0000, 
sim time next is 7407000.0000, 
raw observation next is [21.0, 89.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6729399936381286, 6.911199999999999, 6.9112, 121.9260426156618, 502838.1389472418, 502838.1389472423, 141446.5698589824], 
processed observation next is [1.0, 0.7391304347826086, 0.3333333333333333, 0.895, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5911749920476608, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17958504962401495, 0.17958504962401511, 0.2720126343441969], 
reward next is 0.7280, 
noisyNet noise sample is [array([-1.6791234], dtype=float32), 1.1408622]. 
=============================================
[2019-03-24 05:01:03,059] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[58.073795]
 [54.20437 ]
 [52.999542]
 [52.293236]
 [52.310257]], R is [[61.6310463 ]
 [61.01473618]
 [60.40459061]
 [60.31238174]
 [60.26273346]].
[2019-03-24 05:01:05,310] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 9.6637569e-31 1.0888468e-19 7.6285903e-36 1.2829258e-27], sum to 1.0000
[2019-03-24 05:01:05,318] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6857
[2019-03-24 05:01:05,326] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.55, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6662823463548041, 6.911199999999999, 6.9112, 121.9260426156618, 497462.3336650471, 497462.3336650476, 139677.694216258], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7411800.0000, 
sim time next is 7412400.0000, 
raw observation next is [20.5, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6605474628289181, 6.911200000000001, 6.9112, 121.9260426156618, 493101.2248821052, 493101.2248821048, 138949.4693708826], 
processed observation next is [1.0, 0.8260869565217391, 0.3148148148148148, 0.9, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5756843285361476, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17610758031503757, 0.17610758031503743, 0.2672105180209281], 
reward next is 0.7328, 
noisyNet noise sample is [array([-0.01127779], dtype=float32), 0.5021159]. 
=============================================
[2019-03-24 05:01:07,415] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 7.4563008e-31 1.1309653e-19 6.5853499e-34 3.4061326e-24], sum to 1.0000
[2019-03-24 05:01:07,424] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0380
[2019-03-24 05:01:07,428] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.16666666666666, 78.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.773222249848895, 6.911199999999999, 6.9112, 121.9260426156618, 574941.5070720172, 574941.5070720176, 156704.9329894172], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7474800.0000, 
sim time next is 7475400.0000, 
raw observation next is [24.3, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7793617476674013, 6.911199999999999, 6.9112, 121.9260426156618, 579155.6264703393, 579155.6264703397, 157641.6057820586], 
processed observation next is [0.0, 0.5217391304347826, 0.4555555555555556, 0.78, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7242021845842517, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2068412951679783, 0.20684129516797847, 0.30315693419626655], 
reward next is 0.6968, 
noisyNet noise sample is [array([1.0881319], dtype=float32), 0.2567025]. 
=============================================
[2019-03-24 05:01:07,901] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12500, global step 199321: loss 0.0179
[2019-03-24 05:01:07,904] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12500, global step 199322: learning rate 0.0000
[2019-03-24 05:01:07,948] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12500, global step 199346: loss 0.0007
[2019-03-24 05:01:07,951] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12500, global step 199346: learning rate 0.0000
[2019-03-24 05:01:08,446] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12500, global step 199592: loss 0.1512
[2019-03-24 05:01:08,449] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12500, global step 199593: learning rate 0.0000
[2019-03-24 05:01:08,651] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12500, global step 199690: loss 0.0021
[2019-03-24 05:01:08,652] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12500, global step 199690: learning rate 0.0000
[2019-03-24 05:01:08,700] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12500, global step 199713: loss 0.0148
[2019-03-24 05:01:08,705] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12500, global step 199713: learning rate 0.0000
[2019-03-24 05:01:08,811] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12500, global step 199771: loss 0.0139
[2019-03-24 05:01:08,814] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12500, global step 199773: learning rate 0.0000
[2019-03-24 05:01:08,936] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12500, global step 199836: loss 0.0120
[2019-03-24 05:01:08,937] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12500, global step 199836: learning rate 0.0000
[2019-03-24 05:01:09,267] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-24 05:01:09,270] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:01:09,271] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:01:09,271] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:01:09,274] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:01:09,276] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:01:09,277] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:01:09,275] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:01:09,278] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:01:09,279] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:01:09,278] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:01:09,291] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run9
[2019-03-24 05:01:09,315] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run9
[2019-03-24 05:01:09,340] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run9
[2019-03-24 05:01:09,365] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run9
[2019-03-24 05:01:09,365] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run9
[2019-03-24 05:01:14,268] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00539368], dtype=float32), 0.007016149]
[2019-03-24 05:01:14,269] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.71674332833333, 12.32522277166666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5067610798230531, 6.9112, 6.9112, 121.9260426156618, 361833.4571576603, 361833.4571576603, 88753.82948847218]
[2019-03-24 05:01:14,270] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:01:14,273] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 4.9778485e-26 1.6121822e-15 2.7670142e-30 2.4675216e-21], sampled 0.0832701505835931
[2019-03-24 05:01:16,029] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00539368], dtype=float32), 0.007016149]
[2019-03-24 05:01:16,032] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [31.72115913, 37.2252602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6479170361071888, 6.911199999999999, 6.9112, 121.9260426156618, 484031.0755666795, 484031.0755666799, 140009.9201875346]
[2019-03-24 05:01:16,033] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:01:16,036] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 7.4015404e-26 2.6513046e-15 4.2588427e-30 3.8449645e-21], sampled 0.8295191561670275
[2019-03-24 05:01:18,307] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00539368], dtype=float32), 0.007016149]
[2019-03-24 05:01:18,308] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.73270607666667, 43.02640607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7090645719013086, 6.9112, 6.9112, 121.9260426156618, 529754.6894452482, 529754.6894452482, 146581.7161828455]
[2019-03-24 05:01:18,308] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:01:18,310] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 8.6278224e-28 1.7493122e-16 2.4282613e-32 9.7466150e-23], sampled 0.1477846962059055
[2019-03-24 05:01:28,200] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00539368], dtype=float32), 0.007016149]
[2019-03-24 05:01:28,203] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.09436883833333, 89.16823964166667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7978760470179402, 6.9112, 6.9112, 121.9260426156618, 589980.9995445126, 589980.9995445126, 161142.2332907163]
[2019-03-24 05:01:28,206] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:01:28,211] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 4.8338473e-28 1.1830254e-16 1.2363706e-32 5.9473366e-23], sampled 0.5804126262749966
[2019-03-24 05:01:37,186] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00539368], dtype=float32), 0.007016149]
[2019-03-24 05:01:37,187] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [18.93333333333333, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5806016906602497, 6.9112, 6.9112, 121.9260426156618, 430402.1815910457, 430402.1815910457, 128195.8269866235]
[2019-03-24 05:01:37,189] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:01:37,191] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.3804634e-28 5.7754670e-17 2.8730125e-33 2.1705948e-23], sampled 0.6128749214629027
[2019-03-24 05:02:28,552] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00539368], dtype=float32), 0.007016149]
[2019-03-24 05:02:28,553] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.99612412, 82.79804390166666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.679931962823588, 6.911200000000001, 6.9112, 121.9260426156618, 508055.5126826545, 508055.5126826541, 142144.3974705004]
[2019-03-24 05:02:28,555] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:02:28,558] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.3138756e-27 2.0001334e-16 4.0066428e-32 1.3019446e-22], sampled 0.060009646213199264
[2019-03-24 05:02:47,145] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00539368], dtype=float32), 0.007016149]
[2019-03-24 05:02:47,147] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.72227757666666, 72.30694165999999, 1.0, 2.0, 0.9314480652999211, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.017262268565228, 6.9112, 121.9255436674065, 1170734.450675406, 1116421.311694268, 227287.7487696176]
[2019-03-24 05:02:47,151] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:02:47,153] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.00000000e+00 1.03879805e-20 2.82276654e-12 4.48871755e-24
 6.24746157e-17], sampled 0.5630274580626741
[2019-03-24 05:02:47,155] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1170734.450675406 W.
[2019-03-24 05:02:52,298] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00539368], dtype=float32), 0.007016149]
[2019-03-24 05:02:52,299] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.21999374, 95.75427273666668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6344133684863368, 6.9112, 6.9112, 121.9260426156618, 473808.6507208747, 473808.6507208747, 136688.0790502816]
[2019-03-24 05:02:52,301] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:02:52,306] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.00000000e+00 1.00197565e-27 1.68302879e-16 2.91246328e-32
 1.03773554e-22], sampled 0.41440175248457267
[2019-03-24 05:02:56,405] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 05:02:56,434] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8363.4356 2339457156.4423 616.0000
[2019-03-24 05:02:56,779] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8632.2996 2219190181.5071 543.0000
[2019-03-24 05:02:56,823] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 05:02:57,042] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 05:02:58,058] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 200000, evaluation results [200000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8632.299632096856, 2219190181.5070963, 543.0, 8363.435597385289, 2339457156.4422946, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 05:02:58,078] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12500, global step 200015: loss 0.0193
[2019-03-24 05:02:58,080] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12500, global step 200016: learning rate 0.0000
[2019-03-24 05:02:58,120] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12500, global step 200030: loss 0.0137
[2019-03-24 05:02:58,124] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12500, global step 200031: learning rate 0.0000
[2019-03-24 05:02:58,310] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12500, global step 200127: loss 0.0007
[2019-03-24 05:02:58,314] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12500, global step 200127: learning rate 0.0000
[2019-03-24 05:02:58,505] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12500, global step 200226: loss 0.0163
[2019-03-24 05:02:58,508] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12500, global step 200228: learning rate 0.0000
[2019-03-24 05:02:58,565] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12500, global step 200259: loss 0.0179
[2019-03-24 05:02:58,568] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12500, global step 200260: learning rate 0.0000
[2019-03-24 05:02:58,717] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12500, global step 200341: loss 0.0088
[2019-03-24 05:02:58,720] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12500, global step 200342: learning rate 0.0000
[2019-03-24 05:02:58,778] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12500, global step 200372: loss 0.0036
[2019-03-24 05:02:58,782] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12500, global step 200372: learning rate 0.0000
[2019-03-24 05:02:59,041] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12500, global step 200505: loss 0.0441
[2019-03-24 05:02:59,045] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12500, global step 200507: learning rate 0.0000
[2019-03-24 05:02:59,528] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 2.7566319e-26 5.3053739e-15 3.6725287e-30 6.8210032e-21], sum to 1.0000
[2019-03-24 05:02:59,539] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1414
[2019-03-24 05:02:59,545] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.9, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7149662351330287, 6.911200000000001, 6.9112, 121.9260426156618, 533976.355423836, 533976.3554238356, 147681.5675258927], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7528200.0000, 
sim time next is 7528800.0000, 
raw observation next is [20.9, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7153274178410772, 6.911199999999999, 6.9112, 121.9260426156618, 534246.1993203267, 534246.1993203271, 147722.2809204737], 
processed observation next is [0.0, 0.13043478260869565, 0.32962962962962955, 0.96, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6441592723013464, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19080221404297382, 0.19080221404297398, 0.28408130946244947], 
reward next is 0.7159, 
noisyNet noise sample is [array([-0.5702056], dtype=float32), 0.63366944]. 
=============================================
[2019-03-24 05:02:59,559] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12500, global step 200783: loss 0.0009
[2019-03-24 05:02:59,560] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12500, global step 200783: learning rate 0.0000
[2019-03-24 05:03:05,918] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 3.8561906e-19 4.9066575e-12 6.9033218e-23 2.0781532e-15], sum to 1.0000
[2019-03-24 05:03:05,924] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4791
[2019-03-24 05:03:05,929] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1450849.800153625 W.
[2019-03-24 05:03:05,933] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.93333333333334, 66.33333333333333, 1.0, 2.0, 0.628957071865919, 1.0, 1.0, 0.628957071865919, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1450849.800153625, 1450849.800153625, 278963.1406629775], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7652400.0000, 
sim time next is 7653000.0000, 
raw observation next is [27.01666666666667, 65.66666666666667, 1.0, 2.0, 0.6218238246390777, 1.0, 2.0, 0.6218238246390777, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1434647.163024831, 1434647.163024831, 276448.8475801569], 
processed observation next is [1.0, 0.5652173913043478, 0.5561728395061729, 0.6566666666666667, 1.0, 1.0, 0.5497902674274734, 1.0, 1.0, 0.5497902674274734, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5123739867945826, 0.5123739867945826, 0.5316323991926094], 
reward next is 0.4684, 
noisyNet noise sample is [array([-1.2220789], dtype=float32), 1.066979]. 
=============================================
[2019-03-24 05:03:05,942] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[50.759808]
 [51.74679 ]
 [52.417416]
 [53.52958 ]
 [52.58664 ]], R is [[50.66124725]
 [50.15463638]
 [49.65309143]
 [49.57008743]
 [49.61791992]].
[2019-03-24 05:03:05,972] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.2818506e-18 1.8151396e-12 1.8469246e-22 4.4973765e-15], sum to 1.0000
[2019-03-24 05:03:05,981] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7116
[2019-03-24 05:03:05,988] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1200931.866031824 W.
[2019-03-24 05:03:05,991] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.35, 65.83333333333333, 1.0, 2.0, 0.5144029604145415, 1.0, 2.0, 0.5144029604145415, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260425274067, 1200931.866031824, 1200931.866031824, 241177.5801158075], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7656600.0000, 
sim time next is 7657200.0000, 
raw observation next is [26.2, 66.0, 1.0, 2.0, 0.5390274015549703, 1.0, 2.0, 0.5390274015549703, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156349, 1263174.082895059, 1263174.082895058, 249294.0742791042], 
processed observation next is [1.0, 0.6521739130434783, 0.5259259259259259, 0.66, 1.0, 1.0, 0.45122309708925035, 1.0, 1.0, 0.45122309708925035, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288199574, 0.4511336010339496, 0.4511336010339493, 0.4794116813059696], 
reward next is 0.5206, 
noisyNet noise sample is [array([-2.2789857], dtype=float32), -0.25089487]. 
=============================================
[2019-03-24 05:03:10,324] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 5.4155589e-18 9.0373896e-11 1.6900565e-21 3.0648159e-15], sum to 1.0000
[2019-03-24 05:03:10,329] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6819
[2019-03-24 05:03:10,335] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1013709.37667643 W.
[2019-03-24 05:03:10,337] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.6, 50.0, 1.0, 2.0, 0.8407457366611919, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1013709.37667643, 1013709.37667643, 207079.2717438199], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7737000.0000, 
sim time next is 7737600.0000, 
raw observation next is [28.8, 49.00000000000001, 1.0, 2.0, 0.9797086214943505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.389041588258624, 6.9112, 121.9243302937256, 1430098.356329463, 1185404.190662787, 239201.8219209838], 
processed observation next is [1.0, 0.5652173913043478, 0.6222222222222222, 0.49000000000000005, 1.0, 1.0, 0.9758435970170839, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.04778415882586238, 0.0, 0.8094507607831689, 0.5107494129748082, 0.423358639522424, 0.4600035036941996], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1089233], dtype=float32), 2.3472378]. 
=============================================
[2019-03-24 05:03:11,877] A3C_AGENT_WORKER-Thread-12 INFO:Local step 13000, global step 207177: loss 0.0438
[2019-03-24 05:03:11,887] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 13000, global step 207179: learning rate 0.0000
[2019-03-24 05:03:12,276] A3C_AGENT_WORKER-Thread-15 INFO:Local step 13000, global step 207381: loss 0.0088
[2019-03-24 05:03:12,279] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 13000, global step 207382: learning rate 0.0000
[2019-03-24 05:03:12,618] A3C_AGENT_WORKER-Thread-22 INFO:Local step 13000, global step 207559: loss 0.1022
[2019-03-24 05:03:12,621] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 13000, global step 207560: learning rate 0.0000
[2019-03-24 05:03:12,717] A3C_AGENT_WORKER-Thread-17 INFO:Local step 13000, global step 207608: loss 0.0692
[2019-03-24 05:03:12,719] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 13000, global step 207608: learning rate 0.0000
[2019-03-24 05:03:12,822] A3C_AGENT_WORKER-Thread-2 INFO:Local step 13000, global step 207665: loss 0.0377
[2019-03-24 05:03:12,823] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 13000, global step 207665: learning rate 0.0000
[2019-03-24 05:03:13,020] A3C_AGENT_WORKER-Thread-10 INFO:Local step 13000, global step 207770: loss 0.0254
[2019-03-24 05:03:13,023] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 13000, global step 207771: learning rate 0.0000
[2019-03-24 05:03:13,296] A3C_AGENT_WORKER-Thread-14 INFO:Local step 13000, global step 207914: loss 0.0295
[2019-03-24 05:03:13,297] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 13000, global step 207914: learning rate 0.0000
[2019-03-24 05:03:13,366] A3C_AGENT_WORKER-Thread-21 INFO:Local step 13000, global step 207951: loss 0.0557
[2019-03-24 05:03:13,374] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 13000, global step 207951: learning rate 0.0000
[2019-03-24 05:03:13,397] A3C_AGENT_WORKER-Thread-20 INFO:Local step 13000, global step 207968: loss 0.0161
[2019-03-24 05:03:13,400] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 13000, global step 207969: learning rate 0.0000
[2019-03-24 05:03:13,646] A3C_AGENT_WORKER-Thread-19 INFO:Local step 13000, global step 208095: loss 0.0502
[2019-03-24 05:03:13,646] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 13000, global step 208095: learning rate 0.0000
[2019-03-24 05:03:13,845] A3C_AGENT_WORKER-Thread-13 INFO:Local step 13000, global step 208199: loss 0.0786
[2019-03-24 05:03:13,847] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 13000, global step 208199: learning rate 0.0000
[2019-03-24 05:03:13,965] A3C_AGENT_WORKER-Thread-16 INFO:Local step 13000, global step 208259: loss 0.0965
[2019-03-24 05:03:13,968] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 13000, global step 208259: learning rate 0.0000
[2019-03-24 05:03:14,017] A3C_AGENT_WORKER-Thread-3 INFO:Local step 13000, global step 208284: loss 0.0896
[2019-03-24 05:03:14,020] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 13000, global step 208285: learning rate 0.0000
[2019-03-24 05:03:14,246] A3C_AGENT_WORKER-Thread-18 INFO:Local step 13000, global step 208403: loss 0.0921
[2019-03-24 05:03:14,248] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 13000, global step 208404: learning rate 0.0000
[2019-03-24 05:03:14,317] A3C_AGENT_WORKER-Thread-9 INFO:Local step 13000, global step 208442: loss 0.1887
[2019-03-24 05:03:14,319] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 13000, global step 208442: learning rate 0.0000
[2019-03-24 05:03:14,941] A3C_AGENT_WORKER-Thread-11 INFO:Local step 13000, global step 208772: loss 0.5183
[2019-03-24 05:03:14,943] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 13000, global step 208773: learning rate 0.0000
[2019-03-24 05:03:15,251] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 3.0648993e-14 2.8972954e-08 9.7429277e-17 1.4650139e-11], sum to 1.0000
[2019-03-24 05:03:15,256] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8902
[2019-03-24 05:03:15,263] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1392096.98415607 W.
[2019-03-24 05:03:15,268] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.3, 39.16666666666666, 1.0, 2.0, 0.9495098822115245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.334568072473278, 6.9112, 121.9240954719902, 1392096.98415607, 1175298.153146367, 232832.7352811949], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7818600.0000, 
sim time next is 7819200.0000, 
raw observation next is [29.4, 39.0, 1.0, 2.0, 0.3509272825026941, 1.0, 1.0, 0.3509272825026941, 1.0, 1.0, 0.5683655053395382, 6.911199999999999, 6.9112, 121.94756008, 1270118.201881696, 1270118.201881697, 275565.4317314466], 
processed observation next is [1.0, 0.5217391304347826, 0.6444444444444444, 0.39, 1.0, 1.0, 0.22729438393177873, 1.0, 0.5, 0.22729438393177873, 1.0, 0.5, 0.4604568816744227, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.45361364352917716, 0.4536136435291775, 0.5299335225604742], 
reward next is 0.4701, 
noisyNet noise sample is [array([-0.6801971], dtype=float32), 1.0818937]. 
=============================================
[2019-03-24 05:03:15,739] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 1.0371000e-19 1.3018042e-09 4.0752854e-24 1.5091164e-14], sum to 1.0000
[2019-03-24 05:03:15,753] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0569
[2019-03-24 05:03:15,762] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.63333333333334, 77.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6896086820503569, 6.911200000000001, 6.9112, 121.9260426156618, 515286.7629207319, 515286.7629207314, 143175.0670537035], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7867200.0000, 
sim time next is 7867800.0000, 
raw observation next is [22.55, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6896477331399765, 6.911200000000001, 6.9112, 121.9260426156618, 515321.3368435396, 515321.3368435391, 143207.4187012306], 
processed observation next is [1.0, 0.043478260869565216, 0.3907407407407408, 0.78, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6120596664249706, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18404333458697844, 0.18404333458697825, 0.27539888211775115], 
reward next is 0.7246, 
noisyNet noise sample is [array([1.1132374], dtype=float32), -0.40064752]. 
=============================================
[2019-03-24 05:03:16,899] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 5.6972313e-27 1.9191186e-13 5.8905685e-32 9.2714248e-21], sum to 1.0000
[2019-03-24 05:03:16,907] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4128
[2019-03-24 05:03:16,912] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.4, 63.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7198046822852404, 6.911200000000001, 6.9112, 121.9260426156618, 537730.7017162744, 537730.7017162739, 147926.0065020675], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7848600.0000, 
sim time next is 7849200.0000, 
raw observation next is [25.3, 63.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.717236886128152, 6.911200000000001, 6.9112, 121.9260426156618, 535847.2444880364, 535847.2444880359, 147541.1464907477], 
processed observation next is [1.0, 0.8695652173913043, 0.49259259259259264, 0.6366666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6465461076601899, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1913740158885844, 0.19137401588858424, 0.28373297402066866], 
reward next is 0.7163, 
noisyNet noise sample is [array([-0.00815462], dtype=float32), 1.6287796]. 
=============================================
[2019-03-24 05:03:20,615] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:03:20,616] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:03:20,633] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run2
[2019-03-24 05:03:21,011] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:03:21,012] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:03:21,026] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run2
[2019-03-24 05:03:21,084] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 5.8912356e-27 4.8107216e-14 6.8905339e-31 8.1909435e-19], sum to 1.0000
[2019-03-24 05:03:21,086] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7498
[2019-03-24 05:03:21,091] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.76666666666667, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7235671136322109, 6.911200000000001, 6.9112, 121.9260426156618, 540459.39358808, 540459.3935880795, 148541.3837628545], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7947600.0000, 
sim time next is 7948200.0000, 
raw observation next is [23.68333333333333, 74.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7231488984191891, 6.911200000000001, 6.9112, 121.9260426156618, 540156.0115665081, 540156.0115665076, 148474.8103539332], 
processed observation next is [1.0, 1.0, 0.4327160493827159, 0.745, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6539361230239862, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1929128612737529, 0.19291286127375273, 0.28552848144987153], 
reward next is 0.7145, 
noisyNet noise sample is [array([-0.54218096], dtype=float32), -0.5378286]. 
=============================================
[2019-03-24 05:03:21,294] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:03:21,294] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:03:21,295] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run2
[2019-03-24 05:03:21,383] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:03:21,383] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:03:21,384] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run2
[2019-03-24 05:03:21,471] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:03:21,471] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:03:21,473] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run2
[2019-03-24 05:03:21,702] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:03:21,703] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:03:21,704] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run2
[2019-03-24 05:03:21,734] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:03:21,735] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:03:21,736] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run2
[2019-03-24 05:03:21,777] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:03:21,777] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:03:21,778] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run2
[2019-03-24 05:03:21,876] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:03:21,876] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:03:21,877] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run2
[2019-03-24 05:03:22,093] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:03:22,093] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:03:22,095] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run2
[2019-03-24 05:03:22,121] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:03:22,122] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:03:22,123] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:03:22,124] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:03:22,126] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run2
[2019-03-24 05:03:22,151] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run2
[2019-03-24 05:03:22,181] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:03:22,182] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:03:22,183] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run2
[2019-03-24 05:03:22,274] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:03:22,274] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:03:22,282] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run2
[2019-03-24 05:03:22,328] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:03:22,328] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:03:22,330] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run2
[2019-03-24 05:03:22,380] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:03:22,380] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:03:22,382] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run2
[2019-03-24 05:03:30,768] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 3.7222099e-19 1.1976821e-10 5.3752313e-21 2.1946712e-14], sum to 1.0000
[2019-03-24 05:03:30,773] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3190
[2019-03-24 05:03:30,779] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1711289.291456407 W.
[2019-03-24 05:03:30,783] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [37.4, 13.0, 1.0, 2.0, 0.8090337374624919, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9556914108255532, 6.911199999999999, 6.9112, 121.9260426156618, 1711289.291456407, 1711289.291456407, 324995.5159276599], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 139200.0000, 
sim time next is 139800.0000, 
raw observation next is [37.4, 12.5, 1.0, 2.0, 0.4789194816275308, 1.0, 1.0, 0.4789194816275308, 1.0, 2.0, 0.779934156388772, 6.9112, 6.9112, 121.94756008, 1747487.12522898, 1747487.12522898, 332435.5614547393], 
processed observation next is [1.0, 0.6086956521739131, 0.9407407407407407, 0.125, 1.0, 1.0, 0.3796660495565843, 1.0, 0.5, 0.3796660495565843, 1.0, 1.0, 0.7249176954859649, 0.0, 0.0, 0.8096049824067558, 0.6241025447246358, 0.6241025447246358, 0.6392991566437294], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.56638], dtype=float32), -0.26779184]. 
=============================================
[2019-03-24 05:03:46,362] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 5.0584477e-22 1.3162963e-08 2.4538307e-25 1.2531810e-15], sum to 1.0000
[2019-03-24 05:03:46,369] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1375
[2019-03-24 05:03:46,374] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.93333333333333, 56.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.501489069501265, 6.911200000000001, 6.9112, 121.9260426156618, 360887.1799558208, 360887.1799558203, 116200.4767859805], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 436200.0000, 
sim time next is 436800.0000, 
raw observation next is [21.66666666666667, 58.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5022071423336402, 6.911200000000001, 6.9112, 121.9260426156618, 361484.5634428379, 361484.5634428374, 116284.7779208222], 
processed observation next is [1.0, 0.043478260869565216, 0.3580246913580249, 0.5833333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3777589279170502, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12910162980101353, 0.12910162980101336, 0.2236245729246581], 
reward next is 0.7764, 
noisyNet noise sample is [array([1.1438941], dtype=float32), -0.09456621]. 
=============================================
[2019-03-24 05:03:48,594] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-24 05:03:48,595] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:03:48,597] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:03:48,597] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:03:48,598] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:03:48,600] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:03:48,600] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:03:48,603] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:03:48,603] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:03:48,605] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:03:48,608] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:03:48,619] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run10
[2019-03-24 05:03:48,620] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run10
[2019-03-24 05:03:48,663] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run10
[2019-03-24 05:03:48,688] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run10
[2019-03-24 05:03:48,710] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run10
[2019-03-24 05:03:51,290] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00583714], dtype=float32), 0.00796825]
[2019-03-24 05:03:51,292] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [36.55635669666667, 8.612647265833333, 1.0, 2.0, 0.7551223978408387, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 967482.1612952325, 967482.1612952325, 190296.908916346]
[2019-03-24 05:03:51,292] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:03:51,297] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.9984992e-01 5.3067432e-15 1.5000737e-04 3.9368257e-16 4.0896544e-09], sampled 0.3050286583016999
[2019-03-24 05:03:51,298] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 967482.1612952325 W.
[2019-03-24 05:03:55,492] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00583714], dtype=float32), 0.00796825]
[2019-03-24 05:03:55,494] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.9, 47.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5089222175006263, 6.911200000000001, 6.9112, 121.9260426156618, 367516.2610158193, 367516.2610158189, 117240.9347140959]
[2019-03-24 05:03:55,494] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:03:55,496] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.9999797e-01 1.0282340e-20 2.0693619e-06 2.4061389e-22 1.1268931e-12], sampled 0.258809138671948
[2019-03-24 05:04:11,678] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00583714], dtype=float32), 0.00796825]
[2019-03-24 05:04:11,679] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.66666666666667, 51.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5758392407625482, 6.9112, 6.9112, 121.9260426156618, 424842.2911265926, 424842.2911265926, 126555.2534699749]
[2019-03-24 05:04:11,681] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:04:11,684] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.9999821e-01 6.8162049e-21 1.8222028e-06 1.5483140e-22 8.7965491e-13], sampled 0.9575480458513528
[2019-03-24 05:04:18,667] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00583714], dtype=float32), 0.00796825]
[2019-03-24 05:04:18,668] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.415951835, 74.634316335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7368114497229948, 6.9112, 6.9112, 121.9260426156618, 549018.2870193118, 549018.2870193118, 151595.6531179201]
[2019-03-24 05:04:18,671] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:04:18,673] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.9999654e-01 7.8912882e-20 3.5015426e-06 2.1229627e-21 3.7246603e-12], sampled 0.2701970013348104
[2019-03-24 05:04:25,087] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00583714], dtype=float32), 0.00796825]
[2019-03-24 05:04:25,088] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.335550045, 49.313049995, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.766165556784384, 6.911200000000001, 6.9112, 121.9260426156618, 570208.7670215472, 570208.7670215467, 155545.4117529469]
[2019-03-24 05:04:25,089] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:04:25,093] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.9999905e-01 3.9787564e-22 9.2913626e-07 7.1434794e-24 1.7554565e-13], sampled 0.30077182908920064
[2019-03-24 05:04:25,425] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00583714], dtype=float32), 0.00796825]
[2019-03-24 05:04:25,426] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.66754852, 64.57905795666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.587248792353825, 6.911200000000001, 6.9112, 121.9260426156618, 434365.2404809173, 434365.2404809168, 128208.4399579637]
[2019-03-24 05:04:25,428] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:04:25,430] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.9999785e-01 1.2514936e-20 2.1286905e-06 2.9540627e-22 1.2640959e-12], sampled 0.1911667802667435
[2019-03-24 05:05:26,571] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00583714], dtype=float32), 0.00796825]
[2019-03-24 05:05:26,574] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.1, 80.66666666666666, 1.0, 1.0, 0.6846295506041897, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9258452583227, 854687.2978068204, 854687.2978068204, 176060.0864199414]
[2019-03-24 05:05:26,576] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:05:26,578] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.9997938e-01 2.1911384e-17 2.0588719e-05 9.6654597e-19 1.2250423e-10], sampled 0.3550107570359834
[2019-03-24 05:05:26,579] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 854687.2978068204 W.
[2019-03-24 05:05:35,686] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8361.0016 2339564142.9708 616.0000
[2019-03-24 05:05:36,004] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 05:05:36,180] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7840.1416 2529781811.2082 829.0000
[2019-03-24 05:05:36,309] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 05:05:36,394] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 05:05:37,409] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 225000, evaluation results [225000.0, 7840.141570579064, 2529781811.2081637, 829.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8361.00155136605, 2339564142.970784, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 05:05:58,404] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9999535e-01 4.1421816e-21 4.7039330e-06 1.7798320e-21 1.4587878e-09], sum to 1.0000
[2019-03-24 05:05:58,409] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7514
[2019-03-24 05:05:58,412] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.8, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5685422224095793, 6.9112, 6.9112, 121.9260426156618, 417600.3411074103, 417600.3411074103, 124958.694999299], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 889200.0000, 
sim time next is 889800.0000, 
raw observation next is [21.86666666666667, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5696793838517343, 6.9112, 6.9112, 121.9260426156618, 418778.3653628051, 418778.3653628051, 125224.1709753833], 
processed observation next is [0.0, 0.30434782608695654, 0.36543209876543226, 0.66, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4620992298146679, 0.0, 0.0, 0.8094621288201359, 0.14956370191528753, 0.14956370191528753, 0.24081571341419866], 
reward next is 0.7592, 
noisyNet noise sample is [array([-1.871082], dtype=float32), -1.3104243]. 
=============================================
[2019-03-24 05:06:08,420] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.9997032e-01 1.5290328e-12 2.6583286e-05 3.8660573e-14 3.1555776e-06], sum to 1.0000
[2019-03-24 05:06:08,429] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0845
[2019-03-24 05:06:08,436] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1122599.399747054 W.
[2019-03-24 05:06:08,442] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.45, 41.5, 1.0, 1.0, 0.3027637046886381, 1.0, 1.0, 0.3027637046886381, 1.0, 2.0, 0.5006960235191656, 6.911199999999999, 6.9112, 121.94756008, 1122599.399747054, 1122599.399747055, 255163.3009310459], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1085400.0000, 
sim time next is 1086000.0000, 
raw observation next is [26.6, 41.0, 1.0, 2.0, 0.2559201746938478, 1.0, 2.0, 0.2559201746938478, 1.0, 2.0, 0.4240965164333135, 6.911199999999999, 6.9112, 121.94756008, 950503.5627848747, 950503.5627848752, 237661.460912109], 
processed observation next is [1.0, 0.5652173913043478, 0.5407407407407407, 0.41, 1.0, 1.0, 0.11419068415934264, 1.0, 1.0, 0.11419068415934264, 1.0, 1.0, 0.2801206455416418, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.33946555813745527, 0.33946555813745544, 0.457041270984825], 
reward next is 0.5430, 
noisyNet noise sample is [array([-1.1226121], dtype=float32), -1.4174023]. 
=============================================
[2019-03-24 05:06:08,462] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[43.37549 ]
 [47.189587]
 [44.969868]
 [42.00354 ]
 [42.166958]], R is [[42.09666061]
 [42.18499374]
 [41.76314545]
 [41.3455162 ]
 [41.59678268]].
[2019-03-24 05:06:08,898] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.9999893e-01 2.9030969e-18 1.0359946e-06 3.3802610e-20 1.8533679e-09], sum to 1.0000
[2019-03-24 05:06:08,907] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5786
[2019-03-24 05:06:08,911] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.8, 52.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5735079146690085, 6.9112, 6.9112, 121.9260426156618, 424119.3167940284, 424119.3167940284, 126908.5703617152], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1101600.0000, 
sim time next is 1102200.0000, 
raw observation next is [24.55, 53.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5766427510751517, 6.9112, 6.9112, 121.9260426156618, 426298.4244697895, 426298.4244697895, 127110.9597938902], 
processed observation next is [1.0, 0.782608695652174, 0.46481481481481485, 0.5316666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4708034388439396, 0.0, 0.0, 0.8094621288201359, 0.1522494373106391, 0.1522494373106391, 0.24444415344978884], 
reward next is 0.7556, 
noisyNet noise sample is [array([-0.12204801], dtype=float32), -0.77820694]. 
=============================================
[2019-03-24 05:06:12,720] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9994302e-01 6.9633065e-16 5.7031131e-05 3.5411267e-18 3.2607623e-08], sum to 1.0000
[2019-03-24 05:06:12,727] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4672
[2019-03-24 05:06:12,739] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.75, 65.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6896148921248536, 6.911200000000001, 6.9112, 121.9260426156618, 505322.3740186592, 505322.3740186587, 135622.6696047292], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1169400.0000, 
sim time next is 1170000.0000, 
raw observation next is [21.8, 65.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6845656823590729, 6.9112, 6.9112, 121.9260426156618, 501938.7783165568, 501938.7783165568, 135277.2659821412], 
processed observation next is [1.0, 0.5652173913043478, 0.362962962962963, 0.65, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6057071029488411, 0.0, 0.0, 0.8094621288201359, 0.1792638493987703, 0.1792638493987703, 0.2601485884271946], 
reward next is 0.7399, 
noisyNet noise sample is [array([-2.088878], dtype=float32), -0.99598557]. 
=============================================
[2019-03-24 05:06:12,754] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[60.64194 ]
 [57.85737 ]
 [55.530025]
 [53.689842]
 [54.29385 ]], R is [[61.62306976]
 [61.74602509]
 [61.86577606]
 [61.97132492]
 [62.07992172]].
[2019-03-24 05:06:13,028] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9999988e-01 1.2276364e-20 1.0504967e-07 8.0904137e-21 4.8296488e-11], sum to 1.0000
[2019-03-24 05:06:13,036] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0461
[2019-03-24 05:06:13,039] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.33333333333333, 80.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5931570529865716, 6.9112, 6.9112, 121.9260426156618, 438673.1824347615, 438673.1824347615, 128714.6240482215], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1192200.0000, 
sim time next is 1192800.0000, 
raw observation next is [20.26666666666667, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5923224474367388, 6.9112, 6.9112, 121.9260426156618, 438048.4804608754, 438048.4804608754, 128633.416206407], 
processed observation next is [1.0, 0.8260869565217391, 0.3061728395061729, 0.81, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4904030592959234, 0.0, 0.0, 0.8094621288201359, 0.15644588587888406, 0.15644588587888406, 0.2473719542430904], 
reward next is 0.7526, 
noisyNet noise sample is [array([0.9107195], dtype=float32), -0.012929401]. 
=============================================
[2019-03-24 05:06:17,907] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.000000e+00 9.328025e-25 9.186123e-10 5.247757e-26 1.974095e-13], sum to 1.0000
[2019-03-24 05:06:17,917] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4723
[2019-03-24 05:06:17,921] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.13333333333333, 61.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6752271366180383, 6.911200000000001, 6.9112, 121.9260426156618, 504494.9710044519, 504494.9710044515, 141451.3154095395], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1277400.0000, 
sim time next is 1278000.0000, 
raw observation next is [25.0, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6798881021564246, 6.9112, 6.9112, 121.9260426156618, 507987.2172869714, 507987.2172869714, 141980.9982388229], 
processed observation next is [1.0, 0.8260869565217391, 0.48148148148148145, 0.62, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5998601276955307, 0.0, 0.0, 0.8094621288201359, 0.18142400617391835, 0.18142400617391835, 0.2730403812285056], 
reward next is 0.7270, 
noisyNet noise sample is [array([-2.0495374], dtype=float32), 0.738416]. 
=============================================
[2019-03-24 05:06:17,936] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[78.42652 ]
 [78.64063 ]
 [79.046715]
 [79.56622 ]
 [79.61622 ]], R is [[77.71363831]
 [77.66448212]
 [77.61652374]
 [77.56873322]
 [77.52132416]].
[2019-03-24 05:06:24,415] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9846989e-01 3.6808988e-21 1.5301214e-03 1.4868043e-20 6.5617138e-09], sum to 1.0000
[2019-03-24 05:06:24,425] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1770
[2019-03-24 05:06:24,432] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.15, 47.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5400445485598647, 6.9112, 6.9112, 121.9260426156618, 396351.6650192451, 396351.6650192451, 122341.860840488], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1408200.0000, 
sim time next is 1408800.0000, 
raw observation next is [25.5, 46.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5474881852203336, 6.9112, 6.9112, 121.9260426156618, 402611.0206456096, 402611.0206456096, 123362.813634825], 
processed observation next is [0.0, 0.30434782608695654, 0.5, 0.46333333333333326, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.434360231525417, 0.0, 0.0, 0.8094621288201359, 0.14378965023057486, 0.14378965023057486, 0.23723618006697114], 
reward next is 0.7628, 
noisyNet noise sample is [array([-0.8038532], dtype=float32), 0.54497933]. 
=============================================
[2019-03-24 05:06:25,612] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-24 05:06:25,614] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:06:25,615] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:06:25,616] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:06:25,617] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:06:25,619] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:06:25,620] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:06:25,621] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:06:25,622] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:06:25,623] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:06:25,623] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:06:25,640] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run11
[2019-03-24 05:06:25,641] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run11
[2019-03-24 05:06:25,641] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run11
[2019-03-24 05:06:25,718] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run11
[2019-03-24 05:06:25,719] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run11
[2019-03-24 05:06:28,491] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0067023], dtype=float32), 0.009070841]
[2019-03-24 05:06:28,491] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [30.87770819, 34.17127597, 1.0, 2.0, 0.6895602001213172, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.926042566778, 854178.6024788739, 854178.6024788739, 176859.7666330372]
[2019-03-24 05:06:28,492] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:06:28,494] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.9999332e-01 2.1404728e-20 6.6439843e-06 7.2480861e-21 4.6569948e-09], sampled 0.35006179320301045
[2019-03-24 05:06:28,498] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 854178.6024788739 W.
[2019-03-24 05:06:41,890] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0067023], dtype=float32), 0.009070841]
[2019-03-24 05:06:41,894] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.33333333333333, 68.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.546708489734174, 6.911200000000001, 6.9112, 121.9260426156618, 401414.1982518285, 401414.1982518281, 122992.3531846061]
[2019-03-24 05:06:41,895] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:06:41,899] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.99999881e-01 5.06048262e-26 1.45004364e-07 1.16585168e-26
 1.33530504e-11], sampled 0.9271631239281621
[2019-03-24 05:06:54,919] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0067023], dtype=float32), 0.009070841]
[2019-03-24 05:06:54,920] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.20652917, 71.774345285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5985258304917863, 6.9112, 6.9112, 121.9260426156618, 444172.5360212696, 444172.5360212696, 130184.7700710214]
[2019-03-24 05:06:54,921] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:06:54,923] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.9999988e-01 2.7732544e-26 1.4479238e-07 6.2776014e-27 1.1637655e-11], sampled 0.31543774115888923
[2019-03-24 05:07:04,846] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0067023], dtype=float32), 0.009070841]
[2019-03-24 05:07:04,847] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.689514895, 71.50832756, 1.0, 2.0, 0.9796932837806513, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.019547023569425, 6.9112, 121.9253303133053, 1172328.960924225, 1116845.92504813, 235870.9794660384]
[2019-03-24 05:07:04,847] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:07:04,849] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.99981523e-01 1.09491183e-19 1.85128320e-05 4.15290098e-20
 1.40969405e-08], sampled 0.37325551218502906
[2019-03-24 05:07:04,850] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1172328.960924225 W.
[2019-03-24 05:07:17,698] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0067023], dtype=float32), 0.009070841]
[2019-03-24 05:07:17,700] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.5, 74.0, 1.0, 2.0, 0.7266545208373887, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 828197.0036673112, 828197.0036673112, 181246.0972287277]
[2019-03-24 05:07:17,701] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:07:17,704] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.9998951e-01 4.0278956e-20 1.0520981e-05 1.4612467e-20 7.6425817e-09], sampled 0.7556841680775174
[2019-03-24 05:07:17,706] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 828197.0036673112 W.
[2019-03-24 05:07:21,977] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0067023], dtype=float32), 0.009070841]
[2019-03-24 05:07:21,979] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.36666666666667, 80.83333333333333, 1.0, 2.0, 0.7366322807836106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 839575.2813244447, 839575.2813244447, 183199.2047997858]
[2019-03-24 05:07:21,980] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:07:21,982] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.9999726e-01 1.5113443e-22 2.7338281e-06 4.8343993e-23 7.6125217e-10], sampled 0.49542493516247055
[2019-03-24 05:07:21,986] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 839575.2813244447 W.
[2019-03-24 05:07:39,795] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0067023], dtype=float32), 0.009070841]
[2019-03-24 05:07:39,797] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.44148053, 88.21953978833334, 1.0, 2.0, 0.6295771467642124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 717502.2820306332, 717502.2820306332, 163239.634169193]
[2019-03-24 05:07:39,797] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:07:39,799] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.9999666e-01 6.0587234e-22 3.3610420e-06 1.9998918e-22 1.2557911e-09], sampled 0.7739163717850512
[2019-03-24 05:07:39,800] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 717502.2820306332 W.
[2019-03-24 05:07:46,598] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0067023], dtype=float32), 0.009070841]
[2019-03-24 05:07:46,600] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [34.0, 39.0, 1.0, 2.0, 0.6776345327303467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 788571.0094617154, 788571.0094617154, 172742.9778801264]
[2019-03-24 05:07:46,600] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:07:46,603] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.9999344e-01 6.6823220e-21 6.5476770e-06 2.3556424e-21 3.4707337e-09], sampled 0.5114342264915865
[2019-03-24 05:07:46,604] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 788571.0094617154 W.
[2019-03-24 05:08:13,820] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 05:08:13,857] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8402.8788 2292956496.3333 697.0000
[2019-03-24 05:08:14,005] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8632.2426 2219246464.9484 543.0000
[2019-03-24 05:08:14,009] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8360.9859 2339485308.5124 616.0000
[2019-03-24 05:08:14,103] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 05:08:15,119] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 250000, evaluation results [250000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8632.242577039086, 2219246464.948387, 543.0, 8360.985930709368, 2339485308.5123887, 616.0, 8402.878782042042, 2292956496.3332763, 697.0]
[2019-03-24 05:08:15,489] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.00000000e+00 1.15239355e-24 7.69031283e-10 7.92463317e-24
 1.42559003e-11], sum to 1.0000
[2019-03-24 05:08:15,498] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8374
[2019-03-24 05:08:15,501] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.85, 26.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6246145262115563, 6.9112, 6.9112, 121.9260426156618, 463004.6381789575, 463004.6381789575, 132310.4803135818], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1425000.0000, 
sim time next is 1425600.0000, 
raw observation next is [32.0, 26.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6272852181562566, 6.911200000000001, 6.9112, 121.9260426156618, 465251.0213970454, 465251.0213970449, 132742.7489549461], 
processed observation next is [0.0, 0.5217391304347826, 0.7407407407407407, 0.26, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5341065226953207, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16616107907037336, 0.16616107907037317, 0.25527451722105016], 
reward next is 0.7447, 
noisyNet noise sample is [array([-1.7137142], dtype=float32), 0.25714752]. 
=============================================
[2019-03-24 05:08:26,387] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9954188e-01 7.6791467e-16 4.5708448e-04 9.3484041e-16 1.1037445e-06], sum to 1.0000
[2019-03-24 05:08:26,394] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9327
[2019-03-24 05:08:26,402] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 802864.5977711327 W.
[2019-03-24 05:08:26,406] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [19.9, 80.0, 1.0, 2.0, 0.3192238443466063, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5409001225946666, 6.9112, 6.9112, 121.9260426156618, 802864.5977711327, 802864.5977711327, 195744.168206036], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1681200.0000, 
sim time next is 1681800.0000, 
raw observation next is [20.08333333333333, 79.33333333333334, 1.0, 2.0, 0.3234394907685314, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5461241628547822, 6.911199999999999, 6.9112, 121.9260426156618, 811750.7665192467, 811750.7665192472, 197109.7233914657], 
processed observation next is [1.0, 0.4782608695652174, 0.29938271604938255, 0.7933333333333334, 1.0, 1.0, 0.19457082234348977, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.43265520356847764, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.28991098804258814, 0.2899109880425883, 0.37905716036820325], 
reward next is 0.6209, 
noisyNet noise sample is [array([1.5164077], dtype=float32), -1.1539327]. 
=============================================
[2019-03-24 05:08:34,504] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 3.7829575e-21 2.4102844e-09 4.8070695e-22 2.1791827e-11], sum to 1.0000
[2019-03-24 05:08:34,512] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2322
[2019-03-24 05:08:34,516] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.65, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5722404021954408, 6.911199999999999, 6.9112, 121.9260426156618, 420734.0692121024, 420734.0692121029, 125485.5872745175], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1798200.0000, 
sim time next is 1798800.0000, 
raw observation next is [19.2, 82.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5601790832435561, 6.911200000000001, 6.9112, 121.9260426156618, 410312.071202925, 410312.0712029245, 123695.6477511801], 
processed observation next is [1.0, 0.8260869565217391, 0.26666666666666666, 0.8233333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.45022385405444515, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14654002542961608, 0.1465400254296159, 0.23787624567534635], 
reward next is 0.7621, 
noisyNet noise sample is [array([-0.8554621], dtype=float32), -1.8789034]. 
=============================================
[2019-03-24 05:08:39,656] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 6.7581625e-23 1.7454795e-12 2.2222437e-26 1.6032542e-13], sum to 1.0000
[2019-03-24 05:08:39,664] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6885
[2019-03-24 05:08:39,671] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.26666666666667, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6586118938299026, 6.911200000000001, 6.9112, 121.9260426156618, 491677.7582625075, 491677.758262507, 138785.2337710832], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1902000.0000, 
sim time next is 1902600.0000, 
raw observation next is [20.2, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6534621769380664, 6.911200000000001, 6.9112, 121.9260426156618, 487721.0829431233, 487721.0829431229, 138078.166663423], 
processed observation next is [1.0, 0.0, 0.3037037037037037, 0.92, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.566827721172583, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17418610105111546, 0.17418610105111532, 0.2655349358911981], 
reward next is 0.7345, 
noisyNet noise sample is [array([0.55934286], dtype=float32), 0.20748818]. 
=============================================
[2019-03-24 05:08:40,444] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 2.6685652e-22 7.3862250e-11 8.3666292e-25 1.2387832e-09], sum to 1.0000
[2019-03-24 05:08:40,450] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6512
[2019-03-24 05:08:40,456] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.6, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6256371668453201, 6.9112, 6.9112, 121.9260426156618, 465392.3996552366, 465392.3996552366, 133597.6715975098], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1911600.0000, 
sim time next is 1912200.0000, 
raw observation next is [19.6, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6139596813393736, 6.9112, 6.9112, 121.9260426156618, 456722.3095725488, 456722.3095725488, 132478.4351580848], 
processed observation next is [1.0, 0.13043478260869565, 0.28148148148148155, 0.92, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5174496016742169, 0.0, 0.0, 0.8094621288201359, 0.16311511056162456, 0.16311511056162456, 0.2547662214578554], 
reward next is 0.7452, 
noisyNet noise sample is [array([-0.87615865], dtype=float32), 0.9165567]. 
=============================================
[2019-03-24 05:08:45,083] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 3.8780284e-24 3.4651156e-12 1.0194230e-24 1.2178232e-12], sum to 1.0000
[2019-03-24 05:08:45,090] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6842
[2019-03-24 05:08:45,093] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.33333333333334, 92.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6084674600366925, 6.911200000000001, 6.9112, 121.9260426156618, 451999.6580332079, 451999.6580332075, 131446.9176104824], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2000400.0000, 
sim time next is 2001000.0000, 
raw observation next is [19.31666666666667, 92.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6081975329206407, 6.911199999999999, 6.9112, 121.9260426156618, 451808.4452332759, 451808.4452332763, 131428.1299481105], 
processed observation next is [0.0, 0.13043478260869565, 0.27098765432098776, 0.9283333333333332, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5102469161508009, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16136015901188425, 0.16136015901188439, 0.2527464037463663], 
reward next is 0.7473, 
noisyNet noise sample is [array([0.13351068], dtype=float32), 0.070544794]. 
=============================================
[2019-03-24 05:08:45,107] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[77.863914]
 [77.59701 ]
 [78.17758 ]
 [78.05927 ]
 [77.89728 ]], R is [[77.96379089]
 [77.93136597]
 [77.89920807]
 [77.86726379]
 [77.83554077]].
[2019-03-24 05:08:45,499] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 8.3924847e-26 8.2252233e-13 7.9157163e-25 6.3441993e-13], sum to 1.0000
[2019-03-24 05:08:45,503] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4544
[2019-03-24 05:08:45,507] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.15, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8717357576356268, 6.9112, 6.9112, 121.9260426156618, 638598.2588006834, 638598.2588006834, 172096.1983314953], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2038200.0000, 
sim time next is 2038800.0000, 
raw observation next is [28.2, 63.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8762665306174081, 6.911200000000001, 6.9112, 121.9260426156618, 641478.322903193, 641478.3229031925, 172778.6600641994], 
processed observation next is [0.0, 0.6086956521739131, 0.6, 0.6300000000000001, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.84533316327176, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22909940103685464, 0.22909940103685447, 0.3322666539696142], 
reward next is 0.6677, 
noisyNet noise sample is [array([2.0539656], dtype=float32), 0.6596578]. 
=============================================
[2019-03-24 05:08:51,029] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 5.2219648e-23 3.7393725e-12 4.4057763e-25 7.3466339e-14], sum to 1.0000
[2019-03-24 05:08:51,036] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5273
[2019-03-24 05:08:51,039] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.83333333333333, 52.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9173005925717893, 6.911199999999999, 6.9112, 121.9260426156618, 666944.4972653025, 666944.4972653029, 179043.0603411371], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2126400.0000, 
sim time next is 2127000.0000, 
raw observation next is [30.91666666666667, 51.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9122302531767811, 6.911200000000001, 6.9112, 121.9260426156618, 663924.7592124519, 663924.7592124514, 178250.7826747206], 
processed observation next is [0.0, 0.6086956521739131, 0.7006172839506175, 0.5166666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8902878164709762, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23711598543301854, 0.23711598543301837, 0.342789966682155], 
reward next is 0.6572, 
noisyNet noise sample is [array([0.18667322], dtype=float32), 0.6477199]. 
=============================================
[2019-03-24 05:08:51,059] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[66.88421 ]
 [66.80671 ]
 [66.72518 ]
 [66.652504]
 [66.60099 ]], R is [[66.96237183]
 [66.94843292]
 [66.93312836]
 [66.91662598]
 [66.89916229]].
[2019-03-24 05:09:00,609] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.9746972e-17 2.2814368e-09 7.3461248e-19 1.2325618e-08], sum to 1.0000
[2019-03-24 05:09:00,616] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2336
[2019-03-24 05:09:00,630] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1124927.719503664 W.
[2019-03-24 05:09:00,635] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.2, 68.33333333333333, 1.0, 2.0, 0.4807850587479258, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7683421848613824, 6.911199999999999, 6.9112, 121.9260426156618, 1124927.719503664, 1124927.719503665, 249761.3901873944], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2306400.0000, 
sim time next is 2307000.0000, 
raw observation next is [26.25, 67.66666666666667, 1.0, 2.0, 0.319152548939423, 1.0, 1.0, 0.319152548939423, 1.0, 2.0, 0.5089466952678854, 6.911199999999999, 6.9112, 121.94756008, 1109007.114605032, 1109007.114605032, 263513.64964881], 
processed observation next is [1.0, 0.6956521739130435, 0.5277777777777778, 0.6766666666666667, 1.0, 1.0, 0.18946732016597978, 1.0, 0.5, 0.18946732016597978, 1.0, 1.0, 0.3861833690848567, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.39607396950179713, 0.39607396950179713, 0.5067570185554038], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.05900108], dtype=float32), -0.40438935]. 
=============================================
[2019-03-24 05:09:00,655] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[57.37342 ]
 [56.042065]
 [55.162163]
 [54.21598 ]
 [52.97638 ]], R is [[56.47992325]
 [56.43481445]
 [56.34521484]
 [56.32459641]
 [56.2981987 ]].
[2019-03-24 05:09:03,228] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9999940e-01 1.8187311e-17 4.8610920e-09 9.6503798e-16 5.3724011e-07], sum to 1.0000
[2019-03-24 05:09:03,236] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2044
[2019-03-24 05:09:03,244] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1113221.666762885 W.
[2019-03-24 05:09:03,248] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.58333333333334, 40.16666666666667, 1.0, 2.0, 0.4552266982327005, 1.0, 2.0, 0.4552266982327005, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1113221.666762885, 1113221.666762886, 224869.9862675896], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2368200.0000, 
sim time next is 2368800.0000, 
raw observation next is [28.7, 40.0, 1.0, 2.0, 0.4524802300426587, 1.0, 2.0, 0.4524802300426587, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1106910.717891733, 1106910.717891733, 224057.7795718087], 
processed observation next is [1.0, 0.43478260869565216, 0.6185185185185185, 0.4, 1.0, 1.0, 0.34819075005078415, 1.0, 1.0, 0.34819075005078415, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3953252563899046, 0.3953252563899046, 0.43088034533040137], 
reward next is 0.5691, 
noisyNet noise sample is [array([-0.18586552], dtype=float32), 0.89699465]. 
=============================================
[2019-03-24 05:09:03,321] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-24 05:09:03,322] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:09:03,323] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:09:03,324] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:09:03,329] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:09:03,331] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:09:03,332] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:09:03,332] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:09:03,333] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:09:03,333] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:09:03,334] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:09:03,350] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run12
[2019-03-24 05:09:03,351] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run12
[2019-03-24 05:09:03,351] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run12
[2019-03-24 05:09:03,431] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run12
[2019-03-24 05:09:03,454] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run12
[2019-03-24 05:09:16,254] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00644235], dtype=float32), 0.009075018]
[2019-03-24 05:09:16,255] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.45, 64.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6415881681205078, 6.911200000000001, 6.9112, 121.9260426156618, 477617.5826328609, 477617.5826328604, 135475.6361094023]
[2019-03-24 05:09:16,257] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:09:16,262] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.5750647e-22 8.2443855e-13 2.4734940e-23 1.5958939e-11], sampled 0.5610838226583995
[2019-03-24 05:09:17,558] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00644235], dtype=float32), 0.009075018]
[2019-03-24 05:09:17,560] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [18.83333333333334, 45.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6125066613775062, 6.9112, 6.9112, 121.9260426156618, 437358.5942489271, 437358.5942489271, 103324.2967213333]
[2019-03-24 05:09:17,561] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:09:17,563] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.2458796e-21 2.3050353e-12 2.0355656e-22 3.8859246e-11], sampled 0.16192527655281497
[2019-03-24 05:09:25,843] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00644235], dtype=float32), 0.009075018]
[2019-03-24 05:09:25,845] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.6, 81.66666666666666, 1.0, 2.0, 0.5391505921500672, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156403, 675783.770495671, 675783.770495671, 150098.6126584751]
[2019-03-24 05:09:25,846] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:09:25,848] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 2.8590294e-18 2.3602131e-10 6.9158565e-19 2.6326679e-09], sampled 0.5823312812997186
[2019-03-24 05:09:35,150] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00644235], dtype=float32), 0.009075018]
[2019-03-24 05:09:35,152] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.83333333333333, 98.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8849910770475354, 6.911200000000001, 6.9112, 121.9260426156618, 649008.1765999633, 649008.1765999629, 173678.281122062]
[2019-03-24 05:09:35,152] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:09:35,155] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 4.5439559e-22 1.7211377e-12 7.6716559e-23 3.1975721e-11], sampled 0.3953141153338424
[2019-03-24 05:10:12,204] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00644235], dtype=float32), 0.009075018]
[2019-03-24 05:10:12,205] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.75, 60.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8223761830925634, 6.9112, 6.9112, 121.9260426156618, 608094.8814026205, 608094.8814026205, 164255.1665463641]
[2019-03-24 05:10:12,208] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:10:12,210] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 5.6473025e-23 5.3799304e-13 8.6628642e-24 1.1193491e-11], sampled 0.7731489503983255
[2019-03-24 05:10:34,163] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00644235], dtype=float32), 0.009075018]
[2019-03-24 05:10:34,164] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.579984225, 80.46498697499999, 1.0, 2.0, 0.9899845126415138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.082953938812211, 6.9112, 121.9252667884331, 1216563.245950849, 1128610.437741948, 238318.1379604364]
[2019-03-24 05:10:34,165] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:10:34,169] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.5026773e-17 1.0324730e-09 4.2407602e-18 1.0094858e-08], sampled 0.385996007477048
[2019-03-24 05:10:34,169] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1216563.245950849 W.
[2019-03-24 05:10:41,748] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00644235], dtype=float32), 0.009075018]
[2019-03-24 05:10:41,748] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.931366955, 90.71425970333334, 1.0, 2.0, 0.6595914669855911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 751725.0978819978, 751725.0978819978, 168636.6707886143]
[2019-03-24 05:10:41,749] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:10:41,751] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 8.7311253e-20 3.3904695e-11 1.8123993e-20 4.7754611e-10], sampled 0.13295029984378282
[2019-03-24 05:10:41,752] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 751725.0978819978 W.
[2019-03-24 05:10:48,135] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00644235], dtype=float32), 0.009075018]
[2019-03-24 05:10:48,136] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.09944003666667, 94.00326774166668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.931149609243449, 6.9112, 6.9112, 121.9260426156618, 672768.9856810818, 672768.9856810818, 181524.6657282607]
[2019-03-24 05:10:48,137] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:10:48,140] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 5.5247622e-22 1.5879531e-12 9.0823841e-23 2.8213524e-11], sampled 0.09457048885349328
[2019-03-24 05:10:51,877] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8363.4371 2339475986.9735 616.0000
[2019-03-24 05:10:51,987] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8558.6918 2258312516.3468 536.0000
[2019-03-24 05:10:52,070] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 05:10:52,252] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 05:10:52,313] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 05:10:53,327] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 275000, evaluation results [275000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8558.691802686531, 2258312516.34677, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8363.437110714249, 2339475986.973477, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 05:11:01,249] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9999881e-01 1.1658425e-17 1.5486146e-09 3.9384876e-19 1.1613547e-06], sum to 1.0000
[2019-03-24 05:11:01,263] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1287
[2019-03-24 05:11:01,269] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.63333333333333, 57.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8334799245960732, 6.911199999999999, 6.9112, 121.9260426156618, 620149.2569218939, 620149.2569218944, 155834.3871413973], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2518800.0000, 
sim time next is 2519400.0000, 
raw observation next is [24.56666666666667, 57.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8174003069513254, 6.9112, 6.9112, 121.9260426156618, 608156.2517053074, 608156.2517053074, 154012.0575726407], 
processed observation next is [1.0, 0.13043478260869565, 0.46543209876543223, 0.5766666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7717503836891567, 0.0, 0.0, 0.8094621288201359, 0.21719866132332408, 0.21719866132332408, 0.2961770337935398], 
reward next is 0.7038, 
noisyNet noise sample is [array([0.38749567], dtype=float32), -0.4033209]. 
=============================================
[2019-03-24 05:11:01,368] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9967873e-01 4.5087077e-16 3.2309850e-07 2.2031432e-16 3.2097285e-04], sum to 1.0000
[2019-03-24 05:11:01,375] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3392
[2019-03-24 05:11:01,378] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.98333333333333, 55.66666666666667, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8379615510609552, 6.911200000000001, 6.9112, 121.9260426156618, 624834.7427386107, 624834.7427386102, 157646.9790891288], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2515800.0000, 
sim time next is 2516400.0000, 
raw observation next is [24.9, 56.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7939691996877363, 6.9112, 6.9112, 121.9260426156618, 590928.741972025, 590928.741972025, 151529.317328123], 
processed observation next is [1.0, 0.13043478260869565, 0.47777777777777775, 0.56, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7424614996096703, 0.0, 0.0, 0.8094621288201359, 0.21104597927572322, 0.21104597927572322, 0.29140253332331345], 
reward next is 0.7086, 
noisyNet noise sample is [array([-1.3861405], dtype=float32), 0.90182555]. 
=============================================
[2019-03-24 05:11:01,606] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9992239e-01 3.9595378e-16 5.3187096e-06 2.2257654e-15 7.2201401e-05], sum to 1.0000
[2019-03-24 05:11:01,614] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1242
[2019-03-24 05:11:01,619] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1730993.971677372 W.
[2019-03-24 05:11:01,622] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [33.46666666666667, 32.33333333333334, 1.0, 2.0, 0.7365086005510131, 1.0, 1.0, 0.7365086005510131, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1730993.971677372, 1730993.971677372, 320715.7455766006], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2562000.0000, 
sim time next is 2562600.0000, 
raw observation next is [33.43333333333333, 32.66666666666666, 1.0, 2.0, 0.8582087927768709, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9696384748330572, 6.911199999999999, 6.9112, 121.9260426156618, 1728602.946784842, 1728602.946784842, 342771.3263450974], 
processed observation next is [1.0, 0.6521739130434783, 0.7938271604938271, 0.32666666666666655, 1.0, 1.0, 0.8312009437819892, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9620480935413214, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6173581952803008, 0.6173581952803008, 0.6591756275867258], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3980213], dtype=float32), 1.5575382]. 
=============================================
[2019-03-24 05:11:01,809] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9984884e-01 1.1580571e-18 2.4754281e-06 2.2851836e-18 1.4857903e-04], sum to 1.0000
[2019-03-24 05:11:01,814] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9656
[2019-03-24 05:11:01,819] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.53333333333333, 44.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8178350216019962, 6.9112, 6.9112, 121.9260426156618, 611129.583010579, 611129.583010579, 157722.0291907505], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2533800.0000, 
sim time next is 2534400.0000, 
raw observation next is [28.8, 44.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9296947226897198, 6.911199999999999, 6.9112, 121.9260426156618, 694792.0790009631, 694792.0790009636, 171397.1182697328], 
processed observation next is [1.0, 0.34782608695652173, 0.6222222222222222, 0.44, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9121184033621496, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2481400282146297, 0.24814002821462985, 0.32960984282640926], 
reward next is 0.6704, 
noisyNet noise sample is [array([-0.14802061], dtype=float32), -0.067481056]. 
=============================================
[2019-03-24 05:11:10,459] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.9999726e-01 5.8058373e-20 3.3218417e-10 1.5311640e-19 2.7949009e-06], sum to 1.0000
[2019-03-24 05:11:10,468] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3895
[2019-03-24 05:11:10,476] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.2, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7486511526716836, 6.911199999999999, 6.9112, 121.9260426156618, 559069.157127115, 559069.1571271154, 151663.4567899397], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2696400.0000, 
sim time next is 2697000.0000, 
raw observation next is [21.16666666666667, 91.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7327792414136801, 6.9112, 6.9112, 121.9260426156618, 547500.8354499525, 547500.8354499525, 149182.1432561269], 
processed observation next is [0.0, 0.21739130434782608, 0.33950617283950635, 0.9133333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6659740517671, 0.0, 0.0, 0.8094621288201359, 0.19553601266069734, 0.19553601266069734, 0.28688873703101325], 
reward next is 0.7131, 
noisyNet noise sample is [array([0.05700599], dtype=float32), 0.045130413]. 
=============================================
[2019-03-24 05:11:10,493] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[67.798546]
 [67.62664 ]
 [67.51723 ]
 [67.42196 ]
 [67.31516 ]], R is [[67.90455627]
 [67.93384552]
 [67.95744324]
 [67.97534943]
 [67.98766327]].
[2019-03-24 05:11:10,558] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 2.9657328e-22 9.8651200e-15 5.1899376e-21 4.9289731e-08], sum to 1.0000
[2019-03-24 05:11:10,568] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2926
[2019-03-24 05:11:10,571] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.03333333333333, 84.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6705800427412125, 6.911200000000001, 6.9112, 121.9260426156618, 500493.2848324693, 500493.2848324688, 139837.2591105975], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2699400.0000, 
sim time next is 2700000.0000, 
raw observation next is [21.0, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6556955565435773, 6.911200000000001, 6.9112, 121.9260426156618, 488877.1281617636, 488877.1281617631, 137645.7501582399], 
processed observation next is [0.0, 0.2608695652173913, 0.3333333333333333, 0.83, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5696194456794715, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.174598974343487, 0.1745989743434868, 0.2647033656889229], 
reward next is 0.7353, 
noisyNet noise sample is [array([0.21030562], dtype=float32), 0.17156865]. 
=============================================
[2019-03-24 05:11:10,585] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[73.509   ]
 [73.555756]
 [73.58441 ]
 [73.57674 ]
 [73.54581 ]], R is [[73.52880096]
 [73.52458954]
 [73.5160141 ]
 [73.50296021]
 [73.48548126]].
[2019-03-24 05:11:10,637] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.9970919e-01 8.8723643e-21 1.4990693e-09 8.1596521e-20 2.9082331e-04], sum to 1.0000
[2019-03-24 05:11:10,643] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2146
[2019-03-24 05:11:10,646] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.05, 92.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8551402890101766, 6.9112, 6.9112, 121.9260426156618, 630841.836855951, 630841.836855951, 168844.0847401743], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2688600.0000, 
sim time next is 2689200.0000, 
raw observation next is [23.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8624548376542425, 6.911199999999999, 6.9112, 121.9260426156618, 635486.391906922, 635486.3919069223, 169995.5703975945], 
processed observation next is [0.0, 0.13043478260869565, 0.4074074074074074, 0.94, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8280685470678031, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22695942568104358, 0.22695942568104369, 0.32691455845691253], 
reward next is 0.6731, 
noisyNet noise sample is [array([0.49795288], dtype=float32), 0.38855913]. 
=============================================
[2019-03-24 05:11:13,207] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.9998784e-01 2.0092475e-16 1.6707336e-08 1.0610072e-15 1.2153009e-05], sum to 1.0000
[2019-03-24 05:11:13,215] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3352
[2019-03-24 05:11:13,220] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 701707.3160492858 W.
[2019-03-24 05:11:13,226] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 54.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9714525751494597, 6.911200000000001, 6.9112, 121.9259664681445, 701707.3160492858, 701707.3160492853, 187159.4169476494], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2745000.0000, 
sim time next is 2745600.0000, 
raw observation next is [30.66666666666667, 56.66666666666666, 1.0, 1.0, 0.3107911179457228, 1.0, 1.0, 0.3107911179457228, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 708386.6123708332, 708386.6123708336, 183070.6525602499], 
processed observation next is [0.0, 0.782608695652174, 0.6913580246913582, 0.5666666666666665, 1.0, 0.5, 0.17951323564966998, 1.0, 0.5, 0.17951323564966998, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.252995218703869, 0.25299521870386915, 0.3520589472312498], 
reward next is 0.6479, 
noisyNet noise sample is [array([1.404546], dtype=float32), 0.26054487]. 
=============================================
[2019-03-24 05:11:20,050] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.8939051e-16 1.0358009e-12 7.8608840e-19 2.8586375e-10], sum to 1.0000
[2019-03-24 05:11:20,063] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5776
[2019-03-24 05:11:20,069] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 723227.0545957246 W.
[2019-03-24 05:11:20,077] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.2, 97.0, 1.0, 2.0, 0.3088050168136739, 1.0, 2.0, 0.3088050168136739, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 723227.0545957246, 723227.0545957246, 183495.9463599985], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2867400.0000, 
sim time next is 2868000.0000, 
raw observation next is [22.26666666666667, 96.0, 1.0, 2.0, 0.2004670279815299, 1.0, 2.0, 0.2004670279815299, 1.0, 1.0, 0.3201807984829979, 6.9112, 6.9112, 121.94756008, 701754.6573358857, 701754.6573358857, 220669.1874357016], 
processed observation next is [1.0, 0.17391304347826086, 0.38024691358024704, 0.96, 1.0, 1.0, 0.04817503331134512, 1.0, 1.0, 0.04817503331134512, 1.0, 0.5, 0.15022599810374737, 0.0, 0.0, 0.8096049824067558, 0.2506266633342449, 0.2506266633342449, 0.42436382199173384], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.6135758], dtype=float32), -0.0043257545]. 
=============================================
[2019-03-24 05:11:20,094] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[47.710636]
 [47.957985]
 [47.844677]
 [47.537804]
 [47.308094]], R is [[47.58916092]
 [47.76039124]
 [47.85172272]
 [47.97390366]
 [47.49416351]].
[2019-03-24 05:11:24,195] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9646145e-01 1.0452249e-08 4.0517803e-06 1.8792397e-09 3.5344877e-03], sum to 1.0000
[2019-03-24 05:11:24,201] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4045
[2019-03-24 05:11:24,207] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1871524.27634004 W.
[2019-03-24 05:11:24,211] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.16666666666667, 83.16666666666667, 1.0, 2.0, 0.820495101642803, 1.0, 2.0, 0.820495101642803, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1871524.27634004, 1871524.27634004, 352297.2259375444], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2981400.0000, 
sim time next is 2982000.0000, 
raw observation next is [28.33333333333334, 82.33333333333334, 1.0, 2.0, 0.7627980305944293, 1.0, 2.0, 0.7627980305944293, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1739790.850350177, 1739790.850350177, 328622.9235701787], 
processed observation next is [1.0, 0.5217391304347826, 0.6049382716049385, 0.8233333333333335, 1.0, 1.0, 0.7176167030886063, 1.0, 1.0, 0.7176167030886063, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6213538751250632, 0.6213538751250632, 0.6319671607118821], 
reward next is 0.3680, 
noisyNet noise sample is [array([0.36708266], dtype=float32), 1.8872648]. 
=============================================
[2019-03-24 05:11:24,231] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[25.725359]
 [25.145947]
 [24.452723]
 [24.997438]
 [24.650831]], R is [[26.9936676 ]
 [27.04623795]
 [26.77577591]
 [26.50801849]
 [26.242939  ]].
[2019-03-24 05:11:25,680] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.9924183e-01 6.7532415e-09 5.7819070e-06 3.9328345e-08 7.5236452e-04], sum to 1.0000
[2019-03-24 05:11:25,686] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3860
[2019-03-24 05:11:25,691] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1697949.741419793 W.
[2019-03-24 05:11:25,698] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.66666666666666, 90.66666666666666, 1.0, 2.0, 0.7444705334043309, 1.0, 1.0, 0.7444705334043309, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1697949.741419793, 1697949.741419793, 321342.8687649313], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2994000.0000, 
sim time next is 2994600.0000, 
raw observation next is [25.83333333333334, 89.83333333333333, 1.0, 2.0, 0.7489084318802219, 1.0, 2.0, 0.7489084318802219, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1708081.146490069, 1708081.14649007, 323094.7310616039], 
processed observation next is [1.0, 0.6521739130434783, 0.5123456790123458, 0.8983333333333333, 1.0, 1.0, 0.7010814665240738, 1.0, 1.0, 0.7010814665240738, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6100289808893103, 0.6100289808893107, 0.6213360212723151], 
reward next is 0.3787, 
noisyNet noise sample is [array([-1.1261], dtype=float32), -1.9973365]. 
=============================================
[2019-03-24 05:11:27,131] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.6010840e-01 2.0556334e-08 5.8293936e-06 2.1779393e-07 3.9885517e-02], sum to 1.0000
[2019-03-24 05:11:27,135] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4345
[2019-03-24 05:11:27,140] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 695432.0914917601 W.
[2019-03-24 05:11:27,152] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.6, 97.33333333333333, 1.0, 2.0, 0.6061229565575258, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 695432.0914917601, 695432.0914917601, 159362.931344432], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3021600.0000, 
sim time next is 3022200.0000, 
raw observation next is [23.45, 98.0, 1.0, 2.0, 0.3022489421112639, 1.0, 1.0, 0.3022489421112639, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 690293.4330704986, 690293.4330704991, 181070.7719313396], 
processed observation next is [1.0, 1.0, 0.42407407407407405, 0.98, 1.0, 1.0, 0.1693439787038856, 1.0, 0.5, 0.1693439787038856, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2465333689537495, 0.24653336895374967, 0.3482130229448839], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.00988939], dtype=float32), -1.2388295]. 
=============================================
[2019-03-24 05:11:29,674] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.9648321e-01 2.0661246e-09 7.2401991e-07 4.0033967e-09 3.5160186e-03], sum to 1.0000
[2019-03-24 05:11:29,685] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9907
[2019-03-24 05:11:29,692] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 880411.8552250122 W.
[2019-03-24 05:11:29,695] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 98.0, 1.0, 2.0, 0.7724411847718551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 880411.8552250122, 880411.8552250122, 190310.3295466763], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3037200.0000, 
sim time next is 3037800.0000, 
raw observation next is [25.0, 99.0, 1.0, 2.0, 0.7775509993381703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 886239.2794000545, 886239.2794000545, 191344.5515561363], 
processed observation next is [1.0, 0.13043478260869565, 0.48148148148148145, 0.99, 1.0, 1.0, 0.7351797611168693, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3165140283571623, 0.3165140283571623, 0.3679702914541083], 
reward next is 0.6320, 
noisyNet noise sample is [array([0.4353677], dtype=float32), -0.25691643]. 
=============================================
[2019-03-24 05:11:34,437] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9999964e-01 6.5143876e-12 2.4230504e-10 2.1141186e-11 3.5735943e-07], sum to 1.0000
[2019-03-24 05:11:34,441] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9664
[2019-03-24 05:11:34,446] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1728194.486597688 W.
[2019-03-24 05:11:34,451] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.2, 32.66666666666666, 1.0, 2.0, 0.5050088527580832, 1.0, 2.0, 0.5050088527580832, 1.0, 2.0, 0.8039999236742815, 6.911199999999999, 6.9112, 121.94756008, 1728194.486597688, 1728194.486597689, 346057.9018498432], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3159600.0000, 
sim time next is 3160200.0000, 
raw observation next is [34.25, 31.83333333333334, 1.0, 2.0, 0.7388553390865379, 1.0, 2.0, 0.7388553390865379, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1715520.269402878, 1715520.269402879, 320668.4324202197], 
processed observation next is [1.0, 0.5652173913043478, 0.8240740740740741, 0.3183333333333334, 1.0, 1.0, 0.6891134989125451, 1.0, 1.0, 0.6891134989125451, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6126858105010278, 0.6126858105010282, 0.6166700623465764], 
reward next is 0.3833, 
noisyNet noise sample is [array([0.34685662], dtype=float32), -0.19982125]. 
=============================================
[2019-03-24 05:11:36,431] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.1315232e-17 4.7464630e-15 5.0919370e-16 4.2397144e-08], sum to 1.0000
[2019-03-24 05:11:36,434] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0917
[2019-03-24 05:11:36,440] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 709651.4982803711 W.
[2019-03-24 05:11:36,446] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.93333333333334, 57.33333333333333, 1.0, 2.0, 0.2075638874563133, 1.0, 2.0, 0.2075638874563133, 1.0, 1.0, 0.3304484687143331, 6.9112, 6.9112, 121.94756008, 709651.4982803711, 709651.4982803711, 223081.2745086605], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3184800.0000, 
sim time next is 3185400.0000, 
raw observation next is [29.96666666666667, 54.66666666666666, 1.0, 2.0, 0.5911622372598743, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 683643.1556678123, 683643.1556678123, 157041.6764791869], 
processed observation next is [1.0, 0.8695652173913043, 0.6654320987654322, 0.5466666666666665, 1.0, 1.0, 0.5132883776903265, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24415826988136155, 0.24415826988136155, 0.3020032239984363], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7319769], dtype=float32), -1.721634]. 
=============================================
[2019-03-24 05:11:37,376] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 2.6591121e-24 1.4477949e-21 1.3528822e-25 9.4991354e-13], sum to 1.0000
[2019-03-24 05:11:37,384] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0222
[2019-03-24 05:11:37,389] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.0, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.777483874133793, 6.911200000000001, 6.9112, 121.9260426156618, 578867.6894265086, 578867.6894265082, 156761.971582866], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3222000.0000, 
sim time next is 3222600.0000, 
raw observation next is [24.38333333333333, 74.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7755718140930868, 6.9112, 6.9112, 121.9260426156618, 577579.1965345622, 577579.1965345622, 156437.7236427931], 
processed observation next is [0.0, 0.30434782608695654, 0.4586419753086418, 0.7483333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7194647676163585, 0.0, 0.0, 0.8094621288201359, 0.20627828447662935, 0.20627828447662935, 0.3008417762361406], 
reward next is 0.6992, 
noisyNet noise sample is [array([-0.12633607], dtype=float32), -0.8485626]. 
=============================================
[2019-03-24 05:11:38,597] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.0921339e-25 1.1465902e-20 2.7035537e-24 2.0390449e-13], sum to 1.0000
[2019-03-24 05:11:38,604] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9049
[2019-03-24 05:11:38,611] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.36666666666667, 84.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8939197222711849, 6.9112, 6.9112, 121.9260426156618, 656572.0380783449, 656572.0380783449, 174619.2942642355], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3206400.0000, 
sim time next is 3207000.0000, 
raw observation next is [24.18333333333333, 83.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8718811763220181, 6.911200000000001, 6.9112, 121.9260426156618, 642734.8156958595, 642734.815695859, 171122.6789016421], 
processed observation next is [0.0, 0.08695652173913043, 0.45123456790123445, 0.8366666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8398514704025225, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22954814846280697, 0.2295481484628068, 0.32908207481085017], 
reward next is 0.6709, 
noisyNet noise sample is [array([-2.0254865], dtype=float32), 0.50181204]. 
=============================================
[2019-03-24 05:11:38,623] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[74.27494]
 [72.3274 ]
 [70.95102]
 [73.73728]
 [73.7951 ]], R is [[75.8155899 ]
 [75.72162628]
 [74.96440887]
 [74.84150696]
 [74.74073029]].
[2019-03-24 05:11:41,620] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-24 05:11:41,623] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:11:41,623] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:11:41,624] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:11:41,624] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:11:41,625] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:11:41,626] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:11:41,628] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:11:41,628] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:11:41,633] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:11:41,639] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:11:41,650] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run13
[2019-03-24 05:11:41,651] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run13
[2019-03-24 05:11:41,674] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run13
[2019-03-24 05:11:41,731] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run13
[2019-03-24 05:11:41,755] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run13
[2019-03-24 05:12:05,104] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00647127], dtype=float32), 0.00947351]
[2019-03-24 05:12:05,105] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [18.8, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9702079162391182, 6.911199999999999, 6.9112, 121.9259555827073, 708899.285121986, 708899.2851219864, 164615.6169876633]
[2019-03-24 05:12:05,106] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:12:05,108] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 9.1947740e-23 2.0225805e-19 1.1377753e-21 8.3051177e-13], sampled 0.5953813096453204
[2019-03-24 05:12:05,109] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 708899.285121986 W.
[2019-03-24 05:12:53,777] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00647127], dtype=float32), 0.00947351]
[2019-03-24 05:12:53,778] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.83032989, 86.49306985, 1.0, 2.0, 0.8472573330345956, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 965739.4223052763, 965739.4223052767, 205913.9160823073]
[2019-03-24 05:12:53,779] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:12:53,781] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 4.4814236e-19 3.9979577e-16 4.4278134e-18 1.7833571e-10], sampled 0.30789615006618043
[2019-03-24 05:12:53,783] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 965739.4223052763 W.
[2019-03-24 05:13:08,373] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00647127], dtype=float32), 0.00947351]
[2019-03-24 05:13:08,376] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.83333333333334, 91.50000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7493446761915673, 6.9112, 6.9112, 121.9260426156618, 558783.5100949724, 558783.5100949724, 152710.4029871052]
[2019-03-24 05:13:08,376] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:13:08,381] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.1531373e-23 3.5522302e-20 1.6217866e-22 2.7663099e-13], sampled 0.21772279461247024
[2019-03-24 05:13:11,897] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00647127], dtype=float32), 0.00947351]
[2019-03-24 05:13:11,899] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.94094883, 78.34385621999999, 1.0, 2.0, 0.7187027386361072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 819129.1989249972, 819129.1989249972, 179710.3810016346]
[2019-03-24 05:13:11,899] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:13:11,905] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 7.1441046e-19 5.9609859e-16 6.9701812e-18 2.2235591e-10], sampled 0.8455245023570293
[2019-03-24 05:13:11,906] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 819129.1989249972 W.
[2019-03-24 05:13:23,408] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00647127], dtype=float32), 0.00947351]
[2019-03-24 05:13:23,409] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [19.33333333333334, 76.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5132774507542635, 6.9112, 6.9112, 121.9260426156618, 371659.7699927638, 371659.7699927638, 117958.2870933222]
[2019-03-24 05:13:23,410] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:13:23,412] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 2.5612960e-23 7.0143184e-20 3.4513912e-22 4.5168266e-13], sampled 0.5036292555338698
[2019-03-24 05:13:30,302] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 05:13:30,595] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5295 2529767993.6091 831.0000
[2019-03-24 05:13:30,914] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 05:13:30,921] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 05:13:30,922] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8403.5218 2293034398.2444 697.0000
[2019-03-24 05:13:31,935] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 300000, evaluation results [300000.0, 7841.529523729852, 2529767993.609111, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8403.521846518315, 2293034398.244441, 697.0]
[2019-03-24 05:13:35,265] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 3.1660868e-15 6.6390999e-12 2.0576378e-13 1.9803792e-08], sum to 1.0000
[2019-03-24 05:13:35,276] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4869
[2019-03-24 05:13:35,290] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 790997.4106130407 W.
[2019-03-24 05:13:35,294] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 87.33333333333333, 1.0, 2.0, 0.3470163395898975, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5524613141602962, 6.911200000000001, 6.9112, 121.9260426156618, 790997.4106130407, 790997.4106130402, 208314.82759245], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3361200.0000, 
sim time next is 3361800.0000, 
raw observation next is [26.16666666666667, 88.16666666666667, 1.0, 2.0, 0.6923349801973372, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 789061.5266833629, 789061.5266833629, 174697.4455790026], 
processed observation next is [0.0, 0.9130434782608695, 0.5246913580246916, 0.8816666666666667, 1.0, 1.0, 0.6337321192825442, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28180768810120105, 0.28180768810120105, 0.33595662611346655], 
reward next is 0.6640, 
noisyNet noise sample is [array([-0.7366693], dtype=float32), -0.4743591]. 
=============================================
[2019-03-24 05:13:35,942] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.9996483e-01 6.5893707e-10 1.1262521e-08 1.7497174e-09 3.5132034e-05], sum to 1.0000
[2019-03-24 05:13:35,947] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9624
[2019-03-24 05:13:35,948] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 800864.2462416242 W.
[2019-03-24 05:13:35,954] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.63333333333333, 94.0, 1.0, 2.0, 0.3476252762993862, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5539178822301574, 6.911199999999999, 6.9112, 121.9260426156618, 800864.2462416242, 800864.2462416247, 208336.6178826561], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3385200.0000, 
sim time next is 3385800.0000, 
raw observation next is [23.45, 94.0, 1.0, 2.0, 0.339251233194257, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5407823916258299, 6.911199999999999, 6.9112, 121.9260426156618, 783767.9220673463, 783767.9220673467, 205893.9429995546], 
processed observation next is [1.0, 0.17391304347826086, 0.42407407407407405, 0.94, 1.0, 1.0, 0.2133943252312583, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.42597798953228727, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27991711502405225, 0.2799171150240524, 0.39594989038375883], 
reward next is 0.6041, 
noisyNet noise sample is [array([-0.6269339], dtype=float32), -0.097244896]. 
=============================================
[2019-03-24 05:13:50,216] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9957544e-01 2.4928846e-13 5.4188369e-11 1.9623415e-10 4.2457040e-04], sum to 1.0000
[2019-03-24 05:13:50,222] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0961
[2019-03-24 05:13:50,229] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1289122.97542187 W.
[2019-03-24 05:13:50,234] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.33333333333334, 100.0, 1.0, 2.0, 0.5575105297071785, 0.0, 1.0, 0.0, 1.0, 2.0, 0.888769514445499, 6.911200000000001, 6.9112, 121.9260424772189, 1289122.97542187, 1289122.975421869, 277410.3132092254], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3666000.0000, 
sim time next is 3666600.0000, 
raw observation next is [22.5, 100.0, 1.0, 2.0, 0.3635817227069137, 1.0, 1.0, 0.3635817227069137, 1.0, 2.0, 0.5788339435794498, 6.9112, 6.9112, 121.94756008, 1243502.106865058, 1243502.106865058, 281496.6636429592], 
processed observation next is [1.0, 0.43478260869565216, 0.3888888888888889, 1.0, 1.0, 1.0, 0.2423591936987068, 1.0, 0.5, 0.2423591936987068, 1.0, 1.0, 0.47354242947431224, 0.0, 0.0, 0.8096049824067558, 0.4441078953089493, 0.4441078953089493, 0.5413397377749215], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.16033924], dtype=float32), 0.52939093]. 
=============================================
[2019-03-24 05:13:51,972] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.6549380e-01 3.5976278e-10 8.8793435e-08 1.6009255e-07 3.4505911e-02], sum to 1.0000
[2019-03-24 05:13:51,983] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8484
[2019-03-24 05:13:51,990] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1527913.272374701 W.
[2019-03-24 05:13:51,998] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.9, 84.0, 1.0, 2.0, 0.6699846522815411, 1.0, 1.0, 0.6699846522815411, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1527913.272374701, 1527913.272374701, 292958.9403439612], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3690000.0000, 
sim time next is 3690600.0000, 
raw observation next is [26.91666666666667, 84.83333333333333, 1.0, 2.0, 0.3944153391718238, 1.0, 2.0, 0.3944153391718238, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 899103.2052491646, 899103.2052491646, 204661.9594324932], 
processed observation next is [1.0, 0.7391304347826086, 0.5524691358024693, 0.8483333333333333, 1.0, 1.0, 0.27906587996645693, 1.0, 1.0, 0.27906587996645693, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.32110828758898735, 0.32110828758898735, 0.39358069121633305], 
reward next is 0.6064, 
noisyNet noise sample is [array([-0.5802928], dtype=float32), 0.16754593]. 
=============================================
[2019-03-24 05:13:59,605] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9996877e-01 1.9986044e-18 2.7543855e-15 1.2521902e-16 3.1216463e-05], sum to 1.0000
[2019-03-24 05:13:59,617] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1865
[2019-03-24 05:13:59,622] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 703500.78921404 W.
[2019-03-24 05:13:59,628] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.0, 59.0, 1.0, 1.0, 0.3086485393490955, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4913785266249212, 6.911199999999999, 6.9112, 121.9260426156618, 703500.78921404, 703500.7892140405, 197583.5670785972], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3834000.0000, 
sim time next is 3834600.0000, 
raw observation next is [30.16666666666666, 59.66666666666667, 1.0, 2.0, 0.3133434477230591, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4988529736587623, 6.911199999999999, 6.9112, 121.9260426156618, 714206.8511385453, 714206.8511385458, 198865.1896098116], 
processed observation next is [0.0, 0.391304347826087, 0.6728395061728393, 0.5966666666666667, 1.0, 1.0, 0.18255172347983228, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.37356621707345283, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.25507387540662335, 0.2550738754066235, 0.3824330569419454], 
reward next is 0.6176, 
noisyNet noise sample is [array([1.0102831], dtype=float32), -1.5482839]. 
=============================================
[2019-03-24 05:14:00,492] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.9715781e-01 1.7466194e-14 1.9721531e-12 4.3352336e-11 2.8421935e-03], sum to 1.0000
[2019-03-24 05:14:00,498] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0837
[2019-03-24 05:14:00,503] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 702059.9172871851 W.
[2019-03-24 05:14:00,507] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.5, 47.33333333333333, 1.0, 2.0, 0.2053444643160193, 1.0, 2.0, 0.2053444643160193, 1.0, 2.0, 0.3269150747934197, 6.9112, 6.9112, 121.94756008, 702059.9172871851, 702059.9172871851, 222348.3274772926], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3841800.0000, 
sim time next is 3842400.0000, 
raw observation next is [32.6, 49.66666666666667, 1.0, 2.0, 0.3131353164028213, 1.0, 2.0, 0.3131353164028213, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 713732.2344909149, 713732.2344909153, 183643.0097589868], 
processed observation next is [0.0, 0.4782608695652174, 0.7629629629629631, 0.4966666666666667, 1.0, 1.0, 0.18230394809859676, 1.0, 1.0, 0.18230394809859676, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.254904369461041, 0.25490436946104117, 0.35315963415189766], 
reward next is 0.6468, 
noisyNet noise sample is [array([0.8589548], dtype=float32), -1.9416506]. 
=============================================
[2019-03-24 05:14:06,297] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.4608783e-01 5.4133812e-16 2.6352556e-11 6.2949917e-13 3.5391212e-01], sum to 1.0000
[2019-03-24 05:14:06,301] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3514
[2019-03-24 05:14:06,311] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 862150.6690043117 W.
[2019-03-24 05:14:06,317] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.1, 77.0, 1.0, 2.0, 0.2521428563160095, 1.0, 2.0, 0.2521428563160095, 1.0, 2.0, 0.4014196389746273, 6.911200000000002, 6.9112, 121.94756008, 862150.6690043117, 862150.6690043107, 238386.5655376925], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3957600.0000, 
sim time next is 3958200.0000, 
raw observation next is [29.15, 76.0, 1.0, 2.0, 0.3845493933669394, 0.0, 1.0, 0.0, 1.0, 2.0, 0.6122151581395705, 6.911199999999999, 6.9112, 121.9260426156618, 876600.0831167743, 876600.0831167748, 219384.8200852405], 
processed observation next is [0.0, 0.8260869565217391, 0.6351851851851852, 0.76, 1.0, 1.0, 0.26732070638921357, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.5152689476744631, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3130714582559908, 0.313071458255991, 0.42189388477930867], 
reward next is 0.5781, 
noisyNet noise sample is [array([-1.4813043], dtype=float32), -1.4470694]. 
=============================================
[2019-03-24 05:14:07,343] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.8583385e-01 3.4683470e-10 5.9095264e-08 1.4948636e-06 4.1416463e-01], sum to 1.0000
[2019-03-24 05:14:07,344] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6197
[2019-03-24 05:14:07,351] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.55, 86.83333333333333, 1.0, 2.0, 0.6563696812531066, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 748051.4922117024, 748051.4922117024, 168045.8262567445], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3981000.0000, 
sim time next is 3981600.0000, 
raw observation next is [25.5, 87.0, 1.0, 2.0, 0.2184084134013017, 1.0, 1.0, 0.2184084134013017, 1.0, 1.0, 0.3477133072003077, 6.9112, 6.9112, 121.94756008, 746746.495976689, 746746.495976689, 226702.2351730102], 
processed observation next is [1.0, 0.08695652173913043, 0.5, 0.87, 1.0, 1.0, 0.06953382547774013, 1.0, 0.5, 0.06953382547774013, 1.0, 0.5, 0.18464163400038458, 0.0, 0.0, 0.8096049824067558, 0.2666951771345318, 0.2666951771345318, 0.43596583687117346], 
reward next is 0.5640, 
noisyNet noise sample is [array([-1.6756071], dtype=float32), -0.38706884]. 
=============================================
[2019-03-24 05:14:08,346] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.4100671e-01 4.3228242e-12 1.1253986e-08 9.0658475e-10 3.5899329e-01], sum to 1.0000
[2019-03-24 05:14:08,351] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2253
[2019-03-24 05:14:08,356] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1018004.948539402 W.
[2019-03-24 05:14:08,359] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.36666666666667, 94.0, 1.0, 2.0, 0.4465401033568594, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7109063873400011, 6.911199999999998, 6.9112, 121.9260426156618, 1018004.948539402, 1018004.948539403, 238895.9703348571], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4000800.0000, 
sim time next is 4001400.0000, 
raw observation next is [24.35, 94.0, 1.0, 2.0, 0.4524137085333048, 1.0, 1.0, 0.4524137085333048, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1031404.379634751, 1031404.37963475, 221058.1048083503], 
processed observation next is [1.0, 0.30434782608695654, 0.4574074074074075, 0.94, 1.0, 1.0, 0.3481115577777439, 1.0, 0.5, 0.3481115577777439, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3683587070124111, 0.3683587070124107, 0.4251117400160583], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3357222], dtype=float32), 1.7097138]. 
=============================================
[2019-03-24 05:14:09,278] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.6719984e-02 5.2181566e-13 2.1959520e-10 1.4652853e-10 9.8328006e-01], sum to 1.0000
[2019-03-24 05:14:09,279] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1411
[2019-03-24 05:14:09,282] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.485299484039739, 1.0, 2.0, 0.485299484039739, 1.0, 2.0, 0.7726125836920481, 6.911199999999999, 6.9112, 121.94756008, 1660233.515278834, 1660233.515278834, 336432.4514139523], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4028400.0000, 
sim time next is 4029000.0000, 
raw observation next is [26.16666666666667, 88.16666666666667, 1.0, 2.0, 0.42250772228029, 1.0, 2.0, 0.42250772228029, 1.0, 2.0, 0.6726460539860927, 6.9112, 6.9112, 121.94756008, 1445227.65592578, 1445227.65592578, 307082.0822556608], 
processed observation next is [1.0, 0.6521739130434783, 0.5246913580246916, 0.8816666666666667, 1.0, 1.0, 0.3125091931908214, 1.0, 1.0, 0.3125091931908214, 1.0, 1.0, 0.5908075674826158, 0.0, 0.0, 0.8096049824067558, 0.5161527342592072, 0.5161527342592072, 0.5905424658762708], 
reward next is 0.4095, 
noisyNet noise sample is [array([-1.1084465], dtype=float32), 0.33964196]. 
=============================================
[2019-03-24 05:14:09,285] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.5922173e-01 9.3716538e-13 8.2624234e-11 2.8127209e-10 7.4077821e-01], sum to 1.0000
[2019-03-24 05:14:09,288] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5291
[2019-03-24 05:14:09,293] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.35, 83.5, 1.0, 2.0, 0.2037387711899974, 1.0, 2.0, 0.2037387711899974, 1.0, 1.0, 0.3243587590430185, 6.9112, 6.9112, 121.94756008, 696567.6588767591, 696567.6588767591, 221819.7789250231], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4037400.0000, 
sim time next is 4038000.0000, 
raw observation next is [26.23333333333333, 85.33333333333333, 1.0, 2.0, 0.2075123698421534, 1.0, 2.0, 0.2075123698421534, 1.0, 2.0, 0.330366450994779, 6.911199999999999, 6.9112, 121.94756008, 709475.2804043482, 709475.2804043486, 223064.2299659851], 
processed observation next is [1.0, 0.7391304347826086, 0.5271604938271603, 0.8533333333333333, 1.0, 1.0, 0.05656234505018262, 1.0, 1.0, 0.05656234505018262, 1.0, 1.0, 0.16295806374347374, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.25338402871583865, 0.2533840287158388, 0.42896967301150984], 
reward next is 0.5710, 
noisyNet noise sample is [array([-1.885364], dtype=float32), -0.20327038]. 
=============================================
[2019-03-24 05:14:09,307] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[40.71447 ]
 [40.387264]
 [40.41792 ]
 [40.23843 ]
 [40.03948 ]], R is [[41.41921234]
 [41.35803604]
 [41.23881912]
 [41.12873459]
 [41.02601624]].
[2019-03-24 05:14:09,314] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[42.30361 ]
 [41.607513]
 [41.127922]
 [39.07026 ]
 [38.74304 ]], R is [[42.8860054 ]
 [42.45714569]
 [42.68327332]
 [42.7951355 ]
 [42.36718369]].
[2019-03-24 05:14:10,519] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.1770436e-01 3.6465334e-14 8.9334373e-11 3.1771014e-10 7.8229564e-01], sum to 1.0000
[2019-03-24 05:14:10,525] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3491
[2019-03-24 05:14:10,530] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.66666666666667, 96.0, 1.0, 2.0, 0.3336694855533722, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5312126878574582, 6.911199999999999, 6.9112, 121.9260426156618, 760559.1761357443, 760559.1761357448, 204514.3771589239], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4051200.0000, 
sim time next is 4051800.0000, 
raw observation next is [24.5, 97.0, 1.0, 2.0, 0.2222552161784857, 1.0, 1.0, 0.2222552161784857, 1.0, 2.0, 0.3538375425032049, 6.9112, 6.9112, 121.94756008, 759905.3761075959, 759905.3761075959, 228002.4823918119], 
processed observation next is [1.0, 0.9130434782608695, 0.46296296296296297, 0.97, 1.0, 1.0, 0.07411335259343536, 1.0, 0.5, 0.07411335259343536, 1.0, 1.0, 0.19229692812900614, 0.0, 0.0, 0.8096049824067558, 0.27139477718128424, 0.27139477718128424, 0.438466312291946], 
reward next is 0.5615, 
noisyNet noise sample is [array([1.6853813], dtype=float32), -0.356815]. 
=============================================
[2019-03-24 05:14:13,704] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.6225448e-01 1.0320372e-12 1.3925948e-10 9.7491329e-12 7.3774552e-01], sum to 1.0000
[2019-03-24 05:14:13,716] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5903
[2019-03-24 05:14:13,719] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.25, 68.33333333333334, 1.0, 2.0, 0.4520345088953514, 1.0, 2.0, 0.4520345088953514, 1.0, 1.0, 0.7196536598975762, 6.911200000000001, 6.9112, 121.94756008, 1546328.779009541, 1546328.779009541, 320625.6545569886], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4101000.0000, 
sim time next is 4101600.0000, 
raw observation next is [27.4, 68.66666666666667, 1.0, 2.0, 0.4539971320983983, 1.0, 2.0, 0.4539971320983983, 1.0, 2.0, 0.7227782199550022, 6.911199999999999, 6.9112, 121.94756008, 1553049.367336834, 1553049.367336835, 321542.9682868756], 
processed observation next is [1.0, 0.4782608695652174, 0.5703703703703703, 0.6866666666666668, 1.0, 1.0, 0.34999658583142657, 1.0, 1.0, 0.34999658583142657, 1.0, 1.0, 0.6534727749437527, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5546604883345836, 0.5546604883345839, 0.6183518620901454], 
reward next is 0.3816, 
noisyNet noise sample is [array([-0.48548996], dtype=float32), 2.1108162]. 
=============================================
[2019-03-24 05:14:19,281] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.8192400e-01 4.6443462e-19 5.9606609e-19 7.5534659e-17 1.8076042e-02], sum to 1.0000
[2019-03-24 05:14:19,286] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2532
[2019-03-24 05:14:19,291] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [34.08333333333334, 32.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7218025349390118, 6.911200000000001, 6.9112, 121.9260426156618, 537215.7981155034, 537215.7981155029, 150283.5663385686], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4211400.0000, 
sim time next is 4212000.0000, 
raw observation next is [34.0, 34.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7553048952107363, 6.911199999999999, 6.9112, 121.9260426156618, 560675.8243547771, 560675.8243547776, 155021.2462699711], 
processed observation next is [1.0, 0.782608695652174, 0.8148148148148148, 0.34, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6941311190134203, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20024136584099184, 0.200241365840992, 0.298117781288406], 
reward next is 0.7019, 
noisyNet noise sample is [array([-1.2408376], dtype=float32), -1.6689295]. 
=============================================
[2019-03-24 05:14:19,308] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[62.82117 ]
 [61.67201 ]
 [58.93398 ]
 [55.82211 ]
 [53.992676]], R is [[62.67736053]
 [62.76158142]
 [62.8521843 ]
 [62.22366333]
 [61.60142899]].
[2019-03-24 05:14:19,514] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9999571e-01 1.7220598e-23 3.2119510e-20 8.6347109e-18 4.2724478e-06], sum to 1.0000
[2019-03-24 05:14:19,521] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4328
[2019-03-24 05:14:19,525] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.0, 58.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7290368759962289, 6.9112, 6.9112, 121.9260426156618, 544772.4093939225, 544772.4093939225, 148467.6861208703], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4230000.0000, 
sim time next is 4230600.0000, 
raw observation next is [25.83333333333334, 60.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7294535016576041, 6.9112, 6.9112, 121.9260426156618, 545070.8892816791, 545070.8892816791, 148582.8331648383], 
processed observation next is [1.0, 1.0, 0.5123456790123458, 0.6066666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6618168770720051, 0.0, 0.0, 0.8094621288201359, 0.1946681747434568, 0.1946681747434568, 0.28573621762468904], 
reward next is 0.7143, 
noisyNet noise sample is [array([-1.0269516], dtype=float32), -0.31476524]. 
=============================================
[2019-03-24 05:14:20,141] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-24 05:14:20,142] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:14:20,143] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:14:20,144] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:14:20,144] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:14:20,145] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:14:20,147] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:14:20,148] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:14:20,148] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:14:20,149] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:14:20,149] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:14:20,165] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run14
[2019-03-24 05:14:20,190] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run14
[2019-03-24 05:14:20,191] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run14
[2019-03-24 05:14:20,191] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run14
[2019-03-24 05:14:20,192] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run14
[2019-03-24 05:14:44,767] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00605219], dtype=float32), 0.00977251]
[2019-03-24 05:14:44,769] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.1, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6726777346769585, 6.9112, 6.9112, 121.9260426156618, 502409.6434119284, 502409.6434119284, 140680.92160669]
[2019-03-24 05:14:44,772] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:14:44,774] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.9993920e-01 1.8940110e-19 8.3824101e-18 3.2772221e-16 6.0752645e-05], sampled 0.08735871053525712
[2019-03-24 05:15:16,651] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00605219], dtype=float32), 0.00977251]
[2019-03-24 05:15:16,652] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.18676588333333, 72.16759317333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7151896737895079, 6.911199999999999, 6.9112, 121.9260426156618, 533944.2927551906, 533944.2927551911, 148031.9049647981]
[2019-03-24 05:15:16,653] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:15:16,657] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.9884230e-01 5.0756263e-19 7.7525332e-17 1.7895153e-15 1.1577213e-03], sampled 0.12762517544696717
[2019-03-24 05:15:49,540] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00605219], dtype=float32), 0.00977251]
[2019-03-24 05:15:49,541] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.73333333333333, 66.0, 1.0, 2.0, 0.6832778930129592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 778733.8246306609, 778733.8246306609, 173002.1404880387]
[2019-03-24 05:15:49,542] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:15:49,545] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.84909117e-01 1.41310094e-15 1.52135588e-13 1.56315445e-12
 1.50908455e-02], sampled 0.7203514479370722
[2019-03-24 05:15:49,546] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 778733.8246306609 W.
[2019-03-24 05:15:55,736] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00605219], dtype=float32), 0.00977251]
[2019-03-24 05:15:55,737] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9061380621872062, 6.911200000000001, 6.9112, 121.9260426156618, 657097.2291691273, 657097.2291691268, 177796.1826916694]
[2019-03-24 05:15:55,738] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:15:55,741] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.9987757e-01 4.0772381e-19 2.1924536e-17 7.2367403e-16 1.2242860e-04], sampled 0.039212173150220075
[2019-03-24 05:15:57,173] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00605219], dtype=float32), 0.00977251]
[2019-03-24 05:15:57,174] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.13333333333333, 79.0, 1.0, 2.0, 0.8567328257374369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 976546.8679350729, 976546.8679350729, 207940.9928378507]
[2019-03-24 05:15:57,175] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:15:57,179] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.812029e-01 7.137515e-15 6.463976e-13 5.769658e-12 1.879702e-02], sampled 0.23271522795045985
[2019-03-24 05:15:57,181] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 976546.8679350729 W.
[2019-03-24 05:16:04,006] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00605219], dtype=float32), 0.00977251]
[2019-03-24 05:16:04,008] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.63704793333333, 85.09242391000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6897411064004164, 6.911200000000001, 6.9112, 121.9260426156618, 515434.6943641484, 515434.694364148, 143635.4076842346]
[2019-03-24 05:16:04,011] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:16:04,014] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.9992931e-01 5.3434963e-19 2.0741713e-17 7.4892673e-16 7.0671944e-05], sampled 0.28806821062948984
[2019-03-24 05:16:08,334] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8322.5717 2296864299.3985 681.0000
[2019-03-24 05:16:08,505] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8282.4516 2343662780.7188 576.0000
[2019-03-24 05:16:08,883] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8489.6855 2262582638.2281 524.0000
[2019-03-24 05:16:09,017] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00605219], dtype=float32), 0.00977251]
[2019-03-24 05:16:09,018] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.93333333333334, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7259730273158881, 6.911200000000001, 6.9112, 121.9260426156618, 542240.0995821464, 542240.0995821459, 148849.2432781466]
[2019-03-24 05:16:09,018] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:16:09,019] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.9994040e-01 1.3612538e-19 6.3477389e-18 2.5425981e-16 5.9572030e-05], sampled 0.3836561440258406
[2019-03-24 05:16:09,029] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7722.4488 2536651232.5700 769.0000
[2019-03-24 05:16:09,087] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8555.2040 2223442795.6013 538.0000
[2019-03-24 05:16:10,102] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 325000, evaluation results [325000.0, 7722.448780886036, 2536651232.56996, 769.0, 8489.68545207284, 2262582638.228143, 524.0, 8555.204022047794, 2223442795.6012974, 538.0, 8282.451631777742, 2343662780.718843, 576.0, 8322.57172626587, 2296864299.3985205, 681.0]
[2019-03-24 05:16:19,737] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 7.1498285e-27 2.0500491e-25 1.6729387e-26 3.6609457e-12], sum to 1.0000
[2019-03-24 05:16:19,744] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6746
[2019-03-24 05:16:19,747] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.4, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7933339986548111, 6.911199999999999, 6.9112, 121.9260426156618, 589962.3460578196, 589962.34605782, 159131.8183538486], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4424400.0000, 
sim time next is 4425000.0000, 
raw observation next is [22.33333333333334, 91.50000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7929054445404793, 6.9112, 6.9112, 121.9260426156618, 589647.4828861657, 589647.4828861657, 159076.746517584], 
processed observation next is [0.0, 0.21739130434782608, 0.38271604938271625, 0.9150000000000001, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7411318056755991, 0.0, 0.0, 0.8094621288201359, 0.2105883867450592, 0.2105883867450592, 0.30591682022612304], 
reward next is 0.6941, 
noisyNet noise sample is [array([-1.7929896], dtype=float32), 1.0201699]. 
=============================================
[2019-03-24 05:16:19,771] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[71.312325]
 [71.26382 ]
 [71.26659 ]
 [71.280365]
 [71.28668 ]], R is [[71.28240204]
 [71.26355743]
 [71.24493408]
 [71.22650146]
 [71.20821381]].
[2019-03-24 05:16:31,719] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.3007163e-01 7.6480966e-13 7.7946937e-12 4.5486384e-10 7.6992834e-01], sum to 1.0000
[2019-03-24 05:16:31,726] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6879
[2019-03-24 05:16:31,732] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.5, 89.83333333333334, 1.0, 2.0, 0.2229809609260485, 1.0, 2.0, 0.2229809609260485, 1.0, 1.0, 0.3549929517771812, 6.911199999999999, 6.9112, 121.94756008, 762387.979483128, 762387.9794831284, 228248.7174580312], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4662600.0000, 
sim time next is 4663200.0000, 
raw observation next is [25.4, 90.66666666666667, 1.0, 2.0, 0.222045929011141, 1.0, 2.0, 0.222045929011141, 1.0, 2.0, 0.3535043505167849, 6.9112, 6.9112, 121.94756008, 759189.4550540863, 759189.4550540863, 227931.5289015266], 
processed observation next is [1.0, 1.0, 0.49629629629629624, 0.9066666666666667, 1.0, 1.0, 0.0738642012037393, 1.0, 1.0, 0.0738642012037393, 1.0, 1.0, 0.19188043814598113, 0.0, 0.0, 0.8096049824067558, 0.2711390910907451, 0.2711390910907451, 0.4383298632721665], 
reward next is 0.5617, 
noisyNet noise sample is [array([2.2453513], dtype=float32), 1.1260365]. 
=============================================
[2019-03-24 05:16:32,431] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.3416506e-01 4.6794259e-17 1.1673167e-13 1.1783047e-13 6.5834969e-02], sum to 1.0000
[2019-03-24 05:16:32,437] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5597
[2019-03-24 05:16:32,445] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 699322.3358504833 W.
[2019-03-24 05:16:32,452] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.0, 99.0, 1.0, 2.0, 0.2043277315605976, 1.0, 2.0, 0.2043277315605976, 1.0, 2.0, 0.3253122260354044, 6.911200000000001, 6.9112, 121.94756008, 699322.3358504833, 699322.3358504828, 222016.6383049623], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4690200.0000, 
sim time next is 4690800.0000, 
raw observation next is [23.0, 100.0, 1.0, 2.0, 0.3061974320828766, 1.0, 2.0, 0.3061974320828766, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 701356.85438213, 701356.8543821304, 182125.7434082467], 
processed observation next is [1.0, 0.30434782608695654, 0.4074074074074074, 1.0, 1.0, 1.0, 0.1740445620034245, 1.0, 1.0, 0.1740445620034245, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2504845908507607, 0.25048459085076086, 0.35024181424662826], 
reward next is 0.6498, 
noisyNet noise sample is [array([-0.5186879], dtype=float32), 1.2587997]. 
=============================================
[2019-03-24 05:16:34,798] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.4033725e-03 4.9804399e-13 1.1639758e-10 4.0057489e-11 9.9459660e-01], sum to 1.0000
[2019-03-24 05:16:34,805] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4925
[2019-03-24 05:16:34,811] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.76666666666667, 83.66666666666667, 1.0, 2.0, 0.5371666100305781, 1.0, 2.0, 0.5371666100305781, 1.0, 2.0, 0.8551867374638287, 6.9112, 6.9112, 121.94756008, 1837856.019079298, 1837856.019079298, 362205.1642363117], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4713600.0000, 
sim time next is 4714200.0000, 
raw observation next is [28.15, 81.0, 1.0, 2.0, 0.5896098301879531, 1.0, 2.0, 0.5896098301879531, 1.0, 2.0, 0.9386780519108116, 6.9112, 6.9112, 121.94756008, 2017487.310710415, 2017487.310710415, 389743.560974072], 
processed observation next is [1.0, 0.5652173913043478, 0.5981481481481481, 0.81, 1.0, 1.0, 0.5114402740332775, 1.0, 1.0, 0.5114402740332775, 1.0, 1.0, 0.9233475648885144, 0.0, 0.0, 0.8096049824067558, 0.7205311823965768, 0.7205311823965768, 0.7495068480270616], 
reward next is 0.2505, 
noisyNet noise sample is [array([0.14821514], dtype=float32), 0.39810982]. 
=============================================
[2019-03-24 05:16:42,050] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.30749075e-02 2.56440310e-16 6.28380160e-13 4.22193259e-13
 9.86925125e-01], sum to 1.0000
[2019-03-24 05:16:42,062] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1662
[2019-03-24 05:16:42,066] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.0, 95.0, 1.0, 2.0, 0.2225309830860958, 1.0, 2.0, 0.2225309830860958, 1.0, 2.0, 0.3542765724012212, 6.9112, 6.9112, 121.94756008, 760848.7093810502, 760848.7093810502, 228096.0115540895], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4858200.0000, 
sim time next is 4858800.0000, 
raw observation next is [25.0, 94.66666666666666, 1.0, 2.0, 0.2208863908404625, 1.0, 2.0, 0.2208863908404625, 1.0, 2.0, 0.3516583279855429, 6.9112, 6.9112, 121.94756008, 755222.9660227349, 755222.9660227349, 227538.8608619299], 
processed observation next is [1.0, 0.21739130434782608, 0.48148148148148145, 0.9466666666666665, 1.0, 1.0, 0.07248379861959821, 1.0, 1.0, 0.07248379861959821, 1.0, 1.0, 0.18957290998192863, 0.0, 0.0, 0.8096049824067558, 0.2697224878652625, 0.2697224878652625, 0.43757473242678824], 
reward next is 0.5624, 
noisyNet noise sample is [array([-0.9315255], dtype=float32), 0.5092841]. 
=============================================
[2019-03-24 05:16:47,712] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.8514482e-02 5.1226809e-12 6.4421479e-10 2.3241939e-09 9.7148550e-01], sum to 1.0000
[2019-03-24 05:16:47,719] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0590
[2019-03-24 05:16:47,722] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.66666666666667, 79.66666666666667, 1.0, 2.0, 0.2808017909501992, 1.0, 2.0, 0.2808017909501992, 1.0, 2.0, 0.4477290928437433, 6.9112, 6.9112, 121.94756008, 974868.5142320471, 974868.5142320471, 248830.2631425219], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4954800.0000, 
sim time next is 4955400.0000, 
raw observation next is [24.75, 80.5, 1.0, 2.0, 0.3059520025718525, 1.0, 2.0, 0.3059520025718525, 1.0, 2.0, 0.48734997745603, 6.911200000000001, 6.9112, 121.94756008, 1054301.862974919, 1054301.862974919, 258371.4245390506], 
processed observation next is [1.0, 0.34782608695652173, 0.4722222222222222, 0.805, 1.0, 1.0, 0.17375238401411014, 1.0, 1.0, 0.17375238401411014, 1.0, 1.0, 0.35918747182003746, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.37653637963389963, 0.37653637963389963, 0.49686812411355885], 
reward next is 0.5031, 
noisyNet noise sample is [array([0.3427066], dtype=float32), 0.7872865]. 
=============================================
[2019-03-24 05:16:55,311] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.6581403e-02 2.0087344e-16 2.6238269e-14 3.8823901e-14 9.8341864e-01], sum to 1.0000
[2019-03-24 05:16:55,322] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7560
[2019-03-24 05:16:55,329] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.95, 94.0, 1.0, 2.0, 0.2398264553508843, 1.0, 1.0, 0.2398264553508843, 1.0, 2.0, 0.3818115275209721, 6.911199999999999, 6.9112, 121.94756008, 820014.742886483, 820014.7428864834, 234046.9116497258], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5103000.0000, 
sim time next is 5103600.0000, 
raw observation next is [25.93333333333333, 94.0, 1.0, 2.0, 0.2424128810743031, 1.0, 2.0, 0.2424128810743031, 1.0, 2.0, 0.3859292015066599, 6.9112, 6.9112, 121.94756008, 828863.0320375883, 828863.0320375883, 234951.2022506793], 
processed observation next is [0.0, 0.043478260869565216, 0.5160493827160493, 0.94, 1.0, 1.0, 0.09811057270750367, 1.0, 1.0, 0.09811057270750367, 1.0, 1.0, 0.23241150188332482, 0.0, 0.0, 0.8096049824067558, 0.2960225114419958, 0.2960225114419958, 0.45182923509746015], 
reward next is 0.5482, 
noisyNet noise sample is [array([-0.41595414], dtype=float32), 0.05230948]. 
=============================================
[2019-03-24 05:16:57,082] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9281996e-01 7.7045189e-19 6.7858063e-15 1.6963019e-14 7.1799876e-03], sum to 1.0000
[2019-03-24 05:16:57,087] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3881
[2019-03-24 05:16:57,095] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 957576.8231761511 W.
[2019-03-24 05:16:57,098] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.5, 70.5, 1.0, 2.0, 0.8401006367650169, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 957576.8231761511, 957576.8231761511, 204375.4180755511], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5153400.0000, 
sim time next is 5154000.0000, 
raw observation next is [31.33333333333333, 70.33333333333333, 1.0, 2.0, 0.8399143758907199, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 957364.3837369089, 957364.3837369084, 204334.6031505887], 
processed observation next is [0.0, 0.6521739130434783, 0.7160493827160492, 0.7033333333333333, 1.0, 1.0, 0.8094218760603809, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.34191585133461033, 0.34191585133461017, 0.39295115990497825], 
reward next is 0.6070, 
noisyNet noise sample is [array([0.7206541], dtype=float32), -3.3443146]. 
=============================================
[2019-03-24 05:16:57,113] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[55.251984]
 [56.476265]
 [56.519714]
 [57.027203]
 [58.743958]], R is [[55.17432785]
 [54.6225853 ]
 [54.67480469]
 [54.72303391]
 [54.76751709]].
[2019-03-24 05:16:57,869] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.8925555e-01 2.0645638e-15 6.6799336e-14 2.4252789e-12 1.0744516e-02], sum to 1.0000
[2019-03-24 05:16:57,876] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4237
[2019-03-24 05:16:57,879] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 819151.6171809149 W.
[2019-03-24 05:16:57,883] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.03333333333333, 85.33333333333334, 1.0, 2.0, 0.2395741552022612, 1.0, 1.0, 0.2395741552022612, 1.0, 2.0, 0.3814098574675219, 6.9112, 6.9112, 121.94756008, 819151.6171809149, 819151.6171809149, 233958.9002051312], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5170800.0000, 
sim time next is 5171400.0000, 
raw observation next is [26.9, 85.5, 1.0, 2.0, 0.3590506320510862, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5716202996880521, 6.911199999999999, 6.9112, 121.9260426156618, 818443.3125677009, 818443.3125677013, 211802.5239109187], 
processed observation next is [0.0, 0.8695652173913043, 0.5518518518518518, 0.855, 1.0, 1.0, 0.23696503815605505, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.46452537461006504, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.29230118305989317, 0.29230118305989333, 0.40731254598253597], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.32576394], dtype=float32), -0.69197]. 
=============================================
[2019-03-24 05:16:57,956] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.9479042e-01 2.4819204e-16 1.2174715e-14 5.4352406e-15 3.0520952e-01], sum to 1.0000
[2019-03-24 05:16:57,963] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9389
[2019-03-24 05:16:57,966] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.9, 85.5, 1.0, 2.0, 0.7181165947475849, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 818460.7947308827, 818460.7947308823, 179602.4574482474], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5171400.0000, 
sim time next is 5172000.0000, 
raw observation next is [26.76666666666667, 85.66666666666666, 1.0, 2.0, 0.2381132745338397, 1.0, 1.0, 0.2381132745338397, 1.0, 1.0, 0.379084087865833, 6.9112, 6.9112, 121.94756008, 814153.9235824955, 814153.9235824955, 233449.9913765986], 
processed observation next is [0.0, 0.8695652173913043, 0.5469135802469137, 0.8566666666666666, 1.0, 1.0, 0.09299199349266632, 1.0, 0.5, 0.09299199349266632, 1.0, 0.5, 0.2238551098322912, 0.0, 0.0, 0.8096049824067558, 0.2907692584223198, 0.2907692584223198, 0.4489422911088435], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0158844], dtype=float32), -0.3872411]. 
=============================================
[2019-03-24 05:16:57,977] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[52.985485]
 [53.710766]
 [54.250957]
 [53.785408]
 [54.000042]], R is [[52.35369873]
 [52.48477173]
 [52.58432388]
 [52.60930252]
 [52.08320999]].
[2019-03-24 05:16:58,334] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-24 05:16:58,335] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:16:58,335] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:16:58,335] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:16:58,336] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:16:58,337] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:16:58,336] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:16:58,337] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:16:58,338] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:16:58,338] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:16:58,340] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:16:58,355] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run15
[2019-03-24 05:16:58,378] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run15
[2019-03-24 05:16:58,380] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run15
[2019-03-24 05:16:58,402] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run15
[2019-03-24 05:16:58,402] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run15
[2019-03-24 05:17:00,312] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00605219], dtype=float32), 0.00999602]
[2019-03-24 05:17:00,313] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.800524285, 9.882994295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6432218661834893, 6.911199999999999, 6.9112, 121.9260426156618, 459297.2647875809, 459297.2647875814, 112983.2160124556]
[2019-03-24 05:17:00,314] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:17:00,317] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.99895930e-01 6.12689216e-19 1.00496927e-17 1.63227272e-16
 1.04055645e-04], sampled 0.862960611530383
[2019-03-24 05:17:39,469] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00605219], dtype=float32), 0.00999602]
[2019-03-24 05:17:39,470] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.04232613, 101.665555095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7899495224722126, 6.9112, 6.9112, 121.9260426156618, 588792.0765558524, 588792.0765558524, 157806.2379450009]
[2019-03-24 05:17:39,472] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:17:39,474] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.9858874e-01 5.5525739e-18 2.0515902e-16 1.8261158e-15 1.4112452e-03], sampled 0.12500449632829413
[2019-03-24 05:17:58,647] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00605219], dtype=float32), 0.00999602]
[2019-03-24 05:17:58,649] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.30714984666667, 91.63661362666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8801114044400279, 6.911200000000001, 6.9112, 121.9260426156618, 646751.1297176951, 646751.1297176946, 172731.0715119385]
[2019-03-24 05:17:58,650] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:17:58,654] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.9868196e-01 6.3240287e-17 1.4165247e-15 1.3658496e-14 1.3180068e-03], sampled 0.828798525109223
[2019-03-24 05:18:02,980] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00605219], dtype=float32), 0.00999602]
[2019-03-24 05:18:02,983] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.09799029333333, 93.94904404500001, 1.0, 2.0, 0.5990548299931062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 689948.5489114064, 689948.5489114064, 158268.6217702789]
[2019-03-24 05:18:02,983] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:18:02,987] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [7.4968833e-01 1.1503413e-14 9.7997500e-13 3.2219045e-12 2.5031173e-01], sampled 0.06618626360078761
[2019-03-24 05:18:02,988] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 689948.5489114064 W.
[2019-03-24 05:18:46,311] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8010.7686 2367869714.6646 374.0000
[2019-03-24 05:18:46,823] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8150.4378 2300751323.4544 336.0000
[2019-03-24 05:18:47,316] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7444.5047 2632270127.3499 351.0000
[2019-03-24 05:18:47,381] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8041.4546 2363538819.2740 250.0000
[2019-03-24 05:18:47,532] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 7945.2308 2425940618.7592 296.0000
[2019-03-24 05:18:48,548] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 350000, evaluation results [350000.0, 7444.504695562533, 2632270127.349935, 351.0, 8041.454607917213, 2363538819.2739925, 250.0, 8150.437835492652, 2300751323.454371, 336.0, 7945.230849581664, 2425940618.7591724, 296.0, 8010.768617723271, 2367869714.6646376, 374.0]
[2019-03-24 05:18:49,724] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.2998485e-03 1.0800140e-13 3.6772602e-11 8.9651613e-11 9.9470019e-01], sum to 1.0000
[2019-03-24 05:18:49,730] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5571
[2019-03-24 05:18:49,733] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.6, 76.66666666666667, 1.0, 2.0, 0.5657447445547567, 1.0, 2.0, 0.5657447445547567, 1.0, 2.0, 0.9006840583511851, 6.9112, 6.9112, 121.94756008, 1935738.878087951, 1935738.878087951, 377027.7091097008], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5222400.0000, 
sim time next is 5223000.0000, 
raw observation next is [27.75, 74.83333333333333, 1.0, 2.0, 0.555780338664482, 1.0, 2.0, 0.555780338664482, 1.0, 2.0, 0.8848203996558237, 6.9112, 6.9112, 121.94756008, 1901608.6117717, 1901608.6117717, 371809.3939615453], 
processed observation next is [1.0, 0.43478260869565216, 0.5833333333333334, 0.7483333333333333, 1.0, 1.0, 0.47116706983866896, 1.0, 1.0, 0.47116706983866896, 1.0, 1.0, 0.8560254995697797, 0.0, 0.0, 0.8096049824067558, 0.6791459327756071, 0.6791459327756071, 0.715018065310664], 
reward next is 0.2850, 
noisyNet noise sample is [array([0.61804867], dtype=float32), -1.7883793]. 
=============================================
[2019-03-24 05:18:49,750] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[42.274155]
 [41.94873 ]
 [41.718452]
 [41.505928]
 [41.569386]], R is [[42.77787399]
 [42.62504196]
 [42.46107864]
 [42.3095665 ]
 [42.14846039]].
[2019-03-24 05:18:51,137] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.3106166e-01 2.3150656e-14 8.5927356e-11 9.6509620e-11 6.6893834e-01], sum to 1.0000
[2019-03-24 05:18:51,147] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3242
[2019-03-24 05:18:51,166] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 814351.3994991452 W.
[2019-03-24 05:18:51,169] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.1, 99.33333333333334, 1.0, 2.0, 0.2381709990915079, 1.0, 2.0, 0.2381709990915079, 1.0, 2.0, 0.3791759872415983, 6.9112, 6.9112, 121.94756008, 814351.3994991452, 814351.3994991452, 233470.0775292893], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5205000.0000, 
sim time next is 5205600.0000, 
raw observation next is [23.0, 100.0, 1.0, 2.0, 0.2371505363329687, 1.0, 2.0, 0.2371505363329687, 1.0, 2.0, 0.3775513772958522, 6.911199999999999, 6.9112, 121.94756008, 810860.4002796604, 810860.4002796608, 233115.2662696498], 
processed observation next is [1.0, 0.2608695652173913, 0.4074074074074074, 1.0, 1.0, 1.0, 0.0918458765868675, 1.0, 1.0, 0.0918458765868675, 1.0, 1.0, 0.22193922161981522, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2895930000998787, 0.2895930000998789, 0.4482985889800957], 
reward next is 0.5517, 
noisyNet noise sample is [array([-0.09941962], dtype=float32), -0.38089067]. 
=============================================
[2019-03-24 05:18:57,518] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.2492530e-02 1.1327775e-20 1.1561717e-15 5.1953549e-16 9.6750748e-01], sum to 1.0000
[2019-03-24 05:18:57,531] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0527
[2019-03-24 05:18:57,534] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.4, 74.0, 1.0, 2.0, 0.2101355862410448, 1.0, 2.0, 0.2101355862410448, 1.0, 2.0, 0.334542696934008, 6.911200000000001, 6.9112, 121.94756008, 718448.1391348307, 718448.1391348302, 223934.0058668169], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5346000.0000, 
sim time next is 5346600.0000, 
raw observation next is [27.31666666666666, 74.33333333333334, 1.0, 2.0, 0.2094034713202676, 1.0, 2.0, 0.2094034713202676, 1.0, 2.0, 0.3333771461368123, 6.9112, 6.9112, 121.94756008, 715943.8884472634, 715943.8884472634, 223690.8722047621], 
processed observation next is [1.0, 0.9130434782608695, 0.5672839506172836, 0.7433333333333334, 1.0, 1.0, 0.058813656333651904, 1.0, 1.0, 0.058813656333651904, 1.0, 1.0, 0.16672143267101536, 0.0, 0.0, 0.8096049824067558, 0.2556942458740226, 0.2556942458740226, 0.4301747542399271], 
reward next is 0.5698, 
noisyNet noise sample is [array([-0.7312294], dtype=float32), -2.3361332]. 
=============================================
[2019-03-24 05:19:05,179] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5741019e-02 1.9954965e-10 1.0786262e-08 1.4144584e-09 9.8425901e-01], sum to 1.0000
[2019-03-24 05:19:05,188] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3886
[2019-03-24 05:19:05,193] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.3, 69.0, 1.0, 2.0, 0.7542153278208389, 1.0, 2.0, 0.6904723258868543, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2363068.462477216, 2363068.462477216, 444126.3766232204], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5497200.0000, 
sim time next is 5497800.0000, 
raw observation next is [30.93333333333334, 70.0, 1.0, 2.0, 0.6274055889538206, 1.0, 2.0, 0.627067456453345, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2145811.273679656, 2145811.273679656, 410302.3828469225], 
processed observation next is [1.0, 0.6521739130434783, 0.7012345679012348, 0.7, 1.0, 1.0, 0.5564352249450245, 1.0, 1.0, 0.5560326862539822, 1.0, 1.0, 0.9972168686025908, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7663611691713057, 0.7663611691713057, 0.7890430439363895], 
reward next is 0.2110, 
noisyNet noise sample is [array([1.3034682], dtype=float32), -0.86227924]. 
=============================================
[2019-03-24 05:19:05,302] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.0851918e-03 4.4181966e-10 3.5824053e-09 1.0208653e-08 9.9691474e-01], sum to 1.0000
[2019-03-24 05:19:05,306] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7564
[2019-03-24 05:19:05,310] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.4, 63.0, 1.0, 2.0, 0.8784425874352126, 1.0, 2.0, 0.752585955694041, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2575952.485570873, 2575952.485570873, 480632.5742839884], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5493600.0000, 
sim time next is 5494200.0000, 
raw observation next is [33.05, 64.0, 1.0, 2.0, 0.9074193981707664, 1.0, 2.0, 0.7670743610618178, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2625616.362136754, 2625616.362136754, 489627.7559451839], 
processed observation next is [1.0, 0.6086956521739131, 0.7796296296296296, 0.64, 1.0, 1.0, 0.889784997822341, 1.0, 1.0, 0.7227075726926402, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.9377201293345551, 0.9377201293345551, 0.9415918383561229], 
reward next is 0.0584, 
noisyNet noise sample is [array([-1.741977], dtype=float32), 1.4743987]. 
=============================================
[2019-03-24 05:19:06,854] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9689639e-01 2.5586671e-18 1.6287372e-15 4.0669453e-14 3.1036232e-03], sum to 1.0000
[2019-03-24 05:19:06,868] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2455
[2019-03-24 05:19:06,875] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 783144.953208226 W.
[2019-03-24 05:19:06,879] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.8, 91.0, 1.0, 2.0, 0.3435731681803448, 0.0, 1.0, 0.0, 1.0, 2.0, 0.546979673140024, 6.911199999999999, 6.9112, 121.9260426156618, 783144.953208226, 783144.9532082265, 207327.8325823636], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5529600.0000, 
sim time next is 5530200.0000, 
raw observation next is [25.76666666666667, 91.16666666666667, 1.0, 2.0, 0.2288620280647611, 1.0, 1.0, 0.2288620280647611, 1.0, 2.0, 0.3643558021949966, 6.9112, 6.9112, 121.94756008, 782506.0339218477, 782506.0339218477, 230254.9462542874], 
processed observation next is [1.0, 0.0, 0.5098765432098766, 0.9116666666666667, 1.0, 1.0, 0.08197860483900132, 1.0, 0.5, 0.08197860483900132, 1.0, 1.0, 0.2054447527437457, 0.0, 0.0, 0.8096049824067558, 0.27946644068637416, 0.27946644068637416, 0.4427979735659373], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0322921], dtype=float32), 0.014184313]. 
=============================================
[2019-03-24 05:19:12,336] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 4.3789143e-19 4.8041303e-17 3.4563164e-16 5.3439042e-08], sum to 1.0000
[2019-03-24 05:19:12,343] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2579
[2019-03-24 05:19:12,347] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 702025.5131238446 W.
[2019-03-24 05:19:12,351] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.05, 96.0, 1.0, 2.0, 0.3080015842735142, 1.0, 1.0, 0.3080015842735142, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 702025.5131238446, 702025.5131238446, 182391.9615073486], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5639400.0000, 
sim time next is 5640000.0000, 
raw observation next is [24.1, 96.0, 1.0, 2.0, 0.3123816732591819, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4973217973894624, 6.9112, 6.9112, 121.9260426156618, 712013.650905107, 712013.650905107, 198601.324313881], 
processed observation next is [0.0, 0.2608695652173913, 0.4481481481481482, 0.96, 1.0, 1.0, 0.18140675387997848, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.371652246736828, 0.0, 0.0, 0.8094621288201359, 0.2542905896089668, 0.2542905896089668, 0.3819256236805404], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.61865276], dtype=float32), 0.67215973]. 
=============================================
[2019-03-24 05:19:12,371] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[40.857933]
 [41.51242 ]
 [41.175697]
 [41.750744]
 [43.488235]], R is [[40.39188385]
 [40.63721085]
 [40.85259628]
 [40.44406891]
 [40.69129944]].
[2019-03-24 05:19:22,020] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.99990821e-01 1.11637406e-24 6.49617805e-23 1.07589696e-19
 9.13113581e-06], sum to 1.0000
[2019-03-24 05:19:22,027] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9885
[2019-03-24 05:19:22,029] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.53333333333333, 45.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6058608634861454, 6.911200000000001, 6.9112, 121.9260426156618, 451634.0123590674, 451634.0123590669, 132591.1631189824], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5852400.0000, 
sim time next is 5853000.0000, 
raw observation next is [27.36666666666667, 46.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6126792146287054, 6.911200000000001, 6.9112, 121.9260426156618, 456828.9431559874, 456828.9431559869, 133382.2646762591], 
processed observation next is [1.0, 0.7391304347826086, 0.569135802469136, 0.46, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5158490182858818, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16315319398428121, 0.16315319398428105, 0.2565043551466521], 
reward next is 0.7435, 
noisyNet noise sample is [array([0.5917107], dtype=float32), -0.25557774]. 
=============================================
[2019-03-24 05:19:22,050] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[66.70409 ]
 [65.758286]
 [63.244785]
 [58.908268]
 [58.09209 ]], R is [[65.99728394]
 [66.0823288 ]
 [66.16830444]
 [65.50662231]
 [64.85155487]].
[2019-03-24 05:19:22,107] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.1423057e-23 4.6828455e-25 1.2472777e-21 2.6926195e-08], sum to 1.0000
[2019-03-24 05:19:22,113] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3369
[2019-03-24 05:19:22,117] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.33333333333334, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8941397915910099, 6.9112, 6.9112, 121.9260426156618, 667457.4028083998, 667457.4028083998, 169661.9231578299], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5807400.0000, 
sim time next is 5808000.0000, 
raw observation next is [21.46666666666667, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8124582112287531, 6.9112, 6.9112, 121.9260426156618, 606429.1810520081, 606429.1810520081, 159712.7620258509], 
processed observation next is [1.0, 0.21739130434782608, 0.35061728395061736, 0.93, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7655727640359413, 0.0, 0.0, 0.8094621288201359, 0.21658185037571717, 0.21658185037571717, 0.3071399269727902], 
reward next is 0.6929, 
noisyNet noise sample is [array([0.2197411], dtype=float32), 0.99799955]. 
=============================================
[2019-03-24 05:19:22,140] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[59.027546]
 [59.3765  ]
 [59.540176]
 [59.36924 ]
 [59.22623 ]], R is [[59.43800354]
 [59.51735306]
 [59.63454819]
 [59.75009537]
 [59.86352539]].
[2019-03-24 05:19:22,556] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9978405e-01 1.8814216e-16 5.8379908e-15 1.1951935e-15 2.1600585e-04], sum to 1.0000
[2019-03-24 05:19:22,563] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9963
[2019-03-24 05:19:22,571] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1125006.699632794 W.
[2019-03-24 05:19:22,574] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.6, 45.5, 1.0, 2.0, 0.3062794062272127, 1.0, 2.0, 0.3062794062272127, 1.0, 1.0, 0.5017245252227269, 6.9112, 6.9112, 121.94756008, 1125006.699632794, 1125006.699632794, 257074.1664281652], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5830200.0000, 
sim time next is 5830800.0000, 
raw observation next is [26.66666666666667, 45.66666666666666, 1.0, 2.0, 0.3145201805592852, 1.0, 2.0, 0.3145201805592852, 1.0, 2.0, 0.5137356458661354, 6.911199999999999, 6.9112, 121.94756008, 1151465.87051022, 1151465.87051022, 260449.1950453456], 
processed observation next is [1.0, 0.4782608695652174, 0.5432098765432101, 0.45666666666666655, 1.0, 1.0, 0.18395259590391097, 1.0, 1.0, 0.18395259590391097, 1.0, 1.0, 0.3921695573326692, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.4112378108965072, 0.4112378108965072, 0.5008638366256646], 
reward next is 0.4991, 
noisyNet noise sample is [array([-1.0064266], dtype=float32), 0.084806636]. 
=============================================
[2019-03-24 05:19:23,922] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 2.8314308e-24 8.1059630e-26 1.2432427e-24 2.2404882e-08], sum to 1.0000
[2019-03-24 05:19:23,932] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6630
[2019-03-24 05:19:23,938] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.45, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.65575770502222, 6.9112, 6.9112, 121.9260426156618, 483465.3454825889, 483465.3454825889, 133814.6711245278], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5887800.0000, 
sim time next is 5888400.0000, 
raw observation next is [19.4, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6207892622021809, 6.9112, 6.9112, 121.9260426156618, 457395.6620533384, 457395.6620533384, 130352.7869381724], 
processed observation next is [1.0, 0.13043478260869565, 0.274074074074074, 0.85, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5259865777527261, 0.0, 0.0, 0.8094621288201359, 0.16335559359047802, 0.16335559359047802, 0.25067843641956233], 
reward next is 0.7493, 
noisyNet noise sample is [array([0.7870838], dtype=float32), 1.7913681]. 
=============================================
[2019-03-24 05:19:27,507] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.9067581e-01 1.0921227e-17 2.8572142e-16 1.1681511e-13 9.3241362e-03], sum to 1.0000
[2019-03-24 05:19:27,515] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9360
[2019-03-24 05:19:27,522] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1162450.020969312 W.
[2019-03-24 05:19:27,529] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.35, 57.83333333333333, 1.0, 2.0, 0.3254246006720528, 1.0, 1.0, 0.3254246006720528, 1.0, 1.0, 0.523326141253502, 6.9112, 6.9112, 121.94756008, 1162450.020969312, 1162450.020969312, 265636.1917016862], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5914200.0000, 
sim time next is 5914800.0000, 
raw observation next is [26.6, 57.0, 1.0, 2.0, 0.4864198805562661, 1.0, 2.0, 0.4864198805562661, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260425980895, 1161699.24759355, 1161699.24759355, 233495.4072824641], 
processed observation next is [1.0, 0.4782608695652174, 0.5407407407407407, 0.57, 1.0, 1.0, 0.3885950959003168, 1.0, 1.0, 0.3885950959003168, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621287034741, 0.41489258842626786, 0.41489258842626786, 0.44902962938935403], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8264427], dtype=float32), 1.1544522]. 
=============================================
[2019-03-24 05:19:29,002] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 4.1235061e-27 1.5324199e-25 1.1967386e-22 1.3066918e-10], sum to 1.0000
[2019-03-24 05:19:29,011] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1432
[2019-03-24 05:19:29,020] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.55, 79.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7067407979281294, 6.9112, 6.9112, 121.9260426156618, 528138.2389495781, 528138.2389495781, 145704.3777534836], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5967000.0000, 
sim time next is 5967600.0000, 
raw observation next is [22.53333333333333, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.700746010314613, 6.9112, 6.9112, 121.9260426156618, 523661.1529169891, 523661.1529169891, 144827.7974240418], 
processed observation next is [1.0, 0.043478260869565216, 0.3901234567901234, 0.79, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6259325128932663, 0.0, 0.0, 0.8094621288201359, 0.1870218403274961, 0.1870218403274961, 0.2785149950462342], 
reward next is 0.7215, 
noisyNet noise sample is [array([-0.17444578], dtype=float32), 0.12841357]. 
=============================================
[2019-03-24 05:19:35,683] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4112013e-02 5.7297842e-17 2.6315004e-13 5.6255239e-13 9.8588794e-01], sum to 1.0000
[2019-03-24 05:19:35,691] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7848
[2019-03-24 05:19:35,698] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.06666666666667, 54.33333333333334, 1.0, 2.0, 0.8672992365125938, 1.0, 1.0, 0.8672992365125938, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.925185272195, 1978401.340569756, 1978401.340569756, 372346.6523958827], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6096000.0000, 
sim time next is 6096600.0000, 
raw observation next is [30.2, 53.5, 1.0, 2.0, 0.5592842296749533, 1.0, 2.0, 0.5592842296749533, 1.0, 1.0, 0.8903987082582576, 6.911200000000001, 6.9112, 121.94756008, 1913610.055047292, 1913610.055047292, 373638.2544026123], 
processed observation next is [1.0, 0.5652173913043478, 0.674074074074074, 0.535, 1.0, 1.0, 0.47533836866065865, 1.0, 1.0, 0.47533836866065865, 1.0, 0.5, 0.862998385322822, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.68343216251689, 0.68343216251689, 0.7185351046204083], 
reward next is 0.2815, 
noisyNet noise sample is [array([-0.61545956], dtype=float32), 2.4207814]. 
=============================================
[2019-03-24 05:19:36,966] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-24 05:19:36,968] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:19:36,968] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:19:36,968] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:19:36,970] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:19:36,972] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:19:36,975] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:19:36,976] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:19:36,977] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:19:36,973] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:19:36,980] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:19:36,991] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run16
[2019-03-24 05:19:37,015] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run16
[2019-03-24 05:19:37,036] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run16
[2019-03-24 05:19:37,038] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run16
[2019-03-24 05:19:37,039] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run16
[2019-03-24 05:19:38,499] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00605219], dtype=float32), 0.010382339]
[2019-03-24 05:19:38,500] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.55032893, 44.49259628666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4719310623518582, 6.9112, 6.9112, 121.9260426156618, 336958.9458799263, 336958.9458799263, 110505.3344173985]
[2019-03-24 05:19:38,501] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:19:38,503] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 4.8419292e-21 1.0908371e-21 2.1169714e-19 2.7734198e-10], sampled 0.8298887670656708
[2019-03-24 05:19:40,388] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00605219], dtype=float32), 0.010382339]
[2019-03-24 05:19:40,390] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.83333333333333, 23.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5460023515026785, 6.911200000000001, 6.9112, 121.9260426156618, 389859.3150604327, 389859.3150604322, 105493.0038581308]
[2019-03-24 05:19:40,390] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:19:40,393] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 5.7148547e-22 1.3510120e-22 3.2112053e-20 1.4364102e-10], sampled 0.2831913016848765
[2019-03-24 05:19:42,871] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00605219], dtype=float32), 0.010382339]
[2019-03-24 05:19:42,872] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [31.73093759, 26.84563132, 1.0, 2.0, 0.8745615139402563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9257843174538, 1096630.026022787, 1096630.026022787, 215784.9605436226]
[2019-03-24 05:19:42,872] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:19:42,875] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.94388998e-01 1.26272606e-14 2.48062150e-13 2.27165465e-12
 5.61093213e-03], sampled 0.7986058008808251
[2019-03-24 05:19:42,879] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1096630.026022787 W.
[2019-03-24 05:19:45,105] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00605219], dtype=float32), 0.010382339]
[2019-03-24 05:19:45,107] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.67506059, 36.99138287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5749891580440554, 6.911199999999999, 6.9112, 121.9260426156618, 419477.5620206857, 419477.5620206862, 124252.2735263858]
[2019-03-24 05:19:45,108] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:19:45,110] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 4.1425011e-21 1.1259492e-21 2.1007856e-19 4.4555004e-10], sampled 0.6581771536568566
[2019-03-24 05:20:26,089] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00605219], dtype=float32), 0.010382339]
[2019-03-24 05:20:26,090] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [35.03333333333333, 59.5, 1.0, 2.0, 0.7967808912897022, 1.0, 2.0, 0.7967808912897022, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426155811, 1817377.856078657, 1817377.856078657, 342429.2874657822]
[2019-03-24 05:20:26,092] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:20:26,094] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [7.4021709e-01 2.2424640e-15 3.0947892e-13 1.5395461e-12 2.5978291e-01], sampled 0.2547030216172932
[2019-03-24 05:20:26,096] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1817377.856078657 W.
[2019-03-24 05:20:35,328] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00605219], dtype=float32), 0.010382339]
[2019-03-24 05:20:35,330] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.16666666666667, 99.00000000000001, 1.0, 2.0, 0.7714867756743363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 879323.4162060571, 879323.4162060571, 190125.1636187511]
[2019-03-24 05:20:35,332] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:20:35,335] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.9922037e-01 4.0194665e-16 6.4873872e-15 8.5841077e-14 7.7955879e-04], sampled 0.6290610064810737
[2019-03-24 05:20:35,338] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 879323.4162060571 W.
[2019-03-24 05:20:55,026] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00605219], dtype=float32), 0.010382339]
[2019-03-24 05:20:55,027] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.08333333333334, 85.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8720427453295815, 6.9112, 6.9112, 121.9260426156618, 641823.1732746133, 641823.1732746133, 171427.5506063064]
[2019-03-24 05:20:55,029] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:20:55,032] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.4909576e-21 5.6697758e-22 1.0137405e-19 6.8474509e-10], sampled 0.9434019040174502
[2019-03-24 05:21:02,611] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00605219], dtype=float32), 0.010382339]
[2019-03-24 05:21:02,612] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7625307901261226, 6.911200000000001, 6.9112, 121.9260426156618, 567403.1220713924, 567403.122071392, 155170.7522912922]
[2019-03-24 05:21:02,614] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:21:02,616] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.4498454e-21 4.1125518e-22 8.4047806e-20 3.1348060e-10], sampled 0.13200717887900904
[2019-03-24 05:21:22,293] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00605219], dtype=float32), 0.010382339]
[2019-03-24 05:21:22,295] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [19.1699122, 81.5144037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5362765587731015, 6.911200000000001, 6.9112, 121.9260426156618, 392581.8764816096, 392581.8764816091, 121558.5786446366]
[2019-03-24 05:21:22,297] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:21:22,301] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 4.2912806e-22 9.2125745e-23 2.3218021e-20 8.9518851e-11], sampled 0.05027752662311591
[2019-03-24 05:21:24,423] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00605219], dtype=float32), 0.010382339]
[2019-03-24 05:21:24,425] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.47595388, 83.54280894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6748051242828834, 6.9112, 6.9112, 121.9260426156618, 504085.9250326853, 504085.9250326853, 141115.1495212805]
[2019-03-24 05:21:24,427] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:21:24,429] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 9.7780513e-22 2.8596233e-22 5.8670124e-20 2.8410152e-10], sampled 0.9293406235403817
[2019-03-24 05:21:24,712] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00605219], dtype=float32), 0.010382339]
[2019-03-24 05:21:24,714] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.03333333333333, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6061110260744047, 6.911200000000001, 6.9112, 121.9260426156618, 450414.4715193914, 450414.4715193909, 131347.4839395481]
[2019-03-24 05:21:24,715] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:21:24,718] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.0356480e-21 2.3796084e-22 5.3865029e-20 1.5357468e-10], sampled 0.09498086765180613
[2019-03-24 05:21:25,441] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8339.5340 2340384417.1553 583.0000
[2019-03-24 05:21:25,480] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8388.2891 2293608518.3948 674.0000
[2019-03-24 05:21:25,510] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8542.0345 2258916112.2197 526.0000
[2019-03-24 05:21:25,539] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8621.9142 2219933439.7938 536.0000
[2019-03-24 05:21:25,591] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7814.8211 2531921076.8124 707.0000
[2019-03-24 05:21:26,605] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 375000, evaluation results [375000.0, 7814.821125041382, 2531921076.8124065, 707.0, 8542.034495311043, 2258916112.2197466, 526.0, 8621.914158961932, 2219933439.7937737, 536.0, 8339.534008313225, 2340384417.155311, 583.0, 8388.289050505593, 2293608518.3948417, 674.0]
[2019-03-24 05:21:29,094] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.4776869e-01 1.4846175e-17 1.6312255e-15 3.7267548e-15 5.2231282e-02], sum to 1.0000
[2019-03-24 05:21:29,100] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4734
[2019-03-24 05:21:29,105] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1466453.231061024 W.
[2019-03-24 05:21:29,110] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.93333333333334, 80.33333333333334, 1.0, 2.0, 0.6523021009155768, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9879361820995626, 6.911200000000001, 6.9112, 121.926042615619, 1466453.231061024, 1466453.231061023, 307023.3620177748], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6165600.0000, 
sim time next is 6166200.0000, 
raw observation next is [25.11666666666667, 79.16666666666666, 1.0, 2.0, 0.6475758847400142, 1.0, 1.0, 0.6475758847400142, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1486732.540749361, 1486732.540749362, 285295.2617237306], 
processed observation next is [1.0, 0.34782608695652173, 0.4858024691358026, 0.7916666666666665, 1.0, 1.0, 0.5804474818333502, 1.0, 0.5, 0.5804474818333502, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5309759074104861, 0.5309759074104864, 0.5486447340840973], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.17148551], dtype=float32), 0.9964657]. 
=============================================
[2019-03-24 05:21:30,388] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0965175e-03 5.9740661e-22 5.3968856e-17 3.1933953e-15 9.9890351e-01], sum to 1.0000
[2019-03-24 05:21:30,398] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6663
[2019-03-24 05:21:30,405] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.6, 61.0, 1.0, 2.0, 0.3376007133003787, 1.0, 2.0, 0.3376007133003787, 1.0, 2.0, 0.537471330461842, 6.911199999999999, 6.9112, 121.94756008, 1154576.346160889, 1154576.34616089, 270827.9454452133], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6179400.0000, 
sim time next is 6180000.0000, 
raw observation next is [28.73333333333333, 60.33333333333333, 1.0, 2.0, 0.3764877704751651, 1.0, 2.0, 0.3764877704751651, 1.0, 2.0, 0.5993807919471377, 6.9112, 6.9112, 121.94756008, 1287679.751814717, 1287679.751814717, 286935.7236970784], 
processed observation next is [1.0, 0.5217391304347826, 0.619753086419753, 0.6033333333333333, 1.0, 1.0, 0.2577235362799584, 1.0, 1.0, 0.2577235362799584, 1.0, 1.0, 0.49922598993392203, 0.0, 0.0, 0.8096049824067558, 0.4598856256481132, 0.4598856256481132, 0.5517994686482277], 
reward next is 0.4482, 
noisyNet noise sample is [array([1.5281656], dtype=float32), -0.09485215]. 
=============================================
[2019-03-24 05:21:30,429] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[66.07163 ]
 [65.70567 ]
 [64.91206 ]
 [64.83139 ]
 [64.718315]], R is [[65.82705688]
 [65.64796448]
 [65.45239258]
 [65.16568756]
 [64.83563232]].
[2019-03-24 05:21:31,724] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 5.5074654e-22 4.8405650e-20 1.9854379e-17 3.2388439e-08], sum to 1.0000
[2019-03-24 05:21:31,733] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4756
[2019-03-24 05:21:31,740] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.6, 65.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8888186783994974, 6.9112, 6.9112, 121.9260426156618, 651059.150198973, 651059.150198973, 174345.011793545], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6207600.0000, 
sim time next is 6208200.0000, 
raw observation next is [27.45, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8837445015249357, 6.911200000000001, 6.9112, 121.9260426156618, 648113.5129784888, 648113.5129784883, 173510.4129983332], 
processed observation next is [1.0, 0.8695652173913043, 0.5722222222222222, 0.66, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8546806269061696, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23146911177803173, 0.23146911177803156, 0.33367387115064073], 
reward next is 0.6663, 
noisyNet noise sample is [array([1.0470423], dtype=float32), -1.5687985]. 
=============================================
[2019-03-24 05:21:33,181] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.4303011e-27 2.3099041e-26 8.2123273e-23 1.9361203e-12], sum to 1.0000
[2019-03-24 05:21:33,188] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9211
[2019-03-24 05:21:33,193] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.9, 84.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7684876040567813, 6.9112, 6.9112, 121.9260426156618, 572757.9198683313, 572757.9198683313, 155241.3683118729], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6234600.0000, 
sim time next is 6235200.0000, 
raw observation next is [22.8, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7671300250611937, 6.911199999999999, 6.9112, 121.9260426156618, 571776.2603218477, 571776.2603218481, 155054.0257724297], 
processed observation next is [0.0, 0.17391304347826086, 0.4, 0.85, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7089125313264921, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20420580725780277, 0.20420580725780288, 0.2981808187931341], 
reward next is 0.7018, 
noisyNet noise sample is [array([1.3985336], dtype=float32), -0.6075346]. 
=============================================
[2019-03-24 05:21:34,042] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 2.5290789e-25 4.0294360e-24 2.6359378e-21 2.1407325e-12], sum to 1.0000
[2019-03-24 05:21:34,047] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7417
[2019-03-24 05:21:34,054] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.71666666666667, 84.50000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8178599446553844, 6.9112, 6.9112, 121.9260426156618, 605945.6487599636, 605945.6487599636, 163243.2606427542], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6246600.0000, 
sim time next is 6247200.0000, 
raw observation next is [23.83333333333334, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8215473084185528, 6.911199999999999, 6.9112, 121.9260426156618, 608396.1437569393, 608396.1437569398, 163821.5165902267], 
processed observation next is [0.0, 0.30434782608695654, 0.43827160493827183, 0.84, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7769341355231909, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21728433705604977, 0.21728433705604994, 0.31504137805812826], 
reward next is 0.6850, 
noisyNet noise sample is [array([0.10614567], dtype=float32), -1.172963]. 
=============================================
[2019-03-24 05:21:34,662] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.4094921e-26 1.0647368e-25 1.4668166e-23 2.4015276e-10], sum to 1.0000
[2019-03-24 05:21:34,671] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5791
[2019-03-24 05:21:34,676] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.2, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7642879443913861, 6.9112, 6.9112, 121.9260426156618, 569874.2895561907, 569874.2895561907, 154528.2646835608], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6238800.0000, 
sim time next is 6239400.0000, 
raw observation next is [22.31666666666667, 88.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7671522022894899, 6.9112, 6.9112, 121.9260426156618, 571891.9158904561, 571891.9158904561, 154973.6534223876], 
processed observation next is [0.0, 0.21739130434782608, 0.38209876543209886, 0.8866666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7089402528618624, 0.0, 0.0, 0.8094621288201359, 0.20424711281802002, 0.20424711281802002, 0.2980262565815146], 
reward next is 0.7020, 
noisyNet noise sample is [array([-0.16401143], dtype=float32), 0.2419656]. 
=============================================
[2019-03-24 05:21:35,054] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9999964e-01 9.9674472e-21 5.7813664e-19 5.6023229e-17 3.0581907e-07], sum to 1.0000
[2019-03-24 05:21:35,059] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4827
[2019-03-24 05:21:35,064] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 713245.0849384058 W.
[2019-03-24 05:21:35,069] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.15, 69.0, 1.0, 2.0, 0.6258433779100208, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 713245.0849384058, 713245.0849384058, 162578.3730187482], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6265800.0000, 
sim time next is 6266400.0000, 
raw observation next is [28.3, 68.33333333333333, 1.0, 2.0, 0.3137483139103504, 1.0, 1.0, 0.3137483139103504, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 715130.0971331133, 715130.0971331138, 183792.7168296731], 
processed observation next is [0.0, 0.5217391304347826, 0.6037037037037037, 0.6833333333333332, 1.0, 1.0, 0.18303370703613145, 1.0, 0.5, 0.18303370703613145, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.25540360611896906, 0.25540360611896923, 0.35344753236475596], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5951361], dtype=float32), -2.1325831]. 
=============================================
[2019-03-24 05:21:36,430] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.99890208e-01 1.40406947e-16 8.29007226e-17 2.88055852e-15
 1.09724635e-04], sum to 1.0000
[2019-03-24 05:21:36,436] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2948
[2019-03-24 05:21:36,443] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 694293.3613020515 W.
[2019-03-24 05:21:36,449] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.21666666666667, 65.66666666666666, 1.0, 2.0, 0.6007475094500472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 694293.3613020515, 694293.3613020515, 158673.6146459851], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6292200.0000, 
sim time next is 6292800.0000, 
raw observation next is [28.1, 66.0, 1.0, 2.0, 0.2021242250950278, 1.0, 1.0, 0.2021242250950278, 1.0, 1.0, 0.3217883490777316, 6.9112, 6.9112, 121.94756008, 691045.1586369374, 691045.1586369374, 221289.7714718819], 
processed observation next is [0.0, 0.8695652173913043, 0.5962962962962963, 0.66, 1.0, 1.0, 0.05014788701789025, 1.0, 0.5, 0.05014788701789025, 1.0, 0.5, 0.15223543634716444, 0.0, 0.0, 0.8096049824067558, 0.24680184237033478, 0.24680184237033478, 0.4255572528305421], 
reward next is 0.5744, 
noisyNet noise sample is [array([-1.6835198], dtype=float32), 0.8068242]. 
=============================================
[2019-03-24 05:21:36,827] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 6.5813523e-28 1.4801873e-25 1.2523068e-22 6.3746181e-10], sum to 1.0000
[2019-03-24 05:21:36,840] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9365
[2019-03-24 05:21:36,844] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.0, 77.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.92768292677112, 6.911200000000001, 6.9112, 121.9260426156618, 677086.94885644, 677086.9488564396, 180014.3551709818], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6300000.0000, 
sim time next is 6300600.0000, 
raw observation next is [25.81666666666667, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9261778343348768, 6.9112, 6.9112, 121.9260426156618, 676225.3141933124, 676225.3141933124, 179766.4535232735], 
processed observation next is [0.0, 0.9565217391304348, 0.5117283950617285, 0.78, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.907722292918596, 0.0, 0.0, 0.8094621288201359, 0.24150904078332586, 0.24150904078332586, 0.34570471831398747], 
reward next is 0.6543, 
noisyNet noise sample is [array([-1.0702361], dtype=float32), -0.7388955]. 
=============================================
[2019-03-24 05:21:38,856] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9999082e-01 4.5681513e-18 1.3747140e-18 8.0605408e-16 9.2136943e-06], sum to 1.0000
[2019-03-24 05:21:38,868] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1347
[2019-03-24 05:21:38,875] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 731433.2501939355 W.
[2019-03-24 05:21:38,881] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.85, 79.0, 1.0, 2.0, 0.3208975691406897, 1.0, 1.0, 0.3208975691406897, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 731433.2501939355, 731433.2501939359, 185551.3589258166], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6340200.0000, 
sim time next is 6340800.0000, 
raw observation next is [27.1, 78.0, 1.0, 2.0, 0.3270724782347899, 1.0, 2.0, 0.3270724782347899, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 745514.7845746785, 745514.784574679, 187084.4190780227], 
processed observation next is [0.0, 0.391304347826087, 0.5592592592592593, 0.78, 1.0, 1.0, 0.19889580742236895, 1.0, 1.0, 0.19889580742236895, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2662552802052423, 0.2662552802052425, 0.35977772899619753], 
reward next is 0.6402, 
noisyNet noise sample is [array([0.74340117], dtype=float32), -0.35027826]. 
=============================================
[2019-03-24 05:21:50,754] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.89733875e-01 6.04803100e-13 1.63362271e-12 1.96594867e-12
 1.02661215e-02], sum to 1.0000
[2019-03-24 05:21:50,761] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1943
[2019-03-24 05:21:50,766] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 816777.6769700322 W.
[2019-03-24 05:21:50,772] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.76666666666667, 87.66666666666667, 1.0, 2.0, 0.3583203077626756, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5704575996359008, 6.911199999999999, 6.9112, 121.9260426156618, 816777.6769700322, 816777.6769700326, 211589.8115102404], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6552600.0000, 
sim time next is 6553200.0000, 
raw observation next is [26.73333333333334, 87.33333333333334, 1.0, 2.0, 0.3559240272632692, 1.0, 1.0, 0.3559240272632692, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 811312.5546968123, 811312.5546968128, 194423.2924078845], 
processed observation next is [1.0, 0.8695652173913043, 0.5456790123456793, 0.8733333333333334, 1.0, 1.0, 0.23324288959913003, 1.0, 0.5, 0.23324288959913003, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2897544838202901, 0.2897544838202903, 0.37389094693823943], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.26639372], dtype=float32), 1.3947144]. 
=============================================
[2019-03-24 05:21:52,493] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 8.1330504e-22 2.7297440e-22 1.6106765e-22 1.1544631e-10], sum to 1.0000
[2019-03-24 05:21:52,497] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4549
[2019-03-24 05:21:52,500] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.6, 37.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5701640728450709, 6.911199999999999, 6.9112, 121.9260426156618, 422511.2205994647, 422511.2205994652, 127140.2470866364], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6630000.0000, 
sim time next is 6630600.0000, 
raw observation next is [28.3, 39.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5709411731006501, 6.9112, 6.9112, 121.9260426156618, 424090.0044466032, 424090.0044466032, 127905.768944922], 
processed observation next is [1.0, 0.7391304347826086, 0.6037037037037037, 0.395, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.46367646637581256, 0.0, 0.0, 0.8094621288201359, 0.15146071587378684, 0.15146071587378684, 0.24597263258638846], 
reward next is 0.7540, 
noisyNet noise sample is [array([-0.5587031], dtype=float32), 0.56647724]. 
=============================================
[2019-03-24 05:21:53,554] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9999440e-01 1.1190768e-17 8.0770291e-18 4.5690439e-16 5.5806536e-06], sum to 1.0000
[2019-03-24 05:21:53,561] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8647
[2019-03-24 05:21:53,577] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 934630.6456138123 W.
[2019-03-24 05:21:53,600] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.46666666666667, 41.16666666666666, 1.0, 2.0, 0.3717534061849328, 0.0, 2.0, 0.0, 1.0, 1.0, 0.62941909524886, 6.911199999999999, 6.9112, 121.9260426156618, 934630.6456138123, 934630.6456138127, 210580.0852446558], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6603000.0000, 
sim time next is 6603600.0000, 
raw observation next is [26.63333333333333, 40.33333333333334, 1.0, 2.0, 0.8073114077999644, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1020327.648662016, 1020327.648662016, 201134.5444532628], 
processed observation next is [1.0, 0.43478260869565216, 0.5419753086419752, 0.40333333333333343, 1.0, 1.0, 0.7706088188094814, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3644027316650057, 0.3644027316650057, 0.3867972008716592], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.47266], dtype=float32), -0.7678409]. 
=============================================
[2019-03-24 05:21:56,358] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 9.8276036e-21 1.5980349e-19 9.5614223e-22 5.8566143e-09], sum to 1.0000
[2019-03-24 05:21:56,364] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2781
[2019-03-24 05:21:56,370] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1036748.906541904 W.
[2019-03-24 05:21:56,374] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.05, 33.5, 1.0, 2.0, 0.2774972660336887, 1.0, 1.0, 0.2774972660336887, 1.0, 2.0, 0.4632339444238504, 6.911200000000001, 6.9112, 121.94756008, 1036748.906541904, 1036748.906541903, 245095.5284106077], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6696600.0000, 
sim time next is 6697200.0000, 
raw observation next is [28.2, 33.0, 1.0, 2.0, 0.3142267277654015, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5315078281465678, 6.911199999999999, 6.9112, 121.9260426156618, 789471.3048410595, 789471.30484106, 194502.1959854308], 
processed observation next is [1.0, 0.5217391304347826, 0.6, 0.33, 1.0, 1.0, 0.1836032473397637, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.41438478518320976, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.28195403744323555, 0.2819540374432357, 0.3740426845873669], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9226561], dtype=float32), 0.48237133]. 
=============================================
[2019-03-24 05:21:57,403] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.7397137e-01 9.7580803e-17 2.3181752e-14 5.1268310e-13 2.6028607e-02], sum to 1.0000
[2019-03-24 05:21:57,407] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2424
[2019-03-24 05:21:57,415] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 971627.3203240929 W.
[2019-03-24 05:21:57,419] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.55, 29.33333333333333, 1.0, 2.0, 0.3890612402604505, 1.0, 2.0, 0.3890612402604505, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 971627.3203240929, 971627.3203240933, 206254.1355530982], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6702600.0000, 
sim time next is 6703200.0000, 
raw observation next is [29.7, 29.0, 1.0, 2.0, 0.2691947006291037, 1.0, 2.0, 0.2691947006291037, 1.0, 1.0, 0.447972095370905, 6.911199999999999, 6.9112, 121.94756008, 1003297.647010402, 1003297.647010402, 242222.0905814065], 
processed observation next is [1.0, 0.6086956521739131, 0.6555555555555556, 0.29, 1.0, 1.0, 0.12999369122512347, 1.0, 1.0, 0.12999369122512347, 1.0, 0.5, 0.3099651192136312, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.3583205882180007, 0.3583205882180007, 0.46581171265655097], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.29136539], dtype=float32), 1.1603727]. 
=============================================
[2019-03-24 05:21:59,515] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 2.0338983e-28 1.4316775e-26 8.2681010e-28 6.1003427e-13], sum to 1.0000
[2019-03-24 05:21:59,525] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7645
[2019-03-24 05:21:59,533] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.16666666666667, 84.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5913897009786976, 6.911199999999999, 6.9112, 121.9260426156618, 426913.1180678609, 426913.1180678614, 123930.3340035176], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6756000.0000, 
sim time next is 6756600.0000, 
raw observation next is [18.08333333333333, 84.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5814063895314128, 6.9112, 6.9112, 121.9260426156618, 419347.5798206844, 419347.5798206844, 122957.6972188956], 
processed observation next is [1.0, 0.17391304347826086, 0.22530864197530848, 0.8466666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4767579869142659, 0.0, 0.0, 0.8094621288201359, 0.14976699279310157, 0.14976699279310157, 0.23645711003633768], 
reward next is 0.7635, 
noisyNet noise sample is [array([-1.1565181], dtype=float32), -2.328244]. 
=============================================
[2019-03-24 05:22:01,596] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 3.2769373e-29 1.9218906e-29 1.1413475e-23 7.3957301e-10], sum to 1.0000
[2019-03-24 05:22:01,603] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6230
[2019-03-24 05:22:01,611] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.93333333333334, 78.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.780921540071052, 6.9112, 6.9112, 121.9260426156618, 581423.9595103266, 581423.9595103266, 157181.8853218045], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6819600.0000, 
sim time next is 6820200.0000, 
raw observation next is [23.85, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7807065329897344, 6.911200000000001, 6.9112, 121.9260426156618, 581216.2608609654, 581216.2608609649, 157187.4125943856], 
processed observation next is [1.0, 0.9565217391304348, 0.43888888888888894, 0.79, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7258831662371679, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20757723602177333, 0.20757723602177316, 0.30228348575843383], 
reward next is 0.6977, 
noisyNet noise sample is [array([1.3552585], dtype=float32), 0.9995233]. 
=============================================
[2019-03-24 05:22:02,498] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.8774195e-01 2.5206869e-18 2.9610930e-16 1.7606163e-14 1.2258006e-02], sum to 1.0000
[2019-03-24 05:22:02,505] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5719
[2019-03-24 05:22:02,510] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.6, 58.5, 1.0, 2.0, 0.16, 1.0, 2.0, 0.16, 1.0, 2.0, 0.2516523073950272, 6.9112, 6.9112, 121.94756008, 554916.1675039008, 554916.1675039008, 206424.036118142], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6802200.0000, 
sim time next is 6802800.0000, 
raw observation next is [27.43333333333334, 59.33333333333333, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7569743115029742, 6.9112, 6.9112, 121.9260426156618, 560572.8511396579, 560572.8511396579, 155781.9216638947], 
processed observation next is [1.0, 0.7391304347826086, 0.5716049382716052, 0.5933333333333333, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.6962178893787176, 0.0, 0.0, 0.8094621288201359, 0.20020458969273497, 0.20020458969273497, 0.29958061858441287], 
reward next is 0.7004, 
noisyNet noise sample is [array([-0.05405921], dtype=float32), 0.11008965]. 
=============================================
[2019-03-24 05:22:06,359] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 3.7634206e-31 7.3037752e-31 2.2189136e-27 1.0863903e-12], sum to 1.0000
[2019-03-24 05:22:06,366] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1273
[2019-03-24 05:22:06,369] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.15, 58.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7197466809467944, 6.911199999999999, 6.9112, 121.9260426156618, 537761.4269045444, 537761.4269045448, 147704.341976904], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6898200.0000, 
sim time next is 6898800.0000, 
raw observation next is [26.0, 59.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7172579653334051, 6.9112, 6.9112, 121.9260426156618, 535919.550871799, 535919.550871799, 147360.3710704686], 
processed observation next is [0.0, 0.8695652173913043, 0.5185185185185185, 0.5933333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6465724566667563, 0.0, 0.0, 0.8094621288201359, 0.19139983959707108, 0.19139983959707108, 0.28338532898167035], 
reward next is 0.7166, 
noisyNet noise sample is [array([0.04863257], dtype=float32), -1.067506]. 
=============================================
[2019-03-24 05:22:15,123] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-24 05:22:15,124] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:22:15,126] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:22:15,126] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:22:15,127] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:22:15,128] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:22:15,129] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:22:15,132] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:22:15,127] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:22:15,132] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:22:15,134] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:22:15,145] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run17
[2019-03-24 05:22:15,145] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run17
[2019-03-24 05:22:15,194] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run17
[2019-03-24 05:22:15,195] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run17
[2019-03-24 05:22:15,196] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run17
[2019-03-24 05:22:16,944] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00605368], dtype=float32), 0.011166733]
[2019-03-24 05:22:16,945] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.77489885333333, 36.02696753, 1.0, 2.0, 0.8173129455277172, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260303752963, 1024994.687176763, 1024994.687176763, 203158.563777121]
[2019-03-24 05:22:16,945] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:22:16,947] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [9.3886375e-01 5.8015954e-20 1.6540793e-16 2.4660755e-16 6.1136190e-02], sampled 0.9123113833818138
[2019-03-24 05:22:16,948] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1024994.687176763 W.
[2019-03-24 05:22:20,246] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00605368], dtype=float32), 0.011166733]
[2019-03-24 05:22:20,247] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.14125208333333, 30.548494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5319116190252645, 6.9112, 6.9112, 121.9260426156618, 379795.6888451095, 379795.6888451095, 104943.4442933257]
[2019-03-24 05:22:20,248] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:22:20,251] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 5.8230193e-28 2.7746923e-27 2.5196996e-25 1.1405203e-12], sampled 0.4484120757266983
[2019-03-24 05:22:29,299] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00605368], dtype=float32), 0.011166733]
[2019-03-24 05:22:29,300] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.33333333333333, 49.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4387761809405348, 6.9112, 6.9112, 121.9260426156618, 313281.5139616701, 313281.5139616701, 97357.00821180272]
[2019-03-24 05:22:29,302] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:22:29,304] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 5.0119115e-28 3.2902429e-27 2.6008835e-25 2.1979577e-12], sampled 0.8317014297629379
[2019-03-24 05:22:36,838] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00605368], dtype=float32), 0.011166733]
[2019-03-24 05:22:36,839] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.179971075, 44.94516542500001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5812052387068342, 6.9112, 6.9112, 121.9260426156618, 429716.3629827091, 429716.3629827091, 127551.0932249719]
[2019-03-24 05:22:36,841] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:22:36,843] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.3849997e-28 8.8249490e-28 7.9825451e-26 1.0413872e-12], sampled 0.20780820444274817
[2019-03-24 05:22:42,038] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00605368], dtype=float32), 0.011166733]
[2019-03-24 05:22:42,039] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [18.98333333333333, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5934041086878035, 6.911199999999999, 6.9112, 121.9260426156618, 440045.2863595317, 440045.2863595322, 129481.3913895287]
[2019-03-24 05:22:42,040] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:22:42,043] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 5.1733743e-28 8.3105094e-27 4.3939434e-25 1.3705948e-11], sampled 0.3562047374190702
[2019-03-24 05:22:47,473] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00605368], dtype=float32), 0.011166733]
[2019-03-24 05:22:47,473] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.16666666666667, 54.5, 1.0, 2.0, 0.7620325733081678, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 869051.348892228, 869051.348892228, 188241.2580318584]
[2019-03-24 05:22:47,474] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:22:47,478] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.9327093e-01 7.8757045e-21 1.3099440e-17 2.8597295e-17 6.7290352e-03], sampled 0.5392377498370137
[2019-03-24 05:22:47,480] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 869051.348892228 W.
[2019-03-24 05:23:09,240] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00605368], dtype=float32), 0.011166733]
[2019-03-24 05:23:09,241] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.0, 84.0, 1.0, 2.0, 0.6966180347427905, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 793945.4975731691, 793945.4975731691, 175505.1869816261]
[2019-03-24 05:23:09,242] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:23:09,246] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.9693608e-01 6.0058311e-22 1.2264609e-18 3.0410253e-18 3.0638769e-03], sampled 0.0652267620969944
[2019-03-24 05:23:09,247] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 793945.4975731691 W.
[2019-03-24 05:23:14,557] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00605368], dtype=float32), 0.011166733]
[2019-03-24 05:23:14,558] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8676053518566094, 6.911199999999999, 6.9112, 121.9260426156618, 638963.6058271043, 638963.6058271046, 170745.3206385814]
[2019-03-24 05:23:14,559] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:23:14,563] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 4.5338996e-28 4.3116329e-27 2.9823032e-25 4.2002261e-12], sampled 0.3757161992227175
[2019-03-24 05:23:47,307] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00605368], dtype=float32), 0.011166733]
[2019-03-24 05:23:47,308] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.1, 62.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5708965417061681, 6.911200000000001, 6.9112, 121.9260426156618, 417867.5302177193, 417867.5302177188, 124492.1864236017]
[2019-03-24 05:23:47,311] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:23:47,313] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 6.0733498e-28 3.0842545e-27 2.6926835e-25 1.2925490e-12], sampled 0.8710035304623849
[2019-03-24 05:23:51,637] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00605368], dtype=float32), 0.011166733]
[2019-03-24 05:23:51,640] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.0, 73.33333333333334, 1.0, 2.0, 0.963262923237002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.918331638918825, 6.9112, 121.9259293113514, 1101716.851436081, 1098064.81828478, 231980.8446622759]
[2019-03-24 05:23:51,641] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:23:51,644] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [9.2489254e-01 1.8421674e-18 2.8213238e-15 4.0787783e-15 7.5107478e-02], sampled 0.06656479999117582
[2019-03-24 05:23:51,645] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1101716.851436081 W.
[2019-03-24 05:23:53,472] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00605368], dtype=float32), 0.011166733]
[2019-03-24 05:23:53,472] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.7, 74.5, 1.0, 2.0, 0.7562350616070284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 934099.6500975102, 934099.6500975102, 190009.8914644356]
[2019-03-24 05:23:53,473] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:23:53,475] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.3484217e-01 3.9134574e-19 8.0394068e-16 1.1452047e-15 6.5157868e-02], sampled 0.42852879590906046
[2019-03-24 05:23:53,476] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 934099.6500975102 W.
[2019-03-24 05:23:54,950] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00605368], dtype=float32), 0.011166733]
[2019-03-24 05:23:54,952] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.11666666666667, 93.50000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8549109865559612, 6.911199999999999, 6.9112, 121.9260426156618, 629298.3515822401, 629298.3515822405, 169202.0927413671]
[2019-03-24 05:23:54,953] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:23:54,956] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.00000000e+00 3.28898837e-27 8.88779630e-26 3.23258416e-24
 1.11609846e-10], sampled 0.41216568533987397
[2019-03-24 05:24:02,366] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00605368], dtype=float32), 0.011166733]
[2019-03-24 05:24:02,367] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [18.65697699, 90.15401908666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.775085871195345, 6.911200000000001, 6.9112, 121.9260426156618, 569689.323622128, 569689.3236221276, 145011.7818809164]
[2019-03-24 05:24:02,368] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:24:02,371] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.3535828e-27 4.0846817e-26 1.5023625e-24 8.6646731e-11], sampled 0.9787662599016559
[2019-03-24 05:24:03,300] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8603.8354 2222116967.1954 522.0000
[2019-03-24 05:24:03,416] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8536.4311 2260789667.8976 499.0000
[2019-03-24 05:24:03,469] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7815.3570 2535449988.7332 648.0000
[2019-03-24 05:24:03,525] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8379.5779 2295244776.1197 641.0000
[2019-03-24 05:24:03,624] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8334.6879 2342219724.0888 554.0000
[2019-03-24 05:24:04,641] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 400000, evaluation results [400000.0, 7815.357010323621, 2535449988.7331815, 648.0, 8536.431129140654, 2260789667.8976045, 499.0, 8603.835449543221, 2222116967.19538, 522.0, 8334.68788176321, 2342219724.0888357, 554.0, 8379.577932725619, 2295244776.1196938, 641.0]
[2019-03-24 05:24:06,977] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.8632985e-01 9.8302184e-21 3.8115990e-17 6.4017850e-17 1.3670176e-02], sum to 1.0000
[2019-03-24 05:24:06,987] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5281
[2019-03-24 05:24:06,994] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1106992.027078884 W.
[2019-03-24 05:24:06,999] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.15, 76.83333333333333, 1.0, 2.0, 0.3150520967566097, 1.0, 1.0, 0.3150520967566097, 1.0, 2.0, 0.5036403654285534, 6.911199999999999, 6.9112, 121.94756008, 1106992.027078884, 1106992.027078885, 261827.0359760064], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7059000.0000, 
sim time next is 7059600.0000, 
raw observation next is [23.9, 78.0, 1.0, 2.0, 0.5263945367305215, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8446161890380784, 6.911199999999999, 6.9112, 121.9260426156618, 1247021.83881714, 1247021.83881714, 265228.1018289297], 
processed observation next is [1.0, 0.7391304347826086, 0.4407407407407407, 0.78, 1.0, 1.0, 0.43618397229823985, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.8057702362975979, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4453649424346929, 0.4453649424346929, 0.510054041978711], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3835363], dtype=float32), 0.6167502]. 
=============================================
[2019-03-24 05:24:08,888] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.5922870e-01 7.7812963e-18 1.4344298e-13 3.5621213e-15 6.4077133e-01], sum to 1.0000
[2019-03-24 05:24:08,897] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3921
[2019-03-24 05:24:08,902] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.76666666666667, 73.33333333333334, 1.0, 2.0, 0.2442679003524922, 1.0, 2.0, 0.2442679003524922, 1.0, 1.0, 0.3969502606686524, 6.911199999999999, 6.9112, 121.94756008, 888252.9298100987, 888252.9298100992, 234636.0259067949], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7125600.0000, 
sim time next is 7126200.0000, 
raw observation next is [22.85, 72.5, 1.0, 2.0, 0.2349356926311771, 1.0, 2.0, 0.2349356926311771, 1.0, 2.0, 0.3817072950901816, 6.9112, 6.9112, 121.94756008, 854056.191320166, 854056.191320166, 231387.9627626381], 
processed observation next is [1.0, 0.4782608695652174, 0.4018518518518519, 0.725, 1.0, 1.0, 0.08920915789425847, 1.0, 1.0, 0.08920915789425847, 1.0, 1.0, 0.22713411886272697, 0.0, 0.0, 0.8096049824067558, 0.3050200683286307, 0.3050200683286307, 0.44497685146661176], 
reward next is 0.5550, 
noisyNet noise sample is [array([0.06722629], dtype=float32), 0.57548916]. 
=============================================
[2019-03-24 05:24:09,492] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1473484e-02 3.6467108e-17 1.0949560e-13 3.7979423e-14 9.8852646e-01], sum to 1.0000
[2019-03-24 05:24:09,501] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2670
[2019-03-24 05:24:09,505] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.9, 60.66666666666667, 1.0, 2.0, 0.2657046812835395, 1.0, 2.0, 0.2657046812835395, 1.0, 2.0, 0.4346098997711936, 6.9112, 6.9112, 121.94756008, 974237.1848528133, 974237.1848528133, 241936.2308512255], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7136400.0000, 
sim time next is 7137000.0000, 
raw observation next is [23.85, 61.0, 1.0, 2.0, 0.2642615580317247, 1.0, 2.0, 0.2642615580317247, 1.0, 2.0, 0.4323241016141324, 6.911200000000002, 6.9112, 121.94756008, 969134.5004045445, 969134.5004045436, 241401.8978785978], 
processed observation next is [1.0, 0.6086956521739131, 0.43888888888888894, 0.61, 1.0, 1.0, 0.12412090241871987, 1.0, 1.0, 0.12412090241871987, 1.0, 1.0, 0.2904051270176654, 1.7763568394002506e-16, 0.0, 0.8096049824067558, 0.3461194644301945, 0.34611946443019415, 0.4642344189973035], 
reward next is 0.5358, 
noisyNet noise sample is [array([-0.24823959], dtype=float32), -0.53453296]. 
=============================================
[2019-03-24 05:24:09,521] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[57.03111 ]
 [56.478928]
 [55.85276 ]
 [55.632294]
 [57.772285]], R is [[57.67463684]
 [57.63262939]
 [57.5865593 ]
 [57.0106926 ]
 [56.44058609]].
[2019-03-24 05:24:15,738] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 2.7807532e-27 1.1447261e-24 7.2316362e-24 2.1623778e-10], sum to 1.0000
[2019-03-24 05:24:15,746] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1737
[2019-03-24 05:24:15,753] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.83333333333333, 74.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6757327276753142, 6.9112, 6.9112, 121.9260426156618, 504729.7876253656, 504729.7876253656, 141089.5607893444], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7240200.0000, 
sim time next is 7240800.0000, 
raw observation next is [22.76666666666667, 74.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6733292326212765, 6.9112, 6.9112, 121.9260426156618, 502888.0009144154, 502888.0009144154, 140731.1128246027], 
processed observation next is [1.0, 0.8260869565217391, 0.3987654320987655, 0.7433333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5916615407765956, 0.0, 0.0, 0.8094621288201359, 0.17960285746943408, 0.17960285746943408, 0.2706367554319283], 
reward next is 0.7294, 
noisyNet noise sample is [array([0.8610244], dtype=float32), -1.3981236]. 
=============================================
[2019-03-24 05:24:18,482] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9999952e-01 8.8871867e-25 4.1471710e-25 1.1049793e-22 4.1800388e-07], sum to 1.0000
[2019-03-24 05:24:18,488] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3650
[2019-03-24 05:24:18,490] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.8, 83.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6943543299886182, 6.9112, 6.9112, 121.9260426156618, 518856.1939715584, 518856.1939715584, 143817.1104147113], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7338000.0000, 
sim time next is 7338600.0000, 
raw observation next is [21.65, 84.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6918348055565563, 6.911199999999999, 6.9112, 121.9260426156618, 516955.5983200212, 516955.5983200216, 143440.8833741406], 
processed observation next is [1.0, 0.9565217391304348, 0.35740740740740734, 0.845, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6147935069456953, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18462699940000757, 0.1846269994000077, 0.27584785264257805], 
reward next is 0.7242, 
noisyNet noise sample is [array([0.530737], dtype=float32), 0.47087273]. 
=============================================
[2019-03-24 05:24:29,793] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 8.2176564e-30 6.0619819e-29 9.5940922e-28 7.8299178e-13], sum to 1.0000
[2019-03-24 05:24:29,802] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5935
[2019-03-24 05:24:29,806] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.95, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7709911554878967, 6.9112, 6.9112, 121.9260426156618, 573627.2464989118, 573627.2464989118, 156234.268459588], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7511400.0000, 
sim time next is 7512000.0000, 
raw observation next is [21.9, 94.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7700760477648014, 6.9112, 6.9112, 121.9260426156618, 572982.4012826721, 572982.4012826721, 156101.7210163517], 
processed observation next is [0.0, 0.9565217391304348, 0.36666666666666664, 0.9433333333333332, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7125950597060018, 0.0, 0.0, 0.8094621288201359, 0.2046365718866686, 0.2046365718866686, 0.30019561733913785], 
reward next is 0.6998, 
noisyNet noise sample is [array([1.6991757], dtype=float32), 0.7604852]. 
=============================================
[2019-03-24 05:24:29,821] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[68.03874]
 [68.06624]
 [68.1116 ]
 [68.15996]
 [68.14434]], R is [[68.02840424]
 [68.04766846]
 [68.06645203]
 [68.0847168 ]
 [68.10243988]].
[2019-03-24 05:24:31,844] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 9.0901110e-31 6.0078102e-30 5.6357560e-27 6.1825257e-13], sum to 1.0000
[2019-03-24 05:24:31,850] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8156
[2019-03-24 05:24:31,854] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.0, 64.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8877198351231401, 6.911199999999999, 6.9112, 121.9260426156618, 649402.1302626427, 649402.1302626432, 174375.2345964715], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7572600.0000, 
sim time next is 7573200.0000, 
raw observation next is [28.0, 63.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8813411299966746, 6.9112, 6.9112, 121.9260426156618, 645809.8496416922, 645809.8496416922, 173313.7389744589], 
processed observation next is [0.0, 0.6521739130434783, 0.5925925925925926, 0.6333333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8516764124958431, 0.0, 0.0, 0.8094621288201359, 0.23064637487203293, 0.23064637487203293, 0.3332956518739594], 
reward next is 0.6667, 
noisyNet noise sample is [array([-0.14381133], dtype=float32), 0.21241884]. 
=============================================
[2019-03-24 05:24:33,502] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 2.2695871e-25 6.4693894e-28 5.1421997e-24 7.5957872e-11], sum to 1.0000
[2019-03-24 05:24:33,511] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8888
[2019-03-24 05:24:33,516] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.7, 85.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8278818694923791, 6.9112, 6.9112, 121.9260426156618, 612699.8413941469, 612699.8413941469, 164755.8612026791], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7594800.0000, 
sim time next is 7595400.0000, 
raw observation next is [23.65, 85.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8274440778121464, 6.9112, 6.9112, 121.9260426156618, 612403.2816684187, 612403.2816684187, 164691.4518166933], 
processed observation next is [0.0, 0.9130434782608695, 0.4314814814814814, 0.8566666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7843050972651829, 0.0, 0.0, 0.8094621288201359, 0.21871545773872095, 0.21871545773872095, 0.31671433041671787], 
reward next is 0.6833, 
noisyNet noise sample is [array([-0.52668446], dtype=float32), 0.7397983]. 
=============================================
[2019-03-24 05:24:34,295] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.8783790e-30 6.8517486e-29 3.7591114e-26 8.2725813e-13], sum to 1.0000
[2019-03-24 05:24:34,302] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5775
[2019-03-24 05:24:34,308] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.78333333333333, 86.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6623196145222917, 6.911200000000001, 6.9112, 121.9260426156618, 494184.4411305993, 494184.4411305989, 138777.1830674076], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7613400.0000, 
sim time next is 7614000.0000, 
raw observation next is [20.7, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6551875270836894, 6.911200000000001, 6.9112, 121.9260426156618, 488778.8531014838, 488778.8531014834, 137933.9964193436], 
processed observation next is [1.0, 0.13043478260869565, 0.3222222222222222, 0.87, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5689844088546118, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17456387610767277, 0.17456387610767263, 0.2652576854218146], 
reward next is 0.7347, 
noisyNet noise sample is [array([-0.46986791], dtype=float32), -1.1884365]. 
=============================================
[2019-03-24 05:24:34,324] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[71.39533]
 [71.34939]
 [71.09283]
 [70.23514]
 [69.39583]], R is [[71.58899689]
 [71.60623169]
 [71.62156677]
 [71.63484192]
 [71.63276672]].
[2019-03-24 05:24:35,693] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.2385597e-05 8.6026411e-23 1.5319075e-16 6.6266593e-18 9.9997759e-01], sum to 1.0000
[2019-03-24 05:24:35,706] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9884
[2019-03-24 05:24:35,711] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.33333333333334, 78.66666666666666, 1.0, 2.0, 0.3695606557915477, 1.0, 2.0, 0.3695606557915477, 1.0, 2.0, 0.5883525997704436, 6.9112, 6.9112, 121.94756008, 1263967.790888862, 1263967.790888862, 284004.8996007454], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7642200.0000, 
sim time next is 7642800.0000, 
raw observation next is [25.6, 78.0, 1.0, 2.0, 0.3865291684715722, 1.0, 2.0, 0.3865291684715722, 1.0, 2.0, 0.6153670245829198, 6.9112, 6.9112, 121.94756008, 1322053.408683427, 1322053.408683427, 291231.4567209751], 
processed observation next is [1.0, 0.4782608695652174, 0.5037037037037038, 0.78, 1.0, 1.0, 0.26967758151377647, 1.0, 1.0, 0.26967758151377647, 1.0, 1.0, 0.5192087807286497, 0.0, 0.0, 0.8096049824067558, 0.47216193167265247, 0.47216193167265247, 0.5600604936941829], 
reward next is 0.4399, 
noisyNet noise sample is [array([0.15077949], dtype=float32), -0.8534876]. 
=============================================
[2019-03-24 05:24:42,512] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 5.0691505e-29 2.5566733e-27 1.5648504e-26 2.8652122e-12], sum to 1.0000
[2019-03-24 05:24:42,519] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5859
[2019-03-24 05:24:42,523] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 72.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6194652884858165, 6.911200000000001, 6.9112, 121.9260426156618, 460428.1532035113, 460428.1532035109, 132697.105600418], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7770600.0000, 
sim time next is 7771200.0000, 
raw observation next is [21.86666666666667, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6151561906601286, 6.9112, 6.9112, 121.9260426156618, 457025.4851631747, 457025.4851631747, 132129.1154098917], 
processed observation next is [1.0, 0.9565217391304348, 0.36543209876543226, 0.73, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5189452383251607, 0.0, 0.0, 0.8094621288201359, 0.16322338755827667, 0.16322338755827667, 0.2540944527113302], 
reward next is 0.7459, 
noisyNet noise sample is [array([-0.6046204], dtype=float32), -2.3476396]. 
=============================================
[2019-03-24 05:24:44,272] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4918446e-04 8.6871300e-21 8.1600375e-18 1.6726065e-18 9.9985075e-01], sum to 1.0000
[2019-03-24 05:24:44,282] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1442
[2019-03-24 05:24:44,285] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.93333333333333, 36.16666666666666, 1.0, 2.0, 0.4001189871559699, 1.0, 2.0, 0.4001189871559699, 1.0, 2.0, 0.6420081471313719, 6.9112, 6.9112, 121.94756008, 1422004.980305209, 1422004.980305209, 297005.8655216326], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7829400.0000, 
sim time next is 7830000.0000, 
raw observation next is [31.0, 36.0, 1.0, 2.0, 0.3953910878769598, 1.0, 2.0, 0.3953910878769598, 1.0, 2.0, 0.6342959193443217, 6.9112, 6.9112, 121.94756008, 1404471.017194877, 1404471.017194877, 294944.556198032], 
processed observation next is [1.0, 0.6521739130434783, 0.7037037037037037, 0.36, 1.0, 1.0, 0.2802274855678093, 1.0, 1.0, 0.2802274855678093, 1.0, 1.0, 0.5428698991804021, 0.0, 0.0, 0.8096049824067558, 0.5015967918553131, 0.5015967918553131, 0.5672010696116], 
reward next is 0.4328, 
noisyNet noise sample is [array([-1.5754726], dtype=float32), -0.15357801]. 
=============================================
[2019-03-24 05:24:44,302] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[66.33651]
 [66.46375]
 [65.99081]
 [65.5182 ]
 [64.69789]], R is [[66.15284729]
 [65.92015076]
 [65.6989975 ]
 [65.50627136]
 [65.31424713]].
[2019-03-24 05:24:46,056] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9999559e-01 1.8823173e-21 8.3426510e-19 3.9904374e-19 4.3999712e-06], sum to 1.0000
[2019-03-24 05:24:46,067] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6320
[2019-03-24 05:24:46,072] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.93333333333333, 41.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6693853829123452, 6.911200000000001, 6.9112, 121.9260426156618, 500118.7458441036, 500118.7458441032, 142171.1629879669], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7839600.0000, 
sim time next is 7840200.0000, 
raw observation next is [29.61666666666667, 42.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.678043017865389, 6.911199999999999, 6.9112, 121.9260426156618, 506587.7141664604, 506587.7141664608, 143112.3043938983], 
processed observation next is [1.0, 0.7391304347826086, 0.6524691358024692, 0.4266666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5975537723317362, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1809241836308787, 0.18092418363087887, 0.2752159699882659], 
reward next is 0.7248, 
noisyNet noise sample is [array([-0.2804491], dtype=float32), -0.54364103]. 
=============================================
[2019-03-24 05:24:48,242] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 4.7940481e-30 4.2181029e-28 5.9911124e-27 3.2862543e-12], sum to 1.0000
[2019-03-24 05:24:48,252] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7734
[2019-03-24 05:24:48,257] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.35, 48.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7052306696823885, 6.9112, 6.9112, 121.9260426156618, 526829.2568489473, 526829.2568489473, 146318.6409387204], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7842600.0000, 
sim time next is 7843200.0000, 
raw observation next is [28.03333333333333, 50.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7052350671745777, 6.9112, 6.9112, 121.9260426156618, 526818.1634080211, 526818.1634080211, 146353.9972130531], 
processed observation next is [1.0, 0.782608695652174, 0.5938271604938271, 0.5, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6315438339682222, 0.0, 0.0, 0.8094621288201359, 0.18814934407429323, 0.18814934407429323, 0.28144999464048676], 
reward next is 0.7186, 
noisyNet noise sample is [array([-0.52386063], dtype=float32), -1.593626]. 
=============================================
[2019-03-24 05:24:51,343] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:24:51,344] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:24:51,351] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run3
[2019-03-24 05:24:51,796] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:24:51,797] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:24:51,797] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:24:51,797] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:24:51,799] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run3
[2019-03-24 05:24:51,820] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run3
[2019-03-24 05:24:51,853] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:24:51,853] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:24:51,855] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run3
[2019-03-24 05:24:51,935] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:24:51,935] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:24:51,936] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run3
[2019-03-24 05:24:51,960] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:24:51,960] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:24:51,962] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run3
[2019-03-24 05:24:52,023] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:24:52,024] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:24:52,025] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run3
[2019-03-24 05:24:52,082] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:24:52,083] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:24:52,084] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run3
[2019-03-24 05:24:52,162] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:24:52,163] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:24:52,164] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run3
[2019-03-24 05:24:52,225] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:24:52,225] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:24:52,227] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run3
[2019-03-24 05:24:52,286] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:24:52,286] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:24:52,288] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run3
[2019-03-24 05:24:52,342] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:24:52,343] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:24:52,344] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run3
[2019-03-24 05:24:52,370] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:24:52,381] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:24:52,383] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run3
[2019-03-24 05:24:52,453] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:24:52,453] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:24:52,455] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run3
[2019-03-24 05:24:52,593] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:24:52,594] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:24:52,595] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run3
[2019-03-24 05:24:52,659] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:24:52,659] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:24:52,661] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run3
[2019-03-24 05:24:52,876] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.8458916e-01 4.8357513e-05 6.1729283e-05 1.4169524e-04 1.5159120e-02], sum to 1.0000
[2019-03-24 05:24:52,877] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5820
[2019-03-24 05:24:52,894] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.3, 70.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6401637539787259, 6.9112, 6.9112, 121.9260426156618, 476623.1218437224, 476623.1218437224, 135393.9937986651], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1200.0000, 
sim time next is 1800.0000, 
raw observation next is [21.4, 71.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6075104954524263, 6.9112, 6.9112, 121.9260426156618, 449772.5575231512, 449772.5575231512, 130335.54451912], 
processed observation next is [1.0, 0.0, 0.3481481481481481, 0.715, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5093881193155329, 0.0, 0.0, 0.8094621288201359, 0.1606330562582683, 0.1606330562582683, 0.25064527792138463], 
reward next is 0.7494, 
noisyNet noise sample is [array([-0.60063374], dtype=float32), -0.4098094]. 
=============================================
[2019-03-24 05:24:54,729] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.1070005e-30 3.7774834e-33 9.1326327e-28 4.1947535e-14], sum to 1.0000
[2019-03-24 05:24:54,735] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3582
[2019-03-24 05:24:54,740] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.86666666666667, 62.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4626739700813369, 6.9112, 6.9112, 121.9260426156618, 330347.9552395532, 330347.9552395532, 104359.4336229165], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 24000.0000, 
sim time next is 24600.0000, 
raw observation next is [20.33333333333334, 59.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4737279104254347, 6.911200000000001, 6.9112, 121.9260426156618, 338242.1789497917, 338242.1789497912, 105845.2450791279], 
processed observation next is [1.0, 0.2608695652173913, 0.3086419753086422, 0.5966666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.34215988803179337, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12080077819635418, 0.120800778196354, 0.2035485482290921], 
reward next is 0.7965, 
noisyNet noise sample is [array([0.587192], dtype=float32), 0.44110096]. 
=============================================
[2019-03-24 05:24:55,738] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-24 05:24:55,741] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:24:55,742] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:24:55,743] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:24:55,743] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:24:55,744] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:24:55,746] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:24:55,746] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:24:55,747] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:24:55,747] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:24:55,748] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:24:55,759] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run18
[2019-03-24 05:24:55,782] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run18
[2019-03-24 05:24:55,783] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run18
[2019-03-24 05:24:55,783] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run18
[2019-03-24 05:24:55,865] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run18
[2019-03-24 05:25:01,947] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00605386], dtype=float32), 0.012369469]
[2019-03-24 05:25:01,948] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.53468570666667, 49.01386663666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7803651719279495, 6.911200000000001, 6.9112, 121.9260426156618, 581692.9315485081, 581692.9315485077, 150862.5640283202]
[2019-03-24 05:25:01,949] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:25:01,951] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 9.7467167e-25 1.5691792e-25 1.3588211e-23 3.6641572e-13], sampled 0.03967707631869022
[2019-03-24 05:25:32,970] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00605386], dtype=float32), 0.012369469]
[2019-03-24 05:25:32,971] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.0, 81.66666666666667, 1.0, 2.0, 0.582848452741555, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9279137188134554, 6.9112, 6.9112, 122.3005077781202, 1329021.491165986, 1329021.491165986, 287325.7158043771]
[2019-03-24 05:25:32,972] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:25:32,975] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.9999797e-01 4.5981807e-20 8.2203198e-19 6.4289635e-18 2.0273135e-06], sampled 0.09987327417452452
[2019-03-24 05:25:32,976] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1329021.491165986 W.
[2019-03-24 05:25:46,366] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00605386], dtype=float32), 0.012369469]
[2019-03-24 05:25:46,368] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.97182376, 102.2488493, 1.0, 2.0, 0.8499095966997885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 968764.4945315961, 968764.4945315961, 206484.6340935059]
[2019-03-24 05:25:46,369] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:25:46,374] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.9978358e-01 5.8207670e-18 2.8946242e-16 1.0824185e-15 2.1645674e-04], sampled 0.3323943864795226
[2019-03-24 05:25:46,374] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 968764.4945315961 W.
[2019-03-24 05:25:53,705] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00605386], dtype=float32), 0.012369469]
[2019-03-24 05:25:53,706] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.725237255, 81.00287681, 1.0, 2.0, 0.8197124786264364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156604, 998198.6293802859, 998198.6293802862, 202887.3417944156]
[2019-03-24 05:25:53,706] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:25:53,710] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.9835497e-01 2.5683131e-17 2.0314338e-15 6.0084841e-15 1.6450250e-03], sampled 0.8447071829364471
[2019-03-24 05:25:53,711] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 998198.6293802859 W.
[2019-03-24 05:26:25,573] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00605386], dtype=float32), 0.012369469]
[2019-03-24 05:26:25,575] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.75, 92.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6911920282090016, 6.911200000000001, 6.9112, 121.9260426156618, 516517.8330158389, 516517.8330158385, 143744.6859300658]
[2019-03-24 05:26:25,578] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:26:25,582] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 6.2704969e-26 9.2257437e-27 1.0106181e-24 8.4925658e-14], sampled 0.609687082893797
[2019-03-24 05:26:29,986] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00605386], dtype=float32), 0.012369469]
[2019-03-24 05:26:29,989] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9108563171402232, 6.9112, 6.9112, 121.9260426156618, 661296.5895181913, 661296.5895181913, 178319.489528411]
[2019-03-24 05:26:29,991] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:26:29,994] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.8478872e-25 3.1159494e-26 3.0185989e-24 1.9048996e-13], sampled 0.6951942628018994
[2019-03-24 05:26:43,112] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8553.5670 2258711948.7538 527.0000
[2019-03-24 05:26:43,333] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8397.0884 2294006084.2700 678.0000
[2019-03-24 05:26:43,338] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7843.3076 2532028197.9243 729.0000
[2019-03-24 05:26:43,436] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8357.0426 2340424968.5687 590.0000
[2019-03-24 05:26:43,588] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8627.5537 2219662840.9598 538.0000
[2019-03-24 05:26:44,603] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 425000, evaluation results [425000.0, 7843.307605771022, 2532028197.924337, 729.0, 8553.56699133894, 2258711948.7538295, 527.0, 8627.553730971833, 2219662840.9597588, 538.0, 8357.042609279439, 2340424968.568712, 590.0, 8397.088383313676, 2294006084.2700176, 678.0]
[2019-03-24 05:26:47,985] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 3.0715841e-28 2.7149802e-27 7.7528094e-27 3.7543140e-13], sum to 1.0000
[2019-03-24 05:26:47,990] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0837
[2019-03-24 05:26:47,993] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 75.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7408527163925221, 6.911200000000001, 6.9112, 121.9260426156618, 551789.9142875605, 551789.91428756, 146028.2735924112], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 109800.0000, 
sim time next is 110400.0000, 
raw observation next is [22.1, 74.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7053884691613791, 6.9112, 6.9112, 121.9260426156618, 525516.378036543, 525516.378036543, 142373.9844981825], 
processed observation next is [1.0, 0.2608695652173913, 0.3740740740740741, 0.7466666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6317355864517238, 0.0, 0.0, 0.8094621288201359, 0.1876844207273368, 0.1876844207273368, 0.27379612403496634], 
reward next is 0.7262, 
noisyNet noise sample is [array([-0.66436315], dtype=float32), -0.34411478]. 
=============================================
[2019-03-24 05:26:48,444] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 2.5619305e-31 2.7651268e-29 2.3766346e-28 2.3379939e-14], sum to 1.0000
[2019-03-24 05:26:48,452] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9374
[2019-03-24 05:26:48,459] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.8, 73.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6932096545818764, 6.9112, 6.9112, 121.9260426156618, 517475.1900157155, 517475.1900157155, 142353.1391927332], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 114600.0000, 
sim time next is 115200.0000, 
raw observation next is [22.9, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7216847306914578, 6.9112, 6.9112, 121.9260426156618, 538860.0367576529, 538860.0367576529, 145626.6754042933], 
processed observation next is [1.0, 0.34782608695652173, 0.4037037037037037, 0.73, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6521059133643222, 0.0, 0.0, 0.8094621288201359, 0.19245001312773316, 0.19245001312773316, 0.28005129885441016], 
reward next is 0.7199, 
noisyNet noise sample is [array([-1.2502666], dtype=float32), 1.1864814]. 
=============================================
[2019-03-24 05:26:50,097] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.4012238e-06 9.9619730e-24 1.7617677e-19 3.6811638e-20 9.9999356e-01], sum to 1.0000
[2019-03-24 05:26:50,106] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5103
[2019-03-24 05:26:50,109] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [37.31666666666666, 9.5, 1.0, 2.0, 0.4321805580979134, 1.0, 2.0, 0.4321805580979134, 1.0, 2.0, 0.7120397162992674, 6.9112, 6.9112, 121.94756008, 1597376.180325646, 1597376.180325646, 309855.9438421468], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 143400.0000, 
sim time next is 144000.0000, 
raw observation next is [37.3, 9.0, 1.0, 2.0, 0.4377386087283457, 1.0, 2.0, 0.4377386087283457, 1.0, 2.0, 0.7227463842196412, 6.911200000000001, 6.9112, 121.94756008, 1621219.143089143, 1621219.143089143, 312271.6244702842], 
processed observation next is [1.0, 0.6956521739130435, 0.9370370370370369, 0.09, 1.0, 1.0, 0.33064120086707816, 1.0, 1.0, 0.33064120086707816, 1.0, 1.0, 0.6534329802745514, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.579006836817551, 0.579006836817551, 0.6005223547505466], 
reward next is 0.3995, 
noisyNet noise sample is [array([-0.097882], dtype=float32), -0.7211476]. 
=============================================
[2019-03-24 05:26:50,129] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[63.42663 ]
 [63.323963]
 [63.20344 ]
 [62.9929  ]
 [62.88709 ]], R is [[63.33566284]
 [63.10643005]
 [62.87843704]
 [62.64525986]
 [62.40193558]].
[2019-03-24 05:26:51,214] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 2.3117735e-33 3.9513720e-35 2.3562928e-31 4.6232580e-18], sum to 1.0000
[2019-03-24 05:26:51,220] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5179
[2019-03-24 05:26:51,232] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.8, 14.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6576264735230277, 6.9112, 6.9112, 121.9260426156618, 469586.1291278343, 469586.1291278343, 121064.9044175306], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 162000.0000, 
sim time next is 162600.0000, 
raw observation next is [31.71666666666667, 13.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.659759517997422, 6.9112, 6.9112, 121.9260426156618, 471109.7231940881, 471109.7231940881, 120297.714390342], 
processed observation next is [1.0, 0.9130434782608695, 0.730246913580247, 0.1366666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5746993974967776, 0.0, 0.0, 0.8094621288201359, 0.16825347256931716, 0.16825347256931716, 0.23134175844296537], 
reward next is 0.7687, 
noisyNet noise sample is [array([-0.12547891], dtype=float32), 0.4276262]. 
=============================================
[2019-03-24 05:26:53,858] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 3.2251502e-28 7.3815131e-28 1.9431383e-27 3.8772916e-15], sum to 1.0000
[2019-03-24 05:26:53,867] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0113
[2019-03-24 05:26:53,869] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.46666666666667, 57.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6270018494096673, 6.9112, 6.9112, 121.9260426156618, 466108.7465854274, 466108.7465854274, 133488.9403430283], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 204000.0000, 
sim time next is 204600.0000, 
raw observation next is [24.83333333333333, 54.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6218307249101465, 6.911200000000001, 6.9112, 121.9260426156618, 461897.0048083175, 461897.004808317, 132706.4652583316], 
processed observation next is [0.0, 0.34782608695652173, 0.4753086419753085, 0.5466666666666665, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.527288406137683, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16496321600297054, 0.16496321600297037, 0.25520474088140693], 
reward next is 0.7448, 
noisyNet noise sample is [array([-1.4248592], dtype=float32), -1.1985178]. 
=============================================
[2019-03-24 05:26:55,475] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 2.1289512e-32 5.0015448e-34 2.2063377e-34 3.0125273e-15], sum to 1.0000
[2019-03-24 05:26:55,486] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2192
[2019-03-24 05:26:55,492] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.7, 26.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6191484404242006, 6.9112, 6.9112, 121.9260426156618, 449839.9795027294, 449839.9795027294, 127395.4224602873], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 244800.0000, 
sim time next is 245400.0000, 
raw observation next is [29.36666666666667, 26.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.62502148979816, 6.911200000000001, 6.9112, 121.9260426156618, 453908.9614898568, 453908.9614898563, 127840.8698377663], 
processed observation next is [0.0, 0.8695652173913043, 0.64320987654321, 0.26833333333333337, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5312768622476999, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16211034338923458, 0.16211034338923438, 0.24584782661108903], 
reward next is 0.7542, 
noisyNet noise sample is [array([-0.57797307], dtype=float32), 0.298906]. 
=============================================
[2019-03-24 05:26:59,646] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 5.6211131e-27 3.2742490e-30 2.1509400e-27 1.7770126e-12], sum to 1.0000
[2019-03-24 05:26:59,655] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7343
[2019-03-24 05:26:59,660] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.75, 31.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5878490637114607, 6.911200000000001, 6.9112, 121.9260426156618, 424943.5181986219, 424943.5181986215, 123843.0951215168], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 322200.0000, 
sim time next is 322800.0000, 
raw observation next is [27.63333333333333, 31.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5865382132175067, 6.9112, 6.9112, 121.9260426156618, 423860.3492061299, 423860.3492061299, 123682.2287626829], 
processed observation next is [0.0, 0.7391304347826086, 0.5790123456790122, 0.3133333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4831727665218833, 0.0, 0.0, 0.8094621288201359, 0.1513786961450464, 0.1513786961450464, 0.23785043992823635], 
reward next is 0.7621, 
noisyNet noise sample is [array([-2.1250682], dtype=float32), -0.19128945]. 
=============================================
[2019-03-24 05:27:04,163] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.3332934e-28 3.8211649e-26 6.2681803e-25 4.2782102e-12], sum to 1.0000
[2019-03-24 05:27:04,170] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.9030246e-29 1.6733902e-28 6.9256487e-27 2.7101761e-14], sum to 1.0000
[2019-03-24 05:27:04,170] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7360
[2019-03-24 05:27:04,178] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3567
[2019-03-24 05:27:04,181] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.6, 29.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6018667438386478, 6.911199999999999, 6.9112, 121.9260426156618, 442594.2863759515, 442594.286375952, 128175.5795048403], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 411600.0000, 
sim time next is 412200.0000, 
raw observation next is [29.45, 30.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5982908511579024, 6.911200000000001, 6.9112, 121.9260426156618, 439761.622480201, 439761.6224802005, 127752.5186183133], 
processed observation next is [1.0, 0.782608695652174, 0.6462962962962963, 0.3, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4978635639473779, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1570577223143575, 0.15705772231435733, 0.24567792041983327], 
reward next is 0.7543, 
noisyNet noise sample is [array([-0.08586277], dtype=float32), 0.5172085]. 
=============================================
[2019-03-24 05:27:04,185] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.1, 34.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5815429275813947, 6.911200000000001, 6.9112, 121.9260426156618, 426511.1483839597, 426511.1483839593, 125805.9234302001], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 417600.0000, 
sim time next is 418200.0000, 
raw observation next is [27.95, 34.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.577088728738294, 6.911200000000001, 6.9112, 121.9260426156618, 423051.2240079078, 423051.2240079073, 125324.6821474231], 
processed observation next is [1.0, 0.8695652173913043, 0.5907407407407407, 0.34333333333333343, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4713609109228674, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15108972285996708, 0.1510897228599669, 0.2410090041296598], 
reward next is 0.7590, 
noisyNet noise sample is [array([-2.0493662], dtype=float32), 0.59327704]. 
=============================================
[2019-03-24 05:27:06,572] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 2.4999493e-24 3.5898748e-24 3.9882251e-23 8.3086316e-10], sum to 1.0000
[2019-03-24 05:27:06,580] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3665
[2019-03-24 05:27:06,583] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.2, 76.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4722653321308973, 6.911199999999999, 6.9112, 121.9260426156618, 337197.6670878755, 337197.667087876, 108119.2446693024], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 450600.0000, 
sim time next is 451200.0000, 
raw observation next is [18.5, 75.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4639546558280127, 6.9112, 6.9112, 121.9260426156618, 331262.5588531865, 331262.5588531865, 108592.6153015747], 
processed observation next is [1.0, 0.21739130434782608, 0.24074074074074073, 0.75, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.32994331978501584, 0.0, 0.0, 0.8094621288201359, 0.11830805673328089, 0.11830805673328089, 0.20883195250302827], 
reward next is 0.7912, 
noisyNet noise sample is [array([-0.01872073], dtype=float32), 0.09023014]. 
=============================================
[2019-03-24 05:27:08,917] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 7.2162681e-29 4.0800464e-31 1.5759065e-29 1.2533368e-18], sum to 1.0000
[2019-03-24 05:27:08,921] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6191
[2019-03-24 05:27:08,926] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.8, 32.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5979703050564789, 6.911200000000001, 6.9112, 121.9260426156618, 442907.6813709493, 442907.6813709488, 129568.6681518713], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 500400.0000, 
sim time next is 501000.0000, 
raw observation next is [29.56666666666667, 33.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5941777320684944, 6.9112, 6.9112, 121.9260426156618, 440273.863345944, 440273.863345944, 129327.5453341455], 
processed observation next is [1.0, 0.8260869565217391, 0.6506172839506174, 0.33, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.492722165085618, 0.0, 0.0, 0.8094621288201359, 0.15724066548069426, 0.15724066548069426, 0.2487068179502798], 
reward next is 0.7513, 
noisyNet noise sample is [array([-1.5708791], dtype=float32), -0.09521432]. 
=============================================
[2019-03-24 05:27:08,948] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[64.6356 ]
 [64.24829]
 [64.38991]
 [64.14859]
 [64.08516]], R is [[64.46029663]
 [64.56652069]
 [64.67121887]
 [64.77431488]
 [64.8755188 ]].
[2019-03-24 05:27:09,294] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 2.8578283e-34 2.2543534e-36 1.0399127e-34 1.6318060e-18], sum to 1.0000
[2019-03-24 05:27:09,305] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8065
[2019-03-24 05:27:09,310] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.8, 32.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5979703050712758, 6.911200000000001, 6.9112, 121.9260426156618, 442907.6813709493, 442907.6813709488, 129568.6681463597], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 500400.0000, 
sim time next is 501000.0000, 
raw observation next is [29.56666666666667, 33.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5941777320713033, 6.9112, 6.9112, 121.9260426156618, 440273.863345944, 440273.863345944, 129327.5453330715], 
processed observation next is [1.0, 0.8260869565217391, 0.6506172839506174, 0.33, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4927221650891291, 0.0, 0.0, 0.8094621288201359, 0.15724066548069426, 0.15724066548069426, 0.24870681794821442], 
reward next is 0.7513, 
noisyNet noise sample is [array([1.0754385], dtype=float32), 0.19592157]. 
=============================================
[2019-03-24 05:27:09,329] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[78.83618 ]
 [78.7727  ]
 [78.66435 ]
 [78.589935]
 [78.55562 ]], R is [[78.73973083]
 [78.70316315]
 [78.66648865]
 [78.62963104]
 [78.59228516]].
[2019-03-24 05:27:12,353] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.1698244e-01 8.3332913e-18 5.4697445e-15 4.6729244e-13 4.8301753e-01], sum to 1.0000
[2019-03-24 05:27:12,361] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1584
[2019-03-24 05:27:12,371] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1293035.34405931 W.
[2019-03-24 05:27:12,373] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.2, 44.66666666666667, 1.0, 2.0, 0.535204269495619, 1.0, 2.0, 0.535204269495619, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1293035.34405931, 1293035.344059311, 249538.5498970082], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 555600.0000, 
sim time next is 556200.0000, 
raw observation next is [27.9, 46.0, 1.0, 2.0, 0.5403141999049415, 1.0, 2.0, 0.5403141999049415, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1306530.605959381, 1306530.605959381, 251256.5461569646], 
processed observation next is [1.0, 0.43478260869565216, 0.5888888888888888, 0.46, 1.0, 1.0, 0.45275499988683504, 1.0, 1.0, 0.45275499988683504, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.46661807355692175, 0.46661807355692175, 0.4831856656864704], 
reward next is 0.5168, 
noisyNet noise sample is [array([-1.1277984], dtype=float32), -0.3591187]. 
=============================================
[2019-03-24 05:27:13,216] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 2.2038636e-20 2.4013242e-19 5.1863604e-19 4.0811252e-10], sum to 1.0000
[2019-03-24 05:27:13,222] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1596
[2019-03-24 05:27:13,235] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1395022.934264087 W.
[2019-03-24 05:27:13,240] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.9, 34.0, 1.0, 2.0, 0.3881329682510834, 1.0, 1.0, 0.3881329682510834, 1.0, 2.0, 0.6260321672241924, 6.9112, 6.9112, 121.94756008, 1395022.934264087, 1395022.934264087, 291510.9961564331], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 570600.0000, 
sim time next is 571200.0000, 
raw observation next is [31.0, 33.66666666666667, 1.0, 2.0, 0.565729399914921, 1.0, 2.0, 0.565729399914921, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1365334.309937318, 1365334.309937318, 259658.6653463115], 
processed observation next is [1.0, 0.6086956521739131, 0.7037037037037037, 0.3366666666666667, 1.0, 1.0, 0.4830111903749059, 1.0, 1.0, 0.4830111903749059, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.487619396406185, 0.487619396406185, 0.49934358720444516], 
reward next is 0.5007, 
noisyNet noise sample is [array([0.13558373], dtype=float32), 1.2887887]. 
=============================================
[2019-03-24 05:27:14,418] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.9537221e-01 1.7361870e-18 9.7175001e-17 8.2828303e-16 1.0462776e-01], sum to 1.0000
[2019-03-24 05:27:14,427] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2617
[2019-03-24 05:27:14,437] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1413392.9449676 W.
[2019-03-24 05:27:14,444] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.13333333333334, 34.0, 1.0, 2.0, 0.5954394906850684, 1.0, 2.0, 0.5954394906850684, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1413392.9449676, 1413392.9449676, 268989.8469093078], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 645600.0000, 
sim time next is 646200.0000, 
raw observation next is [32.35, 33.0, 1.0, 2.0, 0.5714710265692957, 1.0, 2.0, 0.5714710265692957, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1362794.965667949, 1362794.965667949, 261013.7692912241], 
processed observation next is [1.0, 0.4782608695652174, 0.7537037037037038, 0.33, 1.0, 1.0, 0.4898464602015425, 1.0, 1.0, 0.4898464602015425, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.48671248773855325, 0.48671248773855325, 0.5019495563292771], 
reward next is 0.4981, 
noisyNet noise sample is [array([-0.00468344], dtype=float32), -0.78874254]. 
=============================================
[2019-03-24 05:27:15,436] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.2813063e-28 5.9645144e-30 6.4606195e-25 1.1359845e-13], sum to 1.0000
[2019-03-24 05:27:15,442] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9984
[2019-03-24 05:27:15,446] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.58333333333334, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5999103756430578, 6.9112, 6.9112, 121.9260426156618, 436627.382288394, 436627.382288394, 126006.1799336753], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 623400.0000, 
sim time next is 624000.0000, 
raw observation next is [20.86666666666667, 69.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5647835793174846, 6.9112, 6.9112, 121.9260426156618, 411906.1307011053, 411906.1307011053, 123323.5459442276], 
processed observation next is [1.0, 0.21739130434782608, 0.3283950617283952, 0.69, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4559794741468557, 0.0, 0.0, 0.8094621288201359, 0.14710933239325188, 0.14710933239325188, 0.23716066527736077], 
reward next is 0.7628, 
noisyNet noise sample is [array([1.1625023], dtype=float32), -0.5386932]. 
=============================================
[2019-03-24 05:27:15,462] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[68.0939  ]
 [67.77553 ]
 [67.85009 ]
 [67.92227 ]
 [67.732086]], R is [[67.77355957]
 [67.853508  ]
 [67.94470215]
 [68.0340271 ]
 [68.12173462]].
[2019-03-24 05:27:15,946] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 2.2254096e-32 5.3176673e-32 7.1778793e-31 6.6036737e-16], sum to 1.0000
[2019-03-24 05:27:15,954] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5341
[2019-03-24 05:27:15,957] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.06666666666667, 61.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6477041885516412, 6.9112, 6.9112, 121.9260426156618, 478169.4941766353, 478169.4941766353, 133386.1331685991], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 628800.0000, 
sim time next is 629400.0000, 
raw observation next is [23.33333333333334, 60.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6454252984476012, 6.9112, 6.9112, 121.9260426156618, 476952.7248635819, 476952.7248635819, 133426.7146425157], 
processed observation next is [1.0, 0.2608695652173913, 0.4197530864197533, 0.6, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5567816230595015, 0.0, 0.0, 0.8094621288201359, 0.17034025887985066, 0.17034025887985066, 0.2565898358509917], 
reward next is 0.7434, 
noisyNet noise sample is [array([-0.56005245], dtype=float32), -0.47436026]. 
=============================================
[2019-03-24 05:27:31,718] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 3.3910702e-30 9.9169247e-30 2.9994367e-27 1.5355072e-13], sum to 1.0000
[2019-03-24 05:27:31,724] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2332
[2019-03-24 05:27:31,727] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.86666666666667, 58.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8018571383553161, 6.9112, 6.9112, 121.9260426156618, 587209.8712836981, 587209.8712836981, 146855.8968322484], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 980400.0000, 
sim time next is 981000.0000, 
raw observation next is [23.0, 58.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9082638147245633, 6.9112, 6.9112, 121.9260426156618, 666343.8320234707, 666343.8320234707, 158862.4821737531], 
processed observation next is [1.0, 0.34782608695652173, 0.4074074074074074, 0.58, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.885329768405704, 0.0, 0.0, 0.8094621288201359, 0.23797994000838238, 0.23797994000838238, 0.30550477341106363], 
reward next is 0.6945, 
noisyNet noise sample is [array([0.5106817], dtype=float32), -0.0691758]. 
=============================================
[2019-03-24 05:27:31,742] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[70.738815]
 [71.17022 ]
 [71.078125]
 [71.000534]
 [71.08069 ]], R is [[70.33887482]
 [70.35307312]
 [70.40647888]
 [70.4571228 ]
 [70.50422668]].
[2019-03-24 05:27:33,261] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-24 05:27:33,262] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:27:33,262] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:27:33,264] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:27:33,268] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:27:33,269] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:27:33,272] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:27:33,267] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:27:33,273] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:27:33,272] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:27:33,269] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:27:33,288] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run19
[2019-03-24 05:27:33,310] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run19
[2019-03-24 05:27:33,346] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run19
[2019-03-24 05:27:33,366] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run19
[2019-03-24 05:27:33,398] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run19
[2019-03-24 05:27:35,602] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00605386], dtype=float32), 0.013374037]
[2019-03-24 05:27:35,604] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [19.76666666666667, 49.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6240058861754223, 6.911199999999999, 6.9112, 121.9260426156618, 445571.9676638002, 445571.9676638006, 108388.8178229852]
[2019-03-24 05:27:35,605] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:27:35,607] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 6.3207316e-28 7.6822967e-28 4.0184411e-26 2.7668943e-14], sampled 0.20660229394599927
[2019-03-24 05:27:53,091] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00605386], dtype=float32), 0.013374037]
[2019-03-24 05:27:53,092] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.65580779333334, 41.21031489333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5480953090884252, 6.911200000000001, 6.9112, 121.9260426156618, 402927.9383229974, 402927.938322997, 123351.3169040275]
[2019-03-24 05:27:53,093] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:27:53,095] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 5.4053126e-29 6.5356896e-29 4.0092064e-27 8.1579378e-15], sampled 0.13054602027165896
[2019-03-24 05:28:01,223] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00605386], dtype=float32), 0.013374037]
[2019-03-24 05:28:01,223] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.47508198, 64.339456945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9649837622316348, 6.9112, 6.9112, 121.9260426156618, 691373.8443591198, 691373.8443591198, 186864.3324022608]
[2019-03-24 05:28:01,225] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:28:01,229] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 6.3397329e-29 1.0725663e-28 5.7620581e-27 1.8108465e-14], sampled 0.1836879203348981
[2019-03-24 05:28:01,230] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 691373.8443591198 W.
[2019-03-24 05:28:14,400] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00605386], dtype=float32), 0.013374037]
[2019-03-24 05:28:14,402] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.33333333333334, 98.0, 1.0, 2.0, 0.662060663351956, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 754540.5837400875, 754540.5837400875, 169084.11365559]
[2019-03-24 05:28:14,405] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:28:14,408] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 4.8713234e-24 1.7008306e-22 1.4165298e-21 3.9413304e-09], sampled 0.22047401317639803
[2019-03-24 05:28:14,409] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 754540.5837400875 W.
[2019-03-24 05:28:28,533] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00605386], dtype=float32), 0.013374037]
[2019-03-24 05:28:28,535] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.95093819666667, 90.77592990000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8144892121727808, 6.911200000000001, 6.9112, 121.9260426156618, 602274.315502599, 602274.3155025986, 163242.8958820876]
[2019-03-24 05:28:28,536] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:28:28,539] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 9.2619139e-29 1.6564265e-28 8.4794320e-27 2.3418679e-14], sampled 0.08660097669725564
[2019-03-24 05:28:50,261] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00605386], dtype=float32), 0.013374037]
[2019-03-24 05:28:50,263] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.85, 74.5, 1.0, 2.0, 0.7190117134818207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 819481.5359949768, 819481.5359949768, 179775.9853047547]
[2019-03-24 05:28:50,263] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:28:50,267] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 3.2329754e-26 7.3185234e-25 9.5922820e-24 1.0214934e-10], sampled 0.48678850741663826
[2019-03-24 05:28:50,269] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 819481.5359949768 W.
[2019-03-24 05:29:00,415] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00605386], dtype=float32), 0.013374037]
[2019-03-24 05:29:00,416] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.16666666666666, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8710610632672549, 6.9112, 6.9112, 121.9260426156618, 640143.8608827848, 640143.8608827848, 171543.9313017364]
[2019-03-24 05:29:00,417] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:29:00,420] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 6.1935548e-30 1.1111684e-29 6.8461345e-28 6.4170543e-15], sampled 0.606695880188631
[2019-03-24 05:29:20,544] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8558.6511 2258349589.2695 536.0000
[2019-03-24 05:29:20,598] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8632.3601 2219297961.4369 543.0000
[2019-03-24 05:29:20,886] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8363.8049 2339472239.3583 616.0000
[2019-03-24 05:29:20,896] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.6234 2529719186.9184 831.0000
[2019-03-24 05:29:20,905] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8405.4972 2292959084.8233 698.0000
[2019-03-24 05:29:21,918] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 450000, evaluation results [450000.0, 7841.62338275036, 2529719186.918448, 831.0, 8558.651143062722, 2258349589.2694674, 536.0, 8632.36009710971, 2219297961.4369493, 543.0, 8363.804901582153, 2339472239.3583117, 616.0, 8405.49719520256, 2292959084.8233175, 698.0]
[2019-03-24 05:29:22,648] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9999559e-01 4.8510276e-19 7.1129947e-18 1.3340326e-17 4.3951022e-06], sum to 1.0000
[2019-03-24 05:29:22,655] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5083
[2019-03-24 05:29:22,661] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 935030.0161449253 W.
[2019-03-24 05:29:22,665] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.3, 53.0, 1.0, 2.0, 0.3779501008330155, 0.0, 1.0, 0.0, 1.0, 1.0, 0.625712554656786, 6.911199999999999, 6.9112, 121.9260426156618, 935030.0161449253, 935030.0161449257, 213947.3357488605], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 997200.0000, 
sim time next is 997800.0000, 
raw observation next is [25.33333333333334, 52.83333333333334, 1.0, 2.0, 0.2683144654571507, 1.0, 1.0, 0.2683144654571507, 1.0, 2.0, 0.4400271980030064, 6.911199999999999, 6.9112, 121.94756008, 986674.6655590298, 986674.6655590303, 242737.3745850238], 
processed observation next is [1.0, 0.5652173913043478, 0.49382716049382736, 0.5283333333333334, 1.0, 1.0, 0.1289457922108937, 1.0, 0.5, 0.1289457922108937, 1.0, 1.0, 0.3000339975037579, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.3523838091282249, 0.3523838091282251, 0.4668026434327381], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5260235], dtype=float32), -0.17596465]. 
=============================================
[2019-03-24 05:29:24,722] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 4.8193103e-32 2.0925986e-31 7.2850834e-29 5.4173594e-17], sum to 1.0000
[2019-03-24 05:29:24,730] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3850
[2019-03-24 05:29:24,737] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.16666666666667, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6247656041571785, 6.911200000000001, 6.9112, 121.9260426156618, 455140.0409065691, 455140.0409065686, 128378.5577268429], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1045200.0000, 
sim time next is 1045800.0000, 
raw observation next is [21.1, 66.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5589943875474842, 6.9112, 6.9112, 121.9260426156618, 407242.8929824411, 407242.8929824411, 122648.362131136], 
processed observation next is [1.0, 0.08695652173913043, 0.3370370370370371, 0.665, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.44874298443435523, 0.0, 0.0, 0.8094621288201359, 0.14544389035087182, 0.14544389035087182, 0.23586223486756924], 
reward next is 0.7641, 
noisyNet noise sample is [array([-0.351741], dtype=float32), 0.45649347]. 
=============================================
[2019-03-24 05:29:25,514] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.6779206e-30 2.4794274e-30 2.3191648e-27 9.8088321e-15], sum to 1.0000
[2019-03-24 05:29:25,519] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9195
[2019-03-24 05:29:25,523] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.03333333333333, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5350589315918213, 6.9112, 6.9112, 121.9260426156618, 389829.385167547, 389829.385167547, 120655.8339030919], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1046400.0000, 
sim time next is 1047000.0000, 
raw observation next is [20.96666666666667, 67.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5289246891221746, 6.911200000000001, 6.9112, 121.9260426156618, 385395.3665520636, 385395.3665520631, 120164.4483840187], 
processed observation next is [1.0, 0.08695652173913043, 0.3320987654320988, 0.675, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4111558614027182, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13764120234002272, 0.13764120234002253, 0.23108547766157442], 
reward next is 0.7689, 
noisyNet noise sample is [array([0.84592396], dtype=float32), -1.0290245]. 
=============================================
[2019-03-24 05:29:25,548] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[73.08505]
 [73.28089]
 [72.98553]
 [72.59647]
 [72.81115]], R is [[72.94807434]
 [72.98656464]
 [73.02083588]
 [73.04374695]
 [73.03103638]].
[2019-03-24 05:29:28,200] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9974102e-01 1.3196722e-13 2.7704084e-13 2.9429779e-12 2.5897744e-04], sum to 1.0000
[2019-03-24 05:29:28,208] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0655
[2019-03-24 05:29:28,214] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1364270.952821771 W.
[2019-03-24 05:29:28,220] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.53333333333333, 43.66666666666667, 1.0, 2.0, 0.9333473130026205, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.294681785274169, 6.9112, 121.9244302163886, 1364270.952821771, 1167896.600516522, 229305.717996046], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1093800.0000, 
sim time next is 1094400.0000, 
raw observation next is [26.5, 44.0, 1.0, 2.0, 0.5261840584913623, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8767233172951922, 6.911199999999999, 6.9112, 121.9258116896134, 1308935.68096327, 1308935.68096327, 261696.628119104], 
processed observation next is [1.0, 0.6956521739130435, 0.5370370370370371, 0.44, 1.0, 1.0, 0.4359334029659075, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.84590414661899, -8.881784197001253e-17, 0.0, 0.8094605957113207, 0.46747702891545356, 0.46747702891545356, 0.5032627463828923], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.340924], dtype=float32), -0.4716658]. 
=============================================
[2019-03-24 05:29:28,460] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.9355423e-01 1.2433152e-13 1.0618146e-12 4.9058865e-12 6.4457478e-03], sum to 1.0000
[2019-03-24 05:29:28,468] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2851
[2019-03-24 05:29:28,475] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 966598.3072209365 W.
[2019-03-24 05:29:28,479] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.6, 41.0, 1.0, 2.0, 0.764048917514315, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9259651226588, 966598.3072209365, 966598.307220936, 192058.5001909694], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1086000.0000, 
sim time next is 1086600.0000, 
raw observation next is [26.75, 40.5, 1.0, 2.0, 0.3726812969031551, 1.0, 1.0, 0.3726812969031551, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260425920322, 932449.6593761765, 932449.6593761765, 201776.922572295], 
processed observation next is [1.0, 0.5652173913043478, 0.5462962962962963, 0.405, 1.0, 1.0, 0.2531920201228037, 1.0, 0.5, 0.2531920201228037, 0.0, 1.0, -0.25, 0.0, 0.0, 0.80946212866326, 0.3330177354914916, 0.3330177354914916, 0.38803254340825966], 
reward next is 0.6120, 
noisyNet noise sample is [array([1.9553808], dtype=float32), 0.5214399]. 
=============================================
[2019-03-24 05:29:28,630] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 7.7647484e-24 3.5605950e-23 3.3285025e-22 5.2418126e-12], sum to 1.0000
[2019-03-24 05:29:28,635] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7763
[2019-03-24 05:29:28,639] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.85, 69.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5427451800367489, 6.911199999999999, 6.9112, 121.9260426156618, 396696.5531632054, 396696.5531632059, 121830.1890654504], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1113000.0000, 
sim time next is 1113600.0000, 
raw observation next is [20.7, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5409067416243152, 6.9112, 6.9112, 121.9260426156618, 394907.3273808458, 394907.3273808458, 121483.6247325095], 
processed observation next is [1.0, 0.9130434782608695, 0.3222222222222222, 0.7, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4261334270303939, 0.0, 0.0, 0.8094621288201359, 0.1410383312074449, 0.1410383312074449, 0.23362235525482597], 
reward next is 0.7664, 
noisyNet noise sample is [array([0.42839247], dtype=float32), 0.5116362]. 
=============================================
[2019-03-24 05:29:35,160] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.2177488e-27 2.6097787e-25 1.1401328e-24 1.5317990e-08], sum to 1.0000
[2019-03-24 05:29:35,167] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8441
[2019-03-24 05:29:35,175] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.3, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5604457425477941, 6.911199999999999, 6.9112, 121.9260426156618, 412642.8571621415, 412642.8571621419, 124740.7079866557], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1213200.0000, 
sim time next is 1213800.0000, 
raw observation next is [18.26666666666667, 93.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5585723268338015, 6.9112, 6.9112, 121.9260426156618, 410992.4739848207, 410992.4739848207, 124439.289871485], 
processed observation next is [1.0, 0.043478260869565216, 0.23209876543209887, 0.9383333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4482154085422519, 0.0, 0.0, 0.8094621288201359, 0.14678302642315025, 0.14678302642315025, 0.23930632667593268], 
reward next is 0.7607, 
noisyNet noise sample is [array([1.1683934], dtype=float32), 1.2065647]. 
=============================================
[2019-03-24 05:29:41,959] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 4.2517546e-20 2.0720042e-21 5.2463921e-20 1.2085691e-09], sum to 1.0000
[2019-03-24 05:29:41,964] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0648
[2019-03-24 05:29:41,971] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1118903.869494831 W.
[2019-03-24 05:29:41,975] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.75, 32.5, 1.0, 2.0, 0.4573844872490565, 1.0, 1.0, 0.4573844872490565, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1118903.869494831, 1118903.869494831, 225530.8843382305], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1348200.0000, 
sim time next is 1348800.0000, 
raw observation next is [30.76666666666667, 32.33333333333334, 1.0, 2.0, 0.440491299584311, 1.0, 2.0, 0.440491299584311, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1077634.554215837, 1077634.554215837, 220493.7856087002], 
processed observation next is [1.0, 0.6086956521739131, 0.6950617283950619, 0.3233333333333334, 1.0, 1.0, 0.3339182137908464, 1.0, 1.0, 0.3339182137908464, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3848694836485132, 0.3848694836485132, 0.4240265107859619], 
reward next is 0.5760, 
noisyNet noise sample is [array([-1.2519624], dtype=float32), -0.70505375]. 
=============================================
[2019-03-24 05:29:42,287] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 1.4810229e-33 4.2505848e-36 2.3661648e-31 5.3698850e-20], sum to 1.0000
[2019-03-24 05:29:42,292] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2209
[2019-03-24 05:29:42,299] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.5, 38.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5813473231971856, 6.9112, 6.9112, 121.9260426156618, 431580.8006293143, 431580.8006293143, 128693.7799427999], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1363200.0000, 
sim time next is 1363800.0000, 
raw observation next is [28.25, 39.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5866810334798606, 6.9112, 6.9112, 121.9260426156618, 435570.1032520838, 435570.1032520838, 129210.6264540277], 
processed observation next is [1.0, 0.782608695652174, 0.6018518518518519, 0.39, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.48335129184982567, 0.0, 0.0, 0.8094621288201359, 0.1555607511614585, 0.1555607511614585, 0.24848197395005328], 
reward next is 0.7515, 
noisyNet noise sample is [array([0.41706812], dtype=float32), -0.20651802]. 
=============================================
[2019-03-24 05:29:44,008] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 5.7642827e-33 7.4906747e-33 1.6815087e-30 6.4808060e-19], sum to 1.0000
[2019-03-24 05:29:44,019] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6673
[2019-03-24 05:29:44,025] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.15, 63.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6032254564117109, 6.911200000000001, 6.9112, 121.9260426156618, 447465.9499623754, 447465.9499623749, 130493.6383004982], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1377000.0000, 
sim time next is 1377600.0000, 
raw observation next is [22.93333333333333, 64.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6031121513850493, 6.9112, 6.9112, 121.9260426156618, 447290.0274702317, 447290.0274702317, 130420.9028103715], 
processed observation next is [1.0, 0.9565217391304348, 0.40493827160493817, 0.6466666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5038901892313116, 0.0, 0.0, 0.8094621288201359, 0.1597464383822256, 0.1597464383822256, 0.25080942848148363], 
reward next is 0.7492, 
noisyNet noise sample is [array([-0.13384692], dtype=float32), -0.14356105]. 
=============================================
[2019-03-24 05:29:48,326] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 5.5658987e-32 2.9195922e-33 4.4008919e-31 1.7141730e-19], sum to 1.0000
[2019-03-24 05:29:48,335] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9525
[2019-03-24 05:29:48,341] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.8, 68.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5829369220402939, 6.9112, 6.9112, 121.9260426156618, 429709.7266107418, 429709.7266107418, 126997.6806524677], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1483200.0000, 
sim time next is 1483800.0000, 
raw observation next is [21.71666666666667, 69.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5852074084916945, 6.911199999999999, 6.9112, 121.9260426156618, 431632.8994712498, 431632.8994712502, 127334.5642169373], 
processed observation next is [0.0, 0.17391304347826086, 0.3598765432098766, 0.69, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4815092606146181, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15415460695401778, 0.15415460695401792, 0.24487416195564865], 
reward next is 0.7551, 
noisyNet noise sample is [array([0.03604854], dtype=float32), 0.91496474]. 
=============================================
[2019-03-24 05:29:53,803] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9999714e-01 2.7801372e-22 2.1703611e-19 1.0985401e-18 2.8415739e-06], sum to 1.0000
[2019-03-24 05:29:53,807] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5364
[2019-03-24 05:29:53,814] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 931048.8820335323 W.
[2019-03-24 05:29:53,826] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.63333333333333, 48.33333333333334, 1.0, 2.0, 0.2546737560172651, 1.0, 2.0, 0.2546737560172651, 1.0, 2.0, 0.415546386328587, 6.911199999999999, 6.9112, 121.94756008, 931048.8820335323, 931048.8820335327, 238097.3016500815], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1600800.0000, 
sim time next is 1601400.0000, 
raw observation next is [26.71666666666667, 47.66666666666667, 1.0, 2.0, 0.7671781741942794, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 950614.9609234993, 950614.9609234993, 192329.207307729], 
processed observation next is [1.0, 0.5217391304347826, 0.5450617283950618, 0.47666666666666674, 1.0, 1.0, 0.7228311597550945, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.339505343186964, 0.339505343186964, 0.36986386020717116], 
reward next is 0.6301, 
noisyNet noise sample is [array([-0.2806643], dtype=float32), 1.1497343]. 
=============================================
[2019-03-24 05:29:54,876] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.3459457e-01 3.9839808e-16 4.9424454e-11 1.0752688e-11 6.5405443e-02], sum to 1.0000
[2019-03-24 05:29:54,883] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2023
[2019-03-24 05:29:54,890] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1201985.025601809 W.
[2019-03-24 05:29:54,893] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.53333333333333, 56.66666666666667, 1.0, 2.0, 0.4855174023580784, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8042808927439653, 6.911200000000001, 6.9112, 121.9259285124238, 1201985.025601809, 1201985.025601808, 248052.7436607438], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1588800.0000, 
sim time next is 1589400.0000, 
raw observation next is [24.65, 56.5, 1.0, 2.0, 0.3262534534942262, 1.0, 1.0, 0.3262534534942262, 1.0, 2.0, 0.5330072779492787, 6.911200000000002, 6.9112, 121.94756008, 1194739.535947394, 1194739.535947393, 265067.8236313969], 
processed observation next is [1.0, 0.391304347826087, 0.46851851851851845, 0.565, 1.0, 1.0, 0.1979207779693169, 1.0, 0.5, 0.1979207779693169, 1.0, 1.0, 0.41625909743659834, 1.7763568394002506e-16, 0.0, 0.8096049824067558, 0.4266926914097836, 0.42669269140978316, 0.5097458146757633], 
reward next is 0.4903, 
noisyNet noise sample is [array([-0.6703236], dtype=float32), 0.272151]. 
=============================================
[2019-03-24 05:29:55,397] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9999952e-01 9.8907136e-20 1.1679438e-18 2.2065494e-17 4.4604113e-07], sum to 1.0000
[2019-03-24 05:29:55,401] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2470
[2019-03-24 05:29:55,407] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1202985.365771003 W.
[2019-03-24 05:29:55,410] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.75, 42.16666666666666, 1.0, 2.0, 0.490261587361649, 1.0, 1.0, 0.490261587361649, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1202985.365771003, 1202985.365771003, 235729.6889095955], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1612200.0000, 
sim time next is 1612800.0000, 
raw observation next is [27.8, 42.0, 1.0, 2.0, 0.9364925516775584, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.272964297803585, 6.9112, 121.9245186764474, 1349120.235426713, 1163866.896313807, 229865.8214678767], 
processed observation next is [1.0, 0.6956521739130435, 0.5851851851851853, 0.42, 1.0, 1.0, 0.9243958948542362, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.03617642978035853, 0.0, 0.8094520114485374, 0.48182865550954035, 0.4156667486835025, 0.44204965666899365], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7987227], dtype=float32), 1.674863]. 
=============================================
[2019-03-24 05:29:57,822] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9999928e-01 1.2720246e-18 1.3487701e-16 5.9794941e-17 6.8550224e-07], sum to 1.0000
[2019-03-24 05:29:57,829] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3921
[2019-03-24 05:29:57,836] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 927439.0028354987 W.
[2019-03-24 05:29:57,842] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.36666666666667, 71.66666666666667, 1.0, 2.0, 0.7453417947127923, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 927439.0028354987, 927439.0028354987, 187962.3221762104], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1689600.0000, 
sim time next is 1690200.0000, 
raw observation next is [22.55, 71.0, 1.0, 2.0, 0.4038193210240698, 1.0, 1.0, 0.4038193210240698, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 993762.9779615626, 993762.977961563, 210063.7395302442], 
processed observation next is [1.0, 0.5652173913043478, 0.3907407407407408, 0.71, 1.0, 1.0, 0.290261096457226, 1.0, 0.5, 0.290261096457226, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.35491534927198665, 0.3549153492719868, 0.40396872986585425], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.46644318], dtype=float32), -1.2487952]. 
=============================================
[2019-03-24 05:30:02,772] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9999988e-01 4.2256429e-19 1.3220772e-17 5.1974762e-17 7.7134573e-08], sum to 1.0000
[2019-03-24 05:30:02,773] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0580
[2019-03-24 05:30:02,780] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1043790.856860907 W.
[2019-03-24 05:30:02,784] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.25, 66.0, 1.0, 2.0, 0.8642694705562337, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260424066681, 1043790.856860907, 1043790.856860907, 212315.0478318783], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1773000.0000, 
sim time next is 1773600.0000, 
raw observation next is [25.3, 65.66666666666666, 1.0, 2.0, 0.4387177794470661, 1.0, 1.0, 0.4387177794470661, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426155981, 1049367.171039602, 1049367.171039602, 219191.0103624127], 
processed observation next is [1.0, 0.5217391304347826, 0.49259259259259264, 0.6566666666666666, 1.0, 1.0, 0.3318068802941263, 1.0, 0.5, 0.3318068802941263, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288197131, 0.3747739896570007, 0.3747739896570007, 0.42152117377387055], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6284598], dtype=float32), -0.87963885]. 
=============================================
[2019-03-24 05:30:05,410] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 2.2826725e-32 3.0623718e-31 1.1392461e-31 2.0499322e-17], sum to 1.0000
[2019-03-24 05:30:05,416] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6428
[2019-03-24 05:30:05,424] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.35, 73.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6505595313068578, 6.911199999999999, 6.9112, 121.9260426156618, 485157.6145745868, 485157.6145745873, 137252.6577933889], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1794600.0000, 
sim time next is 1795200.0000, 
raw observation next is [21.9, 74.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6325606272242734, 6.911200000000001, 6.9112, 121.9260426156618, 471069.5523858909, 471069.5523858904, 134741.0936004649], 
processed observation next is [1.0, 0.782608695652174, 0.36666666666666664, 0.7466666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5407007840303417, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1682391258521039, 0.1682391258521037, 0.25911748769320175], 
reward next is 0.7409, 
noisyNet noise sample is [array([0.04425745], dtype=float32), 0.26676548]. 
=============================================
[2019-03-24 05:30:05,590] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.00000000e+00 2.14130530e-26 7.54999914e-26 1.99218218e-25
 1.12507144e-13], sum to 1.0000
[2019-03-24 05:30:05,600] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3096
[2019-03-24 05:30:05,608] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.56666666666667, 91.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5638867439105396, 6.911200000000001, 6.9112, 121.9260426156618, 414752.052467285, 414752.0524672845, 124829.8502722001], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1828200.0000, 
sim time next is 1828800.0000, 
raw observation next is [18.6, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5630101229983537, 6.911200000000001, 6.9112, 121.9260426156618, 414183.1975982408, 414183.1975982403, 124790.7352771534], 
processed observation next is [1.0, 0.17391304347826086, 0.2444444444444445, 0.91, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4537626537479421, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1479225705708003, 0.1479225705708001, 0.23998218322529502], 
reward next is 0.7600, 
noisyNet noise sample is [array([1.7184768], dtype=float32), -0.8113967]. 
=============================================
[2019-03-24 05:30:10,579] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 3.0032386e-34 2.7602523e-33 6.1691672e-32 7.2036179e-21], sum to 1.0000
[2019-03-24 05:30:10,581] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5504
[2019-03-24 05:30:10,586] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.1, 91.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.627936341212489, 6.9112, 6.9112, 121.9260426156618, 468295.8093931106, 468295.8093931106, 134993.1781394396], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1924200.0000, 
sim time next is 1924800.0000, 
raw observation next is [20.13333333333333, 91.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6638387478769683, 6.911200000000001, 6.9112, 121.9260426156618, 495110.7442863549, 495110.7442863545, 138667.1660523165], 
processed observation next is [1.0, 0.2608695652173913, 0.30123456790123443, 0.9133333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5797984348462103, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17682526581655533, 0.1768252658165552, 0.26666762702368557], 
reward next is 0.7333, 
noisyNet noise sample is [array([0.46148708], dtype=float32), 2.4993596]. 
=============================================
[2019-03-24 05:30:10,692] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-24 05:30:10,693] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:30:10,693] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:30:10,694] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:30:10,694] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:30:10,694] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:30:10,696] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:30:10,696] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:30:10,697] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:30:10,695] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:30:10,699] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:30:10,717] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run20
[2019-03-24 05:30:10,717] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run20
[2019-03-24 05:30:10,761] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run20
[2019-03-24 05:30:10,785] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run20
[2019-03-24 05:30:10,786] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run20
[2019-03-24 05:30:23,550] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00696207], dtype=float32), 0.013335252]
[2019-03-24 05:30:23,551] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.28422786, 57.67708846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5700953402887943, 6.911200000000001, 6.9112, 121.9260426156618, 420050.5267840187, 420050.5267840183, 125747.3166910071]
[2019-03-24 05:30:23,552] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:30:23,555] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 2.8073068e-32 3.5482385e-33 2.1087628e-30 3.1507426e-19], sampled 0.6914081270782486
[2019-03-24 05:30:31,275] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00696207], dtype=float32), 0.013335252]
[2019-03-24 05:30:31,278] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [33.16666666666666, 33.33333333333334, 1.0, 2.0, 0.5616047171163825, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9022727927395621, 6.9112, 6.9112, 121.9260426156132, 1334678.190976302, 1334678.190976302, 277941.6896023591]
[2019-03-24 05:30:31,280] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:30:31,283] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.3307003e-23 5.7679856e-23 1.9538624e-21 2.9058525e-11], sampled 0.7894404071253306
[2019-03-24 05:30:31,288] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1334678.190976302 W.
[2019-03-24 05:30:37,168] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00696207], dtype=float32), 0.013335252]
[2019-03-24 05:30:37,170] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.39873091, 77.48127624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5960114672387673, 6.9112, 6.9112, 121.9260426156618, 442931.6487410496, 442931.6487410496, 130406.6631355539]
[2019-03-24 05:30:37,172] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:30:37,174] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 5.8659925e-32 5.8913521e-33 3.6275831e-30 2.6507533e-19], sampled 0.6658361389790023
[2019-03-24 05:30:38,244] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00696207], dtype=float32), 0.013335252]
[2019-03-24 05:30:38,248] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.09837229666666, 75.78909869333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8649281290751215, 6.911200000000001, 6.9112, 121.9260426156618, 633838.9911496262, 633838.9911496257, 171163.3838982959]
[2019-03-24 05:30:38,248] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:30:38,251] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.1623718e-31 1.3406246e-32 7.4093218e-30 5.1514994e-19], sampled 0.9001914643721758
[2019-03-24 05:31:16,052] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00696207], dtype=float32), 0.013335252]
[2019-03-24 05:31:16,053] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.70598074333333, 98.55129546833334, 1.0, 2.0, 0.9297890485769784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260259111066, 1059877.59085533, 1059877.59085533, 224235.0441449582]
[2019-03-24 05:31:16,054] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:31:16,058] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.2293767e-25 4.2042781e-25 2.1879029e-23 1.4157800e-12], sampled 0.46974338510996505
[2019-03-24 05:31:16,059] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1059877.59085533 W.
[2019-03-24 05:31:49,010] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00696207], dtype=float32), 0.013335252]
[2019-03-24 05:31:49,011] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.76523173, 88.78123253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7664237814149522, 6.9112, 6.9112, 121.9260426156618, 572416.7383741025, 572416.7383741025, 153616.4410436623]
[2019-03-24 05:31:49,013] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:31:49,016] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.9765070e-31 2.4718134e-32 1.2769969e-29 8.0290240e-19], sampled 0.6977318865619624
[2019-03-24 05:31:52,798] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00696207], dtype=float32), 0.013335252]
[2019-03-24 05:31:52,800] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.1, 86.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.732641395200508, 6.9112, 6.9112, 121.9260426156618, 547108.9795020476, 547108.9795020476, 149817.8158890374]
[2019-03-24 05:31:52,800] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:31:52,804] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 3.3811726e-32 4.1984588e-33 2.4668987e-30 3.2735680e-19], sampled 0.9724097865622977
[2019-03-24 05:31:56,613] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00696207], dtype=float32), 0.013335252]
[2019-03-24 05:31:56,614] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.46666666666667, 56.00000000000001, 1.0, 2.0, 0.7347068542100562, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 899537.812376306, 899537.812376306, 185433.8032636269]
[2019-03-24 05:31:56,615] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:31:56,616] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 8.3772767e-22 3.5005863e-21 8.7952751e-20 2.5065655e-10], sampled 0.506189306303738
[2019-03-24 05:31:56,619] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 899537.812376306 W.
[2019-03-24 05:31:57,446] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8559.5106 2258278767.0965 536.0000
[2019-03-24 05:31:57,480] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 05:31:57,675] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8631.8876 2219290158.1300 543.0000
[2019-03-24 05:31:57,796] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 05:31:57,893] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8403.5218 2293034398.2444 697.0000
[2019-03-24 05:31:58,907] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 475000, evaluation results [475000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8559.510645911187, 2258278767.096507, 536.0, 8631.887602225204, 2219290158.130003, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8403.521846518315, 2293034398.244441, 697.0]
[2019-03-24 05:31:59,856] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.00000000e+00 3.90795095e-32 3.34414154e-31 5.67234893e-30
 1.20367155e-20], sum to 1.0000
[2019-03-24 05:31:59,861] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8706
[2019-03-24 05:31:59,867] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.03333333333333, 91.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6437072773837927, 6.9112, 6.9112, 121.9260426156618, 479997.5126775113, 479997.5126775113, 136501.0013515873], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1923000.0000, 
sim time next is 1923600.0000, 
raw observation next is [20.06666666666667, 91.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6272345054192348, 6.9112, 6.9112, 121.9260426156618, 467742.8858127754, 467742.8858127754, 134888.1546135258], 
processed observation next is [1.0, 0.2608695652173913, 0.29876543209876555, 0.9166666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5340431317740434, 0.0, 0.0, 0.8094621288201359, 0.1670510306474198, 0.1670510306474198, 0.25940029733370346], 
reward next is 0.7406, 
noisyNet noise sample is [array([1.1618524], dtype=float32), 0.7151399]. 
=============================================
[2019-03-24 05:32:03,579] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.6378997e-32 2.2399054e-32 1.4148399e-28 6.2857959e-20], sum to 1.0000
[2019-03-24 05:32:03,591] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6556
[2019-03-24 05:32:03,595] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.03333333333333, 82.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6258239767998032, 6.9112, 6.9112, 121.9260426156618, 466228.4825172593, 466228.4825172593, 134247.7981963324], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2013600.0000, 
sim time next is 2014200.0000, 
raw observation next is [21.15, 81.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6253198690438605, 6.911199999999999, 6.9112, 121.9260426156618, 465872.1061336468, 465872.1061336472, 134217.3145386188], 
processed observation next is [0.0, 0.30434782608695654, 0.33888888888888885, 0.815, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5316498363048255, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.166382895047731, 0.16638289504773116, 0.25811022026657465], 
reward next is 0.7419, 
noisyNet noise sample is [array([-1.3720711], dtype=float32), -1.7332445]. 
=============================================
[2019-03-24 05:32:03,937] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 2.5047475e-34 8.7678308e-37 1.5042423e-33 2.3983318e-18], sum to 1.0000
[2019-03-24 05:32:03,949] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2400
[2019-03-24 05:32:03,952] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6146005679066686, 6.911199999999999, 6.9112, 121.9260426156618, 457314.29162581, 457314.2916258104, 132638.1315649277], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2008800.0000, 
sim time next is 2009400.0000, 
raw observation next is [20.13333333333333, 88.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6155791191552376, 6.911199999999999, 6.9112, 121.9260426156618, 458121.9777834929, 458121.9777834934, 132801.8489952444], 
processed observation next is [0.0, 0.2608695652173913, 0.30123456790123443, 0.8816666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5194738989440469, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16361499206553318, 0.16361499206553337, 0.25538817114470075], 
reward next is 0.7446, 
noisyNet noise sample is [array([0.9361722], dtype=float32), 0.37146673]. 
=============================================
[2019-03-24 05:32:05,423] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.3057792e-30 1.1119766e-32 1.4609725e-27 1.5226350e-19], sum to 1.0000
[2019-03-24 05:32:05,429] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3396
[2019-03-24 05:32:05,435] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.93333333333333, 65.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8145914109134689, 6.911200000000001, 6.9112, 121.9260426156618, 602321.1526738517, 602321.1526738512, 163265.725847562], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2032800.0000, 
sim time next is 2033400.0000, 
raw observation next is [27.06666666666667, 65.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8222615702222495, 6.911200000000001, 6.9112, 121.9260426156618, 607365.7298621216, 607365.7298621212, 164451.7074761429], 
processed observation next is [0.0, 0.5217391304347826, 0.5580246913580248, 0.6516666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7778269627778119, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21691633209361486, 0.2169163320936147, 0.3162532836079671], 
reward next is 0.6837, 
noisyNet noise sample is [array([-0.80366224], dtype=float32), -0.16533355]. 
=============================================
[2019-03-24 05:32:18,272] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.4811710e-24 1.5244336e-23 2.8125090e-22 4.7596271e-11], sum to 1.0000
[2019-03-24 05:32:18,278] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4151
[2019-03-24 05:32:18,285] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.4, 95.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6853132483828182, 6.9112, 6.9112, 121.9260426156618, 512100.9669835112, 512100.9669835112, 142860.6320567388], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2265000.0000, 
sim time next is 2265600.0000, 
raw observation next is [20.4, 95.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6779616655506695, 6.9112, 6.9112, 121.9260426156618, 506610.2435691761, 506610.2435691761, 142105.8807981062], 
processed observation next is [1.0, 0.21739130434782608, 0.31111111111111106, 0.9533333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5974520819383369, 0.0, 0.0, 0.8094621288201359, 0.18093222984613433, 0.18093222984613433, 0.2732805399963581], 
reward next is 0.7267, 
noisyNet noise sample is [array([0.29031935], dtype=float32), -1.647876]. 
=============================================
[2019-03-24 05:32:20,655] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.1570099e-24 3.0286235e-23 2.2558145e-22 1.8970587e-11], sum to 1.0000
[2019-03-24 05:32:20,662] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0451
[2019-03-24 05:32:20,666] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.06666666666667, 68.0, 1.0, 2.0, 0.1660288786098236, 1.0, 1.0, 0.1660288786098236, 1.0, 2.0, 0.2656310847925187, 6.911199999999999, 6.9112, 121.94756008, 584842.4857806581, 584842.4857806585, 209649.3209131758], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2308800.0000, 
sim time next is 2309400.0000, 
raw observation next is [25.95, 68.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7826070803069642, 6.911200000000001, 6.9112, 121.9260426156618, 578751.4953969334, 578751.4953969329, 159212.347363343], 
processed observation next is [1.0, 0.7391304347826086, 0.5166666666666666, 0.685, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.7282588503837053, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20669696264176193, 0.20669696264176177, 0.3061775910833519], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.97115606], dtype=float32), 1.9749333]. 
=============================================
[2019-03-24 05:32:23,876] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.5558907e-28 1.8162669e-29 1.0991712e-27 5.7537625e-17], sum to 1.0000
[2019-03-24 05:32:23,883] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6352
[2019-03-24 05:32:23,886] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.91666666666666, 62.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6383055132570865, 6.911200000000001, 6.9112, 121.9260426156618, 475508.6745527202, 475508.6745527197, 135465.3660584691], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2415000.0000, 
sim time next is 2415600.0000, 
raw observation next is [23.7, 64.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6391727737707329, 6.911200000000001, 6.9112, 121.9260426156618, 476106.2811236511, 476106.2811236507, 135504.2176214728], 
processed observation next is [1.0, 1.0, 0.4333333333333333, 0.64, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5489659672134161, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1700379575441611, 0.17003795754416098, 0.2605850338874477], 
reward next is 0.7394, 
noisyNet noise sample is [array([0.51514715], dtype=float32), 1.183689]. 
=============================================
[2019-03-24 05:32:24,555] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 2.7397987e-31 1.1056657e-32 1.8693172e-28 2.9177424e-19], sum to 1.0000
[2019-03-24 05:32:24,561] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6815
[2019-03-24 05:32:24,564] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.83333333333333, 49.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6419302746434464, 6.911200000000001, 6.9112, 121.9260426156618, 478805.5961316588, 478805.5961316584, 136482.6635211927], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2407200.0000, 
sim time next is 2407800.0000, 
raw observation next is [26.61666666666667, 50.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.642340568535572, 6.9112, 6.9112, 121.9260426156618, 479106.5701891867, 479106.5701891867, 136517.7243099719], 
processed observation next is [1.0, 0.8695652173913043, 0.5413580246913582, 0.5, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5529257106694649, 0.0, 0.0, 0.8094621288201359, 0.17110948935328096, 0.17110948935328096, 0.2625340852114844], 
reward next is 0.7375, 
noisyNet noise sample is [array([-0.23025079], dtype=float32), 0.73055226]. 
=============================================
[2019-03-24 05:32:31,684] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.8570868e-02 8.5698760e-16 1.1398280e-12 1.8964090e-12 9.5142913e-01], sum to 1.0000
[2019-03-24 05:32:31,689] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1511
[2019-03-24 05:32:31,695] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.23333333333333, 37.33333333333334, 1.0, 2.0, 0.3972179741915865, 1.0, 1.0, 0.3972179741915865, 1.0, 2.0, 0.6396176194532325, 6.911199999999999, 6.9112, 121.94756008, 1423072.978716167, 1423072.978716167, 295555.1733443101], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2539200.0000, 
sim time next is 2539800.0000, 
raw observation next is [30.4, 36.5, 1.0, 2.0, 0.3962095236926981, 1.0, 2.0, 0.3962095236926981, 1.0, 2.0, 0.637182929738126, 6.9112, 6.9112, 121.94756008, 1415657.120870318, 1415657.120870318, 295180.3151176938], 
processed observation next is [1.0, 0.391304347826087, 0.6814814814814815, 0.365, 1.0, 1.0, 0.28120181391987864, 1.0, 1.0, 0.28120181391987864, 1.0, 1.0, 0.5464786621726574, 0.0, 0.0, 0.8096049824067558, 0.5055918288822564, 0.5055918288822564, 0.5676544521494111], 
reward next is 0.4323, 
noisyNet noise sample is [array([0.58932745], dtype=float32), -2.7400694]. 
=============================================
[2019-03-24 05:32:33,161] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.2434366e-25 1.1049981e-27 2.2297937e-25 5.8235882e-16], sum to 1.0000
[2019-03-24 05:32:33,166] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4371
[2019-03-24 05:32:33,176] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.3, 60.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8038936676940525, 6.911200000000001, 6.9112, 121.9260426156618, 596809.9868693413, 596809.9868693409, 160957.4751914091], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2583000.0000, 
sim time next is 2583600.0000, 
raw observation next is [27.06666666666667, 61.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8049265789042435, 6.9112, 6.9112, 121.9260426156618, 597638.6430663546, 597638.6430663546, 161057.6802859774], 
processed observation next is [1.0, 0.9130434782608695, 0.5580246913580248, 0.6166666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7561582236303044, 0.0, 0.0, 0.8094621288201359, 0.21344237252369805, 0.21344237252369805, 0.3097263082422642], 
reward next is 0.6903, 
noisyNet noise sample is [array([1.164522], dtype=float32), -0.3282933]. 
=============================================
[2019-03-24 05:32:40,028] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 2.6986218e-29 3.8970876e-30 4.0042196e-29 2.1027872e-14], sum to 1.0000
[2019-03-24 05:32:40,038] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4742
[2019-03-24 05:32:40,043] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.06666666666667, 86.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.686170240976533, 6.9112, 6.9112, 121.9260426156618, 512500.1260645965, 512500.1260645965, 142132.3933032486], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2698800.0000, 
sim time next is 2699400.0000, 
raw observation next is [21.03333333333333, 84.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6705800427412125, 6.911200000000001, 6.9112, 121.9260426156618, 500493.2848324693, 500493.2848324688, 139837.2591105975], 
processed observation next is [0.0, 0.21739130434782608, 0.3345679012345678, 0.8466666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5882250534265157, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1787476017258819, 0.1787476017258817, 0.2689178059819182], 
reward next is 0.7311, 
noisyNet noise sample is [array([0.5095652], dtype=float32), -0.27635995]. 
=============================================
[2019-03-24 05:32:40,375] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 4.7184321e-28 5.3040412e-29 2.9197027e-26 1.0547650e-15], sum to 1.0000
[2019-03-24 05:32:40,386] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0403
[2019-03-24 05:32:40,391] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.16666666666667, 76.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8428389655186963, 6.911200000000001, 6.9112, 121.9260426156618, 622357.0836936982, 622357.0836936977, 167102.8317185401], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2707800.0000, 
sim time next is 2708400.0000, 
raw observation next is [25.53333333333333, 74.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8485986260130671, 6.9112, 6.9112, 121.9260426156618, 626322.7777543446, 626322.7777543446, 167919.8251575038], 
processed observation next is [0.0, 0.34782608695652173, 0.5012345679012346, 0.7466666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8107482825163339, 0.0, 0.0, 0.8094621288201359, 0.22368670634083737, 0.22368670634083737, 0.3229227406875073], 
reward next is 0.6771, 
noisyNet noise sample is [array([-0.4940844], dtype=float32), 0.088561125]. 
=============================================
[2019-03-24 05:32:46,852] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4873807e-07 2.4761166e-13 3.0948659e-09 4.8171950e-10 9.9999988e-01], sum to 1.0000
[2019-03-24 05:32:46,853] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0373
[2019-03-24 05:32:46,856] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.83333333333333, 57.33333333333333, 1.0, 2.0, 0.743576185145166, 1.0, 2.0, 0.6851527545490176, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2344838.885800609, 2344838.88580061, 441154.9940257428], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2819400.0000, 
sim time next is 2820000.0000, 
raw observation next is [32.86666666666667, 57.66666666666667, 1.0, 2.0, 0.7092591871740681, 1.0, 2.0, 0.6679942555634688, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2286041.163041701, 2286041.163041701, 431737.4411800804], 
processed observation next is [1.0, 0.6521739130434783, 0.7728395061728395, 0.5766666666666667, 1.0, 1.0, 0.6538799847310335, 1.0, 1.0, 0.6047550661469867, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8096049824067558, 0.8164432725148932, 0.8164432725148932, 0.8302643099616931], 
reward next is 0.1697, 
noisyNet noise sample is [array([1.8205551], dtype=float32), -0.4731892]. 
=============================================
[2019-03-24 05:32:46,900] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[30.079891]
 [29.847754]
 [30.134462]
 [29.790861]
 [29.390718]], R is [[30.21529961]
 [30.06477165]
 [29.87336159]
 [29.75520897]
 [29.63069725]].
[2019-03-24 05:32:47,948] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-24 05:32:47,949] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:32:47,949] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:32:47,949] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:32:47,950] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:32:47,951] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:32:47,952] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:32:47,953] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:32:47,953] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:32:47,954] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:32:47,955] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:32:47,959] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run21
[2019-03-24 05:32:47,985] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run21
[2019-03-24 05:32:48,011] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run21
[2019-03-24 05:32:48,012] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run21
[2019-03-24 05:32:48,012] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run21
[2019-03-24 05:33:03,162] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00696207], dtype=float32), 0.013356489]
[2019-03-24 05:33:03,163] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.0, 43.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4877976446395326, 6.9112, 6.9112, 121.9260426156618, 348290.2636325575, 348290.2636325575, 105020.4671064817]
[2019-03-24 05:33:03,165] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:33:03,167] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.0092427e-24 9.5849298e-24 2.9560756e-22 3.0210379e-11], sampled 0.7961990422579035
[2019-03-24 05:33:03,921] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00696207], dtype=float32), 0.013356489]
[2019-03-24 05:33:03,923] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.0, 57.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6708957814313501, 6.9112, 6.9112, 121.9260426156618, 483687.3591051355, 483687.3591051355, 130708.3084854431]
[2019-03-24 05:33:03,924] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:33:03,927] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 3.1171770e-24 2.4412102e-23 7.4288236e-22 3.3660550e-11], sampled 0.8951317704665349
[2019-03-24 05:33:45,564] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00696207], dtype=float32), 0.013356489]
[2019-03-24 05:33:45,568] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.93333333333334, 88.66666666666666, 1.0, 2.0, 0.4267455917307775, 1.0, 2.0, 0.4267455917307775, 1.0, 2.0, 0.6793928801690413, 6.9112, 6.9112, 121.94756008, 1459737.50247241, 1459737.50247241, 308996.3015849422]
[2019-03-24 05:33:45,569] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:33:45,573] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.9083503e-01 2.3403237e-16 2.6259461e-13 2.7546826e-13 8.0916494e-01], sampled 0.9099887433155582
[2019-03-24 05:34:17,710] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00696207], dtype=float32), 0.013356489]
[2019-03-24 05:34:17,713] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.78622565333333, 78.71710286, 1.0, 2.0, 0.2513387539205716, 1.0, 2.0, 0.2513387539205716, 1.0, 2.0, 0.4001394817733036, 6.911200000000001, 6.9112, 121.94756008, 859399.6649060935, 859399.664906093, 238100.656382152]
[2019-03-24 05:34:17,717] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:34:17,719] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [6.3002883e-03 2.7593503e-17 8.9811567e-14 4.5722151e-14 9.9369967e-01], sampled 0.3691674639089051
[2019-03-24 05:34:24,896] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00696207], dtype=float32), 0.013356489]
[2019-03-24 05:34:24,898] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [30.4, 46.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8056194000554743, 6.911199999999999, 6.9112, 121.9260426156618, 597885.4331828302, 597885.4331828306, 161268.5108620487]
[2019-03-24 05:34:24,899] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:34:24,902] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.4600777e-24 1.8914796e-23 5.0670225e-22 7.7570290e-11], sampled 0.9322184571619192
[2019-03-24 05:34:37,879] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8337.0021 2397597791.7783 177.0000
[2019-03-24 05:34:37,906] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8295.2088 2482978621.1049 142.0000
[2019-03-24 05:34:38,069] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7851.0952 2694034706.1194 141.0000
[2019-03-24 05:34:38,109] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8264.5343 2449550076.8622 187.0000
[2019-03-24 05:34:38,292] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8360.0255 2434042673.6345 144.0000
[2019-03-24 05:34:39,305] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 500000, evaluation results [500000.0, 7851.095194305679, 2694034706.119354, 141.0, 8360.025508807817, 2434042673.634458, 144.0, 8337.002131609184, 2397597791.7782593, 177.0, 8295.208784536595, 2482978621.1048546, 142.0, 8264.534333235491, 2449550076.8621774, 187.0]
[2019-03-24 05:34:41,560] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.4863222e-06 2.1171892e-16 1.0094859e-12 7.5833171e-13 9.9999452e-01], sum to 1.0000
[2019-03-24 05:34:41,568] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3936
[2019-03-24 05:34:41,574] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.41666666666666, 84.83333333333333, 1.0, 2.0, 0.398510537751704, 1.0, 2.0, 0.398510537751704, 1.0, 2.0, 0.6344417546828454, 6.911200000000001, 6.9112, 121.94756008, 1363069.982436956, 1363069.982436955, 296430.2815123675], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2891400.0000, 
sim time next is 2892000.0000, 
raw observation next is [24.53333333333333, 85.66666666666667, 1.0, 2.0, 0.4289119731204142, 1.0, 2.0, 0.4289119731204142, 1.0, 2.0, 0.6828418298954592, 6.9112, 6.9112, 121.94756008, 1467154.982371253, 1467154.982371253, 309978.6813159784], 
processed observation next is [1.0, 0.4782608695652174, 0.46419753086419746, 0.8566666666666667, 1.0, 1.0, 0.3201333013338264, 1.0, 1.0, 0.3201333013338264, 1.0, 1.0, 0.6035522873693239, 0.0, 0.0, 0.8096049824067558, 0.5239839222754474, 0.5239839222754474, 0.5961128486845738], 
reward next is 0.4039, 
noisyNet noise sample is [array([0.5529446], dtype=float32), -0.75820065]. 
=============================================
[2019-03-24 05:34:41,585] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[50.825054]
 [50.849033]
 [50.493916]
 [50.683376]
 [50.78034 ]], R is [[50.35918808]
 [50.28554153]
 [50.2244606 ]
 [50.14020538]
 [50.05894089]].
[2019-03-24 05:34:44,206] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.8787308e-01 1.7886954e-14 1.1224102e-12 6.7827384e-12 1.2126914e-02], sum to 1.0000
[2019-03-24 05:34:44,213] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0364
[2019-03-24 05:34:44,221] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 735854.3988570871 W.
[2019-03-24 05:34:44,231] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.1, 91.0, 1.0, 2.0, 0.3228363041091024, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5139659101860922, 6.911199999999999, 6.9112, 121.9260426156618, 735854.3988570871, 735854.3988570876, 201482.8193812951], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2937600.0000, 
sim time next is 2938200.0000, 
raw observation next is [25.08333333333334, 91.50000000000001, 1.0, 2.0, 0.2155232634525628, 1.0, 1.0, 0.2155232634525628, 1.0, 2.0, 0.3431200545191416, 6.9112, 6.9112, 121.94756008, 736877.320361581, 736877.320361581, 225732.466135459], 
processed observation next is [1.0, 0.0, 0.4845679012345681, 0.9150000000000001, 1.0, 1.0, 0.06609912315781287, 1.0, 0.5, 0.06609912315781287, 1.0, 1.0, 0.178900068148927, 0.0, 0.0, 0.8096049824067558, 0.2631704715577075, 0.2631704715577075, 0.43410089641434424], 
reward next is 0.5659, 
noisyNet noise sample is [array([-1.8128645], dtype=float32), -1.5097892]. 
=============================================
[2019-03-24 05:34:44,862] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.8848697e-02 7.1929835e-14 3.9348386e-12 4.3310664e-11 9.8115128e-01], sum to 1.0000
[2019-03-24 05:34:44,869] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8878
[2019-03-24 05:34:44,871] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.25, 90.0, 1.0, 2.0, 0.2967160670174374, 1.0, 1.0, 0.2967160670174374, 1.0, 2.0, 0.4723816420594283, 6.911199999999999, 6.9112, 121.94756008, 1014660.480373484, 1014660.480373485, 254799.575595407], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2946600.0000, 
sim time next is 2947200.0000, 
raw observation next is [25.16666666666666, 91.33333333333334, 1.0, 2.0, 0.2792048486893806, 1.0, 2.0, 0.2792048486893806, 1.0, 2.0, 0.4445032121805956, 6.9112, 6.9112, 121.94756008, 954741.2176947503, 954741.2176947503, 248219.3115912412], 
processed observation next is [1.0, 0.08695652173913043, 0.4876543209876541, 0.9133333333333334, 1.0, 1.0, 0.14191053415402455, 1.0, 1.0, 0.14191053415402455, 1.0, 1.0, 0.3056290152257444, 0.0, 0.0, 0.8096049824067558, 0.3409790063195537, 0.3409790063195537, 0.47734482998315614], 
reward next is 0.5227, 
noisyNet noise sample is [array([1.9202452], dtype=float32), 1.0692354]. 
=============================================
[2019-03-24 05:34:46,131] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.1491591e-15 3.0127801e-15 9.9048123e-14 2.5745496e-08], sum to 1.0000
[2019-03-24 05:34:46,136] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9427
[2019-03-24 05:34:46,144] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 869665.4843486882 W.
[2019-03-24 05:34:46,151] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.3815090290482874, 1.0, 2.0, 0.3815090290482874, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 869665.4843486882, 869665.4843486885, 201170.9784686305], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2961000.0000, 
sim time next is 2961600.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.73520791316193, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 837950.973513922, 837950.973513922, 182912.9846418032], 
processed observation next is [1.0, 0.2608695652173913, 0.48148148148148145, 0.94, 1.0, 1.0, 0.6847713251927738, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2992682048264007, 0.2992682048264007, 0.3517557396957754], 
reward next is 0.6482, 
noisyNet noise sample is [array([2.1696885], dtype=float32), 0.79794264]. 
=============================================
[2019-03-24 05:34:50,415] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.9810762e-07 3.1691145e-17 1.2133802e-12 7.6083611e-13 9.9999952e-01], sum to 1.0000
[2019-03-24 05:34:50,421] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4422
[2019-03-24 05:34:50,428] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.0, 100.0, 1.0, 2.0, 0.2560204207976955, 1.0, 2.0, 0.2560204207976955, 1.0, 2.0, 0.4075928479129304, 6.911200000000001, 6.9112, 121.94756008, 875416.7745242609, 875416.7745242604, 239770.3536595997], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3038400.0000, 
sim time next is 3039000.0000, 
raw observation next is [25.13333333333334, 98.16666666666667, 1.0, 2.0, 0.2788432048563761, 1.0, 2.0, 0.2788432048563761, 1.0, 2.0, 0.4439274634205351, 6.9112, 6.9112, 121.94756008, 953503.8070870737, 953503.8070870737, 248085.2172422087], 
processed observation next is [1.0, 0.17391304347826086, 0.48641975308642, 0.9816666666666667, 1.0, 1.0, 0.1414800057814001, 1.0, 1.0, 0.1414800057814001, 1.0, 1.0, 0.30490932927566883, 0.0, 0.0, 0.8096049824067558, 0.34053707395966915, 0.34053707395966915, 0.47708695623501673], 
reward next is 0.5229, 
noisyNet noise sample is [array([-2.0118368], dtype=float32), 0.60207593]. 
=============================================
[2019-03-24 05:34:50,456] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[46.123905]
 [46.08172 ]
 [45.871376]
 [45.50619 ]
 [45.415276]], R is [[46.08502579]
 [46.16307831]
 [46.23816681]
 [46.31368256]
 [46.39329529]].
[2019-03-24 05:34:51,131] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.4182102e-08 1.0854293e-12 2.2264110e-10 9.2784426e-11 1.0000000e+00], sum to 1.0000
[2019-03-24 05:34:51,137] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4585
[2019-03-24 05:34:51,140] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.33333333333334, 89.0, 1.0, 2.0, 0.4927435250780572, 1.0, 2.0, 0.4927435250780572, 1.0, 2.0, 0.7844637394605422, 6.9112, 6.9112, 121.94756008, 1685723.970340418, 1685723.970340418, 340041.7431324694], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3057600.0000, 
sim time next is 3058200.0000, 
raw observation next is [27.5, 89.0, 1.0, 2.0, 0.5089662841382772, 1.0, 2.0, 0.5089662841382772, 1.0, 2.0, 0.8102909002227896, 6.9112, 6.9112, 121.94756008, 1741277.702986147, 1741277.702986147, 348011.6041850062], 
processed observation next is [1.0, 0.391304347826087, 0.5740740740740741, 0.89, 1.0, 1.0, 0.41543605254556804, 1.0, 1.0, 0.41543605254556804, 1.0, 1.0, 0.7628636252784871, 0.0, 0.0, 0.8096049824067558, 0.6218848939236239, 0.6218848939236239, 0.6692530849711658], 
reward next is 0.3307, 
noisyNet noise sample is [array([1.5313882], dtype=float32), 0.22884889]. 
=============================================
[2019-03-24 05:34:51,590] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1469137e-07 1.4540890e-12 3.1403055e-10 8.7129359e-10 9.9999988e-01], sum to 1.0000
[2019-03-24 05:34:51,597] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4681
[2019-03-24 05:34:51,603] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.51666666666667, 82.5, 1.0, 2.0, 0.5600961296571377, 1.0, 2.0, 0.5600961296571377, 1.0, 2.0, 0.8916912794716317, 6.9112, 6.9112, 121.94756008, 1916390.978362848, 1916390.978362848, 374062.9728184599], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3081000.0000, 
sim time next is 3081600.0000, 
raw observation next is [26.0, 84.0, 1.0, 2.0, 0.5389932501627313, 1.0, 2.0, 0.5389932501627313, 1.0, 2.0, 0.8580948080437325, 6.911200000000001, 6.9112, 121.94756008, 1844112.116345715, 1844112.116345714, 363139.3771261002], 
processed observation next is [1.0, 0.6956521739130435, 0.5185185185185185, 0.84, 1.0, 1.0, 0.45118244066991814, 1.0, 1.0, 0.45118244066991814, 1.0, 1.0, 0.8226185100546657, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6586114701234697, 0.6586114701234693, 0.6983449560117311], 
reward next is 0.3017, 
noisyNet noise sample is [array([0.7911287], dtype=float32), -0.043593097]. 
=============================================
[2019-03-24 05:34:57,771] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.9863196e-07 2.3544529e-21 2.9625520e-16 2.9551704e-16 9.9999964e-01], sum to 1.0000
[2019-03-24 05:34:57,778] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0983
[2019-03-24 05:34:57,784] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.9, 60.0, 1.0, 2.0, 0.2148349972238105, 1.0, 2.0, 0.2148349972238105, 1.0, 2.0, 0.3420243122677017, 6.9112, 6.9112, 121.94756008, 734523.0003943974, 734523.0003943974, 225501.8111185108], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3184200.0000, 
sim time next is 3184800.0000, 
raw observation next is [29.93333333333334, 57.33333333333333, 1.0, 2.0, 0.2075593334541133, 1.0, 2.0, 0.2075593334541133, 1.0, 2.0, 0.3304412185945173, 6.911200000000001, 6.9112, 121.94756008, 709635.9211483118, 709635.9211483113, 223079.7677624822], 
processed observation next is [1.0, 0.8695652173913043, 0.6641975308641977, 0.5733333333333333, 1.0, 1.0, 0.05661825411203963, 1.0, 1.0, 0.05661825411203963, 1.0, 1.0, 0.16305152324314662, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2534414004101114, 0.2534414004101112, 0.42899955338938883], 
reward next is 0.5710, 
noisyNet noise sample is [array([0.4901248], dtype=float32), -0.7539124]. 
=============================================
[2019-03-24 05:35:02,693] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.5571153e-26 3.7042941e-25 8.9691000e-25 1.9276369e-13], sum to 1.0000
[2019-03-24 05:35:02,699] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8221
[2019-03-24 05:35:02,703] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.9, 93.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7961491819010603, 6.9112, 6.9112, 121.9260426156618, 592618.5591337895, 592618.5591337895, 159140.3766890381], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3298800.0000, 
sim time next is 3299400.0000, 
raw observation next is [21.85, 93.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7906612607568124, 6.911200000000001, 6.9112, 121.9260426156618, 588794.5200696108, 588794.5200696103, 158290.7802781863], 
processed observation next is [0.0, 0.17391304347826086, 0.36481481481481487, 0.935, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7383265759460156, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21028375716771813, 0.21028375716771797, 0.30440534668881986], 
reward next is 0.6956, 
noisyNet noise sample is [array([-0.32270557], dtype=float32), -0.47344348]. 
=============================================
[2019-03-24 05:35:06,087] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9266690e-01 3.4954556e-14 2.5312454e-11 5.4788007e-11 7.3331571e-03], sum to 1.0000
[2019-03-24 05:35:06,095] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6970
[2019-03-24 05:35:06,100] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 777886.8874435668 W.
[2019-03-24 05:35:06,104] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.96666666666667, 70.66666666666667, 1.0, 2.0, 0.3412675744519907, 1.0, 1.0, 0.3412675744519907, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 777886.8874435668, 777886.8874435673, 190659.2532975913], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3341400.0000, 
sim time next is 3342000.0000, 
raw observation next is [28.93333333333334, 71.33333333333334, 1.0, 2.0, 0.6891548855361288, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 785435.282056843, 785435.282056843, 174101.2120251616], 
processed observation next is [0.0, 0.6956521739130435, 0.6271604938271608, 0.7133333333333334, 1.0, 1.0, 0.6299462923049153, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2805126007345868, 0.2805126007345868, 0.3348100231253108], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.29032263], dtype=float32), -0.99949825]. 
=============================================
[2019-03-24 05:35:06,126] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[41.44041 ]
 [40.863487]
 [41.440723]
 [40.896503]
 [41.01333 ]], R is [[39.8439064 ]
 [39.4454689 ]
 [39.05101395]
 [39.2904129 ]
 [39.55842209]].
[2019-03-24 05:35:06,834] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.9999917e-01 7.9446134e-14 2.5708129e-12 2.2890155e-12 8.6403986e-07], sum to 1.0000
[2019-03-24 05:35:06,842] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6913
[2019-03-24 05:35:06,855] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1754800.492614994 W.
[2019-03-24 05:35:06,862] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.73333333333333, 92.0, 1.0, 1.0, 0.5129150463047628, 1.0, 1.0, 0.5129150463047628, 1.0, 2.0, 0.8165774581940404, 6.911199999999999, 6.9112, 121.94756008, 1754800.492614994, 1754800.492614994, 349973.1311066313], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3378000.0000, 
sim time next is 3378600.0000, 
raw observation next is [23.8, 92.5, 1.0, 2.0, 0.4877149132503907, 1.0, 2.0, 0.4877149132503907, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260417448113, 1111941.807985919, 1111941.80798592, 231608.5937301236], 
processed observation next is [1.0, 0.08695652173913043, 0.43703703703703706, 0.925, 1.0, 1.0, 0.3901368014885604, 1.0, 1.0, 0.3901368014885604, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621230385942, 0.39712207428068536, 0.3971220742806857, 0.4454011417886992], 
reward next is 0.5546, 
noisyNet noise sample is [array([0.653508], dtype=float32), 1.7407084]. 
=============================================
[2019-03-24 05:35:08,812] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.0972533e-05 6.3627255e-12 9.6833404e-09 1.8658817e-09 9.9995899e-01], sum to 1.0000
[2019-03-24 05:35:08,818] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0767
[2019-03-24 05:35:08,822] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.6, 64.0, 1.0, 2.0, 0.6071461656432688, 1.0, 2.0, 0.6071461656432688, 1.0, 2.0, 0.9665964690742481, 6.911199999999999, 6.9112, 121.94756008, 2077561.754978239, 2077561.75497824, 399282.9411725183], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3427200.0000, 
sim time next is 3427800.0000, 
raw observation next is [30.38333333333334, 64.83333333333334, 1.0, 2.0, 0.5923040784776865, 1.0, 2.0, 0.5923040784776865, 1.0, 2.0, 0.9429673829336082, 6.9112, 6.9112, 121.94756008, 2026716.768151674, 2026716.768151674, 391198.4049063274], 
processed observation next is [1.0, 0.6956521739130435, 0.6808641975308645, 0.6483333333333334, 1.0, 1.0, 0.5146477124734363, 1.0, 1.0, 0.5146477124734363, 1.0, 1.0, 0.9287092286670101, 0.0, 0.0, 0.8096049824067558, 0.7238274171970264, 0.7238274171970264, 0.7523046248198605], 
reward next is 0.2477, 
noisyNet noise sample is [array([0.53189754], dtype=float32), -1.1449767]. 
=============================================
[2019-03-24 05:35:10,176] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.1611974e-02 4.8371411e-12 1.7135560e-10 2.2022995e-09 9.7838801e-01], sum to 1.0000
[2019-03-24 05:35:10,182] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3832
[2019-03-24 05:35:10,192] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.0, 59.0, 1.0, 2.0, 0.6926322856879799, 1.0, 2.0, 0.6596808048204247, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2257554.517379532, 2257554.517379532, 427266.1113328823], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3423600.0000, 
sim time next is 3424200.0000, 
raw observation next is [31.76666666666667, 59.83333333333334, 1.0, 2.0, 0.6159424412736008, 1.0, 2.0, 0.6159424412736008, 1.0, 2.0, 0.980600426352434, 6.911200000000001, 6.9112, 121.94756008, 2107696.788569909, 2107696.788569908, 404130.2566899174], 
processed observation next is [1.0, 0.6521739130434783, 0.7320987654320988, 0.5983333333333334, 1.0, 1.0, 0.5427886205638104, 1.0, 1.0, 0.5427886205638104, 1.0, 1.0, 0.9757505329405425, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7527488530606818, 0.7527488530606815, 0.7771735705575334], 
reward next is 0.2228, 
noisyNet noise sample is [array([-0.10668941], dtype=float32), 0.28443158]. 
=============================================
[2019-03-24 05:35:18,051] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 6.9192813e-28 6.0946896e-32 1.2630570e-24 5.0404238e-20], sum to 1.0000
[2019-03-24 05:35:18,059] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9422
[2019-03-24 05:35:18,064] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.8, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8534137955281037, 6.911200000000001, 6.9112, 121.9260426156618, 628957.2427147543, 628957.2427147538, 168802.1834678794], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3626400.0000, 
sim time next is 3627000.0000, 
raw observation next is [23.6, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8640274031223814, 6.911200000000001, 6.9112, 121.9260426156618, 635175.3685198958, 635175.3685198954, 170585.2705329001], 
processed observation next is [1.0, 1.0, 0.4296296296296297, 0.91, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8300342539029767, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2268483458999628, 0.22684834589996264, 0.32804859717865403], 
reward next is 0.6720, 
noisyNet noise sample is [array([-0.22964987], dtype=float32), -1.7705015]. 
=============================================
[2019-03-24 05:35:18,077] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[50.074383]
 [50.083473]
 [50.096313]
 [50.082687]
 [50.067528]], R is [[50.24032974]
 [50.41330719]
 [50.58742905]
 [50.7606926 ]
 [50.92769623]].
[2019-03-24 05:35:19,606] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 3.8869669e-35 6.8009709e-36 1.9678532e-33 8.6698926e-27], sum to 1.0000
[2019-03-24 05:35:19,618] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4733
[2019-03-24 05:35:19,621] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.95, 82.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8913210987441216, 6.911199999999999, 6.9112, 121.9260426156618, 652701.9635590657, 652701.9635590661, 174714.9494685386], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3611400.0000, 
sim time next is 3612000.0000, 
raw observation next is [24.9, 81.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.879772547170346, 6.9112, 6.9112, 121.9260426156618, 645736.9990607153, 645736.9990607153, 172868.7429491599], 
processed observation next is [1.0, 0.8260869565217391, 0.47777777777777775, 0.8133333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8497156839629324, 0.0, 0.0, 0.8094621288201359, 0.2306203568073983, 0.2306203568073983, 0.33243989028684595], 
reward next is 0.6676, 
noisyNet noise sample is [array([1.0575938], dtype=float32), 1.5950096]. 
=============================================
[2019-03-24 05:35:19,634] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[63.10687 ]
 [61.966465]
 [61.656986]
 [61.43955 ]
 [60.856216]], R is [[63.121418  ]
 [63.15421295]
 [63.18429184]
 [63.21457672]
 [63.24526215]].
[2019-03-24 05:35:24,766] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.9999988e-01 3.7297787e-15 6.0536589e-15 7.1227366e-13 6.3918030e-08], sum to 1.0000
[2019-03-24 05:35:24,772] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9340
[2019-03-24 05:35:24,780] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 754395.5762659544 W.
[2019-03-24 05:35:24,787] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.6619334912322691, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 754395.5762659544, 754395.5762659544, 169061.6324302095], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3727800.0000, 
sim time next is 3728400.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.3333610375363617, 0.0, 2.0, 0.0, 1.0, 1.0, 0.530721628568927, 6.9112, 6.9112, 121.9260426156618, 759855.7577629411, 759855.7577629411, 204427.6732729902], 
processed observation next is [1.0, 0.13043478260869565, 0.48148148148148145, 0.94, 1.0, 1.0, 0.20638218754328774, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.41340203571115874, 0.0, 0.0, 0.8094621288201359, 0.2713770563439075, 0.2713770563439075, 0.3931301409095966], 
reward next is 0.6069, 
noisyNet noise sample is [array([-2.6626773], dtype=float32), -3.881665]. 
=============================================
[2019-03-24 05:35:27,918] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 2.1921473e-15 8.8764864e-17 2.7496646e-14 1.9414065e-10], sum to 1.0000
[2019-03-24 05:35:27,922] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9802
[2019-03-24 05:35:27,929] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 842871.3684587639 W.
[2019-03-24 05:35:27,932] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.2, 59.0, 1.0, 2.0, 0.369761317436444, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5886720596442121, 6.911199999999999, 6.9112, 121.9260426156618, 842871.3684587639, 842871.3684587644, 214959.3020310928], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3778200.0000, 
sim time next is 3778800.0000, 
raw observation next is [33.46666666666667, 55.0, 1.0, 2.0, 0.7250515982774736, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 826369.1043271106, 826369.1043271101, 180946.2370364266], 
processed observation next is [1.0, 0.7391304347826086, 0.7950617283950618, 0.55, 1.0, 1.0, 0.6726804741398494, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.29513182297396806, 0.2951318229739679, 0.3479735327623589], 
reward next is 0.6520, 
noisyNet noise sample is [array([-0.29388192], dtype=float32), 1.9224895]. 
=============================================
[2019-03-24 05:35:28,349] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-24 05:35:28,356] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:35:28,357] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:35:28,357] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:35:28,357] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:35:28,358] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:35:28,359] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:35:28,361] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run22
[2019-03-24 05:35:28,396] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:35:28,398] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:35:28,407] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run22
[2019-03-24 05:35:28,413] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:35:28,441] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:35:28,453] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run22
[2019-03-24 05:35:28,485] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run22
[2019-03-24 05:35:28,509] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run22
[2019-03-24 05:35:32,156] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0058538], dtype=float32), 0.012776358]
[2019-03-24 05:35:32,157] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.83325518, 9.056428314999998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6314539976290182, 6.911199999999999, 6.9112, 121.9260426156618, 450955.3133493119, 450955.3133493124, 108905.9900041377]
[2019-03-24 05:35:32,157] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:35:32,159] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 3.0736984e-25 1.4131677e-28 2.9052071e-24 1.8887085e-18], sampled 0.03886963541023958
[2019-03-24 05:36:01,533] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0058538], dtype=float32), 0.012776358]
[2019-03-24 05:36:01,534] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.66666666666666, 60.83333333333334, 1.0, 2.0, 0.6054266995062895, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 693015.8009773268, 693015.8009773268, 159164.5100293065]
[2019-03-24 05:36:01,537] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:36:01,540] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.6102182e-19 2.2486247e-21 2.4085820e-18 9.9788277e-13], sampled 0.40736862062438595
[2019-03-24 05:36:01,541] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 693015.8009773268 W.
[2019-03-24 05:36:07,706] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0058538], dtype=float32), 0.012776358]
[2019-03-24 05:36:07,707] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.06666666666667, 71.33333333333334, 1.0, 2.0, 0.68683841733185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 782793.8367764028, 782793.8367764023, 173668.2215546083]
[2019-03-24 05:36:07,709] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:36:07,712] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.8109852e-17 2.6870187e-18 6.2445577e-16 3.6469150e-09], sampled 0.6222351930959578
[2019-03-24 05:36:07,714] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 782793.8367764028 W.
[2019-03-24 05:36:21,421] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0058538], dtype=float32), 0.012776358]
[2019-03-24 05:36:21,424] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.64518569333333, 87.24528888333333, 1.0, 2.0, 0.5253416743045587, 0.0, 2.0, 0.0, 1.0, 2.0, 0.838534592224864, 6.911199999999999, 6.9112, 121.9260426156618, 1223022.428685524, 1223022.428685525, 265483.4505641051]
[2019-03-24 05:36:21,425] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:36:21,429] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 2.3652985e-16 4.7387874e-17 7.1512086e-15 2.0343032e-08], sampled 0.3976392544698736
[2019-03-24 05:36:21,434] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1223022.428685524 W.
[2019-03-24 05:36:35,340] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0058538], dtype=float32), 0.012776358]
[2019-03-24 05:36:35,340] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.8, 75.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7817515246986905, 6.9112, 6.9112, 121.9260426156618, 580753.9308088006, 580753.9308088006, 158024.9508444807]
[2019-03-24 05:36:35,341] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:36:35,343] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 7.1879371e-23 9.6749581e-26 6.4995873e-22 1.8875867e-16], sampled 0.48590604719311914
[2019-03-24 05:37:06,736] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0058538], dtype=float32), 0.012776358]
[2019-03-24 05:37:06,736] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.76575806333333, 61.59546043, 1.0, 1.0, 0.8129237055863987, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999998, 6.9112, 121.9258727752126, 994110.6140587616, 994110.6140587626, 201571.2035501977]
[2019-03-24 05:37:06,738] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:37:06,741] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.3683801e-18 1.4148781e-20 1.2885334e-17 1.1415868e-12], sampled 0.8896433262070358
[2019-03-24 05:37:06,742] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 994110.6140587616 W.
[2019-03-24 05:37:14,771] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8557.5967 2258548947.8579 535.0000
[2019-03-24 05:37:14,880] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7836.4970 2530353769.4648 783.0000
[2019-03-24 05:37:15,026] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8356.1964 2339872606.7505 608.0000
[2019-03-24 05:37:15,091] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8635.8292 2219502933.9141 541.0000
[2019-03-24 05:37:15,103] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8393.1788 2293365856.4691 683.0000
[2019-03-24 05:37:16,119] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 525000, evaluation results [525000.0, 7836.496957356892, 2530353769.4647794, 783.0, 8557.596678474492, 2258548947.857913, 535.0, 8635.829179357088, 2219502933.9140606, 541.0, 8356.196409719314, 2339872606.7504725, 608.0, 8393.1788412747, 2293365856.4691315, 683.0]
[2019-03-24 05:37:20,644] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 3.5239026e-19 2.4038629e-19 4.1789992e-17 2.1506643e-09], sum to 1.0000
[2019-03-24 05:37:20,652] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6785
[2019-03-24 05:37:20,657] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 902743.7518357142 W.
[2019-03-24 05:37:20,662] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.35, 89.0, 1.0, 2.0, 0.2640076413725395, 1.0, 1.0, 0.2640076413725395, 1.0, 2.0, 0.4203087631936958, 6.9112, 6.9112, 121.94756008, 902743.7518357142, 902743.7518357142, 242647.213868251], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3882600.0000, 
sim time next is 3883200.0000, 
raw observation next is [27.13333333333333, 89.0, 1.0, 2.0, 0.7791210094509785, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 888029.7867147104, 888029.7867147104, 191667.5191528127], 
processed observation next is [0.0, 0.9565217391304348, 0.5604938271604937, 0.89, 1.0, 1.0, 0.7370488207749744, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3171534952552537, 0.3171534952552537, 0.3685913829861783], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.47647026], dtype=float32), 0.6776962]. 
=============================================
[2019-03-24 05:37:24,199] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.6815255e-01 1.9544009e-11 2.2566105e-10 2.9811642e-10 4.3184736e-01], sum to 1.0000
[2019-03-24 05:37:24,208] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6367
[2019-03-24 05:37:24,216] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.25, 70.0, 1.0, 2.0, 0.3740716107859179, 1.0, 1.0, 0.3740716107859179, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 852702.1529785384, 852702.1529785384, 199187.3035745014], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3929400.0000, 
sim time next is 3930000.0000, 
raw observation next is [30.5, 70.0, 1.0, 2.0, 0.2554595962338899, 1.0, 2.0, 0.2554595962338899, 1.0, 1.0, 0.4066999969425709, 6.911199999999999, 6.9112, 121.94756008, 873498.0410138364, 873498.0410138369, 239569.6925687601], 
processed observation next is [0.0, 0.4782608695652174, 0.6851851851851852, 0.7, 1.0, 1.0, 0.11364237646891658, 1.0, 1.0, 0.11364237646891658, 1.0, 0.5, 0.25837499617821363, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.31196358607637015, 0.3119635860763703, 0.4607109472476156], 
reward next is 0.5393, 
noisyNet noise sample is [array([-0.91298145], dtype=float32), -0.2257042]. 
=============================================
[2019-03-24 05:37:24,231] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[37.35134 ]
 [37.595867]
 [37.736206]
 [37.103367]
 [38.489655]], R is [[37.44512177]
 [37.68761826]
 [37.31074142]
 [36.93763351]
 [37.22183609]].
[2019-03-24 05:37:24,905] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.9863130e-01 4.9525637e-14 6.3341986e-13 1.8839574e-12 1.3686612e-03], sum to 1.0000
[2019-03-24 05:37:24,912] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8125
[2019-03-24 05:37:24,920] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 926962.120629229 W.
[2019-03-24 05:37:24,925] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 0.8132580015314982, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 926962.120629229, 926962.1206292285, 198702.2451573188], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3945000.0000, 
sim time next is 3945600.0000, 
raw observation next is [31.0, 70.0, 1.0, 2.0, 0.4073717631479544, 0.0, 2.0, 0.0, 1.0, 1.0, 0.6485491141036396, 6.911199999999999, 6.9112, 121.9260426156618, 928656.3671238293, 928656.3671238298, 226393.0548290186], 
processed observation next is [0.0, 0.6956521739130435, 0.7037037037037037, 0.7, 1.0, 1.0, 0.2944901942237553, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.5606863926295494, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3316629882585105, 0.33166298825851065, 0.4353712592865742], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.06656977], dtype=float32), -1.665902]. 
=============================================
[2019-03-24 05:37:25,587] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.8026882e-01 4.7264910e-16 9.5167168e-13 1.1341502e-12 7.1973121e-01], sum to 1.0000
[2019-03-24 05:37:25,593] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8685
[2019-03-24 05:37:25,597] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.96666666666667, 84.33333333333333, 1.0, 2.0, 0.3313795665949026, 1.0, 2.0, 0.3313795665949026, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 755337.0115215193, 755337.0115215197, 188161.4001464339], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3975000.0000, 
sim time next is 3975600.0000, 
raw observation next is [25.93333333333334, 84.66666666666667, 1.0, 2.0, 0.220894703044918, 1.0, 2.0, 0.220894703044918, 1.0, 1.0, 0.3516715612857456, 6.9112, 6.9112, 121.94756008, 755251.39991474, 755251.39991474, 227541.6730452174], 
processed observation next is [1.0, 0.0, 0.5160493827160496, 0.8466666666666667, 1.0, 1.0, 0.07249369410109287, 1.0, 1.0, 0.07249369410109287, 1.0, 0.5, 0.189589451607182, 0.0, 0.0, 0.8096049824067558, 0.26973264282669285, 0.26973264282669285, 0.43758014047157195], 
reward next is 0.5624, 
noisyNet noise sample is [array([0.72860664], dtype=float32), 0.32936624]. 
=============================================
[2019-03-24 05:37:26,168] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9999928e-01 5.8589242e-16 2.9187230e-17 2.4133493e-14 7.4189916e-07], sum to 1.0000
[2019-03-24 05:37:26,176] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0521
[2019-03-24 05:37:26,193] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 764569.9147620485 W.
[2019-03-24 05:37:26,196] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.1, 83.66666666666667, 1.0, 2.0, 0.3354281836762986, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5340125925459562, 6.911199999999999, 6.9112, 121.9260426156618, 764569.9147620485, 764569.914762049, 205010.2055523475], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3973200.0000, 
sim time next is 3973800.0000, 
raw observation next is [26.05, 83.83333333333333, 1.0, 2.0, 0.3340270471848143, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5317819376196835, 6.911200000000001, 6.9112, 121.9260426156618, 761374.5993392722, 761374.5993392718, 204614.4829377756], 
processed observation next is [0.0, 1.0, 0.5203703703703704, 0.8383333333333333, 1.0, 1.0, 0.20717505617239798, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.41472742202460433, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2719194997640258, 0.27191949976402563, 0.3934893902649531], 
reward next is 0.6065, 
noisyNet noise sample is [array([1.0599356], dtype=float32), -0.64401406]. 
=============================================
[2019-03-24 05:37:38,052] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9974865e-01 2.7370224e-15 7.4565352e-15 9.4637018e-15 2.5131088e-04], sum to 1.0000
[2019-03-24 05:37:38,061] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5662
[2019-03-24 05:37:38,066] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1434628.409288813 W.
[2019-03-24 05:37:38,071] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.4, 57.5, 1.0, 2.0, 0.6291178439685904, 1.0, 2.0, 0.6291178439685904, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1434628.409288813, 1434628.409288813, 278201.0264105516], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4185000.0000, 
sim time next is 4185600.0000, 
raw observation next is [29.53333333333333, 56.0, 1.0, 2.0, 0.6502079855736281, 0.0, 1.0, 0.0, 1.0, 1.0, 0.992095252099879, 6.911199999999999, 6.9112, 121.9260426156618, 1460515.63554523, 1460515.63554523, 307426.62908883], 
processed observation next is [1.0, 0.43478260869565216, 0.6493827160493827, 0.56, 1.0, 1.0, 0.5835809352067002, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9901190651248487, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5216127269804393, 0.5216127269804393, 0.5912050559400578], 
reward next is 0.4088, 
noisyNet noise sample is [array([-0.38496327], dtype=float32), -0.89006597]. 
=============================================
[2019-03-24 05:37:46,616] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1476340e-04 6.0408082e-15 4.5720209e-13 1.5481306e-14 9.9988520e-01], sum to 1.0000
[2019-03-24 05:37:46,624] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6838
[2019-03-24 05:37:46,626] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.0, 59.0, 1.0, 2.0, 0.2115367902855169, 1.0, 2.0, 0.2115367902855169, 1.0, 2.0, 0.3367734594068374, 6.911200000000001, 6.9112, 121.94756008, 723241.079137724, 723241.0791377235, 224400.1788848892], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4384800.0000, 
sim time next is 4385400.0000, 
raw observation next is [31.0, 60.16666666666667, 1.0, 2.0, 0.2160919544923359, 1.0, 2.0, 0.2160919544923359, 1.0, 2.0, 0.3440254291754345, 6.9112, 6.9112, 121.94756008, 738822.6205498974, 738822.6205498974, 225923.2485191347], 
processed observation next is [1.0, 0.782608695652174, 0.7037037037037037, 0.6016666666666667, 1.0, 1.0, 0.06677613630039987, 1.0, 1.0, 0.06677613630039987, 1.0, 1.0, 0.1800317864692931, 0.0, 0.0, 0.8096049824067558, 0.26386522162496334, 0.26386522162496334, 0.43446778561372057], 
reward next is 0.5655, 
noisyNet noise sample is [array([-0.15622126], dtype=float32), -0.7092035]. 
=============================================
[2019-03-24 05:37:47,912] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.6411826e-07 3.0233224e-16 2.7170440e-13 5.4433586e-15 9.9999928e-01], sum to 1.0000
[2019-03-24 05:37:47,918] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3444
[2019-03-24 05:37:47,923] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.86666666666667, 75.0, 1.0, 2.0, 0.2234424811201534, 1.0, 2.0, 0.2234424811201534, 1.0, 2.0, 0.3557277069568596, 6.9112, 6.9112, 121.94756008, 763966.7365192494, 763966.7365192494, 228405.4580516226], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4393200.0000, 
sim time next is 4393800.0000, 
raw observation next is [27.9, 76.0, 1.0, 2.0, 0.2259721454576497, 1.0, 2.0, 0.2259721454576497, 1.0, 2.0, 0.3597550149675696, 6.911200000000002, 6.9112, 121.94756008, 772620.2084029871, 772620.2084029863, 229266.6936271544], 
processed observation next is [1.0, 0.8695652173913043, 0.5888888888888888, 0.76, 1.0, 1.0, 0.07853826840196394, 1.0, 1.0, 0.07853826840196394, 1.0, 1.0, 0.199693768709462, 1.7763568394002506e-16, 0.0, 0.8096049824067558, 0.2759357887153525, 0.27593578871535224, 0.4408974877445277], 
reward next is 0.5591, 
noisyNet noise sample is [array([0.9815572], dtype=float32), -0.047488604]. 
=============================================
[2019-03-24 05:38:02,110] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.8313189e-01 1.3661430e-13 1.2910732e-11 9.7299304e-12 1.6868100e-02], sum to 1.0000
[2019-03-24 05:38:02,119] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1823
[2019-03-24 05:38:02,127] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 791809.2618260939 W.
[2019-03-24 05:38:02,136] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.2, 90.0, 1.0, 2.0, 0.2315815682779766, 1.0, 1.0, 0.2315815682779766, 1.0, 1.0, 0.3686853987836772, 6.9112, 6.9112, 121.94756008, 791809.2618260939, 791809.2618260939, 231189.2117574074], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4653600.0000, 
sim time next is 4654200.0000, 
raw observation next is [26.1, 92.0, 1.0, 2.0, 0.3521363329418781, 1.0, 2.0, 0.3521363329418781, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 802674.1577490118, 802674.1577490122, 193443.4986047746], 
processed observation next is [1.0, 0.8695652173913043, 0.5222222222222223, 0.92, 1.0, 1.0, 0.22873372969271205, 1.0, 1.0, 0.22873372969271205, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2866693420532185, 0.28666934205321865, 0.37200672808610497], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.09549043], dtype=float32), -1.027461]. 
=============================================
[2019-03-24 05:38:04,391] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.4690872e-01 3.1617431e-11 1.7665902e-09 7.4416490e-10 6.5309125e-01], sum to 1.0000
[2019-03-24 05:38:04,398] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4094
[2019-03-24 05:38:04,402] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.0, 94.0, 1.0, 2.0, 0.3763775676366939, 1.0, 2.0, 0.3763775676366939, 1.0, 1.0, 0.5992053454392356, 6.9112, 6.9112, 121.94756008, 1287302.514636694, 1287302.514636694, 286888.889016778], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4701600.0000, 
sim time next is 4702200.0000, 
raw observation next is [24.55, 91.50000000000001, 1.0, 2.0, 0.4179969729477004, 1.0, 2.0, 0.4179969729477004, 1.0, 2.0, 0.6654647941437601, 6.911199999999999, 6.9112, 121.94756008, 1429783.810458836, 1429783.810458836, 305055.5257337085], 
processed observation next is [1.0, 0.43478260869565216, 0.46481481481481485, 0.9150000000000001, 1.0, 1.0, 0.30713925350916715, 1.0, 1.0, 0.30713925350916715, 1.0, 1.0, 0.5818309926797002, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5106370751638699, 0.5106370751638699, 0.5866452417955933], 
reward next is 0.4134, 
noisyNet noise sample is [array([-0.07294583], dtype=float32), -0.71435755]. 
=============================================
[2019-03-24 05:38:05,304] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-24 05:38:05,306] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:38:05,306] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:38:05,307] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:38:05,307] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:38:05,308] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:38:05,308] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:38:05,309] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:38:05,311] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:38:05,310] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:38:05,315] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:38:05,327] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run23
[2019-03-24 05:38:05,356] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run23
[2019-03-24 05:38:05,378] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run23
[2019-03-24 05:38:05,403] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run23
[2019-03-24 05:38:05,428] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run23
[2019-03-24 05:38:26,849] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00616515], dtype=float32), 0.012612067]
[2019-03-24 05:38:26,850] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.16666666666666, 56.33333333333334, 1.0, 2.0, 0.6467825739663403, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9563040398554539, 6.9112, 6.9112, 121.9260426153766, 1504000.702271176, 1504000.702271176, 295760.8147469404]
[2019-03-24 05:38:26,851] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:38:26,859] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.5110598e-15 6.0727584e-17 7.9335020e-15 2.9336780e-09], sampled 0.9615534981512114
[2019-03-24 05:38:26,860] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1504000.702271176 W.
[2019-03-24 05:38:28,983] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00616515], dtype=float32), 0.012612067]
[2019-03-24 05:38:28,984] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.5334635, 78.194706935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6382368264326798, 6.9112, 6.9112, 121.9260426156618, 471109.7863009957, 471109.7863009957, 132442.6360792926]
[2019-03-24 05:38:28,985] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:38:28,988] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 6.2478202e-24 7.0989214e-28 9.6452666e-24 4.3553934e-18], sampled 0.024498639607361872
[2019-03-24 05:38:54,167] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00616515], dtype=float32), 0.012612067]
[2019-03-24 05:38:54,169] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.11735071, 101.5720872866667, 1.0, 2.0, 0.7840371157589596, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 893636.3536480549, 893636.3536480549, 192676.1208962745]
[2019-03-24 05:38:54,171] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:38:54,174] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.2477900e-16 1.0392554e-17 1.2282955e-15 7.7103213e-09], sampled 0.017966030993556648
[2019-03-24 05:38:54,176] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 893636.3536480549 W.
[2019-03-24 05:38:57,965] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00616515], dtype=float32), 0.012612067]
[2019-03-24 05:38:57,966] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.58333333333334, 60.16666666666667, 1.0, 2.0, 1.01160132925608, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.216144299278199, 6.9112, 121.9246844752402, 1309481.114120728, 1153324.116738254, 243538.2704241342]
[2019-03-24 05:38:57,967] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:38:57,970] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [9.9999964e-01 2.9204296e-16 1.1330179e-16 4.9226213e-15 3.7668443e-07], sampled 0.7127077411615964
[2019-03-24 05:38:57,973] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1309481.114120728 W.
[2019-03-24 05:39:05,219] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00616515], dtype=float32), 0.012612067]
[2019-03-24 05:39:05,220] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.17416181, 93.47754737333334, 1.0, 2.0, 0.6148591171537047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 706352.9482894645, 706352.9482894645, 160929.086489605]
[2019-03-24 05:39:05,221] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:39:05,224] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.00000000e+00 3.90255624e-18 1.02783653e-19 3.21828613e-17
 1.36031075e-10], sampled 0.052977008002793036
[2019-03-24 05:39:05,225] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 706352.9482894645 W.
[2019-03-24 05:39:06,368] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00616515], dtype=float32), 0.012612067]
[2019-03-24 05:39:06,369] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.73670527166666, 78.79433853333333, 1.0, 2.0, 0.7996916864329835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 911489.861316027, 911489.861316027, 195891.1430639768]
[2019-03-24 05:39:06,369] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:39:06,372] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 2.6150796e-18 9.3791800e-20 2.7116094e-17 2.7814351e-10], sampled 0.012134968706127514
[2019-03-24 05:39:06,373] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 911489.861316027 W.
[2019-03-24 05:39:24,583] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00616515], dtype=float32), 0.012612067]
[2019-03-24 05:39:24,584] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.44080153, 41.35314429, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6291039407969724, 6.9112, 6.9112, 121.9260426156618, 467717.5850326903, 467717.5850326903, 133730.0524737738]
[2019-03-24 05:39:24,585] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:39:24,589] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 4.2955158e-25 3.6408243e-29 7.3682458e-25 7.7511554e-19], sampled 0.7077493733792127
[2019-03-24 05:39:24,620] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00616515], dtype=float32), 0.012612067]
[2019-03-24 05:39:24,623] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.61693207, 47.518913735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6110988624754474, 6.9112, 6.9112, 121.9260426156618, 454617.7765529333, 454617.7765529333, 132222.4993795332]
[2019-03-24 05:39:24,624] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:39:24,627] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 7.0544981e-25 6.7383721e-29 1.2059579e-24 1.1928396e-18], sampled 0.403201947244911
[2019-03-24 05:39:51,530] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7832.2412 2530457072.2445 787.0000
[2019-03-24 05:39:51,629] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.2157 2219327515.0977 542.0000
[2019-03-24 05:39:51,647] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8359.1742 2339576585.4919 610.0000
[2019-03-24 05:39:51,665] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8558.2756 2258559483.9870 536.0000
[2019-03-24 05:39:51,766] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8400.8516 2293191706.8576 687.0000
[2019-03-24 05:39:52,781] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 550000, evaluation results [550000.0, 7832.241224074645, 2530457072.244546, 787.0, 8558.275598773422, 2258559483.986975, 536.0, 8633.215743022329, 2219327515.097705, 542.0, 8359.174243753323, 2339576585.491862, 610.0, 8400.851553697983, 2293191706.8576207, 687.0]
[2019-03-24 05:39:54,784] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.6337373e-01 6.0207904e-13 7.2835106e-11 5.6308375e-11 6.3662630e-01], sum to 1.0000
[2019-03-24 05:39:54,790] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6410
[2019-03-24 05:39:54,794] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.0, 94.0, 1.0, 2.0, 0.20464505313817, 1.0, 1.0, 0.20464505313817, 1.0, 2.0, 0.3258015894200517, 6.9112, 6.9112, 121.94756008, 699667.5830190907, 699667.5830190907, 222117.9237815149], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4755600.0000, 
sim time next is 4756200.0000, 
raw observation next is [24.03333333333333, 93.66666666666667, 1.0, 2.0, 0.2029573615701719, 1.0, 2.0, 0.2029573615701719, 1.0, 2.0, 0.3231147294795217, 6.911200000000001, 6.9112, 121.94756008, 693894.8687682202, 693894.8687682197, 221563.0831671984], 
processed observation next is [1.0, 0.043478260869565216, 0.4456790123456789, 0.9366666666666668, 1.0, 1.0, 0.05113971615496656, 1.0, 1.0, 0.05113971615496656, 1.0, 1.0, 0.15389341184940208, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.24781959598865005, 0.2478195959886499, 0.42608285224461234], 
reward next is 0.5739, 
noisyNet noise sample is [array([-0.34197462], dtype=float32), -1.0359031]. 
=============================================
[2019-03-24 05:40:03,614] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.5169675e-16 1.5659959e-20 1.8355376e-16 2.2805491e-13], sum to 1.0000
[2019-03-24 05:40:03,621] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2662
[2019-03-24 05:40:03,629] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 995885.8980103775 W.
[2019-03-24 05:40:03,632] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.1, 86.0, 1.0, 2.0, 0.2912294009367853, 1.0, 2.0, 0.2912294009367853, 1.0, 1.0, 0.4636466909707909, 6.911200000000003, 6.9112, 121.94756008, 995885.8980103775, 995885.8980103761, 252719.4379614003], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4910400.0000, 
sim time next is 4911000.0000, 
raw observation next is [28.91666666666667, 87.33333333333334, 1.0, 2.0, 0.4370085733958442, 0.0, 1.0, 0.0, 1.0, 2.0, 0.6957318812218056, 6.911199999999999, 6.9112, 121.9260426156618, 996261.207447793, 996261.2074477935, 235805.3053320366], 
processed observation next is [1.0, 0.8695652173913043, 0.6265432098765434, 0.8733333333333334, 1.0, 1.0, 0.3297721111855288, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.619664851527257, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3558075740884975, 0.35580757408849767, 0.4534717410231473], 
reward next is 0.5465, 
noisyNet noise sample is [array([1.7099993], dtype=float32), 0.10064149]. 
=============================================
[2019-03-24 05:40:03,656] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[27.47404 ]
 [27.293705]
 [27.317436]
 [25.881618]
 [26.208073]], R is [[27.69852448]
 [27.42153931]
 [27.72987366]
 [27.96468925]
 [28.19603348]].
[2019-03-24 05:40:04,042] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 6.3968016e-20 7.1858223e-24 6.8092006e-21 2.6275015e-16], sum to 1.0000
[2019-03-24 05:40:04,047] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4682
[2019-03-24 05:40:04,052] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 771108.2504065998 W.
[2019-03-24 05:40:04,056] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.58333333333334, 78.83333333333333, 1.0, 1.0, 0.648068168302765, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260110749695, 771108.2504065998, 771108.2504066003, 168016.0850099935], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4954200.0000, 
sim time next is 4954800.0000, 
raw observation next is [24.66666666666667, 79.66666666666667, 1.0, 2.0, 0.2799677614283442, 1.0, 1.0, 0.2799677614283442, 1.0, 1.0, 0.4466701954407421, 6.9112, 6.9112, 121.94756008, 975296.0138865411, 975296.0138865411, 248504.4650290956], 
processed observation next is [1.0, 0.34782608695652173, 0.469135802469136, 0.7966666666666667, 1.0, 1.0, 0.14281876360517165, 1.0, 0.5, 0.14281876360517165, 1.0, 0.5, 0.3083377443009276, 0.0, 0.0, 0.8096049824067558, 0.34832000495947896, 0.34832000495947896, 0.47789320197902996], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.1364304], dtype=float32), 1.1333226]. 
=============================================
[2019-03-24 05:40:04,533] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 2.5242988e-17 5.6757301e-21 3.4772907e-16 1.5372340e-12], sum to 1.0000
[2019-03-24 05:40:04,542] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4917
[2019-03-24 05:40:04,549] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1158686.460584725 W.
[2019-03-24 05:40:04,555] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.16666666666667, 83.16666666666667, 1.0, 2.0, 0.9619300473576863, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.99999299957638, 6.9112, 121.9257271939146, 1158686.460584725, 1113216.626203793, 232583.1995343042], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4936200.0000, 
sim time next is 4936800.0000, 
raw observation next is [24.93333333333333, 84.33333333333334, 1.0, 2.0, 0.8562408042985885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9259891461126, 994880.550157246, 994880.550157246, 208819.5443356436], 
processed observation next is [1.0, 0.13043478260869565, 0.47901234567901224, 0.8433333333333334, 1.0, 1.0, 0.8288581003554625, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094617738379336, 0.3553144821990164, 0.3553144821990164, 0.4015760467993146], 
reward next is 0.5984, 
noisyNet noise sample is [array([-1.4206235], dtype=float32), -1.2648354]. 
=============================================
[2019-03-24 05:40:14,054] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.5783648e-17 1.6913409e-20 1.6315508e-18 1.0325639e-12], sum to 1.0000
[2019-03-24 05:40:14,063] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3856
[2019-03-24 05:40:14,069] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 795230.249353184 W.
[2019-03-24 05:40:14,071] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.83333333333334, 98.33333333333334, 1.0, 2.0, 0.3488723540427738, 1.0, 2.0, 0.3488723540427738, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 795230.249353184, 795230.249353184, 192602.7617182035], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5115000.0000, 
sim time next is 5115600.0000, 
raw observation next is [24.8, 98.0, 1.0, 2.0, 0.3470570705044838, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5525261591028308, 6.911199999999999, 6.9112, 121.9260426156618, 791090.3015532552, 791090.3015532556, 208326.2095347772], 
processed observation next is [0.0, 0.21739130434782608, 0.4740740740740741, 0.98, 1.0, 1.0, 0.22268698869581408, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.4406576988785384, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.28253225055473397, 0.28253225055473413, 0.4006273260284177], 
reward next is 0.5994, 
noisyNet noise sample is [array([0.19997558], dtype=float32), 2.9905937]. 
=============================================
[2019-03-24 05:40:17,299] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9997663e-01 1.5137021e-14 5.1103097e-14 2.2682409e-13 2.3355344e-05], sum to 1.0000
[2019-03-24 05:40:17,306] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8976
[2019-03-24 05:40:17,313] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1901649.369128251 W.
[2019-03-24 05:40:17,317] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.75, 74.83333333333333, 1.0, 2.0, 0.5557922380909119, 1.0, 2.0, 0.5557922380909119, 1.0, 1.0, 0.8848393439302376, 6.9112, 6.9112, 121.94756008, 1901649.369128251, 1901649.369128251, 371815.5936610307], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5223000.0000, 
sim time next is 5223600.0000, 
raw observation next is [27.9, 73.0, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.977598926704619, 6.9112, 121.9258296647622, 1912114.416581807, 1878112.290827103, 383892.7965919305], 
processed observation next is [1.0, 0.4782608695652174, 0.5888888888888888, 0.73, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 0.006639892670461922, 0.0, 0.809460715047616, 0.682898005922074, 0.6707543895811082, 0.7382553780614048], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5908009], dtype=float32), 0.8125944]. 
=============================================
[2019-03-24 05:40:17,473] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 3.3560837e-20 1.1018398e-22 6.0068325e-20 4.8364175e-14], sum to 1.0000
[2019-03-24 05:40:17,478] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0283
[2019-03-24 05:40:17,483] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 746695.3700718239 W.
[2019-03-24 05:40:17,488] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.7, 93.0, 1.0, 2.0, 0.3275901729228915, 0.0, 1.0, 0.0, 1.0, 1.0, 0.521534224160343, 6.911199999999999, 6.9112, 121.9260426156618, 746695.3700718239, 746695.3700718243, 202806.6927760323], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5189400.0000, 
sim time next is 5190000.0000, 
raw observation next is [24.6, 92.66666666666666, 1.0, 2.0, 0.2159668878364041, 1.0, 1.0, 0.2159668878364041, 1.0, 2.0, 0.3438263189860544, 6.9112, 6.9112, 121.94756008, 738394.8092901866, 738394.8092901866, 225881.2760955789], 
processed observation next is [1.0, 0.043478260869565216, 0.46666666666666673, 0.9266666666666665, 1.0, 1.0, 0.0666272474242906, 1.0, 0.5, 0.0666272474242906, 1.0, 1.0, 0.179782898732568, 0.0, 0.0, 0.8096049824067558, 0.26371243188935234, 0.26371243188935234, 0.43438706941457483], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2075661], dtype=float32), -0.013737399]. 
=============================================
[2019-03-24 05:40:17,513] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[36.08864 ]
 [36.20734 ]
 [36.07354 ]
 [36.093636]
 [36.66661 ]], R is [[35.87078857]
 [35.51208115]
 [35.15695953]
 [34.8053894 ]
 [34.45733643]].
[2019-03-24 05:40:23,118] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.3175781e-22 6.3722355e-25 4.2228308e-23 6.9549695e-16], sum to 1.0000
[2019-03-24 05:40:23,123] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2187
[2019-03-24 05:40:23,131] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 798550.430782345 W.
[2019-03-24 05:40:23,135] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.36666666666667, 91.66666666666667, 1.0, 1.0, 0.2266154287572432, 1.0, 1.0, 0.2266154287572432, 1.0, 2.0, 0.3625886486583125, 6.9112, 6.9112, 121.94756008, 798550.430782345, 798550.430782345, 229342.1665562771], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5296800.0000, 
sim time next is 5297400.0000, 
raw observation next is [22.25, 92.0, 1.0, 2.0, 0.2104460343641774, 1.0, 2.0, 0.2104460343641774, 1.0, 2.0, 0.3367168863505103, 6.911200000000001, 6.9112, 121.94756008, 741541.7054834302, 741541.7054834297, 223883.8931159801], 
processed observation next is [1.0, 0.30434782608695654, 0.37962962962962965, 0.92, 1.0, 1.0, 0.060054802814496884, 1.0, 1.0, 0.060054802814496884, 1.0, 1.0, 0.17089610793813784, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.26483632338693935, 0.2648363233869392, 0.43054594829996173], 
reward next is 0.5695, 
noisyNet noise sample is [array([-1.1995705], dtype=float32), -0.75910854]. 
=============================================
[2019-03-24 05:40:24,099] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 4.9513309e-20 4.7705608e-26 5.7372882e-22 6.0189097e-16], sum to 1.0000
[2019-03-24 05:40:24,111] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7812
[2019-03-24 05:40:24,114] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.36666666666667, 67.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9250510056121259, 6.9112, 6.9112, 121.9260426156618, 665724.5852571523, 665724.5852571523, 180997.5623550962], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5334000.0000, 
sim time next is 5334600.0000, 
raw observation next is [28.33333333333334, 67.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9420402615116615, 6.911200000000001, 6.9112, 121.9260426156618, 678167.7190721342, 678167.7190721338, 183317.9720612145], 
processed observation next is [1.0, 0.7391304347826086, 0.6049382716049385, 0.6783333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9275503268895768, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24220275681147652, 0.24220275681147635, 0.35253456165618174], 
reward next is 0.6475, 
noisyNet noise sample is [array([-0.33399883], dtype=float32), -1.6269152]. 
=============================================
[2019-03-24 05:40:28,590] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9999547e-01 1.4710833e-11 4.3119258e-12 1.2281472e-11 4.5013071e-06], sum to 1.0000
[2019-03-24 05:40:28,595] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7489
[2019-03-24 05:40:28,600] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2131006.950853545 W.
[2019-03-24 05:40:28,605] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.33333333333334, 82.33333333333334, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 7.404607285427208, 6.9112, 121.9241432862336, 2131006.950853545, 1878342.256472572, 382367.3651055178], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5412000.0000, 
sim time next is 5412600.0000, 
raw observation next is [28.5, 81.5, 1.0, 2.0, 0.9094725894090506, 1.0, 1.0, 0.9094725894090506, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9257454841562, 2074714.964542936, 2074714.964542936, 391067.7610138572], 
processed observation next is [1.0, 0.6521739130434783, 0.6111111111111112, 0.815, 1.0, 1.0, 0.8922292731060126, 1.0, 0.5, 0.8922292731060126, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094601561759337, 0.7409696301939057, 0.7409696301939057, 0.75205338656511], 
reward next is 0.2479, 
noisyNet noise sample is [array([0.63769406], dtype=float32), -0.23241957]. 
=============================================
[2019-03-24 05:40:29,657] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 9.3223758e-16 5.4569097e-18 4.2009626e-16 8.5114337e-12], sum to 1.0000
[2019-03-24 05:40:29,662] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9599
[2019-03-24 05:40:29,672] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 788545.72248075 W.
[2019-03-24 05:40:29,676] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.86666666666667, 73.0, 1.0, 2.0, 0.3459413190826866, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5507498465018428, 6.9112, 6.9112, 121.9260426156618, 788545.72248075, 788545.72248075, 208010.0789647839], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5419200.0000, 
sim time next is 5419800.0000, 
raw observation next is [29.8, 73.5, 1.0, 2.0, 0.2276331538164461, 1.0, 1.0, 0.2276331538164461, 1.0, 2.0, 0.362399394370039, 6.9112, 6.9112, 121.94756008, 778302.236371874, 778302.236371874, 229834.1376693639], 
processed observation next is [1.0, 0.7391304347826086, 0.6592592592592593, 0.735, 1.0, 1.0, 0.08051565930529299, 1.0, 0.5, 0.08051565930529299, 1.0, 1.0, 0.2029992429625487, 0.0, 0.0, 0.8096049824067558, 0.2779650844185264, 0.2779650844185264, 0.4419887262872383], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.4094745], dtype=float32), -1.0138861]. 
=============================================
[2019-03-24 05:40:30,217] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.0862809e-15 1.4175252e-20 5.5386402e-17 7.6245775e-13], sum to 1.0000
[2019-03-24 05:40:30,225] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8300
[2019-03-24 05:40:30,238] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 858745.41481327 W.
[2019-03-24 05:40:30,241] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.26666666666667, 77.5, 1.0, 2.0, 0.3767212428160145, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5997524875174334, 6.9112, 6.9112, 121.9260426156618, 858745.41481327, 858745.41481327, 217031.0486825453], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5424600.0000, 
sim time next is 5425200.0000, 
raw observation next is [29.2, 78.0, 1.0, 2.0, 0.2535423432241958, 1.0, 1.0, 0.2535423432241958, 1.0, 2.0, 0.4036476677105666, 6.9112, 6.9112, 121.94756008, 866938.6327933607, 866938.6327933607, 238885.0326535026], 
processed observation next is [1.0, 0.8260869565217391, 0.637037037037037, 0.78, 1.0, 1.0, 0.11135993240975688, 1.0, 0.5, 0.11135993240975688, 1.0, 1.0, 0.2545595846382082, 0.0, 0.0, 0.8096049824067558, 0.30962094028334314, 0.30962094028334314, 0.45939429356442807], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.70151013], dtype=float32), -1.0656849]. 
=============================================
[2019-03-24 05:40:33,928] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.00000000e+00 2.44107238e-14 3.24329060e-18 1.16181885e-14
 2.82750046e-10], sum to 1.0000
[2019-03-24 05:40:33,934] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9651
[2019-03-24 05:40:33,940] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 952891.8669528335 W.
[2019-03-24 05:40:33,944] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.38333333333333, 93.0, 1.0, 2.0, 0.4179964940272522, 1.0, 2.0, 0.4179964940272522, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 952891.8669528335, 952891.866952834, 211187.7794656704], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5544600.0000, 
sim time next is 5545200.0000, 
raw observation next is [25.36666666666667, 93.0, 1.0, 2.0, 0.3843967382491279, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6119721262203845, 6.911199999999999, 6.9112, 121.9260426156618, 876251.899007981, 876251.8990079814, 219334.9304593579], 
processed observation next is [1.0, 0.17391304347826086, 0.49506172839506185, 0.93, 1.0, 1.0, 0.26713897410610465, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.5149651577754807, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.31294710678856463, 0.3129471067885648, 0.4217979431910729], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.27121365], dtype=float32), -0.11590784]. 
=============================================
[2019-03-24 05:40:42,247] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-24 05:40:42,249] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:40:42,249] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:40:42,250] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:40:42,250] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:40:42,251] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:40:42,252] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:40:42,253] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:40:42,253] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:40:42,254] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:40:42,255] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:40:42,269] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run24
[2019-03-24 05:40:42,269] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run24
[2019-03-24 05:40:42,269] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run24
[2019-03-24 05:40:42,318] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run24
[2019-03-24 05:40:42,344] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run24
[2019-03-24 05:40:45,445] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00567939], dtype=float32), 0.012741094]
[2019-03-24 05:40:45,446] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [16.4, 56.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3569822907965252, 6.9112, 6.9112, 121.9260426156618, 254871.8455379715, 254871.8455379715, 77457.8134941383]
[2019-03-24 05:40:45,446] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:40:45,447] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 5.8362678e-30 2.1036073e-35 3.2366957e-30 1.8849752e-23], sampled 0.3181438901292881
[2019-03-24 05:40:55,916] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00567939], dtype=float32), 0.012741094]
[2019-03-24 05:40:55,917] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.7, 64.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6831957352364542, 6.9112, 6.9112, 121.9260426156618, 504959.9722792754, 504959.9722792754, 137174.505455769]
[2019-03-24 05:40:55,917] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:40:55,919] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 2.9276184e-28 2.2745614e-33 1.7165863e-28 4.1751164e-22], sampled 0.31594241354944674
[2019-03-24 05:41:54,365] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00567939], dtype=float32), 0.012741094]
[2019-03-24 05:41:54,367] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.56666666666667, 88.0, 1.0, 2.0, 0.7729161963598403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 880953.5743871881, 880953.5743871881, 190412.9943963402]
[2019-03-24 05:41:54,368] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:41:54,370] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 2.0289234e-28 2.2015311e-32 5.3822293e-28 4.3909555e-20], sampled 0.9798413201718715
[2019-03-24 05:41:54,371] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 880953.5743871881 W.
[2019-03-24 05:42:27,336] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.7414 2219189295.2583 543.0000
[2019-03-24 05:42:28,008] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8559.5151 2258223744.7508 536.0000
[2019-03-24 05:42:28,108] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 05:42:28,281] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 05:42:28,323] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 05:42:29,340] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 575000, evaluation results [575000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8559.515058168116, 2258223744.7507515, 536.0, 8633.741374971278, 2219189295.2583184, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 05:42:31,919] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.3745071e-34 5.5040225e-29], sum to 1.0000
[2019-03-24 05:42:31,925] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6791
[2019-03-24 05:42:31,931] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.06666666666667, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7456335324696408, 6.9112, 6.9112, 121.9260426156618, 556799.0029587015, 556799.0029587015, 151340.1321308659], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5721600.0000, 
sim time next is 5722200.0000, 
raw observation next is [21.1, 94.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7431617189446348, 6.9112, 6.9112, 121.9260426156618, 554992.8537276682, 554992.8537276682, 150985.667802706], 
processed observation next is [0.0, 0.21739130434782608, 0.3370370370370371, 0.945, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6789521486807933, 0.0, 0.0, 0.8094621288201359, 0.1982117334741672, 0.1982117334741672, 0.29035705346674234], 
reward next is 0.7096, 
noisyNet noise sample is [array([0.11099879], dtype=float32), -0.086471274]. 
=============================================
[2019-03-24 05:42:36,747] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 5.8567668e-29 1.6993546e-34 6.4941365e-29 1.4529721e-23], sum to 1.0000
[2019-03-24 05:42:36,753] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9975
[2019-03-24 05:42:36,759] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1490464.687956178 W.
[2019-03-24 05:42:36,763] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.13333333333333, 41.66666666666667, 1.0, 2.0, 0.9723456590591086, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.475572408063393, 6.9112, 121.9236939876816, 1490464.687956178, 1201461.139097766, 238262.0792444201], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5848800.0000, 
sim time next is 5849400.0000, 
raw observation next is [28.16666666666666, 41.33333333333334, 1.0, 2.0, 0.3667972400267094, 1.0, 1.0, 0.3667972400267094, 1.0, 1.0, 0.5958727293963688, 6.9112, 6.9112, 121.94756008, 1333593.64256377, 1333593.64256377, 281997.229019279], 
processed observation next is [1.0, 0.6956521739130435, 0.5987654320987652, 0.41333333333333344, 1.0, 1.0, 0.24618719050798737, 1.0, 0.5, 0.24618719050798737, 1.0, 0.5, 0.49484091174546097, 0.0, 0.0, 0.8096049824067558, 0.47628344377277504, 0.47628344377277504, 0.5423023634986135], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9069359], dtype=float32), -0.7445339]. 
=============================================
[2019-03-24 05:42:40,711] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.7172997e-36 3.2070910e-28], sum to 1.0000
[2019-03-24 05:42:40,720] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7215
[2019-03-24 05:42:40,725] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.83333333333334, 64.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7086166227794015, 6.911200000000001, 6.9112, 121.9260426156618, 529540.8884078572, 529540.8884078567, 145905.5225815938], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5862000.0000, 
sim time next is 5862600.0000, 
raw observation next is [24.65, 65.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7043207166702565, 6.9112, 6.9112, 121.9260426156618, 526333.6253358336, 526333.6253358336, 145330.3586803797], 
processed observation next is [1.0, 0.8695652173913043, 0.46851851851851845, 0.655, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6304008958378207, 0.0, 0.0, 0.8094621288201359, 0.18797629476279773, 0.18797629476279773, 0.2794814590007302], 
reward next is 0.7205, 
noisyNet noise sample is [array([1.1445612], dtype=float32), 1.7409811]. 
=============================================
[2019-03-24 05:42:40,809] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 6.4471741e-26 5.2195564e-30 8.2021394e-26 2.3767490e-16], sum to 1.0000
[2019-03-24 05:42:40,818] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3963
[2019-03-24 05:42:40,826] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1353815.337299641 W.
[2019-03-24 05:42:40,835] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.1, 44.5, 1.0, 2.0, 0.3821152317543529, 1.0, 2.0, 0.3821152317543529, 1.0, 2.0, 0.6124160285619467, 6.911200000000001, 6.9112, 121.94756008, 1353815.337299641, 1353815.337299641, 289240.9020262959], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5923800.0000, 
sim time next is 5924400.0000, 
raw observation next is [29.26666666666667, 43.66666666666667, 1.0, 2.0, 0.606836113157373, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9617699131004236, 6.911199999999999, 6.9112, 121.9260426156618, 1442050.009676435, 1442050.009676436, 292345.6176491905], 
processed observation next is [1.0, 0.5652173913043478, 0.6395061728395063, 0.4366666666666667, 1.0, 1.0, 0.5319477537587773, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9522123913755295, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5150178605987268, 0.5150178605987271, 0.5622031108638278], 
reward next is 0.4378, 
noisyNet noise sample is [array([-0.91807497], dtype=float32), -1.8685842]. 
=============================================
[2019-03-24 05:42:42,465] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 5.2911157e-26 5.9251207e-31 5.0711504e-26 1.8923866e-18], sum to 1.0000
[2019-03-24 05:42:42,476] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8376
[2019-03-24 05:42:42,483] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1225052.464812026 W.
[2019-03-24 05:42:42,492] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.76666666666667, 46.16666666666667, 1.0, 2.0, 0.343134715426854, 1.0, 1.0, 0.343134715426854, 1.0, 2.0, 0.5516615094188377, 6.911199999999999, 6.9112, 121.94756008, 1225052.464812026, 1225052.464812027, 272779.4252179786], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5922600.0000, 
sim time next is 5923200.0000, 
raw observation next is [28.93333333333334, 45.33333333333334, 1.0, 2.0, 0.3712959969422774, 1.0, 2.0, 0.3712959969422774, 1.0, 2.0, 0.5954277954539016, 6.9112, 6.9112, 121.94756008, 1317567.460641871, 1317567.460641871, 284602.6193189765], 
processed observation next is [1.0, 0.5652173913043478, 0.6271604938271608, 0.4533333333333334, 1.0, 1.0, 0.25154285350271116, 1.0, 1.0, 0.25154285350271116, 1.0, 1.0, 0.4942847443173769, 0.0, 0.0, 0.8096049824067558, 0.4705598073720968, 0.4705598073720968, 0.5473127294595701], 
reward next is 0.4527, 
noisyNet noise sample is [array([-0.30077124], dtype=float32), 0.27473003]. 
=============================================
[2019-03-24 05:42:43,067] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 4.6469503e-26 1.3678408e-28 5.0420839e-25 3.1864982e-18], sum to 1.0000
[2019-03-24 05:42:43,075] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5284
[2019-03-24 05:42:43,082] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 835525.1854976609 W.
[2019-03-24 05:42:43,086] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.6, 68.0, 1.0, 2.0, 0.3419232532515777, 1.0, 1.0, 0.3419232532515777, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 835525.1854976609, 835525.1854976614, 193082.0983608517], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5907600.0000, 
sim time next is 5908200.0000, 
raw observation next is [23.85, 67.0, 1.0, 2.0, 0.4332678321636506, 1.0, 2.0, 0.4332678321636506, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1054797.216942761, 1054797.216942761, 218217.8942272425], 
processed observation next is [1.0, 0.391304347826087, 0.43888888888888894, 0.67, 1.0, 1.0, 0.32531884781386977, 1.0, 1.0, 0.32531884781386977, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3767132917652718, 0.3767132917652718, 0.41964979659085094], 
reward next is 0.5804, 
noisyNet noise sample is [array([0.29022002], dtype=float32), -0.059831142]. 
=============================================
[2019-03-24 05:42:50,837] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 1.2892814e-31 2.1726576e-38 4.3730072e-33 1.3985375e-21], sum to 1.0000
[2019-03-24 05:42:50,842] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4882
[2019-03-24 05:42:50,846] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.78333333333333, 82.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8122842537090035, 6.911199999999999, 6.9112, 121.9260426156618, 602594.4370065748, 602594.4370065753, 162212.6663027556], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6048600.0000, 
sim time next is 6049200.0000, 
raw observation next is [23.66666666666666, 83.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8111722887617363, 6.911200000000001, 6.9112, 121.9260426156618, 601778.7100497469, 601778.7100497466, 162068.3028267902], 
processed observation next is [1.0, 0.0, 0.4320987654320985, 0.8366666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7639653609521704, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2149209678749096, 0.2149209678749095, 0.31166981312844266], 
reward next is 0.6883, 
noisyNet noise sample is [array([1.4567237], dtype=float32), -1.076308]. 
=============================================
[2019-03-24 05:42:53,846] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.1047056e-30 6.9865989e-35 3.6936435e-31 9.9374906e-22], sum to 1.0000
[2019-03-24 05:42:53,852] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4630
[2019-03-24 05:42:53,857] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.06666666666666, 67.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8750121420864352, 6.911199999999999, 6.9112, 121.9260426156618, 643137.6318613628, 643137.6318613633, 172034.4735470461], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6122400.0000, 
sim time next is 6123000.0000, 
raw observation next is [26.98333333333333, 67.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.874203064725757, 6.9112, 6.9112, 121.9260426156618, 642743.3579362264, 642743.3579362264, 171879.560938331], 
processed observation next is [1.0, 0.8695652173913043, 0.5549382716049381, 0.6766666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8427538309071964, 0.0, 0.0, 0.8094621288201359, 0.22955119926293802, 0.22955119926293802, 0.3305376171890981], 
reward next is 0.6695, 
noisyNet noise sample is [array([-0.20699342], dtype=float32), 0.24745686]. 
=============================================
[2019-03-24 05:42:53,876] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[52.685154]
 [52.605167]
 [52.84679 ]
 [53.23151 ]
 [53.15688 ]], R is [[52.77207184]
 [52.91351318]
 [53.05347061]
 [53.19145203]
 [53.32685471]].
[2019-03-24 05:42:56,360] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9996245e-01 6.4838061e-14 3.4144196e-14 5.3020515e-14 3.7516475e-05], sum to 1.0000
[2019-03-24 05:42:56,367] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0693
[2019-03-24 05:42:56,379] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1552068.275100996 W.
[2019-03-24 05:42:56,383] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.85, 69.5, 1.0, 2.0, 0.7285974292858474, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9904534324672688, 6.911199999999999, 6.9112, 121.9260426156618, 1552068.275100996, 1552068.275100997, 321252.7254011538], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6172200.0000, 
sim time next is 6172800.0000, 
raw observation next is [27.03333333333333, 68.66666666666667, 1.0, 2.0, 0.6501390793085672, 1.0, 1.0, 0.6501390793085672, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1485165.170254485, 1485165.170254485, 285849.0168370398], 
processed observation next is [1.0, 0.43478260869565216, 0.55679012345679, 0.6866666666666668, 1.0, 1.0, 0.5834989039387705, 1.0, 0.5, 0.5834989039387705, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5304161322337446, 0.5304161322337446, 0.549709647763538], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2476104], dtype=float32), 0.7642756]. 
=============================================
[2019-03-24 05:43:00,482] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 1.6211660e-32 0.0000000e+00 8.7023004e-34 2.7917795e-24], sum to 1.0000
[2019-03-24 05:43:00,488] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2020
[2019-03-24 05:43:00,493] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.1, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7695405836686154, 6.911200000000001, 6.9112, 121.9260426156618, 573487.5604613783, 573487.5604613778, 155412.0250671858], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6233400.0000, 
sim time next is 6234000.0000, 
raw observation next is [23.0, 83.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7693077193914253, 6.911199999999999, 6.9112, 121.9260426156618, 573340.6923375642, 573340.6923375647, 155362.7426245603], 
processed observation next is [0.0, 0.13043478260869565, 0.4074074074074074, 0.8366666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7116346492392817, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2047645329777015, 0.20476453297770167, 0.29877450504723135], 
reward next is 0.7012, 
noisyNet noise sample is [array([0.4606271], dtype=float32), 1.2840736]. 
=============================================
[2019-03-24 05:43:00,517] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[63.94656 ]
 [64.397865]
 [64.40233 ]
 [64.5494  ]
 [64.67962 ]], R is [[64.02913666]
 [64.08998108]
 [64.14994049]
 [64.20877075]
 [64.26641846]].
[2019-03-24 05:43:05,183] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 6.1726649e-35 4.3931962e-37 1.0108486e-33 8.8165166e-25], sum to 1.0000
[2019-03-24 05:43:05,193] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5280
[2019-03-24 05:43:05,199] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.13333333333333, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9037108535357383, 6.9112, 6.9112, 121.9260426156618, 662320.6479954047, 662320.6479954047, 176241.8564081186], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6320400.0000, 
sim time next is 6321000.0000, 
raw observation next is [24.11666666666667, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9027948474858433, 6.911199999999999, 6.9112, 121.9260426156618, 661807.6374407382, 661807.6374407386, 176085.5916941315], 
processed observation next is [0.0, 0.13043478260869565, 0.44876543209876557, 0.88, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.878493559357304, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23635987051454935, 0.2363598705145495, 0.3386261378733298], 
reward next is 0.6614, 
noisyNet noise sample is [array([-0.38182124], dtype=float32), 0.3570257]. 
=============================================
[2019-03-24 05:43:05,213] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[57.267635]
 [57.44126 ]
 [57.5607  ]
 [57.67111 ]
 [57.959663]], R is [[57.20212555]
 [57.29117584]
 [57.37879181]
 [57.46492004]
 [57.54950333]].
[2019-03-24 05:43:18,635] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-24 05:43:18,636] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:43:18,637] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:43:18,637] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:43:18,638] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:43:18,638] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:43:18,639] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:43:18,639] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:43:18,640] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:43:18,641] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:43:18,644] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:43:18,656] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run25
[2019-03-24 05:43:18,685] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run25
[2019-03-24 05:43:18,708] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run25
[2019-03-24 05:43:18,708] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run25
[2019-03-24 05:43:18,744] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run25
[2019-03-24 05:43:20,969] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00567939], dtype=float32), 0.013001922]
[2019-03-24 05:43:20,970] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.4, 62.0, 1.0, 2.0, 0.9638200231097899, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.33525791511818, 6.9112, 121.9245361929487, 1392577.476607441, 1175424.605204562, 235709.4718582042]
[2019-03-24 05:43:20,971] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:43:20,972] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.0304176e-23 1.5372912e-25 1.1055574e-22 1.7732796e-14], sampled 0.9521304608378066
[2019-03-24 05:43:20,974] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1392577.476607441 W.
[2019-03-24 05:43:24,451] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00567939], dtype=float32), 0.013001922]
[2019-03-24 05:43:24,453] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.41666666666666, 47.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.451014395579537, 6.9112, 6.9112, 121.9260426156618, 323109.801405657, 323109.801405657, 111876.6080733267]
[2019-03-24 05:43:24,455] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:43:24,457] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 4.8613411e-37 0.0000000e+00 2.7194973e-36 3.7137294e-26], sampled 0.5620232136074156
[2019-03-24 05:43:58,330] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00567939], dtype=float32), 0.013001922]
[2019-03-24 05:43:58,331] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [34.45878024666667, 42.02212226, 1.0, 2.0, 1.002863010704863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.162301101109344, 6.9112, 121.9248749032618, 1271918.545330073, 1143333.569898595, 241412.4637695457]
[2019-03-24 05:43:58,334] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:43:58,336] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.0242281e-26 1.2403791e-28 1.5609521e-25 6.2331815e-16], sampled 0.767632753338528
[2019-03-24 05:43:58,337] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1271918.545330073 W.
[2019-03-24 05:44:12,785] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00567939], dtype=float32), 0.013001922]
[2019-03-24 05:44:12,877] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [32.0, 66.33333333333333, 1.0, 2.0, 0.9063576722335019, 1.0, 2.0, 0.9063576722335019, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2067600.893626458, 2067600.893626458, 389664.9162557596]
[2019-03-24 05:44:12,878] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:44:12,881] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 5.3994348e-23 3.0687794e-24 9.3914151e-22 1.3664647e-12], sampled 0.4809180618992581
[2019-03-24 05:44:12,883] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2067600.893626458 W.
[2019-03-24 05:45:01,853] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 05:45:02,436] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 05:45:02,476] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8559.5106 2258278767.0965 536.0000
[2019-03-24 05:45:02,481] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.0243 2219243581.2580 543.0000
[2019-03-24 05:45:02,779] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8362.6197 2339528955.2376 616.0000
[2019-03-24 05:45:03,791] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 600000, evaluation results [600000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8559.510645911187, 2258278767.096507, 536.0, 8633.02425815251, 2219243581.258006, 543.0, 8362.619748969548, 2339528955.237554, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 05:45:13,447] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 8.0262764e-17 3.3765823e-18 9.0649665e-17 8.2403622e-09], sum to 1.0000
[2019-03-24 05:45:13,454] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6244
[2019-03-24 05:45:13,463] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 934042.3326937092 W.
[2019-03-24 05:45:13,468] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.7, 57.0, 1.0, 2.0, 0.3757387093202604, 1.0, 2.0, 0.3757387093202604, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 934042.3326937092, 934042.3326937096, 202490.8313751387], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6771600.0000, 
sim time next is 6772200.0000, 
raw observation next is [23.88333333333333, 56.5, 1.0, 2.0, 0.3536814050520466, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5920841919612517, 6.911199999999999, 6.9112, 121.9260426156618, 882649.3609965631, 882649.3609965636, 206112.4801423763], 
processed observation next is [1.0, 0.391304347826087, 0.4401234567901233, 0.565, 1.0, 1.0, 0.23057310125243644, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.49010523995156463, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3152319146416297, 0.31523191464162986, 0.3963701541199544], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8867715], dtype=float32), 1.4249134]. 
=============================================
[2019-03-24 05:45:14,183] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9999869e-01 1.1672587e-15 2.3319849e-16 2.0867220e-15 1.2525699e-06], sum to 1.0000
[2019-03-24 05:45:14,194] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3664
[2019-03-24 05:45:14,204] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1044357.949754491 W.
[2019-03-24 05:45:14,208] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.1, 49.16666666666667, 1.0, 2.0, 0.2881488224765437, 1.0, 2.0, 0.2881488224765437, 1.0, 1.0, 0.4671571927288157, 6.911200000000001, 6.9112, 121.94756008, 1044357.949754491, 1044357.949754491, 250754.8503443234], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6785400.0000, 
sim time next is 6786000.0000, 
raw observation next is [27.2, 49.0, 1.0, 2.0, 0.2487956876825425, 1.0, 2.0, 0.2487956876825425, 1.0, 2.0, 0.4029738573972872, 6.911200000000001, 6.9112, 121.94756008, 900330.2031301794, 900330.203130179, 236421.1293409677], 
processed observation next is [1.0, 0.5652173913043478, 0.5629629629629629, 0.49, 1.0, 1.0, 0.1057091520030268, 1.0, 1.0, 0.1057091520030268, 1.0, 1.0, 0.25371732174660894, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.3215465011179212, 0.32154650111792105, 0.4546560179633994], 
reward next is 0.5453, 
noisyNet noise sample is [array([-0.19932312], dtype=float32), 1.2922091]. 
=============================================
[2019-03-24 05:45:14,227] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[37.097183]
 [37.377453]
 [37.112614]
 [36.57451 ]
 [35.948147]], R is [[39.27256393]
 [39.39761734]
 [39.59729385]
 [39.82902908]
 [40.03596497]].
[2019-03-24 05:45:21,967] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 2.2035452e-34 1.9695569e-34 2.4940310e-34 5.6248566e-23], sum to 1.0000
[2019-03-24 05:45:21,974] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1879
[2019-03-24 05:45:21,977] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.6, 48.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7876769504450416, 6.9112, 6.9112, 121.9260426156618, 585798.148916711, 585798.148916711, 158410.6819015614], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6976800.0000, 
sim time next is 6977400.0000, 
raw observation next is [29.31666666666667, 48.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7826015711968508, 6.9112, 6.9112, 121.9260426156618, 582356.1598019082, 582356.1598019082, 157591.1288401856], 
processed observation next is [0.0, 0.782608695652174, 0.6413580246913582, 0.4883333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7282519639960635, 0.0, 0.0, 0.8094621288201359, 0.20798434278639577, 0.20798434278639577, 0.3030598631542031], 
reward next is 0.6969, 
noisyNet noise sample is [array([-1.9646631], dtype=float32), -0.47139382]. 
=============================================
[2019-03-24 05:45:22,254] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 1.5606346e-35 1.4646033e-37 3.2010068e-34 3.3466054e-23], sum to 1.0000
[2019-03-24 05:45:22,259] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7708
[2019-03-24 05:45:22,270] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.56666666666667, 85.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.691972472430123, 6.9112, 6.9112, 121.9260426156618, 517070.003503301, 517070.003503301, 143521.7381866515], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6932400.0000, 
sim time next is 6933000.0000, 
raw observation next is [21.68333333333333, 85.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6955175666700589, 6.9112, 6.9112, 121.9260426156618, 519743.6915571484, 519743.6915571484, 144096.1628648597], 
processed observation next is [0.0, 0.21739130434782608, 0.35864197530864184, 0.8533333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6193969583375736, 0.0, 0.0, 0.8094621288201359, 0.18562274698469586, 0.18562274698469586, 0.2771080055093456], 
reward next is 0.7229, 
noisyNet noise sample is [array([-0.95831704], dtype=float32), -1.0121337]. 
=============================================
[2019-03-24 05:45:22,296] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[69.27599 ]
 [69.364685]
 [69.43402 ]
 [69.52241 ]
 [69.57096 ]], R is [[69.21897125]
 [69.2507782 ]
 [69.28311157]
 [69.31607819]
 [69.34989166]].
[2019-03-24 05:45:42,335] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.8131554e-25 1.3832028e-23 1.5543870e-24 1.1376611e-12], sum to 1.0000
[2019-03-24 05:45:42,341] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9064
[2019-03-24 05:45:42,346] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1302893.990973609 W.
[2019-03-24 05:45:42,351] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.9, 61.0, 1.0, 2.0, 0.5521408510750978, 0.0, 1.0, 0.0, 1.0, 1.0, 0.88462762025945, 6.911199999999999, 6.9112, 121.9260426156618, 1302893.990973609, 1302893.990973609, 274753.5952077463], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7315800.0000, 
sim time next is 7316400.0000, 
raw observation next is [26.9, 61.0, 1.0, 2.0, 0.393515105347939, 1.0, 1.0, 0.393515105347939, 1.0, 2.0, 0.6279938305123582, 6.9112, 6.9112, 121.94756008, 1373032.060078961, 1373032.060078961, 294318.2481734729], 
processed observation next is [1.0, 0.6956521739130435, 0.5518518518518518, 0.61, 1.0, 1.0, 0.2779941730332607, 1.0, 0.5, 0.2779941730332607, 1.0, 1.0, 0.5349922881404477, 0.0, 0.0, 0.8096049824067558, 0.49036859288534324, 0.49036859288534324, 0.5659966311028325], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.21072741], dtype=float32), 0.8317928]. 
=============================================
[2019-03-24 05:45:47,453] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.8990492e-38 1.9034424e-25], sum to 1.0000
[2019-03-24 05:45:47,460] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0559
[2019-03-24 05:45:47,464] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.26666666666667, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6435684975639145, 6.9112, 6.9112, 121.9260426156618, 479927.6191491036, 479927.6191491036, 136526.5504293599], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7425600.0000, 
sim time next is 7426200.0000, 
raw observation next is [20.28333333333333, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6417168534878875, 6.9112, 6.9112, 121.9260426156618, 478582.9441831722, 478582.9441831722, 136383.4063476695], 
processed observation next is [1.0, 0.9565217391304348, 0.3067901234567901, 0.9, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5521460668598593, 0.0, 0.0, 0.8094621288201359, 0.17092248006541863, 0.17092248006541863, 0.26227578143782593], 
reward next is 0.7377, 
noisyNet noise sample is [array([-0.80432874], dtype=float32), -0.94213897]. 
=============================================
[2019-03-24 05:45:48,311] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.2674131e-35 0.0000000e+00 2.4010573e-35 3.0919973e-25], sum to 1.0000
[2019-03-24 05:45:48,320] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8185
[2019-03-24 05:45:48,326] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.75, 87.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6896325894523261, 6.911200000000001, 6.9112, 121.9260426156618, 515270.3129725526, 515270.3129725521, 144304.0899764126], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7464600.0000, 
sim time next is 7465200.0000, 
raw observation next is [21.9, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6949848249440989, 6.911199999999999, 6.9112, 121.9260426156618, 519203.1123151541, 519203.1123151546, 145103.4766372804], 
processed observation next is [0.0, 0.391304347826087, 0.36666666666666664, 0.87, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6187310311801235, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1854296829696979, 0.18542968296969806, 0.2790451473793854], 
reward next is 0.7210, 
noisyNet noise sample is [array([-0.27454814], dtype=float32), 0.7108006]. 
=============================================
[2019-03-24 05:45:50,580] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 7.0847673e-37 0.0000000e+00 2.7244428e-34 1.5064822e-25], sum to 1.0000
[2019-03-24 05:45:50,587] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9735
[2019-03-24 05:45:50,603] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.91666666666666, 89.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8029670991418815, 6.911200000000001, 6.9112, 121.9260426156618, 595606.1442749839, 595606.1442749834, 161073.7304010178], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7501800.0000, 
sim time next is 7502400.0000, 
raw observation next is [22.8, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8027103797014364, 6.911200000000001, 6.9112, 121.9260426156618, 595573.9374663914, 595573.9374663909, 160972.3275998288], 
processed observation next is [0.0, 0.8695652173913043, 0.4, 0.9, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7533879746267954, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21270497766656835, 0.21270497766656818, 0.3095621684612092], 
reward next is 0.6904, 
noisyNet noise sample is [array([0.03297266], dtype=float32), -0.69758856]. 
=============================================
[2019-03-24 05:45:51,923] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 3.1800695e-36 4.0252593e-38 3.1182180e-35 7.1378680e-26], sum to 1.0000
[2019-03-24 05:45:51,931] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2657
[2019-03-24 05:45:51,936] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.15, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7349467405789268, 6.9112, 6.9112, 121.9260426156618, 548422.7231916204, 548422.7231916204, 150640.8703311109], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7521000.0000, 
sim time next is 7521600.0000, 
raw observation next is [21.1, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7335941677564036, 6.9112, 6.9112, 121.9260426156618, 547517.4028652122, 547517.4028652122, 150360.569752152], 
processed observation next is [0.0, 0.043478260869565216, 0.3370370370370371, 0.96, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6669927096955044, 0.0, 0.0, 0.8094621288201359, 0.19554192959471864, 0.19554192959471864, 0.2891549418310615], 
reward next is 0.7108, 
noisyNet noise sample is [array([-1.5591964], dtype=float32), -0.3912587]. 
=============================================
[2019-03-24 05:45:52,849] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-24 05:45:52,850] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:45:52,850] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:45:52,852] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:45:52,852] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:45:52,854] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:45:52,856] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:45:52,856] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:45:52,856] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:45:52,857] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:45:52,858] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:45:52,876] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run26
[2019-03-24 05:45:52,877] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run26
[2019-03-24 05:45:52,898] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run26
[2019-03-24 05:45:52,947] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run26
[2019-03-24 05:45:52,973] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run26
[2019-03-24 05:45:54,364] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00567989], dtype=float32), 0.013301698]
[2019-03-24 05:45:54,366] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.46666666666667, 21.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6732870278247604, 6.9112, 6.9112, 121.9260426156618, 482113.8262732611, 482113.8262732611, 129804.5977008661]
[2019-03-24 05:45:54,368] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:45:54,371] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.6759780e-35 0.0000000e+00 3.0827261e-34 3.1980816e-24], sampled 0.5550765840115341
[2019-03-24 05:46:09,823] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00567989], dtype=float32), 0.013301698]
[2019-03-24 05:46:09,825] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [32.33333333333334, 32.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6850122486513341, 6.9112, 6.9112, 121.9260426156618, 511898.341554679, 511898.341554679, 143269.4663462128]
[2019-03-24 05:46:09,826] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:46:09,827] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 4.1035452e-35 2.6344977e-38 7.1667328e-34 5.3721483e-24], sampled 0.23417111080867536
[2019-03-24 05:46:14,275] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00567989], dtype=float32), 0.013301698]
[2019-03-24 05:46:14,276] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.75, 91.50000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7883330332071269, 6.9112, 6.9112, 121.9260426156618, 589043.4748856709, 589043.4748856709, 154100.0169530246]
[2019-03-24 05:46:14,277] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:46:14,279] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.00000000e+00 1.09307144e-33 1.50016565e-36 2.18725027e-32
 1.14560968e-22], sampled 0.46688456266605005
[2019-03-24 05:46:18,307] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00567989], dtype=float32), 0.013301698]
[2019-03-24 05:46:18,308] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [31.70314632166667, 40.1832327, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7624833007771403, 6.9112, 6.9112, 121.9260426156618, 567510.3016918614, 567510.3016918614, 155076.0047991765]
[2019-03-24 05:46:18,311] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:46:18,316] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 3.8633278e-36 0.0000000e+00 8.7005368e-35 1.9507986e-24], sampled 0.32840842952369576
[2019-03-24 05:46:47,685] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00567989], dtype=float32), 0.013301698]
[2019-03-24 05:46:47,686] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.4, 94.66666666666666, 1.0, 2.0, 0.6836302096916058, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1494117.499845947, 1494117.499845947, 314284.4958060323]
[2019-03-24 05:46:47,688] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:46:47,691] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 5.0264249e-28 3.4350917e-29 1.9821674e-26 2.8149110e-16], sampled 0.4181785400037962
[2019-03-24 05:46:47,693] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1494117.499845947 W.
[2019-03-24 05:47:24,989] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00567989], dtype=float32), 0.013301698]
[2019-03-24 05:47:24,989] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.00199177666667, 78.13393794333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8620021803122071, 6.9112, 6.9112, 121.9260426156618, 635682.8789566453, 635682.8789566453, 169785.5345524732]
[2019-03-24 05:47:24,991] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:47:24,993] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 8.4601729e-35 1.0973390e-37 2.0199522e-33 2.8319182e-23], sampled 0.018702714276867427
[2019-03-24 05:47:30,774] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00567989], dtype=float32), 0.013301698]
[2019-03-24 05:47:30,775] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.34518962666667, 88.27676443666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6062077514772486, 6.9112, 6.9112, 121.9260426156618, 451202.40771863, 451202.40771863, 131945.7877856295]
[2019-03-24 05:47:30,776] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:47:30,779] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 4.4548169e-34 6.9017721e-37 1.0175617e-32 9.1511740e-23], sampled 0.49885701678516714
[2019-03-24 05:47:36,478] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8558.6918 2258312516.3468 536.0000
[2019-03-24 05:47:37,256] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8403.5218 2293034398.2444 697.0000
[2019-03-24 05:47:37,362] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8361.8044 2339582728.4665 616.0000
[2019-03-24 05:47:37,400] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7840.1135 2529851152.3099 831.0000
[2019-03-24 05:47:37,470] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.7275 2219196514.3954 543.0000
[2019-03-24 05:47:38,487] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 625000, evaluation results [625000.0, 7840.11350377941, 2529851152.3098564, 831.0, 8558.691802686531, 2258312516.34677, 536.0, 8633.727492015112, 2219196514.395377, 543.0, 8361.804412745285, 2339582728.466484, 616.0, 8403.521846518315, 2293034398.244441, 697.0]
[2019-03-24 05:47:39,808] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 3.9344787e-36 1.0523919e-26], sum to 1.0000
[2019-03-24 05:47:39,815] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3935
[2019-03-24 05:47:39,819] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.5, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8628785788432882, 6.911200000000001, 6.9112, 121.9260426156618, 633328.8675052646, 633328.8675052641, 170677.2274688228], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7569000.0000, 
sim time next is 7569600.0000, 
raw observation next is [27.66666666666666, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8750607866716414, 6.911200000000001, 6.9112, 121.9260426156618, 640866.6289445808, 640866.6289445803, 172564.9047060434], 
processed observation next is [0.0, 0.6086956521739131, 0.5802469135802467, 0.66, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8438259833395517, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22888093890877886, 0.2288809389087787, 0.3318555859731604], 
reward next is 0.6681, 
noisyNet noise sample is [array([-0.825593], dtype=float32), 0.3607921]. 
=============================================
[2019-03-24 05:47:45,245] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.0288026e-32 1.8631222e-37 2.4172288e-30 2.5772898e-24], sum to 1.0000
[2019-03-24 05:47:45,252] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9059
[2019-03-24 05:47:45,254] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.6, 83.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5743109660575253, 6.9112, 6.9112, 121.9260426156618, 423281.7702724445, 423281.7702724445, 126187.7209321695], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7687200.0000, 
sim time next is 7687800.0000, 
raw observation next is [19.6, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5673136210011325, 6.911200000000001, 6.9112, 121.9260426156618, 417272.0730088511, 417272.0730088507, 125130.6853206493], 
processed observation next is [1.0, 1.0, 0.28148148148148155, 0.82, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.45914202625141554, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14902574036030397, 0.1490257403603038, 0.24063593330894095], 
reward next is 0.7594, 
noisyNet noise sample is [array([-0.0413125], dtype=float32), -0.86745846]. 
=============================================
[2019-03-24 05:47:49,400] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9999917e-01 9.3875880e-19 1.5392847e-18 4.3610113e-17 8.7995045e-07], sum to 1.0000
[2019-03-24 05:47:49,409] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8320
[2019-03-24 05:47:49,416] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1544832.217499693 W.
[2019-03-24 05:47:49,421] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.3, 49.0, 1.0, 2.0, 0.6607375856249159, 1.0, 2.0, 0.6607375856249159, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1544832.217499693, 1544832.217499693, 291399.9002845286], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7745400.0000, 
sim time next is 7746000.0000, 
raw observation next is [29.26666666666667, 49.33333333333333, 1.0, 2.0, 0.641338973224291, 1.0, 2.0, 0.641338973224291, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1502273.196537086, 1502273.196537087, 284446.5494359471], 
processed observation next is [1.0, 0.6521739130434783, 0.6395061728395063, 0.4933333333333333, 1.0, 1.0, 0.573022587171775, 1.0, 1.0, 0.573022587171775, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5365261416203879, 0.5365261416203883, 0.547012595069129], 
reward next is 0.4530, 
noisyNet noise sample is [array([0.8047245], dtype=float32), 0.046530288]. 
=============================================
[2019-03-24 05:47:49,440] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[43.09307 ]
 [43.601856]
 [43.560703]
 [42.81023 ]
 [43.35942 ]], R is [[43.61389923]
 [43.61737823]
 [43.56956482]
 [43.13386917]
 [42.70252991]].
[2019-03-24 05:47:52,503] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.0823249e-33 2.5141370e-35 7.3821420e-33 9.0992816e-21], sum to 1.0000
[2019-03-24 05:47:52,508] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7187
[2019-03-24 05:47:52,511] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.4, 48.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7349333029322266, 6.9112, 6.9112, 121.9260426156618, 542343.472204287, 542343.472204287, 141960.7087233702], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7804800.0000, 
sim time next is 7805400.0000, 
raw observation next is [25.58333333333334, 47.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6918313004119458, 6.911200000000001, 6.9112, 121.9260426156618, 510828.2224026649, 510828.2224026644, 137749.1973044003], 
processed observation next is [1.0, 0.34782608695652173, 0.5030864197530867, 0.475, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6147891255149323, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1824386508580946, 0.18243865085809444, 0.2649023025084621], 
reward next is 0.7351, 
noisyNet noise sample is [array([1.2252921], dtype=float32), -0.07689947]. 
=============================================
[2019-03-24 05:47:54,878] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.7369322e-22 9.3800698e-21 4.5249184e-19 5.2476471e-11], sum to 1.0000
[2019-03-24 05:47:54,886] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9739
[2019-03-24 05:47:54,891] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1273534.063735993 W.
[2019-03-24 05:47:54,896] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.8, 36.5, 1.0, 2.0, 0.527004551713584, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8543855812937359, 6.9112, 6.9112, 121.9260426156618, 1273534.063735993, 1273534.063735993, 264382.9521653072], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7828200.0000, 
sim time next is 7828800.0000, 
raw observation next is [30.86666666666667, 36.33333333333334, 1.0, 2.0, 0.3879006554237972, 1.0, 1.0, 0.3879006554237972, 1.0, 2.0, 0.6238149832635661, 6.911199999999999, 6.9112, 121.94756008, 1385915.219537216, 1385915.219537217, 291567.5546436482], 
processed observation next is [1.0, 0.6086956521739131, 0.6987654320987656, 0.36333333333333345, 1.0, 1.0, 0.2713103040759491, 1.0, 0.5, 0.2713103040759491, 1.0, 1.0, 0.5297687290794576, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.4949697212632914, 0.49496972126329175, 0.5607068358531696], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5464748], dtype=float32), 2.1786368]. 
=============================================
[2019-03-24 05:47:58,644] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:47:58,644] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:47:58,677] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run4
[2019-03-24 05:47:59,538] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.7080877e-36 0.0000000e+00 3.3226450e-35 7.1910839e-25], sum to 1.0000
[2019-03-24 05:47:59,545] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5690
[2019-03-24 05:47:59,550] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.13333333333333, 60.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7946971807920163, 6.9112, 6.9112, 121.9260426156618, 590934.9848711631, 590934.9848711631, 159323.3425193657], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7933200.0000, 
sim time next is 7933800.0000, 
raw observation next is [26.96666666666667, 60.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7921583329549946, 6.911200000000001, 6.9112, 121.9260426156618, 589316.7897664442, 589316.7897664438, 158854.0862842123], 
processed observation next is [1.0, 0.8260869565217391, 0.554320987654321, 0.605, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7401979161937433, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21047028205944437, 0.2104702820594442, 0.30548862746963906], 
reward next is 0.6945, 
noisyNet noise sample is [array([-0.1017177], dtype=float32), 0.0047208634]. 
=============================================
[2019-03-24 05:47:59,837] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:47:59,837] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:47:59,848] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run4
[2019-03-24 05:48:00,313] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:48:00,313] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:48:00,318] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run4
[2019-03-24 05:48:00,734] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:48:00,735] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:48:00,742] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run4
[2019-03-24 05:48:00,789] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:48:00,789] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:48:00,796] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run4
[2019-03-24 05:48:00,972] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:48:00,972] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:48:00,973] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run4
[2019-03-24 05:48:00,996] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:48:00,997] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:48:01,000] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run4
[2019-03-24 05:48:01,093] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:48:01,093] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:48:01,096] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run4
[2019-03-24 05:48:01,127] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:48:01,128] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:48:01,133] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run4
[2019-03-24 05:48:01,202] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:48:01,202] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:48:01,204] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run4
[2019-03-24 05:48:01,293] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:48:01,293] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:48:01,294] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run4
[2019-03-24 05:48:01,470] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:48:01,470] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:48:01,471] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run4
[2019-03-24 05:48:01,499] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:48:01,500] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:48:01,501] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run4
[2019-03-24 05:48:01,531] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:48:01,531] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:48:01,545] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run4
[2019-03-24 05:48:01,605] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:48:01,606] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:48:01,607] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run4
[2019-03-24 05:48:01,905] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 05:48:01,905] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:48:01,906] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run4
[2019-03-24 05:48:10,104] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.9460992e-26 1.9056147e-25 1.1715608e-22 9.8942147e-15], sum to 1.0000
[2019-03-24 05:48:10,111] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2621
[2019-03-24 05:48:10,119] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1621276.246874631 W.
[2019-03-24 05:48:10,124] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [37.34999999999999, 10.5, 1.0, 2.0, 0.4398395215373929, 1.0, 2.0, 0.4398395215373929, 1.0, 1.0, 0.7226752244305068, 6.911200000000001, 6.9112, 121.94756008, 1621276.246874631, 1621276.24687463, 313540.3095481102], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 142200.0000, 
sim time next is 142800.0000, 
raw observation next is [37.33333333333333, 10.0, 1.0, 2.0, 0.642944954785973, 1.0, 2.0, 0.642944954785973, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1596400.577507327, 1596400.577507328, 288161.4495433983], 
processed observation next is [1.0, 0.6521739130434783, 0.9382716049382714, 0.1, 1.0, 1.0, 0.5749344699833012, 1.0, 1.0, 0.5749344699833012, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5701430633954739, 0.5701430633954743, 0.5541566337373044], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.43337217], dtype=float32), -0.23032717]. 
=============================================
[2019-03-24 05:48:18,561] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 3.8430563e-37 5.7468675e-27], sum to 1.0000
[2019-03-24 05:48:18,569] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4682
[2019-03-24 05:48:18,573] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.93333333333333, 31.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.58742256049479, 6.9112, 6.9112, 121.9260426156618, 425608.3337529104, 425608.3337529104, 124168.225715422], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 315600.0000, 
sim time next is 316200.0000, 
raw observation next is [27.96666666666667, 31.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5878653158127148, 6.911200000000001, 6.9112, 121.9260426156618, 426119.9960390076, 426119.9960390072, 124278.1861283869], 
processed observation next is [0.0, 0.6521739130434783, 0.5913580246913581, 0.31, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4848316447658935, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15218571287107416, 0.152185712871074, 0.2389965117853594], 
reward next is 0.7610, 
noisyNet noise sample is [array([0.87997234], dtype=float32), -0.44754958]. 
=============================================
[2019-03-24 05:48:23,355] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 2.4836741e-33 7.0517407e-36 3.9755580e-30 1.4368773e-23], sum to 1.0000
[2019-03-24 05:48:23,362] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1411
[2019-03-24 05:48:23,374] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.11666666666667, 73.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6482384325727076, 6.9112, 6.9112, 121.9260426156618, 472470.4378310322, 472470.4378310322, 130603.4655957815], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 529800.0000, 
sim time next is 530400.0000, 
raw observation next is [20.03333333333333, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5991052712929346, 6.9112, 6.9112, 121.9260426156618, 436549.7898222018, 436549.7898222018, 126141.1098591964], 
processed observation next is [1.0, 0.13043478260869565, 0.2975308641975308, 0.74, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.49888158911616814, 0.0, 0.0, 0.8094621288201359, 0.15591063922221493, 0.15591063922221493, 0.24257905742153152], 
reward next is 0.7574, 
noisyNet noise sample is [array([-1.1825317], dtype=float32), 0.68127453]. 
=============================================
[2019-03-24 05:48:24,919] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 4.3714493e-36 0.0000000e+00 6.6785206e-35 2.6496736e-25], sum to 1.0000
[2019-03-24 05:48:24,927] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3155
[2019-03-24 05:48:24,933] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.6, 65.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5029912430207554, 6.9112, 6.9112, 121.9260426156618, 361996.4781312158, 361996.4781312158, 116326.7643531314], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 439200.0000, 
sim time next is 439800.0000, 
raw observation next is [20.45, 65.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8446434041949201, 6.911200000000001, 6.9112, 121.9260426156618, 607661.9530161567, 607661.9530161562, 147217.3523962665], 
processed observation next is [1.0, 0.08695652173913043, 0.31296296296296294, 0.6566666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8058042552436501, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2170221260771988, 0.21702212607719865, 0.2831102930697433], 
reward next is 0.7169, 
noisyNet noise sample is [array([-0.74222815], dtype=float32), 0.88506466]. 
=============================================
[2019-03-24 05:48:29,222] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-24 05:48:29,223] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:48:29,224] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:48:29,224] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:48:29,225] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:48:29,227] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:48:29,224] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:48:29,228] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:48:29,229] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:48:29,228] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:48:29,229] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:48:29,244] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run27
[2019-03-24 05:48:29,269] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run27
[2019-03-24 05:48:29,295] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run27
[2019-03-24 05:48:29,296] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run27
[2019-03-24 05:48:29,296] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run27
[2019-03-24 05:48:46,806] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00567989], dtype=float32), 0.013950583]
[2019-03-24 05:48:46,806] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.2, 61.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6386701564128313, 6.9112, 6.9112, 121.9260426156618, 475794.85420936, 475794.85420936, 135516.0638236728]
[2019-03-24 05:48:46,807] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:48:46,809] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 4.5539328e-30 6.2477948e-32 8.4097452e-29 1.4070037e-20], sampled 0.38375762839640537
[2019-03-24 05:48:48,033] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00567989], dtype=float32), 0.013950583]
[2019-03-24 05:48:48,035] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.55, 49.0, 1.0, 2.0, 0.7005637104630517, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260424718815, 868661.7064078611, 868661.7064078616, 179006.0524066564]
[2019-03-24 05:48:48,036] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:48:48,039] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 4.7213272e-22 1.2374957e-21 2.1283958e-20 5.5045662e-11], sampled 0.9371464069636519
[2019-03-24 05:48:48,041] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 868661.7064078611 W.
[2019-03-24 05:48:52,294] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00567989], dtype=float32), 0.013950583]
[2019-03-24 05:48:52,295] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [20.0, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7015467842592833, 6.911199999999999, 6.9112, 121.9260426156618, 521647.270700645, 521647.2707006454, 141080.7420780375]
[2019-03-24 05:48:52,296] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:48:52,301] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 7.7964316e-28 2.9295495e-29 1.6501403e-26 1.7354390e-18], sampled 0.1296151526579402
[2019-03-24 05:48:56,448] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00567989], dtype=float32), 0.013950583]
[2019-03-24 05:48:56,449] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.0, 77.33333333333334, 1.0, 2.0, 0.6521853424271984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 798050.5109198341, 798050.5109198341, 169532.2861849723]
[2019-03-24 05:48:56,451] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:48:56,454] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.00000000e+00 1.03367007e-22 1.09665689e-22 4.06828630e-21
 2.97898576e-12], sampled 0.07193727024414531
[2019-03-24 05:48:56,457] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 798050.5109198341 W.
[2019-03-24 05:49:13,191] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00567989], dtype=float32), 0.013950583]
[2019-03-24 05:49:13,193] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.33333333333334, 79.0, 1.0, 2.0, 0.8129720729693629, 1.0, 2.0, 0.8129720729693629, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260425171449, 1854346.664424422, 1854346.664424422, 349144.5444798119]
[2019-03-24 05:49:13,195] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:49:13,200] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.9999881e-01 3.1527586e-19 1.4575991e-17 2.3707415e-17 1.1637607e-06], sampled 0.5712500726064946
[2019-03-24 05:49:13,200] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1854346.664424422 W.
[2019-03-24 05:49:13,457] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00567989], dtype=float32), 0.013950583]
[2019-03-24 05:49:13,459] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [33.0, 56.0, 1.0, 2.0, 0.6961051785151627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 793360.6855227139, 793360.6855227135, 175412.9969979935]
[2019-03-24 05:49:13,460] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:49:13,463] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.5077563e-28 1.7848915e-29 6.0909164e-27 8.9419043e-18], sampled 0.6586267667412596
[2019-03-24 05:49:13,463] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 793360.6855227139 W.
[2019-03-24 05:49:19,961] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00567989], dtype=float32), 0.013950583]
[2019-03-24 05:49:19,964] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.43333333333333, 93.83333333333334, 1.0, 2.0, 0.78867476744267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 901778.0216165015, 901778.0216165015, 193756.5838056123]
[2019-03-24 05:49:19,966] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:49:19,968] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 3.4273944e-22 1.9043905e-21 1.8687259e-20 2.6306338e-10], sampled 0.04567475451228942
[2019-03-24 05:49:19,970] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 901778.0216165015 W.
[2019-03-24 05:49:23,767] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00567989], dtype=float32), 0.013950583]
[2019-03-24 05:49:23,769] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.0, 71.0, 1.0, 2.0, 0.9796068072807245, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1831961.304609058, 1831961.304609058, 374720.9987568474]
[2019-03-24 05:49:23,770] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:49:23,773] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.4612835e-21 2.1456291e-20 9.9991021e-20 4.6317701e-09], sampled 0.47831219841897477
[2019-03-24 05:49:23,774] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1831961.304609058 W.
[2019-03-24 05:49:29,490] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00567989], dtype=float32), 0.013950583]
[2019-03-24 05:49:29,494] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.13833689333333, 100.1518757433333, 1.0, 2.0, 0.7231217346297609, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.926042575227, 1539192.364709605, 1539192.364709605, 321468.7072115666]
[2019-03-24 05:49:29,496] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:49:29,499] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [9.99723494e-01 8.16015461e-17 1.30341345e-14 5.85630575e-15
 2.76542851e-04], sampled 0.5559407005994713
[2019-03-24 05:49:29,500] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1539192.364709605 W.
[2019-03-24 05:49:43,237] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00567989], dtype=float32), 0.013950583]
[2019-03-24 05:49:43,239] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.06666666666667, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8470569684208281, 6.911200000000001, 6.9112, 121.9260426156618, 625233.878890609, 625233.8788906086, 167709.5716194115]
[2019-03-24 05:49:43,240] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:49:43,242] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.000000e+00 3.942952e-29 7.987612e-31 7.700429e-28 9.955865e-20], sampled 0.8592450414728955
[2019-03-24 05:49:54,443] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00567989], dtype=float32), 0.013950583]
[2019-03-24 05:49:54,444] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.7, 80.0, 1.0, 2.0, 0.7319156655911994, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1549229.949099645, 1549229.949099646, 323107.8177460686]
[2019-03-24 05:49:54,445] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:49:54,448] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.000000e+00 6.960780e-24 7.077818e-24 3.489665e-22 6.184153e-13], sampled 0.23965432073911452
[2019-03-24 05:49:54,450] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1549229.949099645 W.
[2019-03-24 05:50:13,494] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8363.4371 2339475986.9735 616.0000
[2019-03-24 05:50:13,504] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8555.5555 2258346494.1254 538.0000
[2019-03-24 05:50:13,640] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8634.8420 2219345938.5085 543.0000
[2019-03-24 05:50:13,677] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7836.7758 2529796723.6232 832.0000
[2019-03-24 05:50:13,727] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.2172 2292896277.6031 694.0000
[2019-03-24 05:50:14,743] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 650000, evaluation results [650000.0, 7836.775828027382, 2529796723.6231747, 832.0, 8555.555466585063, 2258346494.125419, 538.0, 8634.842002356323, 2219345938.50851, 543.0, 8363.437110714249, 2339475986.973477, 616.0, 8404.21723949431, 2292896277.603096, 694.0]
[2019-03-24 05:50:15,321] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 3.0041277e-22 7.2598285e-24 5.4604381e-22 9.1809894e-14], sum to 1.0000
[2019-03-24 05:50:15,328] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1119
[2019-03-24 05:50:15,335] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1292384.393936313 W.
[2019-03-24 05:50:15,339] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.7, 48.0, 1.0, 1.0, 0.5241348615440403, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8643377646006986, 6.9112, 6.9112, 121.925091119301, 1292384.393936313, 1292384.393936313, 261823.1486103822], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 549000.0000, 
sim time next is 549600.0000, 
raw observation next is [28.0, 43.66666666666667, 1.0, 2.0, 0.5183638841117213, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8490239775053384, 6.911200000000001, 6.9112, 121.9260423255114, 1269266.162952804, 1269266.162952804, 260370.1236882733], 
processed observation next is [1.0, 0.34782608695652173, 0.5925925925925926, 0.4366666666666667, 1.0, 1.0, 0.42662367156157294, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8112799718816729, 8.881784197001253e-17, 0.0, 0.809462126893839, 0.45330934391171573, 0.45330934391171573, 0.5007117763236025], 
reward next is 0.4993, 
noisyNet noise sample is [array([0.49026057], dtype=float32), 0.071642265]. 
=============================================
[2019-03-24 05:50:15,804] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.6785808e-29 6.2213009e-32 2.1387399e-28 1.8387446e-19], sum to 1.0000
[2019-03-24 05:50:15,814] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2653
[2019-03-24 05:50:15,820] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.6, 61.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8292898542635115, 6.911200000000001, 6.9112, 121.9260426156618, 610325.6266807457, 610325.6266807453, 151216.7755254691], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 546600.0000, 
sim time next is 547200.0000, 
raw observation next is [22.8, 61.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7676942028566985, 6.911200000000001, 6.9112, 121.9260426156618, 565374.5075995541, 565374.5075995537, 144789.6173009247], 
processed observation next is [1.0, 0.34782608695652173, 0.4, 0.61, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7096177535708731, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20191946699984076, 0.2019194669998406, 0.2784415717325475], 
reward next is 0.7216, 
noisyNet noise sample is [array([0.27135724], dtype=float32), -1.1558683]. 
=============================================
[2019-03-24 05:50:25,357] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.99998808e-01 1.13739435e-17 3.06036117e-15 6.81388719e-16
 1.21281039e-06], sum to 1.0000
[2019-03-24 05:50:25,367] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9464
[2019-03-24 05:50:25,374] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1365470.367178497 W.
[2019-03-24 05:50:25,377] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.2, 50.16666666666667, 1.0, 2.0, 0.5637075323141634, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9153324174534564, 6.911199999999998, 6.9112, 121.9260426156247, 1365470.367178497, 1365470.367178498, 277613.0512039237], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 731400.0000, 
sim time next is 732000.0000, 
raw observation next is [27.5, 48.33333333333334, 1.0, 2.0, 0.5452864598314864, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8868591403163251, 6.911199999999999, 6.9112, 121.9260426156618, 1323797.07441072, 1323797.07441072, 270673.4026406481], 
processed observation next is [1.0, 0.4782608695652174, 0.5740740740740741, 0.48333333333333345, 1.0, 1.0, 0.4586743569422457, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8585739253954063, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4727846694324, 0.4727846694324, 0.5205257743089388], 
reward next is 0.4795, 
noisyNet noise sample is [array([0.26180452], dtype=float32), -0.8734492]. 
=============================================
[2019-03-24 05:50:25,396] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[42.281948]
 [42.09698 ]
 [42.915432]
 [42.173347]
 [42.201366]], R is [[42.69668198]
 [42.26971436]
 [41.8470192 ]
 [41.88587189]
 [41.46701431]].
[2019-03-24 05:50:27,770] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 3.2011223e-38 0.0000000e+00 4.0438860e-36 3.1934425e-28], sum to 1.0000
[2019-03-24 05:50:27,780] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0988
[2019-03-24 05:50:27,785] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.36666666666667, 40.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5421998117811699, 6.911200000000001, 6.9112, 121.9260426156618, 396646.2641832421, 396646.2641832416, 121937.0925910852], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 775200.0000, 
sim time next is 775800.0000, 
raw observation next is [26.2, 40.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5392426486733524, 6.911200000000001, 6.9112, 121.9260426156618, 394251.8835190033, 394251.8835190028, 121586.228879321], 
processed observation next is [1.0, 1.0, 0.5259259259259259, 0.405, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4240533108416904, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14080424411392975, 0.14080424411392958, 0.23381967092177117], 
reward next is 0.7662, 
noisyNet noise sample is [array([-0.52642435], dtype=float32), -2.6994398]. 
=============================================
[2019-03-24 05:50:31,275] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.5607107e-29], sum to 1.0000
[2019-03-24 05:50:31,284] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2486
[2019-03-24 05:50:31,288] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.13333333333333, 38.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6793223872076981, 6.9112, 6.9112, 121.9260426156618, 507559.7391736138, 507559.7391736138, 141902.52214148], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 844800.0000, 
sim time next is 845400.0000, 
raw observation next is [29.91666666666666, 38.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.676125116426999, 6.911199999999999, 6.9112, 121.9260426156618, 505122.4370312022, 505122.4370312027, 141398.5789337991], 
processed observation next is [0.0, 0.782608695652174, 0.66358024691358, 0.385, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5951563955337488, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1804008703682865, 0.1804008703682867, 0.2719203441034598], 
reward next is 0.7281, 
noisyNet noise sample is [array([2.3720748], dtype=float32), -0.15763594]. 
=============================================
[2019-03-24 05:50:32,552] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 9.706394e-38 6.828831e-31], sum to 1.0000
[2019-03-24 05:50:32,558] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8818
[2019-03-24 05:50:32,561] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.7, 39.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6729095348434072, 6.911199999999999, 6.9112, 121.9260426156618, 502659.8607122272, 502659.8607122276, 140889.5299953958], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 846000.0000, 
sim time next is 846600.0000, 
raw observation next is [29.48333333333333, 39.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6687257266253198, 6.911199999999999, 6.9112, 121.9260426156618, 499434.8917792091, 499434.8917792096, 140217.2772196679], 
processed observation next is [0.0, 0.8260869565217391, 0.6475308641975308, 0.3933333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5859071582816497, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17836960420686038, 0.17836960420686057, 0.2696486100378229], 
reward next is 0.7304, 
noisyNet noise sample is [array([-1.427138], dtype=float32), -0.27040645]. 
=============================================
[2019-03-24 05:50:38,764] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.5784227e-20 1.9261573e-19 2.6482164e-19 1.4189688e-10], sum to 1.0000
[2019-03-24 05:50:38,777] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0067
[2019-03-24 05:50:38,782] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1222596.129653075 W.
[2019-03-24 05:50:38,789] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.33333333333334, 56.83333333333333, 1.0, 2.0, 0.9048006922082479, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.091602098145234, 6.9112, 121.925370030727, 1222596.129653075, 1130214.640856231, 222599.7858631406], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 987000.0000, 
sim time next is 987600.0000, 
raw observation next is [24.46666666666667, 56.66666666666667, 1.0, 2.0, 0.4758272134447172, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7888284077355125, 6.911200000000001, 6.9112, 121.9259339807687, 1178743.768720821, 1178743.768720821, 244726.0802225368], 
processed observation next is [1.0, 0.43478260869565216, 0.46172839506172847, 0.5666666666666668, 1.0, 1.0, 0.37598477791037765, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.7360355096693907, 8.881784197001253e-17, 0.0, 0.8094614075974181, 0.4209799174002932, 0.4209799174002932, 0.4706270773510323], 
reward next is 0.5294, 
noisyNet noise sample is [array([0.87793076], dtype=float32), 0.9777576]. 
=============================================
[2019-03-24 05:50:38,902] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 3.9709290e-33 1.1991847e-35 1.0397324e-30 9.7482932e-22], sum to 1.0000
[2019-03-24 05:50:38,908] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4598
[2019-03-24 05:50:38,912] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.86666666666667, 58.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8018571383553161, 6.9112, 6.9112, 121.9260426156618, 587209.8712836981, 587209.8712836981, 146855.8968322484], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 980400.0000, 
sim time next is 981000.0000, 
raw observation next is [23.0, 58.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9082638147245633, 6.9112, 6.9112, 121.9260426156618, 666343.8320234707, 666343.8320234707, 158862.4821737531], 
processed observation next is [1.0, 0.34782608695652173, 0.4074074074074074, 0.58, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.885329768405704, 0.0, 0.0, 0.8094621288201359, 0.23797994000838238, 0.23797994000838238, 0.30550477341106363], 
reward next is 0.6945, 
noisyNet noise sample is [array([2.099604], dtype=float32), -2.19153]. 
=============================================
[2019-03-24 05:50:38,928] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[61.75785 ]
 [62.51606 ]
 [62.384247]
 [62.31857 ]
 [62.3897  ]], R is [[61.17902374]
 [61.28482056]
 [61.4289093 ]
 [61.56932449]
 [61.70530701]].
[2019-03-24 05:50:47,020] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 3.2058924e-28 1.1778191e-25 1.8142633e-24 2.5893789e-11], sum to 1.0000
[2019-03-24 05:50:47,030] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3969
[2019-03-24 05:50:47,034] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.78333333333333, 76.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5520861261734343, 6.9112, 6.9112, 121.9260426156618, 395241.6124165848, 395241.6124165848, 119506.5466461419], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1138200.0000, 
sim time next is 1138800.0000, 
raw observation next is [18.76666666666667, 76.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5225631857937805, 6.9112, 6.9112, 121.9260426156618, 374140.9249155162, 374140.9249155162, 117187.0566777449], 
processed observation next is [1.0, 0.17391304347826086, 0.2506172839506174, 0.7633333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.40320398224222553, 0.0, 0.0, 0.8094621288201359, 0.13362175889839864, 0.13362175889839864, 0.22535972438027865], 
reward next is 0.7746, 
noisyNet noise sample is [array([-0.05797461], dtype=float32), 0.49175933]. 
=============================================
[2019-03-24 05:50:50,624] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9993670e-01 3.5539922e-23 1.9226082e-18 1.0836652e-18 6.3259955e-05], sum to 1.0000
[2019-03-24 05:50:50,630] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8562
[2019-03-24 05:50:50,635] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 818109.8474853112 W.
[2019-03-24 05:50:50,642] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.56666666666667, 70.5, 1.0, 2.0, 0.3281265375077173, 1.0, 2.0, 0.3281265375077173, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 818109.8474853112, 818109.8474853117, 189934.095308931], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1180200.0000, 
sim time next is 1180800.0000, 
raw observation next is [21.5, 71.0, 1.0, 2.0, 0.3220160057046909, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5404596945776791, 6.911199999999999, 6.9112, 121.9260426156618, 805021.4083442306, 805021.4083442311, 197105.788716613], 
processed observation next is [1.0, 0.6956521739130435, 0.35185185185185186, 0.71, 1.0, 1.0, 0.19287619726748917, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.4255746182220988, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2875076458372252, 0.2875076458372254, 0.3790495936857942], 
reward next is 0.6210, 
noisyNet noise sample is [array([-1.3571221], dtype=float32), 0.016320419]. 
=============================================
[2019-03-24 05:50:55,095] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 1.8246770e-21 3.0446386e-19 6.0200483e-19 6.4028796e-09], sum to 1.0000
[2019-03-24 05:50:55,101] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4784
[2019-03-24 05:50:55,109] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1180241.205616513 W.
[2019-03-24 05:50:55,114] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.3, 55.0, 1.0, 2.0, 0.9142006670061469, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.030889132473873, 6.9112, 121.9254261610457, 1180241.205616513, 1118949.981984877, 224146.1416973847], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1267200.0000, 
sim time next is 1267800.0000, 
raw observation next is [26.33333333333334, 54.66666666666667, 1.0, 2.0, 0.2730280947827969, 1.0, 1.0, 0.2730280947827969, 1.0, 1.0, 0.4415990808700702, 6.9112, 6.9112, 121.94756008, 985838.0007923121, 985838.0007923121, 245256.9409790295], 
processed observation next is [1.0, 0.6956521739130435, 0.5308641975308644, 0.5466666666666667, 1.0, 1.0, 0.1345572556938058, 1.0, 0.5, 0.1345572556938058, 1.0, 0.5, 0.3019988510875877, 0.0, 0.0, 0.8096049824067558, 0.35208500028296863, 0.35208500028296863, 0.47164796342121057], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1189167], dtype=float32), 1.2547406]. 
=============================================
[2019-03-24 05:50:58,285] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.00000000e+00 1.56415542e-22 1.91350019e-21 1.32302385e-20
 1.00070802e-11], sum to 1.0000
[2019-03-24 05:50:58,289] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9776
[2019-03-24 05:50:58,296] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1238265.754907364 W.
[2019-03-24 05:50:58,300] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.85, 31.0, 1.0, 2.0, 0.3395440831369307, 1.0, 1.0, 0.3395440831369307, 1.0, 2.0, 0.5528633115734903, 6.9112, 6.9112, 121.94756008, 1238265.754907364, 1238265.754907364, 270603.9124605825], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1351800.0000, 
sim time next is 1352400.0000, 
raw observation next is [30.86666666666667, 30.66666666666667, 1.0, 2.0, 0.9417864874879235, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.295677908908262, 6.9112, 121.9244140949184, 1364965.898162535, 1168081.474303002, 231057.6869942918], 
processed observation next is [1.0, 0.6521739130434783, 0.6987654320987656, 0.3066666666666667, 1.0, 1.0, 0.9306981993903851, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.03844779089082619, 0.0, 0.809451317135942, 0.4874878207723339, 0.417171955108215, 0.4443417057582535], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.0346735], dtype=float32), -0.10277369]. 
=============================================
[2019-03-24 05:51:01,596] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.4675132e-32], sum to 1.0000
[2019-03-24 05:51:01,601] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7024
[2019-03-24 05:51:01,605] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.86666666666667, 64.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5144348525715902, 6.911199999999999, 6.9112, 121.9260426156618, 371734.8119741779, 371734.8119741784, 117763.3953683943], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1393800.0000, 
sim time next is 1394400.0000, 
raw observation next is [20.83333333333333, 64.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5098329279506338, 6.9112, 6.9112, 121.9260426156618, 367865.5279997481, 367865.5279997481, 117199.1988547912], 
processed observation next is [0.0, 0.13043478260869565, 0.32716049382716034, 0.6433333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3872911599382923, 0.0, 0.0, 0.8094621288201359, 0.13138054571419577, 0.13138054571419577, 0.2253830747207523], 
reward next is 0.7746, 
noisyNet noise sample is [array([-1.5754753], dtype=float32), 0.039244138]. 
=============================================
[2019-03-24 05:51:03,784] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-24 05:51:03,786] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:51:03,786] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:51:03,787] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:51:03,788] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:51:03,786] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:51:03,791] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:51:03,791] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:51:03,788] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:51:03,796] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:51:03,797] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:51:03,810] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run28
[2019-03-24 05:51:03,810] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run28
[2019-03-24 05:51:03,863] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run28
[2019-03-24 05:51:03,864] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run28
[2019-03-24 05:51:03,917] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run28
[2019-03-24 05:51:18,399] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00546541], dtype=float32), 0.0143315885]
[2019-03-24 05:51:18,400] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [17.0882956, 94.69834935666668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.521971025955564, 6.911199999999999, 6.9112, 121.9260426156618, 379111.9854653195, 379111.98546532, 119101.2905134239]
[2019-03-24 05:51:18,401] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:51:18,403] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.2607243e-36 0.0000000e+00 4.2349687e-35 3.7873932e-27], sampled 0.8209603812960213
[2019-03-24 05:51:19,118] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00546541], dtype=float32), 0.0143315885]
[2019-03-24 05:51:19,120] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.590751395, 67.04986407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8658732185543461, 6.9112, 6.9112, 121.9260426156618, 633463.8839894286, 633463.8839894286, 171507.1290220348]
[2019-03-24 05:51:19,120] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:51:19,124] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.1154581e-36 5.2575833e-38 8.9289087e-35 7.5197038e-26], sampled 0.4286227303097524
[2019-03-24 05:51:23,648] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00546541], dtype=float32), 0.0143315885]
[2019-03-24 05:51:23,650] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.66666666666667, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7030540495559656, 6.9112, 6.9112, 121.9260426156618, 525374.1792269255, 525374.1792269255, 145394.0601472082]
[2019-03-24 05:51:23,651] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:51:23,653] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 4.8872074e-36 7.4112142e-38 1.8121306e-34 2.0647322e-26], sampled 0.6846634422930661
[2019-03-24 05:51:47,929] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00546541], dtype=float32), 0.0143315885]
[2019-03-24 05:51:47,930] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.66666666666667, 75.5, 1.0, 2.0, 0.863572515379302, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9868789384484954, 6.9112, 6.9112, 121.9260426156618, 1711445.393013461, 1711445.393013461, 347472.2290230639]
[2019-03-24 05:51:47,932] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:51:47,935] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 3.4525279e-27 2.7164306e-27 2.6080668e-25 2.5245395e-17], sampled 0.6143698552367576
[2019-03-24 05:51:47,936] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1711445.393013461 W.
[2019-03-24 05:52:10,023] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00546541], dtype=float32), 0.0143315885]
[2019-03-24 05:52:10,026] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.45, 83.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6722791775255466, 6.9112, 6.9112, 121.9260426156618, 502031.6025234369, 502031.6025234369, 140472.1167266478]
[2019-03-24 05:52:10,027] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:52:10,030] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.0224155e-36 1.4408787e-38 4.1584467e-35 6.5477997e-27], sampled 0.581181900354437
[2019-03-24 05:52:34,376] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00546541], dtype=float32), 0.0143315885]
[2019-03-24 05:52:34,377] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.16666666666667, 54.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8404301560936183, 6.9112, 6.9112, 121.9260426156618, 620392.4114560533, 620392.4114560533, 166857.8034389305]
[2019-03-24 05:52:34,381] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:52:34,383] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 7.4335009e-37 0.0000000e+00 2.6447019e-35 3.0021612e-27], sampled 0.23835279254875563
[2019-03-24 05:52:47,807] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 05:52:48,120] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8632.3425 2219214418.8321 543.0000
[2019-03-24 05:52:48,380] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8402.8383 2293061391.6807 697.0000
[2019-03-24 05:52:48,422] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8558.6933 2258331735.7090 536.0000
[2019-03-24 05:52:48,478] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8362.6197 2339528955.2376 616.0000
[2019-03-24 05:52:49,494] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 675000, evaluation results [675000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8558.693290662724, 2258331735.7089543, 536.0, 8632.342517907291, 2219214418.832096, 543.0, 8362.619748969548, 2339528955.237554, 616.0, 8402.83826393434, 2293061391.6806684, 697.0]
[2019-03-24 05:52:51,170] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 6.330330e-37 6.318438e-29], sum to 1.0000
[2019-03-24 05:52:51,175] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9273
[2019-03-24 05:52:51,179] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.63333333333333, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5882129381065484, 6.911200000000001, 6.9112, 121.9260426156618, 434153.1812973912, 434153.1812973908, 127770.8038847988], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1484400.0000, 
sim time next is 1485000.0000, 
raw observation next is [21.55, 71.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5909097422495421, 6.9112, 6.9112, 121.9260426156618, 436438.9862401783, 436438.9862401783, 128179.6624361169], 
processed observation next is [0.0, 0.17391304347826086, 0.35370370370370374, 0.71, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.48863717781192756, 0.0, 0.0, 0.8094621288201359, 0.1558710665143494, 0.1558710665143494, 0.24649935083868635], 
reward next is 0.7535, 
noisyNet noise sample is [array([-1.0987738], dtype=float32), -1.5009266]. 
=============================================
[2019-03-24 05:52:51,199] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[66.21285 ]
 [66.363396]
 [66.46642 ]
 [66.57202 ]
 [66.761284]], R is [[66.1849823 ]
 [66.27742004]
 [66.36977386]
 [66.46185303]
 [66.55322266]].
[2019-03-24 05:52:54,303] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 2.6057836e-37 0.0000000e+00 1.5882479e-37 2.0871545e-30], sum to 1.0000
[2019-03-24 05:52:54,307] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0321
[2019-03-24 05:52:54,312] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [33.53333333333334, 36.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8030067889156888, 6.911200000000001, 6.9112, 121.9260426156618, 594454.5911940134, 594454.5911940129, 161549.0452945043], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1527000.0000, 
sim time next is 1527600.0000, 
raw observation next is [33.36666666666667, 37.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8136429970947743, 6.911199999999999, 6.9112, 121.9260426156618, 601149.6201116801, 601149.6201116806, 163300.0244894749], 
processed observation next is [0.0, 0.6956521739130435, 0.7913580246913581, 0.3766666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7670537463684679, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21469629289702863, 0.2146962928970288, 0.31403850863360555], 
reward next is 0.6860, 
noisyNet noise sample is [array([-0.0446875], dtype=float32), 1.0963538]. 
=============================================
[2019-03-24 05:52:55,172] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 4.6563810e-30 3.1724460e-30 1.7947660e-27 7.5741305e-22], sum to 1.0000
[2019-03-24 05:52:55,180] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7468
[2019-03-24 05:52:55,187] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.2, 72.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6458415206321109, 6.9112, 6.9112, 121.9260426156618, 480692.9358286054, 480692.9358286054, 135818.0410364293], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1559400.0000, 
sim time next is 1560000.0000, 
raw observation next is [22.1, 73.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6461714638915909, 6.9112, 6.9112, 121.9260426156618, 480931.1353859844, 480931.1353859844, 135844.4231889868], 
processed observation next is [1.0, 0.043478260869565216, 0.3740740740740741, 0.7333333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5577143298644885, 0.0, 0.0, 0.8094621288201359, 0.1717611197807087, 0.1717611197807087, 0.26123927536343616], 
reward next is 0.7388, 
noisyNet noise sample is [array([-0.47561523], dtype=float32), -0.60812837]. 
=============================================
[2019-03-24 05:52:55,200] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[53.575966]
 [53.57616 ]
 [53.7323  ]
 [53.828255]
 [53.819515]], R is [[53.54154587]
 [53.74494171]
 [53.94630432]
 [54.14551544]
 [54.34253311]].
[2019-03-24 05:52:59,134] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 9.54577e-33], sum to 1.0000
[2019-03-24 05:52:59,147] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2094
[2019-03-24 05:52:59,151] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.85, 58.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.553526750036907, 6.9112, 6.9112, 121.9260426156618, 405825.7030934722, 405825.7030934722, 123300.5108967356], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1639800.0000, 
sim time next is 1640400.0000, 
raw observation next is [22.76666666666667, 59.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5532643888427426, 6.911200000000001, 6.9112, 121.9260426156618, 405642.7657352916, 405642.7657352912, 123282.3173513995], 
processed observation next is [1.0, 1.0, 0.3987654320987655, 0.59, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.44158048605342826, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14487241633403272, 0.14487241633403256, 0.23708137952192213], 
reward next is 0.7629, 
noisyNet noise sample is [array([-1.2863029], dtype=float32), -1.4158072]. 
=============================================
[2019-03-24 05:53:01,572] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 2.4151347e-24 2.0981132e-24 1.1358796e-22 2.2281120e-16], sum to 1.0000
[2019-03-24 05:53:01,579] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6483
[2019-03-24 05:53:01,588] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1122056.793223081 W.
[2019-03-24 05:53:01,594] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.3, 69.0, 1.0, 2.0, 0.4586388636689278, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7506874355762401, 6.911199999999999, 6.9112, 121.9260426156618, 1122056.793223081, 1122056.793223082, 240057.573639046], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1694400.0000, 
sim time next is 1695000.0000, 
raw observation next is [23.35, 69.0, 1.0, 2.0, 0.9140311915048717, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.081332606899127, 6.9112, 121.9252952822584, 1215432.092835277, 1128309.525835348, 224399.6606432994], 
processed observation next is [1.0, 0.6086956521739131, 0.42037037037037045, 0.69, 1.0, 1.0, 0.8976561803629425, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.017013260689912713, 0.0, 0.8094571673035094, 0.43408289029831326, 0.4029676877983386, 0.43153780892942195], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.54721063], dtype=float32), -0.72253937]. 
=============================================
[2019-03-24 05:53:01,605] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[48.059315]
 [47.728592]
 [47.526154]
 [47.982204]
 [47.809486]], R is [[47.10187531]
 [46.63085556]
 [46.74348068]
 [46.27604675]
 [45.81328583]].
[2019-03-24 05:53:02,500] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 7.2668280e-27 7.0472858e-26 1.5107236e-25 3.8976465e-18], sum to 1.0000
[2019-03-24 05:53:02,506] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6439
[2019-03-24 05:53:02,514] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 994759.3524385515 W.
[2019-03-24 05:53:02,521] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.65, 68.83333333333333, 1.0, 2.0, 0.4086721901137466, 0.0, 1.0, 0.0, 1.0, 2.0, 0.666118806100439, 6.911199999999999, 6.9112, 121.9260426156618, 994759.3524385515, 994759.352438552, 224450.3376335633], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1699800.0000, 
sim time next is 1700400.0000, 
raw observation next is [23.7, 68.66666666666667, 1.0, 2.0, 0.4221037907319991, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6890765192233693, 6.911199999999999, 6.9112, 121.9260426156618, 1029446.824046657, 1029446.824046658, 228514.955510625], 
processed observation next is [1.0, 0.6956521739130435, 0.4333333333333333, 0.6866666666666668, 1.0, 1.0, 0.3120283222999989, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6113456490292116, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3676595800166632, 0.36765958001666355, 0.4394518375204327], 
reward next is 0.5605, 
noisyNet noise sample is [array([0.6644345], dtype=float32), 0.36909157]. 
=============================================
[2019-03-24 05:53:03,444] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.2624342e-36 4.1013237e-27], sum to 1.0000
[2019-03-24 05:53:03,448] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1435
[2019-03-24 05:53:03,456] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.85, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6652099873995092, 6.9112, 6.9112, 121.9260426156618, 496483.3991097205, 496483.3991097205, 139277.9294462682], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1722600.0000, 
sim time next is 1723200.0000, 
raw observation next is [21.76666666666667, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6630888161894452, 6.911200000000001, 6.9112, 121.9260426156618, 494748.7775904469, 494748.7775904465, 138843.2964147798], 
processed observation next is [1.0, 0.9565217391304348, 0.3617283950617285, 0.79, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5788610202368064, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17669599199658817, 0.17669599199658803, 0.2670063392591919], 
reward next is 0.7330, 
noisyNet noise sample is [array([0.23683701], dtype=float32), 0.49790317]. 
=============================================
[2019-03-24 05:53:03,635] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 8.9034200e-38 0.0000000e+00 1.3957927e-36 7.2407339e-27], sum to 1.0000
[2019-03-24 05:53:03,644] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3827
[2019-03-24 05:53:03,649] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.61666666666667, 84.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6779184749617885, 6.911199999999999, 6.9112, 121.9260426156618, 504681.9895320423, 504681.9895320428, 139160.7549406184], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1739400.0000, 
sim time next is 1740000.0000, 
raw observation next is [20.53333333333333, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6327374370074274, 6.9112, 6.9112, 121.9260426156618, 470976.8006922391, 470976.8006922391, 134552.9513218222], 
processed observation next is [1.0, 0.13043478260869565, 0.3160493827160493, 0.85, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5409217962592842, 0.0, 0.0, 0.8094621288201359, 0.16820600024722823, 0.16820600024722823, 0.25875567561888885], 
reward next is 0.7412, 
noisyNet noise sample is [array([0.8152681], dtype=float32), -0.9505738]. 
=============================================
[2019-03-24 05:53:03,679] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[69.808945]
 [69.96114 ]
 [70.05202 ]
 [70.14906 ]
 [70.165016]], R is [[69.96245575]
 [69.99521637]
 [70.02961731]
 [70.06485748]
 [70.09738922]].
[2019-03-24 05:53:05,272] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.0275072e-34 0.0000000e+00 2.1618317e-34 2.8968459e-28], sum to 1.0000
[2019-03-24 05:53:05,282] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0003
[2019-03-24 05:53:05,286] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.38333333333333, 80.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6338686310606348, 6.911199999999999, 6.9112, 121.9260426156618, 472385.686931045, 472385.6869310454, 135210.0964830338], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1728600.0000, 
sim time next is 1729200.0000, 
raw observation next is [21.36666666666667, 80.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6344186441512687, 6.9112, 6.9112, 121.9260426156618, 472808.4343856871, 472808.4343856871, 135278.2915844449], 
processed observation next is [1.0, 0.0, 0.3469135802469137, 0.8033333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5430233051890858, 0.0, 0.0, 0.8094621288201359, 0.1688601551377454, 0.1688601551377454, 0.26015056073931714], 
reward next is 0.7398, 
noisyNet noise sample is [array([1.742182], dtype=float32), -1.355425]. 
=============================================
[2019-03-24 05:53:05,577] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 5.2789641e-24 4.6719123e-23 6.5664479e-23 2.4624407e-16], sum to 1.0000
[2019-03-24 05:53:05,583] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0614
[2019-03-24 05:53:05,588] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1128321.748440058 W.
[2019-03-24 05:53:05,593] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.5, 71.66666666666667, 1.0, 2.0, 0.4643864436288546, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7558180099574714, 6.911199999999999, 6.9112, 121.9260426156618, 1128321.748440058, 1128321.748440058, 242442.5516028266], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1761000.0000, 
sim time next is 1761600.0000, 
raw observation next is [23.6, 71.33333333333334, 1.0, 2.0, 0.4039496580006041, 1.0, 1.0, 0.4039496580006041, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 976937.599793057, 976937.5997930574, 209593.5780265008], 
processed observation next is [1.0, 0.391304347826087, 0.4296296296296297, 0.7133333333333334, 1.0, 1.0, 0.2904162595245287, 1.0, 0.5, 0.2904162595245287, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3489062856403775, 0.3489062856403777, 0.4030645731278861], 
reward next is 0.5969, 
noisyNet noise sample is [array([-1.0319767], dtype=float32), 0.87187237]. 
=============================================
[2019-03-24 05:53:07,042] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.3045391e-23 2.6979504e-23 1.7245614e-20 9.0414181e-16], sum to 1.0000
[2019-03-24 05:53:07,052] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3459
[2019-03-24 05:53:07,057] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1468408.035711749 W.
[2019-03-24 05:53:07,063] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.5, 62.0, 1.0, 2.0, 0.6338229024504671, 1.0, 1.0, 0.6338229024504671, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1468408.035711749, 1468408.035711749, 280997.5614905742], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1783800.0000, 
sim time next is 1784400.0000, 
raw observation next is [27.33333333333334, 63.33333333333334, 1.0, 2.0, 0.6474585253247596, 0.0, 1.0, 0.0, 1.0, 1.0, 0.980586334975171, 6.911199999999999, 6.9112, 121.9260426156618, 1467569.881557333, 1467569.881557333, 304699.4302234197], 
processed observation next is [1.0, 0.6521739130434783, 0.5679012345679014, 0.6333333333333334, 1.0, 1.0, 0.5803077682437614, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9757329187189636, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5241321005561904, 0.5241321005561904, 0.5859604427373455], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.7260392], dtype=float32), 1.808192]. 
=============================================
[2019-03-24 05:53:22,001] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.2983730e-38 0.0000000e+00 3.0812886e-36 2.4114185e-29], sum to 1.0000
[2019-03-24 05:53:22,011] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5885
[2019-03-24 05:53:22,019] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.2, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7020634323649638, 6.911199999999999, 6.9112, 121.9260426156618, 524602.999373148, 524602.9993731484, 145492.6329685983], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2088000.0000, 
sim time next is 2088600.0000, 
raw observation next is [21.08333333333334, 91.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7002556098355417, 6.911200000000001, 6.9112, 121.9260426156618, 523264.6111227977, 523264.6111227972, 145219.7537101271], 
processed observation next is [0.0, 0.17391304347826086, 0.33641975308641997, 0.9166666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6253195122944272, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18688021825814205, 0.18688021825814186, 0.27926875713485977], 
reward next is 0.7207, 
noisyNet noise sample is [array([0.91155905], dtype=float32), -1.6194727]. 
=============================================
[2019-03-24 05:53:26,672] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.1237788e-27 7.9479160e-31 7.4904938e-28 6.7874350e-23], sum to 1.0000
[2019-03-24 05:53:26,680] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2481
[2019-03-24 05:53:26,683] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.912595444990587, 6.9112, 6.9112, 121.9260426156618, 665898.4107619887, 665898.4107619887, 178007.0347148896], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2161800.0000, 
sim time next is 2162400.0000, 
raw observation next is [24.93333333333333, 84.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9141599814711769, 6.9112, 6.9112, 121.9260426156618, 666742.0555607487, 666742.0555607487, 178270.8694322786], 
processed observation next is [1.0, 0.0, 0.47901234567901224, 0.8466666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8926999768389712, 0.0, 0.0, 0.8094621288201359, 0.23812216270026737, 0.23812216270026737, 0.3428285950620742], 
reward next is 0.6572, 
noisyNet noise sample is [array([-0.83451295], dtype=float32), -0.59801924]. 
=============================================
[2019-03-24 05:53:35,394] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.1919086e-38 2.5228079e-31], sum to 1.0000
[2019-03-24 05:53:35,400] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5407
[2019-03-24 05:53:35,405] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.9, 90.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7547295145195271, 6.9112, 6.9112, 121.9260426156618, 563050.4496225804, 563050.4496225804, 153098.897950142], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2330400.0000, 
sim time next is 2331000.0000, 
raw observation next is [21.9, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7546843345433693, 6.9112, 6.9112, 121.9260426156618, 562914.5182568416, 562914.5182568416, 153197.8871024926], 
processed observation next is [1.0, 1.0, 0.36666666666666664, 0.91, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6933554181792114, 0.0, 0.0, 0.8094621288201359, 0.20104089937744343, 0.20104089937744343, 0.2946113213509473], 
reward next is 0.7054, 
noisyNet noise sample is [array([0.6167789], dtype=float32), 0.3528336]. 
=============================================
[2019-03-24 05:53:35,425] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[73.67904 ]
 [73.75229 ]
 [73.800766]
 [73.81526 ]
 [73.846565]], R is [[73.58589172]
 [73.55561829]
 [73.52606964]
 [73.49737549]
 [73.46915436]].
[2019-03-24 05:53:38,611] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-24 05:53:38,612] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:53:38,613] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:53:38,615] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:53:38,615] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:53:38,619] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:53:38,616] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:53:38,618] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:53:38,616] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:53:38,617] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:53:38,623] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:53:38,634] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run29
[2019-03-24 05:53:38,662] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run29
[2019-03-24 05:53:38,663] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run29
[2019-03-24 05:53:38,689] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run29
[2019-03-24 05:53:38,758] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run29
[2019-03-24 05:53:47,638] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00559467], dtype=float32), 0.014290284]
[2019-03-24 05:53:47,641] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [18.16666666666667, 75.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4986847263608357, 6.9112, 6.9112, 121.9260426156618, 356065.5057641739, 356065.5057641739, 108398.8059595804]
[2019-03-24 05:53:47,641] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:53:47,643] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.3640048e-37 0.0000000e+00 2.1514635e-36 4.1820675e-29], sampled 0.8573716963255438
[2019-03-24 05:54:00,178] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00559467], dtype=float32), 0.014290284]
[2019-03-24 05:54:00,179] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.5, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6262444991769064, 6.911200000000001, 6.9112, 121.9260426156618, 464088.7588130899, 464088.7588130895, 132386.3343310738]
[2019-03-24 05:54:00,181] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:54:00,184] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.4339166e-36 0.0000000e+00 2.3843723e-35 3.6665972e-28], sampled 0.4897187719610605
[2019-03-24 05:54:19,214] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00559467], dtype=float32), 0.014290284]
[2019-03-24 05:54:19,215] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.59818523, 87.45343745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8092868614408578, 6.911199999999999, 6.9112, 121.9260426156618, 602080.6100694842, 602080.6100694846, 160965.7358263276]
[2019-03-24 05:54:19,216] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:54:19,220] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 5.3311374e-38 0.0000000e+00 1.3826607e-36 8.0772756e-29], sampled 0.4550179085538155
[2019-03-24 05:54:21,440] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00559467], dtype=float32), 0.014290284]
[2019-03-24 05:54:21,441] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.13351118, 85.724620015, 1.0, 2.0, 0.8554329277057724, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.92604261566, 1005408.681081531, 1005408.681081531, 209196.3889955358]
[2019-03-24 05:54:21,442] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:54:21,445] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 9.2676393e-29 2.7803579e-29 4.3175251e-27 2.0264033e-19], sampled 0.2851556656950214
[2019-03-24 05:54:21,447] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1005408.681081531 W.
[2019-03-24 05:54:54,712] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00559467], dtype=float32), 0.014290284]
[2019-03-24 05:54:54,713] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.53333333333333, 60.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6918705448413677, 6.9112, 6.9112, 121.9260426156618, 517025.6151074707, 517025.6151074707, 143833.5475215414]
[2019-03-24 05:54:54,715] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:54:54,719] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 3.2248017e-38 0.0000000e+00 6.0871688e-37 2.0685052e-29], sampled 0.80488610949084
[2019-03-24 05:55:18,694] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00559467], dtype=float32), 0.014290284]
[2019-03-24 05:55:18,696] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [17.41666666666667, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5019596503067092, 6.911200000000001, 6.9112, 121.9260426156618, 365139.8678170477, 365139.8678170472, 117724.2317656734]
[2019-03-24 05:55:18,699] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:55:18,703] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 5.4193533e-36 3.4271310e-38 1.0012041e-34 1.6552208e-27], sampled 0.3310477915150215
[2019-03-24 05:55:22,865] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 05:55:23,155] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 05:55:23,161] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 05:55:23,265] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8363.4371 2339475986.9735 616.0000
[2019-03-24 05:55:23,332] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 05:55:24,346] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 700000, evaluation results [700000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8363.437110714249, 2339475986.973477, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 05:55:24,652] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.0007303e-27 1.3513687e-28 1.5960074e-25 1.8329679e-18], sum to 1.0000
[2019-03-24 05:55:24,658] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2602
[2019-03-24 05:55:24,667] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1377155.526757779 W.
[2019-03-24 05:55:24,670] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.03333333333333, 37.0, 1.0, 2.0, 0.5726949432485867, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9255748608366279, 6.911199999999999, 6.9112, 121.9260426156618, 1377155.526757779, 1377155.526757779, 281448.8016490241], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2385600.0000, 
sim time next is 2386200.0000, 
raw observation next is [31.01666666666667, 37.0, 1.0, 2.0, 0.5676261490424973, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9182212524131869, 6.911199999999999, 6.9112, 121.9260426156618, 1367045.502680365, 1367045.502680366, 279454.0350306696], 
processed observation next is [1.0, 0.6086956521739131, 0.704320987654321, 0.37, 1.0, 1.0, 0.485269225050592, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8977765655164834, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4882305366715589, 0.48823053667155925, 0.5374116058282108], 
reward next is 0.4626, 
noisyNet noise sample is [array([-1.0752124], dtype=float32), -0.9348274]. 
=============================================
[2019-03-24 05:55:29,656] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 5.4662572e-28 1.0273648e-29 7.8691069e-26 4.7022329e-17], sum to 1.0000
[2019-03-24 05:55:29,662] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8174
[2019-03-24 05:55:29,668] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1132549.31323152 W.
[2019-03-24 05:55:29,673] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.41666666666666, 23.0, 1.0, 2.0, 0.3122152575115371, 1.0, 1.0, 0.3122152575115371, 1.0, 2.0, 0.5064441263875877, 6.911200000000001, 6.9112, 121.94756008, 1132549.31323152, 1132549.31323152, 259951.8412155489], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2466600.0000, 
sim time next is 2467200.0000, 
raw observation next is [34.53333333333333, 23.0, 1.0, 2.0, 0.6062334958477134, 1.0, 2.0, 0.6062334958477134, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1469051.082379348, 1469051.082379348, 273858.6168268824], 
processed observation next is [1.0, 0.5652173913043478, 0.8345679012345678, 0.23, 1.0, 1.0, 0.5312303521996588, 1.0, 1.0, 0.5312303521996588, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5246611008497671, 0.5246611008497671, 0.5266511862055431], 
reward next is 0.4733, 
noisyNet noise sample is [array([-0.09395996], dtype=float32), 0.59355503]. 
=============================================
[2019-03-24 05:55:47,894] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.6978392e-18 1.1261308e-19 5.8922739e-18 1.1772860e-15], sum to 1.0000
[2019-03-24 05:55:47,898] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2954
[2019-03-24 05:55:47,907] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 696522.6598440862 W.
[2019-03-24 05:55:47,912] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.66666666666667, 80.66666666666666, 1.0, 2.0, 0.3035715226292094, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4835102649679722, 6.911199999999999, 6.9112, 121.9260426156618, 696522.6598440862, 696522.6598440866, 196127.3087014253], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2848800.0000, 
sim time next is 2849400.0000, 
raw observation next is [24.75, 85.5, 1.0, 2.0, 0.2985760903966465, 1.0, 1.0, 0.2985760903966465, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 685855.1116733907, 685855.1116733912, 180383.4762948063], 
processed observation next is [1.0, 1.0, 0.4722222222222222, 0.855, 1.0, 1.0, 0.16497153618648394, 1.0, 0.5, 0.16497153618648394, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24494825416906812, 0.2449482541690683, 0.34689130056693523], 
reward next is 0.6531, 
noisyNet noise sample is [array([1.9106479], dtype=float32), -1.6187125]. 
=============================================
[2019-03-24 05:55:50,650] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.9999940e-01 5.7130007e-14 1.1492210e-13 1.2770503e-13 5.7386143e-07], sum to 1.0000
[2019-03-24 05:55:50,658] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5932
[2019-03-24 05:55:50,664] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1739038.951214879 W.
[2019-03-24 05:55:50,669] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.91666666666667, 81.5, 1.0, 2.0, 0.5083125450418992, 1.0, 2.0, 0.5083125450418992, 1.0, 2.0, 0.8092501262905598, 6.9112, 6.9112, 121.94756008, 1739038.951214879, 1739038.951214879, 347687.6780573024], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2902200.0000, 
sim time next is 2902800.0000, 
raw observation next is [26.73333333333333, 83.0, 1.0, 2.0, 0.8171705214139886, 1.0, 2.0, 0.8171705214139886, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156389, 1863933.097585582, 1863933.097585582, 350900.4592754252], 
processed observation next is [1.0, 0.6086956521739131, 0.545679012345679, 0.83, 1.0, 1.0, 0.7823458588261769, 1.0, 1.0, 0.7823458588261769, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288199839, 0.6656903919948507, 0.6656903919948507, 0.6748085755296638], 
reward next is 0.3252, 
noisyNet noise sample is [array([0.6952558], dtype=float32), 0.23809382]. 
=============================================
[2019-03-24 05:55:53,014] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 4.9126683e-20 2.9560319e-21 3.3201761e-19 3.6110444e-14], sum to 1.0000
[2019-03-24 05:55:53,023] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1769
[2019-03-24 05:55:53,029] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 781473.846202098 W.
[2019-03-24 05:55:53,033] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.16666666666667, 88.16666666666667, 1.0, 2.0, 0.6856808222381771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 781473.846202098, 781473.846202098, 173450.6355947006], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2919000.0000, 
sim time next is 2919600.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.228421954413251, 1.0, 1.0, 0.228421954413251, 1.0, 1.0, 0.3636551906095944, 6.911199999999999, 6.9112, 121.94756008, 781000.6042195705, 781000.604219571, 230104.15293114], 
processed observation next is [1.0, 0.8260869565217391, 0.5185185185185185, 0.89, 1.0, 1.0, 0.08145470763482261, 1.0, 0.5, 0.08145470763482261, 1.0, 0.5, 0.20456898826199296, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2789287872212752, 0.27892878722127534, 0.4425079864060385], 
reward next is 0.5575, 
noisyNet noise sample is [array([0.05007857], dtype=float32), -1.4837154]. 
=============================================
[2019-03-24 05:55:57,361] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 1.7522959e-18 2.2855443e-20 8.1114712e-18 1.5104504e-13], sum to 1.0000
[2019-03-24 05:55:57,370] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5842
[2019-03-24 05:55:57,376] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 766078.6623046162 W.
[2019-03-24 05:55:57,380] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 87.33333333333334, 1.0, 2.0, 0.224059861774673, 1.0, 2.0, 0.224059861774673, 1.0, 2.0, 0.356710597065539, 6.9112, 6.9112, 121.94756008, 766078.6623046162, 766078.6623046162, 228615.3179379394], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3010800.0000, 
sim time next is 3011400.0000, 
raw observation next is [25.75, 89.0, 1.0, 2.0, 0.3354676655040668, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5340754489015966, 6.911199999999999, 6.9112, 121.9260426156618, 764659.953929763, 764659.9539297635, 205022.4457686762], 
processed observation next is [1.0, 0.8695652173913043, 0.5092592592592593, 0.89, 1.0, 1.0, 0.20889007798103193, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.41759431112699574, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2730928406892011, 0.27309284068920125, 0.39427393417053114], 
reward next is 0.6057, 
noisyNet noise sample is [array([1.1427741], dtype=float32), 0.46910933]. 
=============================================
[2019-03-24 05:56:03,160] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 4.9833482e-30 7.4571466e-33 6.4947526e-30 3.7213875e-26], sum to 1.0000
[2019-03-24 05:56:03,170] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2773
[2019-03-24 05:56:03,179] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1422402.629250756 W.
[2019-03-24 05:56:03,184] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.66666666666666, 46.0, 1.0, 2.0, 0.4126555046706415, 1.0, 1.0, 0.4126555046706415, 1.0, 2.0, 0.6573205466183016, 6.911199999999999, 6.9112, 121.94756008, 1422402.629250756, 1422402.629250756, 302733.3305231105], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3145200.0000, 
sim time next is 3145800.0000, 
raw observation next is [30.83333333333334, 44.5, 1.0, 2.0, 0.409629634916273, 1.0, 2.0, 0.409629634916273, 1.0, 2.0, 0.6524937036273257, 6.9112, 6.9112, 121.94756008, 1411813.935485177, 1411813.935485177, 301387.6054714426], 
processed observation next is [1.0, 0.391304347826087, 0.6975308641975311, 0.445, 1.0, 1.0, 0.2971781368050869, 1.0, 1.0, 0.2971781368050869, 1.0, 1.0, 0.5656171295341571, 0.0, 0.0, 0.8096049824067558, 0.5042192626732775, 0.5042192626732775, 0.5795915489835435], 
reward next is 0.4204, 
noisyNet noise sample is [array([-0.18492772], dtype=float32), -0.9777801]. 
=============================================
[2019-03-24 05:56:07,241] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.0937396e-35], sum to 1.0000
[2019-03-24 05:56:07,248] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8366
[2019-03-24 05:56:07,253] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.18333333333333, 83.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8718703191057184, 6.911200000000001, 6.9112, 121.9260426156618, 642734.8156958595, 642734.815695859, 171118.9753716245], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3207000.0000, 
sim time next is 3207600.0000, 
raw observation next is [24.0, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8500353837502049, 6.911199999999999, 6.9112, 121.9260426156618, 628564.2695874806, 628564.269587481, 167716.413477382], 
processed observation next is [0.0, 0.13043478260869565, 0.4444444444444444, 0.83, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8125442296877561, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22448723913838592, 0.22448723913838609, 0.3225315643795808], 
reward next is 0.6775, 
noisyNet noise sample is [array([-2.4372082], dtype=float32), 0.83852506]. 
=============================================
[2019-03-24 05:56:08,191] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.9080388e-38], sum to 1.0000
[2019-03-24 05:56:08,202] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8490
[2019-03-24 05:56:08,206] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.41666666666667, 59.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.739199104225526, 6.911199999999999, 6.9112, 121.9260426156618, 551947.4720615966, 551947.472061597, 150668.9570372363], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3226200.0000, 
sim time next is 3226800.0000, 
raw observation next is [26.53333333333333, 60.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7502472425584373, 6.9112, 6.9112, 121.9260426156618, 559862.2019736118, 559862.2019736118, 152399.5092486225], 
processed observation next is [0.0, 0.34782608695652173, 0.5382716049382715, 0.6, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6878090531980465, 0.0, 0.0, 0.8094621288201359, 0.1999507864191471, 0.1999507864191471, 0.29307597932427404], 
reward next is 0.7069, 
noisyNet noise sample is [array([-0.48219413], dtype=float32), 0.31911203]. 
=============================================
[2019-03-24 05:56:13,198] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.7487704e-25 7.6170734e-29 1.1135517e-24 2.6451834e-22], sum to 1.0000
[2019-03-24 05:56:13,204] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3632
[2019-03-24 05:56:13,208] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 805070.0184323974 W.
[2019-03-24 05:56:13,218] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.8, 74.0, 1.0, 2.0, 0.3531868548054806, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5622849753431554, 6.9112, 6.9112, 121.9260426156618, 805070.0184323974, 805070.0184323974, 210096.6525441257], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3344400.0000, 
sim time next is 3345000.0000, 
raw observation next is [28.83333333333333, 74.0, 1.0, 2.0, 0.3480135317369888, 1.0, 1.0, 0.3480135317369888, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 793271.6106614486, 793271.610661449, 192382.6917124192], 
processed observation next is [0.0, 0.7391304347826086, 0.6234567901234566, 0.74, 1.0, 1.0, 0.22382563302022476, 1.0, 0.5, 0.22382563302022476, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2833112895219459, 0.28331128952194606, 0.3699667148315754], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.4977508], dtype=float32), 1.1223773]. 
=============================================
[2019-03-24 05:56:13,236] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[45.04681 ]
 [44.030968]
 [43.893505]
 [43.818123]
 [42.74699 ]], R is [[44.05764008]
 [43.61706543]
 [43.18089676]
 [43.30418396]
 [43.47374344]].
[2019-03-24 05:56:13,626] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-24 05:56:13,626] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:56:13,627] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:56:13,628] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:56:13,628] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:56:13,630] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:56:13,627] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:56:13,631] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:56:13,633] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:56:13,632] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:56:13,635] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:56:13,651] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run30
[2019-03-24 05:56:13,675] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run30
[2019-03-24 05:56:13,701] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run30
[2019-03-24 05:56:13,727] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run30
[2019-03-24 05:56:13,752] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run30
[2019-03-24 05:56:17,765] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00570752], dtype=float32), 0.013934336]
[2019-03-24 05:56:17,766] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.66666666666666, 25.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5755348698620735, 6.911199999999999, 6.9112, 121.9260426156618, 417692.9323882621, 417692.9323882626, 123423.8923056551]
[2019-03-24 05:56:17,768] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 05:56:17,770] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.4288617e-34], sampled 0.5138390817788594
[2019-03-24 05:56:56,374] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00570752], dtype=float32), 0.013934336]
[2019-03-24 05:56:56,375] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.63333333333333, 94.0, 1.0, 2.0, 0.6893794756766912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 800864.2462435955, 800864.2462435955, 174885.1497178044]
[2019-03-24 05:56:56,378] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 05:56:56,382] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 3.3707078e-29 1.0352556e-31 6.8839200e-29 3.5612999e-24], sampled 0.534380367505394
[2019-03-24 05:56:56,384] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 800864.2462435955 W.
[2019-03-24 05:57:04,605] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00570752], dtype=float32), 0.013934336]
[2019-03-24 05:57:04,607] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.0, 91.5, 1.0, 2.0, 0.9782040249178655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.010373154538144, 6.9112, 121.9254255654135, 1165928.783590238, 1115143.521488982, 235508.5475359809]
[2019-03-24 05:57:04,609] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:57:04,611] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.8567026e-28 1.1696270e-30 5.2333381e-28 3.3238695e-23], sampled 0.6495975916651967
[2019-03-24 05:57:04,612] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1165928.783590238 W.
[2019-03-24 05:57:43,682] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00570752], dtype=float32), 0.013934336]
[2019-03-24 05:57:43,683] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.84395812333334, 66.93020225666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.903793000197956, 6.911200000000001, 6.9112, 121.9260426156618, 659379.7205161126, 659379.7205161122, 176843.7010985313]
[2019-03-24 05:57:43,684] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:57:43,688] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.4164312e-38 0.0000000e+00 1.2046067e-38 2.8896757e-33], sampled 0.8930719046211443
[2019-03-24 05:57:58,521] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7840.8063 2529759975.6925 831.0000
[2019-03-24 05:57:58,538] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 05:57:58,555] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8558.6876 2258253977.7077 536.0000
[2019-03-24 05:57:58,558] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8363.4417 2339421032.3157 616.0000
[2019-03-24 05:57:58,713] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.7414 2219189295.2583 543.0000
[2019-03-24 05:57:59,729] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 725000, evaluation results [725000.0, 7840.806321330914, 2529759975.692537, 831.0, 8558.687622313513, 2258253977.70769, 536.0, 8633.741374971278, 2219189295.2583184, 543.0, 8363.441733547912, 2339421032.3156533, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 05:58:06,203] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 3.6508725e-18 1.0295873e-18 1.5300654e-18 1.7845102e-14], sum to 1.0000
[2019-03-24 05:58:06,212] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9418
[2019-03-24 05:58:06,219] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 816575.8401431678 W.
[2019-03-24 05:58:06,223] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.0, 100.0, 1.0, 2.0, 0.7164636182076453, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 816575.8401431678, 816575.8401431678, 179279.9392299216], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3469800.0000, 
sim time next is 3470400.0000, 
raw observation next is [24.0, 100.0, 1.0, 2.0, 0.3603888730232253, 1.0, 1.0, 0.3603888730232253, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 821495.4206475148, 821495.4206475148, 195583.6920155159], 
processed observation next is [1.0, 0.17391304347826086, 0.4444444444444444, 1.0, 1.0, 1.0, 0.23855818217050634, 1.0, 0.5, 0.23855818217050634, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2933912216598267, 0.2933912216598267, 0.3761224846452229], 
reward next is 0.6239, 
noisyNet noise sample is [array([1.294995], dtype=float32), 0.070875786]. 
=============================================
[2019-03-24 05:58:13,775] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 5.1484230e-16 3.2698149e-17 5.9008275e-16 5.9875056e-11], sum to 1.0000
[2019-03-24 05:58:13,781] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1131
[2019-03-24 05:58:13,789] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1477634.296977606 W.
[2019-03-24 05:58:13,795] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 83.0, 1.0, 2.0, 0.6665327452600184, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9940390715867318, 6.911199999999999, 6.9112, 121.9260426156618, 1477634.296977606, 1477634.296977607, 310619.0607488432], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3598200.0000, 
sim time next is 3598800.0000, 
raw observation next is [25.0, 83.0, 1.0, 2.0, 0.6789030524914345, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9931364389611169, 6.9112, 6.9112, 121.9260426156618, 1492574.218685526, 1492574.218685526, 312651.8144712191], 
processed observation next is [1.0, 0.6521739130434783, 0.48148148148148145, 0.83, 1.0, 1.0, 0.6177417291564695, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9914205487013961, 0.0, 0.0, 0.8094621288201359, 0.5330622209591164, 0.5330622209591164, 0.601253489367729], 
reward next is 0.3987, 
noisyNet noise sample is [array([-0.3988587], dtype=float32), -0.7163658]. 
=============================================
[2019-03-24 05:58:16,237] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 8.637827e-37], sum to 1.0000
[2019-03-24 05:58:16,246] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0652
[2019-03-24 05:58:16,250] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.58333333333333, 79.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8374452075415674, 6.9112, 6.9112, 121.9260426156618, 619415.5039641425, 619415.5039641425, 166076.9947765681], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3615000.0000, 
sim time next is 3615600.0000, 
raw observation next is [24.46666666666667, 81.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.840573662602852, 6.9112, 6.9112, 121.9260426156618, 620811.9951095437, 620811.9951095437, 166776.9668891816], 
processed observation next is [1.0, 0.8695652173913043, 0.46172839506172847, 0.8166666666666668, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.800717078253565, 0.0, 0.0, 0.8094621288201359, 0.2217185696819799, 0.2217185696819799, 0.32072493632534926], 
reward next is 0.6793, 
noisyNet noise sample is [array([-0.07205316], dtype=float32), -0.6456184]. 
=============================================
[2019-03-24 05:58:20,939] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.00000000e+00 3.95379257e-16 2.91702371e-16 2.76794477e-14
 1.01547715e-10], sum to 1.0000
[2019-03-24 05:58:20,947] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4844
[2019-03-24 05:58:20,953] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 829346.8424592179 W.
[2019-03-24 05:58:20,957] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.9, 94.66666666666667, 1.0, 2.0, 0.2425543018712261, 1.0, 1.0, 0.2425543018712261, 1.0, 1.0, 0.3861543480211151, 6.911200000000001, 6.9112, 121.94756008, 829346.8424592179, 829346.8424592174, 235000.754910515], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3730200.0000, 
sim time next is 3730800.0000, 
raw observation next is [24.8, 95.33333333333334, 1.0, 2.0, 0.2181756062625854, 1.0, 2.0, 0.2181756062625854, 1.0, 2.0, 0.3473426706534724, 6.911200000000001, 6.9112, 121.94756008, 745950.1324696467, 745950.1324696463, 226623.8103117213], 
processed observation next is [1.0, 0.17391304347826086, 0.4740740740740741, 0.9533333333333335, 1.0, 1.0, 0.06925667412212547, 1.0, 1.0, 0.06925667412212547, 1.0, 1.0, 0.1841783383168405, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2664107615963024, 0.2664107615963022, 0.43581501983023324], 
reward next is 0.5642, 
noisyNet noise sample is [array([-2.408945], dtype=float32), -0.75371975]. 
=============================================
[2019-03-24 05:58:20,968] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 3.4061300e-18 1.9339174e-19 1.8903664e-18 1.5032108e-13], sum to 1.0000
[2019-03-24 05:58:20,975] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3915
[2019-03-24 05:58:20,982] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 753830.1555943263 W.
[2019-03-24 05:58:20,988] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.9, 94.66666666666667, 1.0, 2.0, 0.3307188074354397, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5265151121968323, 6.9112, 6.9112, 121.9260426156618, 753830.1555943263, 753830.1555943263, 203684.2966058375], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3720000.0000, 
sim time next is 3720600.0000, 
raw observation next is [24.85, 95.0, 1.0, 2.0, 0.2206416262615582, 1.0, 1.0, 0.2206416262615582, 1.0, 2.0, 0.3512686548045015, 6.9112, 6.9112, 121.94756008, 754385.690458701, 754385.690458701, 227456.0694845606], 
processed observation next is [1.0, 0.043478260869565216, 0.475925925925926, 0.95, 1.0, 1.0, 0.07219241221614071, 1.0, 0.5, 0.07219241221614071, 1.0, 1.0, 0.18908581850562683, 0.0, 0.0, 0.8096049824067558, 0.2694234608781075, 0.2694234608781075, 0.4374155182395396], 
reward next is 0.5626, 
noisyNet noise sample is [array([1.0144362], dtype=float32), 0.6961558]. 
=============================================
[2019-03-24 05:58:22,554] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 2.0742222e-25 7.9812925e-27 1.9931638e-24 3.0616281e-21], sum to 1.0000
[2019-03-24 05:58:22,558] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0157
[2019-03-24 05:58:22,563] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 886022.7596939573 W.
[2019-03-24 05:58:22,573] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.93333333333334, 63.0, 1.0, 2.0, 0.388680571664149, 0.0, 1.0, 0.0, 1.0, 2.0, 0.6187921285318124, 6.911199999999999, 6.9112, 121.9260424491854, 886022.7596939573, 886022.7596939577, 220641.4868658389], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3777600.0000, 
sim time next is 3778200.0000, 
raw observation next is [33.2, 59.0, 1.0, 2.0, 0.3697712953425821, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5886879447957416, 6.9112, 6.9112, 121.9260426156111, 842894.1256146277, 842894.1256146277, 214962.2727208306], 
processed observation next is [1.0, 0.7391304347826086, 0.7851851851851853, 0.59, 1.0, 1.0, 0.24972773255069294, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.48585993099467695, 0.0, 0.0, 0.8094621288197993, 0.3010336162909385, 0.3010336162909385, 0.4133889860015973], 
reward next is 0.5866, 
noisyNet noise sample is [array([1.235229], dtype=float32), 0.101329744]. 
=============================================
[2019-03-24 05:58:24,965] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 9.6843913e-30 8.8495898e-36 3.1504694e-32 1.2501783e-29], sum to 1.0000
[2019-03-24 05:58:24,972] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0924
[2019-03-24 05:58:24,981] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 771251.8064527054 W.
[2019-03-24 05:58:24,984] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.66666666666667, 50.0, 1.0, 2.0, 0.3383581548124756, 1.0, 1.0, 0.3383581548124756, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 771251.8064527054, 771251.8064527059, 189921.273472051], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3781200.0000, 
sim time next is 3781800.0000, 
raw observation next is [33.5, 51.5, 1.0, 2.0, 0.3411046790613789, 1.0, 2.0, 0.3411046790613789, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 777515.394616911, 777515.3946169114, 190618.2875501758], 
processed observation next is [1.0, 0.782608695652174, 0.7962962962962963, 0.515, 1.0, 1.0, 0.21560080840640347, 1.0, 1.0, 0.21560080840640347, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27768406950603963, 0.2776840695060398, 0.36657362990418424], 
reward next is 0.6334, 
noisyNet noise sample is [array([0.13354546], dtype=float32), 0.94584495]. 
=============================================
[2019-03-24 05:58:26,550] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.000000e+00 2.246928e-35 0.000000e+00 9.290720e-36 5.624619e-31], sum to 1.0000
[2019-03-24 05:58:26,554] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8792
[2019-03-24 05:58:26,557] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.35, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9003903710612099, 6.9112, 6.9112, 121.9260426156618, 659774.0340614716, 659774.0340614716, 175825.0123340663], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3810600.0000, 
sim time next is 3811200.0000, 
raw observation next is [26.23333333333333, 73.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8952524279680698, 6.911200000000001, 6.9112, 121.9260426156618, 656569.0561972376, 656569.0561972371, 175021.6144041103], 
processed observation next is [0.0, 0.08695652173913043, 0.5271604938271603, 0.7333333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8690655349600873, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23448894864187056, 0.2344889486418704, 0.3365800277002121], 
reward next is 0.6634, 
noisyNet noise sample is [array([0.22274658], dtype=float32), 1.3315681]. 
=============================================
[2019-03-24 05:58:27,618] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.4346931e-29 2.5912175e-33 3.0627956e-29 7.2064824e-27], sum to 1.0000
[2019-03-24 05:58:27,625] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5198
[2019-03-24 05:58:27,629] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 827078.8939563234 W.
[2019-03-24 05:58:27,633] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.33333333333334, 55.66666666666667, 1.0, 2.0, 0.362837013934407, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5776483429601478, 6.911199999999999, 6.9112, 121.9260426156618, 827078.8939563234, 827078.8939563239, 212914.5186170193], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3867600.0000, 
sim time next is 3868200.0000, 
raw observation next is [33.0, 58.5, 1.0, 2.0, 0.2527324525077816, 1.0, 1.0, 0.2527324525077816, 1.0, 2.0, 0.402358295313736, 6.911200000000001, 6.9112, 121.94756008, 864167.808355754, 864167.8083557535, 238596.433668885], 
processed observation next is [0.0, 0.782608695652174, 0.7777777777777778, 0.585, 1.0, 1.0, 0.11039577679497808, 1.0, 0.5, 0.11039577679497808, 1.0, 1.0, 0.25294786914217, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.308631360127055, 0.30863136012705483, 0.4588392955170865], 
reward next is 0.5412, 
noisyNet noise sample is [array([-0.71339697], dtype=float32), 0.14680564]. 
=============================================
[2019-03-24 05:58:30,450] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 1.6360809e-19 4.8389700e-23 9.5330608e-20 2.1980318e-17], sum to 1.0000
[2019-03-24 05:58:30,454] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9934
[2019-03-24 05:58:30,459] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 813431.4389593705 W.
[2019-03-24 05:58:30,469] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.4, 95.33333333333334, 1.0, 2.0, 0.3568530919517781, 1.0, 2.0, 0.3568530919517781, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 813431.4389593705, 813431.4389593705, 194664.147168194], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3904800.0000, 
sim time next is 3905400.0000, 
raw observation next is [25.25, 95.66666666666666, 1.0, 2.0, 0.3543551837102444, 1.0, 2.0, 0.3543551837102444, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 807734.5631938679, 807734.5631938684, 194016.5293144832], 
processed observation next is [0.0, 0.17391304347826086, 0.49074074074074076, 0.9566666666666666, 1.0, 1.0, 0.2313752187026719, 1.0, 1.0, 0.2313752187026719, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2884766297120957, 0.28847662971209587, 0.37310871022016], 
reward next is 0.6269, 
noisyNet noise sample is [array([-0.5888905], dtype=float32), -2.7499948]. 
=============================================
[2019-03-24 05:58:32,519] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.0198941e-23 5.0500389e-23 5.3962636e-23 1.5187253e-19], sum to 1.0000
[2019-03-24 05:58:32,526] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4832
[2019-03-24 05:58:32,531] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 891903.2235565325 W.
[2019-03-24 05:58:32,534] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.86666666666667, 69.0, 1.0, 2.0, 0.3912587140797463, 1.0, 1.0, 0.3912587140797463, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 891903.2235565325, 891903.2235565335, 203804.1487964338], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3940800.0000, 
sim time next is 3941400.0000, 
raw observation next is [30.93333333333333, 69.5, 1.0, 2.0, 0.3987674396429128, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6348507508603604, 6.911199999999999, 6.9112, 121.9260426156618, 909030.0711068655, 909030.071106866, 223726.6246753716], 
processed observation next is [0.0, 0.6086956521739131, 0.7012345679012344, 0.695, 1.0, 1.0, 0.28424695195584854, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.5435634385754504, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.32465359682388056, 0.32465359682388073, 0.4302435089910992], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.71851426], dtype=float32), -0.5586315]. 
=============================================
[2019-03-24 05:58:36,269] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 4.9732401e-17 2.2106609e-18 1.6803858e-16 1.4784978e-13], sum to 1.0000
[2019-03-24 05:58:36,275] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2129
[2019-03-24 05:58:36,282] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1769391.957484571 W.
[2019-03-24 05:58:36,289] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.5, 86.5, 1.0, 2.0, 0.5171758031057099, 1.0, 2.0, 0.5171758031057099, 1.0, 2.0, 0.8233607217843094, 6.911200000000001, 6.9112, 121.94756008, 1769391.957484571, 1769391.95748457, 352099.1163448275], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4030200.0000, 
sim time next is 4030800.0000, 
raw observation next is [26.66666666666667, 85.66666666666667, 1.0, 2.0, 0.767046432866796, 1.0, 2.0, 0.767046432866796, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1749490.101073108, 1749490.101073109, 330325.7342367899], 
processed observation next is [1.0, 0.6521739130434783, 0.5432098765432101, 0.8566666666666667, 1.0, 1.0, 0.7226743248414238, 1.0, 1.0, 0.7226743248414238, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6248178932403957, 0.624817893240396, 0.6352417966092114], 
reward next is 0.3648, 
noisyNet noise sample is [array([0.8748694], dtype=float32), -1.7274303]. 
=============================================
[2019-03-24 05:58:39,271] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 5.9429894e-28 4.0230782e-31 4.3122886e-28 1.2582864e-24], sum to 1.0000
[2019-03-24 05:58:39,278] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4378
[2019-03-24 05:58:39,285] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1384281.074943206 W.
[2019-03-24 05:58:39,289] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.85, 69.66666666666667, 1.0, 2.0, 0.6070593046919383, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9664581836108662, 6.911199999999999, 6.9112, 121.9260426156618, 1384281.074943206, 1384281.074943207, 296615.5712291058], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4103400.0000, 
sim time next is 4104000.0000, 
raw observation next is [28.0, 70.0, 1.0, 2.0, 0.4577212640229846, 1.0, 1.0, 0.4577212640229846, 1.0, 2.0, 0.7287071592654529, 6.9112, 6.9112, 121.94756008, 1565802.032086009, 1565802.032086009, 323289.4463562349], 
processed observation next is [1.0, 0.5217391304347826, 0.5925925925925926, 0.7, 1.0, 1.0, 0.35443007621783884, 1.0, 0.5, 0.35443007621783884, 1.0, 1.0, 0.660883949081816, 0.0, 0.0, 0.8096049824067558, 0.5592150114592889, 0.5592150114592889, 0.6217104737619902], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.19177721], dtype=float32), 1.6671082]. 
=============================================
[2019-03-24 05:58:39,308] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[43.671967]
 [44.320824]
 [43.49979 ]
 [42.572155]
 [40.825073]], R is [[42.16188812]
 [41.74026871]
 [41.79623413]
 [41.75128555]
 [41.71263885]].
[2019-03-24 05:58:44,880] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.9151012e-38], sum to 1.0000
[2019-03-24 05:58:44,888] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4537
[2019-03-24 05:58:44,899] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.76161991879967, 6.9112, 6.9112, 121.9260426156618, 569168.3402524664, 569168.3402524664, 151807.8280702221], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4159800.0000, 
sim time next is 4160400.0000, 
raw observation next is [20.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7550555207399259, 6.9112, 6.9112, 121.9260426156618, 564260.9055934986, 564260.9055934986, 151051.0466595526], 
processed observation next is [1.0, 0.13043478260869565, 0.2962962962962963, 1.0, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6938194009249073, 0.0, 0.0, 0.8094621288201359, 0.20152175199767808, 0.20152175199767808, 0.2904827820376012], 
reward next is 0.7095, 
noisyNet noise sample is [array([-0.95092], dtype=float32), -1.802571]. 
=============================================
[2019-03-24 05:58:49,019] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 3.0792574e-35 0.0000000e+00 1.9340112e-36 1.9251612e-31], sum to 1.0000
[2019-03-24 05:58:49,025] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7185
[2019-03-24 05:58:49,033] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.2, 62.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6998455430404165, 6.9112, 6.9112, 121.9260426156618, 522988.6780812491, 522988.6780812491, 144804.5073393174], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4239000.0000, 
sim time next is 4239600.0000, 
raw observation next is [24.93333333333333, 64.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6984129355420527, 6.911200000000001, 6.9112, 121.9260426156618, 521917.7816950351, 521917.7816950346, 144637.5226936851], 
processed observation next is [1.0, 0.043478260869565216, 0.47901234567901224, 0.64, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6230161694275659, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18639920774822683, 0.18639920774822663, 0.2781490821032406], 
reward next is 0.7219, 
noisyNet noise sample is [array([-0.78104436], dtype=float32), -0.5634879]. 
=============================================
[2019-03-24 05:58:49,355] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-24 05:58:49,357] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 05:58:49,359] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:58:49,363] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 05:58:49,365] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:58:49,367] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 05:58:49,369] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 05:58:49,371] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:58:49,372] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 05:58:49,372] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:58:49,373] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 05:58:49,383] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run31
[2019-03-24 05:58:49,410] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run31
[2019-03-24 05:58:49,438] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run31
[2019-03-24 05:58:49,438] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run31
[2019-03-24 05:58:49,510] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run31
[2019-03-24 05:59:05,624] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00533987], dtype=float32), 0.013605248]
[2019-03-24 05:59:05,624] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.82922654666667, 49.05769174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5866081629810105, 6.911200000000001, 6.9112, 121.9260426156618, 421189.1886392356, 421189.1886392352, 122404.5128413643]
[2019-03-24 05:59:05,626] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:59:05,630] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.8724335e-38 0.0000000e+00 0.0000000e+00 3.2079117e-35], sampled 0.14397705662452465
[2019-03-24 05:59:06,420] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00533987], dtype=float32), 0.013605248]
[2019-03-24 05:59:06,421] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.16417589, 36.74267385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4741353201918997, 6.9112, 6.9112, 121.9260426156618, 338533.1348633043, 338533.1348633043, 97326.67486792964]
[2019-03-24 05:59:06,421] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 05:59:06,424] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 5.3004193e-37], sampled 0.859166518054454
[2019-03-24 05:59:31,550] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00533987], dtype=float32), 0.013605248]
[2019-03-24 05:59:31,551] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.23491253333333, 65.49213412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8651735665346254, 6.9112, 6.9112, 121.9260426156618, 636993.2094187966, 636993.2094187966, 170480.8572390042]
[2019-03-24 05:59:31,553] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 05:59:31,557] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.1645786e-37], sampled 0.4169609486933782
[2019-03-24 05:59:31,953] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00533987], dtype=float32), 0.013605248]
[2019-03-24 05:59:31,956] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [35.33333333333334, 43.00000000000001, 1.0, 2.0, 0.7028213020652023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 801019.1439687817, 801019.1439687817, 176678.9752550674]
[2019-03-24 05:59:31,957] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 05:59:31,959] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 3.2869463e-33 8.6980726e-37 5.3608233e-33 3.3351762e-29], sampled 0.23136323733143604
[2019-03-24 05:59:31,960] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 801019.1439687817 W.
[2019-03-24 06:00:03,063] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00533987], dtype=float32), 0.013605248]
[2019-03-24 06:00:03,064] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.28333333333333, 96.33333333333333, 1.0, 2.0, 0.6455336158280346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 735695.9172341208, 735695.9172341203, 166086.8647398154]
[2019-03-24 06:00:03,064] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:00:03,066] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 2.4729451e-32 1.2117476e-35 4.8290269e-32 4.0702122e-28], sampled 0.8656852920899057
[2019-03-24 06:00:03,067] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 735695.9172341208 W.
[2019-03-24 06:00:09,724] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00533987], dtype=float32), 0.013605248]
[2019-03-24 06:00:09,725] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.51212401333333, 83.85565216833334, 1.0, 2.0, 0.7029708642043278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 801189.6919446862, 801189.6919446858, 176710.0776029321]
[2019-03-24 06:00:09,727] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:00:09,729] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.0641336e-29 1.1167461e-32 2.1005024e-29 1.0694995e-25], sampled 0.7041994285641837
[2019-03-24 06:00:09,729] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 801189.6919446862 W.
[2019-03-24 06:00:30,453] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00533987], dtype=float32), 0.013605248]
[2019-03-24 06:00:30,455] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [19.68333333333334, 91.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6218753236585812, 6.911199999999999, 6.9112, 121.9260426156618, 462804.8397417176, 462804.839741718, 133411.2947694907]
[2019-03-24 06:00:30,456] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:00:30,459] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.8128894e-36], sampled 0.18610361016293486
[2019-03-24 06:00:33,772] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 06:00:34,416] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8363.4417 2339421032.3157 616.0000
[2019-03-24 06:00:34,532] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 06:00:34,562] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5295 2529767993.6091 831.0000
[2019-03-24 06:00:34,611] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.2390 2292980111.6144 697.0000
[2019-03-24 06:00:35,626] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 750000, evaluation results [750000.0, 7841.529523729852, 2529767993.609111, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8363.441733547912, 2339421032.3156533, 616.0, 8404.238967854026, 2292980111.6144123, 697.0]
[2019-03-24 06:00:39,860] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.1735262e-19 6.3760414e-21 3.1713505e-19 2.5298796e-14], sum to 1.0000
[2019-03-24 06:00:39,867] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6933
[2019-03-24 06:00:39,874] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 780728.5524441131 W.
[2019-03-24 06:00:39,880] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 93.33333333333334, 1.0, 2.0, 0.3340841932639584, 1.0, 1.0, 0.3340841932639584, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 780728.5524441131, 780728.5524441135, 189737.7581522169], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4335000.0000, 
sim time next is 4335600.0000, 
raw observation next is [22.6, 92.66666666666667, 1.0, 2.0, 0.6015362914735181, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 712736.7414226364, 712736.7414226364, 159569.7622019212], 
processed observation next is [1.0, 0.17391304347826086, 0.39259259259259266, 0.9266666666666667, 1.0, 1.0, 0.5256384422303786, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2545488362223702, 0.2545488362223702, 0.3068649273113869], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.17123637], dtype=float32), -0.3780858]. 
=============================================
[2019-03-24 06:00:41,586] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.7125124e-27 4.7543461e-30 2.6575739e-29 6.6357930e-24], sum to 1.0000
[2019-03-24 06:00:41,593] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5416
[2019-03-24 06:00:41,598] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.06666666666667, 78.33333333333334, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8915786255573895, 6.911199999999999, 6.9112, 121.9260426156618, 654210.4289131393, 654210.4289131397, 174460.9141652469], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4401600.0000, 
sim time next is 4402200.0000, 
raw observation next is [24.78333333333333, 78.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8638953559487873, 6.911200000000001, 6.9112, 121.9260426156618, 638057.4717540786, 638057.4717540783, 169727.7469807019], 
processed observation next is [1.0, 0.9565217391304348, 0.4734567901234567, 0.7816666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.829869194935984, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22787766848359953, 0.2278776684835994, 0.3263995134244267], 
reward next is 0.6736, 
noisyNet noise sample is [array([-0.9390771], dtype=float32), 0.5221272]. 
=============================================
[2019-03-24 06:00:45,269] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 3.6662540e-32 5.4358937e-37 1.9459298e-32 2.7246083e-27], sum to 1.0000
[2019-03-24 06:00:45,277] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2100
[2019-03-24 06:00:45,282] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 728261.4539778 W.
[2019-03-24 06:00:45,286] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.93333333333334, 77.66666666666667, 1.0, 2.0, 0.6390133712968478, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 728261.4539778, 728261.4539777995, 164917.9906815408], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4443600.0000, 
sim time next is 4444200.0000, 
raw observation next is [26.9, 77.0, 1.0, 2.0, 0.3192843735386407, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5083111210396144, 6.911199999999999, 6.9112, 121.9260426156618, 727754.4905832823, 727754.4905832828, 200498.6662355624], 
processed observation next is [0.0, 0.43478260869565216, 0.5518518518518518, 0.77, 1.0, 1.0, 0.1896242542126675, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.38538890129951797, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.25991231806545795, 0.2599123180654581, 0.3855743581453123], 
reward next is 0.6144, 
noisyNet noise sample is [array([0.04152739], dtype=float32), -0.3495584]. 
=============================================
[2019-03-24 06:00:45,985] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 6.6452808e-35 0.0000000e+00 2.3552352e-36 3.8721292e-32], sum to 1.0000
[2019-03-24 06:00:45,991] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5073
[2019-03-24 06:00:45,997] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1439474.213305801 W.
[2019-03-24 06:00:46,006] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.5, 98.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9605136071195756, 8.322661141765803, 6.9112, 122.2783947614526, 1439474.213305801, 714591.162035986, 176825.3311147088], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4587000.0000, 
sim time next is 4587600.0000, 
raw observation next is [21.4, 98.66666666666667, 1.0, 1.0, 0.3805161238276331, 1.0, 1.0, 0.3805161238276331, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9251926480316, 901215.370633805, 901215.3706338055, 202404.563210841], 
processed observation next is [1.0, 0.08695652173913043, 0.3481481481481481, 0.9866666666666667, 1.0, 0.5, 0.26251919503289656, 1.0, 0.5, 0.26251919503289656, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094564859189755, 0.3218626323692161, 0.32186263236921625, 0.3892395446362327], 
reward next is 0.6108, 
noisyNet noise sample is [array([-0.78275335], dtype=float32), -1.0129745]. 
=============================================
[2019-03-24 06:00:47,442] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.000000e+00 4.650362e-38 0.000000e+00 0.000000e+00 8.822355e-36], sum to 1.0000
[2019-03-24 06:00:47,447] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6946
[2019-03-24 06:00:47,452] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.91666666666667, 90.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9193504772349003, 6.9112, 6.9112, 121.9260426156618, 672843.8893468603, 672843.8893468603, 178530.8853615455], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4500600.0000, 
sim time next is 4501200.0000, 
raw observation next is [23.93333333333333, 91.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9237202457596356, 6.911200000000001, 6.9112, 121.9260426156618, 675025.4594832127, 675025.4594832122, 179321.3709168184], 
processed observation next is [0.0, 0.08695652173913043, 0.4419753086419752, 0.9133333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9046503071995445, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24108052124400453, 0.24108052124400436, 0.3448487902246508], 
reward next is 0.6552, 
noisyNet noise sample is [array([-0.08032915], dtype=float32), 2.1625068]. 
=============================================
[2019-03-24 06:00:48,149] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 3.9273371e-38 1.1839808e-34], sum to 1.0000
[2019-03-24 06:00:48,154] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3971
[2019-03-24 06:00:48,162] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 695593.9584742371 W.
[2019-03-24 06:00:48,166] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 95.0, 1.0, 2.0, 0.3044742293181275, 0.0, 1.0, 0.0, 1.0, 2.0, 0.4847898382532637, 6.9112, 6.9112, 121.9260426156618, 695593.9584742371, 695593.9584742371, 196425.6176819031], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4504200.0000, 
sim time next is 4504800.0000, 
raw observation next is [23.66666666666666, 96.0, 1.0, 2.0, 0.6032047381492526, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 695699.8703320171, 695699.8703320171, 159031.36188725], 
processed observation next is [0.0, 0.13043478260869565, 0.4320987654320985, 0.96, 1.0, 1.0, 0.5276246882729198, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24846423940429183, 0.24846423940429183, 0.3058295420908654], 
reward next is 0.6942, 
noisyNet noise sample is [array([-1.1139779], dtype=float32), -1.2790581]. 
=============================================
[2019-03-24 06:00:51,458] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.8508874e-38], sum to 1.0000
[2019-03-24 06:00:51,462] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9960
[2019-03-24 06:00:51,466] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.6, 98.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7897510560154392, 6.9112, 6.9112, 121.9260426156618, 587154.631144536, 587154.631144536, 158769.8513213723], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4586400.0000, 
sim time next is 4587000.0000, 
raw observation next is [21.5, 98.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9605136071195756, 8.322661141765803, 6.9112, 122.2783947614526, 1439474.213305801, 714591.162035986, 176825.3311147088], 
processed observation next is [1.0, 0.08695652173913043, 0.35185185185185186, 0.9833333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9506420088994694, 0.14114611417658027, 0.0, 0.8118013806477806, 0.5140979333235003, 0.25521112929856643, 0.3400487136821323], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.4056066], dtype=float32), -0.92975247]. 
=============================================
[2019-03-24 06:00:51,485] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[60.45085 ]
 [60.238148]
 [60.369034]
 [60.501488]
 [60.623013]], R is [[59.12738419]
 [59.23078156]
 [59.33416367]
 [59.43762207]
 [59.54133224]].
[2019-03-24 06:00:52,384] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 4.216537e-38], sum to 1.0000
[2019-03-24 06:00:52,388] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5784
[2019-03-24 06:00:52,394] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.2, 99.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7752468230817349, 6.9112, 6.9112, 121.9260426156618, 577337.8604870326, 577337.8604870326, 156397.9281675957], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4584000.0000, 
sim time next is 4584600.0000, 
raw observation next is [21.3, 99.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7789207426714954, 6.911200000000001, 6.9112, 121.9260426156618, 579848.0421518955, 579848.042151895, 156995.6968718427], 
processed observation next is [1.0, 0.043478260869565216, 0.3444444444444445, 0.99, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7236509283393691, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2070885864828198, 0.20708858648281964, 0.30191480167662055], 
reward next is 0.6981, 
noisyNet noise sample is [array([0.4138731], dtype=float32), -1.967942]. 
=============================================
[2019-03-24 06:00:53,230] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:00:53,239] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3681
[2019-03-24 06:00:53,243] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7912957653524717, 6.911199999999999, 6.9112, 121.9260426156618, 589640.9569290928, 589640.9569290932, 158094.2251044669], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4592400.0000, 
sim time next is 4593000.0000, 
raw observation next is [21.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7878384960479675, 6.9112, 6.9112, 121.9260426156618, 587063.814966984, 587063.814966984, 157672.8212955674], 
processed observation next is [1.0, 0.13043478260869565, 0.3333333333333333, 1.0, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7347981200599593, 0.0, 0.0, 0.8094621288201359, 0.20966564820249428, 0.20966564820249428, 0.3032169640299373], 
reward next is 0.6968, 
noisyNet noise sample is [array([0.19389004], dtype=float32), -0.81717646]. 
=============================================
[2019-03-24 06:00:53,265] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[65.215004]
 [65.43639 ]
 [64.877174]
 [64.10992 ]
 [64.301025]], R is [[65.36466217]
 [65.40699005]
 [65.44903564]
 [65.49176025]
 [65.52587891]].
[2019-03-24 06:01:02,668] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 3.4465303e-18 8.8538101e-21 4.5388698e-19 3.9656219e-15], sum to 1.0000
[2019-03-24 06:01:02,676] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7186
[2019-03-24 06:01:02,685] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 794289.3474965352 W.
[2019-03-24 06:01:02,688] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.66666666666667, 96.0, 1.0, 2.0, 0.346811217706617, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5522913859553629, 6.9112, 6.9112, 121.926042615627, 794289.3474965352, 794289.3474965352, 208193.6954257799], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4776000.0000, 
sim time next is 4776600.0000, 
raw observation next is [23.83333333333333, 95.0, 1.0, 2.0, 0.3494251003644763, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5564121852606654, 6.911199999999999, 6.9112, 121.9260426156618, 799466.6975427021, 799466.6975427025, 208959.3152135888], 
processed observation next is [1.0, 0.2608695652173913, 0.43827160493827144, 0.95, 1.0, 1.0, 0.22550607186247182, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.44551523157583167, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.28552382055096504, 0.2855238205509652, 0.4018448369492092], 
reward next is 0.5982, 
noisyNet noise sample is [array([-0.19778234], dtype=float32), -0.54572576]. 
=============================================
[2019-03-24 06:01:10,639] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 3.3161930e-24 2.5889022e-28 2.4686936e-25 6.9918904e-24], sum to 1.0000
[2019-03-24 06:01:10,644] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3005
[2019-03-24 06:01:10,651] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1129642.077666019 W.
[2019-03-24 06:01:10,654] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.16666666666667, 83.16666666666667, 1.0, 2.0, 0.492663482688112, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7846191922531266, 6.911199999999999, 6.9112, 121.9260426156618, 1129642.077666019, 1129642.07766602, 254329.5034617003], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4936200.0000, 
sim time next is 4936800.0000, 
raw observation next is [24.93333333333333, 84.33333333333334, 1.0, 2.0, 0.4293319141646038, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6838538987369368, 6.911199999999999, 6.9112, 121.9260426156618, 985865.3936582508, 985865.3936582512, 233215.3949850147], 
processed observation next is [1.0, 0.13043478260869565, 0.47901234567901224, 0.8433333333333334, 1.0, 1.0, 0.32063323114833786, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6048173734211709, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3520947834493753, 0.3520947834493754, 0.44849114420195135], 
reward next is 0.5515, 
noisyNet noise sample is [array([-0.49611798], dtype=float32), 0.24412589]. 
=============================================
[2019-03-24 06:01:15,494] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.7569441e-37 0.0000000e+00 7.2168681e-38 4.8152892e-38], sum to 1.0000
[2019-03-24 06:01:15,506] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8978
[2019-03-24 06:01:15,513] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 878843.061899797 W.
[2019-03-24 06:01:15,515] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.3, 72.0, 1.0, 2.0, 0.7710655715635285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 878843.061899797, 878843.061899797, 190040.5169942562], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5059200.0000, 
sim time next is 5059800.0000, 
raw observation next is [30.45, 70.5, 1.0, 2.0, 0.3880266847389057, 1.0, 1.0, 0.3880266847389057, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 884531.3215484503, 884531.3215484507, 202928.1052958699], 
processed observation next is [0.0, 0.5652173913043478, 0.6833333333333333, 0.705, 1.0, 1.0, 0.27146033897488775, 1.0, 0.5, 0.27146033897488775, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3159040434101608, 0.315904043410161, 0.39024635633821136], 
reward next is 0.6098, 
noisyNet noise sample is [array([0.2604852], dtype=float32), 1.5650158]. 
=============================================
[2019-03-24 06:01:16,452] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:01:16,458] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9305
[2019-03-24 06:01:16,462] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.75, 98.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8896331685006772, 6.911199999999999, 6.9112, 121.9260426156618, 652355.9523323843, 652355.9523323848, 174300.9313129316], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5028600.0000, 
sim time next is 5029200.0000, 
raw observation next is [22.7, 98.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.881305983670415, 6.9112, 6.9112, 121.9260426156618, 647086.9596785632, 647086.9596785632, 173016.8348168271], 
processed observation next is [0.0, 0.21739130434782608, 0.39629629629629626, 0.98, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8516324795880187, 0.0, 0.0, 0.8094621288201359, 0.23110248559948685, 0.23110248559948685, 0.3327246823400521], 
reward next is 0.6673, 
noisyNet noise sample is [array([0.5579168], dtype=float32), 1.4107612]. 
=============================================
[2019-03-24 06:01:25,257] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-24 06:01:25,259] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:01:25,260] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:01:25,261] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:01:25,261] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:01:25,262] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:01:25,264] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:01:25,266] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:01:25,266] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:01:25,266] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:01:25,270] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:01:25,287] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run32
[2019-03-24 06:01:25,316] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run32
[2019-03-24 06:01:25,340] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run32
[2019-03-24 06:01:25,342] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run32
[2019-03-24 06:01:25,366] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run32
[2019-03-24 06:01:27,042] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00460417], dtype=float32), 0.012926742]
[2019-03-24 06:01:27,043] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.05, 26.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5698957956059293, 6.911200000000001, 6.9112, 121.9260426156618, 406924.3908711756, 406924.3908711751, 112221.3872945206]
[2019-03-24 06:01:27,043] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:01:27,045] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 2.7932276e-32 3.8975474e-38 6.7628445e-34 1.9970067e-32], sampled 0.9598369733041854
[2019-03-24 06:01:31,155] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00460417], dtype=float32), 0.012926742]
[2019-03-24 06:01:31,156] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.4, 60.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5025904604247828, 6.9112, 6.9112, 121.9260426156618, 361810.0666512928, 361810.0666512928, 116332.1803878362]
[2019-03-24 06:01:31,156] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:01:31,159] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 4.5896451e-32 7.0667599e-38 1.1578302e-33 3.3076389e-32], sampled 0.022180470076356262
[2019-03-24 06:01:55,029] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00460417], dtype=float32), 0.012926742]
[2019-03-24 06:01:55,029] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [32.0, 52.0, 1.0, 2.0, 0.8302168724108324, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1661429.693629229, 1661429.693629229, 342313.8094852532]
[2019-03-24 06:01:55,030] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:01:55,033] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 2.0937499e-22 7.4033191e-26 3.3376553e-23 8.4868317e-22], sampled 0.8599056492655905
[2019-03-24 06:01:55,036] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1661429.693629229 W.
[2019-03-24 06:02:00,476] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00460417], dtype=float32), 0.012926742]
[2019-03-24 06:02:00,478] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.58333333333334, 77.33333333333333, 1.0, 2.0, 0.7558303548069666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 867849.9915538419, 867849.9915538419, 187308.5186207627]
[2019-03-24 06:02:00,479] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:02:00,483] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 4.9504331e-24 8.0811318e-28 6.1902872e-25 1.8202953e-23], sampled 0.07111701777361479
[2019-03-24 06:02:00,484] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 867849.9915538419 W.
[2019-03-24 06:02:01,675] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00460417], dtype=float32), 0.012926742]
[2019-03-24 06:02:01,676] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.73333333333333, 96.0, 1.0, 2.0, 0.7132525565242277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 840686.3226648556, 840686.3226648556, 179987.6837736572]
[2019-03-24 06:02:01,677] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:02:01,680] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 7.3447328e-24 1.2659397e-27 9.3332934e-25 2.6638040e-23], sampled 0.8123211707812485
[2019-03-24 06:02:01,681] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 840686.3226648556 W.
[2019-03-24 06:02:09,874] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00460417], dtype=float32), 0.012926742]
[2019-03-24 06:02:09,876] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.39134352, 99.07033390000001, 1.0, 2.0, 0.8174192139925333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156399, 931708.0082988649, 931708.0082988645, 199572.4067207392]
[2019-03-24 06:02:09,877] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:02:09,880] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.0245770e-24 1.2217731e-28 1.1726679e-25 3.6160437e-24], sampled 0.7059449599428845
[2019-03-24 06:02:09,882] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 931708.0082988649 W.
[2019-03-24 06:02:26,511] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00460417], dtype=float32), 0.012926742]
[2019-03-24 06:02:26,512] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.0, 94.0, 1.0, 2.0, 0.6189211917261989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 729117.3273615327, 729117.3273615327, 162460.3979046158]
[2019-03-24 06:02:26,513] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:02:26,515] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 3.5668297e-26 1.5344341e-30 2.6416273e-27 7.9054827e-26], sampled 0.28477944876369343
[2019-03-24 06:02:26,517] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 729117.3273615327 W.
[2019-03-24 06:02:51,488] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00460417], dtype=float32), 0.012926742]
[2019-03-24 06:02:51,490] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.66320787, 72.44960845, 1.0, 2.0, 0.7534026237056466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 859837.6858836621, 859837.6858836621, 186554.3251978865]
[2019-03-24 06:02:51,491] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:02:51,493] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.1699289e-25 8.6326206e-30 1.1395533e-26 3.7395332e-25], sampled 0.592158211571712
[2019-03-24 06:02:51,495] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 859837.6858836621 W.
[2019-03-24 06:03:09,061] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00460417], dtype=float32), 0.012926742]
[2019-03-24 06:03:09,062] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [32.80732287, 55.79615013, 1.0, 2.0, 0.844648639476644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 962764.0561542663, 962764.0561542659, 205339.718725022]
[2019-03-24 06:03:09,063] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:03:09,066] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 5.7287123e-23 1.2866954e-26 7.5984605e-24 1.7955309e-22], sampled 0.7499109442069808
[2019-03-24 06:03:09,068] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 962764.0561542663 W.
[2019-03-24 06:03:10,307] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 06:03:10,633] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 06:03:10,668] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.6923 2219214790.8967 543.0000
[2019-03-24 06:03:10,687] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8559.5106 2258278767.0965 536.0000
[2019-03-24 06:03:10,799] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 06:03:11,816] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 775000, evaluation results [775000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8559.510645911187, 2258278767.096507, 536.0, 8633.692344897423, 2219214790.896723, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 06:03:14,148] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 3.9065223e-16 1.9108416e-17 8.5635044e-17 6.5588391e-15], sum to 1.0000
[2019-03-24 06:03:14,160] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7728
[2019-03-24 06:03:14,165] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2004968.310320345 W.
[2019-03-24 06:03:14,169] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.95, 76.0, 1.0, 2.0, 0.5859552593469366, 1.0, 2.0, 0.5859552593469366, 1.0, 1.0, 0.9328598561108503, 6.911200000000001, 6.9112, 121.94756008, 2004968.310320345, 2004968.310320345, 387776.4117344524], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5225400.0000, 
sim time next is 5226000.0000, 
raw observation next is [27.96666666666667, 77.0, 1.0, 2.0, 0.8834766406651495, 1.0, 2.0, 0.8834766406651495, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156521, 2015345.335427829, 2015345.33542783, 379455.7278890199], 
processed observation next is [1.0, 0.4782608695652174, 0.5913580246913581, 0.77, 1.0, 1.0, 0.8612817150775589, 1.0, 1.0, 0.8612817150775589, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288200715, 0.7197661912242247, 0.719766191224225, 0.7297225536327305], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.6443145], dtype=float32), 1.2137545]. 
=============================================
[2019-03-24 06:03:14,188] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[21.960155]
 [22.004114]
 [21.78981 ]
 [22.054937]
 [21.906248]], R is [[21.75640488]
 [21.53884125]
 [21.3234539 ]
 [21.11021996]
 [21.21415901]].
[2019-03-24 06:03:15,969] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 7.4039970e-26 1.9223829e-28 5.6169762e-27 3.3544898e-24], sum to 1.0000
[2019-03-24 06:03:15,974] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4119
[2019-03-24 06:03:15,982] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 817308.0289711765 W.
[2019-03-24 06:03:15,985] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.8, 87.33333333333334, 1.0, 2.0, 0.3585528491632323, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5708278131189317, 6.911199999999999, 6.9112, 121.9260426156618, 817308.0289711765, 817308.0289711768, 211657.7219091716], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5258400.0000, 
sim time next is 5259000.0000, 
raw observation next is [26.7, 87.66666666666667, 1.0, 2.0, 0.3577166251834743, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5694965173092432, 6.9112, 6.9112, 121.9260426156618, 815400.8732488728, 815400.8732488728, 211413.4898821319], 
processed observation next is [1.0, 0.8695652173913043, 0.5444444444444444, 0.8766666666666667, 1.0, 1.0, 0.23537693474223131, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.46187064663655397, 0.0, 0.0, 0.8094621288201359, 0.29121459758888313, 0.29121459758888313, 0.4065644036194844], 
reward next is 0.5934, 
noisyNet noise sample is [array([-0.46966243], dtype=float32), 0.53945845]. 
=============================================
[2019-03-24 06:03:16,005] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[32.218082]
 [31.96021 ]
 [31.459501]
 [31.76827 ]
 [31.419043]], R is [[33.05728912]
 [33.31967926]
 [33.64044952]
 [33.30404663]
 [32.9710083 ]].
[2019-03-24 06:03:18,095] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 5.5791737e-21 3.4922064e-23 4.8375905e-21 6.8827998e-19], sum to 1.0000
[2019-03-24 06:03:18,102] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7740
[2019-03-24 06:03:18,109] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1802120.509957189 W.
[2019-03-24 06:03:18,113] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.4, 66.0, 1.0, 2.0, 0.5267323973782129, 1.0, 2.0, 0.5267323973782129, 1.0, 2.0, 0.8385751311026811, 6.911200000000001, 6.9112, 121.94756008, 1802120.509957189, 1802120.509957189, 356903.319205047], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5328000.0000, 
sim time next is 5328600.0000, 
raw observation next is [28.41666666666667, 66.16666666666667, 1.0, 2.0, 0.9401997317511978, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1786974.175128122, 1786974.175128122, 365786.107818542], 
processed observation next is [1.0, 0.6956521739130435, 0.6080246913580248, 0.6616666666666667, 1.0, 1.0, 0.9288092044657116, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6382050625457579, 0.6382050625457579, 0.7034348227279653], 
reward next is 0.2966, 
noisyNet noise sample is [array([1.388144], dtype=float32), 0.80036616]. 
=============================================
[2019-03-24 06:03:25,756] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.2077875e-21 9.5659356e-24 9.8328066e-23 4.3834724e-21], sum to 1.0000
[2019-03-24 06:03:25,765] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1282
[2019-03-24 06:03:25,771] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1046323.895025218 W.
[2019-03-24 06:03:25,774] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.2, 94.0, 1.0, 2.0, 0.3059690486957747, 1.0, 1.0, 0.3059690486957747, 1.0, 1.0, 0.4871126902399163, 6.911199999999999, 6.9112, 121.94756008, 1046323.895025218, 1046323.895025218, 258345.6208616319], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5455800.0000, 
sim time next is 5456400.0000, 
raw observation next is [26.2, 94.0, 1.0, 2.0, 0.306402496758662, 1.0, 2.0, 0.306402496758662, 1.0, 2.0, 0.4878027536724508, 6.911199999999999, 6.9112, 121.94756008, 1047807.172851237, 1047807.172851237, 258512.9018328228], 
processed observation next is [1.0, 0.13043478260869565, 0.5259259259259259, 0.94, 1.0, 1.0, 0.17428868661745475, 1.0, 1.0, 0.17428868661745475, 1.0, 1.0, 0.3597534420905635, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.37421684744687034, 0.37421684744687034, 0.49714019583235153], 
reward next is 0.5029, 
noisyNet noise sample is [array([1.9513272], dtype=float32), -0.46882465]. 
=============================================
[2019-03-24 06:03:33,468] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 1.6540995e-32 2.4252649e-37 2.1211346e-34 3.3265688e-32], sum to 1.0000
[2019-03-24 06:03:33,474] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0271
[2019-03-24 06:03:33,485] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 725040.0403305569 W.
[2019-03-24 06:03:33,488] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.05, 97.0, 1.0, 2.0, 0.3180940382262405, 1.0, 2.0, 0.3180940382262405, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 725040.0403305569, 725040.0403305573, 184859.4341572254], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5610600.0000, 
sim time next is 5611200.0000, 
raw observation next is [23.93333333333333, 97.33333333333333, 1.0, 2.0, 0.3159301843693437, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5029711426437786, 6.911199999999999, 6.9112, 121.9260426156618, 720105.5951511037, 720105.5951511041, 199574.123184529], 
processed observation next is [1.0, 0.9565217391304348, 0.4419753086419752, 0.9733333333333333, 1.0, 1.0, 0.18563117186826633, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.3787139283047232, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.25718056969682274, 0.2571805696968229, 0.3837963907394788], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9857198], dtype=float32), -1.8526305]. 
=============================================
[2019-03-24 06:03:35,526] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.2624267e-38], sum to 1.0000
[2019-03-24 06:03:35,534] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6416
[2019-03-24 06:03:35,542] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 774956.0374055211 W.
[2019-03-24 06:03:35,546] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.5, 86.0, 1.0, 2.0, 0.3399824278096482, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5412630975276254, 6.911200000000001, 6.9112, 121.9260426156618, 774956.0374055211, 774956.0374055207, 206303.6647439417], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5652000.0000, 
sim time next is 5652600.0000, 
raw observation next is [26.65, 85.33333333333334, 1.0, 2.0, 0.2279071701889185, 1.0, 1.0, 0.2279071701889185, 1.0, 2.0, 0.3628356373591053, 6.911199999999999, 6.9112, 121.94756008, 779239.603968959, 779239.6039689594, 229927.8970994293], 
processed observation next is [0.0, 0.43478260869565216, 0.5425925925925925, 0.8533333333333334, 1.0, 1.0, 0.08084186927252204, 1.0, 0.5, 0.08084186927252204, 1.0, 1.0, 0.20354454669888158, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2782998585603425, 0.27829985856034267, 0.4421690328835179], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.7858403], dtype=float32), 0.05514776]. 
=============================================
[2019-03-24 06:03:41,229] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:03:41,233] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5554
[2019-03-24 06:03:41,236] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.0, 79.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8659672139400448, 6.911200000000001, 6.9112, 121.9260426156618, 637530.8138214416, 637530.8138214411, 170595.5576348407], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5776800.0000, 
sim time next is 5777400.0000, 
raw observation next is [24.9, 79.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8618865916358505, 6.911200000000001, 6.9112, 121.9260426156618, 634914.955542841, 634914.9555428405, 169965.1827629006], 
processed observation next is [0.0, 0.8695652173913043, 0.47777777777777775, 0.7966666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8273582395448131, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22675534126530036, 0.2267553412653002, 0.3268561206978858], 
reward next is 0.6731, 
noisyNet noise sample is [array([-1.9151828], dtype=float32), -0.7692346]. 
=============================================
[2019-03-24 06:03:41,588] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:03:41,599] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8558
[2019-03-24 06:03:41,602] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.33333333333333, 89.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7100218985655387, 6.911200000000001, 6.9112, 121.9260426156618, 530571.3370742662, 530571.3370742657, 146257.9365047987], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5728200.0000, 
sim time next is 5728800.0000, 
raw observation next is [21.36666666666667, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7075216614496765, 6.911200000000001, 6.9112, 121.9260426156618, 528712.0161820297, 528712.0161820293, 145904.5853112974], 
processed observation next is [0.0, 0.30434782608695654, 0.3469135802469137, 0.89, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6344020768120956, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1888257200650106, 0.18882572006501044, 0.2805857409832642], 
reward next is 0.7194, 
noisyNet noise sample is [array([-0.7803832], dtype=float32), -0.59048116]. 
=============================================
[2019-03-24 06:03:41,824] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:03:41,832] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3756
[2019-03-24 06:03:41,838] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.73333333333333, 76.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.895460267669339, 6.9112, 6.9112, 121.9260426156618, 656377.8886854197, 656377.8886854197, 175124.8073525844], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5773200.0000, 
sim time next is 5773800.0000, 
raw observation next is [25.56666666666667, 77.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8905281461983638, 6.9112, 6.9112, 121.9260426156618, 653332.2396659272, 653332.2396659272, 174347.134464237], 
processed observation next is [0.0, 0.8260869565217391, 0.5024691358024692, 0.7733333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8631601827479548, 0.0, 0.0, 0.8094621288201359, 0.23333294273783117, 0.23333294273783117, 0.33528295089276344], 
reward next is 0.6647, 
noisyNet noise sample is [array([0.09673111], dtype=float32), -0.7291644]. 
=============================================
[2019-03-24 06:03:54,496] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:03:54,503] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1899
[2019-03-24 06:03:54,509] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.46666666666667, 57.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8112895303213197, 6.911199999999999, 6.9112, 121.9260426156618, 598902.7697247445, 598902.769724745, 163159.0018080569], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6025200.0000, 
sim time next is 6025800.0000, 
raw observation next is [28.33333333333333, 58.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.823738843632531, 6.911200000000001, 6.9112, 121.9260426156618, 608219.6954214588, 608219.6954214583, 164715.8450916203], 
processed observation next is [1.0, 0.7391304347826086, 0.6049382716049381, 0.5833333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7796735545406638, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21722131979337814, 0.21722131979337797, 0.31676124056080823], 
reward next is 0.6832, 
noisyNet noise sample is [array([-0.19477604], dtype=float32), -0.07685801]. 
=============================================
[2019-03-24 06:03:58,786] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 9.9783326e-28 4.3343670e-30 9.4499268e-28 2.6026913e-24], sum to 1.0000
[2019-03-24 06:03:58,795] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7120
[2019-03-24 06:03:58,799] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1725679.222713349 W.
[2019-03-24 06:03:58,804] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.23333333333333, 64.16666666666667, 1.0, 2.0, 0.7566168655070454, 1.0, 2.0, 0.7566168655070454, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1725679.222713349, 1725679.22271335, 326152.5163107719], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6088200.0000, 
sim time next is 6088800.0000, 
raw observation next is [28.36666666666667, 63.33333333333334, 1.0, 2.0, 0.504237011570292, 1.0, 2.0, 0.504237011570292, 1.0, 1.0, 0.8027617442729024, 6.9112, 6.9112, 121.94756008, 1725082.274715647, 1725082.274715647, 345673.4852807595], 
processed observation next is [1.0, 0.4782608695652174, 0.606172839506173, 0.6333333333333334, 1.0, 1.0, 0.4098059661551095, 1.0, 1.0, 0.4098059661551095, 1.0, 0.5, 0.7534521803411278, 0.0, 0.0, 0.8096049824067558, 0.6161008123984454, 0.6161008123984454, 0.6647567024629991], 
reward next is 0.3352, 
noisyNet noise sample is [array([0.1200757], dtype=float32), -0.8646414]. 
=============================================
[2019-03-24 06:04:01,132] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-24 06:04:01,133] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:04:01,133] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:04:01,133] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:04:01,133] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:04:01,135] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:04:01,136] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:04:01,136] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:04:01,134] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:04:01,138] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:04:01,138] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:04:01,156] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run33
[2019-03-24 06:04:01,157] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run33
[2019-03-24 06:04:01,157] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run33
[2019-03-24 06:04:01,180] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run33
[2019-03-24 06:04:01,226] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run33
[2019-03-24 06:04:14,853] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00518782], dtype=float32), 0.013607092]
[2019-03-24 06:04:14,855] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [17.86666666666667, 84.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4834279832301255, 6.9112, 6.9112, 121.9260426156618, 346574.2047903889, 346574.2047903889, 114353.1223463465]
[2019-03-24 06:04:14,856] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:04:14,858] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.7886014509041197
[2019-03-24 06:05:00,843] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00518782], dtype=float32), 0.013607092]
[2019-03-24 06:05:00,844] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.92011782, 92.49773399, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6841562510824012, 6.911200000000001, 6.9112, 121.9260426156618, 511259.4692156691, 511259.4692156687, 143146.3633032382]
[2019-03-24 06:05:00,845] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:05:00,847] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.0619477e-37 0.0000000e+00 2.3749007e-38 1.1580537e-36], sampled 0.5352508590530394
[2019-03-24 06:05:08,225] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00518782], dtype=float32), 0.013607092]
[2019-03-24 06:05:08,226] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [33.22162039, 69.88884798666666, 1.0, 2.0, 0.5095761589397193, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8112618407689212, 6.911200000000001, 6.9112, 121.9258708886982, 1161821.080360445, 1161821.080360445, 260340.9589897204]
[2019-03-24 06:05:08,228] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:05:08,231] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.2516812e-37 0.0000000e+00 7.2540188e-38 1.7020201e-35], sampled 0.3159212840112148
[2019-03-24 06:05:08,232] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1161821.080360445 W.
[2019-03-24 06:05:13,956] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00518782], dtype=float32), 0.013607092]
[2019-03-24 06:05:13,959] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.0, 75.0, 1.0, 2.0, 0.8551442501396527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 974734.9784946394, 974734.9784946394, 207609.3354108164]
[2019-03-24 06:05:13,959] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:05:13,961] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.42676892932214927
[2019-03-24 06:05:13,965] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 974734.9784946394 W.
[2019-03-24 06:05:25,526] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00518782], dtype=float32), 0.013607092]
[2019-03-24 06:05:25,527] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.7, 66.0, 1.0, 2.0, 0.6874543206431588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 783496.1442088834, 783496.1442088834, 173781.9309474041]
[2019-03-24 06:05:25,527] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:05:25,529] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.3917377929549767
[2019-03-24 06:05:25,531] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 783496.1442088834 W.
[2019-03-24 06:05:36,926] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00518782], dtype=float32), 0.013607092]
[2019-03-24 06:05:36,927] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.66666666666666, 96.0, 1.0, 2.0, 0.725962122682758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 827407.4240463487, 827407.4240463487, 181113.577504888]
[2019-03-24 06:05:36,928] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:05:36,931] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.7776563e-35 0.0000000e+00 1.1559578e-35 2.3788690e-33], sampled 0.008640509238177496
[2019-03-24 06:05:36,932] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 827407.4240463487 W.
[2019-03-24 06:05:45,945] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 06:05:46,198] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 06:05:46,396] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 06:05:46,495] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 06:05:46,563] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 06:05:47,578] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 800000, evaluation results [800000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 06:05:59,845] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 6.6285993e-34 5.7912293e-36 1.5389447e-34 3.6733376e-32], sum to 1.0000
[2019-03-24 06:05:59,853] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0462
[2019-03-24 06:05:59,859] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 769257.1866328277 W.
[2019-03-24 06:05:59,862] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.2, 58.0, 1.0, 2.0, 0.2249890386770459, 1.0, 2.0, 0.2249890386770459, 1.0, 1.0, 0.3581898769552957, 6.9112, 6.9112, 121.94756008, 769257.1866328277, 769257.1866328277, 228931.5653666481], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6372000.0000, 
sim time next is 6372600.0000, 
raw observation next is [31.08333333333333, 58.66666666666667, 1.0, 2.0, 0.3369779187100774, 1.0, 2.0, 0.3369779187100774, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 768104.1271832448, 768104.1271832453, 189571.58892243], 
processed observation next is [0.0, 0.782608695652174, 0.7067901234567899, 0.5866666666666667, 1.0, 1.0, 0.21068799846437783, 1.0, 1.0, 0.21068799846437783, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27432290256544456, 0.2743229025654447, 0.36456074792775], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8670688], dtype=float32), 1.4328351]. 
=============================================
[2019-03-24 06:06:07,087] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 6.1380135e-18 1.5956660e-18 2.2595322e-17 2.4757616e-14], sum to 1.0000
[2019-03-24 06:06:07,095] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7920
[2019-03-24 06:06:07,102] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2185589.811314614 W.
[2019-03-24 06:06:07,105] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.56666666666667, 79.5, 1.0, 2.0, 0.9580163071913933, 1.0, 2.0, 0.9580163071913933, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156156, 2185589.811314614, 2185589.811314615, 413376.4129081852], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6519000.0000, 
sim time next is 6519600.0000, 
raw observation next is [28.7, 79.0, 1.0, 2.0, 0.9693950646845628, 1.0, 2.0, 0.9693950646845628, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2211581.120136419, 2211581.120136419, 418723.8310960166], 
processed observation next is [1.0, 0.4782608695652174, 0.6185185185185185, 0.79, 1.0, 1.0, 0.9635655531959081, 1.0, 1.0, 0.9635655531959081, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.789850400048721, 0.789850400048721, 0.8052381367231088], 
reward next is 0.1948, 
noisyNet noise sample is [array([-0.796713], dtype=float32), 0.67051417]. 
=============================================
[2019-03-24 06:06:07,327] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.8979131e-22 9.2154429e-26 7.0801939e-24 3.8219036e-21], sum to 1.0000
[2019-03-24 06:06:07,333] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4293
[2019-03-24 06:06:07,337] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 759639.0151001698 W.
[2019-03-24 06:06:07,341] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.16666666666667, 79.0, 1.0, 2.0, 0.2221773501566422, 1.0, 1.0, 0.2221773501566422, 1.0, 2.0, 0.3537135772605107, 6.9112, 6.9112, 121.94756008, 759639.0151001698, 759639.0151001698, 227976.0810360539], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6484800.0000, 
sim time next is 6485400.0000, 
raw observation next is [27.1, 79.5, 1.0, 2.0, 0.3335487672780876, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5310205004316854, 6.911199999999999, 6.9112, 121.9260426156618, 760283.8769871064, 760283.8769871069, 204480.6343079271], 
processed observation next is [1.0, 0.043478260869565216, 0.5592592592592593, 0.795, 1.0, 1.0, 0.20660567533105664, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.4137756255396067, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27152995606682373, 0.2715299560668239, 0.393231989053706], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6954783], dtype=float32), 0.43077058]. 
=============================================
[2019-03-24 06:06:13,017] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 6.7852678e-36 7.0331971e-38 6.9811944e-34 2.0008086e-35], sum to 1.0000
[2019-03-24 06:06:13,024] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6306
[2019-03-24 06:06:13,024] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 981584.0069962221 W.
[2019-03-24 06:06:13,029] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.08333333333333, 49.5, 1.0, 2.0, 0.7804024692859128, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 981584.0069962221, 981584.0069962221, 195374.1389831059], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6617400.0000, 
sim time next is 6618000.0000, 
raw observation next is [25.86666666666667, 47.0, 1.0, 2.0, 0.2897590914817789, 1.0, 1.0, 0.2897590914817789, 1.0, 1.0, 0.4793298261273063, 6.911200000000001, 6.9112, 121.94756008, 1074626.110209109, 1074626.110209109, 250195.5035073931], 
processed observation next is [1.0, 0.6086956521739131, 0.5135802469135804, 0.47, 1.0, 1.0, 0.15447510890687965, 1.0, 0.5, 0.15447510890687965, 1.0, 0.5, 0.34916228265913285, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.3837950393603961, 0.3837950393603961, 0.481145199052679], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.5412586], dtype=float32), 0.6522415]. 
=============================================
[2019-03-24 06:06:13,042] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[47.94345 ]
 [47.478756]
 [46.550438]
 [46.817295]
 [45.810722]], R is [[46.17044067]
 [46.33301544]
 [46.45460129]
 [46.4973526 ]
 [46.56442642]].
[2019-03-24 06:06:15,573] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:06:15,578] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5113
[2019-03-24 06:06:15,583] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 45.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5595488211198687, 6.911200000000001, 6.9112, 121.9260426156618, 399534.3522952533, 399534.3522952528, 114236.5523967859], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6667200.0000, 
sim time next is 6667800.0000, 
raw observation next is [22.98333333333333, 44.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5610944545551131, 6.9112, 6.9112, 121.9260426156618, 400638.268411719, 400638.268411719, 113966.6486877635], 
processed observation next is [1.0, 0.17391304347826086, 0.40679012345679005, 0.4483333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4513680681938913, 0.0, 0.0, 0.8094621288201359, 0.14308509586132823, 0.14308509586132823, 0.2191666320918529], 
reward next is 0.7808, 
noisyNet noise sample is [array([-1.0023834], dtype=float32), -0.9141426]. 
=============================================
[2019-03-24 06:06:21,365] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.5125161e-26 1.5173408e-27 1.4085461e-26 2.0171135e-23], sum to 1.0000
[2019-03-24 06:06:21,372] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1879
[2019-03-24 06:06:21,384] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1011991.043100271 W.
[2019-03-24 06:06:21,390] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.16666666666667, 53.00000000000001, 1.0, 2.0, 0.4085271063441852, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6773184747196497, 6.911199999999999, 6.9112, 121.9260426156618, 1011991.043100271, 1011991.043100271, 223075.7649081073], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6776400.0000, 
sim time next is 6777000.0000, 
raw observation next is [25.35, 52.5, 1.0, 2.0, 0.2765206632802967, 1.0, 1.0, 0.2765206632802967, 1.0, 2.0, 0.4534242234323433, 6.9112, 6.9112, 121.94756008, 1016724.341521665, 1016724.341521665, 245760.9790150119], 
processed observation next is [1.0, 0.43478260869565216, 0.4944444444444445, 0.525, 1.0, 1.0, 0.13871507533368652, 1.0, 0.5, 0.13871507533368652, 1.0, 1.0, 0.31678027929042907, 0.0, 0.0, 0.8096049824067558, 0.3631158362577375, 0.3631158362577375, 0.47261726733656134], 
reward next is 0.5274, 
noisyNet noise sample is [array([-0.610173], dtype=float32), -0.5524677]. 
=============================================
[2019-03-24 06:06:21,410] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[38.6028  ]
 [37.73035 ]
 [37.70816 ]
 [37.760826]
 [38.24884 ]], R is [[38.47445679]
 [38.66072083]
 [38.2741127 ]
 [38.48233414]
 [38.6314621 ]].
[2019-03-24 06:06:23,829] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:06:23,838] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4757
[2019-03-24 06:06:23,846] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.86666666666667, 78.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7095418730091834, 6.9112, 6.9112, 121.9260426156618, 530189.3394483243, 530189.3394483243, 146339.9154125814], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6828600.0000, 
sim time next is 6829200.0000, 
raw observation next is [22.8, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7037602088615721, 6.9112, 6.9112, 121.9260426156618, 525901.6028709458, 525901.6028709458, 145476.2290760244], 
processed observation next is [0.0, 0.043478260869565216, 0.4, 0.78, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.629700261076965, 0.0, 0.0, 0.8094621288201359, 0.1878220010253378, 0.1878220010253378, 0.2797619789923546], 
reward next is 0.7202, 
noisyNet noise sample is [array([1.1099074], dtype=float32), -0.41047993]. 
=============================================
[2019-03-24 06:06:27,666] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:06:27,667] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2548
[2019-03-24 06:06:27,686] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.1, 50.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7152041692909558, 6.9112, 6.9112, 121.9260426156618, 534180.3803324989, 534180.3803324989, 147657.9295850639], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6865200.0000, 
sim time next is 6865800.0000, 
raw observation next is [28.26666666666667, 50.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7209856601728991, 6.911200000000001, 6.9112, 121.9260426156618, 538382.4795429893, 538382.4795429888, 148521.2853940236], 
processed observation next is [0.0, 0.4782608695652174, 0.6024691358024692, 0.5, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6512320752161238, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19227945697963902, 0.19227945697963886, 0.28561785652696847], 
reward next is 0.7144, 
noisyNet noise sample is [array([-1.0146782], dtype=float32), 0.773687]. 
=============================================
[2019-03-24 06:06:30,234] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:06:30,244] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5930
[2019-03-24 06:06:30,249] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.33333333333334, 51.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8666869708671926, 6.911200000000001, 6.9112, 121.9260426156618, 637023.1647379935, 637023.164737993, 170954.946114816], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6960000.0000, 
sim time next is 6960600.0000, 
raw observation next is [30.5, 50.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8703028441710153, 6.9112, 6.9112, 121.9260426156618, 639294.0155717502, 639294.0155717502, 171516.6513472252], 
processed observation next is [0.0, 0.5652173913043478, 0.6851851851851852, 0.505, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8378785552137691, 0.0, 0.0, 0.8094621288201359, 0.22831929127562509, 0.22831929127562509, 0.32983971412927926], 
reward next is 0.6702, 
noisyNet noise sample is [array([-0.63299376], dtype=float32), -0.11250689]. 
=============================================
[2019-03-24 06:06:32,732] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:06:32,739] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2094
[2019-03-24 06:06:32,741] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.56666666666667, 57.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7377334506771692, 6.911200000000001, 6.9112, 121.9260426156618, 551063.4179216876, 551063.4179216871, 150116.6065076141], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6983400.0000, 
sim time next is 6984000.0000, 
raw observation next is [26.3, 58.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7325994612259126, 6.911200000000001, 6.9112, 121.9260426156618, 547326.2919595592, 547326.2919595587, 149285.2102671816], 
processed observation next is [0.0, 0.8695652173913043, 0.5296296296296297, 0.58, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6657493265323907, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19547367569984256, 0.1954736756998424, 0.28708694282150304], 
reward next is 0.7129, 
noisyNet noise sample is [array([1.8216045], dtype=float32), -0.13581201]. 
=============================================
[2019-03-24 06:06:32,760] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[68.31878 ]
 [68.34979 ]
 [68.37602 ]
 [68.37176 ]
 [68.412384]], R is [[68.31718445]
 [68.34532166]
 [68.37178802]
 [68.39673615]
 [68.42014313]].
[2019-03-24 06:06:32,934] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:06:32,949] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2465
[2019-03-24 06:06:32,954] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.2, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6870428801602344, 6.9112, 6.9112, 121.9260426156618, 513231.1795302689, 513231.1795302689, 142418.4661284554], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7005600.0000, 
sim time next is 7006200.0000, 
raw observation next is [22.11666666666667, 79.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9560153003795288, 8.689419005682478, 6.9112, 122.0372492819628, 1626114.167735703, 714676.5522232375, 169442.5798363363], 
processed observation next is [1.0, 0.08695652173913043, 0.3746913580246915, 0.7966666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9450191254744108, 0.17782190056824776, 0.0, 0.8102004254375924, 0.5807550599056083, 0.2552416257940134, 0.3258511150698775], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.9286065], dtype=float32), -0.6102835]. 
=============================================
[2019-03-24 06:06:33,615] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:06:33,626] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0167
[2019-03-24 06:06:33,629] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.9, 75.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6928747600268695, 6.911199999999999, 6.9112, 121.9260426156618, 517697.902152799, 517697.9021527995, 143392.3379489017], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7000800.0000, 
sim time next is 7001400.0000, 
raw observation next is [22.8, 75.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6912435201210158, 6.9112, 6.9112, 121.9260426156618, 516460.9060900605, 516460.9060900605, 143148.1232139004], 
processed observation next is [1.0, 0.0, 0.4, 0.755, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6140544001512697, 0.0, 0.0, 0.8094621288201359, 0.18445032360359304, 0.18445032360359304, 0.27528485233442385], 
reward next is 0.7247, 
noisyNet noise sample is [array([-0.8581826], dtype=float32), 0.2703957]. 
=============================================
[2019-03-24 06:06:36,134] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:06:36,141] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4453
[2019-03-24 06:06:36,146] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.51666666666667, 86.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7040093451039189, 6.911200000000001, 6.9112, 121.9260426156618, 526092.9534100988, 526092.9534100983, 145040.0419056785], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7023000.0000, 
sim time next is 7023600.0000, 
raw observation next is [21.6, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7110196154473287, 6.911200000000001, 6.9112, 121.9260426156618, 531337.0692483386, 531337.0692483381, 145862.1211613338], 
processed observation next is [1.0, 0.30434782608695654, 0.3555555555555556, 0.86, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.638774519309161, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18976323901726377, 0.1897632390172636, 0.2805040791564112], 
reward next is 0.7195, 
noisyNet noise sample is [array([0.47249374], dtype=float32), 1.119807]. 
=============================================
[2019-03-24 06:06:36,891] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:06:36,899] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5337
[2019-03-24 06:06:36,904] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.5, 81.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7814993003890661, 6.9112, 6.9112, 121.9260426156618, 581808.7571377095, 581808.7571377095, 157282.4166441853], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7075800.0000, 
sim time next is 7076400.0000, 
raw observation next is [23.5, 81.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7819941866902668, 6.9112, 6.9112, 121.9260426156618, 582093.0024440693, 582093.0024440693, 157397.7735040667], 
processed observation next is [1.0, 0.9130434782608695, 0.42592592592592593, 0.8166666666666668, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7274927333628334, 0.0, 0.0, 0.8094621288201359, 0.20789035801573902, 0.20789035801573902, 0.302688025969359], 
reward next is 0.6973, 
noisyNet noise sample is [array([0.57110286], dtype=float32), 1.2762828]. 
=============================================
[2019-03-24 06:06:37,424] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-24 06:06:37,427] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:06:37,429] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:06:37,431] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:06:37,430] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:06:37,432] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:06:37,432] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:06:37,434] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:06:37,433] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:06:37,437] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:06:37,435] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:06:37,458] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run34
[2019-03-24 06:06:37,459] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run34
[2019-03-24 06:06:37,508] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run34
[2019-03-24 06:06:37,509] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run34
[2019-03-24 06:06:37,543] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run34
[2019-03-24 06:06:55,058] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00570713], dtype=float32), 0.013661251]
[2019-03-24 06:06:55,059] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [33.79209298, 33.66235645166667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7073996688727183, 6.911199999999999, 6.9112, 121.9260426156618, 526774.5088171834, 526774.5088171839, 148437.475625093]
[2019-03-24 06:06:55,060] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:06:55,062] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.19128871435697148
[2019-03-24 06:07:32,758] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00570713], dtype=float32), 0.013661251]
[2019-03-24 06:07:32,759] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.21975458166666, 87.03164773833333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7793278059253907, 6.911200000000001, 6.9112, 121.9260426156618, 578855.7390476118, 578855.7390476114, 157776.3068346057]
[2019-03-24 06:07:32,759] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:07:32,765] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.34622647676813123
[2019-03-24 06:07:46,632] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00570713], dtype=float32), 0.013661251]
[2019-03-24 06:07:46,633] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.83333333333334, 56.66666666666666, 1.0, 2.0, 1.01788228780945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.254844396800668, 6.9112, 121.924380933615, 1336479.706931692, 1160505.459498539, 245067.2435370147]
[2019-03-24 06:07:46,634] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:07:46,637] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.2028347e-38], sampled 0.8762782349041311
[2019-03-24 06:07:46,638] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1336479.706931692 W.
[2019-03-24 06:07:53,684] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00570713], dtype=float32), 0.013661251]
[2019-03-24 06:07:53,685] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.991734185, 88.99511133333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7536202772632559, 6.911200000000001, 6.9112, 121.9260426156618, 559229.6979015329, 559229.6979015324, 154907.6441579311]
[2019-03-24 06:07:53,686] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:07:53,689] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.27867286240635325
[2019-03-24 06:08:22,626] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 06:08:22,706] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.2390 2292980111.6144 697.0000
[2019-03-24 06:08:22,707] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 06:08:22,979] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 06:08:22,994] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 06:08:24,008] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 825000, evaluation results [825000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.238967854026, 2292980111.6144123, 697.0]
[2019-03-24 06:08:24,952] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:08:24,962] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8859
[2019-03-24 06:08:24,969] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.35, 75.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7185569224267183, 6.9112, 6.9112, 121.9260426156618, 536868.2627914804, 536868.2627914804, 147583.7288295291], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7090200.0000, 
sim time next is 7090800.0000, 
raw observation next is [23.33333333333334, 75.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7110086255213769, 6.911200000000001, 6.9112, 121.9260426156618, 531282.5229864849, 531282.5229864845, 146518.7432120871], 
processed observation next is [1.0, 0.043478260869565216, 0.4197530864197533, 0.75, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.638760781901721, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1897437582094589, 0.18974375820945874, 0.2817668138693983], 
reward next is 0.7182, 
noisyNet noise sample is [array([-0.6592155], dtype=float32), 0.7816409]. 
=============================================
[2019-03-24 06:08:33,093] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:08:33,099] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0123
[2019-03-24 06:08:33,102] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.48333333333333, 86.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.659655850799578, 6.911200000000002, 6.9112, 121.9260426156618, 491320.6875995891, 491320.6875995882, 137520.0435283354], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7269000.0000, 
sim time next is 7269600.0000, 
raw observation next is [20.46666666666667, 86.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.634199531768187, 6.9112, 6.9112, 121.9260426156618, 472419.8146216884, 472419.8146216884, 135027.8572282793], 
processed observation next is [1.0, 0.13043478260869565, 0.31358024691358033, 0.8666666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5427494147102337, 0.0, 0.0, 0.8094621288201359, 0.16872136236488872, 0.16872136236488872, 0.2596689562082294], 
reward next is 0.7403, 
noisyNet noise sample is [array([2.136051], dtype=float32), 0.40915185]. 
=============================================
[2019-03-24 06:08:35,348] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 3.6976116e-35 2.8846791e-38 3.4183232e-35 1.2107496e-35], sum to 1.0000
[2019-03-24 06:08:35,354] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6952
[2019-03-24 06:08:35,364] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 782688.7173740042 W.
[2019-03-24 06:08:35,368] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.4, 67.83333333333333, 1.0, 2.0, 0.3273554297120721, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5275142490476428, 6.911199999999999, 6.9112, 121.9260426156618, 782688.7173740042, 782688.7173740047, 201516.9021625738], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7303800.0000, 
sim time next is 7304400.0000, 
raw observation next is [25.6, 67.0, 1.0, 2.0, 0.303892397125451, 1.0, 1.0, 0.303892397125451, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 723842.6379819181, 723842.6379819185, 182794.0726372576], 
processed observation next is [1.0, 0.5652173913043478, 0.5037037037037038, 0.67, 1.0, 1.0, 0.17130047276839408, 1.0, 0.5, 0.17130047276839408, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.25851522785068504, 0.2585152278506852, 0.35152706276395695], 
reward next is 0.6485, 
noisyNet noise sample is [array([-0.8765913], dtype=float32), -0.44847092]. 
=============================================
[2019-03-24 06:08:36,355] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:08:36,360] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1084
[2019-03-24 06:08:36,366] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.26666666666667, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6435684975639145, 6.9112, 6.9112, 121.9260426156618, 479927.6191491036, 479927.6191491036, 136526.5504293599], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7425600.0000, 
sim time next is 7426200.0000, 
raw observation next is [20.28333333333333, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6417168534878875, 6.9112, 6.9112, 121.9260426156618, 478582.9441831722, 478582.9441831722, 136383.4063476695], 
processed observation next is [1.0, 0.9565217391304348, 0.3067901234567901, 0.9, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5521460668598593, 0.0, 0.0, 0.8094621288201359, 0.17092248006541863, 0.17092248006541863, 0.26227578143782593], 
reward next is 0.7377, 
noisyNet noise sample is [array([0.2786225], dtype=float32), 0.21771957]. 
=============================================
[2019-03-24 06:08:37,051] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:08:37,058] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5122
[2019-03-24 06:08:37,062] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.7, 93.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.627649682359925, 6.911200000000001, 6.9112, 121.9260426156618, 467689.6465647605, 467689.64656476, 134529.8385306333], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7438800.0000, 
sim time next is 7439400.0000, 
raw observation next is [19.65, 93.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6263582388516441, 6.9112, 6.9112, 121.9260426156618, 466647.3483365031, 466647.3483365031, 134321.2177482813], 
processed observation next is [0.0, 0.08695652173913043, 0.28333333333333327, 0.935, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5329477985645551, 0.0, 0.0, 0.8094621288201359, 0.16665976726303683, 0.16665976726303683, 0.2583100341313102], 
reward next is 0.7417, 
noisyNet noise sample is [array([-1.2001014], dtype=float32), -1.2572565]. 
=============================================
[2019-03-24 06:08:42,782] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:08:42,790] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3288
[2019-03-24 06:08:42,795] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.2, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6395265865527904, 6.911200000000001, 6.9112, 121.9260426156618, 476775.0605382019, 476775.0605382014, 135960.8179571027], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7422000.0000, 
sim time next is 7422600.0000, 
raw observation next is [20.2, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6372510072892862, 6.911200000000001, 6.9112, 121.9260426156618, 475077.873156973, 475077.8731569726, 135732.3261662945], 
processed observation next is [1.0, 0.9130434782608695, 0.3037037037037037, 0.9, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5465637591116077, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1696706689846332, 0.16967066898463307, 0.26102370416595094], 
reward next is 0.7390, 
noisyNet noise sample is [array([-1.1658812], dtype=float32), 0.015605898]. 
=============================================
[2019-03-24 06:08:46,940] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:08:46,947] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4424
[2019-03-24 06:08:46,954] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.1, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.774544539162665, 6.911200000000001, 6.9112, 121.9260426156618, 576138.363140538, 576138.3631405375, 156743.7901639503], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7509600.0000, 
sim time next is 7510200.0000, 
raw observation next is [22.05, 93.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7733045666420534, 6.9112, 6.9112, 121.9260426156618, 575275.3882957068, 575275.3882957068, 156558.262095555], 
processed observation next is [0.0, 0.9565217391304348, 0.37222222222222223, 0.9333333333333332, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7166307083025666, 0.0, 0.0, 0.8094621288201359, 0.2054554958198953, 0.2054554958198953, 0.30107358095299036], 
reward next is 0.6989, 
noisyNet noise sample is [array([-0.22787698], dtype=float32), 2.9025438]. 
=============================================
[2019-03-24 06:09:00,191] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.4381722e-37 0.0000000e+00 1.5379321e-38 0.0000000e+00], sum to 1.0000
[2019-03-24 06:09:00,201] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5310
[2019-03-24 06:09:00,205] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.6, 65.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5653135732833602, 6.911199999999999, 6.9112, 121.9260426156618, 413934.1472864582, 413934.1472864587, 124076.8754912103], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7792200.0000, 
sim time next is 7792800.0000, 
raw observation next is [21.63333333333333, 65.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5517998451550081, 6.911200000000001, 6.9112, 121.9260426156618, 403793.0499932574, 403793.049993257, 122805.5693943506], 
processed observation next is [1.0, 0.17391304347826086, 0.35679012345678995, 0.65, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4397498064437601, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1442118035690205, 0.14421180356902036, 0.23616455652759732], 
reward next is 0.7638, 
noisyNet noise sample is [array([1.1835058], dtype=float32), -0.14725325]. 
=============================================
[2019-03-24 06:09:04,094] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:09:04,095] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:09:04,110] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run5
[2019-03-24 06:09:07,408] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:09:07,409] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:09:07,425] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run5
[2019-03-24 06:09:08,880] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:09:08,881] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:09:08,895] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run5
[2019-03-24 06:09:08,917] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:09:08,918] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:09:08,926] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run5
[2019-03-24 06:09:09,056] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:09:09,056] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:09:09,062] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run5
[2019-03-24 06:09:09,245] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:09:09,245] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:09:09,256] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run5
[2019-03-24 06:09:09,414] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:09:09,415] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:09:09,419] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run5
[2019-03-24 06:09:09,470] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:09:09,470] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:09:09,474] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run5
[2019-03-24 06:09:09,503] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:09:09,503] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:09:09,510] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run5
[2019-03-24 06:09:09,612] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:09:09,613] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:09:09,616] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run5
[2019-03-24 06:09:09,748] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:09:09,748] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:09:09,750] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run5
[2019-03-24 06:09:09,797] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:09:09,798] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:09:09,799] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run5
[2019-03-24 06:09:09,846] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:09:09,846] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:09:09,847] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run5
[2019-03-24 06:09:10,269] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:09:10,269] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:09:10,270] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run5
[2019-03-24 06:09:10,377] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:09:10,377] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:09:10,378] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run5
[2019-03-24 06:09:10,497] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:09:10,497] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:09:10,499] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run5
[2019-03-24 06:09:14,259] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-24 06:09:14,260] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:09:14,260] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:09:14,261] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:09:14,262] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:09:14,263] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:09:14,263] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:09:14,264] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:09:14,266] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:09:14,267] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:09:14,268] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:09:14,280] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run35
[2019-03-24 06:09:14,280] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run35
[2019-03-24 06:09:14,280] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run35
[2019-03-24 06:09:14,281] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run35
[2019-03-24 06:09:14,353] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run35
[2019-03-24 06:09:58,068] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00594093], dtype=float32), 0.014775671]
[2019-03-24 06:09:58,070] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.91666666666667, 82.66666666666667, 1.0, 2.0, 0.7563068118262253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 916408.3583415262, 916408.3583415262, 189481.2579551978]
[2019-03-24 06:09:58,072] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:09:58,075] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 2.4057410e-36 0.0000000e+00 1.0226071e-35 5.9689179e-34], sampled 0.1314256099829082
[2019-03-24 06:09:58,076] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 916408.3583415262 W.
[2019-03-24 06:10:02,591] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00594093], dtype=float32), 0.014775671]
[2019-03-24 06:10:02,593] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.05588382, 110.9296041, 1.0, 2.0, 0.5931709965454143, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9443475447309811, 6.911199999999999, 6.9112, 121.9260426156618, 1352583.516303143, 1352583.516303143, 291213.2459779045]
[2019-03-24 06:10:02,594] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:10:02,596] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.12432882756078834
[2019-03-24 06:10:02,598] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1352583.516303143 W.
[2019-03-24 06:10:59,917] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 06:11:00,152] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 06:11:00,179] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 06:11:00,194] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 06:11:00,435] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7840.8532 2529795142.6922 831.0000
[2019-03-24 06:11:01,453] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 850000, evaluation results [850000.0, 7840.853177063691, 2529795142.6922317, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 06:11:05,724] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 6.1599094e-37 1.1519256e-35], sum to 1.0000
[2019-03-24 06:11:05,730] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6376
[2019-03-24 06:11:05,737] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1711289.291460243 W.
[2019-03-24 06:11:05,746] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [37.4, 13.0, 1.0, 2.0, 0.8089930004279104, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9556928960728304, 6.911199999999999, 6.9112, 121.9260426156618, 1711289.291460243, 1711289.291460243, 324976.9354969075], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 139200.0000, 
sim time next is 139800.0000, 
raw observation next is [37.4, 12.5, 1.0, 2.0, 0.7106270970036986, 1.0, 1.0, 0.7106270970036986, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1747446.302688734, 1747446.302688735, 313450.8830905135], 
processed observation next is [1.0, 0.6086956521739131, 0.9407407407407407, 0.125, 1.0, 1.0, 0.6555084488139269, 1.0, 0.5, 0.6555084488139269, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6240879652459764, 0.6240879652459768, 0.602790159789449], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.15812472], dtype=float32), -2.9613142]. 
=============================================
[2019-03-24 06:11:10,889] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:11:10,894] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2774
[2019-03-24 06:11:10,898] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.46666666666667, 20.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6488752622299756, 6.911200000000001, 6.9112, 121.9260426156618, 470530.5251641605, 470530.52516416, 129719.5382196907], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 240000.0000, 
sim time next is 240600.0000, 
raw observation next is [31.23333333333333, 21.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6470719481421124, 6.911199999999999, 6.9112, 121.9260426156618, 469375.2921667987, 469375.2921667991, 129614.1478880409], 
processed observation next is [0.0, 0.782608695652174, 0.7123456790123456, 0.2133333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5588399351776405, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16763403291671383, 0.16763403291671394, 0.24925797670777095], 
reward next is 0.7507, 
noisyNet noise sample is [array([0.06654061], dtype=float32), 0.07929292]. 
=============================================
[2019-03-24 06:11:11,294] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:11:11,302] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7804
[2019-03-24 06:11:11,307] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.0, 22.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6452002525575543, 6.9112, 6.9112, 121.9260426156618, 468137.9320081045, 468137.9320081045, 129490.7040893265], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 241200.0000, 
sim time next is 241800.0000, 
raw observation next is [30.78333333333333, 22.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6439937704449364, 6.9112, 6.9112, 121.9260426156618, 467411.3756859585, 467411.3756859585, 129438.5401690046], 
processed observation next is [0.0, 0.8260869565217391, 0.695679012345679, 0.2266666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5549922130561705, 0.0, 0.0, 0.8094621288201359, 0.1669326341735566, 0.1669326341735566, 0.24892026955577806], 
reward next is 0.7511, 
noisyNet noise sample is [array([-0.57494205], dtype=float32), 1.3182545]. 
=============================================
[2019-03-24 06:11:12,341] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:11:12,349] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4794
[2019-03-24 06:11:12,354] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.43333333333333, 48.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4599226918681176, 6.911199999999999, 6.9112, 121.9260426156618, 328383.1295367532, 328383.1295367536, 94346.33054773233], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 279600.0000, 
sim time next is 280200.0000, 
raw observation next is [20.66666666666667, 47.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4614492566501836, 6.911199999999999, 6.9112, 121.9260426156618, 329473.3253577732, 329473.3253577737, 94613.84436550068], 
processed observation next is [0.0, 0.21739130434782608, 0.3209876543209878, 0.47166666666666673, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3268115708127295, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1176690447706333, 0.11766904477063346, 0.18194970070288594], 
reward next is 0.8181, 
noisyNet noise sample is [array([-1.5993549], dtype=float32), -1.6908706]. 
=============================================
[2019-03-24 06:11:29,471] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:11:29,477] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3260
[2019-03-24 06:11:29,481] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.7, 51.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5762949055473171, 6.9112, 6.9112, 121.9260426156618, 424937.7522788614, 424937.7522788614, 126467.1626581406], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 607200.0000, 
sim time next is 607800.0000, 
raw observation next is [24.55, 51.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5736959170172239, 6.911200000000001, 6.9112, 121.9260426156618, 422794.366228377, 422794.3662283766, 126115.0069744167], 
processed observation next is [1.0, 0.0, 0.46481481481481485, 0.515, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.46711989627152983, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15099798793870606, 0.15099798793870592, 0.24252885956618594], 
reward next is 0.7575, 
noisyNet noise sample is [array([1.2960567], dtype=float32), 2.1974053]. 
=============================================
[2019-03-24 06:11:30,507] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.3744765e-37], sum to 1.0000
[2019-03-24 06:11:30,517] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3191
[2019-03-24 06:11:30,522] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.33333333333334, 60.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6454252984476012, 6.9112, 6.9112, 121.9260426156618, 476952.7248635819, 476952.7248635819, 133426.7146425157], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 629400.0000, 
sim time next is 630000.0000, 
raw observation next is [23.6, 59.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.652068375885991, 6.911200000000001, 6.9112, 121.9260426156618, 482300.7318943193, 482300.7318943189, 134320.4885572785], 
processed observation next is [1.0, 0.30434782608695654, 0.4296296296296297, 0.59, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5650854698574886, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17225026139082833, 0.17225026139082816, 0.2583086318409202], 
reward next is 0.7417, 
noisyNet noise sample is [array([-1.9094571], dtype=float32), -0.046347763]. 
=============================================
[2019-03-24 06:11:30,536] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[56.16839 ]
 [56.202324]
 [56.76825 ]
 [56.73028 ]
 [57.019287]], R is [[56.24391937]
 [56.42489243]
 [56.60413361]
 [56.77912521]
 [56.95283508]].
[2019-03-24 06:11:31,367] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.2259033e-38 9.5461151e-37], sum to 1.0000
[2019-03-24 06:11:31,374] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0365
[2019-03-24 06:11:31,382] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 964808.1914754384 W.
[2019-03-24 06:11:31,389] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [34.16666666666666, 25.0, 1.0, 2.0, 0.3957297868745759, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6458695919111738, 6.911199999999999, 6.9112, 121.9260426156618, 964808.1914754384, 964808.1914754389, 220372.9767410532], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 651000.0000, 
sim time next is 651600.0000, 
raw observation next is [34.4, 24.0, 1.0, 2.0, 0.3034932343414455, 1.0, 1.0, 0.3034932343414455, 1.0, 2.0, 0.4915782126633337, 6.911200000000001, 6.9112, 121.94756008, 1098446.873589539, 1098446.873589539, 256653.4750862846], 
processed observation next is [1.0, 0.5652173913043478, 0.8296296296296296, 0.24, 1.0, 1.0, 0.1708252789779113, 1.0, 0.5, 0.1708252789779113, 1.0, 1.0, 0.36447276582916704, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.39230245485340676, 0.39230245485340676, 0.49356437516593193], 
reward next is 0.5064, 
noisyNet noise sample is [array([-0.4417287], dtype=float32), -0.4862708]. 
=============================================
[2019-03-24 06:11:41,615] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:11:41,623] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1415
[2019-03-24 06:11:41,627] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.5, 36.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7190120323128096, 6.9112, 6.9112, 121.9260426156618, 536902.7485832652, 536902.7485832652, 148306.3532651199], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 838200.0000, 
sim time next is 838800.0000, 
raw observation next is [31.4, 37.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7168122669205949, 6.9112, 6.9112, 121.9260426156618, 535318.7071283328, 535318.7071283328, 147956.9298486078], 
processed observation next is [0.0, 0.7391304347826086, 0.7185185185185184, 0.37, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6460153336507435, 0.0, 0.0, 0.8094621288201359, 0.19118525254583316, 0.19118525254583316, 0.28453255740116884], 
reward next is 0.7155, 
noisyNet noise sample is [array([-1.478147], dtype=float32), -0.94219977]. 
=============================================
[2019-03-24 06:11:42,859] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:11:42,866] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6250
[2019-03-24 06:11:42,872] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.91666666666666, 51.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5019448079236557, 6.911200000000001, 6.9112, 121.9260426156618, 361761.0121232748, 361761.0121232743, 116431.8546249511], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 949800.0000, 
sim time next is 950400.0000, 
raw observation next is [22.8, 52.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4999962773617797, 6.911199999999999, 6.9112, 121.9260426156618, 360203.8783045569, 360203.8783045574, 116225.4293405314], 
processed observation next is [1.0, 0.0, 0.4, 0.52, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3749953467022246, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12864424225162746, 0.12864424225162766, 0.22351044103948345], 
reward next is 0.7765, 
noisyNet noise sample is [array([1.0007101], dtype=float32), -0.87508774]. 
=============================================
[2019-03-24 06:11:49,342] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 2.8964010e-30 6.6347502e-33 9.2205581e-30 1.0927507e-25], sum to 1.0000
[2019-03-24 06:11:49,348] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1430
[2019-03-24 06:11:49,354] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1092316.504269962 W.
[2019-03-24 06:11:49,359] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.2, 55.0, 1.0, 2.0, 0.2983671527581166, 1.0, 1.0, 0.2983671527581166, 1.0, 1.0, 0.4873623647394994, 6.911200000000001, 6.9112, 121.94756008, 1092316.504269962, 1092316.504269962, 254200.0129838766], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 993600.0000, 
sim time next is 994200.0000, 
raw observation next is [25.21666666666667, 54.66666666666667, 1.0, 2.0, 0.9239966280943936, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.168881753555199, 6.9112, 121.9250276051794, 1276508.994310402, 1144554.003665013, 226828.5965376804], 
processed observation next is [1.0, 0.5217391304347826, 0.48950617283950626, 0.5466666666666667, 1.0, 1.0, 0.9095197953504687, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.02576817535551994, 0.0, 0.8094553902060693, 0.4558960693965722, 0.4087692870232189, 0.43620883949553924], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.5213808], dtype=float32), 0.11874307]. 
=============================================
[2019-03-24 06:11:50,206] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-24 06:11:50,210] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:11:50,211] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:11:50,211] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:11:50,212] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:11:50,212] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:11:50,213] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:11:50,213] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:11:50,213] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:11:50,214] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:11:50,214] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:11:50,233] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run36
[2019-03-24 06:11:50,257] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run36
[2019-03-24 06:11:50,258] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run36
[2019-03-24 06:11:50,286] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run36
[2019-03-24 06:11:50,352] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run36
[2019-03-24 06:12:05,197] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00603804], dtype=float32), 0.015009394]
[2019-03-24 06:12:05,198] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [32.5, 24.5, 1.0, 2.0, 0.7497594921281161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156589, 940812.8028217267, 940812.8028217267, 189016.9375518241]
[2019-03-24 06:12:05,200] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:12:05,202] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 2.1565389e-31 2.9105945e-34 6.1543383e-31 1.3872249e-29], sampled 0.12700230742686314
[2019-03-24 06:12:05,203] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 940812.8028217267 W.
[2019-03-24 06:12:08,174] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00603804], dtype=float32), 0.015009394]
[2019-03-24 06:12:08,175] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.4, 34.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6320294110927027, 6.9112, 6.9112, 121.9260426156618, 471021.7077489683, 471021.7077489683, 135034.4642082824]
[2019-03-24 06:12:08,176] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:12:08,178] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.238404753743375
[2019-03-24 06:12:43,923] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00603804], dtype=float32), 0.015009394]
[2019-03-24 06:12:43,923] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.75, 89.83333333333333, 1.0, 2.0, 0.7607694188322325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 867101.1017937029, 867101.101793702, 187970.0263312914]
[2019-03-24 06:12:43,924] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:12:43,927] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.9268701e-34 2.2104539e-37 7.6338963e-34 3.0340329e-32], sampled 0.14621757406667002
[2019-03-24 06:12:43,928] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 867101.1017937029 W.
[2019-03-24 06:12:44,958] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00603804], dtype=float32), 0.015009394]
[2019-03-24 06:12:44,960] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [30.16666666666667, 51.83333333333334, 1.0, 2.0, 0.8260209111041128, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9873503026636531, 6.911199999999999, 6.9112, 121.9260426156618, 1667536.751936807, 1667536.751936807, 339762.5434918351]
[2019-03-24 06:12:44,963] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:12:44,965] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 6.8333059e-33 1.1278541e-35 2.7039656e-32 8.7063318e-31], sampled 0.06476865556383604
[2019-03-24 06:12:44,967] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1667536.751936807 W.
[2019-03-24 06:13:00,987] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00603804], dtype=float32), 0.015009394]
[2019-03-24 06:13:00,989] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.47126295833333, 68.94452815166666, 1.0, 2.0, 0.5610951475812972, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 661807.2979385817, 661807.2979385813, 152531.6129033348]
[2019-03-24 06:13:00,991] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:13:00,999] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.9017418359560341
[2019-03-24 06:13:32,982] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00603804], dtype=float32), 0.015009394]
[2019-03-24 06:13:32,983] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [16.35, 79.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3623106587839664, 6.9112, 6.9112, 121.9260426156618, 258676.7401159817, 258676.7401159817, 86998.31312703303]
[2019-03-24 06:13:32,984] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:13:32,988] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.9546277068870161
[2019-03-24 06:13:36,396] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 06:13:36,410] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 06:13:36,442] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 06:13:36,443] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 06:13:36,459] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 06:13:37,472] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 875000, evaluation results [875000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 06:13:37,869] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 1.1297425e-31 2.8678662e-33 1.3653996e-30 1.6950276e-29], sum to 1.0000
[2019-03-24 06:13:37,876] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8970
[2019-03-24 06:13:37,881] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1157167.609505892 W.
[2019-03-24 06:13:37,887] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.5, 46.5, 1.0, 2.0, 0.3160335567360517, 1.0, 2.0, 0.3160335567360517, 1.0, 2.0, 0.5162663685639389, 6.9112, 6.9112, 121.94756008, 1157167.609505892, 1157167.609505892, 261035.404271831], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1007400.0000, 
sim time next is 1008000.0000, 
raw observation next is [26.6, 46.0, 1.0, 2.0, 0.3137851822249648, 1.0, 2.0, 0.3137851822249648, 1.0, 2.0, 0.5121754340600578, 6.911199999999999, 6.9112, 121.94756008, 1147801.22671324, 1147801.226713241, 260202.8147965601], 
processed observation next is [1.0, 0.6956521739130435, 0.5407407407407407, 0.46, 1.0, 1.0, 0.1830775978868629, 1.0, 1.0, 0.1830775978868629, 1.0, 1.0, 0.39021929257507226, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.4099290095404428, 0.40992900954044326, 0.5003900284549233], 
reward next is 0.4996, 
noisyNet noise sample is [array([0.0827973], dtype=float32), 0.94985145]. 
=============================================
[2019-03-24 06:13:37,910] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[43.420727]
 [43.820263]
 [44.499577]
 [43.98711 ]
 [43.388336]], R is [[43.4978714 ]
 [43.56090164]
 [43.12529373]
 [43.35284042]
 [42.91931152]].
[2019-03-24 06:13:38,024] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.7743807e-31 4.0489879e-32 4.3042662e-29 1.2987468e-27], sum to 1.0000
[2019-03-24 06:13:38,030] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6542
[2019-03-24 06:13:38,037] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1061259.432930315 W.
[2019-03-24 06:13:38,042] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.58333333333333, 51.5, 1.0, 2.0, 0.4289838267493348, 0.0, 2.0, 0.0, 1.0, 1.0, 0.710114559134518, 6.911199999999999, 6.9112, 121.9259496829293, 1061259.432930315, 1061259.432930315, 229582.7042938383], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1001400.0000, 
sim time next is 1002000.0000, 
raw observation next is [25.66666666666667, 51.0, 1.0, 2.0, 0.8817774479430333, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.92314662137796, 6.9112, 121.9259493965536, 1105075.839532633, 1098958.106287559, 217276.0298212209], 
processed observation next is [1.0, 0.6086956521739131, 0.506172839506173, 0.51, 1.0, 1.0, 0.8592588665988491, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0011946621377959764, 0.0, 0.8094615099421986, 0.3946699426902261, 0.3924850379598425, 0.4178385188869633], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.03726924], dtype=float32), 0.6395799]. 
=============================================
[2019-03-24 06:13:38,056] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[43.166855]
 [42.456642]
 [42.504986]
 [41.6553  ]
 [41.8338  ]], R is [[42.4858551 ]
 [42.06099701]
 [41.64038849]
 [41.70812607]
 [41.29104614]].
[2019-03-24 06:13:38,373] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 3.2683416e-33 2.1508820e-35 1.7365788e-32 4.2962849e-33], sum to 1.0000
[2019-03-24 06:13:38,381] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4072
[2019-03-24 06:13:38,388] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 893022.6935292521 W.
[2019-03-24 06:13:38,398] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.23333333333333, 54.33333333333334, 1.0, 2.0, 0.7184003635201903, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426119398, 893022.6935292521, 893022.6935292521, 182552.9895882402], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 994800.0000, 
sim time next is 995400.0000, 
raw observation next is [25.25, 54.0, 1.0, 2.0, 0.6470592863216801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156607, 807497.2961021778, 807497.2961021778, 168976.186858132], 
processed observation next is [1.0, 0.5217391304347826, 0.49074074074074076, 0.54, 1.0, 1.0, 0.5798324837162858, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201287, 0.2883918914650635, 0.2883918914650635, 0.3249542054964077], 
reward next is 0.6750, 
noisyNet noise sample is [array([-0.39062703], dtype=float32), 0.3848387]. 
=============================================
[2019-03-24 06:13:41,409] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:13:41,413] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2471
[2019-03-24 06:13:41,421] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.75, 69.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5774466527602328, 6.911200000000001, 6.9112, 121.9260426156618, 420819.3717497817, 420819.3717497812, 124277.8844425222], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1049400.0000, 
sim time next is 1050000.0000, 
raw observation next is [20.7, 69.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5649986721952794, 6.9112, 6.9112, 121.9260426156618, 411730.6132241195, 411730.6132241195, 123204.3706054838], 
processed observation next is [1.0, 0.13043478260869565, 0.3222222222222222, 0.6933333333333332, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.45624834024409927, 0.0, 0.0, 0.8094621288201359, 0.14704664758004266, 0.14704664758004266, 0.23693148193362268], 
reward next is 0.7631, 
noisyNet noise sample is [array([0.4088914], dtype=float32), -0.7657378]. 
=============================================
[2019-03-24 06:13:41,436] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[58.273323]
 [58.530575]
 [59.032093]
 [59.681065]
 [59.835373]], R is [[58.21511459]
 [58.39397049]
 [58.57035065]
 [58.73651505]
 [58.91830826]].
[2019-03-24 06:13:50,873] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.7679508e-36 1.7973606e-37 1.6429403e-36 1.9886292e-32], sum to 1.0000
[2019-03-24 06:13:50,882] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1988
[2019-03-24 06:13:50,890] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 899986.6367897426 W.
[2019-03-24 06:13:50,894] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.26666666666667, 60.0, 1.0, 2.0, 0.3688108513379147, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6024047237897229, 6.911200000000001, 6.9112, 121.9260426037195, 899986.6367897426, 899986.6367897422, 212269.360626813], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1257600.0000, 
sim time next is 1258200.0000, 
raw observation next is [25.45, 59.5, 1.0, 2.0, 0.7743829922701768, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156582, 950788.9138733493, 950788.9138733493, 193581.8235034705], 
processed observation next is [1.0, 0.5652173913043478, 0.4981481481481481, 0.595, 1.0, 1.0, 0.7314083241311629, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.809462128820112, 0.3395674692404819, 0.3395674692404819, 0.37227273750667406], 
reward next is 0.6277, 
noisyNet noise sample is [array([-0.16299242], dtype=float32), 2.4022417]. 
=============================================
[2019-03-24 06:13:56,340] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 7.0974487e-31 2.0562975e-34 4.6277751e-33 5.4337417e-28], sum to 1.0000
[2019-03-24 06:13:56,354] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2399
[2019-03-24 06:13:56,359] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1399659.996770517 W.
[2019-03-24 06:13:56,362] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.9, 30.0, 1.0, 2.0, 0.9442793768856808, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.345409594718348, 6.9112, 121.9242345964229, 1399659.996770517, 1177309.172310596, 231802.7722904205], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1353600.0000, 
sim time next is 1354200.0000, 
raw observation next is [30.91666666666666, 29.66666666666666, 1.0, 2.0, 0.5904664097542436, 1.0, 1.0, 0.5904664097542436, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9257811421462, 1451330.103502248, 1451330.103502247, 268956.0301079511], 
processed observation next is [1.0, 0.6956521739130435, 0.7006172839506171, 0.29666666666666663, 1.0, 1.0, 0.5124600116121947, 1.0, 0.5, 0.5124600116121947, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094603929079057, 0.5183321798222315, 0.5183321798222311, 0.5172231348229829], 
reward next is 0.4828, 
noisyNet noise sample is [array([0.43446675], dtype=float32), 0.33424965]. 
=============================================
[2019-03-24 06:13:58,872] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:13:58,878] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0356
[2019-03-24 06:13:58,883] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.9, 65.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5181273640465938, 6.9112, 6.9112, 121.9260426156618, 374944.4511863582, 374944.4511863582, 118258.9031109607], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1393200.0000, 
sim time next is 1393800.0000, 
raw observation next is [20.86666666666667, 64.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5144348525715902, 6.911199999999999, 6.9112, 121.9260426156618, 371734.8119741779, 371734.8119741784, 117763.3953683943], 
processed observation next is [0.0, 0.13043478260869565, 0.3283950617283952, 0.6466666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3930435657144877, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13276243284792066, 0.13276243284792086, 0.2264680680161429], 
reward next is 0.7735, 
noisyNet noise sample is [array([-0.75870866], dtype=float32), 1.1458212]. 
=============================================
[2019-03-24 06:13:59,061] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:13:59,071] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3867
[2019-03-24 06:13:59,079] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.35, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5490140620816003, 6.911200000000001, 6.9112, 121.9260426156618, 401914.990996273, 401914.9909962725, 122640.0051159273], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1387800.0000, 
sim time next is 1388400.0000, 
raw observation next is [21.26666666666667, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5459851468133904, 6.9112, 6.9112, 121.9260426156618, 399236.7643035965, 399236.7643035965, 122178.4296125197], 
processed observation next is [0.0, 0.043478260869565216, 0.34320987654320995, 0.67, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.43248143351673796, 0.0, 0.0, 0.8094621288201359, 0.1425845586798559, 0.1425845586798559, 0.2349585184856148], 
reward next is 0.7650, 
noisyNet noise sample is [array([-0.31832263], dtype=float32), 2.3416772]. 
=============================================
[2019-03-24 06:14:02,148] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:14:02,153] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8719
[2019-03-24 06:14:02,160] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.35, 27.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6301431864007885, 6.911200000000001, 6.9112, 121.9260426156618, 467163.2539017937, 467163.2539017932, 132880.3584337604], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1452600.0000, 
sim time next is 1453200.0000, 
raw observation next is [31.2, 27.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6284086101994706, 6.9112, 6.9112, 121.9260426156618, 465587.7458674674, 465587.7458674674, 132526.8146057346], 
processed observation next is [0.0, 0.8260869565217391, 0.7111111111111111, 0.2766666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5355107627493382, 0.0, 0.0, 0.8094621288201359, 0.1662813378098098, 0.1662813378098098, 0.2548592588571819], 
reward next is 0.7451, 
noisyNet noise sample is [array([-1.839208], dtype=float32), 1.3198037]. 
=============================================
[2019-03-24 06:14:03,665] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:14:03,675] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1142
[2019-03-24 06:14:03,681] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.78333333333333, 52.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6775568075136456, 6.911200000000001, 6.9112, 121.9260426156618, 506180.8026779687, 506180.8026779682, 141515.4843127279], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1497000.0000, 
sim time next is 1497600.0000, 
raw observation next is [27.1, 51.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6810672757417513, 6.9112, 6.9112, 121.9260426156618, 508856.9253882226, 508856.9253882226, 142062.7117053291], 
processed observation next is [0.0, 0.34782608695652173, 0.5592592592592593, 0.51, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6013340946771891, 0.0, 0.0, 0.8094621288201359, 0.1817346162100795, 0.1817346162100795, 0.27319752251024826], 
reward next is 0.7268, 
noisyNet noise sample is [array([-0.07724882], dtype=float32), -1.3045985]. 
=============================================
[2019-03-24 06:14:06,291] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.3274517e-36 1.1353777e-36], sum to 1.0000
[2019-03-24 06:14:06,300] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2972
[2019-03-24 06:14:06,311] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.2, 71.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8141445525534752, 6.9112, 6.9112, 121.9260426156618, 605144.8280509411, 605144.8280509411, 161883.7250833926], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1539000.0000, 
sim time next is 1539600.0000, 
raw observation next is [24.7, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8085021231563295, 6.911199999999999, 6.9112, 121.9260426156618, 601367.0922144965, 601367.0922144969, 160944.3007887581], 
processed observation next is [0.0, 0.8260869565217391, 0.4703703703703703, 0.74, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7606276539454118, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2147739615051773, 0.21477396150517747, 0.3095082707476117], 
reward next is 0.6905, 
noisyNet noise sample is [array([0.64938307], dtype=float32), -0.4956261]. 
=============================================
[2019-03-24 06:14:06,481] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 8.8952996e-32 1.5448044e-32 1.5849119e-31 1.3439966e-28], sum to 1.0000
[2019-03-24 06:14:06,491] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8237
[2019-03-24 06:14:06,494] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 821006.4329695402 W.
[2019-03-24 06:14:06,499] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.35, 77.5, 1.0, 2.0, 0.2233097334150373, 1.0, 2.0, 0.2233097334150373, 1.0, 1.0, 0.3661863248599585, 6.911200000000001, 6.9112, 121.94756008, 821006.4329695402, 821006.4329695398, 226878.8758878407], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1564200.0000, 
sim time next is 1564800.0000, 
raw observation next is [21.23333333333333, 78.0, 1.0, 2.0, 0.5969937481336666, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426155736, 743146.6627448535, 743146.6627448535, 159895.9940960547], 
processed observation next is [1.0, 0.08695652173913043, 0.34197530864197523, 0.78, 1.0, 1.0, 0.5202306525400793, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288195504, 0.2654095224088763, 0.2654095224088763, 0.30749229633856673], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.0342139], dtype=float32), 1.143943]. 
=============================================
[2019-03-24 06:14:10,461] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:14:10,463] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3619
[2019-03-24 06:14:10,471] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.95, 50.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5765180034319525, 6.911200000000001, 6.9112, 121.9260426156618, 425904.6863787399, 425904.6863787394, 126926.7442211612], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1630200.0000, 
sim time next is 1630800.0000, 
raw observation next is [24.8, 51.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5743307618056781, 6.9112, 6.9112, 121.9260426156618, 423949.2353047241, 423949.2353047241, 126539.9456107889], 
processed observation next is [1.0, 0.9130434782608695, 0.4740740740740741, 0.51, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4679134522570976, 0.0, 0.0, 0.8094621288201359, 0.1514104411802586, 0.1514104411802586, 0.24334604925151712], 
reward next is 0.7567, 
noisyNet noise sample is [array([-1.6602422], dtype=float32), 0.19837762]. 
=============================================
[2019-03-24 06:14:13,845] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:14:13,851] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2285
[2019-03-24 06:14:13,856] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.3, 75.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7001147658691209, 6.911200000000001, 6.9112, 121.9260426156618, 523172.8795674267, 523172.8795674262, 145107.2989396444], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1710000.0000, 
sim time next is 1710600.0000, 
raw observation next is [23.25, 75.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7031609436387749, 6.911200000000001, 6.9112, 121.9260426156618, 525436.5758148564, 525436.575814856, 145538.8146758001], 
processed observation next is [1.0, 0.8260869565217391, 0.4166666666666667, 0.7566666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6289511795484687, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1876559199338773, 0.18765591993387715, 0.27988233591500017], 
reward next is 0.7201, 
noisyNet noise sample is [array([-0.6022155], dtype=float32), 1.2950728]. 
=============================================
[2019-03-24 06:14:15,571] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:14:15,583] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5480
[2019-03-24 06:14:15,588] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.1, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6308060563053021, 6.911200000000001, 6.9112, 121.9260426156618, 470018.1671646133, 470018.1671646129, 134818.0293551415], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1735200.0000, 
sim time next is 1735800.0000, 
raw observation next is [21.03333333333333, 82.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9019059129435748, 6.911200000000001, 6.9112, 121.9260426156618, 672048.9774859407, 672048.9774859402, 164599.6558086752], 
processed observation next is [1.0, 0.08695652173913043, 0.3345679012345678, 0.8233333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8773823911794684, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24001749195926453, 0.24001749195926436, 0.3165377996320677], 
reward next is 0.6835, 
noisyNet noise sample is [array([0.1032011], dtype=float32), -1.0178071]. 
=============================================
[2019-03-24 06:14:17,847] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.3486850e-29 2.1895971e-31 1.3389145e-29 6.7517878e-26], sum to 1.0000
[2019-03-24 06:14:17,853] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3657
[2019-03-24 06:14:17,859] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1570109.211055322 W.
[2019-03-24 06:14:17,863] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.26666666666667, 59.66666666666667, 1.0, 2.0, 0.7285832690463656, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9736095809238313, 6.9112, 6.9112, 121.9260426156618, 1570109.211055322, 1570109.211055322, 317808.9575567417], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1780800.0000, 
sim time next is 1781400.0000, 
raw observation next is [27.63333333333333, 58.83333333333334, 1.0, 2.0, 0.6855424913443445, 1.0, 1.0, 0.6855424913443445, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1598345.990444015, 1598345.990444015, 300436.8383350455], 
processed observation next is [1.0, 0.6086956521739131, 0.5790123456790122, 0.5883333333333334, 1.0, 1.0, 0.6256458230289815, 1.0, 0.5, 0.6256458230289815, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5708378537300054, 0.5708378537300054, 0.5777631506443183], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.3237172], dtype=float32), -0.73784536]. 
=============================================
[2019-03-24 06:14:18,195] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 5.9560894e-34 1.9696517e-37 6.3152653e-34 2.0821970e-33], sum to 1.0000
[2019-03-24 06:14:18,201] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6098
[2019-03-24 06:14:18,204] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.43333333333334, 88.33333333333334, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7003233396588483, 6.911200000000001, 6.9112, 121.9260426156618, 523320.5525635294, 523320.5525635289, 145192.4633280404], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1876800.0000, 
sim time next is 1877400.0000, 
raw observation next is [21.4, 88.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6963931810560616, 6.911200000000001, 6.9112, 121.9260426156618, 520401.1798603097, 520401.1798603093, 144592.6908408511], 
processed observation next is [1.0, 0.7391304347826086, 0.3481481481481481, 0.885, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.620491476320077, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1858575642358249, 0.18585756423582475, 0.27806286700163674], 
reward next is 0.7219, 
noisyNet noise sample is [array([0.5358477], dtype=float32), 0.027156856]. 
=============================================
[2019-03-24 06:14:18,447] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 2.7364297e-35 1.4495357e-36 6.7798118e-35 8.0638095e-32], sum to 1.0000
[2019-03-24 06:14:18,458] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3850
[2019-03-24 06:14:18,467] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1273399.574611861 W.
[2019-03-24 06:14:18,470] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.03333333333333, 67.16666666666667, 1.0, 2.0, 0.5332044134904587, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8585949856930548, 6.911200000000001, 6.9112, 121.9260426156393, 1273399.574611861, 1273399.574611861, 267290.0890157667], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1770600.0000, 
sim time next is 1771200.0000, 
raw observation next is [25.1, 67.0, 1.0, 2.0, 0.3556857973601874, 1.0, 1.0, 0.3556857973601874, 1.0, 2.0, 0.569802754238108, 6.911200000000001, 6.9112, 121.94756008, 1258498.400124287, 1258498.400124286, 278112.8273624257], 
processed observation next is [1.0, 0.5217391304347826, 0.4851851851851852, 0.67, 1.0, 1.0, 0.2329592825716517, 1.0, 0.5, 0.2329592825716517, 1.0, 1.0, 0.462253442797635, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.4494637143301025, 0.4494637143301022, 0.534832360312357], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1405983], dtype=float32), -2.370419]. 
=============================================
[2019-03-24 06:14:22,309] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 1.6933090e-36 0.0000000e+00 2.5933338e-33 1.4622345e-32], sum to 1.0000
[2019-03-24 06:14:22,315] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9670
[2019-03-24 06:14:22,316] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 948334.4640130724 W.
[2019-03-24 06:14:22,318] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.7, 86.0, 1.0, 2.0, 0.2633775902151297, 1.0, 2.0, 0.2633775902151297, 1.0, 1.0, 0.425299389656202, 6.911200000000001, 6.9112, 121.94756008, 948334.4640130724, 948334.464013072, 241820.2052097281], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1868400.0000, 
sim time next is 1869000.0000, 
raw observation next is [21.68333333333333, 86.16666666666667, 1.0, 2.0, 0.4822579119274407, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7818008543592904, 6.911199999999999, 6.9112, 121.9260426156618, 1165226.867658236, 1165226.867658237, 248798.5638625346], 
processed observation next is [1.0, 0.6521739130434783, 0.35864197530864184, 0.8616666666666667, 1.0, 1.0, 0.3836403713421913, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.7272510679491129, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.41615245273508433, 0.41615245273508467, 0.4784587766587204], 
reward next is 0.5215, 
noisyNet noise sample is [array([0.4594666], dtype=float32), -0.8944165]. 
=============================================
[2019-03-24 06:14:22,336] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[52.15153 ]
 [52.137367]
 [52.18573 ]
 [51.319347]
 [52.10318 ]], R is [[51.46487808]
 [50.95022964]
 [50.44072723]
 [50.52736282]
 [50.02209091]].
[2019-03-24 06:14:24,183] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:14:24,190] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3129
[2019-03-24 06:14:24,196] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.26666666666667, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6586118938299026, 6.911200000000001, 6.9112, 121.9260426156618, 491677.7582625075, 491677.758262507, 138785.2337710832], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1902000.0000, 
sim time next is 1902600.0000, 
raw observation next is [20.2, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6534621769380664, 6.911200000000001, 6.9112, 121.9260426156618, 487721.0829431233, 487721.0829431229, 138078.166663423], 
processed observation next is [1.0, 0.0, 0.3037037037037037, 0.92, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.566827721172583, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17418610105111546, 0.17418610105111532, 0.2655349358911981], 
reward next is 0.7345, 
noisyNet noise sample is [array([2.1455224], dtype=float32), 0.32095352]. 
=============================================
[2019-03-24 06:14:26,258] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-24 06:14:26,259] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:14:26,260] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:14:26,261] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:14:26,260] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:14:26,261] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:14:26,262] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:14:26,263] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:14:26,264] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:14:26,265] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:14:26,268] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:14:26,280] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run37
[2019-03-24 06:14:26,307] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run37
[2019-03-24 06:14:26,307] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run37
[2019-03-24 06:14:26,331] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run37
[2019-03-24 06:14:26,388] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run37
[2019-03-24 06:14:33,776] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00636726], dtype=float32), 0.015187028]
[2019-03-24 06:14:33,778] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.25, 28.5, 1.0, 2.0, 0.6079938606085511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 768919.7395536802, 768919.7395536802, 162042.8446079275]
[2019-03-24 06:14:33,780] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:14:33,782] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 7.6361523e-38], sampled 0.8959910717960692
[2019-03-24 06:14:33,784] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 768919.7395536802 W.
[2019-03-24 06:14:35,226] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00636726], dtype=float32), 0.015187028]
[2019-03-24 06:14:35,228] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [30.95, 25.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6244578954758829, 6.9112, 6.9112, 121.9260426156618, 458991.5483983823, 458991.5483983823, 130143.1708828906]
[2019-03-24 06:14:35,229] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:14:35,230] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.03799310703113734
[2019-03-24 06:14:58,654] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00636726], dtype=float32), 0.015187028]
[2019-03-24 06:14:58,656] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.249699915, 49.704011475, 1.0, 2.0, 0.727904158402462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 925390.11205083, 925390.11205083, 184763.7233588373]
[2019-03-24 06:14:58,658] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:14:58,660] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 3.1522870e-38 0.0000000e+00 1.1715384e-37 3.4165613e-36], sampled 0.8766526347822956
[2019-03-24 06:14:58,663] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 925390.11205083 W.
[2019-03-24 06:16:03,565] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00636726], dtype=float32), 0.015187028]
[2019-03-24 06:16:03,566] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.0, 28.0, 1.0, 2.0, 0.6087334660570235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 765097.0102218478, 765097.0102218478, 162110.9248975953]
[2019-03-24 06:16:03,569] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:16:03,571] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.6688228132782714
[2019-03-24 06:16:03,572] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 765097.0102218478 W.
[2019-03-24 06:16:12,290] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 06:16:12,514] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 06:16:12,626] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 06:16:12,648] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 06:16:12,812] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 06:16:13,832] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 900000, evaluation results [900000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 06:16:15,764] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:16:15,774] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7723
[2019-03-24 06:16:15,780] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.6, 60.33333333333334, 1.0, 2.0, 0.2689627554163246, 1.0, 2.0, 0.2689627554163246, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 620216.3716697621, 620216.3716697621, 173542.242359853], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1963200.0000, 
sim time next is 1963800.0000, 
raw observation next is [28.45, 61.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8464683595590098, 6.911199999999999, 6.9112, 121.9260426156618, 617717.1126539863, 617717.1126539868, 169297.7105709247], 
processed observation next is [1.0, 0.7391304347826086, 0.6092592592592593, 0.615, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.8080854494487621, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22061325451928082, 0.220613254519281, 0.3255725203287014], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8199418], dtype=float32), 0.45902255]. 
=============================================
[2019-03-24 06:16:18,980] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:16:18,990] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3234
[2019-03-24 06:16:18,996] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 694462.4588256818 W.
[2019-03-24 06:16:19,003] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.13333333333333, 73.66666666666667, 1.0, 2.0, 0.3046849269760377, 1.0, 1.0, 0.3046849269760377, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 694462.4588256818, 694462.4588256822, 181588.7607408351], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2058000.0000, 
sim time next is 2058600.0000, 
raw observation next is [27.01666666666667, 74.33333333333333, 1.0, 2.0, 0.3039805169853803, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4839468829950118, 6.911199999999999, 6.9112, 121.9260426156618, 692856.185198978, 692856.1851989785, 196317.9423341288], 
processed observation next is [0.0, 0.8260869565217391, 0.5561728395061729, 0.7433333333333333, 1.0, 1.0, 0.171405377363548, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.35493360374376476, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24744863757106358, 0.24744863757106375, 0.37753450448870923], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.41578352], dtype=float32), 1.409919]. 
=============================================
[2019-03-24 06:16:19,042] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.2111139e-35 1.2020505e-37], sum to 1.0000
[2019-03-24 06:16:19,052] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3149
[2019-03-24 06:16:19,059] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1363663.169301924 W.
[2019-03-24 06:16:19,063] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.63333333333334, 91.66666666666667, 1.0, 2.0, 0.3986838091201957, 1.0, 2.0, 0.3986838091201957, 1.0, 2.0, 0.6347176083445387, 6.9112, 6.9112, 121.94756008, 1363663.169301924, 1363663.169301924, 296506.0492844079], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2200800.0000, 
sim time next is 2201400.0000, 
raw observation next is [24.8, 91.0, 1.0, 2.0, 0.5799513509866107, 1.0, 2.0, 0.5799513509866107, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426155601, 1322413.277956359, 1322413.277956359, 261215.5044679669], 
processed observation next is [1.0, 0.4782608695652174, 0.4740740740740741, 0.91, 1.0, 1.0, 0.4999420845078698, 1.0, 1.0, 0.4999420845078698, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288194608, 0.4722904564129854, 0.4722904564129854, 0.502337508592244], 
reward next is 0.4977, 
noisyNet noise sample is [array([-1.4757113], dtype=float32), -0.15758793]. 
=============================================
[2019-03-24 06:16:22,041] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:16:22,049] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5144
[2019-03-24 06:16:22,055] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.1, 98.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9072783218213872, 6.911200000000001, 6.9112, 121.9260426156618, 662573.5889974631, 662573.5889974626, 177191.35049467], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2253600.0000, 
sim time next is 2254200.0000, 
raw observation next is [22.95, 98.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9766194991003011, 8.043130998252185, 6.9112, 121.9219127779227, 1294155.596858012, 714525.3886119861, 183484.9622089437], 
processed observation next is [1.0, 0.08695652173913043, 0.4055555555555555, 0.98, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9707743738753762, 0.11319309982521845, 0.0, 0.8094347109922768, 0.46219842744929, 0.255187638789995, 0.35285569655566096], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.49101233], dtype=float32), -0.27073136]. 
=============================================
[2019-03-24 06:16:41,061] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:16:41,070] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4317
[2019-03-24 06:16:41,074] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.5, 65.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5195252555284818, 6.9112, 6.9112, 121.9260426156618, 378915.3677143677, 378915.3677143677, 119549.21856209], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2440800.0000, 
sim time next is 2441400.0000, 
raw observation next is [22.06666666666667, 62.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6158554590125995, 6.911200000000001, 6.9112, 121.9260426156618, 450508.8200909126, 450508.8200909122, 128361.7997736271], 
processed observation next is [1.0, 0.2608695652173913, 0.3728395061728396, 0.6283333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5198193237657494, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16089600717532593, 0.1608960071753258, 0.2468496149492829], 
reward next is 0.7532, 
noisyNet noise sample is [array([1.644873], dtype=float32), 0.47370517]. 
=============================================
[2019-03-24 06:16:42,924] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:16:42,931] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0140
[2019-03-24 06:16:42,935] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.43333333333334, 44.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6260908461430177, 6.911199999999999, 6.9112, 121.9260426156618, 466101.4700213551, 466101.4700213555, 133964.842674363], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2500800.0000, 
sim time next is 2501400.0000, 
raw observation next is [27.26666666666667, 45.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6262344593742164, 6.911200000000001, 6.9112, 121.9260426156618, 466268.9511834961, 466268.9511834957, 134034.3280737826], 
processed observation next is [1.0, 0.9565217391304348, 0.5654320987654322, 0.4516666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5327930742177704, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16652462542267718, 0.16652462542267704, 0.2577583232188127], 
reward next is 0.7422, 
noisyNet noise sample is [array([0.39331272], dtype=float32), 1.792325]. 
=============================================
[2019-03-24 06:16:46,407] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 7.9837485e-37 6.8113271e-37 2.2085850e-35 4.1099544e-34], sum to 1.0000
[2019-03-24 06:16:46,411] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8176
[2019-03-24 06:16:46,418] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1477316.600293867 W.
[2019-03-24 06:16:46,421] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.0, 30.0, 1.0, 2.0, 0.4108169396863368, 1.0, 1.0, 0.4108169396863368, 1.0, 2.0, 0.6627852459966507, 6.9112, 6.9112, 121.94756008, 1477316.600293867, 1477316.600293867, 301457.0958289193], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2545200.0000, 
sim time next is 2545800.0000, 
raw observation next is [32.1, 30.0, 1.0, 2.0, 0.6496399672972826, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9576720548213261, 6.911200000000001, 6.9112, 121.9260426156618, 1502427.966305993, 1502427.966305993, 297537.4750065402], 
processed observation next is [1.0, 0.4782608695652174, 0.7444444444444445, 0.3, 1.0, 1.0, 0.5829047229729555, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9470900685266576, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5365814165378546, 0.5365814165378546, 0.5721874519356542], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.52684057], dtype=float32), 0.017099341]. 
=============================================
[2019-03-24 06:16:49,628] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:16:49,646] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3921
[2019-03-24 06:16:49,652] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.6, 64.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8075885568647464, 6.9112, 6.9112, 121.9260426156618, 599791.3945577956, 599791.3945577956, 161306.6183621371], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2584800.0000, 
sim time next is 2585400.0000, 
raw observation next is [26.35, 65.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8063137502213491, 6.911200000000001, 6.9112, 121.9260426156618, 598922.0960266674, 598922.0960266669, 161108.7520310846], 
processed observation next is [1.0, 0.9565217391304348, 0.5314814814814816, 0.6533333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7578921877766864, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21390074858095265, 0.21390074858095248, 0.3098245231367011], 
reward next is 0.6902, 
noisyNet noise sample is [array([-1.8451899], dtype=float32), 0.2601545]. 
=============================================
[2019-03-24 06:16:52,315] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:16:52,320] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5321
[2019-03-24 06:16:52,323] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9046883340227069, 6.9112, 6.9112, 121.9260426156618, 663101.7677438912, 663101.7677438912, 176357.8887978343], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2670000.0000, 
sim time next is 2670600.0000, 
raw observation next is [24.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9055184116039113, 6.911199999999999, 6.9112, 121.9260426156618, 663708.6495365291, 663708.6495365296, 176468.7348891917], 
processed observation next is [0.0, 0.9130434782608695, 0.4444444444444444, 0.89, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.881898014504889, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23703880340590325, 0.23703880340590341, 0.33936295170998404], 
reward next is 0.6606, 
noisyNet noise sample is [array([0.4017517], dtype=float32), 0.10447954]. 
=============================================
[2019-03-24 06:16:54,439] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:16:54,449] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7732
[2019-03-24 06:16:54,451] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.66666666666667, 78.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.815567983223835, 6.911200000000001, 6.9112, 121.9260426156618, 604473.9438091654, 604473.9438091649, 162861.8170059821], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2706600.0000, 
sim time next is 2707200.0000, 
raw observation next is [24.8, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8334983023840898, 6.911200000000001, 6.9112, 121.9260426156618, 616238.4676442355, 616238.467644235, 165673.4125867051], 
processed observation next is [0.0, 0.34782608695652173, 0.4740740740740741, 0.79, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7918728779801123, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2200851670157984, 0.22008516701579822, 0.3186027165128944], 
reward next is 0.6814, 
noisyNet noise sample is [array([-0.11311852], dtype=float32), 0.38142443]. 
=============================================
[2019-03-24 06:16:54,621] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:16:54,629] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1060
[2019-03-24 06:16:54,631] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.75, 59.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8852099866010991, 6.9112, 6.9112, 121.9260426156618, 648790.5872865408, 648790.5872865408, 173789.9564085089], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2718600.0000, 
sim time next is 2719200.0000, 
raw observation next is [29.0, 58.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8821499559351377, 6.911200000000001, 6.9112, 121.9260426156618, 646913.2783311206, 646913.2783311201, 173308.3331421227], 
processed observation next is [0.0, 0.4782608695652174, 0.6296296296296297, 0.58, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.852687444918922, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23104045654682878, 0.23104045654682862, 0.3332852560425436], 
reward next is 0.6667, 
noisyNet noise sample is [array([-1.862935], dtype=float32), 0.33253214]. 
=============================================
[2019-03-24 06:16:57,594] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.00000000e+00 5.26766935e-20 7.39304111e-20 1.87258119e-18
 1.37139284e-14], sum to 1.0000
[2019-03-24 06:16:57,599] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1604
[2019-03-24 06:16:57,604] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 793487.2784934413 W.
[2019-03-24 06:16:57,610] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.16666666666666, 89.0, 1.0, 2.0, 0.682072979951491, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 793487.2784934413, 793487.2784934408, 173561.9020031039], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2787000.0000, 
sim time next is 2787600.0000, 
raw observation next is [24.33333333333333, 89.0, 1.0, 2.0, 0.3473748321192359, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5535687711246748, 6.9112, 6.9112, 121.9260426156618, 800852.667112868, 800852.667112868, 208252.5362370031], 
processed observation next is [1.0, 0.2608695652173913, 0.45679012345678993, 0.89, 1.0, 1.0, 0.2230652763324237, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.4419609639058435, 0.0, 0.0, 0.8094621288201359, 0.2860188096831672, 0.2860188096831672, 0.4004856466096214], 
reward next is 0.5995, 
noisyNet noise sample is [array([1.9007672], dtype=float32), 1.4119502]. 
=============================================
[2019-03-24 06:16:59,786] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 3.4199943e-19 2.5735788e-22 5.0139210e-20 2.5647317e-20], sum to 1.0000
[2019-03-24 06:16:59,792] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5419
[2019-03-24 06:16:59,796] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1053832.492790357 W.
[2019-03-24 06:16:59,802] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.65, 52.5, 1.0, 2.0, 0.3081632258789895, 1.0, 2.0, 0.3081632258789895, 1.0, 2.0, 0.4906058917749562, 6.911199999999999, 6.9112, 121.94756008, 1053832.492790357, 1053832.492790358, 259193.49739697], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2826600.0000, 
sim time next is 2827200.0000, 
raw observation next is [32.5, 53.0, 1.0, 2.0, 0.6439834967189099, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 733928.4457683411, 733928.4457683415, 165812.2832705332], 
processed observation next is [1.0, 0.7391304347826086, 0.7592592592592593, 0.53, 1.0, 1.0, 0.5761708294272736, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2621173020601218, 0.26211730206012196, 0.31886977552025614], 
reward next is 0.6811, 
noisyNet noise sample is [array([-0.7069674], dtype=float32), -1.3678542]. 
=============================================
[2019-03-24 06:17:02,953] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-24 06:17:02,954] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:17:02,955] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:17:02,955] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:17:02,955] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:17:02,956] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:17:02,956] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:17:02,957] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:17:02,957] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:17:02,957] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:17:02,959] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:17:02,974] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run38
[2019-03-24 06:17:02,974] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run38
[2019-03-24 06:17:03,023] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run38
[2019-03-24 06:17:03,024] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run38
[2019-03-24 06:17:03,024] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run38
[2019-03-24 06:17:18,590] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00615678], dtype=float32), 0.014745733]
[2019-03-24 06:17:18,591] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [36.66666666666667, 16.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6955007995452966, 6.911199999999999, 6.9112, 121.9260426156618, 517806.9418956711, 517806.9418956716, 141010.2469890745]
[2019-03-24 06:17:18,592] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:17:18,595] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.5258617128993589
[2019-03-24 06:17:26,718] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00615678], dtype=float32), 0.014745733]
[2019-03-24 06:17:26,719] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.56666666666667, 87.33333333333334, 1.0, 2.0, 0.7664963847689765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260425692793, 938519.2160332879, 938519.2160332884, 191878.2307800898]
[2019-03-24 06:17:26,720] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:17:26,723] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 3.1095087e-29 7.3663331e-33 8.4742452e-30 1.3467679e-28], sampled 0.6389515855716651
[2019-03-24 06:17:26,724] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 938519.2160332879 W.
[2019-03-24 06:17:27,224] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00615678], dtype=float32), 0.014745733]
[2019-03-24 06:17:27,225] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [19.58333333333334, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.614646240112839, 6.9112, 6.9112, 121.9260426156618, 457160.9042486201, 457160.9042486201, 132484.7260357655]
[2019-03-24 06:17:27,227] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:17:27,229] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.8934432984456083
[2019-03-24 06:17:29,388] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00615678], dtype=float32), 0.014745733]
[2019-03-24 06:17:29,389] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.18333333333333, 68.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6247800229032835, 6.9112, 6.9112, 121.9260426156618, 465708.433506407, 465708.433506407, 134412.9228922552]
[2019-03-24 06:17:29,390] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:17:29,394] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.4522805260210029
[2019-03-24 06:18:07,313] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00615678], dtype=float32), 0.014745733]
[2019-03-24 06:18:07,315] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.350271375, 93.55877677166669, 1.0, 2.0, 0.7371008108918417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 840109.5803174692, 840109.5803174692, 183289.9702214514]
[2019-03-24 06:18:07,317] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:18:07,319] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 4.5518392e-34 1.7762503e-38 8.7941011e-35 1.8894218e-33], sampled 0.8225298677047617
[2019-03-24 06:18:07,320] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 840109.5803174692 W.
[2019-03-24 06:18:27,513] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00615678], dtype=float32), 0.014745733]
[2019-03-24 06:18:27,515] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.01756423, 80.33142183, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8505594237808869, 6.9112, 6.9112, 121.9260426156618, 629976.8059527356, 629976.8059527356, 167406.4931437164]
[2019-03-24 06:18:27,515] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:18:27,518] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 4.1631863e-38], sampled 0.1600539055375244
[2019-03-24 06:18:33,661] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00615678], dtype=float32), 0.014745733]
[2019-03-24 06:18:33,662] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [17.67437693, 79.88984629666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4714453656614453, 6.9112, 6.9112, 121.9260426156618, 337245.9177763336, 337245.9177763336, 107660.5949918223]
[2019-03-24 06:18:33,664] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:18:33,666] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.32087945099745874
[2019-03-24 06:18:49,062] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 06:18:49,302] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 06:18:49,411] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8363.4371 2339475986.9735 616.0000
[2019-03-24 06:18:49,530] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8403.6009 2292939572.8233 697.0000
[2019-03-24 06:18:49,645] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 06:18:50,659] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 925000, evaluation results [925000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8363.437110714249, 2339475986.973477, 616.0, 8403.600948472696, 2292939572.823255, 697.0]
[2019-03-24 06:18:54,301] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 9.6412423e-27 2.8311197e-30 2.1577540e-26 2.3360005e-26], sum to 1.0000
[2019-03-24 06:18:54,310] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9850
[2019-03-24 06:18:54,316] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 798129.9592200142 W.
[2019-03-24 06:18:54,322] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.75, 90.66666666666666, 1.0, 2.0, 0.6970194521192751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 798129.9592200142, 798129.9592200142, 175766.3263649523], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2955000.0000, 
sim time next is 2955600.0000, 
raw observation next is [24.7, 90.0, 1.0, 2.0, 0.2330296140376424, 1.0, 1.0, 0.2330296140376424, 1.0, 1.0, 0.3709907347926232, 6.9112, 6.9112, 121.94756008, 796762.9024884137, 796762.9024884137, 231688.3575210794], 
processed observation next is [1.0, 0.21739130434782608, 0.4703703703703703, 0.9, 1.0, 1.0, 0.08694001671147907, 1.0, 0.5, 0.08694001671147907, 1.0, 0.5, 0.21373841849077896, 0.0, 0.0, 0.8096049824067558, 0.2845581794601478, 0.2845581794601478, 0.44555453369438347], 
reward next is 0.5544, 
noisyNet noise sample is [array([1.0441209], dtype=float32), -1.4143751]. 
=============================================
[2019-03-24 06:18:56,273] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 3.2934284e-22 1.1469547e-25 3.8311377e-24 8.2440603e-23], sum to 1.0000
[2019-03-24 06:18:56,281] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8325
[2019-03-24 06:18:56,289] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1899650.965207817 W.
[2019-03-24 06:18:56,294] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.0, 77.66666666666667, 1.0, 2.0, 0.5552087879239145, 1.0, 2.0, 0.5552087879239145, 1.0, 2.0, 0.8839104722627323, 6.9112, 6.9112, 121.94756008, 1899650.965207817, 1899650.965207817, 371511.7013680642], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3068400.0000, 
sim time next is 3069000.0000, 
raw observation next is [31.0, 77.0, 1.0, 2.0, 0.8434437170486286, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426156618, 1676527.08892675, 1676527.088926749, 345036.7141086421], 
processed observation next is [1.0, 0.5217391304347826, 0.7037037037037037, 0.77, 1.0, 1.0, 0.8136234726769388, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5987596746166964, 0.5987596746166961, 0.6635321425166194], 
reward next is 0.3365, 
noisyNet noise sample is [array([-0.8393277], dtype=float32), 0.6461697]. 
=============================================
[2019-03-24 06:18:56,305] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[28.385206]
 [26.655796]
 [25.986147]
 [26.325972]
 [26.816378]], R is [[29.72299576]
 [29.71132088]
 [29.46695709]
 [29.17228699]
 [28.88056374]].
[2019-03-24 06:18:58,005] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 6.2833106e-25 1.1542364e-25 9.0180232e-25 2.5287825e-23], sum to 1.0000
[2019-03-24 06:18:58,012] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3039
[2019-03-24 06:18:58,026] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 727247.9918042311 W.
[2019-03-24 06:18:58,029] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.8, 93.0, 1.0, 2.0, 0.3190622650238518, 1.0, 1.0, 0.3190622650238518, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 727247.9918042311, 727247.9918042315, 185098.1788775267], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3031200.0000, 
sim time next is 3031800.0000, 
raw observation next is [24.83333333333334, 93.16666666666667, 1.0, 2.0, 0.3564258745539052, 1.0, 2.0, 0.3564258745539052, 1.0, 1.0, 0.567441600270156, 6.9112, 6.9112, 122.6606223216235, 1219002.964172002, 1219002.964172002, 278668.71505062], 
processed observation next is [1.0, 0.08695652173913043, 0.47530864197530887, 0.9316666666666668, 1.0, 1.0, 0.23384032684988712, 1.0, 1.0, 0.23384032684988712, 1.0, 0.5, 0.45930200033769497, 0.0, 0.0, 0.8143389741586678, 0.4353582014900007, 0.4353582014900007, 0.5359013750973463], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.49327353], dtype=float32), 0.67670876]. 
=============================================
[2019-03-24 06:19:02,943] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 5.7618884e-25 3.6236986e-29 2.7485362e-26 1.9861962e-24], sum to 1.0000
[2019-03-24 06:19:02,953] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4781
[2019-03-24 06:19:02,965] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 896900.1161765736 W.
[2019-03-24 06:19:02,975] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.66666666666667, 76.33333333333334, 1.0, 2.0, 0.7868989224386828, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 896900.1161765736, 896900.1161765731, 193254.7265895823], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3090000.0000, 
sim time next is 3090600.0000, 
raw observation next is [29.5, 77.0, 1.0, 2.0, 0.7706126503051719, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 878326.5367050736, 878326.5367050731, 189949.5288910064], 
processed observation next is [1.0, 0.782608695652174, 0.6481481481481481, 0.77, 1.0, 1.0, 0.7269198217918713, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.31368804882324053, 0.31368804882324036, 0.36528755555962766], 
reward next is 0.6347, 
noisyNet noise sample is [array([0.5795179], dtype=float32), 0.6691711]. 
=============================================
[2019-03-24 06:19:06,891] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:19:06,898] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1158
[2019-03-24 06:19:06,903] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.0, 57.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8793143315075872, 6.9112, 6.9112, 121.9260426156618, 646643.6022451231, 646643.6022451231, 172508.2158544104], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3187800.0000, 
sim time next is 3188400.0000, 
raw observation next is [28.66666666666666, 58.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8763210351323989, 6.911199999999999, 6.9112, 121.9260426156618, 644395.0145847211, 644395.0145847215, 172130.8755626418], 
processed observation next is [1.0, 0.9130434782608695, 0.6172839506172837, 0.5866666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8454012939154987, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23014107663740038, 0.23014107663740055, 0.33102091454354193], 
reward next is 0.6690, 
noisyNet noise sample is [array([0.85957617], dtype=float32), 0.5160026]. 
=============================================
[2019-03-24 06:19:08,027] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.1209128e-37], sum to 1.0000
[2019-03-24 06:19:08,033] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9965
[2019-03-24 06:19:08,039] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 733231.7367276198 W.
[2019-03-24 06:19:08,042] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.2144575059313675, 1.0, 1.0, 0.2144575059313675, 1.0, 1.0, 0.3414233338360994, 6.911200000000001, 6.9112, 121.94756008, 733231.7367276198, 733231.7367276193, 225375.4170082766], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3193200.0000, 
sim time next is 3193800.0000, 
raw observation next is [26.83333333333333, 78.16666666666667, 1.0, 2.0, 0.2142736207637238, 1.0, 2.0, 0.2142736207637238, 1.0, 2.0, 0.3411305826604888, 6.911200000000001, 6.9112, 121.94756008, 732602.7316532416, 732602.7316532411, 225313.8762494044], 
processed observation next is [1.0, 1.0, 0.5493827160493825, 0.7816666666666667, 1.0, 1.0, 0.06461145329014739, 1.0, 1.0, 0.06461145329014739, 1.0, 1.0, 0.17641322832561096, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.26164383273330055, 0.2616438327333004, 0.4332959158642392], 
reward next is 0.5667, 
noisyNet noise sample is [array([0.45187473], dtype=float32), -0.9937888]. 
=============================================
[2019-03-24 06:19:08,835] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:19:08,842] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1465
[2019-03-24 06:19:08,845] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.15, 81.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7630674068262572, 6.9112, 6.9112, 121.9260426156618, 569015.9565080705, 569015.9565080705, 154335.7444999087], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3217800.0000, 
sim time next is 3218400.0000, 
raw observation next is [23.0, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.76258952357766, 6.9112, 6.9112, 121.9260426156618, 568628.3304964163, 568628.3304964163, 154307.4246044373], 
processed observation next is [0.0, 0.2608695652173913, 0.4074074074074074, 0.83, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7032369044720749, 0.0, 0.0, 0.8094621288201359, 0.20308154660586297, 0.20308154660586297, 0.2967450473162256], 
reward next is 0.7033, 
noisyNet noise sample is [array([0.50061214], dtype=float32), -0.94647044]. 
=============================================
[2019-03-24 06:19:13,138] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:19:13,147] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0708
[2019-03-24 06:19:13,151] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.85, 96.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8010070401975783, 6.9112, 6.9112, 121.9260426156618, 595430.429264803, 595430.429264803, 160213.4384622515], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3303000.0000, 
sim time next is 3303600.0000, 
raw observation next is [21.9, 97.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8124762232499523, 6.911199999999999, 6.9112, 121.9260426156618, 603024.7782398058, 603024.7782398063, 162108.1513063015], 
processed observation next is [0.0, 0.21739130434782608, 0.36666666666666664, 0.9766666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7655952790624404, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21536599222850208, 0.21536599222850225, 0.31174644481981056], 
reward next is 0.6883, 
noisyNet noise sample is [array([-1.107927], dtype=float32), -1.7649581]. 
=============================================
[2019-03-24 06:19:15,939] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 5.8888671e-30 1.1841484e-33 9.6548087e-30 3.9749706e-28], sum to 1.0000
[2019-03-24 06:19:15,945] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3897
[2019-03-24 06:19:15,954] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 791014.2983397094 W.
[2019-03-24 06:19:15,957] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.33333333333334, 87.33333333333333, 1.0, 2.0, 0.3470237445379475, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5524731030787542, 6.911199999999999, 6.9112, 121.9260426156618, 791014.2983397094, 791014.2983397099, 208317.0368583342], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3361200.0000, 
sim time next is 3361800.0000, 
raw observation next is [26.16666666666667, 88.16666666666667, 1.0, 2.0, 0.2307841590856526, 1.0, 1.0, 0.2307841590856526, 1.0, 2.0, 0.367415897379693, 6.911200000000001, 6.9112, 121.94756008, 789081.4068646475, 789081.406864647, 230914.8429005807], 
processed observation next is [0.0, 0.9130434782608695, 0.5246913580246916, 0.8816666666666667, 1.0, 1.0, 0.08426685605434835, 1.0, 0.5, 0.08426685605434835, 1.0, 1.0, 0.20926987172461622, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2818147881659455, 0.28181478816594535, 0.4440670055780398], 
reward next is 0.5559, 
noisyNet noise sample is [array([1.0297875], dtype=float32), -1.3341928]. 
=============================================
[2019-03-24 06:19:18,961] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 6.9175903e-21 5.9118943e-22 4.8758299e-21 4.9928928e-18], sum to 1.0000
[2019-03-24 06:19:18,971] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7679
[2019-03-24 06:19:18,971] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1964512.78224771 W.
[2019-03-24 06:19:18,977] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.3, 69.0, 1.0, 2.0, 0.861217412565167, 1.0, 2.0, 0.861217412565167, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1964512.78224771, 1964512.78224771, 369699.8150102469], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3430800.0000, 
sim time next is 3431400.0000, 
raw observation next is [29.41666666666667, 68.5, 1.0, 2.0, 0.2872461074845757, 1.0, 2.0, 0.2872461074845757, 1.0, 1.0, 0.4573051580680621, 6.9112, 6.9112, 121.94756008, 982255.928746115, 982255.928746115, 251219.7812191183], 
processed observation next is [1.0, 0.7391304347826086, 0.6450617283950619, 0.685, 1.0, 1.0, 0.15148346129116153, 1.0, 1.0, 0.15148346129116153, 1.0, 0.5, 0.3216314475850776, 0.0, 0.0, 0.8096049824067558, 0.3508056888378982, 0.3508056888378982, 0.4831149638829198], 
reward next is 0.5169, 
noisyNet noise sample is [array([1.3607813], dtype=float32), 0.8410281]. 
=============================================
[2019-03-24 06:19:20,072] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 3.9259911e-22 2.6184744e-25 3.9379646e-20 1.0356643e-20], sum to 1.0000
[2019-03-24 06:19:20,078] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3288
[2019-03-24 06:19:20,084] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 744829.6822649183 W.
[2019-03-24 06:19:20,088] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.9, 78.0, 1.0, 2.0, 0.3267720558943051, 1.0, 1.0, 0.3267720558943051, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 744829.6822649183, 744829.6822649183, 187009.4193045316], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3441600.0000, 
sim time next is 3442200.0000, 
raw observation next is [26.75, 79.83333333333333, 1.0, 2.0, 0.3277724254041859, 1.0, 2.0, 0.3277724254041859, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 747110.9912192042, 747110.9912192046, 187258.9692412009], 
processed observation next is [1.0, 0.8695652173913043, 0.5462962962962963, 0.7983333333333333, 1.0, 1.0, 0.19972907786212607, 1.0, 1.0, 0.19972907786212607, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26682535400685864, 0.2668253540068588, 0.3601134023869248], 
reward next is 0.6399, 
noisyNet noise sample is [array([-1.7797467], dtype=float32), -0.93990546]. 
=============================================
[2019-03-24 06:19:20,956] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.3856676e-25 1.0906387e-26 8.4172453e-24 7.4263549e-23], sum to 1.0000
[2019-03-24 06:19:20,962] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7258
[2019-03-24 06:19:20,968] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 756989.9818165012 W.
[2019-03-24 06:19:20,973] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.2214029497377542, 1.0, 2.0, 0.2214029497377542, 1.0, 1.0, 0.3524807065731801, 6.911199999999999, 6.9112, 121.94756008, 756989.9818165012, 756989.9818165017, 227713.6963855313], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3457200.0000, 
sim time next is 3457800.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.2217372996571139, 1.0, 2.0, 0.2217372996571139, 1.0, 2.0, 0.3530130025338174, 6.911200000000001, 6.9112, 121.94756008, 758133.7094974883, 758133.7094974879, 227826.9406716657], 
processed observation next is [1.0, 0.0, 0.48148148148148145, 0.94, 1.0, 1.0, 0.07349678530608797, 1.0, 1.0, 0.07349678530608797, 1.0, 1.0, 0.19126625316727172, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.27076203910624586, 0.2707620391062457, 0.4381287320608956], 
reward next is 0.5619, 
noisyNet noise sample is [array([1.0015268], dtype=float32), 0.42832094]. 
=============================================
[2019-03-24 06:19:21,891] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 8.6708167e-20 1.6565470e-20 4.4211085e-20 1.1695003e-18], sum to 1.0000
[2019-03-24 06:19:21,910] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4353
[2019-03-24 06:19:21,915] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 960868.7717383375 W.
[2019-03-24 06:19:21,917] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.0, 94.00000000000001, 1.0, 2.0, 0.4214934586429214, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6710313132431414, 6.9112, 6.9112, 121.9260426156618, 960868.7717383375, 960868.7717383375, 230826.0484091414], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3474600.0000, 
sim time next is 3475200.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.2330050474006116, 1.0, 1.0, 0.2330050474006116, 1.0, 2.0, 0.3709516239063907, 6.9112, 6.9112, 121.94756008, 796678.8618579126, 796678.8618579126, 231679.8795520046], 
processed observation next is [1.0, 0.21739130434782608, 0.48148148148148145, 0.94, 1.0, 1.0, 0.0869107707150138, 1.0, 0.5, 0.0869107707150138, 1.0, 1.0, 0.21368952988298834, 0.0, 0.0, 0.8096049824067558, 0.2845281649492545, 0.2845281649492545, 0.44553822990770114], 
reward next is 0.5545, 
noisyNet noise sample is [array([1.1822466], dtype=float32), 0.58527523]. 
=============================================
[2019-03-24 06:19:33,432] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.1369550e-29 5.6277098e-31 1.7145239e-29 1.8514424e-26], sum to 1.0000
[2019-03-24 06:19:33,439] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0843
[2019-03-24 06:19:33,444] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 759768.882840365 W.
[2019-03-24 06:19:33,452] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.06666666666667, 94.0, 1.0, 2.0, 0.6666458859584031, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 759768.882840365, 759768.882840365, 169924.7537780331], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3710400.0000, 
sim time next is 3711000.0000, 
raw observation next is [25.08333333333334, 94.0, 1.0, 2.0, 0.6695496930899258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 763079.9667469786, 763079.9667469781, 170458.4393314229], 
processed observation next is [1.0, 0.9565217391304348, 0.4845679012345681, 0.94, 1.0, 1.0, 0.606606777488007, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27252855955249233, 0.27252855955249217, 0.32780469102196713], 
reward next is 0.6722, 
noisyNet noise sample is [array([0.9461315], dtype=float32), -1.9008954]. 
=============================================
[2019-03-24 06:19:33,466] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[39.397797]
 [39.396496]
 [38.853985]
 [39.24752 ]
 [39.450886]], R is [[39.94276047]
 [40.21655655]
 [39.81439209]
 [39.97659302]
 [40.18291855]].
[2019-03-24 06:19:34,094] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 5.2784685e-21 1.6588931e-20 1.4618927e-19 3.3776421e-16], sum to 1.0000
[2019-03-24 06:19:34,098] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9159
[2019-03-24 06:19:34,106] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1258605.916363188 W.
[2019-03-24 06:19:34,110] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 100.0, 1.0, 2.0, 0.5400809150997792, 0.0, 1.0, 0.0, 1.0, 1.0, 0.862246378414769, 6.911200000000003, 6.9112, 121.9260426156181, 1258605.916363188, 1258605.916363187, 270780.263759626], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3663600.0000, 
sim time next is 3664200.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.993353736060964, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.31502636454543, 6.9112, 121.9243325908455, 1378463.905281128, 1171671.613366014, 241207.8000568916], 
processed observation next is [1.0, 0.391304347826087, 0.37037037037037035, 1.0, 1.0, 1.0, 0.9920877810249571, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.040382636454542986, 0.0, 0.8094507760336561, 0.49230853760040283, 0.4184541476307193, 0.46386115395556077], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3489425], dtype=float32), -0.43454656]. 
=============================================
[2019-03-24 06:19:35,958] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 1.2968318e-18 4.5444114e-20 4.0177833e-18 5.2363857e-16], sum to 1.0000
[2019-03-24 06:19:35,965] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3130
[2019-03-24 06:19:35,971] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 799469.9520077558 W.
[2019-03-24 06:19:35,975] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.0, 100.0, 1.0, 2.0, 0.7014627358183136, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 799469.9520077558, 799469.9520077553, 176417.2468657731], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3739800.0000, 
sim time next is 3740400.0000, 
raw observation next is [24.0, 100.0, 1.0, 2.0, 0.3387504746815462, 1.0, 1.0, 0.3387504746815462, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 772146.5087235748, 772146.5087235753, 190019.779992233], 
processed observation next is [1.0, 0.30434782608695654, 0.4444444444444444, 1.0, 1.0, 1.0, 0.21279818414469784, 1.0, 0.5, 0.21279818414469784, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2757666102584196, 0.27576661025841975, 0.3654226538312173], 
reward next is 0.6346, 
noisyNet noise sample is [array([-0.20418599], dtype=float32), -0.92748994]. 
=============================================
[2019-03-24 06:19:39,482] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.00000000e+00 1.48680475e-30 4.74397378e-34 8.59522673e-30
 8.46287321e-30], sum to 1.0000
[2019-03-24 06:19:39,489] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7625
[2019-03-24 06:19:39,495] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 744567.8466705444 W.
[2019-03-24 06:19:39,498] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.33333333333334, 59.0, 1.0, 2.0, 0.6533144780257384, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 744567.8466705444, 744567.8466705444, 167491.7306652236], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3793200.0000, 
sim time next is 3793800.0000, 
raw observation next is [30.16666666666666, 59.0, 1.0, 2.0, 0.3215039181666313, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5118447083728975, 6.9112, 6.9112, 121.9260426156618, 732815.9837372851, 732815.9837372851, 201112.7673759678], 
processed observation next is [1.0, 0.9130434782608695, 0.6728395061728393, 0.59, 1.0, 1.0, 0.19226656924598967, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.3898058854661219, 0.0, 0.0, 0.8094621288201359, 0.2617199941918876, 0.2617199941918876, 0.3867553218768611], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9959664], dtype=float32), -0.7570684]. 
=============================================
[2019-03-24 06:19:39,639] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:19:39,647] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2411
[2019-03-24 06:19:39,652] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.66666666666666, 60.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9060168029581515, 6.911199999999999, 6.9112, 121.9260426156618, 662623.5769445844, 662623.5769445848, 176835.947862473], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3829200.0000, 
sim time next is 3829800.0000, 
raw observation next is [28.83333333333334, 59.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8988820484036413, 6.911200000000001, 6.9112, 121.9260426156618, 658231.4706967315, 658231.470696731, 175717.4349902816], 
processed observation next is [0.0, 0.30434782608695654, 0.623456790123457, 0.5933333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8736025605045517, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23508266810597553, 0.23508266810597536, 0.33791814421208], 
reward next is 0.6621, 
noisyNet noise sample is [array([1.6656044], dtype=float32), -0.17683885]. 
=============================================
[2019-03-24 06:19:39,949] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-24 06:19:39,949] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:19:39,951] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:19:39,954] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:19:39,954] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:19:39,955] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:19:39,955] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:19:39,956] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:19:39,954] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:19:39,955] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:19:39,958] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:19:39,970] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run39
[2019-03-24 06:19:39,994] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run39
[2019-03-24 06:19:39,995] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run39
[2019-03-24 06:19:40,044] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run39
[2019-03-24 06:19:40,072] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run39
[2019-03-24 06:19:50,683] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00624545], dtype=float32), 0.014665235]
[2019-03-24 06:19:50,684] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [32.80655243, 37.14688139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7585354149149733, 6.9112, 6.9112, 121.9260426156618, 564116.0416759677, 564116.0416759677, 154877.0777850438]
[2019-03-24 06:19:50,687] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:19:50,689] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.1368556066604233
[2019-03-24 06:19:51,998] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00624545], dtype=float32), 0.014665235]
[2019-03-24 06:19:52,000] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.16666666666667, 28.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4515410917986531, 6.9112, 6.9112, 121.9260426156618, 322397.439754686, 322397.439754686, 89514.14553391402]
[2019-03-24 06:19:52,000] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:19:52,002] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.17674211254470384
[2019-03-24 06:19:58,731] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00624545], dtype=float32), 0.014665235]
[2019-03-24 06:19:58,732] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.2, 64.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5795244113522507, 6.911199999999999, 6.9112, 121.9260426156618, 426627.1542791455, 426627.1542791459, 126398.453615905]
[2019-03-24 06:19:58,736] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:19:58,740] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.41406771646436913
[2019-03-24 06:20:02,513] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00624545], dtype=float32), 0.014665235]
[2019-03-24 06:20:02,513] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.66666666666666, 45.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9623361123041916, 7.130973383039223, 6.9112, 121.9251923437719, 826850.4959805422, 714307.6655843278, 181398.189635128]
[2019-03-24 06:20:02,514] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:20:02,517] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.8212355076499611
[2019-03-24 06:20:02,518] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 826850.4959805422 W.
[2019-03-24 06:20:04,197] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00624545], dtype=float32), 0.014665235]
[2019-03-24 06:20:04,197] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.41908671, 82.80979411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5983579936873922, 6.9112, 6.9112, 121.9260426156618, 444174.4398493751, 444174.4398493751, 130257.9984131298]
[2019-03-24 06:20:04,198] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:20:04,200] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.747118490929098
[2019-03-24 06:20:34,204] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00624545], dtype=float32), 0.014665235]
[2019-03-24 06:20:34,207] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.1939782, 95.04918123666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8278148812648967, 6.9112, 6.9112, 121.9260426156618, 613327.3159682341, 613327.3159682341, 164488.686864337]
[2019-03-24 06:20:34,210] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:20:34,212] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.08133328321714206
[2019-03-24 06:21:14,542] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00624545], dtype=float32), 0.014665235]
[2019-03-24 06:21:14,543] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.58333333333334, 72.5, 1.0, 2.0, 0.728066410998847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 829807.062036478, 829807.062036478, 181528.9223115151]
[2019-03-24 06:21:14,544] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:21:14,548] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.00000000e+00 1.14437475e-35 0.00000000e+00 8.94755535e-36
 3.70011114e-34], sampled 0.8603872345536336
[2019-03-24 06:21:14,550] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 829807.062036478 W.
[2019-03-24 06:21:25,759] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.7982 2219159744.7191 543.0000
[2019-03-24 06:21:26,308] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 06:21:26,828] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7840.8532 2529795142.6922 831.0000
[2019-03-24 06:21:26,879] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 06:21:26,893] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 06:21:27,911] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 950000, evaluation results [950000.0, 7840.853177063691, 2529795142.6922317, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.798202931406, 2219159744.719052, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 06:21:31,671] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 3.9923572e-27 3.3776324e-29 7.8587833e-27 1.0803824e-25], sum to 1.0000
[2019-03-24 06:21:31,681] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8570
[2019-03-24 06:21:31,690] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 839954.3651819131 W.
[2019-03-24 06:21:31,695] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.66666666666667, 89.66666666666666, 1.0, 2.0, 0.2456549243412857, 1.0, 1.0, 0.2456549243412857, 1.0, 2.0, 0.391090639973674, 6.9112, 6.9112, 121.94756008, 839954.3651819131, 839954.3651819131, 236089.995333824], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3897600.0000, 
sim time next is 3898200.0000, 
raw observation next is [26.83333333333333, 89.33333333333333, 1.0, 2.0, 0.3725258455769137, 1.0, 2.0, 0.3725258455769137, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 849176.6047238751, 849176.6047238755, 198776.7993550059], 
processed observation next is [0.0, 0.08695652173913043, 0.5493827160493825, 0.8933333333333333, 1.0, 1.0, 0.25300695902013537, 1.0, 1.0, 0.25300695902013537, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3032773588299554, 0.30327735882995555, 0.3822630756827037], 
reward next is 0.6177, 
noisyNet noise sample is [array([-0.39095274], dtype=float32), -1.093515]. 
=============================================
[2019-03-24 06:21:35,847] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.6338133e-31 2.3484450e-35 7.8359267e-31 1.5734196e-29], sum to 1.0000
[2019-03-24 06:21:35,858] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1980
[2019-03-24 06:21:35,862] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 764605.5673752057 W.
[2019-03-24 06:21:35,870] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.1, 83.66666666666667, 1.0, 2.0, 0.223629231144054, 1.0, 2.0, 0.223629231144054, 1.0, 1.0, 0.356025019076933, 6.9112, 6.9112, 121.94756008, 764605.5673752057, 764605.5673752057, 228468.9155872512], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3973200.0000, 
sim time next is 3973800.0000, 
raw observation next is [26.05, 83.83333333333333, 1.0, 2.0, 0.2226855943282029, 1.0, 2.0, 0.2226855943282029, 1.0, 2.0, 0.3545227185339925, 6.911200000000001, 6.9112, 121.94756008, 761377.5983272744, 761377.598327274, 228148.4681438308], 
processed observation next is [0.0, 1.0, 0.5203703703703704, 0.8383333333333333, 1.0, 1.0, 0.07462570753357488, 1.0, 1.0, 0.07462570753357488, 1.0, 1.0, 0.19315339816749058, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.27192057083116944, 0.2719205708311693, 0.43874705412275156], 
reward next is 0.5613, 
noisyNet noise sample is [array([1.9113798], dtype=float32), -0.435832]. 
=============================================
[2019-03-24 06:21:39,821] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.00000000e+00 1.41127942e-32 1.11726365e-36 3.25132995e-33
 1.83738613e-32], sum to 1.0000
[2019-03-24 06:21:39,826] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5958
[2019-03-24 06:21:39,831] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [33.33333333333334, 36.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7878355815593628, 6.9112, 6.9112, 121.9260426156618, 583457.4554271629, 583457.4554271629, 159561.7128409063], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4214400.0000, 
sim time next is 4215000.0000, 
raw observation next is [33.16666666666666, 37.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7942966393609399, 6.911200000000001, 6.9112, 121.9260426156618, 588082.3560883316, 588082.3560883311, 160427.3730345538], 
processed observation next is [1.0, 0.782608695652174, 0.7839506172839502, 0.3733333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7428707992011748, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21002941288868984, 0.21002941288868968, 0.30851417891260347], 
reward next is 0.6915, 
noisyNet noise sample is [array([0.94435805], dtype=float32), -0.35181692]. 
=============================================
[2019-03-24 06:21:39,852] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[43.464943]
 [43.143997]
 [42.606342]
 [41.529896]
 [40.475815]], R is [[44.2431488 ]
 [44.49386597]
 [44.74343109]
 [44.9906311 ]
 [45.234272  ]].
[2019-03-24 06:21:39,869] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.1759153e-18 3.9473064e-19 3.4137527e-18 1.1557232e-14], sum to 1.0000
[2019-03-24 06:21:39,876] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4160
[2019-03-24 06:21:39,884] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1819966.598739833 W.
[2019-03-24 06:21:39,888] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.2, 84.0, 1.0, 2.0, 0.7979147014205532, 1.0, 1.0, 0.7979147014205532, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1819966.598739833, 1819966.598739833, 342892.9782291356], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4026600.0000, 
sim time next is 4027200.0000, 
raw observation next is [26.13333333333333, 85.66666666666666, 1.0, 2.0, 0.5383458770466318, 1.0, 2.0, 0.5383458770466318, 1.0, 1.0, 0.8570641689594317, 6.911200000000001, 6.9112, 121.94756008, 1841894.90986591, 1841894.909865909, 362808.0795646934], 
processed observation next is [1.0, 0.6086956521739131, 0.5234567901234567, 0.8566666666666666, 1.0, 1.0, 0.4504117583888474, 1.0, 1.0, 0.4504117583888474, 1.0, 0.5, 0.8213302111992895, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6578196106663964, 0.657819610666396, 0.697707845316718], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2379793], dtype=float32), -1.4423183]. 
=============================================
[2019-03-24 06:21:40,177] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.2200548e-20 1.2916565e-20 1.0963939e-21 1.1951090e-16], sum to 1.0000
[2019-03-24 06:21:40,190] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7769
[2019-03-24 06:21:40,196] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1749528.214953195 W.
[2019-03-24 06:21:40,201] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.66666666666667, 85.66666666666667, 1.0, 2.0, 0.9073969303829683, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1749528.214953195, 1749528.214953195, 358569.4455593638], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4030800.0000, 
sim time next is 4031400.0000, 
raw observation next is [26.83333333333333, 84.83333333333333, 1.0, 2.0, 0.5142977709319286, 1.0, 1.0, 0.5142977709319286, 1.0, 2.0, 0.8187788008326856, 6.9112, 6.9112, 121.94756008, 1759535.770283887, 1759535.770283887, 350661.9897140432], 
processed observation next is [1.0, 0.6521739130434783, 0.5493827160493825, 0.8483333333333333, 1.0, 1.0, 0.42178306063324833, 1.0, 0.5, 0.42178306063324833, 1.0, 1.0, 0.7734735010408569, 0.0, 0.0, 0.8096049824067558, 0.6284056322442453, 0.6284056322442453, 0.6743499802193139], 
reward next is 0.3257, 
noisyNet noise sample is [array([-0.72956604], dtype=float32), -0.62941235]. 
=============================================
[2019-03-24 06:22:03,572] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 7.4855750e-37 0.0000000e+00 1.6087186e-36 4.3539792e-34], sum to 1.0000
[2019-03-24 06:22:03,580] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6698
[2019-03-24 06:22:03,588] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.91666666666667, 90.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9193784369661415, 6.911200000000001, 6.9112, 121.9260426156618, 672843.8893449773, 672843.8893449769, 178538.8232925008], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4500600.0000, 
sim time next is 4501200.0000, 
raw observation next is [23.93333333333333, 91.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.923722607898464, 6.9112, 6.9112, 121.9260426156618, 675025.4594832117, 675025.4594832117, 179322.0214296039], 
processed observation next is [0.0, 0.08695652173913043, 0.4419753086419752, 0.9133333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.90465325987308, 0.0, 0.0, 0.8094621288201359, 0.2410805212440042, 0.2410805212440042, 0.3448500412107767], 
reward next is 0.6551, 
noisyNet noise sample is [array([0.9192581], dtype=float32), -0.4737482]. 
=============================================
[2019-03-24 06:22:10,944] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.0847030e-23 4.4923152e-24 1.1105966e-21 7.8058378e-20], sum to 1.0000
[2019-03-24 06:22:10,951] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3383
[2019-03-24 06:22:10,957] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1968393.9486421 W.
[2019-03-24 06:22:10,962] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.8629169935153547, 1.0, 2.0, 0.8629169935153547, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260424785166, 1968393.9486421, 1968393.9486421, 370439.4218378772], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4809000.0000, 
sim time next is 4809600.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.570820146162685, 1.0, 2.0, 0.570820146162685, 1.0, 1.0, 0.9087642630052974, 6.9112, 6.9112, 121.94756008, 1953123.738316887, 1953123.738316887, 379706.2777064238], 
processed observation next is [1.0, 0.6956521739130435, 0.5555555555555556, 0.89, 1.0, 1.0, 0.4890716025746249, 1.0, 1.0, 0.4890716025746249, 1.0, 0.5, 0.8859553287566219, 0.0, 0.0, 0.8096049824067558, 0.697544192256031, 0.697544192256031, 0.730204380204661], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.69737875], dtype=float32), -3.8356202]. 
=============================================
[2019-03-24 06:22:11,828] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.2384619e-24 3.0755768e-24 9.3497656e-23 2.9367545e-22], sum to 1.0000
[2019-03-24 06:22:11,832] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0990
[2019-03-24 06:22:11,837] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 802691.0538926995 W.
[2019-03-24 06:22:11,842] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.1, 92.0, 1.0, 2.0, 0.3521437414677675, 1.0, 2.0, 0.3521437414677675, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 802691.0538926995, 802691.0538927, 193445.4068397342], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4654200.0000, 
sim time next is 4654800.0000, 
raw observation next is [26.0, 94.0, 1.0, 2.0, 0.2380575537523724, 1.0, 2.0, 0.2380575537523724, 1.0, 1.0, 0.378995378567038, 6.9112, 6.9112, 121.94756008, 813963.3026395924, 813963.3026395924, 233430.6042352731], 
processed observation next is [1.0, 0.9130434782608695, 0.5185185185185185, 0.94, 1.0, 1.0, 0.09292565922901475, 1.0, 1.0, 0.09292565922901475, 1.0, 0.5, 0.2237442232087975, 0.0, 0.0, 0.8096049824067558, 0.29070117951414015, 0.29070117951414015, 0.4489050081447559], 
reward next is 0.5511, 
noisyNet noise sample is [array([0.20560429], dtype=float32), -1.6656911]. 
=============================================
[2019-03-24 06:22:11,931] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 3.6996744e-26 2.9380581e-27 1.5469338e-24 1.1000171e-22], sum to 1.0000
[2019-03-24 06:22:11,938] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4339
[2019-03-24 06:22:11,947] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 756616.5389298984 W.
[2019-03-24 06:22:11,950] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.1, 93.16666666666667, 1.0, 2.0, 0.3319406407513321, 1.0, 2.0, 0.3319406407513321, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 756616.5389298984, 756616.5389298989, 188302.4770819502], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4665000.0000, 
sim time next is 4665600.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.2214713902945807, 1.0, 2.0, 0.2214713902945807, 1.0, 1.0, 0.3525896661686012, 6.9112, 6.9112, 121.94756008, 757224.0997521597, 757224.0997521597, 227736.8721060581], 
processed observation next is [1.0, 0.0, 0.48148148148148145, 0.94, 1.0, 1.0, 0.07318022654116751, 1.0, 1.0, 0.07318022654116751, 1.0, 0.5, 0.1907370827107515, 0.0, 0.0, 0.8096049824067558, 0.27043717848291415, 0.27043717848291415, 0.43795552328088094], 
reward next is 0.5620, 
noisyNet noise sample is [array([0.4763679], dtype=float32), -0.36007276]. 
=============================================
[2019-03-24 06:22:16,065] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.3430453e-25 1.6002200e-25 1.0462686e-24 1.3258771e-22], sum to 1.0000
[2019-03-24 06:22:16,072] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8532
[2019-03-24 06:22:16,078] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 746429.5054190878 W.
[2019-03-24 06:22:16,083] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.05, 93.16666666666667, 1.0, 2.0, 0.6549471791048976, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 746429.5054190878, 746429.5054190878, 167789.2529495948], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4751400.0000, 
sim time next is 4752000.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.3289773636359678, 1.0, 1.0, 0.3289773636359678, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 749858.8212638143, 749858.8212638148, 187560.187774617], 
processed observation next is [1.0, 0.0, 0.48148148148148145, 0.94, 1.0, 1.0, 0.2011635281380569, 1.0, 0.5, 0.2011635281380569, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2678067218799337, 0.2678067218799339, 0.36069266879734035], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9514344], dtype=float32), -0.3576022]. 
=============================================
[2019-03-24 06:22:16,100] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[35.38797 ]
 [35.147457]
 [35.212086]
 [35.337543]
 [35.394978]], R is [[34.40309525]
 [34.05906296]
 [33.71847153]
 [33.38128662]
 [33.61351013]].
[2019-03-24 06:22:16,918] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-24 06:22:16,921] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:22:16,923] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:22:16,923] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:22:16,926] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:22:16,927] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:22:16,926] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:22:16,928] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:22:16,928] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:22:16,930] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:22:16,931] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:22:16,952] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run40
[2019-03-24 06:22:16,979] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run40
[2019-03-24 06:22:16,979] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run40
[2019-03-24 06:22:17,025] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run40
[2019-03-24 06:22:17,027] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run40
[2019-03-24 06:22:19,671] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00615197], dtype=float32), 0.014398817]
[2019-03-24 06:22:19,672] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [30.56028227, 35.57896496, 1.0, 2.0, 0.7630286596054485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 942181.1935539596, 942181.1935539596, 191392.1570918227]
[2019-03-24 06:22:19,673] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:22:19,676] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.00000000e+00 2.68969126e-21 9.79944776e-22 1.05820004e-20
 5.16366091e-18], sampled 0.8203017223228255
[2019-03-24 06:22:19,677] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 942181.1935539596 W.
[2019-03-24 06:22:22,870] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00615197], dtype=float32), 0.014398817]
[2019-03-24 06:22:22,871] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [17.05, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4282997120360036, 6.911200000000001, 6.9112, 121.9260426156618, 305799.9356873787, 305799.9356873783, 100756.8013054043]
[2019-03-24 06:22:22,872] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:22:22,874] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 2.0778557e-34 5.4285344e-38 9.4781252e-35 1.4412068e-33], sampled 0.6375758157051485
[2019-03-24 06:22:31,518] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00615197], dtype=float32), 0.014398817]
[2019-03-24 06:22:31,519] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.66666666666667, 66.33333333333334, 1.0, 2.0, 0.566550176000772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156572, 725330.4671113028, 725330.4671113032, 154853.7304116168]
[2019-03-24 06:22:31,520] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:22:31,521] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 3.1594741e-23 2.5128569e-24 9.0074423e-23 8.1087675e-21], sampled 0.31631850198011857
[2019-03-24 06:22:31,525] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 725330.4671113028 W.
[2019-03-24 06:23:18,394] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00615197], dtype=float32), 0.014398817]
[2019-03-24 06:23:18,394] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.83333333333333, 89.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9389365978994321, 6.911199999999999, 6.9112, 121.9260426156618, 678637.4185803039, 678637.4185803044, 182566.7850278604]
[2019-03-24 06:23:18,396] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:23:18,399] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 2.9573899e-33 1.3661561e-36 1.5060912e-33 2.4035994e-32], sampled 0.40346375411368374
[2019-03-24 06:24:03,388] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 06:24:03,743] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7840.8532 2529795142.6922 831.0000
[2019-03-24 06:24:03,810] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8559.5106 2258278767.0965 536.0000
[2019-03-24 06:24:03,825] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.7982 2219159744.7191 543.0000
[2019-03-24 06:24:03,894] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8403.6543 2292911235.5092 697.0000
[2019-03-24 06:24:04,910] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 975000, evaluation results [975000.0, 7840.853177063691, 2529795142.6922317, 831.0, 8559.510645911187, 2258278767.096507, 536.0, 8633.798202931406, 2219159744.719052, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8403.654257497506, 2292911235.509193, 697.0]
[2019-03-24 06:24:08,579] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 5.9956482e-24 1.8784144e-23 2.6169391e-23 9.5562851e-21], sum to 1.0000
[2019-03-24 06:24:08,586] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9068
[2019-03-24 06:24:08,591] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 900825.4265932962 W.
[2019-03-24 06:24:08,594] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 94.0, 1.0, 2.0, 0.3951703932394407, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6291241358384099, 6.9112, 6.9112, 121.9260426156618, 900825.4265932962, 900825.4265932962, 222620.86666292], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4818600.0000, 
sim time next is 4819200.0000, 
raw observation next is [27.0, 94.0, 1.0, 2.0, 0.3974211395872071, 0.0, 2.0, 0.0, 1.0, 2.0, 0.632707397325745, 6.911199999999999, 6.9112, 121.9260426156618, 905959.2321117258, 905959.2321117262, 223312.098851935], 
processed observation next is [1.0, 0.782608695652174, 0.5555555555555556, 0.94, 1.0, 1.0, 0.28264421379429416, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5408842466571812, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.32355686861133065, 0.32355686861133076, 0.4294463439460289], 
reward next is 0.5706, 
noisyNet noise sample is [array([-1.362475], dtype=float32), 0.026323363]. 
=============================================
[2019-03-24 06:24:09,629] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 7.6879568e-20 1.2193064e-19 2.9172750e-19 1.7521104e-16], sum to 1.0000
[2019-03-24 06:24:09,637] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9014
[2019-03-24 06:24:09,646] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 855913.8524398622 W.
[2019-03-24 06:24:09,649] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.33333333333334, 1.0, 2.0, 0.3754797638192175, 1.0, 1.0, 0.3754797638192175, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 855913.8524398622, 855913.8524398622, 199560.3015692832], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4853400.0000, 
sim time next is 4854000.0000, 
raw observation next is [25.0, 94.66666666666667, 1.0, 2.0, 0.6991251121188184, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 796804.3345639971, 796804.3345639971, 175976.273195404], 
processed observation next is [1.0, 0.17391304347826086, 0.48148148148148145, 0.9466666666666668, 1.0, 1.0, 0.6418156096652601, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.284572976629999, 0.284572976629999, 0.33841590999116156], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7667398], dtype=float32), -0.9875035]. 
=============================================
[2019-03-24 06:24:09,664] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[28.394474]
 [28.621475]
 [28.09505 ]
 [28.246193]
 [28.697687]], R is [[28.4546814 ]
 [28.1701355 ]
 [27.88843536]
 [27.60955048]
 [27.33345604]].
[2019-03-24 06:24:17,986] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 3.7877014e-17 9.0654810e-18 2.9177246e-16 1.0738552e-14], sum to 1.0000
[2019-03-24 06:24:17,998] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7898
[2019-03-24 06:24:18,008] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1567369.855242719 W.
[2019-03-24 06:24:18,012] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.1, 84.5, 1.0, 2.0, 0.4581791076028213, 1.0, 2.0, 0.4581791076028213, 1.0, 2.0, 0.7294360611554775, 6.9112, 6.9112, 121.94756008, 1567369.855242719, 1567369.855242719, 323504.6866185727], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4977000.0000, 
sim time next is 4977600.0000, 
raw observation next is [26.73333333333333, 81.0, 1.0, 2.0, 0.4724818976304619, 1.0, 2.0, 0.4724818976304619, 1.0, 2.0, 0.7522065686888326, 6.911199999999999, 6.9112, 121.94756008, 1616344.258851387, 1616344.258851388, 330286.9686890402], 
processed observation next is [1.0, 0.6086956521739131, 0.545679012345679, 0.81, 1.0, 1.0, 0.3720022590838832, 1.0, 1.0, 0.3720022590838832, 1.0, 1.0, 0.6902582108610408, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5772658067326383, 0.5772658067326386, 0.6351672474789235], 
reward next is 0.3648, 
noisyNet noise sample is [array([0.19308393], dtype=float32), -1.0136137]. 
=============================================
[2019-03-24 06:24:21,326] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.1341875e-28 3.9529007e-32 1.4898948e-28 8.1063609e-27], sum to 1.0000
[2019-03-24 06:24:21,332] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2300
[2019-03-24 06:24:21,337] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 792664.056278902 W.
[2019-03-24 06:24:21,341] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.33333333333333, 82.33333333333334, 1.0, 2.0, 0.3477471313378888, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5536247584233239, 6.911199999999999, 6.9112, 121.9260426156618, 792664.056278902, 792664.0562789025, 208525.6940944895], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5046000.0000, 
sim time next is 5046600.0000, 
raw observation next is [27.66666666666667, 80.66666666666667, 1.0, 2.0, 0.3499913490659198, 0.0, 2.0, 0.0, 1.0, 2.0, 0.557197626135418, 6.911199999999997, 6.9112, 121.9260426156618, 797782.2480406505, 797782.2480406519, 209172.4211617533], 
processed observation next is [0.0, 0.391304347826087, 0.580246913580247, 0.8066666666666668, 1.0, 1.0, 0.2261801774594283, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4464970326692725, -2.6645352591003756e-16, 0.0, 0.8094621288201359, 0.2849222314430895, 0.28492223144309, 0.4022546560802948], 
reward next is 0.5977, 
noisyNet noise sample is [array([1.8078462], dtype=float32), -1.3480246]. 
=============================================
[2019-03-24 06:24:24,857] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 3.2802099e-24 3.9295340e-26 2.0690413e-22 3.5578137e-22], sum to 1.0000
[2019-03-24 06:24:24,862] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4076
[2019-03-24 06:24:24,870] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 914498.3221254242 W.
[2019-03-24 06:24:24,877] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.41666666666666, 75.83333333333334, 1.0, 2.0, 0.8023295726243604, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 914498.3221254242, 914498.3221254237, 196432.0973587772], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5141400.0000, 
sim time next is 5142000.0000, 
raw observation next is [30.53333333333333, 75.66666666666667, 1.0, 2.0, 0.3961483748254829, 0.0, 2.0, 0.0, 1.0, 1.0, 0.6306811143740256, 6.911199999999999, 6.9112, 121.9260426156618, 903056.1345354834, 903056.1345354839, 222923.2359289618], 
processed observation next is [0.0, 0.5217391304347826, 0.6864197530864197, 0.7566666666666667, 1.0, 1.0, 0.28112901764938436, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.538351392967532, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.32252004804838696, 0.32252004804838713, 0.42869853063261887], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.8480506], dtype=float32), -0.54760283]. 
=============================================
[2019-03-24 06:24:24,895] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[30.025002]
 [29.925186]
 [29.993032]
 [29.63592 ]
 [29.49987 ]], R is [[30.31083488]
 [30.00772667]
 [30.266325  ]
 [30.55960083]
 [30.85157967]].
[2019-03-24 06:24:25,829] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 3.4588125e-29 1.0879580e-27 4.4903229e-26 6.4695931e-26], sum to 1.0000
[2019-03-24 06:24:25,834] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4659
[2019-03-24 06:24:25,842] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 962663.3022447192 W.
[2019-03-24 06:24:25,848] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.83333333333333, 70.16666666666667, 1.0, 2.0, 0.4222801509555623, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6722837530256455, 6.911199999999999, 6.9112, 121.9260426156618, 962663.3022447192, 962663.3022447196, 231084.8844955165], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5151000.0000, 
sim time next is 5151600.0000, 
raw observation next is [32.0, 71.0, 1.0, 2.0, 0.4383475949178177, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6978636470936739, 6.9112, 6.9112, 121.9260426156618, 999315.8043861691, 999315.8043861691, 236239.8319735678], 
processed observation next is [0.0, 0.6521739130434783, 0.7407407407407407, 0.71, 1.0, 1.0, 0.33136618442597343, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6223295588670923, 0.0, 0.0, 0.8094621288201359, 0.35689850156648895, 0.35689850156648895, 0.4543073691799381], 
reward next is 0.5457, 
noisyNet noise sample is [array([0.80940133], dtype=float32), -0.11184627]. 
=============================================
[2019-03-24 06:24:28,016] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.2083890e-17 2.2598231e-19 1.2022554e-17 1.5187102e-16], sum to 1.0000
[2019-03-24 06:24:28,020] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8062
[2019-03-24 06:24:28,029] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1477904.757267224 W.
[2019-03-24 06:24:28,032] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.33333333333333, 92.33333333333334, 1.0, 2.0, 0.4320557494860548, 1.0, 1.0, 0.4320557494860548, 1.0, 2.0, 0.6878468242552073, 6.911199999999999, 6.9112, 123.1863387007253, 1477904.757267224, 1477904.757267225, 311700.8804725362], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5191800.0000, 
sim time next is 5192400.0000, 
raw observation next is [24.26666666666667, 92.66666666666667, 1.0, 2.0, 0.4126760449805168, 1.0, 2.0, 0.4126760449805168, 1.0, 2.0, 0.6569937035294781, 6.911200000000001, 6.9112, 121.94756008, 1411566.48610172, 1411566.486101719, 302679.4592757643], 
processed observation next is [1.0, 0.08695652173913043, 0.4543209876543211, 0.9266666666666667, 1.0, 1.0, 0.30080481545299614, 1.0, 1.0, 0.30080481545299614, 1.0, 1.0, 0.5712421294118475, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5041308878934714, 0.504130887893471, 0.5820758832226236], 
reward next is 0.4179, 
noisyNet noise sample is [array([-1.0424906], dtype=float32), 0.8758167]. 
=============================================
[2019-03-24 06:24:28,759] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 3.0186411e-19 5.2859724e-18 3.5317365e-18 1.9078710e-16], sum to 1.0000
[2019-03-24 06:24:28,764] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4994
[2019-03-24 06:24:28,769] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 832007.4106315896 W.
[2019-03-24 06:24:28,773] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.65, 91.00000000000001, 1.0, 2.0, 0.3649979664268381, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5810886497054074, 6.911199999999999, 6.9112, 121.9260426156618, 832007.4106315896, 832007.41063159, 213543.0694563816], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5382600.0000, 
sim time next is 5383200.0000, 
raw observation next is [24.7, 91.0, 1.0, 2.0, 0.3521953397479925, 1.0, 1.0, 0.3521953397479925, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 802808.7307485647, 802808.7307485647, 193457.3925018998], 
processed observation next is [1.0, 0.30434782608695654, 0.4703703703703703, 0.91, 1.0, 1.0, 0.22880397589046728, 1.0, 0.5, 0.22880397589046728, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2867174038387731, 0.2867174038387731, 0.3720334471190381], 
reward next is 0.6280, 
noisyNet noise sample is [array([0.2803838], dtype=float32), -0.024733456]. 
=============================================
[2019-03-24 06:24:32,671] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 4.8129830e-20 8.3798372e-21 1.9346026e-20 1.9534333e-18], sum to 1.0000
[2019-03-24 06:24:32,678] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5574
[2019-03-24 06:24:32,687] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 817308.0233163065 W.
[2019-03-24 06:24:32,689] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.8, 87.33333333333334, 1.0, 2.0, 0.3585528466837641, 1.0, 1.0, 0.3585528466837641, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 817308.0233163065, 817308.023316307, 195106.290339098], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5258400.0000, 
sim time next is 5259000.0000, 
raw observation next is [26.7, 87.66666666666667, 1.0, 2.0, 0.2384837500919205, 1.0, 2.0, 0.2384837500919205, 1.0, 1.0, 0.3796738970198443, 6.9112, 6.9112, 121.94756008, 815421.3226659608, 815421.3226659608, 233578.9364554123], 
processed observation next is [1.0, 0.8695652173913043, 0.5444444444444444, 0.8766666666666667, 1.0, 1.0, 0.09343303582371487, 1.0, 1.0, 0.09343303582371487, 1.0, 0.5, 0.22459237127480533, 0.0, 0.0, 0.8096049824067558, 0.29122190095212885, 0.29122190095212885, 0.4491902624142544], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.6977489], dtype=float32), -0.19868094]. 
=============================================
[2019-03-24 06:24:32,701] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[26.790459]
 [26.690643]
 [26.829416]
 [26.697704]
 [26.840773]], R is [[26.54957771]
 [26.28408241]
 [26.61344147]
 [26.89629745]
 [27.17511559]].
[2019-03-24 06:24:36,719] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.7162480e-18 8.7114394e-18 7.1129451e-18 9.1580914e-15], sum to 1.0000
[2019-03-24 06:24:36,725] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8135
[2019-03-24 06:24:36,731] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1815141.291122506 W.
[2019-03-24 06:24:36,735] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.28333333333333, 63.83333333333334, 1.0, 2.0, 0.9648733246475565, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1815141.291122506, 1815141.291122506, 371338.5181431105], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5323800.0000, 
sim time next is 5324400.0000, 
raw observation next is [28.3, 64.0, 1.0, 2.0, 0.9188397991312447, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426156618, 1762590.61637445, 1762590.61637445, 361062.2494378882], 
processed observation next is [1.0, 0.6521739130434783, 0.6037037037037037, 0.64, 1.0, 1.0, 0.9033807132514817, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6294966487051608, 0.6294966487051608, 0.6943504796882466], 
reward next is 0.3056, 
noisyNet noise sample is [array([-0.39087066], dtype=float32), -1.2451044]. 
=============================================
[2019-03-24 06:24:37,035] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 2.4110826e-18 1.3956404e-18 5.8479142e-18 4.8600580e-16], sum to 1.0000
[2019-03-24 06:24:37,039] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8285
[2019-03-24 06:24:37,044] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1426077.407384559 W.
[2019-03-24 06:24:37,049] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.26666666666667, 93.33333333333334, 1.0, 2.0, 0.6253715154566447, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9956118195353475, 6.911199999999999, 6.9112, 121.9252528083678, 1426077.407384559, 1426077.40738456, 303865.0311681458], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5451600.0000, 
sim time next is 5452200.0000, 
raw observation next is [26.25, 93.5, 1.0, 2.0, 0.511865606634107, 1.0, 1.0, 0.511865606634107, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260423748193, 1167044.939222061, 1167044.939222062, 239077.8676022962], 
processed observation next is [1.0, 0.08695652173913043, 0.5277777777777778, 0.935, 1.0, 1.0, 0.4188876269453654, 1.0, 0.5, 0.4188876269453654, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621272211923, 0.41680176400787894, 0.41680176400787927, 0.45976513000441577], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.2188443], dtype=float32), 0.21892597]. 
=============================================
[2019-03-24 06:24:38,852] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 2.0729778e-20 5.9195870e-23 8.3255160e-20 7.2564179e-18], sum to 1.0000
[2019-03-24 06:24:38,861] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4244
[2019-03-24 06:24:38,871] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 708088.9427237179 W.
[2019-03-24 06:24:38,875] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.31666666666667, 79.33333333333334, 1.0, 2.0, 0.3106605813532879, 0.0, 1.0, 0.0, 1.0, 1.0, 0.494581763023229, 6.911199999999999, 6.9112, 121.9260426156618, 708088.9427237179, 708088.9427237182, 198131.098162222], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5353800.0000, 
sim time next is 5354400.0000, 
raw observation next is [26.23333333333333, 79.66666666666667, 1.0, 2.0, 0.6166674425094817, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 706456.9126558809, 706456.9126558809, 161149.6463552922], 
processed observation next is [1.0, 1.0, 0.5271604938271603, 0.7966666666666667, 1.0, 1.0, 0.5436517172731925, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2523060402342432, 0.2523060402342432, 0.3099031660678696], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.37058678], dtype=float32), -2.3556983]. 
=============================================
[2019-03-24 06:24:43,451] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 3.6577364e-15 7.5102245e-16 5.8422149e-15 6.6358011e-14], sum to 1.0000
[2019-03-24 06:24:43,461] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4788
[2019-03-24 06:24:43,469] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2049203.589836699 W.
[2019-03-24 06:24:43,474] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.83333333333334, 73.0, 1.0, 2.0, 0.5988682785470397, 1.0, 2.0, 0.5988682785470397, 1.0, 1.0, 0.9534178032250898, 6.9112, 6.9112, 121.94756008, 2049203.589836699, 2049203.589836699, 394759.3190244609], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5499600.0000, 
sim time next is 5500200.0000, 
raw observation next is [29.46666666666667, 74.0, 1.0, 2.0, 0.8570820810279558, 1.0, 2.0, 0.8570820810279558, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1955069.401485041, 1955069.401485041, 367907.1462294788], 
processed observation next is [1.0, 0.6521739130434783, 0.6469135802469137, 0.74, 1.0, 1.0, 0.8298596202713759, 1.0, 1.0, 0.8298596202713759, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6982390719589432, 0.6982390719589432, 0.7075137427489977], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.14162648], dtype=float32), 1.514413]. 
=============================================
[2019-03-24 06:24:46,078] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 2.8637142e-24 3.3754224e-26 6.4712536e-24 7.9982812e-24], sum to 1.0000
[2019-03-24 06:24:46,083] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9557
[2019-03-24 06:24:46,088] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 831767.3031383811 W.
[2019-03-24 06:24:46,090] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.4, 93.0, 1.0, 2.0, 0.2432618162496737, 1.0, 2.0, 0.2432618162496737, 1.0, 2.0, 0.3872807339537384, 6.9112, 6.9112, 121.94756008, 831767.3031383811, 831767.3031383811, 235248.8298148363], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5542800.0000, 
sim time next is 5543400.0000, 
raw observation next is [25.4, 93.0, 1.0, 2.0, 0.3626123645005171, 1.0, 2.0, 0.3626123645005171, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 826566.5344504811, 826566.5344504815, 196165.0230081419], 
processed observation next is [1.0, 0.13043478260869565, 0.49629629629629624, 0.93, 1.0, 1.0, 0.24120519583394892, 1.0, 1.0, 0.24120519583394892, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2952023337323147, 0.29520233373231486, 0.37724042886181136], 
reward next is 0.6228, 
noisyNet noise sample is [array([0.02445306], dtype=float32), -0.3839762]. 
=============================================
[2019-03-24 06:24:50,282] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:24:50,287] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2466
[2019-03-24 06:24:50,291] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.5, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9357347803911497, 6.911200000000001, 6.9112, 121.9260426156618, 679982.2836453911, 679982.2836453906, 181612.0152510292], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5623200.0000, 
sim time next is 5623800.0000, 
raw observation next is [23.5, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9347075960593053, 6.911199999999999, 6.9112, 121.9260426156618, 679310.3689453211, 679310.3689453214, 181459.6308518919], 
processed observation next is [0.0, 0.08695652173913043, 0.42592592592592593, 0.97, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9183844950741316, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2426108460519004, 0.2426108460519005, 0.3489608285613306], 
reward next is 0.6510, 
noisyNet noise sample is [array([0.03640919], dtype=float32), -0.504596]. 
=============================================
[2019-03-24 06:24:51,455] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.8548450e-31 3.3127767e-33 8.8261138e-31 7.0044161e-30], sum to 1.0000
[2019-03-24 06:24:51,461] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3762
[2019-03-24 06:24:51,469] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 745968.6573410097 W.
[2019-03-24 06:24:51,473] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.51666666666667, 95.66666666666666, 1.0, 2.0, 0.6545430091852068, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 745968.6573410097, 745968.6573410097, 167714.898774529], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5608200.0000, 
sim time next is 5608800.0000, 
raw observation next is [24.4, 96.0, 1.0, 2.0, 0.3251402929293187, 0.0, 2.0, 0.0, 1.0, 1.0, 0.517633935423554, 6.9112, 6.9112, 121.9260426156618, 741108.5163841984, 741108.5163841984, 202123.3957496481], 
processed observation next is [1.0, 0.9565217391304348, 0.4592592592592592, 0.96, 1.0, 1.0, 0.19659558682061748, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.3970424192794424, 0.0, 0.0, 0.8094621288201359, 0.2646816129943566, 0.2646816129943566, 0.3886988379800925], 
reward next is 0.6113, 
noisyNet noise sample is [array([-1.3113276], dtype=float32), 0.22545771]. 
=============================================
[2019-03-24 06:24:53,982] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-24 06:24:53,983] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:24:53,984] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:24:53,984] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:24:53,984] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:24:53,985] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:24:53,986] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:24:53,986] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:24:53,985] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:24:53,987] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:24:53,987] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:24:54,004] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run41
[2019-03-24 06:24:54,004] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run41
[2019-03-24 06:24:54,027] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run41
[2019-03-24 06:24:54,028] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run41
[2019-03-24 06:24:54,111] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run41
[2019-03-24 06:25:00,925] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00637882], dtype=float32), 0.014463217]
[2019-03-24 06:25:00,926] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [17.01766894, 76.2121272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5411485666478925, 6.9112, 6.9112, 121.9260426156618, 386392.7205768006, 386392.7205768006, 105292.4261027109]
[2019-03-24 06:25:00,927] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:25:00,929] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.4402658314238753
[2019-03-24 06:25:07,644] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00637882], dtype=float32), 0.014463217]
[2019-03-24 06:25:07,646] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.66666666666666, 42.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5015587660977456, 6.911200000000001, 6.9112, 121.9260426156618, 358118.2786905263, 358118.2786905258, 109588.6573290397]
[2019-03-24 06:25:07,647] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:25:07,651] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.5694215444810543
[2019-03-24 06:25:24,783] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00637882], dtype=float32), 0.014463217]
[2019-03-24 06:25:24,784] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [19.82988071833334, 99.60489431666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.668799665581514, 6.911200000000001, 6.9112, 121.9260426156618, 499416.7047638915, 499416.7047638911, 140076.8127153877]
[2019-03-24 06:25:24,786] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:25:24,789] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.040272046207708634
[2019-03-24 06:25:50,944] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00637882], dtype=float32), 0.014463217]
[2019-03-24 06:25:50,946] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [33.43333333333334, 33.0, 1.0, 2.0, 0.8108891387501008, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9674577339732593, 6.911200000000001, 6.9112, 121.925602114203, 1676139.588270636, 1676139.588270635, 332343.0363067294]
[2019-03-24 06:25:50,948] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:25:50,953] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 7.4759599e-29 2.2499517e-31 7.6815601e-29 4.6420203e-28], sampled 0.6792169872324079
[2019-03-24 06:25:50,955] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1676139.588270636 W.
[2019-03-24 06:25:51,925] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00637882], dtype=float32), 0.014463217]
[2019-03-24 06:25:51,926] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.83333333333333, 88.33333333333334, 1.0, 2.0, 0.7513086473244299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 856311.9874868011, 856311.9874868006, 186086.6646062069]
[2019-03-24 06:25:51,927] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:25:51,930] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.2588622e-32 5.1209682e-36 7.5627993e-33 2.4379140e-32], sampled 0.597135578654375
[2019-03-24 06:25:51,934] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 856311.9874868011 W.
[2019-03-24 06:25:52,614] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00637882], dtype=float32), 0.014463217]
[2019-03-24 06:25:52,616] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.84336012, 63.12331363333334, 1.0, 2.0, 0.6244679546092236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 715889.7733746492, 715889.7733746492, 162545.0024607432]
[2019-03-24 06:25:52,617] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:25:52,621] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.7054835e-36 0.0000000e+00 7.2381841e-37 2.1805478e-36], sampled 0.8723587882560309
[2019-03-24 06:25:52,622] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 715889.7733746492 W.
[2019-03-24 06:26:08,918] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00637882], dtype=float32), 0.014463217]
[2019-03-24 06:26:08,919] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [30.42395414, 60.37769016, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.835448712776285, 6.9112, 121.9224760285783, 1636425.642448653, 1163141.538031427, 245582.5270229956]
[2019-03-24 06:26:08,921] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:26:08,924] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 4.9845383e-33 1.5859300e-36 2.8271761e-33 8.8527435e-33], sampled 0.2927072025401919
[2019-03-24 06:26:08,925] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1636425.642448653 W.
[2019-03-24 06:26:31,136] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00637882], dtype=float32), 0.014463217]
[2019-03-24 06:26:31,137] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [17.20192005, 76.85054194, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4571838219651135, 6.9112, 6.9112, 121.9260426156618, 326523.7333413525, 326523.7333413525, 99446.44435786003]
[2019-03-24 06:26:31,138] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:26:31,141] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.5070506205293829
[2019-03-24 06:26:41,874] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 06:26:42,200] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 06:26:42,326] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 06:26:42,353] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.7414 2219189295.2583 543.0000
[2019-03-24 06:26:42,420] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8403.6009 2292939572.8233 697.0000
[2019-03-24 06:26:43,435] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1000000, evaluation results [1000000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.741374971278, 2219189295.2583184, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8403.600948472696, 2292939572.823255, 697.0]
[2019-03-24 06:26:46,508] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:26:46,516] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3211
[2019-03-24 06:26:46,524] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.21666666666667, 92.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7290753687075853, 6.911200000000001, 6.9112, 121.9260426156618, 544621.9911798061, 544621.9911798056, 149064.5138256003], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5724600.0000, 
sim time next is 5725200.0000, 
raw observation next is [21.23333333333333, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7264855797653648, 6.9112, 6.9112, 121.9260426156618, 542732.6125100848, 542732.6125100848, 148657.5552051671], 
processed observation next is [0.0, 0.2608695652173913, 0.34197530864197523, 0.92, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6581069747067059, 0.0, 0.0, 0.8094621288201359, 0.19383307589645885, 0.19383307589645885, 0.2858799138560906], 
reward next is 0.7141, 
noisyNet noise sample is [array([-1.1404307], dtype=float32), -0.03502374]. 
=============================================
[2019-03-24 06:26:50,206] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.8599291e-27 2.1573474e-29 4.5849667e-27 4.5729170e-26], sum to 1.0000
[2019-03-24 06:26:50,214] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6599
[2019-03-24 06:26:50,220] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1129080.611101953 W.
[2019-03-24 06:26:50,223] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.5, 66.0, 1.0, 2.0, 0.9076742120189797, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.957554967265675, 6.9112, 121.9257413409774, 1129080.611101953, 1105342.783357395, 222449.5382394447], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5821200.0000, 
sim time next is 5821800.0000, 
raw observation next is [24.65, 64.16666666666667, 1.0, 2.0, 0.4257817542296776, 1.0, 1.0, 0.4257817542296776, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.926014701554, 1030625.351336825, 1030625.351336825, 215852.3026894941], 
processed observation next is [1.0, 0.391304347826087, 0.46851851851851845, 0.6416666666666667, 1.0, 1.0, 0.3164068502734258, 1.0, 0.5, 0.3164068502734258, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094619434994887, 0.36808048262029464, 0.36808048262029464, 0.41510058209518097], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.19039778], dtype=float32), 0.4235781]. 
=============================================
[2019-03-24 06:27:07,545] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:27:07,551] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9877
[2019-03-24 06:27:07,556] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.06666666666667, 62.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8736986788166661, 6.911200000000001, 6.9112, 121.9260426156618, 640934.2636662535, 640934.2636662531, 172155.8086800608], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6117000.0000, 
sim time next is 6117600.0000, 
raw observation next is [27.93333333333333, 63.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.873930357552439, 6.911200000000001, 6.9112, 121.9260426156618, 641187.9420892844, 641187.942089284, 172167.0403575091], 
processed observation next is [1.0, 0.8260869565217391, 0.5901234567901233, 0.6333333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8424129469405486, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22899569360331587, 0.2289956936033157, 0.33109046222597904], 
reward next is 0.6689, 
noisyNet noise sample is [array([-0.64825386], dtype=float32), 1.9818039]. 
=============================================
[2019-03-24 06:27:13,725] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.000000e+00 5.200540e-36 0.000000e+00 2.915624e-37 8.746118e-37], sum to 1.0000
[2019-03-24 06:27:13,733] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3567
[2019-03-24 06:27:13,739] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 746002.4946121684 W.
[2019-03-24 06:27:13,750] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.95, 62.16666666666667, 1.0, 2.0, 0.3272863424661094, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5210505161780787, 6.911199999999999, 6.9112, 121.9260426156618, 746002.4946121684, 746002.4946121689, 202722.6356044431], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6277800.0000, 
sim time next is 6278400.0000, 
raw observation next is [30.0, 62.0, 1.0, 2.0, 0.2188077609291132, 1.0, 1.0, 0.2188077609291132, 1.0, 2.0, 0.3483490814704248, 6.9112, 6.9112, 121.94756008, 748112.5462105114, 748112.5462105114, 226836.8324773414], 
processed observation next is [0.0, 0.6956521739130435, 0.6666666666666666, 0.62, 1.0, 1.0, 0.07000923920132524, 1.0, 0.5, 0.07000923920132524, 1.0, 1.0, 0.185436351838031, 0.0, 0.0, 0.8096049824067558, 0.2671830522180398, 0.2671830522180398, 0.4362246778410412], 
reward next is 0.5638, 
noisyNet noise sample is [array([0.05087913], dtype=float32), 0.93631965]. 
=============================================
[2019-03-24 06:27:21,289] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.1080930e-18 5.2324044e-19 4.7516398e-17 7.7266938e-16], sum to 1.0000
[2019-03-24 06:27:21,299] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7981
[2019-03-24 06:27:21,307] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2138586.475808684 W.
[2019-03-24 06:27:21,310] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.3, 80.5, 1.0, 2.0, 0.937437835245224, 1.0, 2.0, 0.937437835245224, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2138586.475808684, 2138586.475808684, 403819.5276561123], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6517800.0000, 
sim time next is 6518400.0000, 
raw observation next is [28.43333333333333, 80.0, 1.0, 2.0, 0.9465707119644083, 1.0, 2.0, 0.9465707119644083, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2159446.59531383, 2159446.59531383, 408042.8438211816], 
processed observation next is [1.0, 0.43478260869565216, 0.6086419753086418, 0.8, 1.0, 1.0, 0.9363937047195338, 1.0, 1.0, 0.9363937047195338, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.7712309268977964, 0.7712309268977964, 0.7846977765791955], 
reward next is 0.2153, 
noisyNet noise sample is [array([1.9285613], dtype=float32), 0.20096041]. 
=============================================
[2019-03-24 06:27:26,006] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 1.8067725e-21 1.0264949e-22 1.3075448e-21 3.7990696e-20], sum to 1.0000
[2019-03-24 06:27:26,014] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3099
[2019-03-24 06:27:26,016] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1004332.723171522 W.
[2019-03-24 06:27:26,018] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.56666666666666, 83.66666666666667, 1.0, 2.0, 0.4405468136634656, 1.0, 2.0, 0.4405468136634656, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1004332.723171522, 1004332.723171523, 217608.8910498827], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6493200.0000, 
sim time next is 6493800.0000, 
raw observation next is [26.53333333333333, 83.83333333333333, 1.0, 2.0, 0.2883810204969998, 1.0, 2.0, 0.2883810204969998, 1.0, 1.0, 0.4591119765453776, 6.9112, 6.9112, 121.94756008, 986139.3310877329, 986139.3310877329, 251646.1597060734], 
processed observation next is [1.0, 0.13043478260869565, 0.5382716049382715, 0.8383333333333333, 1.0, 1.0, 0.15283454821071407, 1.0, 1.0, 0.15283454821071407, 1.0, 0.5, 0.323889970681722, 0.0, 0.0, 0.8096049824067558, 0.3521926182456189, 0.3521926182456189, 0.48393492251167963], 
reward next is 0.5161, 
noisyNet noise sample is [array([1.155546], dtype=float32), 1.3979193]. 
=============================================
[2019-03-24 06:27:30,631] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 3.2260249e-35 0.0000000e+00 2.5000485e-36 1.2455476e-35], sum to 1.0000
[2019-03-24 06:27:30,637] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9833
[2019-03-24 06:27:30,644] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 731495.7052364501 W.
[2019-03-24 06:27:30,650] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.96666666666667, 43.66666666666667, 1.0, 2.0, 0.5777568087624624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 731495.7052364501, 731495.7052364501, 156738.3037146159], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6601200.0000, 
sim time next is 6601800.0000, 
raw observation next is [26.13333333333333, 42.83333333333333, 1.0, 2.0, 0.2796884749819852, 0.0, 2.0, 0.0, 1.0, 1.0, 0.4746803298662332, 6.911199999999999, 6.9112, 121.9260426156618, 704049.6869426618, 704049.6869426622, 185248.193358461], 
processed observation next is [1.0, 0.391304347826087, 0.5234567901234567, 0.4283333333333333, 1.0, 1.0, 0.14248627974045855, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.34335041233279145, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2514463167652363, 0.2514463167652365, 0.35624652568934806], 
reward next is 0.6438, 
noisyNet noise sample is [array([-1.061526], dtype=float32), 0.26134902]. 
=============================================
[2019-03-24 06:27:32,144] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-24 06:27:32,145] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:27:32,145] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:27:32,148] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:27:32,149] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:27:32,157] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:27:32,158] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:27:32,158] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:27:32,158] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:27:32,159] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:27:32,160] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:27:32,178] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run42
[2019-03-24 06:27:32,178] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run42
[2019-03-24 06:27:32,203] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run42
[2019-03-24 06:27:32,228] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run42
[2019-03-24 06:27:32,283] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run42
[2019-03-24 06:27:33,349] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00644589], dtype=float32), 0.014601823]
[2019-03-24 06:27:33,349] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.2, 69.16666666666667, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.6691868222859606, 6.9112, 6.9112, 121.9260426156618, 500009.6964110497, 500009.6964110497, 140930.7201866824]
[2019-03-24 06:27:33,350] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:27:33,351] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [9.9999332e-01 2.1195369e-06 3.9809424e-07 1.8786332e-06 2.3117391e-06], sampled 0.6170580736379484
[2019-03-24 06:27:34,336] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00644589], dtype=float32), 0.014601823]
[2019-03-24 06:27:34,337] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.99527157333333, 80.62096692, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7736879892135483, 6.9112, 6.9112, 121.9260426156618, 575734.2295888177, 575734.2295888177, 156499.8437510321]
[2019-03-24 06:27:34,339] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:27:34,342] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.5861449640268392
[2019-03-24 06:27:55,197] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00644589], dtype=float32), 0.014601823]
[2019-03-24 06:27:55,198] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [16.65156436, 78.0872897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4255777255608622, 6.911199999999999, 6.9112, 121.9260426156618, 303869.0748785617, 303869.0748785621, 93907.62276345353]
[2019-03-24 06:27:55,199] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:27:55,202] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.8113383134951058
[2019-03-24 06:28:11,641] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00644589], dtype=float32), 0.014601823]
[2019-03-24 06:28:11,642] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.44455295, 87.82716244, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8245905567524078, 6.911199999999999, 6.9112, 121.9260426156618, 610598.4590387228, 610598.4590387233, 164222.7440176254]
[2019-03-24 06:28:11,644] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:28:11,647] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.4337727131766098
[2019-03-24 06:28:14,335] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00644589], dtype=float32), 0.014601823]
[2019-03-24 06:28:14,336] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [31.4, 53.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.926472672432828, 6.911200000000001, 6.9112, 121.9260426156618, 668966.2982240412, 668966.2982240409, 180935.7393141789]
[2019-03-24 06:28:14,339] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:28:14,342] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.3408214067372859
[2019-03-24 06:28:26,147] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00644589], dtype=float32), 0.014601823]
[2019-03-24 06:28:26,147] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.83333333333334, 95.0, 1.0, 2.0, 0.6670456449988271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 760224.7096911407, 760224.7096911407, 169997.6380132942]
[2019-03-24 06:28:26,148] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:28:26,152] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.1614291518363381
[2019-03-24 06:28:26,152] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 760224.7096911407 W.
[2019-03-24 06:28:48,111] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00644589], dtype=float32), 0.014601823]
[2019-03-24 06:28:48,112] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.0, 59.0, 1.0, 2.0, 0.746407586962636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 850722.8518194492, 850722.8518194492, 185122.9488592086]
[2019-03-24 06:28:48,113] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:28:48,116] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.9999501430677489
[2019-03-24 06:28:48,117] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 850722.8518194492 W.
[2019-03-24 06:28:50,042] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00644589], dtype=float32), 0.014601823]
[2019-03-24 06:28:50,043] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [32.5, 46.5, 1.0, 2.0, 0.5932635460019976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 683806.7546368907, 683806.7546368907, 157297.7364049985]
[2019-03-24 06:28:50,044] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:28:50,047] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.30706992837931835
[2019-03-24 06:28:53,655] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00644589], dtype=float32), 0.014601823]
[2019-03-24 06:28:53,656] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.53333333333333, 85.33333333333334, 1.0, 1.0, 0.5624250080028771, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260145649245, 670311.9161528709, 670311.9161528709, 153027.2083020795]
[2019-03-24 06:28:53,657] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:28:53,659] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.10658364438413215
[2019-03-24 06:29:02,420] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00644589], dtype=float32), 0.014601823]
[2019-03-24 06:29:02,423] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [30.45, 27.16666666666666, 1.0, 2.0, 0.5199664623463242, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8700653505549633, 6.911199999999999, 6.9112, 121.9260424963631, 1297567.122720665, 1297567.122720666, 259159.6767674789]
[2019-03-24 06:29:02,424] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:29:02,427] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.2997598131942164
[2019-03-24 06:29:02,428] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1297567.122720665 W.
[2019-03-24 06:29:16,290] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00644589], dtype=float32), 0.014601823]
[2019-03-24 06:29:16,293] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.1, 58.0, 1.0, 2.0, 0.9501597582560093, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.158747326822892, 6.9112, 121.9249596937286, 1269439.157056605, 1142673.926106885, 231840.8323174664]
[2019-03-24 06:29:16,295] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:29:16,297] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.000000e+00 7.363308e-38 0.000000e+00 4.835501e-38 9.774838e-38], sampled 0.3209491293594271
[2019-03-24 06:29:16,299] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1269439.157056605 W.
[2019-03-24 06:29:19,175] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 06:29:19,191] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 06:29:19,457] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 06:29:19,684] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 06:29:19,837] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 06:29:20,849] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1025000, evaluation results [1025000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 06:29:21,900] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 6.7805878e-35 0.0000000e+00 1.2250683e-35 6.1130981e-35], sum to 1.0000
[2019-03-24 06:29:21,906] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7305
[2019-03-24 06:29:21,915] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1327143.150333934 W.
[2019-03-24 06:29:21,918] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.53333333333333, 30.33333333333334, 1.0, 2.0, 0.533927264880303, 0.0, 1.0, 0.0, 1.0, 2.0, 0.888705231220267, 6.911200000000001, 6.9112, 121.9260426156618, 1327143.150333934, 1327143.150333934, 264540.1526357249], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6626400.0000, 
sim time next is 6627000.0000, 
raw observation next is [29.66666666666667, 28.66666666666666, 1.0, 2.0, 0.519716307810988, 1.0, 1.0, 0.519716307810988, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1293619.317187122, 1293619.317187122, 245557.3265298216], 
processed observation next is [1.0, 0.6956521739130435, 0.6543209876543211, 0.2866666666666666, 1.0, 1.0, 0.42823369977498565, 1.0, 0.5, 0.42823369977498565, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.46200689899540076, 0.46200689899540076, 0.47222562794196465], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.60310227], dtype=float32), 0.74218374]. 
=============================================
[2019-03-24 06:29:21,936] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[46.176956]
 [45.2989  ]
 [44.603638]
 [44.538048]
 [44.27172 ]], R is [[45.08063126]
 [44.62982559]
 [44.1835289 ]
 [43.7416954 ]
 [43.30427933]].
[2019-03-24 06:29:26,795] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:29:26,807] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1413
[2019-03-24 06:29:26,811] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.0, 36.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5682635237473216, 6.9112, 6.9112, 121.9260426156618, 418583.0269753039, 418583.0269753039, 125523.7965617284], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6720000.0000, 
sim time next is 6720600.0000, 
raw observation next is [27.75, 37.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5658259231482449, 6.911199999999999, 6.9112, 121.9260426156618, 416837.1849485871, 416837.1849485876, 125333.8512169036], 
processed observation next is [1.0, 0.782608695652174, 0.5833333333333334, 0.37, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.45728240393530606, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14887042319592397, 0.14887042319592414, 0.24102663695558385], 
reward next is 0.7590, 
noisyNet noise sample is [array([-1.5955629], dtype=float32), 0.2948063]. 
=============================================
[2019-03-24 06:29:27,050] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:29:27,058] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3862
[2019-03-24 06:29:27,062] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.5, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5445925774765537, 6.9112, 6.9112, 121.9260426156618, 397627.6317390676, 397627.6317390676, 121805.2850100304], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6746400.0000, 
sim time next is 6747000.0000, 
raw observation next is [19.41666666666667, 79.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8071701914283521, 6.9112, 6.9112, 121.9260426156618, 589105.0529601002, 589105.0529601002, 146559.1489145313], 
processed observation next is [1.0, 0.08695652173913043, 0.2746913580246915, 0.7933333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.75896273928544, 0.0, 0.0, 0.8094621288201359, 0.21039466177146438, 0.21039466177146438, 0.2818445171433294], 
reward next is 0.7182, 
noisyNet noise sample is [array([0.25205535], dtype=float32), 0.65044576]. 
=============================================
[2019-03-24 06:29:27,081] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[58.688282]
 [58.6838  ]
 [58.68956 ]
 [58.859478]
 [59.075806]], R is [[58.68883133]
 [58.86770248]
 [59.04428101]
 [59.21854401]
 [59.3904686 ]].
[2019-03-24 06:29:28,396] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:29:28,405] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2113
[2019-03-24 06:29:28,412] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.25, 80.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6118001715936829, 6.911199999999999, 6.9112, 121.9260426156618, 445913.8868425754, 445913.8868425759, 127309.4338908929], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6748200.0000, 
sim time next is 6748800.0000, 
raw observation next is [19.16666666666667, 80.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5862066063687176, 6.911199999999999, 6.9112, 121.9260426156618, 426959.8320596946, 426959.832059695, 124936.5398810936], 
processed observation next is [1.0, 0.08695652173913043, 0.2654320987654323, 0.8033333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.48275825796089694, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15248565430703379, 0.15248565430703392, 0.24026257669441078], 
reward next is 0.7597, 
noisyNet noise sample is [array([-0.655297], dtype=float32), 1.0974133]. 
=============================================
[2019-03-24 06:29:30,218] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:29:30,226] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7317
[2019-03-24 06:29:30,230] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1419905.419428293 W.
[2019-03-24 06:29:30,234] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.05, 55.0, 1.0, 2.0, 0.6011215231208186, 0.0, 2.0, 0.0, 1.0, 2.0, 0.963420986613104, 6.911199999999997, 6.9112, 121.9260426156618, 1419905.419428293, 1419905.419428294, 293253.2224118086], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6798600.0000, 
sim time next is 6799200.0000, 
raw observation next is [28.06666666666667, 55.33333333333333, 1.0, 2.0, 0.4101155563945426, 1.0, 1.0, 0.4101155563945426, 1.0, 2.0, 0.6541254257639343, 6.9112, 6.9112, 121.94756008, 1426905.497776212, 1426905.497776212, 301625.114209829], 
processed observation next is [1.0, 0.6956521739130435, 0.5950617283950619, 0.5533333333333332, 1.0, 1.0, 0.29775661475540793, 1.0, 0.5, 0.29775661475540793, 1.0, 1.0, 0.5676567822049178, 0.0, 0.0, 0.8096049824067558, 0.5096091063486471, 0.5096091063486471, 0.5800482965573635], 
reward next is 0.4200, 
noisyNet noise sample is [array([0.65356576], dtype=float32), -0.41104722]. 
=============================================
[2019-03-24 06:29:30,251] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 5.2344203e-34 3.4423448e-37 8.5314441e-34 2.2630851e-33], sum to 1.0000
[2019-03-24 06:29:30,261] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1599
[2019-03-24 06:29:30,267] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 994643.335747879 W.
[2019-03-24 06:29:30,272] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.36666666666667, 50.33333333333333, 1.0, 2.0, 0.8037041358283685, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 994643.335747879, 994643.335747879, 199946.242347081], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6781200.0000, 
sim time next is 6781800.0000, 
raw observation next is [26.48333333333333, 50.16666666666667, 1.0, 2.0, 0.7874573383359149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 977652.430954625, 977652.430954625, 196594.5661143154], 
processed observation next is [1.0, 0.4782608695652174, 0.5364197530864196, 0.5016666666666667, 1.0, 1.0, 0.7469730218284701, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.34916158248379464, 0.34916158248379464, 0.3780664732967604], 
reward next is 0.6219, 
noisyNet noise sample is [array([-1.5877132], dtype=float32), 0.619644]. 
=============================================
[2019-03-24 06:29:31,005] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:29:31,010] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9517
[2019-03-24 06:29:31,013] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.03333333333333, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5388658312773006, 6.9112, 6.9112, 121.9260426156618, 391567.6815191884, 391567.6815191884, 120552.8971843553], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6762000.0000, 
sim time next is 6762600.0000, 
raw observation next is [20.3, 71.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5361995687681593, 6.911200000000001, 6.9112, 121.9260426156618, 390009.261106135, 390009.2611061345, 120484.946541394], 
processed observation next is [1.0, 0.2608695652173913, 0.3074074074074074, 0.715, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4202494609601991, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13928902182361963, 0.13928902182361946, 0.23170182027191155], 
reward next is 0.7683, 
noisyNet noise sample is [array([1.5902578], dtype=float32), 0.20333946]. 
=============================================
[2019-03-24 06:29:33,167] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 9.417999e-37 5.478068e-37], sum to 1.0000
[2019-03-24 06:29:33,172] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2056
[2019-03-24 06:29:33,181] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1399207.70470657 W.
[2019-03-24 06:29:33,185] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.95, 60.0, 1.0, 2.0, 0.6048335005546845, 1.0, 2.0, 0.6048335005546845, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260425521411, 1399207.70470657, 1399207.70470657, 270680.0782339292], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7047000.0000, 
sim time next is 7047600.0000, 
raw observation next is [28.13333333333333, 59.33333333333333, 1.0, 2.0, 0.6650298728078895, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9813653891574123, 6.911200000000001, 6.9112, 121.9260426156424, 1487257.070591724, 1487257.070591724, 307944.9154679191], 
processed observation next is [1.0, 0.5652173913043478, 0.5975308641975308, 0.5933333333333333, 1.0, 1.0, 0.6012260390570113, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9767067364467654, 8.881784197001253e-17, 0.0, 0.8094621288200071, 0.5311632394970442, 0.5311632394970442, 0.592201760515229], 
reward next is 0.4078, 
noisyNet noise sample is [array([1.0443187], dtype=float32), -1.4337202]. 
=============================================
[2019-03-24 06:29:35,292] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:29:35,299] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3993
[2019-03-24 06:29:35,306] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.05, 66.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6843782802561867, 6.911200000000001, 6.9112, 121.9260426156618, 511235.6260102167, 511235.6260102162, 142122.1409191964], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6906600.0000, 
sim time next is 6907200.0000, 
raw observation next is [23.9, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6792425409230335, 6.911200000000001, 6.9112, 121.9260426156618, 507329.4542239311, 507329.4542239307, 141408.2027640163], 
processed observation next is [0.0, 0.9565217391304348, 0.4407407407407407, 0.67, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5990531761537918, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18118909079426113, 0.18118909079426096, 0.27193885146926217], 
reward next is 0.7281, 
noisyNet noise sample is [array([0.60033655], dtype=float32), -1.7014436]. 
=============================================
[2019-03-24 06:29:41,070] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:29:41,076] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9563
[2019-03-24 06:29:41,082] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.0, 51.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9228640243576209, 6.9112, 6.9112, 121.9260426156618, 671967.9655011167, 671967.9655011167, 179639.6683041687], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6967200.0000, 
sim time next is 6967800.0000, 
raw observation next is [31.0, 50.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.914289403080061, 6.9112, 6.9112, 121.9260426156618, 666804.8409965873, 666804.8409965873, 178293.8827441545], 
processed observation next is [0.0, 0.6521739130434783, 0.7037037037037037, 0.505, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8928617538500763, 0.0, 0.0, 0.8094621288201359, 0.23814458607020975, 0.23814458607020975, 0.3428728514310664], 
reward next is 0.6571, 
noisyNet noise sample is [array([1.0980679], dtype=float32), -0.03171028]. 
=============================================
[2019-03-24 06:29:41,238] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:29:41,252] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6741
[2019-03-24 06:29:41,260] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.1, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.817302924978459, 6.911199999999999, 6.9112, 121.9260426156618, 610530.3801565837, 610530.3801565842, 157009.2763654682], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7012800.0000, 
sim time next is 7013400.0000, 
raw observation next is [21.01666666666667, 87.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9057963968243443, 6.911199999999999, 6.9112, 121.9260426156618, 676657.275122816, 676657.2751228164, 167477.7915514601], 
processed observation next is [1.0, 0.17391304347826086, 0.3339506172839507, 0.8766666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8822454960304305, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24166331254386283, 0.241663312543863, 0.3220726760605002], 
reward next is 0.6779, 
noisyNet noise sample is [array([-0.85041606], dtype=float32), -0.061417986]. 
=============================================
[2019-03-24 06:29:47,678] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:29:47,686] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2951
[2019-03-24 06:29:47,691] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6124258564426286, 6.911199999999999, 6.9112, 121.9260426156618, 455359.2047939844, 455359.2047939849, 132148.4293035031], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7149600.0000, 
sim time next is 7150200.0000, 
raw observation next is [21.81666666666667, 74.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.614751953679092, 6.9112, 6.9112, 121.9260426156618, 457063.5208351438, 457063.5208351438, 132352.1248235136], 
processed observation next is [1.0, 0.782608695652174, 0.3635802469135804, 0.7416666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5184399420988649, 0.0, 0.0, 0.8094621288201359, 0.16323697172683707, 0.16323697172683707, 0.25452331696829533], 
reward next is 0.7455, 
noisyNet noise sample is [array([1.0507715], dtype=float32), 1.431727]. 
=============================================
[2019-03-24 06:29:55,856] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.7233802e-32 2.3083291e-32 2.1961627e-32 3.3801554e-31], sum to 1.0000
[2019-03-24 06:29:55,861] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8475
[2019-03-24 06:29:55,867] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 905871.8541652694 W.
[2019-03-24 06:29:55,871] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.5, 82.0, 1.0, 2.0, 0.3765024221274395, 1.0, 2.0, 0.3765024221274395, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 905871.8541652694, 905871.8541652699, 201842.4380127918], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7293600.0000, 
sim time next is 7294200.0000, 
raw observation next is [22.61666666666667, 81.16666666666667, 1.0, 2.0, 0.3762335966841198, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6096276568611476, 6.9112, 6.9112, 121.9260426156618, 908230.2889891171, 908230.2889891171, 215105.5208954081], 
processed observation next is [1.0, 0.43478260869565216, 0.39320987654321005, 0.8116666666666668, 1.0, 1.0, 0.25742094843347596, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.5120345710764345, 0.0, 0.0, 0.8094621288201359, 0.3243679603532561, 0.3243679603532561, 0.4136644632604002], 
reward next is 0.5863, 
noisyNet noise sample is [array([-0.4424019], dtype=float32), 0.098843746]. 
=============================================
[2019-03-24 06:29:56,350] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:29:56,359] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2440
[2019-03-24 06:29:56,362] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1218471.075251046 W.
[2019-03-24 06:29:56,366] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.9, 61.0, 1.0, 2.0, 0.5177297154182188, 1.0, 1.0, 0.5177297154182188, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1218471.075251046, 1218471.075251046, 242649.5962844248], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7318800.0000, 
sim time next is 7319400.0000, 
raw observation next is [26.73333333333333, 61.66666666666667, 1.0, 2.0, 0.1952757075965368, 1.0, 2.0, 0.1952757075965368, 1.0, 1.0, 0.3123785525642633, 6.911200000000001, 6.9112, 121.94756008, 687582.6614284705, 687582.66142847, 218906.3153312364], 
processed observation next is [1.0, 0.7391304347826086, 0.545679012345679, 0.6166666666666667, 1.0, 1.0, 0.04199488999587716, 1.0, 1.0, 0.04199488999587716, 1.0, 0.5, 0.14047319070532907, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.24556523622445375, 0.2455652362244536, 0.4209736833293008], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.29041538], dtype=float32), -0.17235985]. 
=============================================
[2019-03-24 06:29:56,584] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:29:56,590] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3211
[2019-03-24 06:29:56,599] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.15, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8085249106164629, 6.9112, 6.9112, 121.9260426156618, 599415.0542580202, 599415.0542580202, 161904.6635497354], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7500600.0000, 
sim time next is 7501200.0000, 
raw observation next is [23.03333333333333, 88.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8046971524841066, 6.911200000000001, 6.9112, 121.9260426156618, 596732.3222065434, 596732.322206543, 161357.9268521091], 
processed observation next is [0.0, 0.8260869565217391, 0.4086419753086419, 0.8866666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7558714406051331, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21311868650233692, 0.21311868650233676, 0.3103037054848252], 
reward next is 0.6897, 
noisyNet noise sample is [array([1.0498991], dtype=float32), 0.55283505]. 
=============================================
[2019-03-24 06:29:56,660] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:29:56,664] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5730
[2019-03-24 06:29:56,668] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.9, 65.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7481157352474531, 6.911199999999999, 6.9112, 121.9260426156618, 557402.65496929, 557402.6549692905, 152953.9042845565], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7322400.0000, 
sim time next is 7323000.0000, 
raw observation next is [25.75, 65.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7552396492538631, 6.911200000000001, 6.9112, 121.9260426156618, 562826.6897272259, 562826.6897272255, 153707.3605808769], 
processed observation next is [1.0, 0.782608695652174, 0.5092592592592593, 0.6566666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6940495615673289, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20100953204543784, 0.20100953204543767, 0.2955910780401479], 
reward next is 0.7044, 
noisyNet noise sample is [array([-0.86081123], dtype=float32), -0.9432805]. 
=============================================
[2019-03-24 06:29:56,683] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[77.570724]
 [78.55795 ]
 [78.66991 ]
 [78.66528 ]
 [75.69023 ]], R is [[77.60153961]
 [77.5313797 ]
 [77.4625473 ]
 [77.39468384]
 [76.62073517]].
[2019-03-24 06:29:58,370] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:29:58,377] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4231
[2019-03-24 06:29:58,382] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.16666666666667, 86.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6793003636800518, 6.911200000000001, 6.9112, 121.9260426156618, 507461.3409748418, 507461.3409748413, 141636.2527447845], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7341000.0000, 
sim time next is 7341600.0000, 
raw observation next is [21.13333333333333, 86.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6756057949535429, 6.9112, 6.9112, 121.9260426156618, 504646.2777987476, 504646.2777987476, 141103.4054285116], 
processed observation next is [1.0, 1.0, 0.33827160493827146, 0.8666666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5945072436919285, 0.0, 0.0, 0.8094621288201359, 0.18023081349955272, 0.18023081349955272, 0.27135270274713774], 
reward next is 0.7286, 
noisyNet noise sample is [array([1.9569973], dtype=float32), 1.2596889]. 
=============================================
[2019-03-24 06:30:01,927] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.1194863e-38], sum to 1.0000
[2019-03-24 06:30:01,934] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3085
[2019-03-24 06:30:01,940] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1196990.214955498 W.
[2019-03-24 06:30:01,944] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.28333333333333, 90.83333333333334, 1.0, 2.0, 0.3342918815769008, 1.0, 1.0, 0.3342918815769008, 1.0, 1.0, 0.538188456100168, 6.911199999999999, 6.9112, 121.94756008, 1196990.214955498, 1196990.214955498, 269124.4287968004], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7398600.0000, 
sim time next is 7399200.0000, 
raw observation next is [21.26666666666667, 90.66666666666667, 1.0, 2.0, 0.4622203776681509, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7475227910777706, 6.9112, 6.9112, 121.9260426156618, 1112542.747991541, 1112542.747991541, 242298.0986320819], 
processed observation next is [1.0, 0.6521739130434783, 0.34320987654320995, 0.9066666666666667, 1.0, 1.0, 0.3597861638906559, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.6844034888472134, 0.0, 0.0, 0.8094621288201359, 0.3973366957112646, 0.3973366957112646, 0.4659578819847729], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.31112593], dtype=float32), -1.0551902]. 
=============================================
[2019-03-24 06:30:03,456] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:30:03,462] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7242
[2019-03-24 06:30:03,466] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.25, 95.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.617569597837151, 6.9112, 6.9112, 121.9260426156618, 459649.9860126651, 459649.9860126651, 133036.0019716331], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7444200.0000, 
sim time next is 7444800.0000, 
raw observation next is [19.2, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6155980957238413, 6.911200000000001, 6.9112, 121.9260426156618, 458144.6642470029, 458144.6642470024, 132811.1884360846], 
processed observation next is [0.0, 0.17391304347826086, 0.26666666666666666, 0.96, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5194976196548016, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1636230943739296, 0.16362309437392944, 0.255406131607855], 
reward next is 0.7446, 
noisyNet noise sample is [array([-0.6087506], dtype=float32), -0.2080492]. 
=============================================
[2019-03-24 06:30:04,368] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:30:04,378] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7233
[2019-03-24 06:30:04,383] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.95, 96.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6050801978607621, 6.911200000000001, 6.9112, 121.9260426156618, 449840.4341871268, 449840.4341871263, 131399.0631786638], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7447800.0000, 
sim time next is 7448400.0000, 
raw observation next is [18.9, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6029646504212294, 6.911199999999999, 6.9112, 121.9260426156618, 448160.4474447812, 448160.4474447817, 131113.0671166819], 
processed observation next is [0.0, 0.21739130434782608, 0.2555555555555555, 0.97, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5037058130265367, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16005730265885043, 0.16005730265885063, 0.2521405136859267], 
reward next is 0.7479, 
noisyNet noise sample is [array([1.9194951], dtype=float32), -0.8452301]. 
=============================================
[2019-03-24 06:30:09,466] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:30:09,473] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8165
[2019-03-24 06:30:09,480] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.66666666666667, 67.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8928227809572105, 6.9112, 6.9112, 121.9260426156618, 651426.3207557818, 651426.3207557818, 175372.9818776219], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7563000.0000, 
sim time next is 7563600.0000, 
raw observation next is [28.0, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8998410542954765, 6.9112, 6.9112, 121.9260426156618, 655585.9463034628, 655585.9463034628, 176474.5224337741], 
processed observation next is [0.0, 0.5652173913043478, 0.5925925925925926, 0.66, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8748013178693456, 0.0, 0.0, 0.8094621288201359, 0.23413783796552246, 0.23413783796552246, 0.33937408160341176], 
reward next is 0.6606, 
noisyNet noise sample is [array([-0.10831313], dtype=float32), 0.27293944]. 
=============================================
[2019-03-24 06:30:09,714] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-24 06:30:09,715] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:30:09,716] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:30:09,717] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:30:09,717] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:30:09,717] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:30:09,718] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:30:09,718] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:30:09,719] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:30:09,721] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:30:09,722] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:30:09,735] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run43
[2019-03-24 06:30:09,763] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run43
[2019-03-24 06:30:09,788] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run43
[2019-03-24 06:30:09,789] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run43
[2019-03-24 06:30:09,837] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run43
[2019-03-24 06:30:18,441] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00676433], dtype=float32), 0.01522479]
[2019-03-24 06:30:18,443] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.66637066666667, 45.99437939666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.63993712113215, 6.9112, 6.9112, 121.9260426156618, 478190.9618061823, 478190.9618061823, 138649.537804698]
[2019-03-24 06:30:18,444] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:30:18,446] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.5834569483822202
[2019-03-24 06:30:48,757] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00676433], dtype=float32), 0.01522479]
[2019-03-24 06:30:48,759] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.53333333333333, 89.0, 1.0, 2.0, 0.6683611021420129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 761724.6668934699, 761724.6668934699, 170238.7939817445]
[2019-03-24 06:30:48,760] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:30:48,764] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.709428244607366
[2019-03-24 06:30:48,765] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 761724.6668934699 W.
[2019-03-24 06:30:50,308] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00676433], dtype=float32), 0.01522479]
[2019-03-24 06:30:50,311] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.0, 70.0, 1.0, 2.0, 0.7125863358728755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 812154.4397895766, 812154.4397895766, 178544.1714482781]
[2019-03-24 06:30:50,311] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:30:50,313] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.07906559894722076
[2019-03-24 06:30:50,314] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 812154.4397895766 W.
[2019-03-24 06:30:53,329] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00676433], dtype=float32), 0.01522479]
[2019-03-24 06:30:53,330] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.40000000000001, 83.33333333333334, 1.0, 2.0, 0.7215280811141246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 822351.062347438, 822351.062347438, 180260.9006552667]
[2019-03-24 06:30:53,332] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:30:53,336] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.0014759817150578058
[2019-03-24 06:30:53,337] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 822351.062347438 W.
[2019-03-24 06:30:56,491] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00676433], dtype=float32), 0.01522479]
[2019-03-24 06:30:56,492] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.0, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9457571932142402, 6.911200000000001, 6.9112, 121.9260426156618, 685028.0569427606, 685028.0569427601, 183317.5023944235]
[2019-03-24 06:30:56,495] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:30:56,497] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.23978128062573278
[2019-03-24 06:30:57,853] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00676433], dtype=float32), 0.01522479]
[2019-03-24 06:30:57,854] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.83333333333334, 75.66666666666667, 1.0, 2.0, 0.8470463105024759, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 965498.7384512568, 965498.7384512568, 205864.2959053983]
[2019-03-24 06:30:57,856] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:30:57,859] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.3060741976340511
[2019-03-24 06:30:57,860] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 965498.7384512568 W.
[2019-03-24 06:31:08,870] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00676433], dtype=float32), 0.01522479]
[2019-03-24 06:31:08,871] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.8, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7051706782317277, 6.9112, 6.9112, 121.9260426156618, 526741.4020262326, 526741.4020262326, 146412.5571313221]
[2019-03-24 06:31:08,875] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:31:08,878] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.005158525355136612
[2019-03-24 06:31:16,330] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00676433], dtype=float32), 0.01522479]
[2019-03-24 06:31:16,330] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.83333333333334, 73.0, 1.0, 2.0, 0.6348712509635868, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 723538.5947233858, 723538.5947233858, 164179.9312501746]
[2019-03-24 06:31:16,331] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:31:16,333] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.20269625928079427
[2019-03-24 06:31:16,334] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 723538.5947233858 W.
[2019-03-24 06:31:21,883] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00676433], dtype=float32), 0.01522479]
[2019-03-24 06:31:21,884] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.66666666666666, 66.0, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.659537663260437, 6.9112, 121.923131701303, 1546285.690430536, 1163079.070236596, 245588.8751749409]
[2019-03-24 06:31:21,884] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:31:21,887] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.10631367610755127
[2019-03-24 06:31:21,889] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1546285.690430536 W.
[2019-03-24 06:31:31,282] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00676433], dtype=float32), 0.01522479]
[2019-03-24 06:31:31,282] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.41666666666666, 58.66666666666666, 1.0, 2.0, 0.8312675621801335, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9962374679269395, 6.9112, 6.9112, 121.925112983053, 1664165.776230174, 1664165.776230174, 342290.9118175929]
[2019-03-24 06:31:31,284] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:31:31,287] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.45098480696159726
[2019-03-24 06:31:31,288] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1664165.776230174 W.
[2019-03-24 06:31:32,020] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00676433], dtype=float32), 0.01522479]
[2019-03-24 06:31:32,021] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.35, 68.5, 1.0, 2.0, 0.6798159826932249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 774786.2811597475, 774786.2811597466, 172358.2300258349]
[2019-03-24 06:31:32,023] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:31:32,026] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.8444770759341814
[2019-03-24 06:31:32,027] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 774786.2811597475 W.
[2019-03-24 06:31:57,073] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 06:31:57,170] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 06:31:57,313] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 06:31:57,428] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 06:31:57,457] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8403.6543 2292911235.5092 697.0000
[2019-03-24 06:31:58,473] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1050000, evaluation results [1050000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8403.654257497506, 2292911235.509193, 697.0]
[2019-03-24 06:32:00,281] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:32:00,291] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1523
[2019-03-24 06:32:00,297] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.1, 86.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.732641395200508, 6.9112, 6.9112, 121.9260426156618, 547108.9795020476, 547108.9795020476, 149817.8158890374], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7605600.0000, 
sim time next is 7606200.0000, 
raw observation next is [22.0, 86.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7247915139082873, 6.9112, 6.9112, 121.9260426156618, 541403.6652583255, 541403.6652583255, 148616.9873664154], 
processed observation next is [1.0, 0.0, 0.37037037037037035, 0.8616666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.655989392385359, 0.0, 0.0, 0.8094621288201359, 0.1933584518779734, 0.1933584518779734, 0.28580189878156803], 
reward next is 0.7142, 
noisyNet noise sample is [array([-1.285905], dtype=float32), -0.42926073]. 
=============================================
[2019-03-24 06:32:00,302] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:32:00,307] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8023
[2019-03-24 06:32:00,313] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.96666666666667, 64.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8160673554186533, 6.911200000000001, 6.9112, 121.9260426156618, 604120.487263188, 604120.4872631875, 163204.1034168853], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7579200.0000, 
sim time next is 7579800.0000, 
raw observation next is [26.8, 65.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8196848361030991, 6.9112, 6.9112, 121.9260426156618, 606565.3915639599, 606565.3915639599, 163749.8692842853], 
processed observation next is [0.0, 0.7391304347826086, 0.5481481481481482, 0.655, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7746060451288739, 0.0, 0.0, 0.8094621288201359, 0.21663049698712852, 0.21663049698712852, 0.3149035947774717], 
reward next is 0.6851, 
noisyNet noise sample is [array([1.5764514], dtype=float32), -0.090878524]. 
=============================================
[2019-03-24 06:32:00,729] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:32:00,734] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1680
[2019-03-24 06:32:00,737] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.55, 56.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5547542563550264, 6.9112, 6.9112, 121.9260426156618, 407934.8339311631, 407934.8339311631, 123982.5223702006], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7799400.0000, 
sim time next is 7800000.0000, 
raw observation next is [23.76666666666667, 55.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5525769736840838, 6.911200000000001, 6.9112, 121.9260426156618, 406506.3521774011, 406506.3521774007, 123879.2803104298], 
processed observation next is [1.0, 0.2608695652173913, 0.43580246913580256, 0.55, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.44072121710510465, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14518084006335752, 0.1451808400633574, 0.23822938521236497], 
reward next is 0.7618, 
noisyNet noise sample is [array([1.1771293], dtype=float32), -0.35060075]. 
=============================================
[2019-03-24 06:32:00,757] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[67.951866]
 [67.90178 ]
 [67.79598 ]
 [67.964806]
 [67.96321 ]], R is [[68.03281403]
 [68.11405945]
 [68.19527435]
 [68.26618195]
 [68.34519958]].
[2019-03-24 06:32:00,967] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:32:00,977] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8407
[2019-03-24 06:32:00,981] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.93333333333334, 90.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6359035913243569, 6.911199999999999, 6.9112, 121.9260426156618, 473637.0440095924, 473637.0440095928, 135146.2518846782], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7618800.0000, 
sim time next is 7619400.0000, 
raw observation next is [19.85, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6462758006399626, 6.9112, 6.9112, 121.9260426156618, 481238.3611880452, 481238.3611880452, 136062.4459859309], 
processed observation next is [1.0, 0.17391304347826086, 0.2907407407407408, 0.91, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5578447507999532, 0.0, 0.0, 0.8094621288201359, 0.1718708432814447, 0.1718708432814447, 0.2616585499729441], 
reward next is 0.7383, 
noisyNet noise sample is [array([0.98489606], dtype=float32), 0.3381307]. 
=============================================
[2019-03-24 06:32:02,475] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:32:02,481] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9811
[2019-03-24 06:32:02,490] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.03333333333333, 83.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8273756171102014, 6.911200000000001, 6.9112, 121.9260426156618, 611933.342262284, 611933.3422622835, 164833.6342157281], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7591200.0000, 
sim time next is 7591800.0000, 
raw observation next is [23.96666666666667, 83.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8255334999290207, 6.911200000000001, 6.9112, 121.9260426156618, 610695.8372560407, 610695.8372560402, 164560.7792852857], 
processed observation next is [0.0, 0.8695652173913043, 0.4432098765432099, 0.8366666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7819168749112759, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21810565616287167, 0.2181056561628715, 0.3164630370870879], 
reward next is 0.6835, 
noisyNet noise sample is [array([0.03432572], dtype=float32), -0.8763941]. 
=============================================
[2019-03-24 06:32:09,873] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:32:09,875] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:32:09,919] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run6
[2019-03-24 06:32:10,213] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 3.6661468e-37 4.0415325e-33], sum to 1.0000
[2019-03-24 06:32:10,217] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7257
[2019-03-24 06:32:10,222] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1084044.416103268 W.
[2019-03-24 06:32:10,226] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.03333333333333, 53.0, 1.0, 2.0, 0.4567513886597349, 1.0, 2.0, 0.4567513886597349, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1084044.416103268, 1084044.416103268, 224211.3409405985], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7735200.0000, 
sim time next is 7735800.0000, 
raw observation next is [28.21666666666667, 52.0, 1.0, 2.0, 0.3080747076306647, 1.0, 2.0, 0.3080747076306647, 1.0, 1.0, 0.4932713847173471, 6.9112, 6.9112, 121.94756008, 1088217.661223918, 1088217.661223918, 259039.2853600071], 
processed observation next is [1.0, 0.5217391304347826, 0.6006172839506173, 0.52, 1.0, 1.0, 0.1762794138460294, 1.0, 1.0, 0.1762794138460294, 1.0, 0.5, 0.3665892308966838, 0.0, 0.0, 0.8096049824067558, 0.38864916472282784, 0.38864916472282784, 0.4981524718461675], 
reward next is 0.5018, 
noisyNet noise sample is [array([1.285513], dtype=float32), -0.7912549]. 
=============================================
[2019-03-24 06:32:12,710] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:32:12,722] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5993
[2019-03-24 06:32:12,732] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.73333333333333, 65.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7091911132531565, 6.911200000000001, 6.9112, 121.9260426156618, 529958.9181142331, 529958.9181142326, 146098.8948460191], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7852800.0000, 
sim time next is 7853400.0000, 
raw observation next is [24.65, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7053665150697953, 6.9112, 6.9112, 121.9260426156618, 527106.5209327815, 527106.5209327815, 145610.5183126413], 
processed observation next is [1.0, 0.9130434782608695, 0.46851851851851845, 0.66, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.631708143837244, 0.0, 0.0, 0.8094621288201359, 0.18825232890456484, 0.18825232890456484, 0.2800202275243102], 
reward next is 0.7200, 
noisyNet noise sample is [array([0.3017174], dtype=float32), 0.9521286]. 
=============================================
[2019-03-24 06:32:14,495] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:32:14,496] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:32:14,514] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run6
[2019-03-24 06:32:18,072] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:32:18,072] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:32:18,082] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run6
[2019-03-24 06:32:18,405] A3C_AGENT_WORKER-Thread-12 INFO:Local step 66500, global step 1060092: loss 0.3097
[2019-03-24 06:32:18,408] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 66500, global step 1060093: learning rate 0.0000
[2019-03-24 06:32:18,421] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:32:18,421] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:32:18,451] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run6
[2019-03-24 06:32:18,484] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:32:18,488] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:32:18,513] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run6
[2019-03-24 06:32:18,568] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:32:18,569] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:32:18,586] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run6
[2019-03-24 06:32:18,993] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:32:18,993] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:32:19,002] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run6
[2019-03-24 06:32:19,027] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:32:19,029] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:32:19,038] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run6
[2019-03-24 06:32:19,061] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:32:19,063] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:32:19,071] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run6
[2019-03-24 06:32:19,173] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:32:19,173] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:32:19,183] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run6
[2019-03-24 06:32:19,240] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:32:19,240] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:32:19,243] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run6
[2019-03-24 06:32:19,274] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:32:19,274] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:32:19,278] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run6
[2019-03-24 06:32:19,441] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:32:19,442] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:32:19,444] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run6
[2019-03-24 06:32:19,629] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:32:19,629] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:32:19,634] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run6
[2019-03-24 06:32:19,993] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:32:19,994] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:32:20,001] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run6
[2019-03-24 06:32:20,177] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:32:20,177] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:32:20,180] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run6
[2019-03-24 06:32:21,649] A3C_AGENT_WORKER-Thread-21 INFO:Local step 66500, global step 1061067: loss 0.5213
[2019-03-24 06:32:21,657] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 66500, global step 1061067: learning rate 0.0000
[2019-03-24 06:32:24,616] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 4.4129675e-36 0.0000000e+00 2.4272642e-37 3.2489355e-34], sum to 1.0000
[2019-03-24 06:32:24,625] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6790
[2019-03-24 06:32:24,630] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 686119.3694893485 W.
[2019-03-24 06:32:24,637] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.5, 75.5, 1.0, 2.0, 0.1880202358535996, 1.0, 1.0, 0.1880202358535996, 1.0, 2.0, 0.3063810714252874, 6.9112, 6.9112, 121.94756008, 686119.3694893485, 686119.3694893485, 215584.974809897], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 95400.0000, 
sim time next is 96000.0000, 
raw observation next is [22.4, 75.66666666666667, 1.0, 2.0, 0.1675101707449979, 1.0, 2.0, 0.1675101707449979, 1.0, 2.0, 0.273210982874672, 6.9112, 6.9112, 121.94756008, 611953.9564327017, 611953.9564327017, 209089.5408318408], 
processed observation next is [1.0, 0.08695652173913043, 0.38518518518518513, 0.7566666666666667, 1.0, 1.0, 0.008940679458330842, 1.0, 1.0, 0.008940679458330842, 1.0, 1.0, 0.09151372859333998, 0.0, 0.0, 0.8096049824067558, 0.2185549844402506, 0.2185549844402506, 0.4020952708304631], 
reward next is 0.5979, 
noisyNet noise sample is [array([-1.9664255], dtype=float32), -0.106335945]. 
=============================================
[2019-03-24 06:32:24,645] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[56.95689 ]
 [59.05128 ]
 [63.021633]
 [63.889984]
 [63.81103 ]], R is [[56.63991547]
 [56.65893173]
 [56.6988945 ]
 [56.1319046 ]
 [56.2987442 ]].
[2019-03-24 06:32:26,519] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.6344977e-38], sum to 1.0000
[2019-03-24 06:32:26,522] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9760
[2019-03-24 06:32:26,525] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.1, 77.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6359885385543254, 6.911199999999999, 6.9112, 121.9260426156618, 471806.1999414873, 471806.1999414878, 133650.7337364674], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 104400.0000, 
sim time next is 105000.0000, 
raw observation next is [21.2, 76.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6712426620479938, 6.9112, 6.9112, 121.9260426156618, 498021.3938532458, 498021.3938532458, 137167.5087388331], 
processed observation next is [1.0, 0.21739130434782608, 0.34074074074074073, 0.7683333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5890533275599922, 0.0, 0.0, 0.8094621288201359, 0.17786478351901636, 0.17786478351901636, 0.26378367065160213], 
reward next is 0.7362, 
noisyNet noise sample is [array([0.20772275], dtype=float32), 1.2982895]. 
=============================================
[2019-03-24 06:32:26,545] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[64.13888 ]
 [64.49851 ]
 [64.22381 ]
 [64.19972 ]
 [65.056366]], R is [[64.72743988]
 [64.82315063]
 [64.91409302]
 [65.00192261]
 [65.08665466]].
[2019-03-24 06:32:27,177] A3C_AGENT_WORKER-Thread-2 INFO:Local step 66500, global step 1063968: loss 0.1240
[2019-03-24 06:32:27,179] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 66500, global step 1063968: learning rate 0.0000
[2019-03-24 06:32:27,789] A3C_AGENT_WORKER-Thread-9 INFO:Local step 66500, global step 1064287: loss 1.3931
[2019-03-24 06:32:27,793] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 66500, global step 1064289: learning rate 0.0000
[2019-03-24 06:32:27,866] A3C_AGENT_WORKER-Thread-15 INFO:Local step 66500, global step 1064325: loss 0.6702
[2019-03-24 06:32:27,869] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 66500, global step 1064325: learning rate 0.0000
[2019-03-24 06:32:27,972] A3C_AGENT_WORKER-Thread-11 INFO:Local step 66500, global step 1064382: loss 0.5885
[2019-03-24 06:32:27,974] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 66500, global step 1064383: learning rate 0.0000
[2019-03-24 06:32:28,079] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:32:28,083] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9436
[2019-03-24 06:32:28,086] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [32.48333333333333, 14.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6619436008716795, 6.911200000000001, 6.9112, 121.9260426156618, 472669.7761785943, 472669.7761785938, 125798.4328120519], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 157800.0000, 
sim time next is 158400.0000, 
raw observation next is [32.2, 15.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6573977303168255, 6.9112, 6.9112, 121.9260426156618, 469422.7422821842, 469422.7422821842, 125109.2357151068], 
processed observation next is [1.0, 0.8695652173913043, 0.7481481481481482, 0.15, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5717471628960318, 0.0, 0.0, 0.8094621288201359, 0.16765097938649434, 0.16765097938649434, 0.24059468406751308], 
reward next is 0.7594, 
noisyNet noise sample is [array([-0.9855965], dtype=float32), 1.1621256]. 
=============================================
[2019-03-24 06:32:28,197] A3C_AGENT_WORKER-Thread-14 INFO:Local step 66500, global step 1064496: loss 0.4647
[2019-03-24 06:32:28,202] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 66500, global step 1064496: learning rate 0.0000
[2019-03-24 06:32:28,267] A3C_AGENT_WORKER-Thread-19 INFO:Local step 66500, global step 1064529: loss 0.2015
[2019-03-24 06:32:28,270] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 66500, global step 1064530: learning rate 0.0000
[2019-03-24 06:32:28,341] A3C_AGENT_WORKER-Thread-22 INFO:Local step 66500, global step 1064568: loss 0.2157
[2019-03-24 06:32:28,342] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 66500, global step 1064568: learning rate 0.0000
[2019-03-24 06:32:28,443] A3C_AGENT_WORKER-Thread-17 INFO:Local step 66500, global step 1064622: loss 0.5722
[2019-03-24 06:32:28,445] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 66500, global step 1064622: learning rate 0.0000
[2019-03-24 06:32:28,463] A3C_AGENT_WORKER-Thread-10 INFO:Local step 66500, global step 1064630: loss 0.1741
[2019-03-24 06:32:28,465] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 66500, global step 1064630: learning rate 0.0000
[2019-03-24 06:32:28,543] A3C_AGENT_WORKER-Thread-3 INFO:Local step 66500, global step 1064671: loss 0.5416
[2019-03-24 06:32:28,545] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 66500, global step 1064672: learning rate 0.0000
[2019-03-24 06:32:28,810] A3C_AGENT_WORKER-Thread-16 INFO:Local step 66500, global step 1064811: loss 0.1662
[2019-03-24 06:32:28,813] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 66500, global step 1064811: learning rate 0.0000
[2019-03-24 06:32:28,846] A3C_AGENT_WORKER-Thread-13 INFO:Local step 66500, global step 1064828: loss 0.1156
[2019-03-24 06:32:28,849] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 66500, global step 1064828: learning rate 0.0000
[2019-03-24 06:32:29,281] A3C_AGENT_WORKER-Thread-18 INFO:Local step 66500, global step 1065050: loss 0.0576
[2019-03-24 06:32:29,286] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 66500, global step 1065051: learning rate 0.0000
[2019-03-24 06:32:29,831] A3C_AGENT_WORKER-Thread-20 INFO:Local step 66500, global step 1065336: loss 0.2491
[2019-03-24 06:32:29,839] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 66500, global step 1065338: learning rate 0.0000
[2019-03-24 06:32:32,146] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67000, global step 1066549: loss 0.1774
[2019-03-24 06:32:32,148] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67000, global step 1066549: learning rate 0.0000
[2019-03-24 06:32:36,882] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67000, global step 1069021: loss 0.1525
[2019-03-24 06:32:36,882] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67000, global step 1069021: learning rate 0.0000
[2019-03-24 06:32:37,415] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:32:37,421] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7957
[2019-03-24 06:32:37,425] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.75, 31.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5878490637114607, 6.911200000000001, 6.9112, 121.9260426156618, 424943.5181986219, 424943.5181986215, 123843.0951215168], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 322200.0000, 
sim time next is 322800.0000, 
raw observation next is [27.63333333333333, 31.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5865382132175067, 6.9112, 6.9112, 121.9260426156618, 423860.3492061299, 423860.3492061299, 123682.2287626829], 
processed observation next is [0.0, 0.7391304347826086, 0.5790123456790122, 0.3133333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4831727665218833, 0.0, 0.0, 0.8094621288201359, 0.1513786961450464, 0.1513786961450464, 0.23785043992823635], 
reward next is 0.7621, 
noisyNet noise sample is [array([0.70428234], dtype=float32), -0.5009842]. 
=============================================
[2019-03-24 06:32:39,665] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.3799839e-36 2.8310491e-34], sum to 1.0000
[2019-03-24 06:32:39,669] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8205
[2019-03-24 06:32:39,676] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.43333333333334, 43.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7075586210268199, 6.9112, 6.9112, 121.9260426156618, 505252.5290949339, 505252.5290949339, 128638.4930384982], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 372000.0000, 
sim time next is 372600.0000, 
raw observation next is [23.85, 42.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.709537216415466, 6.911199999999999, 6.9112, 121.9260426156618, 506665.868683465, 506665.8686834655, 129720.9442414397], 
processed observation next is [1.0, 0.30434782608695654, 0.43888888888888894, 0.42, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6369215205193324, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18095209595838035, 0.18095209595838055, 0.24946335431046096], 
reward next is 0.7505, 
noisyNet noise sample is [array([-0.4500545], dtype=float32), -0.7285185]. 
=============================================
[2019-03-24 06:32:40,496] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.00000000e+00 7.86161547e-31 1.22138565e-29 1.54697103e-29
 4.84043942e-26], sum to 1.0000
[2019-03-24 06:32:40,503] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4494
[2019-03-24 06:32:40,507] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1109873.939172682 W.
[2019-03-24 06:32:40,511] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.8, 33.5, 1.0, 2.0, 0.4377409242511306, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7528130125694149, 6.9112, 6.9112, 121.9260426156618, 1109873.939172682, 1109873.939172682, 229674.8176420623], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 379800.0000, 
sim time next is 380400.0000, 
raw observation next is [27.0, 33.0, 1.0, 2.0, 0.2979616021495573, 1.0, 1.0, 0.2979616021495573, 1.0, 2.0, 0.5043954503569633, 6.911199999999999, 6.9112, 121.94756008, 1123688.57303956, 1123688.57303956, 251985.729541467], 
processed observation next is [1.0, 0.391304347826087, 0.5555555555555556, 0.33, 1.0, 1.0, 0.1642400025589968, 1.0, 0.5, 0.1642400025589968, 1.0, 1.0, 0.3804943129462041, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.4013173475141286, 0.4013173475141286, 0.4845879414258981], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.397732], dtype=float32), 0.62381285]. 
=============================================
[2019-03-24 06:32:42,751] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67000, global step 1072086: loss 0.0659
[2019-03-24 06:32:42,755] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67000, global step 1072086: learning rate 0.0000
[2019-03-24 06:32:42,820] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67000, global step 1072121: loss 0.0518
[2019-03-24 06:32:42,822] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67000, global step 1072121: learning rate 0.0000
[2019-03-24 06:32:43,268] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67000, global step 1072349: loss 0.0700
[2019-03-24 06:32:43,273] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67000, global step 1072350: learning rate 0.0000
[2019-03-24 06:32:43,311] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67000, global step 1072374: loss 0.0734
[2019-03-24 06:32:43,313] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67000, global step 1072375: learning rate 0.0000
[2019-03-24 06:32:43,338] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67000, global step 1072390: loss 0.0865
[2019-03-24 06:32:43,340] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67000, global step 1072390: learning rate 0.0000
[2019-03-24 06:32:43,360] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67000, global step 1072402: loss 0.0859
[2019-03-24 06:32:43,367] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67000, global step 1072404: learning rate 0.0000
[2019-03-24 06:32:43,383] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67000, global step 1072410: loss 0.0969
[2019-03-24 06:32:43,388] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67000, global step 1072411: learning rate 0.0000
[2019-03-24 06:32:43,647] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67000, global step 1072545: loss 0.0501
[2019-03-24 06:32:43,649] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67000, global step 1072545: learning rate 0.0000
[2019-03-24 06:32:43,694] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67000, global step 1072569: loss 0.0575
[2019-03-24 06:32:43,696] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67000, global step 1072569: learning rate 0.0000
[2019-03-24 06:32:44,030] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67000, global step 1072745: loss 0.0966
[2019-03-24 06:32:44,031] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67000, global step 1072745: learning rate 0.0000
[2019-03-24 06:32:44,149] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67000, global step 1072806: loss 0.0949
[2019-03-24 06:32:44,151] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67000, global step 1072807: learning rate 0.0000
[2019-03-24 06:32:44,208] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67000, global step 1072834: loss 0.0550
[2019-03-24 06:32:44,209] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67000, global step 1072835: learning rate 0.0000
[2019-03-24 06:32:44,328] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67000, global step 1072898: loss 0.0479
[2019-03-24 06:32:44,329] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67000, global step 1072898: learning rate 0.0000
[2019-03-24 06:32:44,945] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 7.2155304e-35 2.5425311e-35 3.6006795e-33 1.8463093e-32], sum to 1.0000
[2019-03-24 06:32:44,953] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1153
[2019-03-24 06:32:44,967] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67000, global step 1073227: loss 0.1197
[2019-03-24 06:32:44,968] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1064845.47846335 W.
[2019-03-24 06:32:44,971] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.83333333333334, 31.66666666666667, 1.0, 2.0, 0.2923744539041154, 1.0, 2.0, 0.2923744539041154, 1.0, 2.0, 0.4756282522555529, 6.9112, 6.9112, 121.94756008, 1064845.47846335, 1064845.47846335, 252155.731602052], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 478200.0000, 
sim time next is 478800.0000, 
raw observation next is [31.0, 31.0, 1.0, 2.0, 0.4745235281249367, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7790903402192653, 6.9112, 6.9112, 121.9260426156594, 1164853.176167942, 1164853.176167942, 245075.2000435381], 
processed observation next is [1.0, 0.5652173913043478, 0.7037037037037037, 0.31, 1.0, 1.0, 0.3744327715773056, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.7238629252740816, 0.0, 0.0, 0.80946212882012, 0.41601899148855065, 0.41601899148855065, 0.47129846162218864], 
reward next is 0.5287, 
noisyNet noise sample is [array([1.2896234], dtype=float32), 2.5468242]. 
=============================================
[2019-03-24 06:32:44,975] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67000, global step 1073227: learning rate 0.0000
[2019-03-24 06:32:47,833] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67500, global step 1074712: loss 9.1473
[2019-03-24 06:32:47,837] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67500, global step 1074713: learning rate 0.0000
[2019-03-24 06:32:48,381] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-24 06:32:48,381] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:32:48,382] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:32:48,382] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:32:48,383] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:32:48,383] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:32:48,383] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:32:48,389] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:32:48,389] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:32:48,384] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:32:48,392] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:32:48,405] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run44
[2019-03-24 06:32:48,432] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run44
[2019-03-24 06:32:48,458] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run44
[2019-03-24 06:32:48,482] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run44
[2019-03-24 06:32:48,482] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run44
[2019-03-24 06:33:01,614] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00700841], dtype=float32), 0.016232194]
[2019-03-24 06:33:01,616] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.47090652, 65.18598722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5949553290502441, 6.911199999999999, 6.9112, 121.9260426156618, 442350.8024213753, 442350.8024213757, 130467.3687317891]
[2019-03-24 06:33:01,619] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:33:01,621] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.4478185842643856
[2019-03-24 06:33:06,914] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00700841], dtype=float32), 0.016232194]
[2019-03-24 06:33:06,915] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.03333333333333, 66.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5309103867572663, 6.9112, 6.9112, 121.9260426156618, 386299.6031691252, 386299.6031691252, 120105.7479548234]
[2019-03-24 06:33:06,918] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:33:06,922] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.5007133671834569
[2019-03-24 06:33:07,487] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00700841], dtype=float32), 0.016232194]
[2019-03-24 06:33:07,488] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [34.93333333333333, 25.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.682422052322709, 6.911200000000001, 6.9112, 121.9260426156618, 509950.380069035, 509950.3800690346, 143148.6630550365]
[2019-03-24 06:33:07,490] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:33:07,492] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.30589590897650865
[2019-03-24 06:33:30,090] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00700841], dtype=float32), 0.016232194]
[2019-03-24 06:33:30,092] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.64091109, 86.00016975, 1.0, 2.0, 0.8389894488860987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 956309.4611050747, 956309.4611050747, 204131.1179751004]
[2019-03-24 06:33:30,095] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:33:30,100] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 8.0543587e-35 2.2180413e-35 6.3712859e-33 1.1789534e-30], sampled 0.9727487226977252
[2019-03-24 06:33:30,100] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 956309.4611050747 W.
[2019-03-24 06:33:32,566] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00700841], dtype=float32), 0.016232194]
[2019-03-24 06:33:32,568] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.4, 84.33333333333334, 1.0, 2.0, 0.6503457189835752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 741182.7828649521, 741182.7828649521, 166956.6131831136]
[2019-03-24 06:33:32,569] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:33:32,574] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.7326562e-38 0.0000000e+00 4.6792096e-37 1.4883274e-35], sampled 0.8892821031164129
[2019-03-24 06:33:32,575] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 741182.7828649521 W.
[2019-03-24 06:33:34,217] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00700841], dtype=float32), 0.016232194]
[2019-03-24 06:33:34,219] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [33.13333333333333, 52.0, 1.0, 2.0, 0.7031341774445595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 801375.9205531111, 801375.9205531111, 176738.9955934282]
[2019-03-24 06:33:34,220] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:33:34,224] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.6721958583992789
[2019-03-24 06:33:34,224] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 801375.9205531111 W.
[2019-03-24 06:33:55,214] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00700841], dtype=float32), 0.016232194]
[2019-03-24 06:33:55,215] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.5, 62.0, 1.0, 2.0, 0.8281667184116285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 997668.4168882561, 997668.4168882556, 204322.0489160138]
[2019-03-24 06:33:55,216] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:33:55,220] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 4.8854067e-33 4.4036075e-33 5.2488851e-31 2.9096709e-28], sampled 0.06323527653239291
[2019-03-24 06:33:55,222] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 997668.4168882561 W.
[2019-03-24 06:34:31,120] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00700841], dtype=float32), 0.016232194]
[2019-03-24 06:34:31,121] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.25, 57.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.515830454072026, 6.9112, 6.9112, 121.9260426156618, 373861.5082642369, 373861.5082642369, 118296.882590216]
[2019-03-24 06:34:31,123] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:34:31,126] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.88017384788679
[2019-03-24 06:34:35,682] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 06:34:36,006] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 06:34:36,250] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.2390 2292980111.6144 697.0000
[2019-03-24 06:34:36,366] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 06:34:36,537] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 06:34:37,554] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1075000, evaluation results [1075000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.238967854026, 2292980111.6144123, 697.0]
[2019-03-24 06:34:39,288] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:34:39,299] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9815
[2019-03-24 06:34:39,303] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.8, 41.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6163727290280019, 6.9112, 6.9112, 121.9260426156618, 458282.5659057247, 458282.5659057247, 132519.5123132109], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 595800.0000, 
sim time next is 596400.0000, 
raw observation next is [27.6, 42.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6140623511758844, 6.911200000000001, 6.9112, 121.9260426156618, 456348.0506407567, 456348.0506407563, 132126.9821357573], 
processed observation next is [1.0, 0.9130434782608695, 0.5777777777777778, 0.42, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5175779389698554, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1629814466574131, 0.16298144665741296, 0.25409035026107174], 
reward next is 0.7459, 
noisyNet noise sample is [array([-0.63892573], dtype=float32), 0.6024789]. 
=============================================
[2019-03-24 06:34:41,894] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67500, global step 1077137: loss 25.9129
[2019-03-24 06:34:41,897] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67500, global step 1077138: learning rate 0.0000
[2019-03-24 06:34:47,976] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67500, global step 1080168: loss 22.4363
[2019-03-24 06:34:47,977] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67500, global step 1080168: learning rate 0.0000
[2019-03-24 06:34:48,026] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67500, global step 1080192: loss 22.0890
[2019-03-24 06:34:48,027] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67500, global step 1080193: learning rate 0.0000
[2019-03-24 06:34:48,386] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67500, global step 1080381: loss 18.4278
[2019-03-24 06:34:48,388] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67500, global step 1080383: learning rate 0.0000
[2019-03-24 06:34:48,446] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67500, global step 1080404: loss 20.3097
[2019-03-24 06:34:48,448] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67500, global step 1080405: learning rate 0.0000
[2019-03-24 06:34:48,643] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67500, global step 1080510: loss 19.8254
[2019-03-24 06:34:48,644] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67500, global step 1080511: learning rate 0.0000
[2019-03-24 06:34:48,694] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67500, global step 1080538: loss 16.5337
[2019-03-24 06:34:48,696] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67500, global step 1080539: learning rate 0.0000
[2019-03-24 06:34:48,699] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67500, global step 1080540: loss 16.3137
[2019-03-24 06:34:48,701] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67500, global step 1080541: learning rate 0.0000
[2019-03-24 06:34:48,946] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67500, global step 1080666: loss 16.1106
[2019-03-24 06:34:48,947] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67500, global step 1080666: learning rate 0.0000
[2019-03-24 06:34:48,979] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67500, global step 1080681: loss 16.2019
[2019-03-24 06:34:48,981] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67500, global step 1080681: learning rate 0.0000
[2019-03-24 06:34:49,049] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67500, global step 1080718: loss 12.5246
[2019-03-24 06:34:49,055] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67500, global step 1080719: learning rate 0.0000
[2019-03-24 06:34:49,256] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67500, global step 1080826: loss 13.1639
[2019-03-24 06:34:49,257] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67500, global step 1080826: loss 16.4162
[2019-03-24 06:34:49,259] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67500, global step 1080826: learning rate 0.0000
[2019-03-24 06:34:49,261] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67500, global step 1080827: learning rate 0.0000
[2019-03-24 06:34:49,289] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67500, global step 1080839: loss 17.5896
[2019-03-24 06:34:49,292] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67500, global step 1080840: learning rate 0.0000
[2019-03-24 06:34:50,257] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67500, global step 1081346: loss 20.9019
[2019-03-24 06:34:50,258] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67500, global step 1081346: learning rate 0.0000
[2019-03-24 06:34:52,296] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:34:52,303] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7186
[2019-03-24 06:34:52,307] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.5, 37.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7190496908676002, 6.911200000000001, 6.9112, 121.9260426156618, 536928.9737933252, 536928.9737933248, 148313.7352797832], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 822600.0000, 
sim time next is 823200.0000, 
raw observation next is [31.66666666666666, 36.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7227878686783286, 6.9112, 6.9112, 121.9260426156618, 539633.3522797817, 539633.3522797817, 148873.6670680545], 
processed observation next is [0.0, 0.5217391304347826, 0.7283950617283949, 0.3666666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6534848358479106, 0.0, 0.0, 0.8094621288201359, 0.19272619724277917, 0.19272619724277917, 0.2862955135924125], 
reward next is 0.7137, 
noisyNet noise sample is [array([-0.08698886], dtype=float32), -1.3116888]. 
=============================================
[2019-03-24 06:34:52,458] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68000, global step 1082496: loss 0.0174
[2019-03-24 06:34:52,460] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68000, global step 1082496: learning rate 0.0000
[2019-03-24 06:34:57,515] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68000, global step 1085133: loss 0.0093
[2019-03-24 06:34:57,517] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68000, global step 1085133: learning rate 0.0000
[2019-03-24 06:35:03,173] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68000, global step 1088098: loss 0.0673
[2019-03-24 06:35:03,180] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68000, global step 1088098: learning rate 0.0000
[2019-03-24 06:35:03,542] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68000, global step 1088290: loss 0.1515
[2019-03-24 06:35:03,544] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68000, global step 1088291: learning rate 0.0000
[2019-03-24 06:35:03,596] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68000, global step 1088324: loss 0.1781
[2019-03-24 06:35:03,598] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68000, global step 1088324: learning rate 0.0000
[2019-03-24 06:35:03,668] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68000, global step 1088352: loss 0.2078
[2019-03-24 06:35:03,670] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68000, global step 1088353: learning rate 0.0000
[2019-03-24 06:35:03,698] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68000, global step 1088370: loss 0.2094
[2019-03-24 06:35:03,699] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68000, global step 1088370: learning rate 0.0000
[2019-03-24 06:35:03,782] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68000, global step 1088415: loss 0.2581
[2019-03-24 06:35:03,784] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68000, global step 1088415: learning rate 0.0000
[2019-03-24 06:35:03,928] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68000, global step 1088489: loss 0.2668
[2019-03-24 06:35:03,931] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68000, global step 1088489: learning rate 0.0000
[2019-03-24 06:35:04,041] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68000, global step 1088552: loss 0.3255
[2019-03-24 06:35:04,045] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68000, global step 1088553: learning rate 0.0000
[2019-03-24 06:35:04,220] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68000, global step 1088640: loss 0.1775
[2019-03-24 06:35:04,224] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68000, global step 1088640: learning rate 0.0000
[2019-03-24 06:35:04,237] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68000, global step 1088649: loss 0.1643
[2019-03-24 06:35:04,238] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68000, global step 1088649: learning rate 0.0000
[2019-03-24 06:35:04,473] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68000, global step 1088773: loss 0.1554
[2019-03-24 06:35:04,476] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68000, global step 1088773: learning rate 0.0000
[2019-03-24 06:35:04,501] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68000, global step 1088782: loss 0.1928
[2019-03-24 06:35:04,503] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68000, global step 1088782: learning rate 0.0000
[2019-03-24 06:35:04,546] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.8799997e-37], sum to 1.0000
[2019-03-24 06:35:04,551] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0607
[2019-03-24 06:35:04,554] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.56666666666667, 59.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6391737123616812, 6.9112, 6.9112, 121.9260426156618, 468174.4248342889, 468174.4248342889, 130757.312966882], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1065000.0000, 
sim time next is 1065600.0000, 
raw observation next is [22.7, 59.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5889131857244206, 6.9112, 6.9112, 121.9260426156618, 431469.4925148584, 431469.4925148584, 126255.0752644626], 
processed observation next is [1.0, 0.34782608695652173, 0.39629629629629626, 0.59, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4861414821555258, 0.0, 0.0, 0.8094621288201359, 0.15409624732673513, 0.15409624732673513, 0.2427982216624281], 
reward next is 0.7572, 
noisyNet noise sample is [array([0.5313481], dtype=float32), -0.8931775]. 
=============================================
[2019-03-24 06:35:04,607] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68000, global step 1088841: loss 0.1605
[2019-03-24 06:35:04,609] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68000, global step 1088842: learning rate 0.0000
[2019-03-24 06:35:05,439] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68000, global step 1089266: loss 0.3360
[2019-03-24 06:35:05,443] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68000, global step 1089267: learning rate 0.0000
[2019-03-24 06:35:08,201] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68500, global step 1090679: loss -104.5661
[2019-03-24 06:35:08,203] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68500, global step 1090680: learning rate 0.0000
[2019-03-24 06:35:13,249] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68500, global step 1093306: loss -140.5372
[2019-03-24 06:35:13,251] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68500, global step 1093307: learning rate 0.0000
[2019-03-24 06:35:16,052] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:35:16,066] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9900
[2019-03-24 06:35:16,070] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.66666666666666, 57.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6715434192082088, 6.9112, 6.9112, 121.9260426156618, 501690.2731984644, 501690.2731984644, 140888.2929508817], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1275000.0000, 
sim time next is 1275600.0000, 
raw observation next is [25.53333333333333, 58.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6749367620120915, 6.911200000000001, 6.9112, 121.9260426156618, 504242.048779625, 504242.0487796246, 141296.7251489064], 
processed observation next is [1.0, 0.782608695652174, 0.5012345679012346, 0.5866666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5936709525151144, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18008644599272322, 0.18008644599272305, 0.2717244714402046], 
reward next is 0.7283, 
noisyNet noise sample is [array([-1.1449364], dtype=float32), 2.7154171]. 
=============================================
[2019-03-24 06:35:17,571] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 4.7082158e-37 3.2364174e-34], sum to 1.0000
[2019-03-24 06:35:17,575] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4700
[2019-03-24 06:35:17,582] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.8, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6481175265860943, 6.911200000000001, 6.9112, 121.9260426156618, 483204.0152868385, 483204.015286838, 136851.8165138249], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1323000.0000, 
sim time next is 1323600.0000, 
raw observation next is [22.03333333333333, 77.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6482609333436659, 6.9112, 6.9112, 121.9260426156618, 483515.9815767184, 483515.9815767184, 137108.0003088868], 
processed observation next is [1.0, 0.30434782608695654, 0.37160493827160485, 0.77, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5603261666795822, 0.0, 0.0, 0.8094621288201359, 0.1726842791345423, 0.1726842791345423, 0.2636692313632439], 
reward next is 0.7363, 
noisyNet noise sample is [array([-1.0584289], dtype=float32), -0.8703298]. 
=============================================
[2019-03-24 06:35:18,620] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68500, global step 1096092: loss 5.4610
[2019-03-24 06:35:18,625] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68500, global step 1096092: learning rate 0.0000
[2019-03-24 06:35:19,058] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68500, global step 1096319: loss -64.1737
[2019-03-24 06:35:19,059] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68500, global step 1096319: learning rate 0.0000
[2019-03-24 06:35:19,142] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68500, global step 1096364: loss -37.6505
[2019-03-24 06:35:19,145] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68500, global step 1096365: learning rate 0.0000
[2019-03-24 06:35:19,160] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68500, global step 1096371: loss -106.8642
[2019-03-24 06:35:19,164] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68500, global step 1096372: learning rate 0.0000
[2019-03-24 06:35:19,319] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68500, global step 1096455: loss -95.4023
[2019-03-24 06:35:19,320] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68500, global step 1096455: learning rate 0.0000
[2019-03-24 06:35:19,353] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68500, global step 1096468: loss 13.5140
[2019-03-24 06:35:19,355] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68500, global step 1096470: learning rate 0.0000
[2019-03-24 06:35:19,400] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68500, global step 1096491: loss -111.7267
[2019-03-24 06:35:19,402] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68500, global step 1096493: learning rate 0.0000
[2019-03-24 06:35:19,495] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68500, global step 1096545: loss -45.4701
[2019-03-24 06:35:19,498] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68500, global step 1096545: learning rate 0.0000
[2019-03-24 06:35:19,703] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68500, global step 1096653: loss 1.3537
[2019-03-24 06:35:19,704] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68500, global step 1096653: learning rate 0.0000
[2019-03-24 06:35:19,875] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68500, global step 1096742: loss -74.1513
[2019-03-24 06:35:19,879] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68500, global step 1096742: learning rate 0.0000
[2019-03-24 06:35:19,932] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68500, global step 1096769: loss -70.9241
[2019-03-24 06:35:19,933] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68500, global step 1096769: learning rate 0.0000
[2019-03-24 06:35:20,028] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68500, global step 1096820: loss -71.1492
[2019-03-24 06:35:20,031] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68500, global step 1096821: learning rate 0.0000
[2019-03-24 06:35:20,367] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68500, global step 1096998: loss -73.3609
[2019-03-24 06:35:20,373] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68500, global step 1097000: learning rate 0.0000
[2019-03-24 06:35:20,698] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:35:20,703] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6686
[2019-03-24 06:35:20,706] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [32.59999999999999, 33.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7184804917065639, 6.911200000000001, 6.9112, 121.9260426156618, 536615.5587882494, 536615.5587882489, 148052.2871801122], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1507200.0000, 
sim time next is 1507800.0000, 
raw observation next is [32.95, 32.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7185034160733721, 6.911200000000001, 6.9112, 121.9260426156618, 536600.2022084438, 536600.2022084434, 148115.6338066652], 
processed observation next is [0.0, 0.43478260869565216, 0.775925925925926, 0.32, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6481292700917152, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1916429293601585, 0.19164292936015836, 0.28483775732051], 
reward next is 0.7152, 
noisyNet noise sample is [array([0.8148655], dtype=float32), 2.8433428]. 
=============================================
[2019-03-24 06:35:21,109] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68500, global step 1097381: loss -49.1399
[2019-03-24 06:35:21,111] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68500, global step 1097381: learning rate 0.0000
[2019-03-24 06:35:23,530] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69000, global step 1098624: loss 0.0082
[2019-03-24 06:35:23,531] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69000, global step 1098624: learning rate 0.0000
[2019-03-24 06:35:26,145] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-24 06:35:26,146] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:35:26,147] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:35:26,148] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:35:26,149] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:35:26,149] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:35:26,151] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:35:26,152] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:35:26,148] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:35:26,154] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:35:26,156] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:35:26,169] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run45
[2019-03-24 06:35:26,195] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run45
[2019-03-24 06:35:26,222] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run45
[2019-03-24 06:35:26,222] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run45
[2019-03-24 06:35:26,279] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run45
[2019-03-24 06:36:08,068] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00711774], dtype=float32), 0.0163571]
[2019-03-24 06:36:08,069] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.90555288666667, 72.17928018333333, 1.0, 2.0, 0.6386967784766797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 727900.4727738707, 727900.4727738702, 164861.7653430454]
[2019-03-24 06:36:08,071] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:36:08,075] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.5686429e-37 9.0339137e-36], sampled 0.9955961688077634
[2019-03-24 06:36:08,077] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 727900.4727738707 W.
[2019-03-24 06:36:12,845] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00711774], dtype=float32), 0.0163571]
[2019-03-24 06:36:12,847] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.45, 78.5, 1.0, 2.0, 0.6831419197516214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 778578.7767991655, 778578.7767991651, 172976.1664491504]
[2019-03-24 06:36:12,848] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:36:12,850] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.00000000e+00 0.00000000e+00 0.00000000e+00 2.17336325e-37
 1.18327124e-35], sampled 0.7067584566662009
[2019-03-24 06:36:12,851] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 778578.7767991655 W.
[2019-03-24 06:36:13,565] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00711774], dtype=float32), 0.0163571]
[2019-03-24 06:36:13,566] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.0, 87.33333333333333, 1.0, 2.0, 0.717660505462668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 817940.6976002268, 817940.6976002268, 179516.7749858172]
[2019-03-24 06:36:13,568] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:36:13,572] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 5.0787473e-38 3.3499935e-36], sampled 0.6028625148540553
[2019-03-24 06:36:13,574] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 817940.6976002268 W.
[2019-03-24 06:36:17,726] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00711774], dtype=float32), 0.0163571]
[2019-03-24 06:36:17,727] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.90221818, 71.94301003, 1.0, 2.0, 0.5588592083478463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 658656.3322117605, 658656.3322117605, 152136.5323131195]
[2019-03-24 06:36:17,728] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:36:17,731] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.00000000e+00 7.18986757e-35 1.40731979e-36 1.40610375e-33
 5.25651686e-32], sampled 0.32936979563962865
[2019-03-24 06:36:38,992] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00711774], dtype=float32), 0.0163571]
[2019-03-24 06:36:38,993] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.0, 84.0, 1.0, 2.0, 0.7174211429434018, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 817667.7429416358, 817667.7429416358, 179468.1150702188]
[2019-03-24 06:36:38,995] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:36:38,999] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.000000e+00 9.918612e-33 1.614851e-33 4.332993e-31 6.747735e-29], sampled 0.9258769082867939
[2019-03-24 06:36:39,000] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 817667.7429416358 W.
[2019-03-24 06:36:40,963] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00711774], dtype=float32), 0.0163571]
[2019-03-24 06:36:40,964] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.0, 90.66666666666667, 1.0, 2.0, 1.02, 1.0, 1.0, 1.02, 1.0, 1.0, 0.9977734948820727, 14.13319111254159, 6.9112, 132.0925915166872, 7054607.2547695, 3047926.862511875, 534962.6379564404]
[2019-03-24 06:36:40,965] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:36:40,967] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 6.7058123e-27 9.8650267e-26 4.9046786e-25 3.7981859e-20], sampled 0.4584172204513637
[2019-03-24 06:36:40,969] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 0, 0, 1] for the demand 7054607.2547695 W.
[2019-03-24 06:36:47,558] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00711774], dtype=float32), 0.0163571]
[2019-03-24 06:36:47,561] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.66666666666667, 79.0, 1.0, 2.0, 0.6381842207090235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 727316.0514156824, 727316.0514156824, 164769.5802202808]
[2019-03-24 06:36:47,564] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:36:47,567] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 4.9220983e-37 0.0000000e+00 1.4029841e-35 8.5109005e-34], sampled 0.696632900757503
[2019-03-24 06:36:47,568] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 727316.0514156824 W.
[2019-03-24 06:36:48,024] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00711774], dtype=float32), 0.0163571]
[2019-03-24 06:36:48,024] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.29764287666667, 56.69382528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9003119051514303, 6.9112, 6.9112, 121.9260426156618, 658556.1447494478, 658556.1447494478, 176054.5105316933]
[2019-03-24 06:36:48,026] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:36:48,031] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.6043750720558417
[2019-03-24 06:37:07,758] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00711774], dtype=float32), 0.0163571]
[2019-03-24 06:37:07,759] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.73333333333333, 51.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5199242543646837, 6.911200000000001, 6.9112, 121.9260426156618, 378281.9002905095, 378281.900290509, 119199.1752935366]
[2019-03-24 06:37:07,761] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:37:07,765] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.000000e+00 0.000000e+00 0.000000e+00 5.134695e-38 4.356016e-37], sampled 0.940216293114815
[2019-03-24 06:37:11,763] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00711774], dtype=float32), 0.0163571]
[2019-03-24 06:37:11,764] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.07500543666666, 79.36641126833332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6964736985694424, 6.911199999999999, 6.9112, 121.9260426156618, 520384.8096993727, 520384.8096993731, 143769.3932903707]
[2019-03-24 06:37:11,767] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:37:11,770] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 5.1057094e-38 0.0000000e+00 4.7627337e-37 5.0804186e-36], sampled 0.41277208544450184
[2019-03-24 06:37:13,741] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 06:37:14,136] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 06:37:14,185] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 06:37:14,226] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 06:37:14,395] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 06:37:15,412] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1100000, evaluation results [1100000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 06:37:17,197] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:37:17,201] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7477
[2019-03-24 06:37:17,207] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [34.06666666666667, 32.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7490224290180449, 6.9112, 6.9112, 121.9260426156618, 557176.7981535309, 557176.7981535309, 153661.3400068459], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1525200.0000, 
sim time next is 1525800.0000, 
raw observation next is [33.88333333333333, 33.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7635329868483502, 6.9112, 6.9112, 121.9260426156618, 567145.3362992061, 567145.3362992061, 155842.2023543769], 
processed observation next is [0.0, 0.6521739130434783, 0.8104938271604938, 0.33666666666666656, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7044162335604378, 0.0, 0.0, 0.8094621288201359, 0.20255190582114505, 0.20255190582114505, 0.29969654298918635], 
reward next is 0.7003, 
noisyNet noise sample is [array([-1.4103098], dtype=float32), 0.7735486]. 
=============================================
[2019-03-24 06:37:17,964] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69000, global step 1101260: loss 0.1627
[2019-03-24 06:37:17,969] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69000, global step 1101260: learning rate 0.0000
[2019-03-24 06:37:23,789] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69000, global step 1104067: loss 0.0116
[2019-03-24 06:37:23,793] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69000, global step 1104069: learning rate 0.0000
[2019-03-24 06:37:24,080] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69000, global step 1104214: loss 0.0538
[2019-03-24 06:37:24,087] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69000, global step 1104215: learning rate 0.0000
[2019-03-24 06:37:24,342] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69000, global step 1104354: loss 0.0112
[2019-03-24 06:37:24,344] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69000, global step 1104354: learning rate 0.0000
[2019-03-24 06:37:24,364] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69000, global step 1104364: loss 0.0099
[2019-03-24 06:37:24,368] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69000, global step 1104364: learning rate 0.0000
[2019-03-24 06:37:24,409] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69000, global step 1104386: loss 0.0068
[2019-03-24 06:37:24,412] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69000, global step 1104387: learning rate 0.0000
[2019-03-24 06:37:24,420] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69000, global step 1104391: loss 0.0187
[2019-03-24 06:37:24,423] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69000, global step 1104391: learning rate 0.0000
[2019-03-24 06:37:24,463] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69000, global step 1104414: loss 0.0377
[2019-03-24 06:37:24,465] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69000, global step 1104414: learning rate 0.0000
[2019-03-24 06:37:24,672] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69000, global step 1104522: loss 0.0431
[2019-03-24 06:37:24,673] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69000, global step 1104523: learning rate 0.0000
[2019-03-24 06:37:24,810] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69000, global step 1104596: loss 0.0179
[2019-03-24 06:37:24,813] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69000, global step 1104596: learning rate 0.0000
[2019-03-24 06:37:24,922] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69000, global step 1104657: loss 0.0657
[2019-03-24 06:37:24,925] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69000, global step 1104658: learning rate 0.0000
[2019-03-24 06:37:24,938] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69000, global step 1104667: loss 0.1388
[2019-03-24 06:37:24,940] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69000, global step 1104667: learning rate 0.0000
[2019-03-24 06:37:25,116] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69000, global step 1104754: loss 0.1665
[2019-03-24 06:37:25,118] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69000, global step 1104754: learning rate 0.0000
[2019-03-24 06:37:25,321] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69000, global step 1104864: loss 0.1122
[2019-03-24 06:37:25,324] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69000, global step 1104864: learning rate 0.0000
[2019-03-24 06:37:26,250] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69000, global step 1105349: loss 0.2759
[2019-03-24 06:37:26,251] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69000, global step 1105350: learning rate 0.0000
[2019-03-24 06:37:29,181] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69500, global step 1106867: loss 53.3056
[2019-03-24 06:37:29,183] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69500, global step 1106868: learning rate 0.0000
[2019-03-24 06:37:32,620] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:37:32,627] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7698
[2019-03-24 06:37:32,635] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.36666666666667, 91.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.552249030976355, 6.911199999999999, 6.9112, 121.9260426156618, 405150.0509332714, 405150.0509332719, 123312.0795723066], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1818600.0000, 
sim time next is 1819200.0000, 
raw observation next is [18.33333333333334, 91.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5505985164135264, 6.911200000000001, 6.9112, 121.9260426156618, 403860.1874726863, 403860.1874726859, 123133.3815687907], 
processed observation next is [1.0, 0.043478260869565216, 0.2345679012345681, 0.9133333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.438248145516908, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1442357812402451, 0.14423578124024497, 0.23679496455536675], 
reward next is 0.7632, 
noisyNet noise sample is [array([0.55635625], dtype=float32), 0.5641366]. 
=============================================
[2019-03-24 06:37:33,303] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:37:33,322] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1349
[2019-03-24 06:37:33,325] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.15, 68.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6912764713624754, 6.911199999999999, 6.9112, 121.9260426156618, 516561.2024613763, 516561.2024613768, 144177.1005373264], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1792200.0000, 
sim time next is 1792800.0000, 
raw observation next is [23.7, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6828944435690153, 6.911200000000001, 6.9112, 121.9260426156618, 510298.11634964, 510298.1163496395, 142639.9887335887], 
processed observation next is [1.0, 0.782608695652174, 0.4333333333333333, 0.7, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.603618054461269, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18224932726772858, 0.18224932726772838, 0.27430767064151673], 
reward next is 0.7257, 
noisyNet noise sample is [array([-2.0685592], dtype=float32), -0.121529505]. 
=============================================
[2019-03-24 06:37:33,773] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69500, global step 1109263: loss -53.4664
[2019-03-24 06:37:33,774] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69500, global step 1109263: learning rate 0.0000
[2019-03-24 06:37:35,202] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 4.9380945e-33 5.2064211e-34 4.0138636e-32 6.4505770e-31], sum to 1.0000
[2019-03-24 06:37:35,211] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3443
[2019-03-24 06:37:35,215] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 897347.0202587066 W.
[2019-03-24 06:37:35,218] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.73333333333333, 85.33333333333333, 1.0, 2.0, 0.3692219811107885, 0.0, 2.0, 0.0, 1.0, 1.0, 0.6011260581155007, 6.911199999999999, 6.9112, 121.9260426156618, 897347.0202587066, 897347.020258707, 212645.8222811541], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1867200.0000, 
sim time next is 1867800.0000, 
raw observation next is [21.71666666666667, 85.66666666666667, 1.0, 2.0, 0.2420937478167808, 1.0, 1.0, 0.2420937478167808, 1.0, 2.0, 0.391350057776079, 6.911199999999999, 6.9112, 121.94756008, 873274.2453100346, 873274.2453100351, 234166.8730085109], 
processed observation next is [1.0, 0.6086956521739131, 0.3598765432098766, 0.8566666666666667, 1.0, 1.0, 0.09773065216283429, 1.0, 0.5, 0.09773065216283429, 1.0, 1.0, 0.23918757222009873, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.3118836590392981, 0.3118836590392982, 0.45032090963175175], 
reward next is 0.5497, 
noisyNet noise sample is [array([-0.34649044], dtype=float32), -0.8929545]. 
=============================================
[2019-03-24 06:37:35,571] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:37:35,577] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5427
[2019-03-24 06:37:35,582] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.46666666666667, 90.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6108287007010146, 6.911200000000001, 6.9112, 121.9260426156618, 453440.8135994675, 453440.813599467, 131444.6992170127], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1992000.0000, 
sim time next is 1992600.0000, 
raw observation next is [19.45, 90.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6090071172170761, 6.911199999999999, 6.9112, 121.9260426156618, 451950.1315878597, 451950.1315878602, 131174.0378227436], 
processed observation next is [0.0, 0.043478260869565216, 0.2759259259259259, 0.905, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5112588965213452, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16141076128137846, 0.16141076128137863, 0.25225776504373765], 
reward next is 0.7477, 
noisyNet noise sample is [array([-2.129925], dtype=float32), -0.04092373]. 
=============================================
[2019-03-24 06:37:39,426] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69500, global step 1112198: loss 130.9089
[2019-03-24 06:37:39,428] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69500, global step 1112200: learning rate 0.0000
[2019-03-24 06:37:39,682] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69500, global step 1112329: loss 35.9228
[2019-03-24 06:37:39,683] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69500, global step 1112329: learning rate 0.0000
[2019-03-24 06:37:39,720] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69500, global step 1112352: loss -63.1013
[2019-03-24 06:37:39,723] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69500, global step 1112353: learning rate 0.0000
[2019-03-24 06:37:39,725] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69500, global step 1112354: loss -34.7717
[2019-03-24 06:37:39,727] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69500, global step 1112354: learning rate 0.0000
[2019-03-24 06:37:39,800] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69500, global step 1112389: loss 71.0751
[2019-03-24 06:37:39,802] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69500, global step 1112389: learning rate 0.0000
[2019-03-24 06:37:39,815] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69500, global step 1112396: loss 0.5225
[2019-03-24 06:37:39,820] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69500, global step 1112398: learning rate 0.0000
[2019-03-24 06:37:39,862] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69500, global step 1112421: loss 38.6454
[2019-03-24 06:37:39,863] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69500, global step 1112421: learning rate 0.0000
[2019-03-24 06:37:40,067] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69500, global step 1112525: loss 151.0912
[2019-03-24 06:37:40,070] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69500, global step 1112526: learning rate 0.0000
[2019-03-24 06:37:40,256] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69500, global step 1112631: loss 134.4302
[2019-03-24 06:37:40,258] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69500, global step 1112631: learning rate 0.0000
[2019-03-24 06:37:40,448] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69500, global step 1112725: loss 64.5062
[2019-03-24 06:37:40,450] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69500, global step 1112725: learning rate 0.0000
[2019-03-24 06:37:40,492] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69500, global step 1112744: loss 151.4292
[2019-03-24 06:37:40,495] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69500, global step 1112746: learning rate 0.0000
[2019-03-24 06:37:40,700] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69500, global step 1112862: loss 51.2182
[2019-03-24 06:37:40,705] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69500, global step 1112863: learning rate 0.0000
[2019-03-24 06:37:40,728] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69500, global step 1112873: loss 41.0186
[2019-03-24 06:37:40,732] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69500, global step 1112874: learning rate 0.0000
[2019-03-24 06:37:41,680] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69500, global step 1113364: loss -141.1696
[2019-03-24 06:37:41,682] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69500, global step 1113364: learning rate 0.0000
[2019-03-24 06:37:44,261] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70000, global step 1114715: loss 55.1093
[2019-03-24 06:37:44,264] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70000, global step 1114716: learning rate 0.0000
[2019-03-24 06:37:47,007] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0719109e-37], sum to 1.0000
[2019-03-24 06:37:47,017] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6933
[2019-03-24 06:37:47,021] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7394950334885965, 6.911200000000001, 6.9112, 121.9260426156618, 551679.1743891629, 551679.1743891625, 151319.3708964634], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2098800.0000, 
sim time next is 2099400.0000, 
raw observation next is [22.11666666666667, 89.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7438274567895407, 6.911200000000001, 6.9112, 121.9260426156618, 554713.3335544587, 554713.3335544582, 152021.3367670792], 
processed observation next is [0.0, 0.30434782608695654, 0.3746913580246915, 0.8966666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6797843209869259, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1981119048408781, 0.19811190484087793, 0.2923487245520754], 
reward next is 0.7077, 
noisyNet noise sample is [array([-0.01760289], dtype=float32), 0.6692001]. 
=============================================
[2019-03-24 06:37:47,434] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:37:47,439] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6508
[2019-03-24 06:37:47,444] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.2, 72.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7950567169925374, 6.9112, 6.9112, 121.9260426156618, 590793.2305399342, 590793.2305399342, 159587.8054099513], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2313600.0000, 
sim time next is 2314200.0000, 
raw observation next is [25.1, 72.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.793737068099124, 6.911199999999999, 6.9112, 121.9260426156618, 589898.4741463098, 589898.4741463102, 159379.6184839674], 
processed observation next is [1.0, 0.782608695652174, 0.4851851851851852, 0.725, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7421713351239051, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21067802648082493, 0.2106780264808251, 0.3064992663153219], 
reward next is 0.6935, 
noisyNet noise sample is [array([0.8267447], dtype=float32), 0.7652018]. 
=============================================
[2019-03-24 06:37:49,174] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70000, global step 1117272: loss 20.1356
[2019-03-24 06:37:49,177] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70000, global step 1117274: learning rate 0.0000
[2019-03-24 06:37:49,938] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:37:49,949] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2103
[2019-03-24 06:37:49,956] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.4, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6946920153732989, 6.9112, 6.9112, 121.9260426156618, 519134.5993493844, 519134.5993493844, 144135.5730793264], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2270400.0000, 
sim time next is 2271000.0000, 
raw observation next is [20.4, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6939510771021318, 6.9112, 6.9112, 121.9260426156618, 518580.7199765248, 518580.7199765248, 144054.9242564823], 
processed observation next is [1.0, 0.2608695652173913, 0.31111111111111106, 0.96, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6174388463776647, 0.0, 0.0, 0.8094621288201359, 0.185207399991616, 0.185207399991616, 0.2770287004932352], 
reward next is 0.7230, 
noisyNet noise sample is [array([0.83545476], dtype=float32), -0.7094501]. 
=============================================
[2019-03-24 06:37:49,980] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[64.04445]
 [64.42737]
 [64.46106]
 [64.27844]
 [64.82077]], R is [[64.41073608]
 [64.48944092]
 [64.56784821]
 [64.64696503]
 [64.71468353]].
[2019-03-24 06:37:53,149] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.1066396e-26 6.2257765e-28 9.2439524e-28 1.0321402e-24], sum to 1.0000
[2019-03-24 06:37:53,158] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3682
[2019-03-24 06:37:53,168] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1500764.377775701 W.
[2019-03-24 06:37:53,178] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.7, 91.0, 1.0, 2.0, 0.689453897298387, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1500764.377775701, 1500764.377775701, 315323.9145841746], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2217600.0000, 
sim time next is 2218200.0000, 
raw observation next is [24.48333333333333, 91.83333333333334, 1.0, 2.0, 0.6594290315473061, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1466496.052994492, 1466496.052994492, 310010.8165269642], 
processed observation next is [1.0, 0.6956521739130435, 0.4623456790123456, 0.9183333333333334, 1.0, 1.0, 0.5945583708896501, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8094621288201359, 0.5237485903551757, 0.5237485903551757, 0.5961746471672388], 
reward next is 0.4038, 
noisyNet noise sample is [array([-0.12278602], dtype=float32), 0.7418393]. 
=============================================
[2019-03-24 06:37:53,272] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 8.2079030e-25 5.2060028e-27 2.2317181e-24 2.2282910e-23], sum to 1.0000
[2019-03-24 06:37:53,278] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6389
[2019-03-24 06:37:53,285] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.2, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9298978956529634, 6.911199999999999, 6.9112, 121.9260426156618, 679689.7339543964, 679689.7339543969, 180130.108744391], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2185200.0000, 
sim time next is 2185800.0000, 
raw observation next is [24.25, 88.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9775964444049293, 7.09061965653655, 6.9112, 121.925320728994, 806176.39316657, 714298.0366596899, 186770.2650498093], 
processed observation next is [1.0, 0.30434782608695654, 0.4537037037037037, 0.8883333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9719955555061616, 0.017941965653654978, 0.0, 0.8094573362433709, 0.28792014041663216, 0.25510644166417495, 0.35917358663424864], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2022866], dtype=float32), 0.20791145]. 
=============================================
[2019-03-24 06:37:54,634] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70000, global step 1120096: loss 13.2799
[2019-03-24 06:37:54,639] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70000, global step 1120096: learning rate 0.0000
[2019-03-24 06:37:55,038] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70000, global step 1120305: loss 35.1208
[2019-03-24 06:37:55,040] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70000, global step 1120305: learning rate 0.0000
[2019-03-24 06:37:55,074] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70000, global step 1120322: loss 24.9677
[2019-03-24 06:37:55,075] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70000, global step 1120322: learning rate 0.0000
[2019-03-24 06:37:55,088] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70000, global step 1120324: loss 35.4516
[2019-03-24 06:37:55,092] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70000, global step 1120326: learning rate 0.0000
[2019-03-24 06:37:55,168] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70000, global step 1120365: loss 10.3286
[2019-03-24 06:37:55,171] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70000, global step 1120366: learning rate 0.0000
[2019-03-24 06:37:55,181] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70000, global step 1120375: loss 14.4739
[2019-03-24 06:37:55,185] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70000, global step 1120376: learning rate 0.0000
[2019-03-24 06:37:55,362] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70000, global step 1120465: loss 23.7353
[2019-03-24 06:37:55,364] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70000, global step 1120466: learning rate 0.0000
[2019-03-24 06:37:55,561] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70000, global step 1120566: loss 23.8684
[2019-03-24 06:37:55,563] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70000, global step 1120566: learning rate 0.0000
[2019-03-24 06:37:55,694] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70000, global step 1120633: loss 48.9451
[2019-03-24 06:37:55,697] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70000, global step 1120634: learning rate 0.0000
[2019-03-24 06:37:55,737] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70000, global step 1120655: loss 10.3863
[2019-03-24 06:37:55,740] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70000, global step 1120658: learning rate 0.0000
[2019-03-24 06:37:55,763] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70000, global step 1120667: loss 10.3696
[2019-03-24 06:37:55,765] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70000, global step 1120668: learning rate 0.0000
[2019-03-24 06:37:55,954] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70000, global step 1120767: loss -2.1019
[2019-03-24 06:37:55,956] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70000, global step 1120770: learning rate 0.0000
[2019-03-24 06:37:56,142] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70000, global step 1120866: loss 49.5825
[2019-03-24 06:37:56,143] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70000, global step 1120867: learning rate 0.0000
[2019-03-24 06:37:56,917] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70000, global step 1121269: loss 30.7499
[2019-03-24 06:37:56,918] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70000, global step 1121269: learning rate 0.0000
[2019-03-24 06:37:59,755] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70500, global step 1122739: loss -41.1604
[2019-03-24 06:37:59,756] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70500, global step 1122739: learning rate 0.0000
[2019-03-24 06:38:04,104] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-24 06:38:04,107] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:38:04,108] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:38:04,110] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:38:04,111] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:38:04,111] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:38:04,112] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:38:04,112] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:38:04,113] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:38:04,113] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:38:04,114] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:38:04,128] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run46
[2019-03-24 06:38:04,154] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run46
[2019-03-24 06:38:04,156] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run46
[2019-03-24 06:38:04,207] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run46
[2019-03-24 06:38:04,241] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run46
[2019-03-24 06:38:15,415] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00751794], dtype=float32), 0.016598007]
[2019-03-24 06:38:15,416] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.06666666666667, 65.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5389541917109123, 6.911200000000001, 6.9112, 121.9260426156618, 390975.8709444482, 390975.8709444478, 120303.2178962871]
[2019-03-24 06:38:15,418] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:38:15,422] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.016592541828260643
[2019-03-24 06:38:25,032] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00751794], dtype=float32), 0.016598007]
[2019-03-24 06:38:25,033] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.13824776, 55.82375076, 1.0, 2.0, 0.5189805690587197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426089641, 646382.4771942298, 646382.4771942294, 146711.5548734141]
[2019-03-24 06:38:25,033] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:38:25,037] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 4.1763748e-37 0.0000000e+00 6.0122852e-36 2.6636556e-35], sampled 0.45207307531573226
[2019-03-24 06:38:30,695] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00751794], dtype=float32), 0.016598007]
[2019-03-24 06:38:30,695] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [19.5, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6102993808339285, 6.9112, 6.9112, 121.9260426156618, 453264.1210875884, 453264.1210875884, 131550.4224020631]
[2019-03-24 06:38:30,696] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:38:30,698] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.8401261686205503
[2019-03-24 06:38:40,893] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00751794], dtype=float32), 0.016598007]
[2019-03-24 06:38:40,894] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.01666666666667, 70.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.916846723877437, 6.911200000000001, 6.9112, 121.9260426156618, 670150.2486442369, 670150.2486442365, 178365.0188816973]
[2019-03-24 06:38:40,895] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:38:40,898] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.0029976438329719635
[2019-03-24 06:38:49,540] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00751794], dtype=float32), 0.016598007]
[2019-03-24 06:38:49,541] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.95502465666667, 81.60040262, 1.0, 2.0, 0.9848870423524162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.051549534820917, 6.9112, 121.9254584449738, 1194654.294515517, 1122783.132738085, 237097.286576923]
[2019-03-24 06:38:49,541] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:38:49,544] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 2.5796584e-33 7.4327713e-35 7.3061958e-32 1.1192465e-30], sampled 0.21236095051890114
[2019-03-24 06:38:49,546] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1194654.294515517 W.
[2019-03-24 06:39:02,866] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00751794], dtype=float32), 0.016598007]
[2019-03-24 06:39:02,867] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.4, 92.0, 1.0, 2.0, 0.574672615026626, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 686933.279913732, 686933.279913732, 155173.8827087421]
[2019-03-24 06:39:02,867] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:39:02,871] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 3.2686233e-36 2.2987790e-38 6.8655941e-35 5.7809935e-34], sampled 0.4448970817624319
[2019-03-24 06:39:02,873] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 686933.279913732 W.
[2019-03-24 06:39:10,373] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00751794], dtype=float32), 0.016598007]
[2019-03-24 06:39:10,374] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.85, 56.5, 1.0, 2.0, 0.7212975428149878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 837200.0778252328, 837200.0778252328, 180964.2581090076]
[2019-03-24 06:39:10,375] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:39:10,379] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 2.9786238e-37 0.0000000e+00 7.1018448e-36 6.7528127e-35], sampled 0.2283496635075134
[2019-03-24 06:39:10,379] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 837200.0778252328 W.
[2019-03-24 06:39:33,033] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00751794], dtype=float32), 0.016598007]
[2019-03-24 06:39:33,034] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.1, 80.0, 1.0, 2.0, 0.9018274859205648, 1.0, 2.0, 0.9018274859205648, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2057254.639395896, 2057254.639395896, 387628.2970910116]
[2019-03-24 06:39:33,036] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:39:33,038] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.12852350274081514
[2019-03-24 06:39:33,040] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2057254.639395896 W.
[2019-03-24 06:39:51,233] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 06:39:51,329] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 06:39:51,359] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 06:39:51,658] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 06:39:51,731] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 06:39:52,747] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1125000, evaluation results [1125000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 06:39:53,636] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70500, global step 1125437: loss 14.5553
[2019-03-24 06:39:53,637] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70500, global step 1125437: learning rate 0.0000
[2019-03-24 06:39:53,748] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:39:53,756] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2594
[2019-03-24 06:39:53,761] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.26666666666667, 79.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5047513015242158, 6.911199999999999, 6.9112, 121.9260426156618, 360894.6053994664, 360894.6053994668, 115645.939671719], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2436600.0000, 
sim time next is 2437200.0000, 
raw observation next is [18.1, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5460815189181336, 6.9112, 6.9112, 121.9260426156618, 390277.3472577312, 390277.3472577312, 118806.5275654492], 
processed observation next is [1.0, 0.21739130434782608, 0.22592592592592597, 0.81, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.43260189864766696, 0.0, 0.0, 0.8094621288201359, 0.13938476687776113, 0.13938476687776113, 0.2284740914720177], 
reward next is 0.7715, 
noisyNet noise sample is [array([-0.2663708], dtype=float32), -0.8017127]. 
=============================================
[2019-03-24 06:39:53,974] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.00000000e+00 1.14618964e-32 5.55053667e-36 3.71127006e-31
 1.82180230e-31], sum to 1.0000
[2019-03-24 06:39:53,981] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8303
[2019-03-24 06:39:53,992] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1254248.735725231 W.
[2019-03-24 06:39:53,995] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.86666666666667, 31.0, 1.0, 2.0, 0.5121427613730156, 1.0, 2.0, 0.5121427613730156, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260425590652, 1254248.735725231, 1254248.735725231, 242598.231749297], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2454000.0000, 
sim time next is 2454600.0000, 
raw observation next is [31.13333333333333, 30.0, 1.0, 2.0, 0.34876304883316, 1.0, 2.0, 0.34876304883316, 1.0, 1.0, 0.5676029932021489, 6.911200000000001, 6.9112, 121.94756008, 1271113.693403943, 1271113.693403943, 274393.8255792368], 
processed observation next is [1.0, 0.391304347826087, 0.7086419753086418, 0.3, 1.0, 1.0, 0.22471791527757143, 1.0, 1.0, 0.22471791527757143, 1.0, 0.5, 0.4595037415026861, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.45396917621569394, 0.45396917621569394, 0.5276804338062245], 
reward next is 0.4723, 
noisyNet noise sample is [array([0.815619], dtype=float32), 0.8984251]. 
=============================================
[2019-03-24 06:39:58,975] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70500, global step 1128062: loss 24.9858
[2019-03-24 06:39:58,977] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70500, global step 1128062: learning rate 0.0000
[2019-03-24 06:39:59,478] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70500, global step 1128309: loss 24.9854
[2019-03-24 06:39:59,480] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70500, global step 1128309: learning rate 0.0000
[2019-03-24 06:39:59,492] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70500, global step 1128315: loss -34.1965
[2019-03-24 06:39:59,495] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70500, global step 1128315: learning rate 0.0000
[2019-03-24 06:39:59,626] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70500, global step 1128373: loss 32.9356
[2019-03-24 06:39:59,630] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70500, global step 1128373: learning rate 0.0000
[2019-03-24 06:39:59,632] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70500, global step 1128376: loss -5.0412
[2019-03-24 06:39:59,636] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70500, global step 1128376: learning rate 0.0000
[2019-03-24 06:39:59,708] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70500, global step 1128406: loss -41.2767
[2019-03-24 06:39:59,709] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70500, global step 1128406: learning rate 0.0000
[2019-03-24 06:39:59,960] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70500, global step 1128511: loss -34.0731
[2019-03-24 06:39:59,963] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70500, global step 1128513: learning rate 0.0000
[2019-03-24 06:40:00,199] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70500, global step 1128618: loss -5.8690
[2019-03-24 06:40:00,202] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70500, global step 1128619: learning rate 0.0000
[2019-03-24 06:40:00,252] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70500, global step 1128640: loss -46.8439
[2019-03-24 06:40:00,254] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70500, global step 1128640: learning rate 0.0000
[2019-03-24 06:40:00,266] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70500, global step 1128644: loss -20.9175
[2019-03-24 06:40:00,269] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70500, global step 1128645: learning rate 0.0000
[2019-03-24 06:40:00,446] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70500, global step 1128723: loss -15.3657
[2019-03-24 06:40:00,448] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70500, global step 1128723: learning rate 0.0000
[2019-03-24 06:40:00,517] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70500, global step 1128754: loss 19.4769
[2019-03-24 06:40:00,518] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70500, global step 1128754: learning rate 0.0000
[2019-03-24 06:40:00,845] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70500, global step 1128930: loss -38.5456
[2019-03-24 06:40:00,852] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70500, global step 1128931: learning rate 0.0000
[2019-03-24 06:40:01,572] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70500, global step 1129310: loss -59.8265
[2019-03-24 06:40:01,577] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70500, global step 1129310: learning rate 0.0000
[2019-03-24 06:40:04,372] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71000, global step 1130780: loss 0.3267
[2019-03-24 06:40:04,373] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71000, global step 1130780: learning rate 0.0000
[2019-03-24 06:40:04,576] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 5.9439118e-38 2.3128902e-36], sum to 1.0000
[2019-03-24 06:40:04,583] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9769
[2019-03-24 06:40:04,587] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.7, 79.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9280409876248358, 6.9112, 6.9112, 121.9260426156618, 676645.756739748, 676645.756739748, 180188.6158820447], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2661600.0000, 
sim time next is 2662200.0000, 
raw observation next is [25.55, 80.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.924139584229315, 6.911199999999999, 6.9112, 121.9260426156618, 674328.7595738204, 674328.7595738209, 179564.7651011347], 
processed observation next is [0.0, 0.8260869565217391, 0.5018518518518519, 0.8, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9051744802866437, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24083169984779298, 0.24083169984779315, 0.3453168559637206], 
reward next is 0.6547, 
noisyNet noise sample is [array([0.06140801], dtype=float32), -0.30306563]. 
=============================================
[2019-03-24 06:40:08,278] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:40:08,293] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5693
[2019-03-24 06:40:08,301] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.53333333333333, 74.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8485986260130671, 6.9112, 6.9112, 121.9260426156618, 626322.7777543446, 626322.7777543446, 167919.8251575038], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2708400.0000, 
sim time next is 2709000.0000, 
raw observation next is [25.9, 72.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8512010994171478, 6.9112, 6.9112, 121.9260426156618, 628056.3840254659, 628056.3840254659, 168306.8530565362], 
processed observation next is [0.0, 0.34782608695652173, 0.5148148148148147, 0.725, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8140013742714347, 0.0, 0.0, 0.8094621288201359, 0.2243058514376664, 0.2243058514376664, 0.32366702510872347], 
reward next is 0.6763, 
noisyNet noise sample is [array([-1.1271565], dtype=float32), 0.9078524]. 
=============================================
[2019-03-24 06:40:08,315] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[68.21965 ]
 [68.233055]
 [68.24923 ]
 [68.25787 ]
 [68.300766]], R is [[68.25317383]
 [68.24771881]
 [68.24388885]
 [68.24284363]
 [68.2472229 ]].
[2019-03-24 06:40:09,671] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71000, global step 1133549: loss 0.7811
[2019-03-24 06:40:09,672] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71000, global step 1133549: learning rate 0.0000
[2019-03-24 06:40:12,112] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 6.9039191e-18 9.5035145e-18 6.6682973e-17 1.3765345e-14], sum to 1.0000
[2019-03-24 06:40:12,127] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7006
[2019-03-24 06:40:12,133] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 990667.927357428 W.
[2019-03-24 06:40:12,138] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.95, 84.5, 1.0, 2.0, 0.8691133478080072, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 990667.927357428, 990667.927357428, 210627.2949044287], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2791800.0000, 
sim time next is 2792400.0000, 
raw observation next is [26.26666666666667, 83.0, 1.0, 2.0, 0.2672776361048632, 1.0, 1.0, 0.2672776361048632, 1.0, 1.0, 0.4255147013038487, 6.9112, 6.9112, 121.94756008, 913931.7885321593, 913931.7885321593, 243835.2845374836], 
processed observation next is [1.0, 0.30434782608695654, 0.5283950617283951, 0.83, 1.0, 1.0, 0.1277114715534086, 1.0, 0.5, 0.1277114715534086, 1.0, 0.5, 0.28189337662981084, 0.0, 0.0, 0.8096049824067558, 0.3264042101900569, 0.3264042101900569, 0.46891400872593], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.56283015], dtype=float32), 1.3981471]. 
=============================================
[2019-03-24 06:40:14,333] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71000, global step 1135957: loss 5.3057
[2019-03-24 06:40:14,335] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71000, global step 1135957: learning rate 0.0000
[2019-03-24 06:40:14,872] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71000, global step 1136229: loss 5.1623
[2019-03-24 06:40:14,874] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71000, global step 1136230: learning rate 0.0000
[2019-03-24 06:40:14,953] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71000, global step 1136274: loss 3.4561
[2019-03-24 06:40:14,953] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71000, global step 1136274: learning rate 0.0000
[2019-03-24 06:40:15,088] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71000, global step 1136345: loss 4.4265
[2019-03-24 06:40:15,091] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71000, global step 1136345: learning rate 0.0000
[2019-03-24 06:40:15,158] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71000, global step 1136381: loss 3.4640
[2019-03-24 06:40:15,162] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71000, global step 1136382: learning rate 0.0000
[2019-03-24 06:40:15,243] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71000, global step 1136425: loss 3.3985
[2019-03-24 06:40:15,247] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71000, global step 1136425: learning rate 0.0000
[2019-03-24 06:40:15,335] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71000, global step 1136478: loss 3.1662
[2019-03-24 06:40:15,340] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71000, global step 1136478: learning rate 0.0000
[2019-03-24 06:40:15,489] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71000, global step 1136556: loss 0.4697
[2019-03-24 06:40:15,491] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71000, global step 1136556: learning rate 0.0000
[2019-03-24 06:40:15,507] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71000, global step 1136563: loss 2.5711
[2019-03-24 06:40:15,509] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71000, global step 1136563: learning rate 0.0000
[2019-03-24 06:40:15,617] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71000, global step 1136623: loss 1.7268
[2019-03-24 06:40:15,622] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71000, global step 1136624: learning rate 0.0000
[2019-03-24 06:40:15,830] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71000, global step 1136724: loss 1.8990
[2019-03-24 06:40:15,832] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71000, global step 1136725: learning rate 0.0000
[2019-03-24 06:40:15,919] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71000, global step 1136773: loss 0.7402
[2019-03-24 06:40:15,923] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71000, global step 1136773: learning rate 0.0000
[2019-03-24 06:40:15,923] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71000, global step 1136774: loss 1.6284
[2019-03-24 06:40:15,929] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71000, global step 1136776: learning rate 0.0000
[2019-03-24 06:40:16,950] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71000, global step 1137313: loss 1.7381
[2019-03-24 06:40:16,953] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71000, global step 1137314: learning rate 0.0000
[2019-03-24 06:40:19,066] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 2.0195404e-29 7.6797535e-34 4.7108735e-30 5.5748107e-29], sum to 1.0000
[2019-03-24 06:40:19,070] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8037
[2019-03-24 06:40:19,078] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 774470.6142477124 W.
[2019-03-24 06:40:19,083] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.76666666666667, 89.0, 1.0, 2.0, 0.2265130698024052, 1.0, 1.0, 0.2265130698024052, 1.0, 1.0, 0.3606161841410964, 6.9112, 6.9112, 121.94756008, 774470.6142477124, 774470.6142477124, 229451.3181757543], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2931600.0000, 
sim time next is 2932200.0000, 
raw observation next is [25.65, 89.0, 1.0, 2.0, 0.3374779746713316, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5372759265670809, 6.911199999999999, 6.9112, 121.9260426156618, 769244.5217281438, 769244.5217281441, 205591.3057791556], 
processed observation next is [1.0, 0.9565217391304348, 0.5055555555555555, 0.89, 1.0, 1.0, 0.2112833031801567, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.4215949082088511, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27473018633147994, 0.27473018633148005, 0.3953678957291454], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.5839704], dtype=float32), -0.9789876]. 
=============================================
[2019-03-24 06:40:20,075] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71500, global step 1138926: loss 83.9344
[2019-03-24 06:40:20,078] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71500, global step 1138926: learning rate 0.0000
[2019-03-24 06:40:21,462] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 6.9270211e-20 7.6925002e-21 4.6421123e-19 1.1019813e-17], sum to 1.0000
[2019-03-24 06:40:21,467] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6882
[2019-03-24 06:40:21,474] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 821815.5366538906 W.
[2019-03-24 06:40:21,476] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.7210584644233614, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 821815.5366538906, 821815.5366538906, 180165.7847793123], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2962200.0000, 
sim time next is 2962800.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.7814390797003891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 890673.4217528201, 890673.4217528201, 192130.8865337888], 
processed observation next is [1.0, 0.30434782608695654, 0.48148148148148145, 0.94, 1.0, 1.0, 0.7398084282147489, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3180976506260072, 0.3180976506260072, 0.36948247410344004], 
reward next is 0.6305, 
noisyNet noise sample is [array([0.13659427], dtype=float32), -0.111671075]. 
=============================================
[2019-03-24 06:40:24,796] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71500, global step 1141369: loss 55.1924
[2019-03-24 06:40:24,798] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71500, global step 1141369: learning rate 0.0000
[2019-03-24 06:40:29,910] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71500, global step 1143982: loss 177.8853
[2019-03-24 06:40:29,911] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71500, global step 1143983: learning rate 0.0000
[2019-03-24 06:40:30,410] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71500, global step 1144247: loss 117.8861
[2019-03-24 06:40:30,413] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71500, global step 1144247: learning rate 0.0000
[2019-03-24 06:40:30,473] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71500, global step 1144272: loss 163.1370
[2019-03-24 06:40:30,475] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71500, global step 1144272: learning rate 0.0000
[2019-03-24 06:40:30,607] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71500, global step 1144343: loss 36.4626
[2019-03-24 06:40:30,609] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71500, global step 1144343: learning rate 0.0000
[2019-03-24 06:40:30,852] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71500, global step 1144467: loss 127.6251
[2019-03-24 06:40:30,853] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71500, global step 1144467: learning rate 0.0000
[2019-03-24 06:40:30,911] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71500, global step 1144502: loss -80.5078
[2019-03-24 06:40:30,912] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71500, global step 1144502: learning rate 0.0000
[2019-03-24 06:40:31,034] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71500, global step 1144564: loss 28.3826
[2019-03-24 06:40:31,037] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71500, global step 1144565: learning rate 0.0000
[2019-03-24 06:40:31,077] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71500, global step 1144586: loss 38.1752
[2019-03-24 06:40:31,078] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71500, global step 1144586: learning rate 0.0000
[2019-03-24 06:40:31,093] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71500, global step 1144592: loss 17.3976
[2019-03-24 06:40:31,098] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71500, global step 1144592: learning rate 0.0000
[2019-03-24 06:40:31,204] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71500, global step 1144653: loss 75.0385
[2019-03-24 06:40:31,205] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71500, global step 1144653: learning rate 0.0000
[2019-03-24 06:40:31,362] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71500, global step 1144734: loss 69.8864
[2019-03-24 06:40:31,362] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71500, global step 1144734: learning rate 0.0000
[2019-03-24 06:40:31,491] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71500, global step 1144802: loss -16.4462
[2019-03-24 06:40:31,492] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71500, global step 1144802: learning rate 0.0000
[2019-03-24 06:40:31,532] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71500, global step 1144823: loss -26.7952
[2019-03-24 06:40:31,534] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71500, global step 1144823: learning rate 0.0000
[2019-03-24 06:40:32,595] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71500, global step 1145376: loss 21.6010
[2019-03-24 06:40:32,599] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71500, global step 1145376: learning rate 0.0000
[2019-03-24 06:40:33,480] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:40:33,490] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3759
[2019-03-24 06:40:33,493] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.33333333333334, 92.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8122246650642586, 6.9112, 6.9112, 121.9260426156618, 603459.9388562782, 603459.9388562782, 161776.7597856677], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3210600.0000, 
sim time next is 3211200.0000, 
raw observation next is [22.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8074155587684765, 6.911200000000001, 6.9112, 121.9260426156618, 600362.026008195, 600362.0260081945, 160920.679468327], 
processed observation next is [0.0, 0.17391304347826086, 0.37037037037037035, 0.94, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7592694484605955, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21441500928864107, 0.2144150092886409, 0.3094628451313981], 
reward next is 0.6905, 
noisyNet noise sample is [array([-1.4705672], dtype=float32), 0.11283545]. 
=============================================
[2019-03-24 06:40:35,616] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72000, global step 1146958: loss -231.4966
[2019-03-24 06:40:35,619] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72000, global step 1146958: learning rate 0.0000
[2019-03-24 06:40:36,658] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 8.8025586e-35 0.0000000e+00 7.3428150e-35 1.0031998e-34], sum to 1.0000
[2019-03-24 06:40:36,666] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2803
[2019-03-24 06:40:36,676] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 687291.5322332876 W.
[2019-03-24 06:40:36,684] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.5, 53.66666666666667, 1.0, 2.0, 0.2010268164486663, 1.0, 1.0, 0.2010268164486663, 1.0, 1.0, 0.3200412387726195, 6.9112, 6.9112, 121.94756008, 687291.5322332876, 687291.5322332876, 220930.3579208408], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3260400.0000, 
sim time next is 3261000.0000, 
raw observation next is [30.75, 51.33333333333334, 1.0, 2.0, 0.2931686152913709, 0.0, 1.0, 0.0, 1.0, 2.0, 0.4671003478284418, 6.9112, 6.9112, 121.9260426156618, 674822.7167619086, 674822.7167619086, 193295.1622237631], 
processed observation next is [0.0, 0.7391304347826086, 0.6944444444444444, 0.5133333333333334, 1.0, 1.0, 0.1585340658230606, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.3338754347855522, 0.0, 0.0, 0.8094621288201359, 0.24100811312925308, 0.24100811312925308, 0.37172146581492904], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0902784], dtype=float32), -1.4717635]. 
=============================================
[2019-03-24 06:40:36,698] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[49.987724]
 [50.51752 ]
 [50.695118]
 [50.391327]
 [51.47644 ]], R is [[49.92444229]
 [49.4251976 ]
 [49.62366867]
 [49.77583313]
 [49.92440033]].
[2019-03-24 06:40:40,365] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72000, global step 1149434: loss -96.3353
[2019-03-24 06:40:40,367] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72000, global step 1149435: learning rate 0.0000
[2019-03-24 06:40:41,449] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-24 06:40:41,450] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:40:41,451] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:40:41,452] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:40:41,453] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:40:41,453] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:40:41,454] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:40:41,452] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:40:41,457] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:40:41,458] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:40:41,456] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:40:41,473] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run47
[2019-03-24 06:40:41,500] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run47
[2019-03-24 06:40:41,501] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run47
[2019-03-24 06:40:41,551] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run47
[2019-03-24 06:40:41,551] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run47
[2019-03-24 06:40:56,479] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00708231], dtype=float32), 0.016094044]
[2019-03-24 06:40:56,481] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.1, 68.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5400828572285145, 6.9112, 6.9112, 121.9260426156618, 388218.5580073925, 388218.5580073925, 119086.1861654661]
[2019-03-24 06:40:56,482] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:40:56,484] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 5.2437228e-38 0.0000000e+00 1.0662423e-37 3.9752991e-38], sampled 0.3986311015856323
[2019-03-24 06:41:49,850] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00708231], dtype=float32), 0.016094044]
[2019-03-24 06:41:49,852] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.487179475, 89.853741195, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7742260920285371, 6.9112, 6.9112, 121.9260426156618, 575900.1211140533, 575900.1211140533, 156705.8977886105]
[2019-03-24 06:41:49,853] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:41:49,857] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.000000e+00 3.994165e-37 0.000000e+00 7.913766e-37 3.188875e-37], sampled 0.8525646712568984
[2019-03-24 06:41:53,021] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00708231], dtype=float32), 0.016094044]
[2019-03-24 06:41:53,023] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.95, 84.50000000000001, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.745735613150734, 6.9112, 121.923046916182, 1631446.038560244, 1204099.714755557, 247786.8132197091]
[2019-03-24 06:41:53,026] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:41:53,028] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 4.9531156e-24 6.5885681e-26 2.7214559e-23 6.5477879e-23], sampled 0.6576240009910911
[2019-03-24 06:41:53,030] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1631446.038560244 W.
[2019-03-24 06:41:57,453] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00708231], dtype=float32), 0.016094044]
[2019-03-24 06:41:57,454] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.53073969166667, 95.51613941333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9068146269855589, 6.911200000000001, 6.9112, 121.9260426156618, 661526.6107748105, 661526.6107748101, 177258.5046496465]
[2019-03-24 06:41:57,456] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:41:57,460] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.09549711168714448
[2019-03-24 06:42:09,467] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00708231], dtype=float32), 0.016094044]
[2019-03-24 06:42:09,468] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.787088265, 76.42220798666666, 1.0, 2.0, 0.8250092044033933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 940364.5133978993, 940364.5133978993, 201158.2673856526]
[2019-03-24 06:42:09,470] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:42:09,474] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.2089834e-25 5.8238191e-28 5.0385848e-25 7.7261865e-25], sampled 0.35261035326470136
[2019-03-24 06:42:09,475] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 940364.5133978993 W.
[2019-03-24 06:42:17,674] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00708231], dtype=float32), 0.016094044]
[2019-03-24 06:42:17,677] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.49259632, 68.83572686, 1.0, 2.0, 0.7816366092195911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260425961866, 951339.2710020383, 951339.2710020383, 194826.9641397353]
[2019-03-24 06:42:17,677] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:42:17,680] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.0822055e-25 5.0581623e-28 4.6003360e-25 7.0959542e-25], sampled 0.5087002330772039
[2019-03-24 06:42:17,683] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 951339.2710020383 W.
[2019-03-24 06:42:23,350] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00708231], dtype=float32), 0.016094044]
[2019-03-24 06:42:23,351] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [19.85319402666667, 93.58146980666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6612645075176888, 6.911200000000001, 6.9112, 121.9260426156618, 493751.021175751, 493751.0211757505, 139220.7708033631]
[2019-03-24 06:42:23,352] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:42:23,354] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.5877564e-38 0.0000000e+00], sampled 0.7304026928901458
[2019-03-24 06:42:28,923] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 06:42:29,027] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 06:42:29,062] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 06:42:29,167] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 06:42:29,348] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 06:42:30,366] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1150000, evaluation results [1150000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 06:42:33,311] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 6.1994420e-22 2.0211197e-22 1.1223818e-20 7.9206602e-20], sum to 1.0000
[2019-03-24 06:42:33,317] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1225
[2019-03-24 06:42:33,323] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2077561.754978239 W.
[2019-03-24 06:42:33,327] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.6, 64.0, 1.0, 2.0, 0.6071461656432688, 1.0, 2.0, 0.6071461656432688, 1.0, 2.0, 0.9665964690742481, 6.911199999999999, 6.9112, 121.94756008, 2077561.754978239, 2077561.75497824, 399282.9411725183], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3427200.0000, 
sim time next is 3427800.0000, 
raw observation next is [30.38333333333334, 64.83333333333334, 1.0, 2.0, 0.8884354877750861, 1.0, 2.0, 0.8884354877750861, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2026670.060208725, 2026670.060208725, 381652.7479466486], 
processed observation next is [1.0, 0.6956521739130435, 0.6808641975308645, 0.6483333333333334, 1.0, 1.0, 0.8671851044941501, 1.0, 1.0, 0.8671851044941501, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.7238107357888304, 0.7238107357888304, 0.7339475922050935], 
reward next is 0.2661, 
noisyNet noise sample is [array([0.40841642], dtype=float32), -0.117220104]. 
=============================================
[2019-03-24 06:42:34,277] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 3.2860819e-25 3.5679183e-26 2.7879257e-25 9.9676630e-24], sum to 1.0000
[2019-03-24 06:42:34,283] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9682
[2019-03-24 06:42:34,287] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1964514.791449728 W.
[2019-03-24 06:42:34,291] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.3, 69.0, 1.0, 2.0, 0.5741456395734919, 1.0, 2.0, 0.5741456395734919, 1.0, 2.0, 0.9140585568190616, 6.911200000000001, 6.9112, 121.94756008, 1964514.791449728, 1964514.791449727, 381468.8607009546], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3430800.0000, 
sim time next is 3431400.0000, 
raw observation next is [29.41666666666667, 68.5, 1.0, 2.0, 0.4308412942104461, 1.0, 2.0, 0.4308412942104461, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 982192.4704426692, 982192.4704426697, 214824.0760282655], 
processed observation next is [1.0, 0.7391304347826086, 0.6450617283950619, 0.685, 1.0, 1.0, 0.322430112155293, 1.0, 1.0, 0.322430112155293, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3507830251580962, 0.35078302515809634, 0.4131232231312798], 
reward next is 0.5869, 
noisyNet noise sample is [array([-1.2663388], dtype=float32), -0.30558586]. 
=============================================
[2019-03-24 06:42:34,328] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72000, global step 1151930: loss -92.3164
[2019-03-24 06:42:34,333] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72000, global step 1151931: learning rate 0.0000
[2019-03-24 06:42:34,761] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72000, global step 1152135: loss -37.0690
[2019-03-24 06:42:34,764] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72000, global step 1152136: learning rate 0.0000
[2019-03-24 06:42:34,910] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72000, global step 1152208: loss -128.8995
[2019-03-24 06:42:34,914] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72000, global step 1152209: learning rate 0.0000
[2019-03-24 06:42:35,364] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72000, global step 1152430: loss 30.5794
[2019-03-24 06:42:35,366] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72000, global step 1152431: learning rate 0.0000
[2019-03-24 06:42:35,403] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72000, global step 1152450: loss -73.4224
[2019-03-24 06:42:35,407] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72000, global step 1152450: learning rate 0.0000
[2019-03-24 06:42:35,460] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72000, global step 1152480: loss -105.3200
[2019-03-24 06:42:35,462] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72000, global step 1152480: learning rate 0.0000
[2019-03-24 06:42:35,559] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72000, global step 1152526: loss -79.7493
[2019-03-24 06:42:35,561] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72000, global step 1152526: learning rate 0.0000
[2019-03-24 06:42:35,626] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72000, global step 1152560: loss -106.1419
[2019-03-24 06:42:35,627] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72000, global step 1152561: loss -45.6109
[2019-03-24 06:42:35,628] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72000, global step 1152562: learning rate 0.0000
[2019-03-24 06:42:35,630] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72000, global step 1152563: learning rate 0.0000
[2019-03-24 06:42:35,729] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72000, global step 1152611: loss -37.7269
[2019-03-24 06:42:35,736] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72000, global step 1152612: learning rate 0.0000
[2019-03-24 06:42:35,949] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72000, global step 1152720: loss -50.1704
[2019-03-24 06:42:35,952] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72000, global step 1152721: learning rate 0.0000
[2019-03-24 06:42:36,148] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72000, global step 1152816: loss -117.2143
[2019-03-24 06:42:36,150] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72000, global step 1152817: loss -125.6203
[2019-03-24 06:42:36,151] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72000, global step 1152817: learning rate 0.0000
[2019-03-24 06:42:36,151] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72000, global step 1152817: learning rate 0.0000
[2019-03-24 06:42:37,087] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.4870430e-15 4.5047234e-16 1.1232205e-14 4.6565280e-13], sum to 1.0000
[2019-03-24 06:42:37,092] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6022
[2019-03-24 06:42:37,099] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 857835.1885019905 W.
[2019-03-24 06:42:37,104] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.33333333333334, 88.66666666666666, 1.0, 2.0, 0.7526443217335607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 857835.1885019905, 857835.1885019905, 186344.245041019], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3483600.0000, 
sim time next is 3484200.0000, 
raw observation next is [25.41666666666666, 87.33333333333333, 1.0, 2.0, 0.2438051941960339, 1.0, 1.0, 0.2438051941960339, 1.0, 1.0, 0.3881458093409281, 6.911199999999999, 6.9112, 121.94756008, 833626.2457468177, 833626.2457468181, 235439.5436560824], 
processed observation next is [1.0, 0.30434782608695654, 0.49691358024691334, 0.8733333333333333, 1.0, 1.0, 0.09976808832861177, 1.0, 0.5, 0.09976808832861177, 1.0, 0.5, 0.23518226167616013, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.29772365919529203, 0.2977236591952922, 0.4527683531847738], 
reward next is 0.5472, 
noisyNet noise sample is [array([-0.4061635], dtype=float32), 1.4823633]. 
=============================================
[2019-03-24 06:42:37,368] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72000, global step 1153350: loss -12.4383
[2019-03-24 06:42:37,371] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72000, global step 1153352: learning rate 0.0000
[2019-03-24 06:42:40,448] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72500, global step 1154939: loss -3.8694
[2019-03-24 06:42:40,450] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72500, global step 1154939: learning rate 0.0000
[2019-03-24 06:42:40,989] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.2611152e-19 1.7933362e-19 5.1051768e-18 6.8604507e-16], sum to 1.0000
[2019-03-24 06:42:40,995] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1702
[2019-03-24 06:42:41,004] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1580417.985076225 W.
[2019-03-24 06:42:41,007] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 86.0, 1.0, 2.0, 0.7592387785613682, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1580417.985076225, 1580417.985076225, 328276.7182184602], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3679200.0000, 
sim time next is 3679800.0000, 
raw observation next is [26.16666666666667, 86.5, 1.0, 2.0, 0.4815604956824662, 1.0, 1.0, 0.4815604956824662, 1.0, 2.0, 0.7666599924569202, 6.911199999999999, 6.9112, 121.94756008, 1647430.459530337, 1647430.459530337, 334630.9287182494], 
processed observation next is [1.0, 0.6086956521739131, 0.5246913580246916, 0.865, 1.0, 1.0, 0.3828101139076979, 1.0, 0.5, 0.3828101139076979, 1.0, 1.0, 0.7083249905711503, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5883680212608347, 0.5883680212608347, 0.6435210167658642], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.2193768], dtype=float32), -1.7345642]. 
=============================================
[2019-03-24 06:42:41,107] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 8.0807207e-23 5.5566723e-24 2.7596149e-22 2.8826595e-20], sum to 1.0000
[2019-03-24 06:42:41,115] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2232
[2019-03-24 06:42:41,120] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 704045.002072422 W.
[2019-03-24 06:42:41,123] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.85, 81.5, 1.0, 2.0, 0.2059248123647435, 1.0, 1.0, 0.2059248123647435, 1.0, 2.0, 0.327839007787605, 6.9112, 6.9112, 121.94756008, 704045.002072422, 704045.002072422, 222539.7166387915], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3526200.0000, 
sim time next is 3526800.0000, 
raw observation next is [25.46666666666667, 82.33333333333334, 1.0, 2.0, 0.2019617615251383, 1.0, 2.0, 0.2019617615251383, 1.0, 2.0, 0.3215297017833983, 6.9112, 6.9112, 121.94756008, 690489.4597007612, 690489.4597007612, 221236.5203250273], 
processed observation next is [1.0, 0.8260869565217391, 0.4987654320987655, 0.8233333333333335, 1.0, 1.0, 0.049954478006117034, 1.0, 1.0, 0.049954478006117034, 1.0, 1.0, 0.15191212722924785, 0.0, 0.0, 0.8096049824067558, 0.2466033784645576, 0.2466033784645576, 0.4254548467788986], 
reward next is 0.5745, 
noisyNet noise sample is [array([-0.9171885], dtype=float32), -0.4073122]. 
=============================================
[2019-03-24 06:42:45,237] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72500, global step 1157371: loss -32.2281
[2019-03-24 06:42:45,241] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72500, global step 1157371: learning rate 0.0000
[2019-03-24 06:42:45,755] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.4540226e-27 3.8415182e-29 9.5407758e-27 8.7053151e-28], sum to 1.0000
[2019-03-24 06:42:45,764] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6316
[2019-03-24 06:42:45,768] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.16666666666667, 99.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8631245722307543, 6.911200000000001, 6.9112, 121.9260426156618, 636823.4042512253, 636823.404251225, 169836.2317914479], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3649800.0000, 
sim time next is 3650400.0000, 
raw observation next is [22.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8363468847562328, 6.9112, 6.9112, 121.9260426156618, 617713.6727704842, 617713.6727704842, 166238.6060095962], 
processed observation next is [1.0, 0.2608695652173913, 0.37037037037037035, 1.0, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.795433605945291, 0.0, 0.0, 0.8094621288201359, 0.22061202598945864, 0.22061202598945864, 0.31968962694153114], 
reward next is 0.6803, 
noisyNet noise sample is [array([-0.7586647], dtype=float32), 0.04849806]. 
=============================================
[2019-03-24 06:42:47,797] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.5823722e-19 6.1731126e-20 1.8122214e-18 1.0601664e-15], sum to 1.0000
[2019-03-24 06:42:47,803] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5372
[2019-03-24 06:42:47,810] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1531934.243883966 W.
[2019-03-24 06:42:47,817] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 90.0, 1.0, 2.0, 0.4478307938776003, 1.0, 2.0, 0.4478307938776003, 1.0, 1.0, 0.7129612086838761, 6.911200000000001, 6.9112, 121.94756008, 1531934.243883966, 1531934.243883966, 318668.0346248974], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3677400.0000, 
sim time next is 3678000.0000, 
raw observation next is [25.33333333333333, 88.66666666666666, 1.0, 2.0, 0.7280668514695574, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426156618, 1544836.812616528, 1544836.812616528, 322386.6730624426], 
processed observation next is [1.0, 0.5652173913043478, 0.49382716049382697, 0.8866666666666666, 1.0, 1.0, 0.6762700612732826, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5517274330773314, 0.5517274330773314, 0.6199743712739282], 
reward next is 0.3800, 
noisyNet noise sample is [array([-0.65287185], dtype=float32), -1.7503139]. 
=============================================
[2019-03-24 06:42:47,833] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[36.051468]
 [36.041077]
 [35.90054 ]
 [36.525368]
 [36.959656]], R is [[36.26567841]
 [35.90302277]
 [35.54399109]
 [35.63790894]
 [35.82715988]].
[2019-03-24 06:42:49,880] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 2.4780538e-17 1.3880327e-17 2.4945962e-16 1.2496681e-14], sum to 1.0000
[2019-03-24 06:42:49,887] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8098
[2019-03-24 06:42:49,896] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 770745.4131389402 W.
[2019-03-24 06:42:49,899] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.3381361051467986, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5383236917178377, 6.9112, 6.9112, 121.9260426156618, 770745.4131389402, 770745.4131389402, 205777.993987003], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3729600.0000, 
sim time next is 3730200.0000, 
raw observation next is [24.9, 94.66666666666667, 1.0, 2.0, 0.3638222382098819, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5792168520932183, 6.911199999999998, 6.9112, 121.9260426156618, 829325.9057687039, 829325.9057687048, 213198.9802955973], 
processed observation next is [1.0, 0.17391304347826086, 0.47777777777777775, 0.9466666666666668, 1.0, 1.0, 0.24264552167843084, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4740210651165228, -1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.29618782348882283, 0.29618782348882317, 0.4099980390299948], 
reward next is 0.5900, 
noisyNet noise sample is [array([0.5219611], dtype=float32), -0.22688234]. 
=============================================
[2019-03-24 06:42:50,064] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72500, global step 1159871: loss -32.0127
[2019-03-24 06:42:50,067] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72500, global step 1159871: learning rate 0.0000
[2019-03-24 06:42:50,569] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72500, global step 1160132: loss 5.5687
[2019-03-24 06:42:50,570] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72500, global step 1160132: learning rate 0.0000
[2019-03-24 06:42:50,796] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.5799716e-19 2.7884871e-19 2.8756332e-18 8.0020372e-16], sum to 1.0000
[2019-03-24 06:42:50,800] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3494
[2019-03-24 06:42:50,803] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1369044.546647269 W.
[2019-03-24 06:42:50,807] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.5, 94.00000000000001, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.311699457921524, 6.9112, 122.5285924609955, 1369044.546647269, 1162939.480233102, 245672.9451043822], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3744600.0000, 
sim time next is 3745200.0000, 
raw observation next is [25.6, 94.0, 1.0, 2.0, 0.5112245679438476, 1.0, 1.0, 0.5112245679438476, 1.0, 1.0, 0.8138861615884267, 6.9112, 6.9112, 121.94756008, 1749011.315849797, 1749011.315849797, 349132.360408949], 
processed observation next is [1.0, 0.34782608695652173, 0.5037037037037038, 0.94, 1.0, 1.0, 0.41812448564743765, 1.0, 0.5, 0.41812448564743765, 1.0, 0.5, 0.7673577019855334, 0.0, 0.0, 0.8096049824067558, 0.6246468985177847, 0.6246468985177847, 0.671408385401825], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.31223938], dtype=float32), -0.983108]. 
=============================================
[2019-03-24 06:42:50,830] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72500, global step 1160264: loss 11.3967
[2019-03-24 06:42:50,834] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72500, global step 1160264: learning rate 0.0000
[2019-03-24 06:42:51,148] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72500, global step 1160428: loss 26.1544
[2019-03-24 06:42:51,149] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72500, global step 1160428: learning rate 0.0000
[2019-03-24 06:42:51,214] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72500, global step 1160465: loss 3.7279
[2019-03-24 06:42:51,216] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72500, global step 1160465: loss -21.7771
[2019-03-24 06:42:51,216] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72500, global step 1160465: learning rate 0.0000
[2019-03-24 06:42:51,220] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72500, global step 1160466: learning rate 0.0000
[2019-03-24 06:42:51,244] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72500, global step 1160475: loss 5.1280
[2019-03-24 06:42:51,245] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72500, global step 1160475: learning rate 0.0000
[2019-03-24 06:42:51,270] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72500, global step 1160486: loss -16.5323
[2019-03-24 06:42:51,272] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72500, global step 1160487: learning rate 0.0000
[2019-03-24 06:42:51,403] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72500, global step 1160559: loss -48.0897
[2019-03-24 06:42:51,404] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72500, global step 1160559: learning rate 0.0000
[2019-03-24 06:42:51,642] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72500, global step 1160686: loss -3.2189
[2019-03-24 06:42:51,644] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72500, global step 1160686: learning rate 0.0000
[2019-03-24 06:42:51,821] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72500, global step 1160780: loss -27.2773
[2019-03-24 06:42:51,822] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72500, global step 1160781: learning rate 0.0000
[2019-03-24 06:42:51,844] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72500, global step 1160790: loss -5.0545
[2019-03-24 06:42:51,846] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72500, global step 1160790: learning rate 0.0000
[2019-03-24 06:42:51,918] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72500, global step 1160822: loss -45.4004
[2019-03-24 06:42:51,919] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72500, global step 1160823: learning rate 0.0000
[2019-03-24 06:42:52,980] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72500, global step 1161376: loss -22.3693
[2019-03-24 06:42:52,982] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72500, global step 1161376: learning rate 0.0000
[2019-03-24 06:42:56,299] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73000, global step 1163095: loss 15.0569
[2019-03-24 06:42:56,301] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73000, global step 1163095: learning rate 0.0000
[2019-03-24 06:42:59,259] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.4549022e-23 5.3903154e-24 9.7428187e-24 1.0594153e-21], sum to 1.0000
[2019-03-24 06:42:59,263] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6430
[2019-03-24 06:42:59,269] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 843712.1805417603 W.
[2019-03-24 06:42:59,271] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666667, 93.16666666666667, 1.0, 2.0, 0.2467533389169853, 1.0, 1.0, 0.2467533389169853, 1.0, 2.0, 0.3928393517510531, 6.9112, 6.9112, 121.94756008, 843712.1805417603, 843712.1805417603, 236477.1539034119], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3901800.0000, 
sim time next is 3902400.0000, 
raw observation next is [26.0, 94.0, 1.0, 2.0, 0.7365563657214489, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 839488.7098872474, 839488.7098872474, 183181.7427022106], 
processed observation next is [0.0, 0.17391304347826086, 0.5185185185185185, 0.94, 1.0, 1.0, 0.6863766258588677, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2998173963883026, 0.2998173963883026, 0.3522725821196358], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.52020806], dtype=float32), 0.37178665]. 
=============================================
[2019-03-24 06:42:59,901] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.00000000e+00 5.31905356e-22 1.03429327e-22 3.30697459e-22
 7.14570554e-21], sum to 1.0000
[2019-03-24 06:42:59,904] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6784
[2019-03-24 06:42:59,910] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 830880.6592427861 W.
[2019-03-24 06:42:59,913] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 92.5, 1.0, 2.0, 0.2430026454717646, 1.0, 1.0, 0.2430026454717646, 1.0, 1.0, 0.3868681256347041, 6.9112, 6.9112, 121.94756008, 830880.6592427861, 830880.6592427861, 235157.9246175513], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3893400.0000, 
sim time next is 3894000.0000, 
raw observation next is [26.0, 92.0, 1.0, 2.0, 0.3622803490136097, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5767621142769275, 6.911199999999999, 6.9112, 121.9260426156618, 825809.3050777283, 825809.3050777288, 212748.230006913], 
processed observation next is [0.0, 0.043478260869565216, 0.5185185185185185, 0.92, 1.0, 1.0, 0.24080993930191635, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.4709526428461593, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.29493189467061726, 0.2949318946706174, 0.4091312115517558], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.4513671], dtype=float32), 0.5653124]. 
=============================================
[2019-03-24 06:42:59,928] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[29.856415]
 [29.328886]
 [29.36722 ]
 [29.524895]
 [29.472986]], R is [[29.26990891]
 [28.977211  ]
 [28.68743896]
 [28.40056419]
 [28.11655807]].
[2019-03-24 06:43:00,707] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73000, global step 1165367: loss 92.7322
[2019-03-24 06:43:00,709] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73000, global step 1165368: learning rate 0.0000
[2019-03-24 06:43:01,726] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.00000000e+00 2.03921218e-28 2.78845803e-32 5.79511718e-29
 1.03511216e-26], sum to 1.0000
[2019-03-24 06:43:01,732] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5452
[2019-03-24 06:43:01,739] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 837055.0450723119 W.
[2019-03-24 06:43:01,746] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.76666666666667, 87.0, 1.0, 2.0, 0.3672111327721351, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5846120826049162, 6.911199999999999, 6.9112, 121.9260426156618, 837055.0450723119, 837055.0450723124, 214200.3552648737], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3968400.0000, 
sim time next is 3969000.0000, 
raw observation next is [26.65, 86.0, 1.0, 2.0, 0.360620149325421, 1.0, 1.0, 0.360620149325421, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 822022.8906126631, 822022.8906126631, 195644.7216184065], 
processed observation next is [0.0, 0.9565217391304348, 0.5425925925925925, 0.86, 1.0, 1.0, 0.2388335111016917, 1.0, 0.5, 0.2388335111016917, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29357960379023684, 0.29357960379023684, 0.3762398492661663], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.7817107], dtype=float32), 0.34157997]. 
=============================================
[2019-03-24 06:43:01,758] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[44.65882]
 [44.26892]
 [44.20463]
 [43.94471]
 [43.8081 ]], R is [[43.66646194]
 [43.22979736]
 [42.79750061]
 [42.95017242]
 [43.15840912]].
[2019-03-24 06:43:05,621] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73000, global step 1167879: loss 112.0486
[2019-03-24 06:43:05,623] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73000, global step 1167880: learning rate 0.0000
[2019-03-24 06:43:06,310] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73000, global step 1168224: loss 65.7711
[2019-03-24 06:43:06,311] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73000, global step 1168224: learning rate 0.0000
[2019-03-24 06:43:06,499] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73000, global step 1168320: loss 26.5568
[2019-03-24 06:43:06,501] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73000, global step 1168321: learning rate 0.0000
[2019-03-24 06:43:06,646] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73000, global step 1168400: loss -174.8294
[2019-03-24 06:43:06,648] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73000, global step 1168400: learning rate 0.0000
[2019-03-24 06:43:06,753] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73000, global step 1168454: loss 50.2074
[2019-03-24 06:43:06,754] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73000, global step 1168454: learning rate 0.0000
[2019-03-24 06:43:06,819] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73000, global step 1168484: loss -58.2270
[2019-03-24 06:43:06,820] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73000, global step 1168484: learning rate 0.0000
[2019-03-24 06:43:06,856] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73000, global step 1168502: loss -101.6508
[2019-03-24 06:43:06,859] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73000, global step 1168502: learning rate 0.0000
[2019-03-24 06:43:06,985] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73000, global step 1168572: loss 115.8199
[2019-03-24 06:43:06,987] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73000, global step 1168573: learning rate 0.0000
[2019-03-24 06:43:07,322] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73000, global step 1168748: loss 66.4969
[2019-03-24 06:43:07,324] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73000, global step 1168749: learning rate 0.0000
[2019-03-24 06:43:07,354] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73000, global step 1168767: loss -130.8376
[2019-03-24 06:43:07,355] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73000, global step 1168767: learning rate 0.0000
[2019-03-24 06:43:07,423] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73000, global step 1168801: loss -25.7660
[2019-03-24 06:43:07,427] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73000, global step 1168801: learning rate 0.0000
[2019-03-24 06:43:07,476] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73000, global step 1168826: loss -141.3953
[2019-03-24 06:43:07,477] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73000, global step 1168826: learning rate 0.0000
[2019-03-24 06:43:07,581] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73000, global step 1168879: loss -7.7555
[2019-03-24 06:43:07,582] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73000, global step 1168879: learning rate 0.0000
[2019-03-24 06:43:08,563] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73000, global step 1169400: loss -62.1514
[2019-03-24 06:43:08,565] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73000, global step 1169400: learning rate 0.0000
[2019-03-24 06:43:08,709] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:43:08,719] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2173
[2019-03-24 06:43:08,727] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.3, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6711412135875918, 6.9112, 6.9112, 121.9260426156618, 501258.1484782824, 501258.1484782824, 140511.3988106543], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4078800.0000, 
sim time next is 4079400.0000, 
raw observation next is [20.25, 94.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8178117695436721, 6.911200000000001, 6.9112, 121.9260426156618, 610882.5136297246, 610882.5136297242, 157000.4389297853], 
processed observation next is [1.0, 0.21739130434782608, 0.3055555555555556, 0.9416666666666665, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.77226471192959, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2181723262963302, 0.21817232629633004, 0.3019239210188179], 
reward next is 0.6981, 
noisyNet noise sample is [array([-0.96741337], dtype=float32), 0.22550355]. 
=============================================
[2019-03-24 06:43:10,431] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:43:10,440] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2933
[2019-03-24 06:43:10,444] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.3, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7354262974875037, 6.9112, 6.9112, 121.9260426156618, 549350.2316837584, 549350.2316837584, 149828.6697368405], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4129200.0000, 
sim time next is 4129800.0000, 
raw observation next is [21.2, 92.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7339316742926452, 6.9112, 6.9112, 121.9260426156618, 548261.0274395389, 548261.0274395389, 149594.4003068871], 
processed observation next is [1.0, 0.8260869565217391, 0.34074074074074073, 0.9266666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6674145928658065, 0.0, 0.0, 0.8094621288201359, 0.1958075097998353, 0.1958075097998353, 0.28768153905170596], 
reward next is 0.7123, 
noisyNet noise sample is [array([-0.48982012], dtype=float32), 0.92193687]. 
=============================================
[2019-03-24 06:43:11,333] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73500, global step 1170822: loss -5.6985
[2019-03-24 06:43:11,336] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73500, global step 1170823: learning rate 0.0000
[2019-03-24 06:43:12,431] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:43:12,439] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0180
[2019-03-24 06:43:12,448] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.9, 99.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7291674209667005, 6.911200000000001, 6.9112, 121.9260426156618, 544863.2181051526, 544863.2181051521, 147552.2475310201], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4165200.0000, 
sim time next is 4165800.0000, 
raw observation next is [19.91666666666666, 99.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6914159785748084, 6.9112, 6.9112, 121.9260426156618, 516648.7524605885, 516648.7524605885, 143430.0681233546], 
processed observation next is [1.0, 0.21739130434782608, 0.2932098765432097, 0.9916666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6142699732185105, 0.0, 0.0, 0.8094621288201359, 0.18451741159306734, 0.18451741159306734, 0.27582705408337427], 
reward next is 0.7242, 
noisyNet noise sample is [array([0.65403754], dtype=float32), -0.6948944]. 
=============================================
[2019-03-24 06:43:15,830] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73500, global step 1173157: loss -38.3354
[2019-03-24 06:43:15,832] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73500, global step 1173157: learning rate 0.0000
[2019-03-24 06:43:19,373] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-24 06:43:19,374] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:43:19,374] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:43:19,374] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:43:19,376] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:43:19,378] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:43:19,380] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:43:19,378] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:43:19,380] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:43:19,383] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:43:19,385] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:43:19,392] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run48
[2019-03-24 06:43:19,393] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run48
[2019-03-24 06:43:19,453] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run48
[2019-03-24 06:43:19,481] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run48
[2019-03-24 06:43:19,506] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run48
[2019-03-24 06:43:31,696] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00683401], dtype=float32), 0.016025925]
[2019-03-24 06:43:31,698] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.4376259, 37.70090982, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6440689008815248, 6.9112, 6.9112, 121.9260426156618, 480403.6812629625, 480403.6812629625, 136701.9769232839]
[2019-03-24 06:43:31,700] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:43:31,703] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 2.9411380e-37 0.0000000e+00 3.4139671e-37 1.0247773e-37], sampled 0.055355248580190364
[2019-03-24 06:43:37,977] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00683401], dtype=float32), 0.016025925]
[2019-03-24 06:43:37,978] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.0, 42.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5382683044669309, 6.9112, 6.9112, 121.9260426156618, 394137.7802479361, 394137.7802479361, 121770.2755551091]
[2019-03-24 06:43:37,978] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:43:37,982] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.9059669130313813
[2019-03-24 06:43:55,586] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00683401], dtype=float32), 0.016025925]
[2019-03-24 06:43:55,588] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.1, 72.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8698694245550851, 6.911200000000001, 6.9112, 121.9260426156618, 640813.3623602133, 640813.3623602128, 170987.1141239959]
[2019-03-24 06:43:55,588] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:43:55,591] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.8148633982012392
[2019-03-24 06:44:04,045] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00683401], dtype=float32), 0.016025925]
[2019-03-24 06:44:04,047] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [35.53333333333333, 41.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.960934377971025, 6.9112, 121.9257315887407, 739735.475587429, 714267.0938266707, 191602.283455698]
[2019-03-24 06:44:04,047] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:44:04,051] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.90631004354585
[2019-03-24 06:44:04,052] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 739735.475587429 W.
[2019-03-24 06:44:13,812] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00683401], dtype=float32), 0.016025925]
[2019-03-24 06:44:13,813] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.4, 77.66666666666667, 1.0, 2.0, 0.7170215629529966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 817212.0861063274, 817212.0861063274, 179393.513492861]
[2019-03-24 06:44:13,816] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:44:13,821] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 8.4132858e-34 1.9451669e-38 7.8176123e-34 4.3591642e-34], sampled 0.34190699833892113
[2019-03-24 06:44:13,823] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 817212.0861063274 W.
[2019-03-24 06:44:33,821] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00683401], dtype=float32), 0.016025925]
[2019-03-24 06:44:33,822] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [30.42395414, 60.37769016, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.835448712776285, 6.9112, 121.9224760285783, 1636425.642448653, 1163141.538031427, 245582.5270229956]
[2019-03-24 06:44:33,822] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:44:33,825] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 3.2031354e-32 1.2050952e-36 3.1175685e-32 1.7286608e-32], sampled 0.11634009800132561
[2019-03-24 06:44:33,826] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1636425.642448653 W.
[2019-03-24 06:44:46,391] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00683401], dtype=float32), 0.016025925]
[2019-03-24 06:44:46,392] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.75, 57.66666666666667, 1.0, 2.0, 0.3451068019529623, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5495752068683326, 6.9112, 6.9112, 121.9258333811466, 790348.1427805399, 790348.1427805399, 207705.6401099834]
[2019-03-24 06:44:46,395] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:44:46,398] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 4.4108368e-33 1.0287725e-37 4.0808829e-33 2.1730361e-33], sampled 0.12012265082732565
[2019-03-24 06:44:46,400] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 790348.1427805399 W.
[2019-03-24 06:44:53,403] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00683401], dtype=float32), 0.016025925]
[2019-03-24 06:44:53,405] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.2, 65.0, 1.0, 2.0, 0.6181528915022139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 704476.5619017963, 704476.5619017958, 161228.0746026776]
[2019-03-24 06:44:53,408] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:44:53,413] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 3.9210361e-30 3.1475351e-34 3.8904033e-30 2.2557366e-30], sampled 0.43413791395784485
[2019-03-24 06:44:53,414] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 704476.5619017963 W.
[2019-03-24 06:45:06,313] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 06:45:06,747] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 06:45:06,781] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 06:45:06,958] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 06:45:06,959] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 06:45:07,979] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1175000, evaluation results [1175000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 06:45:09,733] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73500, global step 1175855: loss -18.0189
[2019-03-24 06:45:09,734] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73500, global step 1175855: learning rate 0.0000
[2019-03-24 06:45:10,586] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73500, global step 1176280: loss 0.2733
[2019-03-24 06:45:10,591] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73500, global step 1176280: learning rate 0.0000
[2019-03-24 06:45:10,628] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73500, global step 1176298: loss 5.5240
[2019-03-24 06:45:10,629] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73500, global step 1176298: learning rate 0.0000
[2019-03-24 06:45:10,818] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73500, global step 1176390: loss -39.1889
[2019-03-24 06:45:10,824] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73500, global step 1176390: learning rate 0.0000
[2019-03-24 06:45:10,839] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73500, global step 1176401: loss -44.5675
[2019-03-24 06:45:10,840] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73500, global step 1176401: learning rate 0.0000
[2019-03-24 06:45:10,947] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73500, global step 1176456: loss -55.1816
[2019-03-24 06:45:10,949] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73500, global step 1176456: learning rate 0.0000
[2019-03-24 06:45:10,983] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73500, global step 1176471: loss -65.4888
[2019-03-24 06:45:10,986] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73500, global step 1176471: learning rate 0.0000
[2019-03-24 06:45:11,094] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73500, global step 1176528: loss 49.9334
[2019-03-24 06:45:11,096] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73500, global step 1176528: learning rate 0.0000
[2019-03-24 06:45:11,304] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73500, global step 1176629: loss 4.7432
[2019-03-24 06:45:11,306] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73500, global step 1176629: learning rate 0.0000
[2019-03-24 06:45:11,568] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73500, global step 1176763: loss 50.0591
[2019-03-24 06:45:11,571] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73500, global step 1176766: learning rate 0.0000
[2019-03-24 06:45:11,585] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73500, global step 1176772: loss -39.1898
[2019-03-24 06:45:11,592] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73500, global step 1176773: learning rate 0.0000
[2019-03-24 06:45:11,611] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73500, global step 1176782: loss 29.1754
[2019-03-24 06:45:11,613] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73500, global step 1176782: learning rate 0.0000
[2019-03-24 06:45:11,637] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73500, global step 1176791: loss -53.2169
[2019-03-24 06:45:11,639] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73500, global step 1176792: learning rate 0.0000
[2019-03-24 06:45:12,830] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73500, global step 1177365: loss -21.2814
[2019-03-24 06:45:12,833] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73500, global step 1177365: learning rate 0.0000
[2019-03-24 06:45:14,282] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 6.6103814e-30 1.3863545e-33 6.5389031e-30 1.1924046e-30], sum to 1.0000
[2019-03-24 06:45:14,286] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7150
[2019-03-24 06:45:14,291] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1207973.005123594 W.
[2019-03-24 06:45:14,302] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.7, 69.0, 1.0, 2.0, 0.3532017185890371, 1.0, 2.0, 0.3532017185890371, 1.0, 2.0, 0.5623086389706569, 6.911200000000001, 6.9112, 121.94756008, 1207973.005123594, 1207973.005123593, 277189.2755028706], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4626000.0000, 
sim time next is 4626600.0000, 
raw observation next is [28.83333333333334, 68.16666666666667, 1.0, 2.0, 0.5275099690594092, 1.0, 2.0, 0.5275099690594092, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1202741.820833894, 1202741.820833895, 244021.523591796], 
processed observation next is [1.0, 0.5652173913043478, 0.623456790123457, 0.6816666666666668, 1.0, 1.0, 0.43751186792786806, 1.0, 1.0, 0.43751186792786806, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.42955065029781925, 0.4295506502978196, 0.46927216075345385], 
reward next is 0.5307, 
noisyNet noise sample is [array([-1.1854544], dtype=float32), 0.12549762]. 
=============================================
[2019-03-24 06:45:15,888] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74000, global step 1178856: loss 81.0238
[2019-03-24 06:45:15,890] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74000, global step 1178856: learning rate 0.0000
[2019-03-24 06:45:17,998] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.3684016e-32 5.7437016e-38 5.2289747e-33 1.5246718e-31], sum to 1.0000
[2019-03-24 06:45:18,005] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5051
[2019-03-24 06:45:18,019] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 847286.2057283459 W.
[2019-03-24 06:45:18,023] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.33333333333333, 80.66666666666667, 1.0, 2.0, 0.2477980263774034, 1.0, 2.0, 0.2477980263774034, 1.0, 1.0, 0.3945025282111341, 6.911199999999999, 6.9112, 121.94756008, 847286.2057283459, 847286.2057283464, 236846.0006390419], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4473600.0000, 
sim time next is 4474200.0000, 
raw observation next is [28.16666666666667, 82.33333333333333, 1.0, 2.0, 0.3756126859112077, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5979876288218029, 6.911199999999999, 6.9112, 121.9260426156618, 856217.0203343005, 856217.0203343008, 216698.5797762967], 
processed observation next is [0.0, 0.782608695652174, 0.5987654320987656, 0.8233333333333333, 1.0, 1.0, 0.25668176894191397, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.49748453602725357, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.30579179297653586, 0.305791792976536, 0.41672803803133984], 
reward next is 0.5833, 
noisyNet noise sample is [array([0.01286061], dtype=float32), 0.5390313]. 
=============================================
[2019-03-24 06:45:20,086] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74000, global step 1181016: loss -92.3836
[2019-03-24 06:45:20,089] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74000, global step 1181016: learning rate 0.0000
[2019-03-24 06:45:25,403] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74000, global step 1183778: loss 224.1090
[2019-03-24 06:45:25,406] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74000, global step 1183779: learning rate 0.0000
[2019-03-24 06:45:25,641] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.2217656e-25 2.7213763e-28 1.0393419e-26 6.3367409e-27], sum to 1.0000
[2019-03-24 06:45:25,647] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2502
[2019-03-24 06:45:25,659] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1791822.156204683 W.
[2019-03-24 06:45:25,669] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.66666666666667, 65.83333333333334, 1.0, 2.0, 0.9444464805630112, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260248205964, 1791822.156204683, 1791822.156204683, 366737.4426639121], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4639800.0000, 
sim time next is 4640400.0000, 
raw observation next is [29.6, 65.0, 1.0, 2.0, 0.8479349876620554, 1.0, 1.0, 0.8479349876620554, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1934181.5916631, 1934181.5916631, 363959.7563470732], 
processed observation next is [1.0, 0.7391304347826086, 0.6518518518518519, 0.65, 1.0, 1.0, 0.8189702234072088, 1.0, 0.5, 0.8189702234072088, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.6907791398796785, 0.6907791398796785, 0.6999226083597562], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.21688372], dtype=float32), 0.92553276]. 
=============================================
[2019-03-24 06:45:26,283] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74000, global step 1184233: loss -41.6503
[2019-03-24 06:45:26,288] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74000, global step 1184234: learning rate 0.0000
[2019-03-24 06:45:26,508] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74000, global step 1184345: loss 122.3211
[2019-03-24 06:45:26,510] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74000, global step 1184345: learning rate 0.0000
[2019-03-24 06:45:26,525] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74000, global step 1184353: loss -29.6127
[2019-03-24 06:45:26,527] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74000, global step 1184354: learning rate 0.0000
[2019-03-24 06:45:26,635] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74000, global step 1184412: loss 77.7052
[2019-03-24 06:45:26,638] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74000, global step 1184412: learning rate 0.0000
[2019-03-24 06:45:26,655] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74000, global step 1184419: loss 126.8573
[2019-03-24 06:45:26,656] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74000, global step 1184419: learning rate 0.0000
[2019-03-24 06:45:26,715] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74000, global step 1184449: loss 128.4847
[2019-03-24 06:45:26,718] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74000, global step 1184451: learning rate 0.0000
[2019-03-24 06:45:26,896] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74000, global step 1184544: loss 92.0454
[2019-03-24 06:45:26,899] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74000, global step 1184545: learning rate 0.0000
[2019-03-24 06:45:26,935] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74000, global step 1184566: loss 31.0611
[2019-03-24 06:45:26,938] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74000, global step 1184566: learning rate 0.0000
[2019-03-24 06:45:27,272] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74000, global step 1184735: loss 35.2728
[2019-03-24 06:45:27,273] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74000, global step 1184735: loss 110.1891
[2019-03-24 06:45:27,274] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74000, global step 1184735: learning rate 0.0000
[2019-03-24 06:45:27,274] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74000, global step 1184735: learning rate 0.0000
[2019-03-24 06:45:27,455] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74000, global step 1184829: loss 151.9557
[2019-03-24 06:45:27,460] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74000, global step 1184829: learning rate 0.0000
[2019-03-24 06:45:27,574] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74000, global step 1184889: loss 87.2675
[2019-03-24 06:45:27,576] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74000, global step 1184889: learning rate 0.0000
[2019-03-24 06:45:27,774] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 3.5672359e-27 3.7343330e-31 3.6919449e-28 6.6620560e-28], sum to 1.0000
[2019-03-24 06:45:27,781] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8311
[2019-03-24 06:45:27,792] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 812122.8643727744 W.
[2019-03-24 06:45:27,794] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.86666666666667, 92.33333333333334, 1.0, 2.0, 0.3562793230963842, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5672082855769348, 6.9112, 6.9112, 121.9260426156618, 812122.8643727744, 812122.8643727744, 210994.3079413389], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4659600.0000, 
sim time next is 4660200.0000, 
raw observation next is [25.8, 91.5, 1.0, 2.0, 0.3521380304719725, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5606152128463865, 6.9112, 6.9112, 121.9260426156618, 802678.0291955821, 802678.0291955821, 209791.8247069908], 
processed observation next is [1.0, 0.9565217391304348, 0.5111111111111112, 0.915, 1.0, 1.0, 0.22873575056187204, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4507690160579831, 0.0, 0.0, 0.8094621288201359, 0.28667072471270794, 0.28667072471270794, 0.4034458167442131], 
reward next is 0.5966, 
noisyNet noise sample is [array([0.6380745], dtype=float32), 0.5430012]. 
=============================================
[2019-03-24 06:45:28,528] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74000, global step 1185375: loss 119.6846
[2019-03-24 06:45:28,531] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74000, global step 1185378: learning rate 0.0000
[2019-03-24 06:45:31,631] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.4748176e-23 1.0420652e-26 8.1336939e-24 2.0269713e-23], sum to 1.0000
[2019-03-24 06:45:31,639] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3733
[2019-03-24 06:45:31,644] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 740662.6431300628 W.
[2019-03-24 06:45:31,652] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.25, 89.83333333333333, 1.0, 2.0, 0.3249447731744689, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5173226616061992, 6.911200000000001, 6.9112, 121.9260426156618, 740662.6431300628, 740662.6431300624, 202068.9790185037], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4747800.0000, 
sim time next is 4748400.0000, 
raw observation next is [25.3, 89.0, 1.0, 2.0, 0.6445884575186556, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 734618.2316006306, 734618.2316006301, 165917.1864084314], 
processed observation next is [1.0, 1.0, 0.49259259259259264, 0.89, 1.0, 1.0, 0.5768910208555423, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2623636541430823, 0.26236365414308216, 0.3190715123239065], 
reward next is 0.6809, 
noisyNet noise sample is [array([-0.34395117], dtype=float32), -1.915599]. 
=============================================
[2019-03-24 06:45:31,806] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74500, global step 1187083: loss -117.4175
[2019-03-24 06:45:31,809] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74500, global step 1187084: learning rate 0.0000
[2019-03-24 06:45:31,949] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 5.7240870e-21 3.7105652e-22 2.5684019e-21 5.7381913e-20], sum to 1.0000
[2019-03-24 06:45:31,954] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5536
[2019-03-24 06:45:31,961] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 762538.5304706328 W.
[2019-03-24 06:45:31,967] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.1, 92.33333333333334, 1.0, 2.0, 0.6690748565335569, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 762538.5304706328, 762538.5304706324, 170370.0832479199], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4746000.0000, 
sim time next is 4746600.0000, 
raw observation next is [25.15, 91.5, 1.0, 2.0, 0.6631309782993798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 755761.0069403094, 755761.0069403094, 169279.6493980963], 
processed observation next is [1.0, 0.9565217391304348, 0.487037037037037, 0.915, 1.0, 1.0, 0.5989654503564046, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2699146453358248, 0.2699146453358248, 0.3255377873040314], 
reward next is 0.6745, 
noisyNet noise sample is [array([0.42132005], dtype=float32), 1.1710148]. 
=============================================
[2019-03-24 06:45:33,666] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 8.2929354e-19 8.2705049e-19 8.2497444e-18 2.6422178e-15], sum to 1.0000
[2019-03-24 06:45:33,675] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0331
[2019-03-24 06:45:33,681] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1736890.028261495 W.
[2019-03-24 06:45:33,686] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.7615274225421583, 1.0, 1.0, 0.7615274225421583, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1736890.028261495, 1736890.028261496, 328113.3407904395], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4795200.0000, 
sim time next is 4795800.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.9997003216319612, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1854900.938988407, 1854900.938988407, 379361.2031148109], 
processed observation next is [1.0, 0.5217391304347826, 0.5185185185185185, 0.89, 1.0, 1.0, 0.999643240038049, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, 0.0, 0.0, 0.8094621288201359, 0.6624646210672882, 0.6624646210672882, 0.7295407752207902], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6619817], dtype=float32), 0.49262518]. 
=============================================
[2019-03-24 06:45:34,963] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 4.6155176e-20 7.4093522e-22 1.2611001e-20 1.5673106e-20], sum to 1.0000
[2019-03-24 06:45:34,971] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3492
[2019-03-24 06:45:34,986] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 904794.7774314367 W.
[2019-03-24 06:45:34,989] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 94.00000000000001, 1.0, 2.0, 0.2646071105242562, 1.0, 2.0, 0.2646071105242562, 1.0, 1.0, 0.4212631376065761, 6.9112, 6.9112, 121.94756008, 904794.7774314367, 904794.7774314367, 242864.5691957145], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4817400.0000, 
sim time next is 4818000.0000, 
raw observation next is [27.0, 94.0, 1.0, 2.0, 0.7772203918510029, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 885862.2408815589, 885862.2408815589, 191285.2611386186], 
processed observation next is [1.0, 0.782608695652174, 0.5555555555555556, 0.94, 1.0, 1.0, 0.7347861807750035, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.31637937174341385, 0.31637937174341385, 0.3678562714204204], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.84804726], dtype=float32), -0.22360246]. 
=============================================
[2019-03-24 06:45:35,001] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[27.132967]
 [26.798512]
 [26.812801]
 [26.788769]
 [26.983152]], R is [[26.90559578]
 [26.63653946]
 [26.37017441]
 [26.65044975]
 [27.00444221]].
[2019-03-24 06:45:35,565] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74500, global step 1189027: loss -83.6785
[2019-03-24 06:45:35,569] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74500, global step 1189028: learning rate 0.0000
[2019-03-24 06:45:40,764] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74500, global step 1191677: loss -132.0769
[2019-03-24 06:45:40,768] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74500, global step 1191678: learning rate 0.0000
[2019-03-24 06:45:41,782] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74500, global step 1192199: loss -144.3998
[2019-03-24 06:45:41,785] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74500, global step 1192199: learning rate 0.0000
[2019-03-24 06:45:41,831] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 3.6879095e-18 2.4420373e-17 1.5521357e-16 7.3744416e-15], sum to 1.0000
[2019-03-24 06:45:41,835] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6657
[2019-03-24 06:45:41,839] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1523481.118713771 W.
[2019-03-24 06:45:41,842] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.5, 94.0, 1.0, 2.0, 0.7093568754573656, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1523481.118713771, 1523481.118713771, 318932.3174786679], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4974600.0000, 
sim time next is 4975200.0000, 
raw observation next is [24.2, 95.0, 1.0, 2.0, 0.4195718062426106, 1.0, 1.0, 0.4195718062426106, 1.0, 2.0, 0.6679719800379971, 6.911200000000001, 6.9112, 121.94756008, 1435175.669031327, 1435175.669031326, 305761.7756296979], 
processed observation next is [1.0, 0.6086956521739131, 0.45185185185185184, 0.95, 1.0, 1.0, 0.3090140550507269, 1.0, 0.5, 0.3090140550507269, 1.0, 1.0, 0.5849649750474963, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5125627389397596, 0.5125627389397592, 0.588003414672496], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2527486], dtype=float32), 0.4348498]. 
=============================================
[2019-03-24 06:45:42,179] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74500, global step 1192403: loss -67.9151
[2019-03-24 06:45:42,180] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74500, global step 1192404: learning rate 0.0000
[2019-03-24 06:45:42,203] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74500, global step 1192416: loss -38.0401
[2019-03-24 06:45:42,206] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74500, global step 1192416: learning rate 0.0000
[2019-03-24 06:45:42,207] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74500, global step 1192417: loss -104.0644
[2019-03-24 06:45:42,212] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74500, global step 1192417: learning rate 0.0000
[2019-03-24 06:45:42,239] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74500, global step 1192433: loss -28.4045
[2019-03-24 06:45:42,241] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74500, global step 1192434: learning rate 0.0000
[2019-03-24 06:45:42,249] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74500, global step 1192437: loss -34.5870
[2019-03-24 06:45:42,252] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74500, global step 1192437: learning rate 0.0000
[2019-03-24 06:45:42,368] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74500, global step 1192498: loss -95.5388
[2019-03-24 06:45:42,369] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74500, global step 1192499: learning rate 0.0000
[2019-03-24 06:45:42,768] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74500, global step 1192706: loss -53.4249
[2019-03-24 06:45:42,769] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74500, global step 1192706: learning rate 0.0000
[2019-03-24 06:45:42,781] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74500, global step 1192711: loss -20.9898
[2019-03-24 06:45:42,783] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74500, global step 1192711: learning rate 0.0000
[2019-03-24 06:45:42,797] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74500, global step 1192719: loss -59.6777
[2019-03-24 06:45:42,799] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74500, global step 1192720: learning rate 0.0000
[2019-03-24 06:45:43,100] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74500, global step 1192876: loss -24.7208
[2019-03-24 06:45:43,102] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74500, global step 1192876: learning rate 0.0000
[2019-03-24 06:45:43,247] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74500, global step 1192952: loss -60.8070
[2019-03-24 06:45:43,249] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74500, global step 1192952: learning rate 0.0000
[2019-03-24 06:45:44,074] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74500, global step 1193379: loss -34.4601
[2019-03-24 06:45:44,075] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74500, global step 1193380: learning rate 0.0000
[2019-03-24 06:45:47,456] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75000, global step 1195134: loss -69.7260
[2019-03-24 06:45:47,458] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75000, global step 1195135: learning rate 0.0000
[2019-03-24 06:45:48,669] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 3.8246287e-37 0.0000000e+00 1.0416233e-35 4.8476796e-35], sum to 1.0000
[2019-03-24 06:45:48,680] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7962
[2019-03-24 06:45:48,687] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 955665.4392001197 W.
[2019-03-24 06:45:48,691] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 71.66666666666667, 1.0, 2.0, 0.8384247876552261, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 955665.4392001197, 955665.4392001205, 204016.2565259095], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5071200.0000, 
sim time next is 5071800.0000, 
raw observation next is [31.0, 70.83333333333333, 1.0, 2.0, 0.8284846262249309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 944328.3200453813, 944328.3200453809, 201904.1091763603], 
processed observation next is [0.0, 0.6956521739130435, 0.7037037037037037, 0.7083333333333333, 1.0, 1.0, 0.7958150312201558, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3372601143019219, 0.3372601143019217, 0.3882771330314621], 
reward next is 0.6117, 
noisyNet noise sample is [array([-1.1750332], dtype=float32), 0.0020791315]. 
=============================================
[2019-03-24 06:45:51,001] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75000, global step 1196970: loss 39.5701
[2019-03-24 06:45:51,003] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75000, global step 1196970: learning rate 0.0000
[2019-03-24 06:45:55,812] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 1.0900614e-17 1.0346944e-17 1.9359797e-16 8.7081958e-15], sum to 1.0000
[2019-03-24 06:45:55,816] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2480
[2019-03-24 06:45:55,823] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1107475.670614416 W.
[2019-03-24 06:45:55,829] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.75, 90.66666666666667, 1.0, 2.0, 0.3238383152202015, 1.0, 1.0, 0.3238383152202015, 1.0, 1.0, 0.5155611445081857, 6.9112, 6.9112, 121.94756008, 1107475.670614416, 1107475.670614416, 265328.6666295768], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5213400.0000, 
sim time next is 5214000.0000, 
raw observation next is [25.0, 90.33333333333334, 1.0, 2.0, 0.4610379906701748, 1.0, 2.0, 0.4610379906701748, 1.0, 2.0, 0.7339874961060256, 6.9112, 6.9112, 121.94756008, 1577159.784618869, 1577159.784618869, 324851.315940449], 
processed observation next is [1.0, 0.34782608695652173, 0.48148148148148145, 0.9033333333333334, 1.0, 1.0, 0.3583785603216367, 1.0, 1.0, 0.3583785603216367, 1.0, 1.0, 0.6674843701325319, 0.0, 0.0, 0.8096049824067558, 0.5632713516495961, 0.5632713516495961, 0.624714069116248], 
reward next is 0.3753, 
noisyNet noise sample is [array([-0.10723574], dtype=float32), -2.0425117]. 
=============================================
[2019-03-24 06:45:55,843] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[27.792957]
 [27.886164]
 [27.9311  ]
 [27.81795 ]
 [27.646809]], R is [[27.10457993]
 [26.83353424]
 [26.5651989 ]
 [26.2995472 ]
 [26.03655243]].
[2019-03-24 06:45:56,312] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75000, global step 1199715: loss -64.7929
[2019-03-24 06:45:56,317] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75000, global step 1199715: learning rate 0.0000
[2019-03-24 06:45:56,670] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 4.4301009e-15 3.1497741e-16 7.7806473e-15 2.1993614e-13], sum to 1.0000
[2019-03-24 06:45:56,674] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9526
[2019-03-24 06:45:56,680] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2046534.391365796 W.
[2019-03-24 06:45:56,685] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.98333333333333, 78.0, 1.0, 2.0, 0.598089112925109, 1.0, 2.0, 0.598089112925109, 1.0, 1.0, 0.9521773461793235, 6.911200000000001, 6.9112, 121.94756008, 2046534.391365796, 2046534.391365796, 394335.4274458495], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5226600.0000, 
sim time next is 5227200.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.9201345624670866, 1.0, 2.0, 0.9201345624670866, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2099065.945205729, 2099065.945205729, 395896.8790264525], 
processed observation next is [1.0, 0.5217391304347826, 0.5925925925925926, 0.79, 1.0, 1.0, 0.904922098175103, 1.0, 1.0, 0.904922098175103, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7496664090020461, 0.7496664090020461, 0.7613401519739471], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2513369], dtype=float32), 1.2487592]. 
=============================================
[2019-03-24 06:45:56,875] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-24 06:45:56,877] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:45:56,878] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:45:56,879] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:45:56,879] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:45:56,880] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:45:56,881] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:45:56,880] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:45:56,881] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:45:56,884] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:45:56,883] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:45:56,899] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run49
[2019-03-24 06:45:56,927] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run49
[2019-03-24 06:45:56,929] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run49
[2019-03-24 06:45:56,929] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run49
[2019-03-24 06:45:56,929] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run49
[2019-03-24 06:46:36,309] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00631101], dtype=float32), 0.015595284]
[2019-03-24 06:46:36,311] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.16666666666667, 88.16666666666667, 1.0, 2.0, 0.6856808222381771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 781473.846202098, 781473.846202098, 173450.6355427959]
[2019-03-24 06:46:36,313] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:46:36,317] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.3007738e-21 6.8406665e-24 1.1889490e-21 4.7253476e-21], sampled 0.715378441738852
[2019-03-24 06:46:36,319] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 781473.846202098 W.
[2019-03-24 06:46:44,571] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00631101], dtype=float32), 0.015595284]
[2019-03-24 06:46:44,573] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.3, 66.0, 1.0, 2.0, 0.6568244607357666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 771664.2011613335, 771664.201161333, 169217.8372224394]
[2019-03-24 06:46:44,573] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:46:44,577] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.00000000e+00 1.35383544e-20 2.35848743e-23 8.01952654e-21
 1.07505296e-20], sampled 0.8805284953744983
[2019-03-24 06:46:44,578] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 771664.2011613335 W.
[2019-03-24 06:47:19,260] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00631101], dtype=float32), 0.015595284]
[2019-03-24 06:47:19,261] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.85977353, 84.582483145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8808236880546533, 6.911199999999999, 6.9112, 121.9260426156618, 645210.6320188162, 645210.6320188167, 173292.8664085319]
[2019-03-24 06:47:19,262] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:47:19,264] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.5827280e-27 6.1504157e-32 5.4996807e-28 3.6920294e-28], sampled 0.503975000212595
[2019-03-24 06:47:35,854] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00631101], dtype=float32), 0.015595284]
[2019-03-24 06:47:35,859] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.0, 86.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9358971384149307, 6.911199999999999, 6.9112, 121.9260426156618, 678797.0340374294, 678797.0340374298, 181828.6112250602]
[2019-03-24 06:47:35,859] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:47:35,861] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.0529772e-28 2.5025617e-33 3.4057603e-29 2.3617485e-29], sampled 0.8480985559048507
[2019-03-24 06:47:44,589] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 06:47:45,137] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 06:47:45,140] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 06:47:45,166] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 06:47:45,183] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 06:47:46,200] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1200000, evaluation results [1200000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 06:47:46,575] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 5.3281218e-18 3.2341482e-18 1.7435228e-16 1.2796198e-15], sum to 1.0000
[2019-03-24 06:47:46,584] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8297
[2019-03-24 06:47:46,590] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2099065.466397376 W.
[2019-03-24 06:47:46,590] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75000, global step 1200188: loss -6.0088
[2019-03-24 06:47:46,594] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75000, global step 1200188: learning rate 0.0000
[2019-03-24 06:47:46,596] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.9201343528257998, 1.0, 2.0, 0.9201343528257998, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2099065.466397376, 2099065.466397376, 395896.7874712676], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5227200.0000, 
sim time next is 5227800.0000, 
raw observation next is [28.33333333333334, 77.50000000000001, 1.0, 2.0, 0.9726325042632681, 1.0, 2.0, 0.9726325042632681, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2218976.203934018, 2218976.203934018, 420252.9182394596], 
processed observation next is [1.0, 0.5217391304347826, 0.6049382716049385, 0.7750000000000001, 1.0, 1.0, 0.967419647932462, 1.0, 1.0, 0.967419647932462, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.7924915014050065, 0.7924915014050065, 0.8081786889220377], 
reward next is 0.1918, 
noisyNet noise sample is [array([-0.34291926], dtype=float32), 0.48870462]. 
=============================================
[2019-03-24 06:47:46,886] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75000, global step 1200331: loss 35.0930
[2019-03-24 06:47:46,889] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75000, global step 1200332: learning rate 0.0000
[2019-03-24 06:47:46,948] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75000, global step 1200358: loss -24.6812
[2019-03-24 06:47:46,952] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75000, global step 1200359: learning rate 0.0000
[2019-03-24 06:47:47,066] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75000, global step 1200418: loss 49.0161
[2019-03-24 06:47:47,069] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75000, global step 1200419: learning rate 0.0000
[2019-03-24 06:47:47,094] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75000, global step 1200429: loss -32.5613
[2019-03-24 06:47:47,095] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75000, global step 1200430: learning rate 0.0000
[2019-03-24 06:47:47,169] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75000, global step 1200459: loss 115.9478
[2019-03-24 06:47:47,171] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75000, global step 1200459: learning rate 0.0000
[2019-03-24 06:47:47,449] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75000, global step 1200601: loss -10.4107
[2019-03-24 06:47:47,450] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75000, global step 1200601: learning rate 0.0000
[2019-03-24 06:47:47,460] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75000, global step 1200605: loss 84.9477
[2019-03-24 06:47:47,463] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75000, global step 1200607: learning rate 0.0000
[2019-03-24 06:47:47,601] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75000, global step 1200676: loss 21.3445
[2019-03-24 06:47:47,605] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75000, global step 1200677: learning rate 0.0000
[2019-03-24 06:47:47,614] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75000, global step 1200681: loss 71.3203
[2019-03-24 06:47:47,618] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75000, global step 1200681: learning rate 0.0000
[2019-03-24 06:47:48,152] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75000, global step 1200939: loss -44.6491
[2019-03-24 06:47:48,153] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75000, global step 1200939: learning rate 0.0000
[2019-03-24 06:47:48,238] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75000, global step 1200988: loss -47.2686
[2019-03-24 06:47:48,241] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75000, global step 1200988: learning rate 0.0000
[2019-03-24 06:47:48,816] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 6.0177524e-19 1.6074258e-19 3.6310801e-18 8.2802361e-17], sum to 1.0000
[2019-03-24 06:47:48,825] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2792
[2019-03-24 06:47:48,833] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1327662.180622915 W.
[2019-03-24 06:47:48,838] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.35, 84.83333333333334, 1.0, 2.0, 0.3881705708034123, 1.0, 1.0, 0.3881705708034123, 1.0, 2.0, 0.6179801905519512, 6.9112, 6.9112, 123.0399325686975, 1327662.180622915, 1327662.180622915, 292178.7979856544], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5278200.0000, 
sim time next is 5278800.0000, 
raw observation next is [25.3, 84.66666666666667, 1.0, 2.0, 0.3548652587118981, 1.0, 2.0, 0.3548652587118981, 1.0, 2.0, 0.5649570490239709, 6.9112, 6.9112, 121.94756008, 1213666.927291514, 1213666.927291514, 277875.5669539134], 
processed observation next is [1.0, 0.08695652173913043, 0.49259259259259264, 0.8466666666666667, 1.0, 1.0, 0.23198245084749775, 1.0, 1.0, 0.23198245084749775, 1.0, 1.0, 0.45619631127996363, 0.0, 0.0, 0.8096049824067558, 0.43345247403268355, 0.43345247403268355, 0.5343760902959873], 
reward next is 0.4656, 
noisyNet noise sample is [array([2.5957341], dtype=float32), 0.9184955]. 
=============================================
[2019-03-24 06:47:49,186] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75000, global step 1201443: loss 23.1219
[2019-03-24 06:47:49,187] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75000, global step 1201444: learning rate 0.0000
[2019-03-24 06:47:50,325] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.9041327e-17 4.9661852e-18 4.2321975e-17 1.3640200e-15], sum to 1.0000
[2019-03-24 06:47:50,330] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2013
[2019-03-24 06:47:50,334] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1212841.115089535 W.
[2019-03-24 06:47:50,338] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.63333333333334, 85.66666666666667, 1.0, 2.0, 0.5202638988201713, 1.0, 1.0, 0.5202638988201713, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1212841.115089535, 1212841.115089535, 242963.6814623962], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5305800.0000, 
sim time next is 5306400.0000, 
raw observation next is [23.8, 85.0, 1.0, 2.0, 0.3368717974314329, 1.0, 2.0, 0.3368717974314329, 1.0, 1.0, 0.5367900609852715, 6.9112, 6.9112, 121.94756008, 1164534.81213958, 1164534.81213958, 270580.5183052389], 
processed observation next is [1.0, 0.43478260869565216, 0.43703703703703706, 0.85, 1.0, 1.0, 0.2105616636088487, 1.0, 1.0, 0.2105616636088487, 1.0, 0.5, 0.42098757623158933, 0.0, 0.0, 0.8096049824067558, 0.41590529004985, 0.41590529004985, 0.5203471505869979], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.4728245], dtype=float32), 1.5039701]. 
=============================================
[2019-03-24 06:47:52,549] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75500, global step 1203071: loss 67.5508
[2019-03-24 06:47:52,553] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75500, global step 1203073: learning rate 0.0000
[2019-03-24 06:47:56,071] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75500, global step 1204885: loss 70.4033
[2019-03-24 06:47:56,073] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75500, global step 1204886: learning rate 0.0000
[2019-03-24 06:48:00,799] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 1.7458412e-21 5.2387219e-24 2.3180108e-23 5.5261956e-22], sum to 1.0000
[2019-03-24 06:48:00,807] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7840
[2019-03-24 06:48:00,815] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 731623.5754788135 W.
[2019-03-24 06:48:00,820] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.8, 81.0, 1.0, 2.0, 0.3209810296464475, 1.0, 1.0, 0.3209810296464475, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 731623.5754788135, 731623.575478814, 185572.1672156754], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5509800.0000, 
sim time next is 5510400.0000, 
raw observation next is [26.76666666666667, 81.0, 1.0, 2.0, 0.3205001300529368, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5102466450047993, 6.911199999999999, 6.9112, 121.9260426156618, 730526.9214723133, 730526.9214723138, 200835.8963293767], 
processed observation next is [1.0, 0.782608695652174, 0.5469135802469137, 0.81, 1.0, 1.0, 0.19107158339635336, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.3878083062559991, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26090247195439764, 0.2609024719543978, 0.38622287755649365], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1518496], dtype=float32), 0.41644153]. 
=============================================
[2019-03-24 06:48:01,733] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75500, global step 1207818: loss -5.6789
[2019-03-24 06:48:01,737] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75500, global step 1207818: learning rate 0.0000
[2019-03-24 06:48:02,461] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75500, global step 1208187: loss -9.1379
[2019-03-24 06:48:02,463] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75500, global step 1208188: learning rate 0.0000
[2019-03-24 06:48:02,730] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75500, global step 1208329: loss -2.6902
[2019-03-24 06:48:02,732] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75500, global step 1208329: learning rate 0.0000
[2019-03-24 06:48:02,740] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75500, global step 1208331: loss 54.6776
[2019-03-24 06:48:02,741] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75500, global step 1208331: learning rate 0.0000
[2019-03-24 06:48:02,907] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 2.8959613e-21 2.4583736e-26 6.3767713e-21 6.2405886e-21], sum to 1.0000
[2019-03-24 06:48:02,913] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4521
[2019-03-24 06:48:02,919] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 777855.562335317 W.
[2019-03-24 06:48:02,924] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.55, 92.5, 1.0, 2.0, 0.3412538387503946, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5432872251522572, 6.9112, 6.9112, 121.9260426156618, 777855.562335317, 777855.562335317, 206665.6581555788], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5535000.0000, 
sim time next is 5535600.0000, 
raw observation next is [25.53333333333333, 92.66666666666667, 1.0, 2.0, 0.2275229111623391, 1.0, 1.0, 0.2275229111623391, 1.0, 2.0, 0.3622238844743481, 6.9112, 6.9112, 121.94756008, 777925.113639201, 777925.113639201, 229796.4280866341], 
processed observation next is [1.0, 0.043478260869565216, 0.5012345679012346, 0.9266666666666667, 1.0, 1.0, 0.0803844180504037, 1.0, 0.5, 0.0803844180504037, 1.0, 1.0, 0.20277985559293513, 0.0, 0.0, 0.8096049824067558, 0.2778303977282861, 0.2778303977282861, 0.4419162078589118], 
reward next is 0.5581, 
noisyNet noise sample is [array([0.41168958], dtype=float32), 0.13801154]. 
=============================================
[2019-03-24 06:48:02,930] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75500, global step 1208426: loss -30.4254
[2019-03-24 06:48:02,931] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75500, global step 1208426: learning rate 0.0000
[2019-03-24 06:48:03,022] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75500, global step 1208483: loss 133.3586
[2019-03-24 06:48:03,025] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75500, global step 1208483: loss 6.2200
[2019-03-24 06:48:03,028] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75500, global step 1208483: learning rate 0.0000
[2019-03-24 06:48:03,028] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75500, global step 1208484: learning rate 0.0000
[2019-03-24 06:48:03,173] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75500, global step 1208554: loss 110.5199
[2019-03-24 06:48:03,174] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75500, global step 1208555: learning rate 0.0000
[2019-03-24 06:48:03,351] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75500, global step 1208642: loss -44.0409
[2019-03-24 06:48:03,353] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75500, global step 1208644: learning rate 0.0000
[2019-03-24 06:48:03,558] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75500, global step 1208741: loss 53.9889
[2019-03-24 06:48:03,560] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75500, global step 1208741: learning rate 0.0000
[2019-03-24 06:48:03,633] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75500, global step 1208787: loss 33.4949
[2019-03-24 06:48:03,635] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75500, global step 1208787: learning rate 0.0000
[2019-03-24 06:48:04,002] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75500, global step 1208975: loss 87.2936
[2019-03-24 06:48:04,003] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75500, global step 1208975: learning rate 0.0000
[2019-03-24 06:48:04,023] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75500, global step 1208980: loss 8.4409
[2019-03-24 06:48:04,024] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75500, global step 1208981: learning rate 0.0000
[2019-03-24 06:48:04,898] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75500, global step 1209432: loss -88.4608
[2019-03-24 06:48:04,900] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75500, global step 1209432: learning rate 0.0000
[2019-03-24 06:48:05,165] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 3.6988964e-27 2.0232174e-30 5.5092374e-27 3.6003334e-27], sum to 1.0000
[2019-03-24 06:48:05,170] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0224
[2019-03-24 06:48:05,175] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 2.7377657e-28 8.7018450e-32 2.1363006e-29 4.6031858e-30], sum to 1.0000
[2019-03-24 06:48:05,179] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1554787.103116031 W.
[2019-03-24 06:48:05,183] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8591
[2019-03-24 06:48:05,184] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.0, 91.0, 1.0, 2.0, 0.7367842404626269, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1554787.103116031, 1554787.103116032, 324016.7632575419], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5590800.0000, 
sim time next is 5591400.0000, 
raw observation next is [25.05, 91.00000000000001, 1.0, 2.0, 0.2489058864321484, 1.0, 1.0, 0.2489058864321484, 1.0, 2.0, 0.3962662774987711, 6.911199999999999, 6.9112, 121.94756008, 851076.3715989314, 851076.3715989318, 237237.8177442944], 
processed observation next is [1.0, 0.7391304347826086, 0.48333333333333334, 0.9100000000000001, 1.0, 1.0, 0.10584034099065284, 1.0, 0.5, 0.10584034099065284, 1.0, 1.0, 0.24533284687346382, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.30395584699961836, 0.30395584699961853, 0.45622657258518157], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3456273], dtype=float32), -1.348102]. 
=============================================
[2019-03-24 06:48:05,196] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 791597.6784731805 W.
[2019-03-24 06:48:05,202] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.75, 92.83333333333333, 1.0, 2.0, 0.694559091137551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 791597.6784731805, 791597.67847318, 175117.011462904], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5601000.0000, 
sim time next is 5601600.0000, 
raw observation next is [25.8, 93.0, 1.0, 2.0, 0.6988888184228149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 796534.8868371941, 796534.8868371941, 175934.4456327584], 
processed observation next is [1.0, 0.8695652173913043, 0.5111111111111112, 0.93, 1.0, 1.0, 0.6415343076462082, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2844767452989979, 0.2844767452989979, 0.3383354723706892], 
reward next is 0.6617, 
noisyNet noise sample is [array([0.69568056], dtype=float32), 0.89597505]. 
=============================================
[2019-03-24 06:48:07,325] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76000, global step 1210692: loss 2.6476
[2019-03-24 06:48:07,327] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76000, global step 1210693: learning rate 0.0000
[2019-03-24 06:48:10,951] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76000, global step 1212573: loss 4.5427
[2019-03-24 06:48:10,952] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76000, global step 1212574: learning rate 0.0000
[2019-03-24 06:48:13,121] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.2867759e-38 2.2604059e-37], sum to 1.0000
[2019-03-24 06:48:13,130] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0555
[2019-03-24 06:48:13,134] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.16666666666667, 79.33333333333333, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.80506902676641, 6.9112, 6.9112, 121.9260426156053, 601636.3926866006, 601636.3926866006, 156530.1075110474], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5971200.0000, 
sim time next is 5971800.0000, 
raw observation next is [22.08333333333334, 79.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7812486215716541, 6.911199999999999, 6.9112, 121.9260426156618, 583640.301452483, 583640.3014524835, 152927.9846236071], 
processed observation next is [1.0, 0.08695652173913043, 0.373456790123457, 0.7966666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7265607769645677, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20844296480445823, 0.2084429648044584, 0.29409227812232136], 
reward next is 0.7059, 
noisyNet noise sample is [array([0.20482181], dtype=float32), -0.073472984]. 
=============================================
[2019-03-24 06:48:17,340] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76000, global step 1215861: loss 3.0873
[2019-03-24 06:48:17,341] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76000, global step 1215861: learning rate 0.0000
[2019-03-24 06:48:18,085] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76000, global step 1216254: loss 4.1175
[2019-03-24 06:48:18,087] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76000, global step 1216255: learning rate 0.0000
[2019-03-24 06:48:18,169] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76000, global step 1216290: loss 1.0273
[2019-03-24 06:48:18,171] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76000, global step 1216292: learning rate 0.0000
[2019-03-24 06:48:18,381] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76000, global step 1216402: loss 2.6784
[2019-03-24 06:48:18,386] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76000, global step 1216402: learning rate 0.0000
[2019-03-24 06:48:18,410] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76000, global step 1216420: loss 1.2239
[2019-03-24 06:48:18,412] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76000, global step 1216420: learning rate 0.0000
[2019-03-24 06:48:18,415] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76000, global step 1216420: loss 3.9852
[2019-03-24 06:48:18,417] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76000, global step 1216420: learning rate 0.0000
[2019-03-24 06:48:18,752] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76000, global step 1216597: loss 1.7594
[2019-03-24 06:48:18,755] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76000, global step 1216597: learning rate 0.0000
[2019-03-24 06:48:18,789] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76000, global step 1216616: loss 0.6809
[2019-03-24 06:48:18,790] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76000, global step 1216616: learning rate 0.0000
[2019-03-24 06:48:18,923] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76000, global step 1216687: loss 1.4734
[2019-03-24 06:48:18,924] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76000, global step 1216687: learning rate 0.0000
[2019-03-24 06:48:19,085] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76000, global step 1216772: loss 4.2015
[2019-03-24 06:48:19,088] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76000, global step 1216772: learning rate 0.0000
[2019-03-24 06:48:19,124] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76000, global step 1216786: loss 2.3721
[2019-03-24 06:48:19,127] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76000, global step 1216787: learning rate 0.0000
[2019-03-24 06:48:19,387] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76000, global step 1216924: loss 0.0171
[2019-03-24 06:48:19,390] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76000, global step 1216924: learning rate 0.0000
[2019-03-24 06:48:19,666] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76000, global step 1217070: loss 1.2802
[2019-03-24 06:48:19,669] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76000, global step 1217071: learning rate 0.0000
[2019-03-24 06:48:20,782] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76000, global step 1217648: loss 2.7938
[2019-03-24 06:48:20,784] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76000, global step 1217648: learning rate 0.0000
[2019-03-24 06:48:21,282] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.7875067e-38 6.2196478e-37], sum to 1.0000
[2019-03-24 06:48:21,289] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0370
[2019-03-24 06:48:21,297] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1493050.713397617 W.
[2019-03-24 06:48:21,300] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.13333333333334, 47.5, 1.0, 2.0, 0.6322333716313894, 1.0, 2.0, 0.6322333716313894, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1493050.713397617, 1493050.713397618, 281687.0858192386], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5932200.0000, 
sim time next is 5932800.0000, 
raw observation next is [29.1, 48.0, 1.0, 2.0, 0.6180613943679764, 1.0, 2.0, 0.6180613943679764, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1458462.764521011, 1458462.764521011, 276580.6728596063], 
processed observation next is [1.0, 0.6956521739130435, 0.6333333333333334, 0.48, 1.0, 1.0, 0.5453111837714004, 1.0, 1.0, 0.5453111837714004, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5208795587575039, 0.5208795587575039, 0.5318859093453967], 
reward next is 0.4681, 
noisyNet noise sample is [array([-0.60594946], dtype=float32), 0.65740085]. 
=============================================
[2019-03-24 06:48:22,724] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76500, global step 1218654: loss 8.7257
[2019-03-24 06:48:22,726] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76500, global step 1218654: learning rate 0.0000
[2019-03-24 06:48:26,205] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:48:26,210] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4710
[2019-03-24 06:48:26,216] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.6, 83.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7447044524198121, 6.9112, 6.9112, 121.9260426156618, 555938.3395941854, 555938.3395941854, 151482.9901433606], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5962200.0000, 
sim time next is 5962800.0000, 
raw observation next is [22.6, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7407571311776342, 6.9112, 6.9112, 121.9260426156618, 553105.8715461107, 553105.8715461107, 150857.0749609627], 
processed observation next is [1.0, 0.0, 0.39259259259259266, 0.83, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6759464139720428, 0.0, 0.0, 0.8094621288201359, 0.1975378112664681, 0.1975378112664681, 0.2901097595403129], 
reward next is 0.7099, 
noisyNet noise sample is [array([-0.46060526], dtype=float32), -0.120097436]. 
=============================================
[2019-03-24 06:48:26,761] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76500, global step 1220754: loss 5.3944
[2019-03-24 06:48:26,764] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76500, global step 1220754: learning rate 0.0000
[2019-03-24 06:48:32,821] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:48:32,827] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7552
[2019-03-24 06:48:32,832] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.73333333333333, 68.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8679666239752695, 6.9112, 6.9112, 121.9260426156618, 638755.6873130946, 638755.6873130946, 170918.7310213436], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6124800.0000, 
sim time next is 6125400.0000, 
raw observation next is [26.65, 69.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8672323497423071, 6.911200000000001, 6.9112, 121.9260426156618, 638415.0841002644, 638415.0841002639, 170771.143843975], 
processed observation next is [1.0, 0.9130434782608695, 0.5425925925925925, 0.69, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8340404371778839, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22800538717866584, 0.22800538717866567, 0.32840604585379807], 
reward next is 0.6716, 
noisyNet noise sample is [array([1.3394626], dtype=float32), 0.19354284]. 
=============================================
[2019-03-24 06:48:32,860] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76500, global step 1223871: loss 7.2550
[2019-03-24 06:48:32,861] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76500, global step 1223871: learning rate 0.0000
[2019-03-24 06:48:33,208] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 4.9522260e-32 5.2184999e-38 2.0686904e-33 1.0760803e-32], sum to 1.0000
[2019-03-24 06:48:33,221] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3325
[2019-03-24 06:48:33,227] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.0, 85.66666666666667, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8956431051847003, 6.9112, 6.9112, 121.9260426156534, 660157.1489440978, 660157.1489440978, 174240.8465034158], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6162000.0000, 
sim time next is 6162600.0000, 
raw observation next is [24.1, 85.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9007062157624172, 6.911199999999999, 6.9112, 121.9260426156618, 663783.0012850572, 663783.0012850576, 174936.3922284457], 
processed observation next is [1.0, 0.30434782608695654, 0.4481481481481482, 0.8533333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8758827697030214, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23706535760180614, 0.2370653576018063, 0.33641613890085714], 
reward next is 0.6636, 
noisyNet noise sample is [array([-0.9210799], dtype=float32), -1.1755365]. 
=============================================
[2019-03-24 06:48:33,348] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76500, global step 1224122: loss 4.0740
[2019-03-24 06:48:33,351] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76500, global step 1224123: learning rate 0.0000
[2019-03-24 06:48:33,551] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76500, global step 1224224: loss 6.1229
[2019-03-24 06:48:33,553] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76500, global step 1224224: learning rate 0.0000
[2019-03-24 06:48:33,572] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76500, global step 1224236: loss 5.5959
[2019-03-24 06:48:33,574] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76500, global step 1224237: learning rate 0.0000
[2019-03-24 06:48:33,719] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76500, global step 1224311: loss 3.1983
[2019-03-24 06:48:33,720] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76500, global step 1224311: learning rate 0.0000
[2019-03-24 06:48:33,973] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76500, global step 1224442: loss 4.2194
[2019-03-24 06:48:33,975] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76500, global step 1224442: learning rate 0.0000
[2019-03-24 06:48:34,055] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76500, global step 1224482: loss 1.8534
[2019-03-24 06:48:34,057] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76500, global step 1224482: learning rate 0.0000
[2019-03-24 06:48:34,257] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76500, global step 1224592: loss 0.6533
[2019-03-24 06:48:34,258] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76500, global step 1224593: learning rate 0.0000
[2019-03-24 06:48:34,467] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76500, global step 1224698: loss 0.6228
[2019-03-24 06:48:34,470] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76500, global step 1224698: learning rate 0.0000
[2019-03-24 06:48:34,487] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 8.8784078e-34 0.0000000e+00 1.1690218e-35 1.2114941e-34], sum to 1.0000
[2019-03-24 06:48:34,494] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2531
[2019-03-24 06:48:34,498] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 781525.507356986 W.
[2019-03-24 06:48:34,502] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.35, 68.0, 1.0, 2.0, 0.34286306383725, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5458491638993332, 6.911199999999997, 6.9112, 121.9260426156618, 781525.507356986, 781525.5073569875, 207124.7166810193], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6381000.0000, 
sim time next is 6381600.0000, 
raw observation next is [29.23333333333333, 68.66666666666667, 1.0, 2.0, 0.3433825173585103, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5466761508225997, 6.9112, 6.9112, 121.9260426156618, 782710.1594711511, 782710.1594711511, 207273.1671431125], 
processed observation next is [0.0, 0.8695652173913043, 0.6382716049382715, 0.6866666666666668, 1.0, 1.0, 0.21831252066489318, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.43334518852824955, 0.0, 0.0, 0.8094621288201359, 0.27953934266826824, 0.27953934266826824, 0.3986022445059856], 
reward next is 0.6014, 
noisyNet noise sample is [array([-0.9648239], dtype=float32), -0.5761879]. 
=============================================
[2019-03-24 06:48:34,607] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76500, global step 1224769: loss 1.9675
[2019-03-24 06:48:34,611] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76500, global step 1224771: learning rate 0.0000
[2019-03-24 06:48:34,704] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76500, global step 1224817: loss 4.5446
[2019-03-24 06:48:34,705] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76500, global step 1224819: learning rate 0.0000
[2019-03-24 06:48:35,021] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76500, global step 1224976: loss 1.5312
[2019-03-24 06:48:35,022] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76500, global step 1224977: learning rate 0.0000
[2019-03-24 06:48:35,062] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-24 06:48:35,066] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:48:35,067] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:48:35,068] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:48:35,069] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:48:35,070] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:48:35,072] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:48:35,073] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:48:35,075] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:48:35,076] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:48:35,076] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:48:35,092] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run50
[2019-03-24 06:48:35,092] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run50
[2019-03-24 06:48:35,140] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run50
[2019-03-24 06:48:35,141] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run50
[2019-03-24 06:48:35,196] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run50
[2019-03-24 06:48:49,334] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00637793], dtype=float32), 0.015773997]
[2019-03-24 06:48:49,334] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.0, 50.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4578680207138723, 6.911199999999999, 6.9112, 121.9260426156618, 326915.789141236, 326915.7891412365, 105042.5383419186]
[2019-03-24 06:48:49,334] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:48:49,337] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 5.2911491e-36 0.0000000e+00 3.0672625e-36 6.0349158e-37], sampled 0.7659468421558292
[2019-03-24 06:48:57,622] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00637793], dtype=float32), 0.015773997]
[2019-03-24 06:48:57,623] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [19.57513178, 78.982934895, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5254647200038368, 6.911199999999999, 6.9112, 121.9260426156618, 385053.3900554655, 385053.390055466, 120830.0485053254]
[2019-03-24 06:48:57,626] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:48:57,628] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 3.6237701e-35 0.0000000e+00 2.2056213e-35 4.3107743e-36], sampled 0.6108335753816485
[2019-03-24 06:49:00,940] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00637793], dtype=float32), 0.015773997]
[2019-03-24 06:49:00,943] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [18.83333333333334, 93.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5901768972996705, 6.911200000000001, 6.9112, 121.9260426156618, 437069.6174632222, 437069.6174632217, 128804.5360760029]
[2019-03-24 06:49:00,944] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:49:00,947] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 2.8894551e-33 0.0000000e+00 1.7174661e-33 4.2208264e-34], sampled 0.3073664693663485
[2019-03-24 06:49:36,359] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00637793], dtype=float32), 0.015773997]
[2019-03-24 06:49:36,360] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.00049524666667, 92.52291745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7265884357799053, 6.911200000000001, 6.9112, 121.9260426156618, 542906.6193723602, 542906.6193723597, 148359.6251174652]
[2019-03-24 06:49:36,361] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:49:36,363] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.2728895e-33 0.0000000e+00 7.0441127e-34 1.7534049e-34], sampled 0.561131059118026
[2019-03-24 06:49:43,302] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00637793], dtype=float32), 0.015773997]
[2019-03-24 06:49:43,303] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [31.55397588166667, 81.39836576166667, 1.0, 2.0, 0.5238925108960542, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8340539393344387, 6.9112, 6.9112, 121.9258579251898, 1194487.45653943, 1194487.45653943, 265431.8991602878]
[2019-03-24 06:49:43,305] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:49:43,307] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 3.5819537e-32 5.7531553e-37 2.3619700e-32 1.9677567e-32], sampled 0.5772930720846765
[2019-03-24 06:49:43,308] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1194487.45653943 W.
[2019-03-24 06:49:59,636] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00637793], dtype=float32), 0.015773997]
[2019-03-24 06:49:59,636] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.0, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.789236067311456, 6.911200000000001, 6.9112, 121.9260426156618, 585521.0194221146, 585521.0194221142, 159317.9804952162]
[2019-03-24 06:49:59,638] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:49:59,640] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 5.6449663e-34 0.0000000e+00 3.1205162e-34 7.8816581e-35], sampled 0.755203772360999
[2019-03-24 06:50:21,350] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 06:50:21,588] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 06:50:21,709] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 06:50:21,762] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8363.4371 2339475986.9735 616.0000
[2019-03-24 06:50:21,768] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 06:50:22,784] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1225000, evaluation results [1225000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8363.437110714249, 2339475986.973477, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 06:50:22,862] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76500, global step 1225042: loss 0.7227
[2019-03-24 06:50:22,864] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76500, global step 1225042: learning rate 0.0000
[2019-03-24 06:50:23,894] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76500, global step 1225541: loss 9.2614
[2019-03-24 06:50:23,899] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76500, global step 1225541: learning rate 0.0000
[2019-03-24 06:50:25,198] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:50:25,207] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1936
[2019-03-24 06:50:25,211] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.36666666666667, 85.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8066857583688025, 6.9112, 6.9112, 121.9260426156618, 598730.6114999473, 598730.6114999473, 161377.8813092058], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6244800.0000, 
sim time next is 6245400.0000, 
raw observation next is [23.48333333333333, 85.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8107860521714009, 6.9112, 6.9112, 121.9260426156618, 601403.9546231019, 601403.9546231019, 162057.9887349125], 
processed observation next is [0.0, 0.2608695652173913, 0.42530864197530854, 0.8533333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.763482565214251, 0.0, 0.0, 0.8094621288201359, 0.2147871266511078, 0.2147871266511078, 0.3116499783363702], 
reward next is 0.6884, 
noisyNet noise sample is [array([0.09024602], dtype=float32), 1.5477127]. 
=============================================
[2019-03-24 06:50:26,612] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77000, global step 1226899: loss 556.2430
[2019-03-24 06:50:26,615] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77000, global step 1226899: learning rate 0.0000
[2019-03-24 06:50:27,318] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:50:27,325] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2055
[2019-03-24 06:50:27,334] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 788543.5247687678 W.
[2019-03-24 06:50:27,340] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.6, 78.0, 1.0, 2.0, 0.3459403554245441, 1.0, 2.0, 0.3459403554245441, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 788543.5247687678, 788543.5247687682, 191850.9515975296], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6390000.0000, 
sim time next is 6390600.0000, 
raw observation next is [27.5, 78.5, 1.0, 2.0, 0.345468932393374, 1.0, 2.0, 0.345468932393374, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 787468.4014750966, 787468.401475097, 191730.3470259131], 
processed observation next is [0.0, 1.0, 0.5740740740740741, 0.785, 1.0, 1.0, 0.22079634808735002, 1.0, 1.0, 0.22079634808735002, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2812387148125345, 0.28123871481253465, 0.36871220581906367], 
reward next is 0.6313, 
noisyNet noise sample is [array([0.7404851], dtype=float32), 0.4938178]. 
=============================================
[2019-03-24 06:50:29,253] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:50:29,262] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1540
[2019-03-24 06:50:29,265] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.23333333333333, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9152720715871605, 6.911200000000001, 6.9112, 121.9260426156618, 669811.7987088017, 669811.7987088013, 177991.982316871], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6316800.0000, 
sim time next is 6317400.0000, 
raw observation next is [24.21666666666667, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9144980422818305, 6.911199999999999, 6.9112, 121.9260426156618, 669411.5673849771, 669411.5673849776, 177854.0622528392], 
processed observation next is [0.0, 0.08695652173913043, 0.4524691358024692, 0.88, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8931225528522881, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23907555978034897, 0.23907555978034914, 0.34202704279392154], 
reward next is 0.6580, 
noisyNet noise sample is [array([1.0311692], dtype=float32), 0.4308351]. 
=============================================
[2019-03-24 06:50:30,799] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77000, global step 1228998: loss 667.1796
[2019-03-24 06:50:30,802] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77000, global step 1228998: learning rate 0.0000
[2019-03-24 06:50:32,150] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 5.4018562e-34 6.4678265e-38 1.2531975e-34 5.6170177e-35], sum to 1.0000
[2019-03-24 06:50:32,155] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8900
[2019-03-24 06:50:32,161] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 788662.6118234021 W.
[2019-03-24 06:50:32,166] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.03333333333333, 70.66666666666667, 1.0, 2.0, 0.6919851460089722, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 788662.6118234021, 788662.6118234021, 174632.2713847552], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6345600.0000, 
sim time next is 6346200.0000, 
raw observation next is [29.26666666666667, 69.83333333333333, 1.0, 2.0, 0.3479414490402192, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5539341185339197, 6.911199999999999, 6.9112, 121.9260426156618, 793107.2183739879, 793107.2183739883, 208581.3413019316], 
processed observation next is [0.0, 0.43478260869565216, 0.6395061728395063, 0.6983333333333333, 1.0, 1.0, 0.22373982028597522, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.4424176481673996, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.28325257799070996, 0.28325257799071013, 0.40111796404217614], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3643715], dtype=float32), 1.1439962]. 
=============================================
[2019-03-24 06:50:33,262] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 6.3407772e-35 0.0000000e+00 8.9953306e-36 3.1282466e-37], sum to 1.0000
[2019-03-24 06:50:33,268] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5807
[2019-03-24 06:50:33,272] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 784080.3562267534 W.
[2019-03-24 06:50:33,277] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.83333333333333, 65.33333333333333, 1.0, 2.0, 0.229322239772233, 1.0, 2.0, 0.229322239772233, 1.0, 1.0, 0.365088474221341, 6.9112, 6.9112, 121.94756008, 784080.3562267534, 784080.3562267534, 230412.7558088277], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6378600.0000, 
sim time next is 6379200.0000, 
raw observation next is [29.7, 66.0, 1.0, 2.0, 0.2291523536914866, 1.0, 2.0, 0.2291523536914866, 1.0, 2.0, 0.3648180100479893, 6.9112, 6.9112, 121.94756008, 783499.1984354302, 783499.1984354302, 230354.4869902833], 
processed observation next is [0.0, 0.8695652173913043, 0.6555555555555556, 0.66, 1.0, 1.0, 0.08232423058510309, 1.0, 1.0, 0.08232423058510309, 1.0, 1.0, 0.2060225125599866, 0.0, 0.0, 0.8096049824067558, 0.2798211422983679, 0.2798211422983679, 0.4429893980582371], 
reward next is 0.5570, 
noisyNet noise sample is [array([1.0710411], dtype=float32), 1.6124268]. 
=============================================
[2019-03-24 06:50:36,329] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77000, global step 1231842: loss 373.9481
[2019-03-24 06:50:36,332] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77000, global step 1231842: learning rate 0.0000
[2019-03-24 06:50:36,692] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77000, global step 1232035: loss 457.9243
[2019-03-24 06:50:36,694] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77000, global step 1232035: learning rate 0.0000
[2019-03-24 06:50:37,093] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77000, global step 1232241: loss 466.7596
[2019-03-24 06:50:37,096] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77000, global step 1232241: learning rate 0.0000
[2019-03-24 06:50:37,280] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77000, global step 1232338: loss 527.2753
[2019-03-24 06:50:37,283] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77000, global step 1232338: learning rate 0.0000
[2019-03-24 06:50:37,309] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77000, global step 1232357: loss 493.6332
[2019-03-24 06:50:37,310] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77000, global step 1232357: learning rate 0.0000
[2019-03-24 06:50:37,382] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77000, global step 1232393: loss 579.9282
[2019-03-24 06:50:37,384] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77000, global step 1232393: learning rate 0.0000
[2019-03-24 06:50:37,503] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77000, global step 1232454: loss 536.6938
[2019-03-24 06:50:37,504] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77000, global step 1232454: learning rate 0.0000
[2019-03-24 06:50:37,573] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77000, global step 1232491: loss 594.7755
[2019-03-24 06:50:37,577] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77000, global step 1232491: learning rate 0.0000
[2019-03-24 06:50:37,823] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77000, global step 1232621: loss 564.4499
[2019-03-24 06:50:37,826] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77000, global step 1232621: learning rate 0.0000
[2019-03-24 06:50:38,142] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77000, global step 1232782: loss 502.6666
[2019-03-24 06:50:38,148] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77000, global step 1232785: learning rate 0.0000
[2019-03-24 06:50:38,350] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77000, global step 1232892: loss 428.9309
[2019-03-24 06:50:38,352] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77000, global step 1232892: learning rate 0.0000
[2019-03-24 06:50:38,452] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77000, global step 1232942: loss 483.3817
[2019-03-24 06:50:38,455] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77000, global step 1232942: learning rate 0.0000
[2019-03-24 06:50:38,694] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77000, global step 1233066: loss 565.6266
[2019-03-24 06:50:38,697] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77000, global step 1233067: learning rate 0.0000
[2019-03-24 06:50:39,715] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77000, global step 1233598: loss 339.9262
[2019-03-24 06:50:39,716] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77000, global step 1233599: learning rate 0.0000
[2019-03-24 06:50:39,991] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 3.2861797e-19 1.8440100e-22 1.6463791e-20 2.0569801e-19], sum to 1.0000
[2019-03-24 06:50:40,001] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0290
[2019-03-24 06:50:40,005] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1469917.480118571 W.
[2019-03-24 06:50:40,009] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.9, 80.0, 1.0, 2.0, 0.6445780832220888, 1.0, 2.0, 0.6445780832220888, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1469917.480118571, 1469917.480118571, 283717.3694642137], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6525000.0000, 
sim time next is 6525600.0000, 
raw observation next is [27.8, 80.0, 1.0, 2.0, 0.674933078268078, 1.0, 2.0, 0.674933078268078, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1539209.597729427, 1539209.597729427, 294785.2400146329], 
processed observation next is [1.0, 0.5217391304347826, 0.5851851851851853, 0.8, 1.0, 1.0, 0.6130155693667595, 1.0, 1.0, 0.6130155693667595, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5497177134747954, 0.5497177134747954, 0.5668946923358325], 
reward next is 0.4331, 
noisyNet noise sample is [array([0.5804503], dtype=float32), -1.6733567]. 
=============================================
[2019-03-24 06:50:41,745] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77500, global step 1234650: loss 0.9452
[2019-03-24 06:50:41,752] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77500, global step 1234652: learning rate 0.0000
[2019-03-24 06:50:44,284] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:50:44,291] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2183
[2019-03-24 06:50:44,295] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.93333333333334, 68.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8250102641554168, 6.9112, 6.9112, 121.9260426156618, 611491.1949608648, 611491.1949608648, 164044.0009800164], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6567600.0000, 
sim time next is 6568200.0000, 
raw observation next is [25.9, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8028584814773897, 6.9112, 6.9112, 121.9260426156618, 596544.0380716089, 596544.0380716089, 160581.7608447371], 
processed observation next is [1.0, 0.0, 0.5148148148148147, 0.67, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.753573101846737, 0.0, 0.0, 0.8094621288201359, 0.21305144216843175, 0.21305144216843175, 0.30881107854757134], 
reward next is 0.6912, 
noisyNet noise sample is [array([2.0733864], dtype=float32), -0.51607126]. 
=============================================
[2019-03-24 06:50:45,878] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77500, global step 1236829: loss 0.1611
[2019-03-24 06:50:45,879] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77500, global step 1236829: learning rate 0.0000
[2019-03-24 06:50:46,597] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:50:46,603] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2957
[2019-03-24 06:50:46,608] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.16666666666666, 56.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6298002917745948, 6.9112, 6.9112, 121.9260426156618, 469456.1042201903, 469456.1042201903, 134915.8477074954], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6637200.0000, 
sim time next is 6637800.0000, 
raw observation next is [24.88333333333334, 58.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6393021395243887, 6.911199999999999, 6.9112, 121.9260426156618, 476779.2690698266, 476779.269069827, 136137.2758961895], 
processed observation next is [1.0, 0.8260869565217391, 0.47716049382716075, 0.5883333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5491276744054859, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1702783103820809, 0.17027831038208108, 0.2618024536465183], 
reward next is 0.7382, 
noisyNet noise sample is [array([-0.48134884], dtype=float32), -0.0183404]. 
=============================================
[2019-03-24 06:50:51,684] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77500, global step 1239883: loss 0.0522
[2019-03-24 06:50:51,688] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77500, global step 1239883: learning rate 0.0000
[2019-03-24 06:50:51,858] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77500, global step 1239980: loss 0.0367
[2019-03-24 06:50:51,862] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77500, global step 1239980: learning rate 0.0000
[2019-03-24 06:50:52,302] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77500, global step 1240245: loss 0.0681
[2019-03-24 06:50:52,309] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77500, global step 1240246: learning rate 0.0000
[2019-03-24 06:50:52,324] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77500, global step 1240254: loss 0.0571
[2019-03-24 06:50:52,328] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77500, global step 1240256: learning rate 0.0000
[2019-03-24 06:50:52,358] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.1616830e-34 0.0000000e+00 1.5824869e-34 3.0074018e-33], sum to 1.0000
[2019-03-24 06:50:52,362] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8864
[2019-03-24 06:50:52,368] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 700956.751567791 W.
[2019-03-24 06:50:52,378] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.95, 30.66666666666667, 1.0, 2.0, 0.2778157082612805, 0.0, 2.0, 0.0, 1.0, 1.0, 0.4734654920179357, 6.9112, 6.9112, 121.9260426156618, 700956.751567791, 700956.751567791, 184527.4103971747], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6700200.0000, 
sim time next is 6700800.0000, 
raw observation next is [29.1, 30.33333333333334, 1.0, 2.0, 0.7195926348763749, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 911614.2323371973, 911614.2323371973, 183079.4124837706], 
processed observation next is [1.0, 0.5652173913043478, 0.6333333333333334, 0.3033333333333334, 1.0, 1.0, 0.6661817081861606, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.325576511548999, 0.325576511548999, 0.3520757932380204], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.40122133], dtype=float32), -1.9140605]. 
=============================================
[2019-03-24 06:50:52,378] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77500, global step 1240282: loss 0.0635
[2019-03-24 06:50:52,381] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77500, global step 1240283: learning rate 0.0000
[2019-03-24 06:50:52,455] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77500, global step 1240335: loss 0.0377
[2019-03-24 06:50:52,456] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77500, global step 1240335: loss 0.0268
[2019-03-24 06:50:52,456] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77500, global step 1240335: learning rate 0.0000
[2019-03-24 06:50:52,457] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77500, global step 1240335: learning rate 0.0000
[2019-03-24 06:50:52,532] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77500, global step 1240374: loss 0.0213
[2019-03-24 06:50:52,534] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77500, global step 1240374: learning rate 0.0000
[2019-03-24 06:50:53,084] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77500, global step 1240684: loss 0.0085
[2019-03-24 06:50:53,086] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77500, global step 1240684: learning rate 0.0000
[2019-03-24 06:50:53,185] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77500, global step 1240747: loss 0.0116
[2019-03-24 06:50:53,191] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77500, global step 1240748: learning rate 0.0000
[2019-03-24 06:50:53,774] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77500, global step 1241041: loss 0.0395
[2019-03-24 06:50:53,776] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77500, global step 1241041: learning rate 0.0000
[2019-03-24 06:50:54,005] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77500, global step 1241165: loss 0.0122
[2019-03-24 06:50:54,006] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77500, global step 1241166: learning rate 0.0000
[2019-03-24 06:50:54,018] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77500, global step 1241169: loss 0.0109
[2019-03-24 06:50:54,020] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77500, global step 1241169: learning rate 0.0000
[2019-03-24 06:50:55,038] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77500, global step 1241701: loss 0.0133
[2019-03-24 06:50:55,043] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77500, global step 1241701: learning rate 0.0000
[2019-03-24 06:50:56,620] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78000, global step 1242523: loss -61.0794
[2019-03-24 06:50:56,622] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78000, global step 1242524: learning rate 0.0000
[2019-03-24 06:50:58,590] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:50:58,596] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5457
[2019-03-24 06:50:58,599] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.2, 49.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8315420349400252, 6.9112, 6.9112, 121.9260426156618, 614544.7856228406, 614544.7856228406, 165512.8615310591], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6879600.0000, 
sim time next is 6880200.0000, 
raw observation next is [30.06666666666667, 49.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8277214558856114, 6.9112, 6.9112, 121.9260426156618, 612110.7241705005, 612110.7241705005, 164903.9959278897], 
processed observation next is [0.0, 0.6521739130434783, 0.669135802469136, 0.4933333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7846518198570143, 0.0, 0.0, 0.8094621288201359, 0.2186109729180359, 0.2186109729180359, 0.31712306909209553], 
reward next is 0.6829, 
noisyNet noise sample is [array([1.0623635], dtype=float32), -0.76911956]. 
=============================================
[2019-03-24 06:51:00,697] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:51:00,703] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5929
[2019-03-24 06:51:00,708] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1717745.994909782 W.
[2019-03-24 06:51:00,714] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.46666666666667, 66.33333333333334, 1.0, 2.0, 0.5004241045783914, 1.0, 2.0, 0.5004241045783914, 1.0, 1.0, 0.7968361158035652, 6.9112, 6.9112, 121.94756008, 1717745.994909782, 1717745.994909782, 343837.9544425349], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7053600.0000, 
sim time next is 7054200.0000, 
raw observation next is [26.2, 67.5, 1.0, 2.0, 0.8941394170184911, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9800198623156355, 6.911199999999999, 6.9112, 121.9260426156618, 1755507.369907364, 1755507.369907364, 352763.0055634184], 
processed observation next is [1.0, 0.6521739130434783, 0.5259259259259259, 0.675, 1.0, 1.0, 0.8739754964505846, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9750248278945445, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6269669178240586, 0.6269669178240586, 0.6783903953142661], 
reward next is 0.3216, 
noisyNet noise sample is [array([1.0675378], dtype=float32), -0.4164595]. 
=============================================
[2019-03-24 06:51:00,817] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78000, global step 1244708: loss -52.8082
[2019-03-24 06:51:00,819] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78000, global step 1244708: learning rate 0.0000
[2019-03-24 06:51:02,994] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:51:03,001] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8396
[2019-03-24 06:51:03,008] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.0, 50.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8972629680110097, 6.911200000000001, 6.9112, 121.9260426156618, 656211.5062457508, 656211.5062457504, 175672.0839729015], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6963600.0000, 
sim time next is 6964200.0000, 
raw observation next is [31.0, 50.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9017887392625364, 6.911200000000001, 6.9112, 121.9260426156618, 658506.7368153916, 658506.7368153911, 176468.3544146372], 
processed observation next is [0.0, 0.6086956521739131, 0.7037037037037037, 0.505, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8772359240781704, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2351809774340684, 0.23518097743406827, 0.3393622200281485], 
reward next is 0.6606, 
noisyNet noise sample is [array([-0.04690604], dtype=float32), -0.26823488]. 
=============================================
[2019-03-24 06:51:07,366] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78000, global step 1248111: loss 98.6489
[2019-03-24 06:51:07,367] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78000, global step 1248111: loss 110.6472
[2019-03-24 06:51:07,370] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78000, global step 1248112: learning rate 0.0000
[2019-03-24 06:51:07,374] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78000, global step 1248113: learning rate 0.0000
[2019-03-24 06:51:07,612] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78000, global step 1248234: loss -80.1915
[2019-03-24 06:51:07,614] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78000, global step 1248237: learning rate 0.0000
[2019-03-24 06:51:07,655] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78000, global step 1248260: loss -36.4781
[2019-03-24 06:51:07,658] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78000, global step 1248260: learning rate 0.0000
[2019-03-24 06:51:07,777] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78000, global step 1248324: loss 70.6941
[2019-03-24 06:51:07,780] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78000, global step 1248325: learning rate 0.0000
[2019-03-24 06:51:07,887] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78000, global step 1248378: loss 23.3846
[2019-03-24 06:51:07,892] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78000, global step 1248378: learning rate 0.0000
[2019-03-24 06:51:07,913] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78000, global step 1248393: loss 89.8292
[2019-03-24 06:51:07,915] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78000, global step 1248393: learning rate 0.0000
[2019-03-24 06:51:08,018] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78000, global step 1248443: loss 140.5471
[2019-03-24 06:51:08,020] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78000, global step 1248444: learning rate 0.0000
[2019-03-24 06:51:08,506] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78000, global step 1248695: loss 109.1630
[2019-03-24 06:51:08,507] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78000, global step 1248695: learning rate 0.0000
[2019-03-24 06:51:08,605] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78000, global step 1248747: loss 72.9748
[2019-03-24 06:51:08,606] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78000, global step 1248747: learning rate 0.0000
[2019-03-24 06:51:09,080] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78000, global step 1248994: loss 1.2829
[2019-03-24 06:51:09,082] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78000, global step 1248994: learning rate 0.0000
[2019-03-24 06:51:09,352] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78000, global step 1249136: loss 65.1428
[2019-03-24 06:51:09,356] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78000, global step 1249136: learning rate 0.0000
[2019-03-24 06:51:09,522] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78000, global step 1249223: loss 109.3576
[2019-03-24 06:51:09,524] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78000, global step 1249224: learning rate 0.0000
[2019-03-24 06:51:10,777] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78000, global step 1249870: loss 111.1438
[2019-03-24 06:51:10,784] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78000, global step 1249870: learning rate 0.0000
[2019-03-24 06:51:11,022] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-24 06:51:11,024] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:51:11,025] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:51:11,026] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:51:11,030] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:51:11,030] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:51:11,034] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:51:11,037] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:51:11,036] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:51:11,032] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:51:11,038] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:51:11,060] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run51
[2019-03-24 06:51:11,061] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run51
[2019-03-24 06:51:11,110] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run51
[2019-03-24 06:51:11,111] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run51
[2019-03-24 06:51:11,170] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run51
[2019-03-24 06:51:36,036] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00684692], dtype=float32), 0.016060643]
[2019-03-24 06:51:36,037] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.23333333333333, 87.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7266108956167587, 6.9112, 6.9112, 121.9260426156618, 542956.6012725604, 542956.6012725604, 147291.8334675327]
[2019-03-24 06:51:36,039] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:51:36,040] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.35903116892504494
[2019-03-24 06:52:15,265] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00684692], dtype=float32), 0.016060643]
[2019-03-24 06:52:15,267] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.1, 65.5, 1.0, 2.0, 0.6851519831807749, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.925323683636, 1495854.382220768, 1495854.382220768, 314554.0564329664]
[2019-03-24 06:52:15,270] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:52:15,273] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.8993960986356272
[2019-03-24 06:52:15,274] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1495854.382220768 W.
[2019-03-24 06:52:16,562] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00684692], dtype=float32), 0.016060643]
[2019-03-24 06:52:16,562] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.08364660666667, 87.60959072666667, 1.0, 2.0, 0.8566935848072684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260355100152, 976502.1107000484, 976502.1107000489, 207928.7170243329]
[2019-03-24 06:52:16,564] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:52:16,568] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.6521522e-38 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.9712500352274578
[2019-03-24 06:52:16,569] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 976502.1107000484 W.
[2019-03-24 06:52:17,474] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00684692], dtype=float32), 0.016060643]
[2019-03-24 06:52:17,476] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.943823881003254, 6.9112, 6.9112, 121.9260426156618, 684759.2467797921, 684759.2467797921, 182889.917024346]
[2019-03-24 06:52:17,477] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:52:17,480] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.9686204379689349
[2019-03-24 06:52:37,311] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00684692], dtype=float32), 0.016060643]
[2019-03-24 06:52:37,313] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.91666666666666, 92.0, 1.0, 2.0, 0.7844265294543509, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 894080.4617347716, 894080.4617347725, 192737.5988280916]
[2019-03-24 06:52:37,314] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:52:37,316] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.7444741443914717
[2019-03-24 06:52:37,318] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 894080.4617347716 W.
[2019-03-24 06:52:45,426] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00684692], dtype=float32), 0.016060643]
[2019-03-24 06:52:45,427] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.66666666666667, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8155645290540094, 6.9112, 6.9112, 121.9260426156618, 603189.255828699, 603189.255828699, 163339.0865623901]
[2019-03-24 06:52:45,430] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:52:45,431] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.3618979832971847
[2019-03-24 06:52:58,129] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 06:52:58,547] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 06:52:58,657] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 06:52:58,816] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 06:52:58,962] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.2390 2292980111.6144 697.0000
[2019-03-24 06:52:59,979] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1250000, evaluation results [1250000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.238967854026, 2292980111.6144123, 697.0]
[2019-03-24 06:53:01,017] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78500, global step 1250508: loss 0.2052
[2019-03-24 06:53:01,023] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78500, global step 1250508: learning rate 0.0000
[2019-03-24 06:53:01,043] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:53:01,049] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0634
[2019-03-24 06:53:01,052] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.88333333333333, 84.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7011253442141187, 6.9112, 6.9112, 121.9260426156618, 522861.8092177322, 522861.8092177322, 142486.500246925], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7107000.0000, 
sim time next is 7107600.0000, 
raw observation next is [20.86666666666667, 84.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6899462489516905, 6.911199999999999, 6.9112, 121.9260426156618, 514432.6439959545, 514432.6439959549, 141201.181909327], 
processed observation next is [1.0, 0.2608695652173913, 0.3283950617283952, 0.8466666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6124328111896131, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18372594428426944, 0.1837259442842696, 0.27154073444101345], 
reward next is 0.7285, 
noisyNet noise sample is [array([-1.1231399], dtype=float32), -0.6854086]. 
=============================================
[2019-03-24 06:53:02,618] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:53:02,624] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0290
[2019-03-24 06:53:02,635] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.81666666666667, 88.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6163487873128172, 6.911199999999999, 6.9112, 121.9260426156618, 457971.09730721, 457971.0973072104, 132288.6048809834], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7163400.0000, 
sim time next is 7164000.0000, 
raw observation next is [19.8, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6201728884834109, 6.9112, 6.9112, 121.9260426156618, 460826.0895088419, 460826.0895088419, 132667.117227084], 
processed observation next is [1.0, 0.9565217391304348, 0.2888888888888889, 0.89, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5252161106042635, 0.0, 0.0, 0.8094621288201359, 0.16458074625315783, 0.16458074625315783, 0.25512907159054615], 
reward next is 0.7449, 
noisyNet noise sample is [array([-0.43994114], dtype=float32), 1.8225007]. 
=============================================
[2019-03-24 06:53:02,660] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[73.67495 ]
 [73.688835]
 [73.66938 ]
 [73.62945 ]
 [73.54696 ]], R is [[73.74916077]
 [73.75727081]
 [73.76600647]
 [73.77467346]
 [73.78331757]].
[2019-03-24 06:53:03,210] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:53:03,217] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5728
[2019-03-24 06:53:03,224] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.8, 92.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6296302508296938, 6.911199999999999, 6.9112, 121.9260426156618, 469153.8831494225, 469153.8831494229, 134713.7555283928], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7174200.0000, 
sim time next is 7174800.0000, 
raw observation next is [19.8, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6347453457359217, 6.911200000000001, 6.9112, 121.9260426156618, 473066.5438075097, 473066.5438075092, 135326.2480055177], 
processed observation next is [1.0, 0.043478260869565216, 0.2888888888888889, 0.93, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.543431682169902, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16895233707411061, 0.16895233707411042, 0.2602427846259956], 
reward next is 0.7398, 
noisyNet noise sample is [array([0.06119544], dtype=float32), 0.64318335]. 
=============================================
[2019-03-24 06:53:05,594] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78500, global step 1252694: loss 0.5547
[2019-03-24 06:53:05,595] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78500, global step 1252694: learning rate 0.0000
[2019-03-24 06:53:05,995] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:53:06,003] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3040
[2019-03-24 06:53:06,007] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.53333333333333, 71.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6827548979876434, 6.911199999999999, 6.9112, 121.9260426156618, 510172.9771919238, 510172.9771919243, 142486.8156641396], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7234800.0000, 
sim time next is 7235400.0000, 
raw observation next is [23.46666666666667, 71.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6848158190862973, 6.9112, 6.9112, 121.9260426156618, 511706.453580138, 511706.453580138, 142670.3014122856], 
processed observation next is [1.0, 0.7391304347826086, 0.42469135802469143, 0.7166666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6060197738578715, 0.0, 0.0, 0.8094621288201359, 0.18275230485004929, 0.18275230485004929, 0.27436596425439536], 
reward next is 0.7256, 
noisyNet noise sample is [array([0.83446354], dtype=float32), -0.29971093]. 
=============================================
[2019-03-24 06:53:12,167] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78500, global step 1256069: loss 0.2320
[2019-03-24 06:53:12,169] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78500, global step 1256071: learning rate 0.0000
[2019-03-24 06:53:12,246] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78500, global step 1256111: loss 0.3098
[2019-03-24 06:53:12,248] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78500, global step 1256111: learning rate 0.0000
[2019-03-24 06:53:12,268] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78500, global step 1256122: loss 0.3766
[2019-03-24 06:53:12,274] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78500, global step 1256129: learning rate 0.0000
[2019-03-24 06:53:12,598] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78500, global step 1256295: loss 0.0416
[2019-03-24 06:53:12,600] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78500, global step 1256297: learning rate 0.0000
[2019-03-24 06:53:12,692] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78500, global step 1256335: loss 0.0161
[2019-03-24 06:53:12,696] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78500, global step 1256336: learning rate 0.0000
[2019-03-24 06:53:12,762] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78500, global step 1256378: loss 0.0437
[2019-03-24 06:53:12,764] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78500, global step 1256379: learning rate 0.0000
[2019-03-24 06:53:12,797] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78500, global step 1256396: loss 0.0336
[2019-03-24 06:53:12,802] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78500, global step 1256396: learning rate 0.0000
[2019-03-24 06:53:12,944] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78500, global step 1256470: loss 0.0048
[2019-03-24 06:53:12,948] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78500, global step 1256470: learning rate 0.0000
[2019-03-24 06:53:13,024] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:53:13,036] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9886
[2019-03-24 06:53:13,041] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.7, 74.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7264827995607799, 6.911199999999999, 6.9112, 121.9260426156618, 542597.4564559354, 542597.4564559358, 148953.6481641592], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7330800.0000, 
sim time next is 7331400.0000, 
raw observation next is [23.55, 75.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.727527473404245, 6.9112, 6.9112, 121.9260426156618, 543408.8420226715, 543408.8420226715, 149011.173834173], 
processed observation next is [1.0, 0.8695652173913043, 0.4277777777777778, 0.755, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6594093417553062, 0.0, 0.0, 0.8094621288201359, 0.1940745864366684, 0.1940745864366684, 0.28655994968110193], 
reward next is 0.7134, 
noisyNet noise sample is [array([-0.7206052], dtype=float32), -1.2405211]. 
=============================================
[2019-03-24 06:53:13,301] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78500, global step 1256656: loss 0.0067
[2019-03-24 06:53:13,302] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78500, global step 1256656: learning rate 0.0000
[2019-03-24 06:53:13,395] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78500, global step 1256699: loss 0.0064
[2019-03-24 06:53:13,398] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78500, global step 1256702: learning rate 0.0000
[2019-03-24 06:53:13,977] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78500, global step 1257009: loss 0.0164
[2019-03-24 06:53:13,979] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78500, global step 1257009: learning rate 0.0000
[2019-03-24 06:53:14,232] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78500, global step 1257135: loss 0.1081
[2019-03-24 06:53:14,234] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78500, global step 1257135: learning rate 0.0000
[2019-03-24 06:53:14,277] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78500, global step 1257161: loss 0.0649
[2019-03-24 06:53:14,280] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78500, global step 1257161: learning rate 0.0000
[2019-03-24 06:53:14,342] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:53:14,352] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1922
[2019-03-24 06:53:14,358] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.05, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6917344213868004, 6.9112, 6.9112, 121.9260426156618, 515263.7902115753, 515263.7902115753, 140863.1019118412], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7356600.0000, 
sim time next is 7357200.0000, 
raw observation next is [20.0, 90.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6619121675940672, 6.911199999999999, 6.9112, 121.9260426156618, 493126.4158031865, 493126.4158031869, 137870.9477440291], 
processed observation next is [1.0, 0.13043478260869565, 0.2962962962962963, 0.9066666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.577390209492584, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1761165770725666, 0.17611657707256675, 0.26513643796928676], 
reward next is 0.7349, 
noisyNet noise sample is [array([1.6648884], dtype=float32), 0.28436846]. 
=============================================
[2019-03-24 06:53:14,612] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:53:14,619] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4444
[2019-03-24 06:53:14,625] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.1, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7004279678047477, 6.9112, 6.9112, 121.9260426156618, 523420.2866390918, 523420.2866390918, 144714.3886772353], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7336800.0000, 
sim time next is 7337400.0000, 
raw observation next is [21.95, 82.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6963090050163885, 6.9112, 6.9112, 121.9260426156618, 520330.4211667239, 520330.4211667239, 144132.1880427996], 
processed observation next is [1.0, 0.9565217391304348, 0.36851851851851847, 0.8283333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6203862562704856, 0.0, 0.0, 0.8094621288201359, 0.18583229327382997, 0.18583229327382997, 0.27717728469769154], 
reward next is 0.7228, 
noisyNet noise sample is [array([-0.38777375], dtype=float32), 0.7487207]. 
=============================================
[2019-03-24 06:53:15,562] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78500, global step 1257820: loss 0.0303
[2019-03-24 06:53:15,564] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78500, global step 1257820: learning rate 0.0000
[2019-03-24 06:53:16,700] A3C_AGENT_WORKER-Thread-12 INFO:Local step 79000, global step 1258416: loss -136.7443
[2019-03-24 06:53:16,701] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 79000, global step 1258416: learning rate 0.0000
[2019-03-24 06:53:20,901] A3C_AGENT_WORKER-Thread-21 INFO:Local step 79000, global step 1260619: loss -120.9339
[2019-03-24 06:53:20,903] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 79000, global step 1260619: learning rate 0.0000
[2019-03-24 06:53:27,618] A3C_AGENT_WORKER-Thread-17 INFO:Local step 79000, global step 1264131: loss -4.4929
[2019-03-24 06:53:27,623] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 79000, global step 1264131: learning rate 0.0000
[2019-03-24 06:53:27,679] A3C_AGENT_WORKER-Thread-22 INFO:Local step 79000, global step 1264163: loss -131.6721
[2019-03-24 06:53:27,681] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 79000, global step 1264163: learning rate 0.0000
[2019-03-24 06:53:27,768] A3C_AGENT_WORKER-Thread-15 INFO:Local step 79000, global step 1264209: loss -42.3788
[2019-03-24 06:53:27,771] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 79000, global step 1264209: learning rate 0.0000
[2019-03-24 06:53:27,877] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:53:27,885] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2738
[2019-03-24 06:53:27,894] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1675703.424870695 W.
[2019-03-24 06:53:27,898] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.85, 67.0, 1.0, 2.0, 0.7304724945559998, 1.0, 1.0, 0.7304724945559998, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.925170011102, 1675703.424870695, 1675703.424870695, 316363.6110807478], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7651800.0000, 
sim time next is 7652400.0000, 
raw observation next is [26.93333333333334, 66.33333333333333, 1.0, 2.0, 0.6349932353706662, 1.0, 2.0, 0.6349932353706662, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.92604234957, 1462220.055392402, 1462220.055392402, 280991.3416583287], 
processed observation next is [1.0, 0.5652173913043478, 0.5530864197530867, 0.6633333333333333, 1.0, 1.0, 0.5654681373460312, 1.0, 1.0, 0.5654681373460312, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621270535631, 0.5222214483544293, 0.5222214483544293, 0.5403679647275552], 
reward next is 0.4596, 
noisyNet noise sample is [array([-0.6262325], dtype=float32), 1.2156565]. 
=============================================
[2019-03-24 06:53:28,101] A3C_AGENT_WORKER-Thread-9 INFO:Local step 79000, global step 1264378: loss -94.4951
[2019-03-24 06:53:28,103] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 79000, global step 1264379: learning rate 0.0000
[2019-03-24 06:53:28,111] A3C_AGENT_WORKER-Thread-14 INFO:Local step 79000, global step 1264381: loss -104.3074
[2019-03-24 06:53:28,113] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 79000, global step 1264382: learning rate 0.0000
[2019-03-24 06:53:28,118] A3C_AGENT_WORKER-Thread-3 INFO:Local step 79000, global step 1264384: loss -60.4844
[2019-03-24 06:53:28,120] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 79000, global step 1264385: learning rate 0.0000
[2019-03-24 06:53:28,183] A3C_AGENT_WORKER-Thread-16 INFO:Local step 79000, global step 1264419: loss -69.4995
[2019-03-24 06:53:28,184] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 79000, global step 1264419: learning rate 0.0000
[2019-03-24 06:53:28,214] A3C_AGENT_WORKER-Thread-19 INFO:Local step 79000, global step 1264433: loss -77.5112
[2019-03-24 06:53:28,218] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 79000, global step 1264434: learning rate 0.0000
[2019-03-24 06:53:28,390] A3C_AGENT_WORKER-Thread-13 INFO:Local step 79000, global step 1264529: loss -92.2168
[2019-03-24 06:53:28,392] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 79000, global step 1264529: learning rate 0.0000
[2019-03-24 06:53:28,764] A3C_AGENT_WORKER-Thread-11 INFO:Local step 79000, global step 1264715: loss 67.9786
[2019-03-24 06:53:28,766] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 79000, global step 1264715: learning rate 0.0000
[2019-03-24 06:53:29,207] A3C_AGENT_WORKER-Thread-2 INFO:Local step 79000, global step 1264947: loss -61.4726
[2019-03-24 06:53:29,209] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 79000, global step 1264947: learning rate 0.0000
[2019-03-24 06:53:29,327] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:53:29,335] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8730
[2019-03-24 06:53:29,341] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1221342.63941074 W.
[2019-03-24 06:53:29,344] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.4, 39.0, 1.0, 2.0, 0.5026070968747505, 1.0, 1.0, 0.5026070968747505, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1221342.63941074, 1221342.63941074, 239270.617443563], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7819200.0000, 
sim time next is 7819800.0000, 
raw observation next is [29.5, 38.33333333333334, 1.0, 2.0, 0.3620195866174933, 1.0, 2.0, 0.3620195866174933, 1.0, 1.0, 0.5854380391885348, 6.911200000000001, 6.9112, 121.94756008, 1307079.481585435, 1307079.481585434, 280255.8857795486], 
processed observation next is [1.0, 0.5217391304347826, 0.6481481481481481, 0.3833333333333334, 1.0, 1.0, 0.2404995078779682, 1.0, 1.0, 0.2404995078779682, 1.0, 0.5, 0.4817975489856684, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.4668141005662268, 0.4668141005662264, 0.5389536264991319], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.34009874], dtype=float32), 0.2268952]. 
=============================================
[2019-03-24 06:53:29,562] A3C_AGENT_WORKER-Thread-10 INFO:Local step 79000, global step 1265136: loss -131.1504
[2019-03-24 06:53:29,566] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 79000, global step 1265136: learning rate 0.0000
[2019-03-24 06:53:29,738] A3C_AGENT_WORKER-Thread-18 INFO:Local step 79000, global step 1265205: loss -98.6071
[2019-03-24 06:53:29,740] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 79000, global step 1265206: learning rate 0.0000
[2019-03-24 06:53:30,926] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 5.8616797e-38], sum to 1.0000
[2019-03-24 06:53:30,934] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7126
[2019-03-24 06:53:30,940] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 818333.8024952232 W.
[2019-03-24 06:53:30,945] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [20.96666666666667, 83.33333333333333, 1.0, 1.0, 0.3321750053640376, 1.0, 1.0, 0.3321750053640376, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260306904227, 818333.8024952232, 818333.8024952228, 190745.8794893966], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7720800.0000, 
sim time next is 7721400.0000, 
raw observation next is [21.33333333333333, 81.66666666666667, 1.0, 2.0, 0.2332093431920184, 1.0, 2.0, 0.2332093431920184, 1.0, 1.0, 0.3809162052110607, 6.911200000000001, 6.9112, 121.94756008, 853601.1576167847, 853601.1576167842, 230492.2727048861], 
processed observation next is [1.0, 0.34782608695652173, 0.3456790123456788, 0.8166666666666668, 1.0, 1.0, 0.08715397999049808, 1.0, 1.0, 0.08715397999049808, 1.0, 0.5, 0.22614525651382583, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.3048575562917088, 0.30485755629170863, 0.44325437058631945], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.31686145], dtype=float32), 0.23194794]. 
=============================================
[2019-03-24 06:53:31,068] A3C_AGENT_WORKER-Thread-20 INFO:Local step 79000, global step 1265897: loss -15.9305
[2019-03-24 06:53:31,072] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 79000, global step 1265898: learning rate 0.0000
[2019-03-24 06:53:32,190] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:53:32,195] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3277
[2019-03-24 06:53:32,200] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1084044.416103033 W.
[2019-03-24 06:53:32,207] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.03333333333333, 53.0, 1.0, 2.0, 0.4567511258145202, 1.0, 2.0, 0.4567511258145202, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1084044.416103033, 1084044.416103033, 224211.2866570566], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7735200.0000, 
sim time next is 7735800.0000, 
raw observation next is [28.21666666666667, 52.0, 1.0, 2.0, 0.4562609245629771, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7342649433437447, 6.911200000000001, 6.9112, 121.9260426156618, 1088191.246698875, 1088191.246698874, 240797.2058633225], 
processed observation next is [1.0, 0.5217391304347826, 0.6006172839506173, 0.52, 1.0, 1.0, 0.3526915768606871, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.6678311791796809, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.38863973096388393, 0.3886397309638836, 0.4630715497371587], 
reward next is 0.5369, 
noisyNet noise sample is [array([-0.6523014], dtype=float32), 0.46297097]. 
=============================================
[2019-03-24 06:53:33,065] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:53:33,065] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:53:33,113] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run7
[2019-03-24 06:53:35,445] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:53:35,452] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7847
[2019-03-24 06:53:35,460] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.98333333333333, 54.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5515415792491601, 6.9112, 6.9112, 121.9260426156618, 405901.3459390014, 405901.3459390014, 123868.1288074719], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7800600.0000, 
sim time next is 7801200.0000, 
raw observation next is [24.2, 53.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5508038637354833, 6.911200000000001, 6.9112, 121.9260426156618, 405498.5870000121, 405498.5870000116, 123875.1895358978], 
processed observation next is [1.0, 0.30434782608695654, 0.45185185185185184, 0.53, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.43850482966935406, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14482092392857576, 0.14482092392857557, 0.23822151833826502], 
reward next is 0.7618, 
noisyNet noise sample is [array([0.13057537], dtype=float32), 2.168504]. 
=============================================
[2019-03-24 06:53:36,836] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:53:36,838] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:53:36,870] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run7
[2019-03-24 06:53:39,761] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:53:39,769] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8791
[2019-03-24 06:53:39,773] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.5, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7000331229996037, 6.911200000000001, 6.9112, 121.9260426156618, 521171.5420578849, 521171.5420578844, 141474.4739699834], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7887600.0000, 
sim time next is 7888200.0000, 
raw observation next is [21.63333333333333, 77.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8073586850264974, 6.911200000000001, 6.9112, 121.9260426156618, 601203.7125865946, 601203.7125865942, 153325.4222385322], 
processed observation next is [1.0, 0.30434782608695654, 0.35679012345678995, 0.7716666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7591983562831217, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21471561163806951, 0.21471561163806935, 0.2948565812279465], 
reward next is 0.7051, 
noisyNet noise sample is [array([0.33130908], dtype=float32), 0.19212732]. 
=============================================
[2019-03-24 06:53:40,280] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.00000000e+00 1.10252624e-35 0.00000000e+00 1.58708670e-35
 2.00646255e-37], sum to 1.0000
[2019-03-24 06:53:40,285] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8476
[2019-03-24 06:53:40,297] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1206889.270016829 W.
[2019-03-24 06:53:40,303] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.0, 39.0, 1.0, 2.0, 0.487944128705648, 1.0, 1.0, 0.487944128705648, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.92593153519, 1206889.270016829, 1206889.270016828, 235252.7498315871], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 43200.0000, 
sim time next is 43800.0000, 
raw observation next is [28.18333333333334, 38.83333333333334, 1.0, 2.0, 0.4836360743990551, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8004595649009468, 6.9112, 6.9112, 121.9260425817905, 1196407.52704181, 1196407.52704181, 247485.7997471862], 
processed observation next is [1.0, 0.5217391304347826, 0.599382716049383, 0.3883333333333334, 1.0, 1.0, 0.38528104095125604, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.7505744561261835, 0.0, 0.0, 0.8094621285952657, 0.42728840251493216, 0.42728840251493216, 0.4759342302830504], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.33402416], dtype=float32), -1.0353869]. 
=============================================
[2019-03-24 06:53:40,734] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.7550376e-34 0.0000000e+00 1.3262933e-35 8.4630413e-36], sum to 1.0000
[2019-03-24 06:53:40,738] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3571
[2019-03-24 06:53:40,744] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1676321.549411648 W.
[2019-03-24 06:53:40,750] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.75, 53.5, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.780952874765046, 6.9112, 121.9226122301967, 1676321.549411648, 1230942.870970123, 248981.9158183728], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7903800.0000, 
sim time next is 7904400.0000, 
raw observation next is [27.9, 53.0, 1.0, 2.0, 0.4371152108510661, 1.0, 1.0, 0.4371152108510661, 1.0, 1.0, 0.6987356720051645, 6.9112, 6.9112, 121.94756008, 1536037.736387447, 1536037.736387447, 313784.4516683503], 
processed observation next is [1.0, 0.4782608695652174, 0.5888888888888888, 0.53, 1.0, 1.0, 0.3298990605369834, 1.0, 0.5, 0.3298990605369834, 1.0, 0.5, 0.6234195900064556, 0.0, 0.0, 0.8096049824067558, 0.5485849058526596, 0.5485849058526596, 0.6034316378237506], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.37102047], dtype=float32), -0.92550236]. 
=============================================
[2019-03-24 06:53:43,364] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:53:43,365] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:53:43,371] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:53:43,371] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:53:43,373] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run7
[2019-03-24 06:53:43,430] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run7
[2019-03-24 06:53:43,474] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:53:43,475] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:53:43,495] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run7
[2019-03-24 06:53:43,857] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:53:43,857] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:53:43,865] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run7
[2019-03-24 06:53:43,887] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:53:43,889] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:53:43,900] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run7
[2019-03-24 06:53:43,924] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:53:43,927] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:53:43,934] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run7
[2019-03-24 06:53:43,968] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:53:43,969] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:53:43,971] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:53:43,971] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:53:43,983] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run7
[2019-03-24 06:53:44,028] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:53:44,029] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:53:44,036] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run7
[2019-03-24 06:53:44,072] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run7
[2019-03-24 06:53:44,205] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:53:44,205] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:53:44,211] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run7
[2019-03-24 06:53:44,301] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:53:44,301] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:53:44,304] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run7
[2019-03-24 06:53:44,381] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:53:44,382] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:53:44,424] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run7
[2019-03-24 06:53:44,649] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:53:44,649] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:53:44,652] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run7
[2019-03-24 06:53:44,857] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 06:53:44,857] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:53:44,860] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run7
[2019-03-24 06:53:47,003] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:53:47,009] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3756
[2019-03-24 06:53:47,016] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.8, 35.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5122149395936186, 6.911199999999999, 6.9112, 121.9260426156618, 365728.5066216229, 365728.5066216233, 102140.5825179861], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 288000.0000, 
sim time next is 288600.0000, 
raw observation next is [23.93333333333334, 34.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5157031456762071, 6.9112, 6.9112, 121.9260426156618, 368219.731621718, 368219.731621718, 102718.5932154047], 
processed observation next is [0.0, 0.34782608695652173, 0.4419753086419756, 0.34666666666666673, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.39462893209525884, 0.0, 0.0, 0.8094621288201359, 0.13150704700775642, 0.13150704700775642, 0.19753575618347058], 
reward next is 0.8025, 
noisyNet noise sample is [array([-0.06010657], dtype=float32), 1.7935531]. 
=============================================
[2019-03-24 06:53:47,765] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 2.1470783e-35 0.0000000e+00 1.7030723e-35 2.0859724e-34], sum to 1.0000
[2019-03-24 06:53:47,771] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2734
[2019-03-24 06:53:47,777] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 929020.6086136339 W.
[2019-03-24 06:53:47,781] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.5, 43.0, 1.0, 2.0, 0.3685093927884321, 0.0, 1.0, 0.0, 1.0, 2.0, 0.6269169570045806, 6.9112, 6.9112, 121.9260426156618, 929020.6086136339, 929020.6086136339, 209325.7440551005], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 36000.0000, 
sim time next is 36600.0000, 
raw observation next is [25.73333333333333, 42.66666666666667, 1.0, 2.0, 0.2490858572001996, 1.0, 1.0, 0.2490858572001996, 1.0, 2.0, 0.4181507261916548, 6.911200000000001, 6.9112, 121.94756008, 934272.3062383389, 934272.3062383385, 234506.1604423386], 
processed observation next is [1.0, 0.43478260869565216, 0.5086419753086419, 0.4266666666666667, 1.0, 1.0, 0.10605459190499952, 1.0, 0.5, 0.10605459190499952, 1.0, 1.0, 0.27268840773956843, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.33366868079940676, 0.3336686807994066, 0.45097338546603577], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6020742], dtype=float32), 0.2532793]. 
=============================================
[2019-03-24 06:53:50,139] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-24 06:53:50,141] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:53:50,141] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:53:50,144] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:53:50,145] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:53:50,147] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:53:50,149] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:53:50,149] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:53:50,151] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:53:50,153] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:53:50,153] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:53:50,167] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run52
[2019-03-24 06:53:50,195] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run52
[2019-03-24 06:53:50,196] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run52
[2019-03-24 06:53:50,220] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run52
[2019-03-24 06:53:50,254] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run52
[2019-03-24 06:53:52,872] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00737234], dtype=float32), 0.017459555]
[2019-03-24 06:53:52,872] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [37.48225772666667, 19.249714745, 1.0, 2.0, 0.834456702920466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1021452.777274128, 1021452.777274128, 206243.8598008942]
[2019-03-24 06:53:52,875] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:53:52,876] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.9306860942528531
[2019-03-24 06:53:52,877] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1021452.777274128 W.
[2019-03-24 06:53:55,099] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00737234], dtype=float32), 0.017459555]
[2019-03-24 06:53:55,101] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.7, 38.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.501351462518161, 6.911200000000001, 6.9112, 121.9260426156618, 357970.0244135477, 357970.0244135472, 110678.4049720145]
[2019-03-24 06:53:55,102] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:53:55,104] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.8444419026784001
[2019-03-24 06:54:22,010] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00737234], dtype=float32), 0.017459555]
[2019-03-24 06:54:22,012] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.7, 62.5, 1.0, 2.0, 0.9017815458785339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426038612, 1044337.704567778, 1044337.704567777, 218745.485988722]
[2019-03-24 06:54:22,014] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:54:22,017] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.3920247028590794
[2019-03-24 06:54:22,018] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1044337.704567778 W.
[2019-03-24 06:54:51,779] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00737234], dtype=float32), 0.017459555]
[2019-03-24 06:54:51,781] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.75, 95.0, 1.0, 2.0, 0.6874534797296882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 795178.6139149856, 795178.6139149856, 174358.9913357623]
[2019-03-24 06:54:51,781] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:54:51,785] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.21892611263305495
[2019-03-24 06:54:51,786] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 795178.6139149856 W.
[2019-03-24 06:55:05,016] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00737234], dtype=float32), 0.017459555]
[2019-03-24 06:55:05,018] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.14209837, 94.05510388333335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8309719086043923, 6.9112, 6.9112, 121.9260426156618, 615767.3246306959, 615767.3246306959, 164839.349636474]
[2019-03-24 06:55:05,019] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 06:55:05,022] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.5877253100396037
[2019-03-24 06:55:14,468] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00737234], dtype=float32), 0.017459555]
[2019-03-24 06:55:14,469] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.06666666666667, 91.66666666666667, 1.0, 2.0, 0.921695684263546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1050645.543398869, 1050645.543398869, 222360.9639346669]
[2019-03-24 06:55:14,471] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:55:14,473] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.8443277260158858
[2019-03-24 06:55:14,476] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1050645.543398869 W.
[2019-03-24 06:55:23,407] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00737234], dtype=float32), 0.017459555]
[2019-03-24 06:55:23,408] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.0, 92.33333333333334, 1.0, 2.0, 0.575600229282424, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9163743110083611, 6.911199999999999, 6.9112, 121.9260426156618, 1312483.288380111, 1312483.288380112, 284490.5874471643]
[2019-03-24 06:55:23,408] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:55:23,410] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.06758496751127097
[2019-03-24 06:55:23,412] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1312483.288380111 W.
[2019-03-24 06:55:32,811] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00737234], dtype=float32), 0.017459555]
[2019-03-24 06:55:32,814] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [32.80732287, 55.79615013, 1.0, 2.0, 0.5955157490458222, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9480804670748882, 6.9112, 6.9112, 121.9254711583204, 1357934.904620211, 1357934.904620211, 292124.1047783956]
[2019-03-24 06:55:32,815] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:55:32,819] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.12234509674377492
[2019-03-24 06:55:32,821] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1357934.904620211 W.
[2019-03-24 06:55:33,865] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 06:55:34,424] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 06:55:34,467] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 06:55:34,487] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 06:55:34,502] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 06:55:35,514] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1275000, evaluation results [1275000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 06:55:35,730] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.3018801e-37], sum to 1.0000
[2019-03-24 06:55:35,738] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3267
[2019-03-24 06:55:35,743] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.2, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7743853609715505, 6.911199999999999, 6.9112, 121.9260426156618, 577914.532237451, 577914.5322374515, 151023.8491117668], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 97200.0000, 
sim time next is 97800.0000, 
raw observation next is [22.11666666666667, 76.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7556717485631125, 6.9112, 6.9112, 121.9260426156618, 563732.577916411, 563732.577916411, 148631.1693170577], 
processed observation next is [1.0, 0.13043478260869565, 0.3746913580246915, 0.7616666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6945896857038905, 0.0, 0.0, 0.8094621288201359, 0.20133306354157535, 0.20133306354157535, 0.28582917176357253], 
reward next is 0.7142, 
noisyNet noise sample is [array([-0.564393], dtype=float32), -1.7326609]. 
=============================================
[2019-03-24 06:55:40,211] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:55:40,220] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6388
[2019-03-24 06:55:40,225] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.65, 16.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5658683079545456, 6.911200000000001, 6.9112, 121.9260426156618, 404047.840884294, 404047.8408842935, 100186.0481160381], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 179400.0000, 
sim time next is 180000.0000, 
raw observation next is [26.4, 17.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.560673073356489, 6.911199999999999, 6.9112, 121.9260426156618, 400337.3110635812, 400337.3110635817, 99533.79512897716], 
processed observation next is [0.0, 0.08695652173913043, 0.5333333333333333, 0.17, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4508413416956112, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14297761109413615, 0.14297761109413634, 0.19141114447880223], 
reward next is 0.8086, 
noisyNet noise sample is [array([2.8009202], dtype=float32), 1.2299631]. 
=============================================
[2019-03-24 06:55:40,237] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[73.1988  ]
 [73.08507 ]
 [73.17162 ]
 [73.07208 ]
 [72.973755]], R is [[73.06936646]
 [73.14601135]
 [73.22057343]
 [73.29311371]
 [73.36384583]].
[2019-03-24 06:55:49,430] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:55:49,439] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7782
[2019-03-24 06:55:49,443] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.71666666666667, 54.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8819300096132282, 6.911199999999999, 6.9112, 121.9260426156618, 629818.5624798597, 629818.5624798601, 142119.5450829593], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 353400.0000, 
sim time next is 354000.0000, 
raw observation next is [20.53333333333333, 55.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7707242495368096, 6.911200000000001, 6.9112, 121.9260426156618, 550373.94625414, 550373.9462541395, 131168.4515606363], 
processed observation next is [1.0, 0.08695652173913043, 0.3160493827160493, 0.5533333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7134053119210121, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19656212366219286, 0.1965621236621927, 0.2522470222319929], 
reward next is 0.7478, 
noisyNet noise sample is [array([0.18965644], dtype=float32), -1.3669599]. 
=============================================
[2019-03-24 06:55:49,458] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[74.756546]
 [74.086586]
 [73.7061  ]
 [73.718796]
 [73.597946]], R is [[75.57407379]
 [75.54502869]
 [75.59209442]
 [75.63733673]
 [75.68071747]].
[2019-03-24 06:55:49,724] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:55:49,731] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9671
[2019-03-24 06:55:49,738] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.55, 48.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4993592877329123, 6.911200000000001, 6.9112, 121.9260426156618, 356547.2607807575, 356547.2607807571, 110892.7900654733], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 346200.0000, 
sim time next is 346800.0000, 
raw observation next is [22.4, 49.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4960029131067491, 6.9112, 6.9112, 121.9260426156618, 354150.2241856259, 354150.2241856259, 110106.6652299874], 
processed observation next is [1.0, 0.0, 0.38518518518518513, 0.49, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.37000364138343633, 0.0, 0.0, 0.8094621288201359, 0.12648222292343783, 0.12648222292343783, 0.211743586980745], 
reward next is 0.7883, 
noisyNet noise sample is [array([-0.14165895], dtype=float32), -0.5626442]. 
=============================================
[2019-03-24 06:55:54,768] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 3.9721764e-38 1.0668444e-37], sum to 1.0000
[2019-03-24 06:55:54,772] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9763
[2019-03-24 06:55:54,775] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.7, 69.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4750342098237311, 6.911199999999999, 6.9112, 121.9260426156618, 339514.0225898682, 339514.0225898687, 113367.8732168282], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 453600.0000, 
sim time next is 454200.0000, 
raw observation next is [20.0, 67.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6113921259744363, 6.9112, 6.9112, 121.9260426156618, 437747.5854680617, 437747.5854680617, 124405.1251231637], 
processed observation next is [1.0, 0.2608695652173913, 0.2962962962962963, 0.675, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5142401574680453, 0.0, 0.0, 0.8094621288201359, 0.1563384233814506, 0.1563384233814506, 0.23924062523685327], 
reward next is 0.7608, 
noisyNet noise sample is [array([1.0847099], dtype=float32), 0.11258226]. 
=============================================
[2019-03-24 06:55:55,023] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 1.4910176e-32 5.3043026e-37 1.0250340e-32 1.3736900e-31], sum to 1.0000
[2019-03-24 06:55:55,029] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5154
[2019-03-24 06:55:55,029] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1262466.964255241 W.
[2019-03-24 06:55:55,033] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.73333333333333, 41.33333333333334, 1.0, 2.0, 0.914766788871569, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.148753246936115, 6.9112, 121.9250044413292, 1262466.964255241, 1140819.505366741, 224868.5469980692], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 469200.0000, 
sim time next is 469800.0000, 
raw observation next is [28.05, 40.5, 1.0, 2.0, 0.9361974527399025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.305729264822646, 6.9112, 121.9242060170208, 1371978.299528409, 1169947.096599693, 229948.5811586296], 
processed observation next is [1.0, 0.43478260869565216, 0.5944444444444444, 0.405, 1.0, 1.0, 0.924044586595122, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.039452926482264596, 0.0, 0.8094499357150876, 0.48999224983157463, 0.4178382487856046, 0.44220880992044154], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.13305452], dtype=float32), 0.5987254]. 
=============================================
[2019-03-24 06:55:57,143] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:55:57,153] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8230
[2019-03-24 06:55:57,157] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.33333333333334, 41.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5877964339586043, 6.9112, 6.9112, 121.9260426156618, 435555.0725421776, 435555.0725421776, 128742.3620915101], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 506400.0000, 
sim time next is 507000.0000, 
raw observation next is [27.06666666666667, 42.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5886606387142509, 6.911199999999999, 6.9112, 121.9260426156618, 435970.2174772233, 435970.2174772237, 128679.2899102257], 
processed observation next is [1.0, 0.8695652173913043, 0.5580246913580248, 0.4216666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4858257983928136, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15570364909900833, 0.15570364909900847, 0.2474601729042802], 
reward next is 0.7525, 
noisyNet noise sample is [array([-1.1601725], dtype=float32), -1.0455457]. 
=============================================
[2019-03-24 06:55:57,171] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[70.91616]
 [71.48598]
 [71.62173]
 [72.0978 ]
 [71.62529]], R is [[70.7676239 ]
 [70.8123703 ]
 [70.85661316]
 [70.9010849 ]
 [70.9449234 ]].
[2019-03-24 06:55:58,148] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:55:58,152] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7604
[2019-03-24 06:55:58,159] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.93333333333334, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5454950196758523, 6.911200000000001, 6.9112, 121.9260426156618, 399084.9834768675, 399084.9834768671, 122227.9790687953], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 520800.0000, 
sim time next is 521400.0000, 
raw observation next is [21.76666666666667, 64.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5458020541340788, 6.911200000000001, 6.9112, 121.9260426156618, 399264.6410003995, 399264.641000399, 122234.0995888825], 
processed observation next is [1.0, 0.0, 0.3617283950617285, 0.64, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.43225256766759845, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14259451464299983, 0.14259451464299966, 0.23506557613246634], 
reward next is 0.7649, 
noisyNet noise sample is [array([-0.8868101], dtype=float32), -1.116148]. 
=============================================
[2019-03-24 06:55:59,406] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.2229979e-38 3.5462943e-38], sum to 1.0000
[2019-03-24 06:55:59,412] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5745
[2019-03-24 06:55:59,422] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1378476.214368806 W.
[2019-03-24 06:55:59,425] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.6, 47.33333333333333, 1.0, 2.0, 0.5659159947148894, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9227496304561738, 6.911200000000001, 6.9112, 121.9256416925661, 1378476.214368806, 1378476.214368805, 278032.7833327241], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 556800.0000, 
sim time next is 557400.0000, 
raw observation next is [27.3, 48.66666666666667, 1.0, 2.0, 0.5360490400918012, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8729609165139263, 6.911200000000001, 6.9112, 121.9260424934078, 1303584.13132588, 1303584.13132588, 267202.7442478895], 
processed observation next is [1.0, 0.43478260869565216, 0.5666666666666667, 0.4866666666666667, 1.0, 1.0, 0.4476774286807157, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8412011456424079, 8.881784197001253e-17, 0.0, 0.8094621280084966, 0.4655657611878143, 0.4655657611878143, 0.5138514312459413], 
reward next is 0.4861, 
noisyNet noise sample is [array([0.7971799], dtype=float32), 0.08180487]. 
=============================================
[2019-03-24 06:56:05,143] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:56:05,150] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9955
[2019-03-24 06:56:05,156] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.73333333333333, 23.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.644790148965559, 6.911200000000001, 6.9112, 121.9260426156618, 474639.0142959536, 474639.0142959532, 132386.0475615196], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 676200.0000, 
sim time next is 676800.0000, 
raw observation next is [31.5, 24.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6382679986898765, 6.9112, 6.9112, 121.9260426156618, 469381.2747686252, 469381.2747686252, 131544.4465306767], 
processed observation next is [1.0, 0.8695652173913043, 0.7222222222222222, 0.24, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5478349983623456, 0.0, 0.0, 0.8094621288201359, 0.16763616956022329, 0.16763616956022329, 0.2529700894820706], 
reward next is 0.7470, 
noisyNet noise sample is [array([-0.53728765], dtype=float32), 0.5436894]. 
=============================================
[2019-03-24 06:56:05,336] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:56:05,342] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2583
[2019-03-24 06:56:05,349] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1516977.70580734 W.
[2019-03-24 06:56:05,359] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [35.6, 17.83333333333333, 1.0, 2.0, 0.6193901447264217, 1.0, 1.0, 0.6193901447264217, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.926042615621, 1516977.70580734, 1516977.70580734, 279037.7410643633], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 663000.0000, 
sim time next is 663600.0000, 
raw observation next is [35.60000000000001, 17.66666666666667, 1.0, 2.0, 0.6551090728599399, 1.0, 2.0, 0.6551090728599399, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1601462.721926989, 1601462.721926989, 291988.354541786], 
processed observation next is [1.0, 0.6956521739130435, 0.8740740740740743, 0.17666666666666672, 1.0, 1.0, 0.5894155629284998, 1.0, 1.0, 0.5894155629284998, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5719509721167818, 0.5719509721167818, 0.5615160664265115], 
reward next is 0.4385, 
noisyNet noise sample is [array([-1.3068808], dtype=float32), 0.6313286]. 
=============================================
[2019-03-24 06:56:07,642] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:56:07,648] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7373
[2019-03-24 06:56:07,654] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.8, 35.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.572960713185645, 6.911199999999999, 6.9112, 121.9260426156618, 420734.7684051611, 420734.7684051616, 125293.9670878566], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 689400.0000, 
sim time next is 690000.0000, 
raw observation next is [27.66666666666666, 35.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5709488916697484, 6.9112, 6.9112, 121.9260426156618, 418860.141910669, 418860.141910669, 124930.261557451], 
processed observation next is [1.0, 1.0, 0.5802469135802467, 0.3566666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.46368611458718545, 0.0, 0.0, 0.8094621288201359, 0.14959290782523893, 0.14959290782523893, 0.24025050299509806], 
reward next is 0.7597, 
noisyNet noise sample is [array([0.32322595], dtype=float32), -0.5274507]. 
=============================================
[2019-03-24 06:56:07,669] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[69.80059]
 [69.82499]
 [69.88706]
 [69.9015 ]
 [69.8579 ]], R is [[69.85176849]
 [69.91230011]
 [69.97150421]
 [70.0293808 ]
 [70.08602905]].
[2019-03-24 06:56:11,011] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:56:11,018] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1895
[2019-03-24 06:56:11,023] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.2, 40.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5392426486733524, 6.911200000000001, 6.9112, 121.9260426156618, 394251.8835190033, 394251.8835190028, 121586.228879321], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 775800.0000, 
sim time next is 776400.0000, 
raw observation next is [26.03333333333333, 41.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5364298995131875, 6.9112, 6.9112, 121.9260426156618, 391954.3853854141, 391954.3853854141, 121245.3329407183], 
processed observation next is [1.0, 1.0, 0.519753086419753, 0.41, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.42053737439148436, 0.0, 0.0, 0.8094621288201359, 0.13998370906621932, 0.13998370906621932, 0.23316410180907365], 
reward next is 0.7668, 
noisyNet noise sample is [array([-1.121285], dtype=float32), 0.22349574]. 
=============================================
[2019-03-24 06:56:18,816] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:56:18,821] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1914
[2019-03-24 06:56:18,826] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.46666666666667, 48.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6315815573257546, 6.9112, 6.9112, 121.9260426156618, 470121.6359854552, 470121.6359854552, 134443.7723719949], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 931800.0000, 
sim time next is 932400.0000, 
raw observation next is [26.3, 49.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6291227538484889, 6.9112, 6.9112, 121.9260426156618, 468227.3318898458, 468227.3318898458, 134145.2691105424], 
processed observation next is [0.0, 0.8260869565217391, 0.5296296296296297, 0.49, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5364034423106111, 0.0, 0.0, 0.8094621288201359, 0.16722404710351635, 0.16722404710351635, 0.2579716713664277], 
reward next is 0.7420, 
noisyNet noise sample is [array([1.2441552], dtype=float32), -0.571265]. 
=============================================
[2019-03-24 06:56:21,188] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:56:21,193] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8820
[2019-03-24 06:56:21,198] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.23333333333333, 59.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6654246506939081, 6.9112, 6.9112, 121.9260426156618, 477056.3607776678, 477056.3607776678, 129293.6991711229], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 972600.0000, 
sim time next is 973200.0000, 
raw observation next is [21.36666666666667, 59.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5896807354875526, 6.911199999999999, 6.9112, 121.9260426156618, 423602.8250593706, 423602.8250593711, 123057.1248754726], 
processed observation next is [1.0, 0.2608695652173913, 0.3469135802469137, 0.5966666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4871009193594407, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1512867232354895, 0.1512867232354897, 0.23664831706821654], 
reward next is 0.7634, 
noisyNet noise sample is [array([0.37362742], dtype=float32), 1.558598]. 
=============================================
[2019-03-24 06:56:24,215] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-24 06:56:24,217] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:56:24,219] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:56:24,220] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:56:24,221] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:56:24,221] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:56:24,223] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:56:24,223] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:56:24,227] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:56:24,228] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:56:24,228] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:56:24,248] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run53
[2019-03-24 06:56:24,249] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run53
[2019-03-24 06:56:24,273] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run53
[2019-03-24 06:56:24,333] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run53
[2019-03-24 06:56:24,360] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run53
[2019-03-24 06:56:49,108] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00792361], dtype=float32), 0.01787146]
[2019-03-24 06:56:49,109] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.16666666666667, 67.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6370556528557492, 6.911199999999999, 6.9112, 121.9260426156618, 474650.4650801962, 474650.4650801967, 135413.8330320137]
[2019-03-24 06:56:49,111] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:56:49,114] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.04679957086141695
[2019-03-24 06:57:05,326] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00792361], dtype=float32), 0.01787146]
[2019-03-24 06:57:05,327] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.54124816666667, 86.58248505333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7896850330841932, 6.911199999999999, 6.9112, 121.9260426156618, 584882.5622131057, 584882.5622131062, 159770.8393403599]
[2019-03-24 06:57:05,329] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:57:05,331] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.4487232619350934
[2019-03-24 06:57:10,442] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00792361], dtype=float32), 0.01787146]
[2019-03-24 06:57:10,444] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.76666666666667, 93.66666666666667, 1.0, 2.0, 0.6582931482492995, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 750244.7021354008, 750244.7021354008, 168396.395099201]
[2019-03-24 06:57:10,445] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:57:10,449] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.7169839411905666
[2019-03-24 06:57:10,452] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 750244.7021354008 W.
[2019-03-24 06:57:31,611] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00792361], dtype=float32), 0.01787146]
[2019-03-24 06:57:31,612] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.6, 88.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9307011504728089, 6.911200000000001, 6.9112, 121.9260426156618, 677087.461133693, 677087.4611336925, 180802.4195888651]
[2019-03-24 06:57:31,613] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:57:31,617] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.7270123993146881
[2019-03-24 06:57:57,585] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00792361], dtype=float32), 0.01787146]
[2019-03-24 06:57:57,586] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.85, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8368874845502189, 6.911200000000001, 6.9112, 121.9260426156618, 616255.2612109343, 616255.2612109338, 166853.2013197158]
[2019-03-24 06:57:57,587] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:57:57,591] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.7338089783317162
[2019-03-24 06:58:00,914] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00792361], dtype=float32), 0.01787146]
[2019-03-24 06:58:00,916] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.35, 64.0, 1.0, 2.0, 0.7164212078612096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156081, 816527.4780071506, 816527.4780071506, 179280.7820658385]
[2019-03-24 06:58:00,917] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:58:00,920] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.33864872294942083
[2019-03-24 06:58:00,921] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 816527.4780071506 W.
[2019-03-24 06:58:03,490] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00792361], dtype=float32), 0.01787146]
[2019-03-24 06:58:03,493] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.81787191, 69.65913548666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.866011494526577, 6.911199999999999, 6.9112, 121.9260426156618, 647139.5315898849, 647139.5315898854, 164748.4255460246]
[2019-03-24 06:58:03,494] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:58:03,497] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.07521426881833138
[2019-03-24 06:58:03,865] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00792361], dtype=float32), 0.01787146]
[2019-03-24 06:58:03,868] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.71666666666667, 83.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6148477485933103, 6.911200000000001, 6.9112, 121.9260426156618, 457640.6342994961, 457640.6342994956, 132786.5256649448]
[2019-03-24 06:58:03,870] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 06:58:03,874] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.7470804910598371
[2019-03-24 06:58:08,629] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00792361], dtype=float32), 0.01787146]
[2019-03-24 06:58:08,630] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.35985539, 78.04463994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8733599643607393, 6.911200000000001, 6.9112, 121.9260426156618, 640785.0344937239, 640785.0344937234, 172089.2418225909]
[2019-03-24 06:58:08,632] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:58:08,635] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.2665784607221299
[2019-03-24 06:58:12,656] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 06:58:12,833] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 06:58:12,865] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 06:58:12,940] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 06:58:13,048] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 06:58:14,063] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1300000, evaluation results [1300000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 06:58:16,128] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 4.5208740e-37 0.0000000e+00 6.6589545e-36 3.3728660e-38], sum to 1.0000
[2019-03-24 06:58:16,135] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7224
[2019-03-24 06:58:16,138] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.86666666666667, 58.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8798087388478986, 6.911199999999999, 6.9112, 121.9260426156618, 644773.0474337838, 644773.0474337842, 155407.3732560897], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1066800.0000, 
sim time next is 1067400.0000, 
raw observation next is [22.95, 57.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9745061583182715, 7.089909144452831, 6.9112, 121.9253337693488, 805812.3898523501, 714297.8670951562, 166088.4545687993], 
processed observation next is [1.0, 0.34782608695652173, 0.4055555555555555, 0.575, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9681326978978394, 0.01787091444528306, 0.0, 0.8094574228177658, 0.2877901392329822, 0.25510638110541295, 0.31940087417076785], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.0680022], dtype=float32), 0.75775886]. 
=============================================
[2019-03-24 06:58:18,526] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:58:18,532] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7962
[2019-03-24 06:58:18,536] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.25, 75.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5062995454147164, 6.911199999999999, 6.9112, 121.9260426156618, 364783.427891987, 364783.4278919875, 116728.8091088089], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1121400.0000, 
sim time next is 1122000.0000, 
raw observation next is [19.23333333333333, 75.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5061051401789776, 6.911200000000001, 6.9112, 121.9260426156618, 364527.3654101868, 364527.3654101864, 116671.9262748209], 
processed observation next is [1.0, 1.0, 0.26790123456790116, 0.75, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3826314252237219, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13018834478935243, 0.1301883447893523, 0.22436908899004018], 
reward next is 0.7756, 
noisyNet noise sample is [array([0.655413], dtype=float32), -0.24243721]. 
=============================================
[2019-03-24 06:58:18,551] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[73.099815]
 [73.09306 ]
 [73.10848 ]
 [73.07604 ]
 [73.00495 ]], R is [[73.15996552]
 [73.20388794]
 [73.24712372]
 [73.28940582]
 [73.33048248]].
[2019-03-24 06:58:24,487] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:58:24,492] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8890
[2019-03-24 06:58:24,495] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.0, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5300211957602288, 6.911199999999999, 6.9112, 121.9260426156618, 387166.442070602, 387166.4420706025, 120665.7451499473], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1229400.0000, 
sim time next is 1230000.0000, 
raw observation next is [18.06666666666667, 91.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5305544879620767, 6.911200000000001, 6.9112, 121.9260426156618, 387732.4895245812, 387732.4895245808, 120786.5630707677], 
processed observation next is [1.0, 0.21739130434782608, 0.22469135802469148, 0.9166666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.41319310995259584, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13847588911592185, 0.1384758891159217, 0.23228185205916865], 
reward next is 0.7677, 
noisyNet noise sample is [array([0.5104692], dtype=float32), -1.3178864]. 
=============================================
[2019-03-24 06:58:24,510] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[65.629395]
 [65.66619 ]
 [65.74365 ]
 [65.848045]
 [65.923996]], R is [[65.61194611]
 [65.72377777]
 [65.8351059 ]
 [65.94280243]
 [66.05200958]].
[2019-03-24 06:58:27,935] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:58:27,941] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3161
[2019-03-24 06:58:27,947] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.73333333333333, 75.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6701900620044463, 6.911200000000001, 6.9112, 121.9260426156618, 500602.7733589372, 500602.7733589367, 140539.5653456521], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1286400.0000, 
sim time next is 1287000.0000, 
raw observation next is [22.55, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6677543895001382, 6.911199999999999, 6.9112, 121.9260426156618, 498742.9427869919, 498742.9427869924, 140189.5034111509], 
processed observation next is [1.0, 0.9130434782608695, 0.3907407407407408, 0.76, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5846929868751727, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17812247956678282, 0.178122479566783, 0.26959519886759786], 
reward next is 0.7304, 
noisyNet noise sample is [array([-0.14887576], dtype=float32), 0.5035847]. 
=============================================
[2019-03-24 06:58:27,968] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[74.72871]
 [74.56835]
 [74.43134]
 [74.31715]
 [74.36285]], R is [[74.6955719 ]
 [74.67834473]
 [74.66055298]
 [74.6421051 ]
 [74.62294006]].
[2019-03-24 06:58:32,813] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:58:32,821] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3460
[2019-03-24 06:58:32,830] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.581428498430059, 6.911199999999999, 6.9112, 121.9260426156618, 429022.0081478787, 429022.0081478792, 127088.4718569383], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1382400.0000, 
sim time next is 1383000.0000, 
raw observation next is [21.93333333333334, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5790464001795391, 6.9112, 6.9112, 121.9260426156618, 426928.5387358972, 426928.5387358972, 126693.7775862059], 
processed observation next is [0.0, 0.0, 0.3679012345679015, 0.67, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4738080002244239, 0.0, 0.0, 0.8094621288201359, 0.15247447811996329, 0.15247447811996329, 0.2436418799734729], 
reward next is 0.7564, 
noisyNet noise sample is [array([-1.0870107], dtype=float32), 0.36235112]. 
=============================================
[2019-03-24 06:58:32,851] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[72.37046 ]
 [73.190506]
 [73.25649 ]
 [73.302025]
 [73.35905 ]], R is [[71.56369781]
 [71.60366058]
 [71.64195251]
 [71.67876434]
 [71.71445465]].
[2019-03-24 06:58:33,154] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:58:33,165] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9272
[2019-03-24 06:58:33,172] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.16666666666667, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5904679802642704, 6.9112, 6.9112, 121.9260426156618, 436437.0426920403, 436437.0426920403, 128323.3472877696], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1381200.0000, 
sim time next is 1381800.0000, 
raw observation next is [22.08333333333334, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5864569798268535, 6.911199999999999, 6.9112, 121.9260426156618, 433109.2388413184, 433109.2388413188, 127750.6080911557], 
processed observation next is [1.0, 1.0, 0.373456790123457, 0.67, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.48307122478356684, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15468187101475658, 0.15468187101475672, 0.24567424632914556], 
reward next is 0.7543, 
noisyNet noise sample is [array([-0.4852188], dtype=float32), -1.132073]. 
=============================================
[2019-03-24 06:58:36,918] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:58:36,923] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2368
[2019-03-24 06:58:36,927] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.73333333333333, 28.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.622882887140389, 6.9112, 6.9112, 121.9260426156618, 460876.1757982437, 460876.1757982437, 131618.5520327228], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1455000.0000, 
sim time next is 1455600.0000, 
raw observation next is [30.56666666666667, 29.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6191111445255096, 6.9112, 6.9112, 121.9260426156618, 458234.6516159342, 458234.6516159342, 131351.4573511134], 
processed observation next is [0.0, 0.8695652173913043, 0.6876543209876544, 0.2933333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.523888930656887, 0.0, 0.0, 0.8094621288201359, 0.1636552327199765, 0.1636552327199765, 0.25259895644444885], 
reward next is 0.7474, 
noisyNet noise sample is [array([1.3102461], dtype=float32), 0.7563701]. 
=============================================
[2019-03-24 06:58:39,930] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:58:39,940] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6964
[2019-03-24 06:58:39,948] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1514090.94765714 W.
[2019-03-24 06:58:39,955] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.53333333333333, 61.33333333333334, 1.0, 2.0, 0.6745485547866005, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9676376318937777, 6.911200000000001, 6.9112, 121.9260425452142, 1514090.94765714, 1514090.94765714, 306238.7440821697], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1779600.0000, 
sim time next is 1780200.0000, 
raw observation next is [26.9, 60.5, 1.0, 2.0, 0.6518512402030447, 1.0, 1.0, 0.6518512402030447, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156403, 1531466.617616575, 1531466.617616575, 288468.9227334434], 
processed observation next is [1.0, 0.6086956521739131, 0.5518518518518518, 0.605, 1.0, 1.0, 0.5855371907179104, 1.0, 0.5, 0.5855371907179104, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288199932, 0.546952363434491, 0.546952363434491, 0.5547479283335449], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0062038], dtype=float32), -0.2944063]. 
=============================================
[2019-03-24 06:58:40,910] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 7.7620436e-34 0.0000000e+00 2.9793671e-34 1.5543842e-35], sum to 1.0000
[2019-03-24 06:58:40,918] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9354
[2019-03-24 06:58:40,925] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.9, 74.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6459702124614316, 6.911200000000001, 6.9112, 121.9260426156618, 480758.9306342688, 480758.9306342684, 135804.6962814668], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1561200.0000, 
sim time next is 1561800.0000, 
raw observation next is [21.8, 75.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6453531860948983, 6.911200000000001, 6.9112, 121.9260426156618, 480284.6345435274, 480284.6345435269, 135730.0789385446], 
processed observation next is [1.0, 0.043478260869565216, 0.362962962962963, 0.7533333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5566914826186229, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17153022662268835, 0.1715302266226882, 0.26101938257412427], 
reward next is 0.7390, 
noisyNet noise sample is [array([0.08967625], dtype=float32), -0.188035]. 
=============================================
[2019-03-24 06:58:44,066] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 7.1472247e-38 0.0000000e+00 4.2031115e-38 0.0000000e+00], sum to 1.0000
[2019-03-24 06:58:44,070] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3230
[2019-03-24 06:58:44,074] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.0, 77.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6073640758981997, 6.9112, 6.9112, 121.9260426156618, 450479.8554143075, 450479.8554143075, 130846.2251981117], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1796400.0000, 
sim time next is 1797000.0000, 
raw observation next is [20.55, 78.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5960834758529725, 6.911200000000001, 6.9112, 121.9260426156618, 440992.6051865852, 440992.6051865847, 129076.2986906397], 
processed observation next is [1.0, 0.8260869565217391, 0.3166666666666667, 0.7833333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.49510434481621557, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.157497358995209, 0.1574973589952088, 0.24822365132815327], 
reward next is 0.7518, 
noisyNet noise sample is [array([-0.25674593], dtype=float32), -1.9519391]. 
=============================================
[2019-03-24 06:58:44,104] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[57.748367]
 [57.793983]
 [57.80505 ]
 [57.93197 ]
 [58.3963  ]], R is [[57.57912827]
 [57.75170898]
 [57.91902161]
 [58.08071518]
 [58.23596191]].
[2019-03-24 06:58:46,317] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:58:46,325] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3284
[2019-03-24 06:58:46,329] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.83333333333334, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6305757176049026, 6.9112, 6.9112, 121.9260426156618, 469865.1844885266, 469865.1844885266, 134814.2819036912], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1905600.0000, 
sim time next is 1906200.0000, 
raw observation next is [19.75, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6253302616733502, 6.911200000000001, 6.9112, 121.9260426156618, 465733.599980825, 465733.5999808246, 134075.1682105939], 
processed observation next is [1.0, 0.043478260869565216, 0.28703703703703703, 0.92, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5316628270916877, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16633342856458036, 0.16633342856458022, 0.2578368619434498], 
reward next is 0.7422, 
noisyNet noise sample is [array([0.32214364], dtype=float32), 0.5412917]. 
=============================================
[2019-03-24 06:58:48,089] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.8281175e-30 9.7236743e-36 1.1070137e-29 4.6130451e-31], sum to 1.0000
[2019-03-24 06:58:48,164] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5110
[2019-03-24 06:58:48,177] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 708566.5709169958 W.
[2019-03-24 06:58:48,182] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.66666666666667, 74.0, 1.0, 2.0, 0.2852488664631584, 0.0, 1.0, 0.0, 1.0, 2.0, 0.4746440481756411, 6.911199999999999, 6.9112, 121.9260426156618, 708566.5709169958, 708566.5709169962, 187897.846278666], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1687200.0000, 
sim time next is 1687800.0000, 
raw observation next is [21.83333333333334, 73.5, 1.0, 2.0, 0.1928265019550165, 1.0, 1.0, 0.1928265019550165, 1.0, 2.0, 0.3183715377041497, 6.9112, 6.9112, 121.94756008, 713731.5876769688, 713731.5876769688, 216409.8813882532], 
processed observation next is [1.0, 0.5217391304347826, 0.36419753086419776, 0.735, 1.0, 1.0, 0.03907916899406725, 1.0, 0.5, 0.03907916899406725, 1.0, 1.0, 0.14796442213018712, 0.0, 0.0, 0.8096049824067558, 0.2549041384560603, 0.2549041384560603, 0.41617284882356387], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.06056766], dtype=float32), 0.96196705]. 
=============================================
[2019-03-24 06:58:49,624] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:58:49,634] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3215
[2019-03-24 06:58:49,639] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7228245250151966, 6.9112, 6.9112, 121.9260426156618, 539973.681980095, 539973.681980095, 148301.3415749744], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1713600.0000, 
sim time next is 1714200.0000, 
raw observation next is [22.91666666666667, 79.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7211544799282898, 6.911200000000001, 6.9112, 121.9260426156618, 538760.8700817021, 538760.8700817017, 148021.7660199812], 
processed observation next is [1.0, 0.8695652173913043, 0.4043209876543212, 0.7900000000000001, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6514430999103623, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19241459645775075, 0.1924145964577506, 0.2846572423461177], 
reward next is 0.7153, 
noisyNet noise sample is [array([1.2814274], dtype=float32), 0.28690293]. 
=============================================
[2019-03-24 06:58:52,559] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 3.7508702e-36 0.0000000e+00 1.3862882e-37 5.2639653e-38], sum to 1.0000
[2019-03-24 06:58:52,570] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5653
[2019-03-24 06:58:52,582] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1570159.34986282 W.
[2019-03-24 06:58:52,585] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.4, 63.0, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.59204366987, 6.9112, 121.9232416997742, 1570159.34986282, 1221514.54711327, 248589.5006838149], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1789200.0000, 
sim time next is 1789800.0000, 
raw observation next is [25.95, 64.16666666666667, 1.0, 2.0, 0.3279931586899562, 1.0, 1.0, 0.3279931586899562, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9256326228777, 780612.2429451086, 780612.242945109, 188777.5263818134], 
processed observation next is [1.0, 0.7391304347826086, 0.5166666666666666, 0.6416666666666667, 1.0, 1.0, 0.1999918555832812, 1.0, 0.5, 0.1999918555832812, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.809459406894412, 0.2787900867661102, 0.2787900867661104, 0.3630337045804104], 
reward next is 0.6370, 
noisyNet noise sample is [array([0.9816616], dtype=float32), 0.061094858]. 
=============================================
[2019-03-24 06:58:53,542] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 3.3644173e-34 0.0000000e+00 3.1097768e-32 5.3713680e-32], sum to 1.0000
[2019-03-24 06:58:53,547] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1041
[2019-03-24 06:58:53,557] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1514058.233641424 W.
[2019-03-24 06:58:53,561] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.53333333333333, 61.33333333333334, 1.0, 2.0, 0.6759742772604893, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9689181201049658, 6.911200000000001, 6.9112, 121.9260425453159, 1514058.233641424, 1514058.233641424, 306873.1332663217], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1779600.0000, 
sim time next is 1780200.0000, 
raw observation next is [26.9, 60.5, 1.0, 2.0, 0.4396635989227714, 1.0, 1.0, 0.4396635989227714, 1.0, 2.0, 0.7013962336086976, 6.9112, 6.9112, 121.94756008, 1531502.7112203, 1531502.7112203, 314995.435883087], 
processed observation next is [1.0, 0.6086956521739131, 0.5518518518518518, 0.605, 1.0, 1.0, 0.33293285586044213, 1.0, 0.5, 0.33293285586044213, 1.0, 1.0, 0.626745292010872, 0.0, 0.0, 0.8096049824067558, 0.54696525400725, 0.54696525400725, 0.6057604536213211], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.74810964], dtype=float32), 1.1648335]. 
=============================================
[2019-03-24 06:58:55,297] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 06:58:55,304] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6042
[2019-03-24 06:58:55,314] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.33333333333334, 91.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5505985164135264, 6.911200000000001, 6.9112, 121.9260426156618, 403860.1874726863, 403860.1874726859, 123133.3815687907], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1819200.0000, 
sim time next is 1819800.0000, 
raw observation next is [18.3, 91.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5485337557566811, 6.9112, 6.9112, 121.9260426156618, 402263.365647319, 402263.365647319, 122918.1044487839], 
processed observation next is [1.0, 0.043478260869565216, 0.23333333333333336, 0.915, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4356671946958513, 0.0, 0.0, 0.8094621288201359, 0.14366548773118537, 0.14366548773118537, 0.23638097009381517], 
reward next is 0.7636, 
noisyNet noise sample is [array([-1.3683406], dtype=float32), -1.1790127]. 
=============================================
[2019-03-24 06:59:02,550] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-24 06:59:02,551] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 06:59:02,551] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 06:59:02,551] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:59:02,552] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:59:02,553] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 06:59:02,553] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 06:59:02,556] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:59:02,556] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:59:02,555] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 06:59:02,559] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 06:59:02,575] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run54
[2019-03-24 06:59:02,605] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run54
[2019-03-24 06:59:02,606] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run54
[2019-03-24 06:59:02,606] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run54
[2019-03-24 06:59:02,682] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run54
[2019-03-24 06:59:04,231] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00818074], dtype=float32), 0.017965265]
[2019-03-24 06:59:04,233] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.24325126666666, 52.71499802333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8470378426900618, 6.9112, 6.9112, 121.9260426156618, 629184.2757039185, 629184.2757039185, 156534.2474414453]
[2019-03-24 06:59:04,234] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:59:04,237] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.558214090306334
[2019-03-24 06:59:19,298] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00818074], dtype=float32), 0.017965265]
[2019-03-24 06:59:19,300] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.4, 23.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6105674938024342, 6.911199999999999, 6.9112, 121.9260426156618, 443030.7135503388, 443030.7135503392, 126415.2964600786]
[2019-03-24 06:59:19,301] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:59:19,303] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.9127547470967641
[2019-03-24 06:59:21,417] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00818074], dtype=float32), 0.017965265]
[2019-03-24 06:59:21,418] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [35.66666666666666, 19.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.687830878341639, 6.9112, 6.9112, 121.9260426156618, 512914.0907845943, 512914.0907845943, 141047.5258831993]
[2019-03-24 06:59:21,420] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:59:21,424] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.6430433065010925
[2019-03-24 06:59:27,015] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00818074], dtype=float32), 0.017965265]
[2019-03-24 06:59:27,017] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.66666666666667, 66.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8372140972170159, 6.9112, 6.9112, 121.9260426156618, 619101.6683038916, 619101.6683038916, 166098.0189944232]
[2019-03-24 06:59:27,019] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 06:59:27,021] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.6482602882368602
[2019-03-24 06:59:39,983] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00818074], dtype=float32), 0.017965265]
[2019-03-24 06:59:39,984] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.508583525, 82.15545926499999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6730049417006944, 6.9112, 6.9112, 121.9260426156618, 502904.1982670021, 502904.1982670021, 141569.3970319226]
[2019-03-24 06:59:39,985] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 06:59:39,987] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.24670027847774068
[2019-03-24 06:59:47,486] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00818074], dtype=float32), 0.017965265]
[2019-03-24 06:59:47,487] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.5, 68.5, 1.0, 2.0, 0.7294878242580585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 831427.9835502367, 831427.9835502367, 181806.0235355271]
[2019-03-24 06:59:47,489] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 06:59:47,495] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.030590520504989227
[2019-03-24 06:59:47,496] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 831427.9835502367 W.
[2019-03-24 07:00:02,087] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00818074], dtype=float32), 0.017965265]
[2019-03-24 07:00:02,087] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.04843588, 84.906266575, 1.0, 2.0, 0.5608711173458876, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8951117417681872, 6.911199999999999, 6.9112, 121.9260426156618, 1304878.135890363, 1304878.135890363, 278493.2167454516]
[2019-03-24 07:00:02,090] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:00:02,093] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.25603657156231896
[2019-03-24 07:00:02,094] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1304878.135890363 W.
[2019-03-24 07:00:13,517] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00818074], dtype=float32), 0.017965265]
[2019-03-24 07:00:13,519] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.32704349, 105.8746096916667, 1.0, 2.0, 0.7371479421846375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 840163.3275825838, 840163.3275825838, 183292.8529195068]
[2019-03-24 07:00:13,520] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:00:13,524] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.8659645758741327
[2019-03-24 07:00:13,526] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 840163.3275825838 W.
[2019-03-24 07:00:43,929] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00818074], dtype=float32), 0.017965265]
[2019-03-24 07:00:43,931] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.9341695, 99.47392666, 1.0, 2.0, 0.704451169263102, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 834691.2726374808, 834691.2726374808, 178472.0528016972]
[2019-03-24 07:00:43,932] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:00:43,935] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.9002944007024178
[2019-03-24 07:00:43,936] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 834691.2726374808 W.
[2019-03-24 07:00:50,723] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 07:00:51,178] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 07:00:51,203] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 07:00:51,233] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 07:00:51,281] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 07:00:52,298] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1325000, evaluation results [1325000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 07:00:56,685] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:00:56,691] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9179
[2019-03-24 07:00:56,696] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.5, 64.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.839821792305207, 6.9112, 6.9112, 121.9260426156618, 618403.9938132049, 618403.9938132049, 167226.8667354549], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2035200.0000, 
sim time next is 2035800.0000, 
raw observation next is [27.65, 64.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8461780905073077, 6.9112, 6.9112, 121.9260426156618, 622437.6532588879, 622437.6532588879, 168202.185297433], 
processed observation next is [0.0, 0.5652173913043478, 0.5796296296296296, 0.64, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8077226131341347, 0.0, 0.0, 0.8094621288201359, 0.22229916187817425, 0.22229916187817425, 0.3234657409566019], 
reward next is 0.6765, 
noisyNet noise sample is [array([1.0419188], dtype=float32), 1.5694903]. 
=============================================
[2019-03-24 07:00:56,872] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 7.3869724e-37 0.0000000e+00 8.6320585e-38 5.9408091e-37], sum to 1.0000
[2019-03-24 07:00:56,882] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5741
[2019-03-24 07:00:56,891] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 696267.4917137761 W.
[2019-03-24 07:00:56,894] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.36666666666667, 72.33333333333334, 1.0, 2.0, 0.3054764984428471, 1.0, 2.0, 0.3054764984428471, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 696267.4917137761, 696267.4917137766, 181780.0735063647], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2056800.0000, 
sim time next is 2057400.0000, 
raw observation next is [27.25, 73.0, 1.0, 2.0, 0.3052642697794505, 1.0, 2.0, 0.3052642697794505, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 695783.5429316659, 695783.5429316664, 181728.7492058882], 
processed observation next is [0.0, 0.8260869565217391, 0.5648148148148148, 0.73, 1.0, 1.0, 0.1729336544993458, 1.0, 1.0, 0.1729336544993458, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24849412247559496, 0.24849412247559513, 0.34947836385747727], 
reward next is 0.6505, 
noisyNet noise sample is [array([-0.9238872], dtype=float32), 0.19566631]. 
=============================================
[2019-03-24 07:01:00,677] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:01:00,683] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4627
[2019-03-24 07:01:00,695] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.6, 69.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9214593968607446, 6.911199999999999, 6.9112, 121.9260426156618, 669696.623121961, 669696.6231219615, 179649.4819146286], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2115000.0000, 
sim time next is 2115600.0000, 
raw observation next is [27.8, 68.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9234667125949284, 6.911199999999999, 6.9112, 121.9260426156618, 670868.8605968608, 670868.8605968612, 179966.4440065673], 
processed observation next is [0.0, 0.4782608695652174, 0.5851851851851853, 0.68, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9043333907436604, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.239596021641736, 0.23959602164173616, 0.3460893153972448], 
reward next is 0.6539, 
noisyNet noise sample is [array([-1.0131358], dtype=float32), -1.0121853]. 
=============================================
[2019-03-24 07:01:00,962] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:01:00,967] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6271
[2019-03-24 07:01:00,972] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.41666666666666, 48.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8923191132587609, 6.9112, 6.9112, 121.9260426156618, 651761.4318267031, 651761.4318267031, 175177.2528523865], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2130600.0000, 
sim time next is 2131200.0000, 
raw observation next is [31.5, 48.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8891970894040333, 6.911200000000001, 6.9112, 121.9260426156618, 649802.0809638724, 649802.0809638719, 174703.1701819504], 
processed observation next is [0.0, 0.6956521739130435, 0.7222222222222222, 0.48, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8614963617550416, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23207217177281156, 0.2320721717728114, 0.33596763496528925], 
reward next is 0.6640, 
noisyNet noise sample is [array([1.2263774], dtype=float32), 0.26165068]. 
=============================================
[2019-03-24 07:01:04,166] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 7.8228092e-25 1.5751096e-26 1.6476339e-22 1.6755608e-22], sum to 1.0000
[2019-03-24 07:01:04,174] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7905
[2019-03-24 07:01:04,175] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2380094.944684874 W.
[2019-03-24 07:01:04,179] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.63333333333333, 83.66666666666667, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 9.286893064544891, 6.9112, 121.916247209853, 2380094.944684874, 1163625.496287364, 245583.6732302854], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2208000.0000, 
sim time next is 2208600.0000, 
raw observation next is [26.8, 83.0, 1.0, 2.0, 0.5426742136688718, 1.0, 1.0, 0.5426742136688718, 1.0, 1.0, 0.8639550218261203, 6.911200000000001, 6.9112, 121.94756008, 1856719.25688336, 1856719.25688336, 365027.4430316215], 
processed observation next is [1.0, 0.5652173913043478, 0.5481481481481482, 0.83, 1.0, 1.0, 0.4555645400819902, 1.0, 0.5, 0.4555645400819902, 1.0, 0.5, 0.8299437772826503, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6631140203154857, 0.6631140203154857, 0.7019758519838876], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.72513294], dtype=float32), -1.7687813]. 
=============================================
[2019-03-24 07:01:04,655] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.7430751e-26 1.0278162e-28 3.7823892e-24 6.1011575e-24], sum to 1.0000
[2019-03-24 07:01:04,662] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6517
[2019-03-24 07:01:04,678] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2101986.421153739 W.
[2019-03-24 07:01:04,684] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.3, 93.0, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 8.7333596926032, 6.9112, 121.9186069163354, 2101986.421153739, 1168934.701688362, 245899.6751888453], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2199600.0000, 
sim time next is 2200200.0000, 
raw observation next is [24.46666666666667, 92.33333333333333, 1.0, 2.0, 0.6907619484416753, 1.0, 1.0, 0.6907619484416753, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9249453352004, 1575345.063464987, 1575345.063464988, 300681.8906179292], 
processed observation next is [1.0, 0.4782608695652174, 0.46172839506172847, 0.9233333333333333, 1.0, 1.0, 0.6318594624305658, 1.0, 0.5, 0.6318594624305658, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094548440189635, 0.5626232369517811, 0.5626232369517814, 0.5782344050344793], 
reward next is 0.4218, 
noisyNet noise sample is [array([0.07783465], dtype=float32), 2.792771]. 
=============================================
[2019-03-24 07:01:08,531] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 7.3621360e-36 0.0000000e+00 7.6898045e-35 8.2387323e-34], sum to 1.0000
[2019-03-24 07:01:08,541] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3434
[2019-03-24 07:01:08,551] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1399449.785434434 W.
[2019-03-24 07:01:08,555] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.0, 80.0, 1.0, 2.0, 0.608696287336321, 1.0, 2.0, 0.608696287336321, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1399449.785434434, 1399449.785434434, 271609.5409607524], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2295000.0000, 
sim time next is 2295600.0000, 
raw observation next is [25.1, 79.66666666666667, 1.0, 2.0, 0.4126260456373733, 1.0, 2.0, 0.4126260456373733, 1.0, 1.0, 0.6569141029468287, 6.911199999999999, 6.9112, 121.94756008, 1411395.304810709, 1411395.30481071, 302657.2063627513], 
processed observation next is [1.0, 0.5652173913043478, 0.4851851851851852, 0.7966666666666667, 1.0, 1.0, 0.30074529242544445, 1.0, 1.0, 0.30074529242544445, 1.0, 0.5, 0.5711426286835358, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5040697517181104, 0.5040697517181107, 0.5820330891591371], 
reward next is 0.4180, 
noisyNet noise sample is [array([-1.2110626], dtype=float32), 0.06016892]. 
=============================================
[2019-03-24 07:01:11,336] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:01:11,342] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4003
[2019-03-24 07:01:11,348] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.96666666666667, 83.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7596587960566142, 6.911199999999999, 6.9112, 121.9260426156618, 566399.445040213, 566399.4450402134, 153998.0550423729], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2324400.0000, 
sim time next is 2325000.0000, 
raw observation next is [22.83333333333333, 84.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7577662783772883, 6.9112, 6.9112, 121.9260426156618, 565040.0534650126, 565040.0534650126, 153726.8389791882], 
processed observation next is [1.0, 0.9130434782608695, 0.4012345679012344, 0.8416666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6972078479716104, 0.0, 0.0, 0.8094621288201359, 0.20180001909464734, 0.20180001909464734, 0.29562853649843884], 
reward next is 0.7044, 
noisyNet noise sample is [array([1.4171381], dtype=float32), 0.82048595]. 
=============================================
[2019-03-24 07:01:11,363] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[71.562355]
 [71.53819 ]
 [71.32369 ]
 [71.71143 ]
 [71.2662  ]], R is [[71.57783508]
 [71.56591034]
 [71.55361176]
 [71.54103851]
 [71.52828979]].
[2019-03-24 07:01:13,261] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 1.5515441e-38 0.0000000e+00 1.7426789e-38 2.4403072e-38], sum to 1.0000
[2019-03-24 07:01:13,267] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2424
[2019-03-24 07:01:13,274] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1367045.492802781 W.
[2019-03-24 07:01:13,279] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.01666666666667, 37.0, 1.0, 2.0, 0.5708422004251212, 1.0, 1.0, 0.5708422004251212, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1367045.492802781, 1367045.492802781, 261016.0140755955], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2386200.0000, 
sim time next is 2386800.0000, 
raw observation next is [31.0, 37.0, 1.0, 2.0, 0.585706350667727, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9468937376618366, 6.911200000000001, 6.9112, 121.9260426156618, 1409204.99229655, 1409204.99229655, 286342.8840666687], 
processed observation next is [1.0, 0.6521739130434783, 0.7037037037037037, 0.37, 1.0, 1.0, 0.5067932746044369, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9336171720772957, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5032874972487679, 0.5032874972487679, 0.5506593924359013], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.18320252], dtype=float32), 1.3939362]. 
=============================================
[2019-03-24 07:01:16,636] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:01:16,642] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3908
[2019-03-24 07:01:16,648] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.6, 47.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.798166935184539, 6.9112, 6.9112, 121.9260426156618, 593195.0959225703, 593195.0959225703, 151301.935766727], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2446200.0000, 
sim time next is 2446800.0000, 
raw observation next is [27.16666666666667, 45.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7598200619162959, 6.911199999999999, 6.9112, 121.9260426156618, 565370.2354881595, 565370.2354881599, 147610.1193480384], 
processed observation next is [1.0, 0.30434782608695654, 0.5617283950617286, 0.4533333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6997750773953698, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20191794124577123, 0.2019179412457714, 0.28386561413084305], 
reward next is 0.7161, 
noisyNet noise sample is [array([-0.5248687], dtype=float32), -2.1851227]. 
=============================================
[2019-03-24 07:01:18,723] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:01:18,734] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6674
[2019-03-24 07:01:18,751] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1132522.189544983 W.
[2019-03-24 07:01:18,756] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [34.41666666666666, 23.0, 1.0, 2.0, 0.4626016304327616, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7576291060140283, 6.9112, 6.9112, 121.9260426156618, 1132522.189544983, 1132522.189544983, 241314.4719212172], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2466600.0000, 
sim time next is 2467200.0000, 
raw observation next is [34.53333333333333, 23.0, 1.0, 2.0, 0.4065301657405181, 1.0, 1.0, 0.4065301657405181, 1.0, 2.0, 0.6577362028086137, 6.911200000000001, 6.9112, 121.94756008, 1469110.879470896, 1469110.879470896, 299394.1753030489], 
processed observation next is [1.0, 0.5652173913043478, 0.8345679012345678, 0.23, 1.0, 1.0, 0.29348829254823583, 1.0, 0.5, 0.29348829254823583, 1.0, 1.0, 0.572170253510767, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5246824569538914, 0.5246824569538914, 0.5757580294289403], 
reward next is 0.4242, 
noisyNet noise sample is [array([-1.2547172], dtype=float32), -0.26393923]. 
=============================================
[2019-03-24 07:01:26,149] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:01:26,155] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3828
[2019-03-24 07:01:26,159] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.75, 96.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7318859192985672, 6.9112, 6.9112, 121.9260426156618, 546717.1905975307, 546717.1905975307, 149396.1279482763], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2608200.0000, 
sim time next is 2608800.0000, 
raw observation next is [20.7, 96.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7304096147429949, 6.9112, 6.9112, 121.9260426156618, 545647.7030752276, 545647.7030752276, 149147.5908391323], 
processed observation next is [0.0, 0.17391304347826086, 0.3222222222222222, 0.9666666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6630120184287436, 0.0, 0.0, 0.8094621288201359, 0.19487417966972412, 0.19487417966972412, 0.2868222900752544], 
reward next is 0.7132, 
noisyNet noise sample is [array([-0.12001727], dtype=float32), 0.36967343]. 
=============================================
[2019-03-24 07:01:28,737] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 7.5644001e-37 0.0000000e+00 1.0229226e-36 3.9643823e-37], sum to 1.0000
[2019-03-24 07:01:28,738] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9690
[2019-03-24 07:01:28,746] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 693045.5293783814 W.
[2019-03-24 07:01:28,750] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 76.0, 1.0, 2.0, 0.3026047170667925, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4818957579949747, 6.9112, 6.9112, 121.9260426156618, 693045.5293783814, 693045.5293783814, 195890.9994699274], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2658600.0000, 
sim time next is 2659200.0000, 
raw observation next is [26.33333333333334, 76.66666666666667, 1.0, 2.0, 0.5968920465472214, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 688882.8743650343, 688882.8743650343, 157962.7933461673], 
processed observation next is [0.0, 0.782608695652174, 0.5308641975308644, 0.7666666666666667, 1.0, 1.0, 0.5201095792228826, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24602959798751226, 0.24602959798751226, 0.3037746025887833], 
reward next is 0.6962, 
noisyNet noise sample is [array([-0.13210365], dtype=float32), 1.5940291]. 
=============================================
[2019-03-24 07:01:33,131] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 2.2507409e-24 1.0958350e-26 1.2635444e-23 1.9358620e-23], sum to 1.0000
[2019-03-24 07:01:33,141] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9977
[2019-03-24 07:01:33,150] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 738926.0391639645 W.
[2019-03-24 07:01:33,156] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.06666666666667, 92.0, 1.0, 2.0, 0.3241832543752563, 1.0, 1.0, 0.3241832543752563, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 738926.0391639645, 738926.0391639649, 186365.4736910673], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2938800.0000, 
sim time next is 2939400.0000, 
raw observation next is [25.05, 92.5, 1.0, 2.0, 0.6509688237675564, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 741893.2634871984, 741893.2634871984, 167068.2224854996], 
processed observation next is [1.0, 0.0, 0.48333333333333334, 0.925, 1.0, 1.0, 0.5844866949613766, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2649618798168566, 0.2649618798168566, 0.3212850432413454], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.29739928], dtype=float32), 0.38006473]. 
=============================================
[2019-03-24 07:01:36,495] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.3913349e-14 1.7239918e-17 4.9053961e-15 6.3021623e-15], sum to 1.0000
[2019-03-24 07:01:36,502] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4820
[2019-03-24 07:01:36,513] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2555357.691344259 W.
[2019-03-24 07:01:36,518] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.0, 63.0, 1.0, 2.0, 0.8664284059280838, 1.0, 2.0, 0.7465788649404765, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 122.0905245939559, 2555357.691344259, 2555357.69134426, 476997.9003623218], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2808600.0000, 
sim time next is 2809200.0000, 
raw observation next is [32.0, 63.00000000000001, 1.0, 2.0, 0.9104250217066885, 1.0, 2.0, 0.9104250217066885, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2076890.201276262, 2076890.201276262, 391497.8696639844], 
processed observation next is [1.0, 0.5217391304347826, 0.7407407407407407, 0.6300000000000001, 1.0, 1.0, 0.8933631210793911, 1.0, 1.0, 0.8933631210793911, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.7417465004558079, 0.7417465004558079, 0.7528805185845854], 
reward next is 0.2471, 
noisyNet noise sample is [array([-0.44759628], dtype=float32), -0.77101535]. 
=============================================
[2019-03-24 07:01:37,089] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 3.8931014e-17 3.8930066e-20 8.5065924e-17 3.5811457e-18], sum to 1.0000
[2019-03-24 07:01:37,096] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4173
[2019-03-24 07:01:37,107] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2308413.573988111 W.
[2019-03-24 07:01:37,111] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.86666666666667, 57.66666666666667, 1.0, 2.0, 1.011784510268924, 1.0, 2.0, 1.011784510268924, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9258597760853, 2308413.573988111, 2308413.573988111, 439039.4976917953], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2820000.0000, 
sim time next is 2820600.0000, 
raw observation next is [32.9, 58.0, 1.0, 2.0, 0.6816181805071574, 1.0, 2.0, 0.6541737522300134, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2238684.700179027, 2238684.700179027, 424337.0913381064], 
processed observation next is [1.0, 0.6521739130434783, 0.774074074074074, 0.58, 1.0, 1.0, 0.6209740244132826, 1.0, 1.0, 0.5883020859881112, 1.0, 0.5, 0.9972168686025908, 0.0, 0.0, 0.8096049824067558, 0.7995302500639382, 0.7995302500639382, 0.8160328679578969], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7654695], dtype=float32), 2.209266]. 
=============================================
[2019-03-24 07:01:38,160] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.8508205e-19 4.5561753e-22 1.9346774e-19 4.1050011e-20], sum to 1.0000
[2019-03-24 07:01:38,164] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6141
[2019-03-24 07:01:38,173] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 785008.6863980165 W.
[2019-03-24 07:01:38,177] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.0, 100.0, 1.0, 2.0, 0.2251846097575518, 1.0, 1.0, 0.2251846097575518, 1.0, 1.0, 0.3593260388830458, 6.911199999999999, 6.9112, 121.94756008, 785008.6863980165, 785008.686398017, 228968.4135439246], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2862000.0000, 
sim time next is 2862600.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.3984248271570786, 1.0, 2.0, 0.3984248271570786, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 928314.2604680136, 928314.260468014, 206686.78152096], 
processed observation next is [1.0, 0.13043478260869565, 0.37037037037037035, 1.0, 1.0, 1.0, 0.2838390799489031, 1.0, 1.0, 0.2838390799489031, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.33154080731000485, 0.331540807310005, 0.397474579848], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.11162113], dtype=float32), -0.42107165]. 
=============================================
[2019-03-24 07:01:40,795] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-24 07:01:40,798] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:01:40,798] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:01:40,799] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:01:40,800] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:01:40,799] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:01:40,800] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:01:40,800] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:01:40,803] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:01:40,802] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:01:40,803] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:01:40,821] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run55
[2019-03-24 07:01:40,847] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run55
[2019-03-24 07:01:40,848] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run55
[2019-03-24 07:01:40,873] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run55
[2019-03-24 07:01:40,874] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run55
[2019-03-24 07:02:42,350] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00853717], dtype=float32), 0.01734017]
[2019-03-24 07:02:42,352] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.0, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8945382220087654, 6.9112, 6.9112, 121.9260426156618, 653769.7975889391, 653769.7975889391, 175398.0412242922]
[2019-03-24 07:02:42,353] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:02:42,359] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 2.3655228e-32 1.7010577e-37 4.5425466e-32 4.1687294e-32], sampled 0.3886109489149847
[2019-03-24 07:02:42,430] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00853717], dtype=float32), 0.01734017]
[2019-03-24 07:02:42,432] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.8, 72.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8256765478129516, 6.9112, 6.9112, 121.9260426156618, 609852.4770330568, 609852.4770330568, 164899.4376233942]
[2019-03-24 07:02:42,434] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:02:42,436] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 2.2753621e-31 2.2758163e-36 4.1739350e-31 3.9680561e-31], sampled 0.9603354193549811
[2019-03-24 07:02:43,155] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00853717], dtype=float32), 0.01734017]
[2019-03-24 07:02:43,155] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.785631186009043, 6.9112, 6.9112, 121.9260426156618, 585090.7789500315, 585090.7789500315, 157646.2218834291]
[2019-03-24 07:02:43,156] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:02:43,158] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 2.2506997e-30 3.3020994e-35 4.0465526e-30 3.9016392e-30], sampled 0.10208420651892702
[2019-03-24 07:02:53,817] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00853717], dtype=float32), 0.01734017]
[2019-03-24 07:02:53,819] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.66666666666666, 66.0, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.659537663260437, 6.9112, 121.923131701303, 1546285.690430536, 1163079.070236596, 245588.8751749409]
[2019-03-24 07:02:53,820] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:02:53,822] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 9.8464540e-26 9.4816571e-30 1.5426959e-25 1.5854549e-25], sampled 0.21792377023656906
[2019-03-24 07:02:53,822] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1546285.690430536 W.
[2019-03-24 07:03:21,465] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00853717], dtype=float32), 0.01734017]
[2019-03-24 07:03:21,466] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [19.35, 95.0, 1.0, 2.0, 0.6452197996129589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 804938.6865809015, 804938.6865809006, 168630.9595799681]
[2019-03-24 07:03:21,467] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:03:21,473] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 5.1950573e-25 7.6824978e-29 8.6288229e-25 8.6618357e-25], sampled 0.20019264982762752
[2019-03-24 07:03:21,475] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 804938.6865809015 W.
[2019-03-24 07:03:29,363] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 07:03:29,565] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 07:03:29,605] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 07:03:29,716] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 07:03:29,836] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 07:03:30,853] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1350000, evaluation results [1350000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 07:03:33,576] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 2.8223134e-20 8.9152812e-23 2.3953577e-20 2.2460722e-19], sum to 1.0000
[2019-03-24 07:03:33,580] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5316
[2019-03-24 07:03:33,586] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 861588.9616330866 W.
[2019-03-24 07:03:33,589] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.95, 93.33333333333334, 1.0, 2.0, 0.7559359433897281, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 861588.9616330866, 861588.9616330866, 186999.4167723733], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2952600.0000, 
sim time next is 2953200.0000, 
raw observation next is [24.9, 92.66666666666667, 1.0, 2.0, 0.2378985605274696, 1.0, 1.0, 0.2378985605274696, 1.0, 1.0, 0.3787422561749448, 6.9112, 6.9112, 121.94756008, 813419.38665119, 813419.38665119, 233375.294663549], 
processed observation next is [1.0, 0.17391304347826086, 0.47777777777777775, 0.9266666666666667, 1.0, 1.0, 0.09273638158032095, 1.0, 0.5, 0.09273638158032095, 1.0, 0.5, 0.22342782021868096, 0.0, 0.0, 0.8096049824067558, 0.29050692380399645, 0.29050692380399645, 0.44879864358374805], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.4957457], dtype=float32), -2.371612]. 
=============================================
[2019-03-24 07:03:40,169] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 9.1017724e-23 6.8402154e-26 2.5698508e-22 4.2643527e-23], sum to 1.0000
[2019-03-24 07:03:40,170] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3357
[2019-03-24 07:03:40,173] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 788150.4154580106 W.
[2019-03-24 07:03:40,181] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.66666666666667, 77.33333333333334, 1.0, 2.0, 0.6915359676898594, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 788150.4154580106, 788150.4154580106, 174546.6911843207], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3097200.0000, 
sim time next is 3097800.0000, 
raw observation next is [28.0, 74.5, 1.0, 2.0, 0.2282235465670633, 1.0, 1.0, 0.2282235465670633, 1.0, 1.0, 0.3633393188567712, 6.9112, 6.9112, 121.94756008, 780321.8800144176, 780321.8800144176, 230036.2029581486], 
processed observation next is [1.0, 0.8695652173913043, 0.5925925925925926, 0.745, 1.0, 1.0, 0.08121850781793251, 1.0, 0.5, 0.08121850781793251, 1.0, 0.5, 0.20417414857096394, 0.0, 0.0, 0.8096049824067558, 0.2786863857194348, 0.2786863857194348, 0.442377313381055], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.176869], dtype=float32), 0.083422974]. 
=============================================
[2019-03-24 07:03:40,970] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.00000000e+00 3.83605410e-30 3.12296936e-34 1.06162796e-29
 3.78799635e-29], sum to 1.0000
[2019-03-24 07:03:40,980] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9353
[2019-03-24 07:03:40,984] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.0, 58.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8133705972667564, 6.9112, 6.9112, 121.9260426156618, 602888.503701165, 602888.503701165, 162565.6790697958], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3113400.0000, 
sim time next is 3114000.0000, 
raw observation next is [28.0, 58.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8131142705464163, 6.9112, 6.9112, 121.9260426156618, 602698.475924039, 602698.475924039, 162533.2312594236], 
processed observation next is [1.0, 0.043478260869565216, 0.5925925925925926, 0.58, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7663928381830204, 0.0, 0.0, 0.8094621288201359, 0.21524945568715678, 0.21524945568715678, 0.3125639062681223], 
reward next is 0.6874, 
noisyNet noise sample is [array([1.1905388], dtype=float32), 0.8269897]. 
=============================================
[2019-03-24 07:03:41,003] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[41.672215]
 [41.921024]
 [41.53547 ]
 [41.462193]
 [41.56242 ]], R is [[41.77718353]
 [42.04678726]
 [42.31353378]
 [42.57731628]
 [42.83805847]].
[2019-03-24 07:03:44,165] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 4.5137136e-26 1.4924645e-30 4.7987235e-26 3.1722950e-26], sum to 1.0000
[2019-03-24 07:03:44,174] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8514
[2019-03-24 07:03:44,179] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1438167.569077451 W.
[2019-03-24 07:03:44,183] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.0, 43.0, 1.0, 2.0, 0.4145475293166621, 1.0, 1.0, 0.4145475293166621, 1.0, 2.0, 0.6608755598737625, 6.911199999999998, 6.9112, 121.94756008, 1438167.569077451, 1438167.569077452, 303599.3406390938], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3146400.0000, 
sim time next is 3147000.0000, 
raw observation next is [31.31666666666667, 41.16666666666667, 1.0, 2.0, 0.9145924074289354, 0.0, 1.0, 0.0, 1.0, 2.0, 0.974106480419188, 6.911200000000001, 6.9112, 121.9260426156618, 1787955.531145647, 1787955.531145646, 356036.1675296425], 
processed observation next is [1.0, 0.43478260869565216, 0.7154320987654322, 0.41166666666666674, 1.0, 1.0, 0.8983242945582565, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9676331005239849, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6385555468377311, 0.6385555468377307, 0.6846849375570049], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7305239], dtype=float32), -0.6926275]. 
=============================================
[2019-03-24 07:03:44,194] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[36.677002]
 [36.435818]
 [36.075157]
 [36.077934]
 [35.50247 ]], R is [[35.56364059]
 [35.62416077]
 [35.70305252]
 [35.34602356]
 [35.4077034 ]].
[2019-03-24 07:03:45,304] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 7.2346506e-37 0.0000000e+00 4.4222361e-36 8.5565973e-36], sum to 1.0000
[2019-03-24 07:03:45,309] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7893
[2019-03-24 07:03:45,320] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.93333333333334, 48.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8776941959682886, 6.9112, 6.9112, 121.9260426156618, 640309.6037684492, 640309.6037684492, 173389.4597916236], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3180000.0000, 
sim time next is 3180600.0000, 
raw observation next is [31.4, 53.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9264726724328283, 6.911200000000001, 6.9112, 121.9260426156618, 668966.2982240412, 668966.2982240409, 180935.739314179], 
processed observation next is [1.0, 0.8260869565217391, 0.7185185185185184, 0.53, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9080908405410354, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23891653508001473, 0.2389165350800146, 0.3479533448349596], 
reward next is 0.6520, 
noisyNet noise sample is [array([-1.5315177], dtype=float32), -1.8160446]. 
=============================================
[2019-03-24 07:03:46,829] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:03:46,840] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7114
[2019-03-24 07:03:46,845] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.31666666666667, 91.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8021749666809606, 6.9112, 6.9112, 121.9260426156618, 596781.486130368, 596781.486130368, 160085.1925733421], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3211800.0000, 
sim time next is 3212400.0000, 
raw observation next is [22.63333333333333, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7956418608673923, 6.9112, 6.9112, 121.9260426156618, 592180.4627395145, 592180.4627395145, 159116.5388383117], 
processed observation next is [0.0, 0.17391304347826086, 0.393827160493827, 0.88, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7445523260842404, 0.0, 0.0, 0.8094621288201359, 0.2114930224069695, 0.2114930224069695, 0.3059933439198302], 
reward next is 0.6940, 
noisyNet noise sample is [array([-1.3657422], dtype=float32), -2.0056095]. 
=============================================
[2019-03-24 07:03:48,572] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:03:48,580] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3245
[2019-03-24 07:03:48,585] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.5, 60.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8051009748112145, 6.911199999999999, 6.9112, 121.9260426156618, 597322.82868348, 597322.8286834805, 161283.055776059], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3231000.0000, 
sim time next is 3231600.0000, 
raw observation next is [27.66666666666666, 59.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8075975838586077, 6.911200000000001, 6.9112, 121.9260426156618, 598987.7343990449, 598987.7343990445, 161678.2569738674], 
processed observation next is [0.0, 0.391304347826087, 0.5802469135802467, 0.5933333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7594969798232595, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21392419085680175, 0.21392419085680162, 0.31091972494974496], 
reward next is 0.6891, 
noisyNet noise sample is [array([-1.425812], dtype=float32), -0.99410295]. 
=============================================
[2019-03-24 07:03:49,260] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 2.8126421e-34 6.8471219e-37 7.4398705e-33 2.7177191e-32], sum to 1.0000
[2019-03-24 07:03:49,267] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5636
[2019-03-24 07:03:49,276] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2013791.207370857 W.
[2019-03-24 07:03:49,281] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.5, 86.5, 1.0, 2.0, 0.5885308618714814, 1.0, 2.0, 0.5885308618714814, 1.0, 1.0, 0.9369602992114439, 6.911200000000001, 6.9112, 121.94756008, 2013791.207370857, 2013791.207370856, 389162.0349278356], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3511800.0000, 
sim time next is 3512400.0000, 
raw observation next is [27.33333333333334, 85.66666666666667, 1.0, 2.0, 0.8718426840674488, 1.0, 2.0, 0.8718426840674488, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1988776.949993936, 1988776.949993936, 374335.9404047226], 
processed observation next is [1.0, 0.6521739130434783, 0.5679012345679014, 0.8566666666666667, 1.0, 1.0, 0.8474317667469629, 1.0, 1.0, 0.8474317667469629, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7102774821406914, 0.7102774821406914, 0.7198768084706203], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3837014], dtype=float32), -1.0070245]. 
=============================================
[2019-03-24 07:03:49,535] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:03:49,543] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0697
[2019-03-24 07:03:49,547] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [32.0, 41.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8245126828264089, 6.9112, 6.9112, 121.9260426156618, 610460.7773257686, 610460.7773257686, 164243.4518801529], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3250800.0000, 
sim time next is 3251400.0000, 
raw observation next is [32.16666666666667, 41.50000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8439436148431582, 6.911200000000001, 6.9112, 121.9260426156618, 624137.2053295939, 624137.2053295934, 166921.7239411797], 
processed observation next is [0.0, 0.6521739130434783, 0.7469135802469138, 0.4150000000000001, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8049295185539476, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22290614476056925, 0.22290614476056908, 0.3210033152714994], 
reward next is 0.6790, 
noisyNet noise sample is [array([0.78816354], dtype=float32), -0.8679888]. 
=============================================
[2019-03-24 07:04:03,316] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 1.3382404e-29 1.3709887e-31 1.4496411e-28 2.6339783e-28], sum to 1.0000
[2019-03-24 07:04:03,322] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6182
[2019-03-24 07:04:03,325] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.53333333333333, 88.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7796384459448275, 6.911199999999999, 6.9112, 121.9260426156618, 580428.4370370986, 580428.437037099, 157052.5896767046], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3547200.0000, 
sim time next is 3547800.0000, 
raw observation next is [22.8, 85.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7736389549867224, 6.911199999999999, 6.9112, 121.9260426156618, 576311.7512919304, 576311.7512919309, 156080.8195987671], 
processed observation next is [1.0, 0.043478260869565216, 0.4, 0.855, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7170486937334031, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20582562546140373, 0.2058256254614039, 0.30015542230532133], 
reward next is 0.6998, 
noisyNet noise sample is [array([0.5261644], dtype=float32), -0.37645704]. 
=============================================
[2019-03-24 07:04:05,407] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 2.1637240e-24 7.2743714e-27 5.2926522e-25 2.6104782e-23], sum to 1.0000
[2019-03-24 07:04:05,412] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3492
[2019-03-24 07:04:05,416] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.26666666666667, 93.33333333333334, 1.0, 2.0, 0.1766745112834346, 1.0, 2.0, 0.1766745112834346, 1.0, 2.0, 0.2825782177269239, 6.9112, 6.9112, 121.94756008, 621728.1056688621, 621728.1056688621, 212974.9278160428], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3570000.0000, 
sim time next is 3570600.0000, 
raw observation next is [22.08333333333333, 93.16666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8033943261587467, 6.911199999999999, 6.9112, 121.9260426156618, 595403.5353970369, 595403.5353970374, 161343.4175787715], 
processed observation next is [1.0, 0.30434782608695654, 0.3734567901234566, 0.9316666666666665, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.7542429076984333, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21264411978465605, 0.21264411978465622, 0.31027580303609903], 
reward next is 0.6897, 
noisyNet noise sample is [array([0.3261974], dtype=float32), -0.4631937]. 
=============================================
[2019-03-24 07:04:13,286] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 6.8753281e-17 8.6856231e-18 1.3092999e-16 2.4989977e-15], sum to 1.0000
[2019-03-24 07:04:13,293] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6706
[2019-03-24 07:04:13,297] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.6, 94.0, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 11.3377336509042, 6.9112, 121.9000842971317, 3430608.31164589, 1164310.045850777, 245586.6485270414], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3745200.0000, 
sim time next is 3745800.0000, 
raw observation next is [25.7, 94.0, 1.0, 2.0, 0.7315252701554181, 1.0, 1.0, 0.6791272970541437, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2324190.765678807, 2324190.765678807, 437818.8778825696], 
processed observation next is [1.0, 0.34782608695652173, 0.5074074074074074, 0.94, 1.0, 1.0, 0.6803872263754978, 1.0, 0.5, 0.6180086869692186, 1.0, 0.5, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.830068130599574, 0.830068130599574, 0.8419593805434031], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.2532067], dtype=float32), 0.6232293]. 
=============================================
[2019-03-24 07:04:16,301] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 1.8633183e-25 1.5051366e-27 2.6743101e-24 3.6479516e-24], sum to 1.0000
[2019-03-24 07:04:16,307] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0655
[2019-03-24 07:04:16,316] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2266961.432164517 W.
[2019-03-24 07:04:16,320] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.0, 47.0, 1.0, 2.0, 0.9936389543901072, 1.0, 2.0, 0.9936389543901072, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156302, 2266961.432164517, 2266961.432164517, 430265.7890495253], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3769200.0000, 
sim time next is 3769800.0000, 
raw observation next is [34.16666666666667, 46.16666666666667, 1.0, 2.0, 0.9866797687534946, 1.0, 2.0, 0.9866797687534946, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 2251064.214391697, 2251064.214391696, 426931.5219143773], 
processed observation next is [1.0, 0.6521739130434783, 0.8209876543209879, 0.4616666666666667, 1.0, 1.0, 0.9841425818493984, 1.0, 1.0, 0.9841425818493984, 0.0, 1.0, -0.25, 1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.8039515051398919, 0.8039515051398913, 0.8210221575276486], 
reward next is 0.1790, 
noisyNet noise sample is [array([-0.9339385], dtype=float32), 0.5112]. 
=============================================
[2019-03-24 07:04:19,493] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-24 07:04:19,493] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:04:19,494] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:04:19,495] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:04:19,497] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:04:19,496] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:04:19,499] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:04:19,500] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:04:19,501] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:04:19,502] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:04:19,502] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:04:19,526] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run56
[2019-03-24 07:04:19,551] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run56
[2019-03-24 07:04:19,552] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run56
[2019-03-24 07:04:19,580] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run56
[2019-03-24 07:04:19,580] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run56
[2019-03-24 07:04:38,997] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904883], dtype=float32), 0.017387664]
[2019-03-24 07:04:39,000] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.19214814666667, 50.47774348666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7793162193396984, 6.911199999999999, 6.9112, 121.9260426156618, 577139.5295641259, 577139.5295641264, 158509.2322770097]
[2019-03-24 07:04:39,001] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:04:39,003] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 2.2821354e-37 0.0000000e+00 6.8552759e-37 8.0776126e-37], sampled 0.018957004392335497
[2019-03-24 07:04:39,447] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904883], dtype=float32), 0.017387664]
[2019-03-24 07:04:39,448] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [32.16666666666667, 25.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6530540922742303, 6.911200000000001, 6.9112, 121.9260426156618, 484556.1246496861, 484556.1246496856, 135380.6411532239]
[2019-03-24 07:04:39,452] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:04:39,455] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.6816045e-38 1.8650341e-38], sampled 0.883368857937414
[2019-03-24 07:04:46,286] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904883], dtype=float32), 0.017387664]
[2019-03-24 07:04:46,288] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [18.73333333333333, 95.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5727600331555408, 6.911199999999999, 6.9112, 121.9260426156618, 424407.8466726198, 424407.8466726203, 127359.0709055683]
[2019-03-24 07:04:46,289] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:04:46,292] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 7.1883484e-38 0.0000000e+00 2.3946334e-37 2.6749759e-37], sampled 0.24618139191394084
[2019-03-24 07:05:03,240] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904883], dtype=float32), 0.017387664]
[2019-03-24 07:05:03,241] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.66666666666667, 74.66666666666667, 1.0, 2.0, 0.8195489200750213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156335, 947665.7165416266, 947665.7165416266, 200714.3321138374]
[2019-03-24 07:05:03,243] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:05:03,246] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 6.3327231e-29 3.3518523e-33 1.4916350e-28 1.7496419e-28], sampled 0.32668456779543575
[2019-03-24 07:05:03,247] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 947665.7165416266 W.
[2019-03-24 07:05:24,533] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904883], dtype=float32), 0.017387664]
[2019-03-24 07:05:24,534] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.16666666666667, 93.16666666666667, 1.0, 2.0, 0.6759829253545243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 770415.5502711849, 770415.5502711849, 171645.6613856204]
[2019-03-24 07:05:24,535] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:05:24,540] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.3521144e-31 2.6072861e-36 3.3964414e-31 4.2362376e-31], sampled 0.1600245885915671
[2019-03-24 07:05:24,541] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 770415.5502711849 W.
[2019-03-24 07:05:30,982] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904883], dtype=float32), 0.017387664]
[2019-03-24 07:05:30,982] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8147147623086514, 6.911199999999999, 6.9112, 121.9260426156618, 604167.5202988536, 604167.5202988541, 162618.794253152]
[2019-03-24 07:05:30,984] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:05:30,985] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 6.3102293e-35 0.0000000e+00 1.8256746e-34 2.0898591e-34], sampled 0.3429014839043443
[2019-03-24 07:05:58,613] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904883], dtype=float32), 0.017387664]
[2019-03-24 07:05:58,614] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.11692265, 85.23467701, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6022207881744079, 6.911199999999999, 6.9112, 121.9260426156618, 447066.8291558141, 447066.8291558145, 130639.9070130549]
[2019-03-24 07:05:58,615] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:05:58,618] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.8079030e-36 0.0000000e+00 5.7076683e-36 6.2948626e-36], sampled 0.42052838154612315
[2019-03-24 07:05:59,616] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904883], dtype=float32), 0.017387664]
[2019-03-24 07:05:59,617] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.76074121, 98.14882835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8190168179008384, 6.911199999999999, 6.9112, 121.9260426156618, 602490.5386717464, 602490.5386717469, 164731.9997356626]
[2019-03-24 07:05:59,619] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:05:59,623] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 4.4809382e-37 0.0000000e+00 1.4429374e-36 1.6097498e-36], sampled 0.806563304835776
[2019-03-24 07:06:08,202] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 07:06:08,568] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 07:06:08,612] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 07:06:08,692] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 07:06:08,715] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 07:06:09,731] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1375000, evaluation results [1375000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 07:06:14,530] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.0685825e-24 6.7742193e-30 5.7106405e-25 2.7921217e-23], sum to 1.0000
[2019-03-24 07:06:14,535] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8404
[2019-03-24 07:06:14,543] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 816826.1521088869 W.
[2019-03-24 07:06:14,550] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.75, 70.0, 1.0, 2.0, 0.3583415624769044, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5704914378331708, 6.9112, 6.9112, 121.9260426156618, 816826.1521088869, 816826.1521088869, 211596.5138343939], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3928200.0000, 
sim time next is 3928800.0000, 
raw observation next is [30.0, 70.0, 1.0, 2.0, 0.2408230989427984, 1.0, 1.0, 0.2408230989427984, 1.0, 2.0, 0.3833982165777151, 6.911199999999999, 6.9112, 121.94756008, 823424.2973613843, 823424.2973613846, 234394.9248965568], 
processed observation next is [0.0, 0.4782608695652174, 0.6666666666666666, 0.7, 1.0, 1.0, 0.09621797493190287, 1.0, 0.5, 0.09621797493190287, 1.0, 1.0, 0.22924777072214386, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2940801062004944, 0.2940801062004945, 0.4507594709549169], 
reward next is 0.5492, 
noisyNet noise sample is [array([-0.10202295], dtype=float32), 0.2741759]. 
=============================================
[2019-03-24 07:06:16,645] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 5.6645086e-27 5.7703607e-31 2.1348792e-25 1.0034034e-25], sum to 1.0000
[2019-03-24 07:06:16,652] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5160
[2019-03-24 07:06:16,656] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 796085.7445326438 W.
[2019-03-24 07:06:16,659] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.41666666666667, 84.0, 1.0, 2.0, 0.3492474701869404, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5560133467336392, 6.911199999999999, 6.9112, 121.9260426156618, 796085.7445326438, 796085.7445326443, 208955.8131739068], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3970200.0000, 
sim time next is 3970800.0000, 
raw observation next is [26.3, 83.0, 1.0, 2.0, 0.3431952196262043, 1.0, 1.0, 0.3431952196262043, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 782283.0129505999, 782283.0129506004, 191149.4184974747], 
processed observation next is [0.0, 1.0, 0.5296296296296297, 0.83, 1.0, 1.0, 0.21808954717405274, 1.0, 0.5, 0.21808954717405274, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2793867903395, 0.27938679033950015, 0.3675950355720667], 
reward next is 0.6324, 
noisyNet noise sample is [array([0.1348129], dtype=float32), 0.4262571]. 
=============================================
[2019-03-24 07:06:17,667] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 7.4927706e-23 3.2360741e-25 3.4858065e-22 2.1778710e-21], sum to 1.0000
[2019-03-24 07:06:17,673] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4997
[2019-03-24 07:06:17,681] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1046575.444812252 W.
[2019-03-24 07:06:17,685] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.61666666666667, 92.83333333333333, 1.0, 2.0, 0.9181275616879583, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1046575.444812252, 1046575.444812252, 221548.1589555832], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3995400.0000, 
sim time next is 3996000.0000, 
raw observation next is [24.6, 93.0, 1.0, 2.0, 0.4557705220831214, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7256015145659612, 6.911199999999999, 6.9112, 121.9260426156618, 1039062.369669316, 1039062.369669316, 241934.542397392], 
processed observation next is [1.0, 0.2608695652173913, 0.46666666666666673, 0.93, 1.0, 1.0, 0.35210776438466834, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.6570018932074514, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.37109370345332715, 0.37109370345332715, 0.4652587353796], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.28424913], dtype=float32), 1.5818774]. 
=============================================
[2019-03-24 07:06:17,700] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[31.937416]
 [32.229694]
 [31.847313]
 [31.95509 ]
 [31.766603]], R is [[32.00519562]
 [32.25909042]
 [32.4610939 ]
 [32.13648224]
 [31.81511688]].
[2019-03-24 07:06:22,496] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:06:22,502] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2444
[2019-03-24 07:06:22,505] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.1, 97.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7338178200039011, 6.9112, 6.9112, 121.9260426156618, 548340.6811479938, 548340.6811479938, 148079.1499824026], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4081200.0000, 
sim time next is 4081800.0000, 
raw observation next is [20.05, 98.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7235364836325285, 6.9112, 6.9112, 121.9260426156618, 540687.16215807, 540687.16215807, 147162.6294121782], 
processed observation next is [1.0, 0.21739130434782608, 0.29814814814814816, 0.9883333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6544206045406605, 0.0, 0.0, 0.8094621288201359, 0.19310255791359643, 0.19310255791359643, 0.2830050565618812], 
reward next is 0.7170, 
noisyNet noise sample is [array([-0.9564433], dtype=float32), 1.5658121]. 
=============================================
[2019-03-24 07:06:23,153] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 9.797611e-38 6.336881e-36], sum to 1.0000
[2019-03-24 07:06:23,159] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9275
[2019-03-24 07:06:23,166] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2015084.152049417 W.
[2019-03-24 07:06:23,169] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.0, 71.33333333333333, 1.0, 2.0, 0.5889082994298255, 1.0, 2.0, 0.5889082994298255, 1.0, 1.0, 0.9375611920966107, 6.911200000000001, 6.9112, 121.94756008, 2015084.152049417, 2015084.152049416, 389365.3891841951], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4117200.0000, 
sim time next is 4117800.0000, 
raw observation next is [29.0, 70.66666666666667, 1.0, 2.0, 0.5890221689119378, 1.0, 2.0, 0.5890221689119378, 1.0, 2.0, 0.9377424760206036, 6.9112, 6.9112, 121.94756008, 2015474.22207929, 2015474.22207929, 389426.7543885947], 
processed observation next is [1.0, 0.6521739130434783, 0.6296296296296297, 0.7066666666666667, 1.0, 1.0, 0.5107406772761164, 1.0, 1.0, 0.5107406772761164, 1.0, 1.0, 0.9221780950257543, 0.0, 0.0, 0.8096049824067558, 0.719812222171175, 0.719812222171175, 0.7488976045934513], 
reward next is 0.2511, 
noisyNet noise sample is [array([0.66920155], dtype=float32), 0.7690657]. 
=============================================
[2019-03-24 07:06:26,202] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:06:26,211] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6905
[2019-03-24 07:06:26,216] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.33333333333334, 91.50000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7929054445404793, 6.9112, 6.9112, 121.9260426156618, 589647.4828861657, 589647.4828861657, 159076.746517584], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4425000.0000, 
sim time next is 4425600.0000, 
raw observation next is [22.26666666666667, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7922318983918605, 6.911200000000001, 6.9112, 121.9260426156618, 589161.1846985806, 589161.1846985802, 158985.3698583283], 
processed observation next is [0.0, 0.21739130434782608, 0.38024691358024704, 0.92, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7402898729898255, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21041470882092167, 0.2104147088209215, 0.3057410958814006], 
reward next is 0.6943, 
noisyNet noise sample is [array([-0.04140532], dtype=float32), 0.68255323]. 
=============================================
[2019-03-24 07:06:31,743] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.1237372e-38], sum to 1.0000
[2019-03-24 07:06:31,748] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9314
[2019-03-24 07:06:31,753] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.06666666666667, 77.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6520628305615209, 6.9112, 6.9112, 121.9260426156618, 486699.003984089, 486699.003984089, 137969.0827717362], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4252800.0000, 
sim time next is 4253400.0000, 
raw observation next is [21.8, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6452807257989327, 6.911200000000001, 6.9112, 121.9260426156618, 481497.8439906183, 481497.8439906178, 137074.4005129382], 
processed observation next is [1.0, 0.21739130434782608, 0.362962962962963, 0.79, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5566009072486658, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1719635157109351, 0.17196351571093493, 0.26360461637103505], 
reward next is 0.7364, 
noisyNet noise sample is [array([-0.6125301], dtype=float32), -1.1301763]. 
=============================================
[2019-03-24 07:06:38,100] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 1.6256174e-26 2.5690575e-29 1.6652944e-23 1.0334561e-24], sum to 1.0000
[2019-03-24 07:06:38,106] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5857
[2019-03-24 07:06:38,112] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 703369.1158181584 W.
[2019-03-24 07:06:38,115] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.91666666666666, 78.83333333333334, 1.0, 2.0, 0.3076490697754582, 1.0, 1.0, 0.3076490697754582, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 703369.1158181584, 703369.1158181588, 182413.3712639387], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4399800.0000, 
sim time next is 4400400.0000, 
raw observation next is [25.63333333333333, 78.66666666666667, 1.0, 2.0, 0.2975888944615108, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4742964947177557, 6.911199999999999, 6.9112, 121.9260426156618, 686725.2346648632, 686725.2346648637, 194431.9498104359], 
processed observation next is [1.0, 0.9565217391304348, 0.5049382716049381, 0.7866666666666667, 1.0, 1.0, 0.16379630293037004, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.34287061839719457, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24525901238030828, 0.24525901238030845, 0.37390759578929983], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.19468132], dtype=float32), 0.4019623]. 
=============================================
[2019-03-24 07:06:43,941] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 5.5190833e-34 0.0000000e+00 4.9914595e-35 1.4031307e-32], sum to 1.0000
[2019-03-24 07:06:43,946] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8162
[2019-03-24 07:06:43,950] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.96666666666667, 92.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9367646987144012, 6.911200000000001, 6.9112, 121.9260426156618, 682265.0048275827, 682265.0048275823, 181506.1123408691], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4502400.0000, 
sim time next is 4503000.0000, 
raw observation next is [23.98333333333333, 93.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9453945862777159, 6.9112, 6.9112, 121.9260426156618, 687334.7762708185, 687334.7762708185, 182889.458418363], 
processed observation next is [0.0, 0.08695652173913043, 0.4438271604938271, 0.9333333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9317432328471448, 0.0, 0.0, 0.8094621288201359, 0.2454767058110066, 0.2454767058110066, 0.3517104969583904], 
reward next is 0.6483, 
noisyNet noise sample is [array([1.9299606], dtype=float32), 0.96200377]. 
=============================================
[2019-03-24 07:06:43,977] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[44.56818 ]
 [44.033733]
 [42.963776]
 [41.845642]
 [40.09284 ]], R is [[45.14254761]
 [45.34207535]
 [45.54184723]
 [45.74158096]
 [45.94083023]].
[2019-03-24 07:06:44,543] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:06:44,548] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2584
[2019-03-24 07:06:44,551] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.2, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.932094809256069, 6.9112, 6.9112, 121.9260426156618, 678714.7462341245, 678714.7462341245, 180892.3775134531], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4525200.0000, 
sim time next is 4525800.0000, 
raw observation next is [24.33333333333334, 90.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9398230535284579, 6.911200000000001, 6.9112, 121.9260426156618, 683203.0712258479, 683203.0712258475, 182134.7338345134], 
processed observation next is [0.0, 0.391304347826087, 0.4567901234567903, 0.9066666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9247788169105722, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24400109686637425, 0.24400109686637408, 0.3502591035279104], 
reward next is 0.6497, 
noisyNet noise sample is [array([0.54491997], dtype=float32), -1.2842788]. 
=============================================
[2019-03-24 07:06:48,344] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:06:48,352] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5510
[2019-03-24 07:06:48,356] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.26666666666667, 99.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.798695216805911, 6.911199999999999, 6.9112, 121.9260426156618, 594381.4311792044, 594381.4311792048, 159538.5885695428], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4598400.0000, 
sim time next is 4599000.0000, 
raw observation next is [21.2, 99.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7945441120530343, 6.911199999999999, 6.9112, 121.9260426156618, 591479.1175363577, 591479.1175363582, 158906.6490675669], 
processed observation next is [1.0, 0.21739130434782608, 0.34074074074074073, 0.995, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.743180140066293, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2112425419772706, 0.21124254197727077, 0.30558970974532096], 
reward next is 0.6944, 
noisyNet noise sample is [array([-0.06860847], dtype=float32), -0.019846864]. 
=============================================
[2019-03-24 07:06:48,370] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[65.50384 ]
 [65.407326]
 [66.148834]
 [66.3156  ]
 [66.42978 ]], R is [[65.08102417]
 [65.12340546]
 [65.15219879]
 [65.1931839 ]
 [65.22566223]].
[2019-03-24 07:06:58,668] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-24 07:06:58,670] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:06:58,670] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:06:58,671] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:06:58,674] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:06:58,675] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:06:58,677] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:06:58,677] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:06:58,678] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:06:58,679] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:06:58,680] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:06:58,703] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run57
[2019-03-24 07:06:58,729] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run57
[2019-03-24 07:06:58,756] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run57
[2019-03-24 07:06:58,757] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run57
[2019-03-24 07:06:58,781] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run57
[2019-03-24 07:07:37,633] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.017216168]
[2019-03-24 07:07:37,634] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.22377016, 78.076873155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8503019000184768, 6.9112, 6.9112, 121.9260426156618, 627215.9776060561, 627215.9776060561, 168245.8699874601]
[2019-03-24 07:07:37,638] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:07:37,641] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.5186963e-34 0.0000000e+00 3.6596829e-34 1.8595251e-34], sampled 0.9748008263989465
[2019-03-24 07:08:05,203] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.017216168]
[2019-03-24 07:08:05,206] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.2, 89.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6963560187523715, 6.911200000000001, 6.9112, 121.9260426156618, 520377.980622907, 520377.9806229065, 144510.18259831]
[2019-03-24 07:08:05,207] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:08:05,211] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.1036082e-34 0.0000000e+00 2.6770522e-34 1.2739235e-34], sampled 0.831153685768783
[2019-03-24 07:08:08,563] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.017216168]
[2019-03-24 07:08:08,563] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.5, 91.5, 1.0, 2.0, 0.8160938239423414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 930196.3898393563, 930196.3898393563, 199295.1949396227]
[2019-03-24 07:08:08,564] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:08:08,567] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 2.3167498e-28 6.4042791e-33 4.7197282e-28 3.0113585e-28], sampled 0.5961722466519286
[2019-03-24 07:08:08,569] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 930196.3898393563 W.
[2019-03-24 07:08:12,497] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.017216168]
[2019-03-24 07:08:12,498] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.825709705, 87.36072056, 1.0, 2.0, 0.5970770169919842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 702696.5783633613, 702696.5783633613, 158599.4153752114]
[2019-03-24 07:08:12,500] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:08:12,503] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 7.2590943e-28 2.2192549e-32 1.4761992e-27 8.6926395e-28], sampled 0.37675333869451355
[2019-03-24 07:08:12,505] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 702696.5783633613 W.
[2019-03-24 07:08:26,104] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.017216168]
[2019-03-24 07:08:26,106] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.953465105, 63.33717521666667, 1.0, 2.0, 0.7655489105653448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 872551.7174148142, 872551.7174148142, 188931.1164679682]
[2019-03-24 07:08:26,109] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:08:26,113] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.5103087e-25 1.4081894e-29 2.8260555e-25 2.0407639e-25], sampled 0.5781522412618147
[2019-03-24 07:08:26,116] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 872551.7174148142 W.
[2019-03-24 07:08:41,671] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.017216168]
[2019-03-24 07:08:41,672] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.70706834, 110.1156328, 1.0, 2.0, 0.9712443703839553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.108303088703141, 6.9112, 121.925122919718, 1234247.753637382, 1133314.116701838, 235274.8632140126]
[2019-03-24 07:08:41,673] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:08:41,677] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 7.4887626e-25 1.2519399e-28 1.4593984e-24 1.2610014e-24], sampled 0.16399909547902003
[2019-03-24 07:08:41,679] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1234247.753637382 W.
[2019-03-24 07:08:46,055] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.017216168]
[2019-03-24 07:08:46,056] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.0, 54.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7702404824621744, 6.911200000000001, 6.9112, 121.9260426156618, 575546.1148498863, 575546.1148498858, 153333.9485822551]
[2019-03-24 07:08:46,059] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:08:46,063] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.5751408e-32 7.3566819e-38 3.6150636e-32 1.8349486e-32], sampled 0.3554296317284169
[2019-03-24 07:08:47,675] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 07:08:47,728] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 07:08:47,855] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 07:08:47,860] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 07:08:48,217] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 07:08:49,237] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1400000, evaluation results [1400000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 07:08:58,770] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 3.1159874e-17 8.2758702e-19 5.7448805e-17 8.8267196e-16], sum to 1.0000
[2019-03-24 07:08:58,776] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5467
[2019-03-24 07:08:58,784] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 730769.4565918633 W.
[2019-03-24 07:08:58,788] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.33333333333333, 81.66666666666667, 1.0, 2.0, 0.2105101735911341, 1.0, 2.0, 0.2105101735911341, 1.0, 2.0, 0.3356552655326585, 6.911200000000001, 6.9112, 121.94756008, 730769.4565918633, 730769.4565918628, 224048.209178606], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4952400.0000, 
sim time next is 4953000.0000, 
raw observation next is [24.41666666666667, 79.83333333333333, 1.0, 2.0, 0.2842608818328679, 0.0, 1.0, 0.0, 1.0, 2.0, 0.4549377298363635, 6.911199999999999, 6.9112, 121.9260426156618, 668279.8510557725, 668279.851055773, 190489.4996737072], 
processed observation next is [1.0, 0.30434782608695654, 0.4598765432098767, 0.7983333333333333, 1.0, 1.0, 0.14792962122960465, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.3186721622954543, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23867137537706162, 0.2386713753770618, 0.3663259609109754], 
reward next is 0.6337, 
noisyNet noise sample is [array([-1.1802994], dtype=float32), 1.5474442]. 
=============================================
[2019-03-24 07:08:58,805] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[24.144121]
 [24.268465]
 [24.24061 ]
 [23.992273]
 [23.167109]], R is [[24.89859772]
 [25.21875   ]
 [25.49966049]
 [25.24466324]
 [25.67097664]].
[2019-03-24 07:09:01,522] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 5.6867784e-30 6.6315548e-35 1.9397592e-29 3.2583361e-31], sum to 1.0000
[2019-03-24 07:09:01,529] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2042
[2019-03-24 07:09:01,535] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 692687.7997011286 W.
[2019-03-24 07:09:01,539] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 94.16666666666667, 1.0, 2.0, 0.5998795132292132, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 692687.7997011286, 692687.7997011286, 158494.6556769355], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5004600.0000, 
sim time next is 5005200.0000, 
raw observation next is [23.6, 94.33333333333334, 1.0, 2.0, 0.5906099551215989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 686116.8299516359, 686116.8299516359, 157091.2745792872], 
processed observation next is [1.0, 0.9565217391304348, 0.4296296296296297, 0.9433333333333335, 1.0, 1.0, 0.5126308989542844, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2450417249827271, 0.2450417249827271, 0.30209860496016766], 
reward next is 0.6979, 
noisyNet noise sample is [array([-1.0019213], dtype=float32), 0.9946922]. 
=============================================
[2019-03-24 07:09:19,185] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 4.4101889e-22 1.7493042e-25 6.4173216e-23 3.0579981e-21], sum to 1.0000
[2019-03-24 07:09:19,193] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6884
[2019-03-24 07:09:19,201] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 978113.4819260659 W.
[2019-03-24 07:09:19,207] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 87.66666666666667, 1.0, 2.0, 0.4290531764249279, 1.0, 2.0, 0.4290531764249279, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 978113.4819260659, 978113.4819260663, 214313.1001393983], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5366400.0000, 
sim time next is 5367000.0000, 
raw observation next is [24.75, 87.83333333333334, 1.0, 2.0, 0.8344724907234548, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 959930.3188673604, 959930.3188673612, 203626.1853824305], 
processed observation next is [1.0, 0.08695652173913043, 0.4722222222222222, 0.8783333333333334, 1.0, 1.0, 0.8029434413374461, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, -1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.342832256738343, 0.3428322567383433, 0.39158881804313556], 
reward next is 0.6084, 
noisyNet noise sample is [array([-1.1298916], dtype=float32), 0.054445878]. 
=============================================
[2019-03-24 07:09:19,220] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[31.71572 ]
 [31.805593]
 [31.814342]
 [31.520962]
 [31.717663]], R is [[32.07388687]
 [32.34100723]
 [32.52732468]
 [32.71514511]
 [32.38799286]].
[2019-03-24 07:09:21,152] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.1699962e-17 5.9777132e-19 1.2945893e-16 1.4118193e-15], sum to 1.0000
[2019-03-24 07:09:21,171] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9555
[2019-03-24 07:09:21,179] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 824870.0651857198 W.
[2019-03-24 07:09:21,185] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.6, 91.0, 1.0, 2.0, 0.3618685285713428, 1.0, 2.0, 0.3618685285713428, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 824870.0651857198, 824870.0651857198, 195969.6064828919], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5382000.0000, 
sim time next is 5382600.0000, 
raw observation next is [24.65, 91.00000000000001, 1.0, 2.0, 0.2433380946912561, 1.0, 2.0, 0.2433380946912561, 1.0, 1.0, 0.3874021717169529, 6.911199999999999, 6.9112, 121.94756008, 832028.2579642438, 832028.2579642442, 235275.5919349065], 
processed observation next is [1.0, 0.30434782608695654, 0.46851851851851845, 0.9100000000000001, 1.0, 1.0, 0.0992120174895906, 1.0, 1.0, 0.0992120174895906, 1.0, 0.5, 0.2342527146461911, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2971529492729442, 0.2971529492729444, 0.45245306141328173], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6742491], dtype=float32), 1.0730711]. 
=============================================
[2019-03-24 07:09:21,352] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.1041761e-20 2.0027920e-22 1.4377575e-19 2.2533325e-19], sum to 1.0000
[2019-03-24 07:09:21,357] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3880
[2019-03-24 07:09:21,363] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 805885.0737641577 W.
[2019-03-24 07:09:21,367] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.66666666666667, 74.5, 1.0, 2.0, 0.7070884687441044, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 805885.0737641577, 805885.0737641577, 177496.5868748837], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5421000.0000, 
sim time next is 5421600.0000, 
raw observation next is [29.6, 75.0, 1.0, 2.0, 0.3614208147677086, 1.0, 1.0, 0.3614208147677086, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 823848.9645222924, 823848.9645222924, 195854.9248444222], 
processed observation next is [1.0, 0.782608695652174, 0.6518518518518519, 0.75, 1.0, 1.0, 0.23978668424727215, 1.0, 0.5, 0.23978668424727215, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29423177304367587, 0.29423177304367587, 0.3766440862392735], 
reward next is 0.6234, 
noisyNet noise sample is [array([-0.6717533], dtype=float32), -1.6062757]. 
=============================================
[2019-03-24 07:09:22,039] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 5.7915282e-17 9.4123479e-17 1.0735803e-15 8.6511846e-14], sum to 1.0000
[2019-03-24 07:09:22,045] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0756
[2019-03-24 07:09:22,053] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1494296.42111601 W.
[2019-03-24 07:09:22,060] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.73333333333333, 86.83333333333333, 1.0, 2.0, 0.6552581484319547, 1.0, 1.0, 0.6552581484319547, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1494296.42111601, 1494296.42111601, 287574.0672601187], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5388600.0000, 
sim time next is 5389200.0000, 
raw observation next is [25.9, 86.0, 1.0, 2.0, 0.6802816343976977, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1490295.622612314, 1490295.622612314, 313685.6707402739], 
processed observation next is [1.0, 0.391304347826087, 0.5148148148148147, 0.86, 1.0, 1.0, 0.6193828980924972, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5322484366472551, 0.5322484366472551, 0.6032416745005267], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.5658103], dtype=float32), -0.9794959]. 
=============================================
[2019-03-24 07:09:24,066] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.3148553e-24 5.4208404e-29 5.2814564e-26 7.1788324e-25], sum to 1.0000
[2019-03-24 07:09:24,070] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8199
[2019-03-24 07:09:24,075] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 849552.8749165274 W.
[2019-03-24 07:09:24,078] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.75, 91.66666666666667, 1.0, 2.0, 0.3726908203626585, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5933359237099951, 6.911199999999999, 6.9112, 121.9260426156618, 849552.8749165274, 849552.8749165279, 215827.0891480676], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5446200.0000, 
sim time next is 5446800.0000, 
raw observation next is [26.7, 92.0, 1.0, 2.0, 0.3723781039114009, 1.0, 1.0, 0.3723781039114009, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 848839.6395396014, 848839.6395396014, 198737.8805817406], 
processed observation next is [1.0, 0.043478260869565216, 0.5444444444444444, 0.92, 1.0, 1.0, 0.2528310760850011, 1.0, 0.5, 0.2528310760850011, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3031570141212862, 0.3031570141212862, 0.3821882318879627], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7986465], dtype=float32), -0.8624901]. 
=============================================
[2019-03-24 07:09:24,866] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.4159126e-23 7.3068241e-28 4.2986018e-23 2.5254276e-23], sum to 1.0000
[2019-03-24 07:09:24,870] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6237
[2019-03-24 07:09:24,875] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 779203.4077328892 W.
[2019-03-24 07:09:24,880] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.65, 85.33333333333334, 1.0, 2.0, 0.3418448530297985, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5442281391330596, 6.9112, 6.9112, 121.9260426156618, 779203.4077328892, 779203.4077328892, 206834.3904126263], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5652600.0000, 
sim time next is 5653200.0000, 
raw observation next is [26.8, 84.66666666666667, 1.0, 2.0, 0.2286861847020945, 1.0, 1.0, 0.2286861847020945, 1.0, 2.0, 0.3640758538348129, 6.911200000000002, 6.9112, 121.94756008, 781904.4983010353, 781904.4983010343, 230194.6797026412], 
processed observation next is [0.0, 0.43478260869565216, 0.5481481481481482, 0.8466666666666667, 1.0, 1.0, 0.08176926750249346, 1.0, 0.5, 0.08176926750249346, 1.0, 1.0, 0.20509481729351609, 1.7763568394002506e-16, 0.0, 0.8096049824067558, 0.279251606536084, 0.27925160653608366, 0.4426820763512331], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.42658538], dtype=float32), -1.1238377]. 
=============================================
[2019-03-24 07:09:37,827] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-24 07:09:37,830] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:09:37,830] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:09:37,831] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:09:37,831] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:09:37,832] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:09:37,832] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:09:37,832] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:09:37,834] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:09:37,833] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:09:37,841] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:09:37,854] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run58
[2019-03-24 07:09:37,885] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run58
[2019-03-24 07:09:37,886] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run58
[2019-03-24 07:09:37,886] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run58
[2019-03-24 07:09:37,946] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run58
[2019-03-24 07:09:44,264] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.017402185]
[2019-03-24 07:09:44,265] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.2, 33.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5759328335233613, 6.9112, 6.9112, 121.9260426156618, 421758.9340061085, 421758.9340061085, 125021.9489467085]
[2019-03-24 07:09:44,266] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:09:44,269] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.1430264211127351
[2019-03-24 07:10:00,960] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.017402185]
[2019-03-24 07:10:00,961] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.55, 49.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5895278884251131, 6.9112, 6.9112, 121.9260426156618, 436763.761748965, 436763.761748965, 128854.9242735935]
[2019-03-24 07:10:00,963] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:10:00,965] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.5108923838336299
[2019-03-24 07:10:15,473] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.017402185]
[2019-03-24 07:10:15,473] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [35.5, 39.0, 1.0, 2.0, 0.6396230653720437, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 728956.631628372, 728956.6316283715, 165027.8557305793]
[2019-03-24 07:10:15,475] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:10:15,480] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.8869218302033927
[2019-03-24 07:10:15,482] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 728956.631628372 W.
[2019-03-24 07:10:41,504] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.017402185]
[2019-03-24 07:10:41,505] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.54746107333333, 96.56956164666667, 1.0, 2.0, 0.6384467780558887, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 727615.4207793131, 727615.4207793126, 164818.1306159943]
[2019-03-24 07:10:41,506] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:10:41,509] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 3.3666442e-38 0.0000000e+00 7.1479338e-38 1.0313187e-37], sampled 0.33759635920153175
[2019-03-24 07:10:41,510] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 727615.4207793131 W.
[2019-03-24 07:10:59,247] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.017402185]
[2019-03-24 07:10:59,248] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [19.45, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.65575770502222, 6.9112, 6.9112, 121.9260426156618, 483465.3454825889, 483465.3454825889, 133814.6711245278]
[2019-03-24 07:10:59,250] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:10:59,253] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.10372214957954629
[2019-03-24 07:11:02,596] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.017402185]
[2019-03-24 07:11:02,599] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.48333333333333, 69.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8656938543673277, 6.911200000000001, 6.9112, 121.9260426156618, 637682.611400967, 637682.6114009665, 170464.4283452109]
[2019-03-24 07:11:02,601] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:11:02,604] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.10780871337430864
[2019-03-24 07:11:27,531] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 07:11:27,837] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 07:11:27,870] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 07:11:27,916] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 07:11:27,933] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 07:11:28,948] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1425000, evaluation results [1425000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 07:11:29,619] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:11:29,625] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5155
[2019-03-24 07:11:29,629] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.9, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8165745117026666, 6.9112, 6.9112, 121.9260426156618, 605987.5222317474, 605987.5222317474, 162661.7588853603], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5710800.0000, 
sim time next is 5711400.0000, 
raw observation next is [21.85, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8128981943632605, 6.9112, 6.9112, 121.9260426156618, 603519.1075789253, 603519.1075789253, 162077.2703579028], 
processed observation next is [0.0, 0.08695652173913043, 0.36481481481481487, 0.97, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7661227429540757, 0.0, 0.0, 0.8094621288201359, 0.21554253842104476, 0.21554253842104476, 0.3116870583805823], 
reward next is 0.6883, 
noisyNet noise sample is [array([-0.33247772], dtype=float32), -0.34021834]. 
=============================================
[2019-03-24 07:11:34,457] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 9.1792488e-38 0.0000000e+00 0.0000000e+00 4.3127766e-38], sum to 1.0000
[2019-03-24 07:11:34,463] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6262
[2019-03-24 07:11:34,470] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1259630.249338769 W.
[2019-03-24 07:11:34,472] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.96666666666667, 43.66666666666666, 1.0, 2.0, 0.5176087699650617, 1.0, 1.0, 0.5176087699650617, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1259630.249338769, 1259630.249338769, 244119.2091485259], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5845200.0000, 
sim time next is 5845800.0000, 
raw observation next is [27.98333333333333, 43.33333333333334, 1.0, 2.0, 0.9598459090082476, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.389636150911464, 6.9112, 121.9240370367582, 1430513.578553931, 1185515.537223427, 235232.488780544], 
processed observation next is [1.0, 0.6521739130434783, 0.5919753086419752, 0.4333333333333334, 1.0, 1.0, 0.9521975107241043, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.04784361509114641, 0.0, 0.8094488138618711, 0.510897706626404, 0.423398406151224, 0.45237017073181535], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.57127666], dtype=float32), -0.60612345]. 
=============================================
[2019-03-24 07:11:34,838] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.3289370e-35 0.0000000e+00 4.8554682e-36 5.8734396e-35], sum to 1.0000
[2019-03-24 07:11:34,850] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7761
[2019-03-24 07:11:34,856] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1378278.067783731 W.
[2019-03-24 07:11:34,862] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.83333333333333, 45.66666666666667, 1.0, 2.0, 0.3830150304960157, 1.0, 2.0, 0.3830150304960157, 1.0, 1.0, 0.6181836762415873, 6.9112, 6.9112, 121.94756008, 1378278.067783731, 1378278.067783731, 289267.4266543664], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5841600.0000, 
sim time next is 5842200.0000, 
raw observation next is [27.86666666666667, 45.33333333333333, 1.0, 2.0, 0.5788694988173733, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9415538604534579, 6.9112, 6.9112, 121.9260426156618, 1405553.155010413, 1405553.155010413, 283129.8106661461], 
processed observation next is [1.0, 0.6086956521739131, 0.5876543209876545, 0.4533333333333333, 1.0, 1.0, 0.49865416525877765, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9269423255668224, 0.0, 0.0, 0.8094621288201359, 0.501983269646576, 0.501983269646576, 0.5444804051272041], 
reward next is 0.4555, 
noisyNet noise sample is [array([-0.8995198], dtype=float32), 0.35646766]. 
=============================================
[2019-03-24 07:11:35,565] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:11:35,570] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1861
[2019-03-24 07:11:35,575] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.36666666666666, 53.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6549863573037926, 6.9112, 6.9112, 121.9260426156618, 489237.2954695791, 489237.2954695791, 138936.4073089838], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5856600.0000, 
sim time next is 5857200.0000, 
raw observation next is [26.2, 55.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6622488560266391, 6.911199999999999, 6.9112, 121.9260426156618, 494743.9299157869, 494743.9299157874, 139908.5366036246], 
processed observation next is [1.0, 0.8260869565217391, 0.5259259259259259, 0.55, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5778110700332988, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1766942606842096, 0.1766942606842098, 0.2690548780838935], 
reward next is 0.7309, 
noisyNet noise sample is [array([-0.09172652], dtype=float32), 2.258295]. 
=============================================
[2019-03-24 07:11:35,799] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 3.2910405e-38 0.0000000e+00 7.9749828e-37 3.6207543e-37], sum to 1.0000
[2019-03-24 07:11:35,808] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6642
[2019-03-24 07:11:35,808] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1264083.091103163 W.
[2019-03-24 07:11:35,813] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.96666666666667, 43.66666666666666, 1.0, 2.0, 0.3504524393707373, 1.0, 2.0, 0.3504524393707373, 1.0, 2.0, 0.5664134553019324, 6.9112, 6.9112, 121.94756008, 1264083.091103163, 1264083.091103163, 275488.5488917826], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5845200.0000, 
sim time next is 5845800.0000, 
raw observation next is [27.98333333333333, 43.33333333333334, 1.0, 2.0, 0.3448126493055983, 1.0, 2.0, 0.3448126493055983, 1.0, 2.0, 0.5578639266739738, 6.9112, 6.9112, 121.94756008, 1245830.916587882, 1245830.916587882, 273118.3891452357], 
processed observation next is [1.0, 0.6521739130434783, 0.5919753086419752, 0.4333333333333334, 1.0, 1.0, 0.22001505869714083, 1.0, 1.0, 0.22001505869714083, 1.0, 1.0, 0.44732990834246716, 0.0, 0.0, 0.8096049824067558, 0.4449396130671007, 0.4449396130671007, 0.5252276714331456], 
reward next is 0.4748, 
noisyNet noise sample is [array([1.130955], dtype=float32), 1.304197]. 
=============================================
[2019-03-24 07:11:36,761] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:11:36,769] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7008
[2019-03-24 07:11:36,772] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.28333333333333, 67.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.695671818756025, 6.911199999999999, 6.9112, 121.9260426156618, 519863.0729555225, 519863.0729555229, 144165.5676077451], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5863800.0000, 
sim time next is 5864400.0000, 
raw observation next is [24.1, 68.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6942090664087721, 6.9112, 6.9112, 121.9260426156618, 518759.2091526674, 518759.2091526674, 143890.5608266026], 
processed observation next is [1.0, 0.9130434782608695, 0.4481481481481482, 0.68, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6177613330109651, 0.0, 0.0, 0.8094621288201359, 0.18527114612595263, 0.18527114612595263, 0.27671261697423577], 
reward next is 0.7233, 
noisyNet noise sample is [array([-0.30270663], dtype=float32), 1.5913101]. 
=============================================
[2019-03-24 07:11:39,221] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 3.4848740e-38 0.0000000e+00 2.4418262e-37 9.5434936e-37], sum to 1.0000
[2019-03-24 07:11:39,232] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0232
[2019-03-24 07:11:39,236] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1635652.928032886 W.
[2019-03-24 07:11:39,239] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.9, 50.0, 1.0, 2.0, 0.4705776824568831, 1.0, 1.0, 0.4705776824568831, 1.0, 2.0, 0.750414776505422, 6.9112, 6.9112, 121.94756008, 1635652.928032886, 1635652.928032886, 329489.099632678], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5935200.0000, 
sim time next is 5935800.0000, 
raw observation next is [28.85, 50.5, 1.0, 2.0, 0.6912531404981691, 1.0, 2.0, 0.6912531404981691, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1616052.707547649, 1616052.70754765, 302794.1550284894], 
processed observation next is [1.0, 0.6956521739130435, 0.6240740740740741, 0.505, 1.0, 1.0, 0.6324442148787728, 1.0, 1.0, 0.6324442148787728, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5771616812670175, 0.5771616812670178, 0.5822964519778643], 
reward next is 0.4177, 
noisyNet noise sample is [array([1.5287318], dtype=float32), -0.17165375]. 
=============================================
[2019-03-24 07:11:42,667] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.000000e+00 7.867188e-33 5.565245e-38 1.182745e-32 4.885279e-32], sum to 1.0000
[2019-03-24 07:11:42,677] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7997
[2019-03-24 07:11:42,685] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1287522.12669302 W.
[2019-03-24 07:11:42,692] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.65, 72.5, 1.0, 1.0, 0.5316736176988178, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8631823085405647, 6.9112, 6.9112, 121.9250670869436, 1287522.12669302, 1287522.12669302, 265919.2659621076], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5992200.0000, 
sim time next is 5992800.0000, 
raw observation next is [23.83333333333334, 72.33333333333334, 1.0, 2.0, 0.9356782881663726, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.139489292132917, 6.9112, 121.924981668217, 1256004.283256422, 1139100.778671327, 228952.2188819883], 
processed observation next is [1.0, 0.34782608695652173, 0.43827160493827183, 0.7233333333333334, 1.0, 1.0, 0.9234265335313959, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.022828929213291715, 0.0, 0.80945508523241, 0.448572958305865, 0.40682170666833106, 0.44029272861920826], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2258139], dtype=float32), 1.0909889]. 
=============================================
[2019-03-24 07:11:48,501] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 5.1315828e-30 3.1110924e-33 9.9452721e-28 1.9776876e-27], sum to 1.0000
[2019-03-24 07:11:48,504] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8799
[2019-03-24 07:11:48,508] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1675337.876055503 W.
[2019-03-24 07:11:48,512] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.7, 61.5, 1.0, 2.0, 0.8422902244606425, 0.0, 2.0, 0.0, 1.0, 2.0, 0.997646897876601, 6.911199999999999, 6.9112, 121.9260426156618, 1675337.876055503, 1675337.876055504, 344766.5019024434], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6085800.0000, 
sim time next is 6086400.0000, 
raw observation next is [28.5, 62.66666666666666, 1.0, 2.0, 0.7652880712003294, 1.0, 1.0, 0.7652880712003294, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1745475.687220638, 1745475.687220638, 329618.2534423548], 
processed observation next is [1.0, 0.43478260869565216, 0.6111111111111112, 0.6266666666666666, 1.0, 1.0, 0.7205810371432493, 1.0, 0.5, 0.7205810371432493, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6233841740073707, 0.6233841740073707, 0.633881256619913], 
reward next is 0.3661, 
noisyNet noise sample is [array([-0.87270314], dtype=float32), -0.9707858]. 
=============================================
[2019-03-24 07:11:49,390] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 6.7529089e-37 0.0000000e+00 1.8701431e-37 1.2639507e-36], sum to 1.0000
[2019-03-24 07:11:49,396] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1071
[2019-03-24 07:11:49,400] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.75, 80.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8555768554077077, 6.911200000000001, 6.9112, 121.9260426156618, 630646.5685114714, 630646.5685114709, 169050.8986337289], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6136200.0000, 
sim time next is 6136800.0000, 
raw observation next is [24.63333333333333, 81.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8558233620138774, 6.9112, 6.9112, 121.9260426156618, 630795.9122011961, 630795.9122011961, 169091.5795513271], 
processed observation next is [1.0, 0.0, 0.46790123456790106, 0.8133333333333332, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8197792025173467, 0.0, 0.0, 0.8094621288201359, 0.22528425435757002, 0.22528425435757002, 0.3251761145217829], 
reward next is 0.6748, 
noisyNet noise sample is [array([0.03348318], dtype=float32), -0.3799362]. 
=============================================
[2019-03-24 07:11:57,586] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 8.7290980e-34 0.0000000e+00 9.6805303e-34 1.0193688e-31], sum to 1.0000
[2019-03-24 07:11:57,591] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7879
[2019-03-24 07:11:57,598] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 727532.1592210343 W.
[2019-03-24 07:11:57,602] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.13333333333333, 65.0, 1.0, 2.0, 0.2127912694036002, 1.0, 1.0, 0.2127912694036002, 1.0, 2.0, 0.3387706310183586, 6.9112, 6.9112, 121.94756008, 727532.1592210343, 727532.1592210343, 224818.4694527156], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6270000.0000, 
sim time next is 6270600.0000, 
raw observation next is [29.26666666666667, 64.5, 1.0, 2.0, 0.2141389862059776, 1.0, 2.0, 0.2141389862059776, 1.0, 2.0, 0.3409162400598154, 6.911200000000001, 6.9112, 121.94756008, 732142.1955430148, 732142.1955430143, 225268.8301651346], 
processed observation next is [0.0, 0.5652173913043478, 0.6395061728395063, 0.645, 1.0, 1.0, 0.06445117405473523, 1.0, 1.0, 0.06445117405473523, 1.0, 1.0, 0.17614530007476925, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2614793555510767, 0.26147935555107654, 0.433209288779105], 
reward next is 0.5668, 
noisyNet noise sample is [array([0.75523275], dtype=float32), 1.1596271]. 
=============================================
[2019-03-24 07:11:58,044] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.9453238e-37 0.0000000e+00], sum to 1.0000
[2019-03-24 07:11:58,049] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8521
[2019-03-24 07:11:58,057] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 688115.8434852562 W.
[2019-03-24 07:11:58,059] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.75, 75.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9497850299368978, 6.9112, 6.9112, 121.9260426156618, 688115.8434852562, 688115.8434852562, 183852.4836865061], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6259800.0000, 
sim time next is 6260400.0000, 
raw observation next is [26.9, 75.0, 1.0, 1.0, 0.3041979659708863, 1.0, 1.0, 0.3041979659708863, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 693352.0360844444, 693352.0360844447, 181471.2021670161], 
processed observation next is [0.0, 0.4782608695652174, 0.5518518518518518, 0.75, 1.0, 0.5, 0.17166424520343604, 1.0, 0.5, 0.17166424520343604, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24762572717301584, 0.24762572717301598, 0.3489830810904156], 
reward next is 0.6510, 
noisyNet noise sample is [array([0.4102813], dtype=float32), 1.12945]. 
=============================================
[2019-03-24 07:12:01,666] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:12:01,672] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1012
[2019-03-24 07:12:01,677] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 762585.9084736885 W.
[2019-03-24 07:12:01,686] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.23333333333333, 63.33333333333334, 1.0, 2.0, 0.3345582033940202, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5326275556032893, 6.911199999999999, 6.9112, 121.9260426156618, 762585.9084736885, 762585.908473689, 204766.2397684485], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6376800.0000, 
sim time next is 6377400.0000, 
raw observation next is [30.1, 64.0, 1.0, 2.0, 0.3415454983609078, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5437515567508846, 6.911199999999999, 6.9112, 121.9260426156618, 778520.7102045331, 778520.7102045335, 206748.6979502869], 
processed observation next is [0.0, 0.8260869565217391, 0.6703703703703704, 0.64, 1.0, 1.0, 0.216125593286795, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4296894459386057, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27804311078733324, 0.2780431107873334, 0.3975936499043979], 
reward next is 0.6024, 
noisyNet noise sample is [array([-1.2314348], dtype=float32), 2.6590068]. 
=============================================
[2019-03-24 07:12:02,373] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 3.3221160e-33 0.0000000e+00 2.8918024e-34 7.7852080e-33], sum to 1.0000
[2019-03-24 07:12:02,379] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0719
[2019-03-24 07:12:02,389] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 779430.2155385175 W.
[2019-03-24 07:12:02,395] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.0, 59.0, 1.0, 2.0, 0.3419443054702337, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5443864706571722, 6.911199999999999, 6.9112, 121.9260426156618, 779430.2155385175, 779430.2155385179, 206862.2833500309], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6354000.0000, 
sim time next is 6354600.0000, 
raw observation next is [31.06666666666667, 58.83333333333334, 1.0, 2.0, 0.3479837328917272, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5540014358026093, 6.911199999999999, 6.9112, 121.9260426156618, 793203.6512084323, 793203.6512084327, 208592.5478238107], 
processed observation next is [0.0, 0.5652173913043478, 0.7061728395061729, 0.5883333333333334, 1.0, 1.0, 0.22379015820443712, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.44250179475326157, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2832870182887258, 0.283287018288726, 0.40113951504578976], 
reward next is 0.5989, 
noisyNet noise sample is [array([0.22162028], dtype=float32), 1.1314753]. 
=============================================
[2019-03-24 07:12:03,934] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 2.0502221e-24 1.5193043e-27 1.7255319e-24 4.6819141e-26], sum to 1.0000
[2019-03-24 07:12:03,942] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9715
[2019-03-24 07:12:03,946] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1112583.861025014 W.
[2019-03-24 07:12:03,948] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.85, 91.5, 1.0, 2.0, 0.4879963233444629, 1.0, 1.0, 0.4879963233444629, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156568, 1112583.861025014, 1112583.861025014, 231695.1174251999], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6409800.0000, 
sim time next is 6410400.0000, 
raw observation next is [24.8, 91.66666666666666, 1.0, 2.0, 0.4489635649289924, 1.0, 2.0, 0.4489635649289924, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1023533.55296461, 1023533.552964611, 220050.1949611626], 
processed observation next is [1.0, 0.17391304347826086, 0.4740740740740741, 0.9166666666666665, 1.0, 1.0, 0.34400424396308626, 1.0, 1.0, 0.34400424396308626, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3655476974873607, 0.36554769748736105, 0.4231734518483896], 
reward next is 0.5768, 
noisyNet noise sample is [array([0.32913843], dtype=float32), 1.4609035]. 
=============================================
[2019-03-24 07:12:06,377] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 3.5776375e-25 3.0847722e-27 5.2412408e-24 6.0209059e-24], sum to 1.0000
[2019-03-24 07:12:06,386] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4597
[2019-03-24 07:12:06,393] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2237707.877092494 W.
[2019-03-24 07:12:06,396] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.63333333333333, 72.33333333333334, 1.0, 2.0, 0.9808327862900045, 1.0, 2.0, 0.9808327862900045, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2237707.877092494, 2237707.877092495, 424143.9825838484], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6434400.0000, 
sim time next is 6435000.0000, 
raw observation next is [29.8, 71.0, 1.0, 2.0, 1.008603600341607, 1.0, 2.0, 1.008603600341607, 0.0, 2.0, 0.0, 6.911199999999997, 6.9112, 121.9260426156618, 2301146.884452845, 2301146.884452847, 437493.0874144129], 
processed observation next is [1.0, 0.4782608695652174, 0.6592592592592593, 0.71, 1.0, 1.0, 1.010242381359056, 1.0, 1.0, 1.010242381359056, 0.0, 1.0, -0.25, -2.6645352591003756e-16, 0.0, 0.8094621288201359, 0.8218381730188732, 0.8218381730188739, 0.8413328604123325], 
reward next is 0.1587, 
noisyNet noise sample is [array([-0.03633708], dtype=float32), -1.057503]. 
=============================================
[2019-03-24 07:12:06,419] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[32.713974]
 [32.64279 ]
 [32.372887]
 [32.204666]
 [32.01403 ]], R is [[32.95288849]
 [32.62335968]
 [32.29712677]
 [31.97415543]
 [31.65441322]].
[2019-03-24 07:12:07,296] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 2.8346211e-30 5.5507428e-38 6.8339386e-31 1.3924572e-30], sum to 1.0000
[2019-03-24 07:12:07,305] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3326
[2019-03-24 07:12:07,310] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2042059.883515697 W.
[2019-03-24 07:12:07,313] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.83333333333334, 54.66666666666667, 1.0, 2.0, 0.8951742510386217, 1.0, 2.0, 0.8951742510386217, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 2042059.883515697, 2042059.883515696, 384651.1827132127], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6450000.0000, 
sim time next is 6450600.0000, 
raw observation next is [31.76666666666667, 54.83333333333334, 1.0, 2.0, 0.8893079520902208, 1.0, 2.0, 0.8893079520902208, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2028662.558001846, 2028662.558001846, 382039.6011374827], 
processed observation next is [1.0, 0.6521739130434783, 0.7320987654320988, 0.5483333333333335, 1.0, 1.0, 0.8682237524883581, 1.0, 1.0, 0.8682237524883581, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.7245223421435164, 0.7245223421435164, 0.7346915406490051], 
reward next is 0.2653, 
noisyNet noise sample is [array([0.37397817], dtype=float32), 0.99441034]. 
=============================================
[2019-03-24 07:12:08,178] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 2.0386382e-19 4.2777476e-22 1.9696547e-19 2.0467266e-19], sum to 1.0000
[2019-03-24 07:12:08,182] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2349
[2019-03-24 07:12:08,186] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1343553.275638723 W.
[2019-03-24 07:12:08,190] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.43333333333333, 88.33333333333334, 1.0, 2.0, 1.019526744682455, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.264984972777169, 6.9112, 121.9247337529275, 1343553.275638723, 1162385.693469822, 245469.9549100964], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6509400.0000, 
sim time next is 6510000.0000, 
raw observation next is [26.56666666666667, 87.66666666666667, 1.0, 2.0, 0.8996340616422597, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9258295725462, 1740666.763193168, 1740666.763193168, 356888.49689405], 
processed observation next is [1.0, 0.34782608695652173, 0.5395061728395063, 0.8766666666666667, 1.0, 1.0, 0.8805167400503091, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, 8.881784197001253e-17, 0.0, 0.8094607144353976, 0.6216667011404171, 0.6216667011404171, 0.6863240324885577], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.16115493], dtype=float32), -0.04879577]. 
=============================================
[2019-03-24 07:12:08,212] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[30.9193  ]
 [30.904003]
 [30.803888]
 [30.610336]
 [30.872377]], R is [[30.59185791]
 [30.28594017]
 [30.52026367]
 [30.21506119]
 [29.91291046]].
[2019-03-24 07:12:09,806] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 1.1209197e-18 2.0574893e-20 9.0407532e-18 4.1317916e-18], sum to 1.0000
[2019-03-24 07:12:09,812] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4721
[2019-03-24 07:12:09,816] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 927179.858088793 W.
[2019-03-24 07:12:09,820] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.3, 86.33333333333334, 1.0, 2.0, 0.8134489151328832, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 927179.858088793, 927179.858088793, 198731.3977276011], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6499200.0000, 
sim time next is 6499800.0000, 
raw observation next is [26.3, 86.5, 1.0, 2.0, 0.8258398524972677, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 941311.8867313592, 941311.8867313587, 201333.7466530035], 
processed observation next is [1.0, 0.21739130434782608, 0.5296296296296297, 0.865, 1.0, 1.0, 0.7926664910681758, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3361828166897711, 0.33618281668977096, 0.38718028202500676], 
reward next is 0.6128, 
noisyNet noise sample is [array([-0.6446469], dtype=float32), 1.4129424]. 
=============================================
[2019-03-24 07:12:12,757] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:12:12,769] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3672
[2019-03-24 07:12:12,778] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.11666666666667, 48.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.681143310640041, 6.9112, 6.9112, 121.9260426156618, 501628.3440080048, 501628.3440080048, 135998.9100605127], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6588600.0000, 
sim time next is 6589200.0000, 
raw observation next is [25.03333333333333, 48.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6274276969712628, 6.9112, 6.9112, 121.9260426156618, 461993.3702396879, 461993.3702396879, 130822.4599024914], 
processed observation next is [1.0, 0.2608695652173913, 0.482716049382716, 0.4866666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5342846212140784, 0.0, 0.0, 0.8094621288201359, 0.16499763222845998, 0.16499763222845998, 0.2515816536586373], 
reward next is 0.7484, 
noisyNet noise sample is [array([1.0312542], dtype=float32), -0.9737564]. 
=============================================
[2019-03-24 07:12:16,446] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-24 07:12:16,449] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:12:16,451] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:12:16,451] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:12:16,454] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:12:16,455] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:12:16,454] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:12:16,458] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:12:16,459] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:12:16,460] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:12:16,459] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:12:16,473] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run59
[2019-03-24 07:12:16,507] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run59
[2019-03-24 07:12:16,536] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run59
[2019-03-24 07:12:16,567] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run59
[2019-03-24 07:12:16,594] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run59
[2019-03-24 07:12:20,942] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.017411184]
[2019-03-24 07:12:20,943] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [33.31666666666666, 13.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6785436207884727, 6.911199999999999, 6.9112, 121.9260426156618, 484528.4114386844, 484528.4114386849, 128488.3426262418]
[2019-03-24 07:12:20,944] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:12:20,946] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.48239908299317524
[2019-03-24 07:12:25,769] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.017411184]
[2019-03-24 07:12:25,770] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.76266814333334, 50.93118151, 1.0, 2.0, 0.917078723073895, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1091290.032570657, 1091290.032570657, 223621.2018936826]
[2019-03-24 07:12:25,771] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:12:25,775] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.2225407e-38], sampled 0.6610786952546278
[2019-03-24 07:12:25,776] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1091290.032570657 W.
[2019-03-24 07:12:35,026] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.017411184]
[2019-03-24 07:12:35,027] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.74715425666667, 62.39111766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.68343340805408, 6.911199999999999, 6.9112, 121.9260426156618, 508567.8796451052, 508567.8796451056, 139534.5439685749]
[2019-03-24 07:12:35,029] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:12:35,031] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.9372466875758135
[2019-03-24 07:13:09,930] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.017411184]
[2019-03-24 07:13:09,931] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.83333333333333, 79.83333333333333, 1.0, 2.0, 0.7062872532977967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 804971.4304833343, 804971.4304833343, 177338.8302784465]
[2019-03-24 07:13:09,932] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:13:09,936] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.28674407769178345
[2019-03-24 07:13:09,937] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 804971.4304833343 W.
[2019-03-24 07:13:16,074] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.017411184]
[2019-03-24 07:13:16,075] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.73333333333333, 59.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7060440595685167, 6.911199999999999, 6.9112, 121.9260426156618, 527622.3514421702, 527622.3514421707, 145488.3281418784]
[2019-03-24 07:13:16,079] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:13:16,082] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.5641225450583538
[2019-03-24 07:13:30,337] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.017411184]
[2019-03-24 07:13:30,338] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.89513554833334, 82.32112366666668, 1.0, 2.0, 0.5996279851554429, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 701748.7762452505, 701748.77624525, 158874.4170685045]
[2019-03-24 07:13:30,339] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:13:30,341] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 7.2639395e-36 0.0000000e+00 2.1785285e-35 4.8714076e-35], sampled 0.7521409838760469
[2019-03-24 07:13:30,343] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 701748.7762452505 W.
[2019-03-24 07:13:41,894] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.017411184]
[2019-03-24 07:13:41,895] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.61789463666667, 70.60412731666668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7073039202598477, 6.911200000000001, 6.9112, 121.9260426156618, 528430.8693861818, 528430.8693861814, 146409.3835606705]
[2019-03-24 07:13:41,895] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:13:41,898] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.4152357195024011
[2019-03-24 07:13:43,496] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.017411184]
[2019-03-24 07:13:43,498] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.87466554333334, 75.82907584333333, 1.0, 2.0, 0.7774879609027686, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 886167.387734117, 886167.3877341175, 191340.1486765615]
[2019-03-24 07:13:43,503] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:13:43,505] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.09026601675246348
[2019-03-24 07:13:43,506] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 886167.387734117 W.
[2019-03-24 07:13:53,626] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.017411184]
[2019-03-24 07:13:53,626] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.0, 89.83333333333334, 1.0, 2.0, 0.5767841484555937, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9182591488896027, 6.911199999999999, 6.9112, 121.9260426156618, 1315185.177772829, 1315185.177772829, 284938.8081794612]
[2019-03-24 07:13:53,629] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:13:53,633] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.3387328529207454
[2019-03-24 07:13:53,634] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1315185.177772829 W.
[2019-03-24 07:14:05,022] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 07:14:06,145] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 07:14:06,250] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 07:14:06,305] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 07:14:06,385] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 07:14:07,401] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1450000, evaluation results [1450000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 07:14:08,740] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:14:08,752] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3974
[2019-03-24 07:14:08,758] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.16666666666667, 54.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8404301560936183, 6.9112, 6.9112, 121.9260426156618, 620392.4114560533, 620392.4114560533, 166857.8034389305], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6955800.0000, 
sim time next is 6956400.0000, 
raw observation next is [29.33333333333334, 54.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8439990010243402, 6.911199999999999, 6.9112, 121.9260426156618, 622644.0091294512, 622644.0091294517, 167424.4257836117], 
processed observation next is [0.0, 0.5217391304347826, 0.6419753086419755, 0.54, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8049987512804252, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22237286040337545, 0.22237286040337562, 0.32197004958386866], 
reward next is 0.6780, 
noisyNet noise sample is [array([-0.10466677], dtype=float32), 0.9607426]. 
=============================================
[2019-03-24 07:14:10,104] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 9.5812311e-33 1.5616470e-35 2.2026662e-31 5.2038503e-30], sum to 1.0000
[2019-03-24 07:14:10,113] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2303
[2019-03-24 07:14:10,113] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 856841.3218019917 W.
[2019-03-24 07:14:10,119] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.91666666666667, 41.16666666666666, 1.0, 2.0, 0.3410281783046502, 1.0, 2.0, 0.3410281783046502, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156232, 856841.3218019917, 856841.3218019921, 193391.3466060441], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6689400.0000, 
sim time next is 6690000.0000, 
raw observation next is [26.13333333333334, 40.33333333333334, 1.0, 2.0, 0.3273414464779804, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5573863717307715, 6.9112, 6.9112, 121.9260426156618, 825592.5649688254, 825592.5649688254, 197652.3010197345], 
processed observation next is [1.0, 0.43478260869565216, 0.523456790123457, 0.40333333333333343, 1.0, 1.0, 0.19921600771188144, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.4467329646634644, 0.0, 0.0, 0.8094621288201359, 0.2948544874888662, 0.2948544874888662, 0.3801005788841048], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.95207727], dtype=float32), 1.1766682]. 
=============================================
[2019-03-24 07:14:10,139] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[48.404526]
 [48.93019 ]
 [49.100876]
 [53.50392 ]
 [49.161118]], R is [[47.99893188]
 [48.14703751]
 [48.22776031]
 [47.7454834 ]
 [47.26802826]].
[2019-03-24 07:14:12,618] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:14:12,627] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7411
[2019-03-24 07:14:12,629] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.91666666666667, 75.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5859618599142282, 6.9112, 6.9112, 121.9260426156618, 432869.3515947949, 432869.3515947949, 127776.1687265765], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6736200.0000, 
sim time next is 6736800.0000, 
raw observation next is [20.83333333333334, 75.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5851956354454416, 6.9112, 6.9112, 121.9260426156618, 432035.0809444831, 432035.0809444831, 127556.7196608411], 
processed observation next is [1.0, 1.0, 0.3271604938271607, 0.7533333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.481494544306802, 0.0, 0.0, 0.8094621288201359, 0.15429824319445826, 0.15429824319445826, 0.24530138396315596], 
reward next is 0.7547, 
noisyNet noise sample is [array([-0.1745532], dtype=float32), -0.47575888]. 
=============================================
[2019-03-24 07:14:19,195] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:14:19,205] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2204
[2019-03-24 07:14:19,208] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.76666666666667, 50.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7510270816830313, 6.911199999999999, 6.9112, 121.9260426156618, 559907.8071263991, 559907.8071263996, 153025.1610289728], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6867600.0000, 
sim time next is 6868200.0000, 
raw observation next is [28.93333333333334, 50.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7589168599459751, 6.911200000000001, 6.9112, 121.9260426156618, 565363.1678124698, 565363.1678124693, 154300.8080394386], 
processed observation next is [0.0, 0.4782608695652174, 0.6271604938271608, 0.5, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6986460749324688, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20191541707588206, 0.2019154170758819, 0.29673232315276654], 
reward next is 0.7033, 
noisyNet noise sample is [array([-1.1795281], dtype=float32), -0.8805567]. 
=============================================
[2019-03-24 07:14:19,731] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:14:19,739] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7452
[2019-03-24 07:14:19,749] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.46666666666667, 48.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8418120073941867, 6.911200000000001, 6.9112, 121.9260426156618, 621018.083184703, 621018.0831847026, 167152.046389151], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6878400.0000, 
sim time next is 6879000.0000, 
raw observation next is [30.33333333333333, 48.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8369667846551699, 6.911200000000001, 6.9112, 121.9260426156618, 618008.3107817458, 618008.3107817454, 166368.315369701], 
processed observation next is [0.0, 0.6086956521739131, 0.6790123456790121, 0.48833333333333345, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7962084808189623, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22071725385062352, 0.22071725385062335, 0.3199390680186558], 
reward next is 0.6801, 
noisyNet noise sample is [array([1.0102303], dtype=float32), -2.6635685]. 
=============================================
[2019-03-24 07:14:19,764] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[66.49655 ]
 [66.462204]
 [66.40942 ]
 [66.39404 ]
 [66.389725]], R is [[66.5623703 ]
 [66.57529449]
 [66.58674622]
 [66.59667969]
 [66.60456848]].
[2019-03-24 07:14:25,846] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.2091565e-36 1.8439687e-36], sum to 1.0000
[2019-03-24 07:14:25,849] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1634
[2019-03-24 07:14:25,855] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1281661.010071893 W.
[2019-03-24 07:14:25,865] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.56666666666667, 74.66666666666667, 1.0, 2.0, 0.5459662546721041, 1.0, 2.0, 0.5459662546721041, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1281661.010071893, 1281661.010071893, 251659.2430608881], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7035600.0000, 
sim time next is 7036200.0000, 
raw observation next is [24.75, 74.0, 1.0, 2.0, 0.546350052825022, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8755729560961631, 6.9112, 6.9112, 121.9260426156618, 1290151.183191911, 1290151.183191911, 272595.5453080415], 
processed observation next is [1.0, 0.43478260869565216, 0.4722222222222222, 0.74, 1.0, 1.0, 0.4599405390774072, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.8444661951202039, 0.0, 0.0, 0.8094621288201359, 0.46076827971139683, 0.46076827971139683, 0.5242222025154645], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.6878797], dtype=float32), 0.6888821]. 
=============================================
[2019-03-24 07:14:26,653] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:14:26,658] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6793
[2019-03-24 07:14:26,664] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 818738.4657671321 W.
[2019-03-24 07:14:26,668] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.83333333333334, 70.0, 1.0, 2.0, 0.2266870602274557, 1.0, 1.0, 0.2266870602274557, 1.0, 2.0, 0.3667325661172924, 6.911200000000001, 6.9112, 121.94756008, 818738.4657671321, 818738.4657671317, 228785.7985859548], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7231200.0000, 
sim time next is 7231800.0000, 
raw observation next is [23.81666666666667, 70.0, 1.0, 2.0, 0.326964428040496, 1.0, 2.0, 0.326964428040496, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 791770.8772629651, 791770.8772629651, 189003.5429834434], 
processed observation next is [1.0, 0.6956521739130435, 0.43765432098765444, 0.7, 1.0, 1.0, 0.19876717623868576, 1.0, 1.0, 0.19876717623868576, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2827753133082018, 0.2827753133082018, 0.3634683518912373], 
reward next is 0.6365, 
noisyNet noise sample is [array([-0.9869999], dtype=float32), -0.046849]. 
=============================================
[2019-03-24 07:14:35,692] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:14:35,700] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6838
[2019-03-24 07:14:35,704] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.46666666666667, 71.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6848156796605731, 6.911199999999999, 6.9112, 121.9260426156618, 511706.4535801371, 511706.4535801376, 142670.8283568353], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7235400.0000, 
sim time next is 7236000.0000, 
raw observation next is [23.4, 72.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6872058776099249, 6.911200000000001, 6.9112, 121.9260426156618, 513485.3730679289, 513485.3730679285, 142889.4749872998], 
processed observation next is [1.0, 0.782608695652174, 0.42222222222222217, 0.72, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6090073470124061, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18338763323854604, 0.18338763323854587, 0.27478745189865345], 
reward next is 0.7252, 
noisyNet noise sample is [array([-1.1536478], dtype=float32), 0.05738393]. 
=============================================
[2019-03-24 07:14:35,726] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[77.562935]
 [77.313   ]
 [77.726364]
 [76.823074]
 [74.06813 ]], R is [[77.88243103]
 [77.82923889]
 [77.77692413]
 [77.72575378]
 [77.67247009]].
[2019-03-24 07:14:35,761] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:14:35,771] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3969
[2019-03-24 07:14:35,775] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.0, 89.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6729527002669824, 6.911200000000001, 6.9112, 121.9260426156618, 502838.1389494268, 502838.1389494264, 141396.4209857904], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7407000.0000, 
sim time next is 7407600.0000, 
raw observation next is [20.93333333333333, 89.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6765122796669715, 6.911200000000001, 6.9112, 121.9260426156618, 505470.5602856321, 505470.5602856316, 141647.0158545759], 
processed observation next is [1.0, 0.7391304347826086, 0.3308641975308641, 0.8966666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5956403495837143, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18052520010201145, 0.18052520010201129, 0.272398107412646], 
reward next is 0.7276, 
noisyNet noise sample is [array([0.05777381], dtype=float32), -0.96454775]. 
=============================================
[2019-03-24 07:14:35,946] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:14:35,960] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3227
[2019-03-24 07:14:35,964] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1229574.485072486 W.
[2019-03-24 07:14:35,967] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 72.33333333333333, 1.0, 2.0, 0.9318028093388873, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.101604549752063, 6.9112, 121.9252084310151, 1229574.485072486, 1132071.004530604, 227960.473929259], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7224000.0000, 
sim time next is 7224600.0000, 
raw observation next is [24.0, 73.16666666666667, 1.0, 2.0, 0.944209573324025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.190621075239536, 6.9112, 121.9246797409356, 1291675.598608163, 1148588.63314008, 230933.0223085744], 
processed observation next is [1.0, 0.6086956521739131, 0.4444444444444444, 0.7316666666666667, 1.0, 1.0, 0.933582825385744, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.027942107523953562, 0.0, 0.8094530807492438, 0.46131271378862965, 0.41021022612145713, 0.4441019659780277], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.2575332], dtype=float32), -1.4960921]. 
=============================================
[2019-03-24 07:14:40,206] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:14:40,212] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8739
[2019-03-24 07:14:40,221] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.38333333333334, 86.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8098558862978826, 6.9112, 6.9112, 121.9260426156618, 600093.5619821225, 600093.5619821225, 162197.2694647205], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7499400.0000, 
sim time next is 7500000.0000, 
raw observation next is [23.26666666666667, 87.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8106386882298585, 6.911199999999999, 6.9112, 121.9260426156618, 600827.3044445104, 600827.3044445108, 162234.739369116], 
processed observation next is [0.0, 0.8260869565217391, 0.41728395061728407, 0.8733333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.763298360287323, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21458118015875371, 0.21458118015875388, 0.3119898834021462], 
reward next is 0.6880, 
noisyNet noise sample is [array([0.10304653], dtype=float32), -0.43667445]. 
=============================================
[2019-03-24 07:14:40,240] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[71.79165]
 [71.78249]
 [71.71237]
 [71.68641]
 [71.67219]], R is [[71.76213074]
 [71.73258972]
 [71.70326233]
 [71.67362213]
 [71.64365387]].
[2019-03-24 07:14:40,915] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.5749033e-38 1.3833933e-37], sum to 1.0000
[2019-03-24 07:14:40,920] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8278
[2019-03-24 07:14:40,926] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1014699.583829034 W.
[2019-03-24 07:14:40,929] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.6, 75.33333333333334, 1.0, 2.0, 0.4238136742760046, 1.0, 2.0, 0.4238136742760046, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1014699.583829034, 1014699.583829034, 214901.0031806699], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7298400.0000, 
sim time next is 7299000.0000, 
raw observation next is [23.8, 74.5, 1.0, 2.0, 0.4374804160996166, 1.0, 2.0, 0.4374804160996166, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1046686.117810792, 1046686.117810793, 218838.9322035431], 
processed observation next is [1.0, 0.4782608695652174, 0.43703703703703706, 0.745, 1.0, 1.0, 0.33033382869001976, 1.0, 1.0, 0.33033382869001976, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3738164706467115, 0.3738164706467118, 0.42084410039142905], 
reward next is 0.5792, 
noisyNet noise sample is [array([0.5683452], dtype=float32), 0.39831012]. 
=============================================
[2019-03-24 07:14:40,940] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[67.775406]
 [67.23639 ]
 [67.31619 ]
 [67.08939 ]
 [67.125305]], R is [[67.77740479]
 [67.09963226]
 [66.42863464]
 [65.76435089]
 [65.68577576]].
[2019-03-24 07:14:41,807] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:14:41,816] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0318
[2019-03-24 07:14:41,823] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1558979.653679929 W.
[2019-03-24 07:14:41,830] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.86666666666667, 61.33333333333333, 1.0, 2.0, 0.450970586146421, 1.0, 2.0, 0.450970586146421, 1.0, 2.0, 0.7185792053877501, 6.9112, 6.9112, 121.94756008, 1558979.653679929, 1558979.653679929, 320222.344734197], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7314000.0000, 
sim time next is 7314600.0000, 
raw observation next is [26.88333333333333, 61.16666666666666, 1.0, 2.0, 0.4466078629174546, 1.0, 2.0, 0.4466078629174546, 1.0, 2.0, 0.711672195976265, 6.911199999999999, 6.9112, 121.94756008, 1544652.7550441, 1544652.7550441, 318193.8478521503], 
processed observation next is [1.0, 0.6521739130434783, 0.5512345679012344, 0.6116666666666666, 1.0, 1.0, 0.3411998368064935, 1.0, 1.0, 0.3411998368064935, 1.0, 1.0, 0.6395902449703311, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5516616982300357, 0.5516616982300357, 0.6119112458695198], 
reward next is 0.3881, 
noisyNet noise sample is [array([-0.6188123], dtype=float32), 0.18917951]. 
=============================================
[2019-03-24 07:14:43,996] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:14:44,003] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8318
[2019-03-24 07:14:44,010] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.36666666666667, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6380039828107333, 6.911199999999999, 6.9112, 121.9260426156618, 475338.084300661, 475338.0843006615, 135489.1574444173], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7364400.0000, 
sim time next is 7365000.0000, 
raw observation next is [19.33333333333334, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6407842601845046, 6.911200000000001, 6.9112, 121.9260426156618, 477318.6169445714, 477318.6169445709, 135676.4026912526], 
processed observation next is [1.0, 0.21739130434782608, 0.27160493827160515, 0.96, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5509803252306308, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1704709346230612, 0.17047093462306104, 0.2609161590216396], 
reward next is 0.7391, 
noisyNet noise sample is [array([-2.8046005], dtype=float32), 2.3698134]. 
=============================================
[2019-03-24 07:14:44,023] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[67.8114 ]
 [67.98454]
 [68.0094 ]
 [68.0299 ]
 [68.12651]], R is [[67.81814575]
 [67.87940216]
 [67.94075775]
 [68.00102234]
 [68.05419922]].
[2019-03-24 07:14:46,176] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:14:46,182] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1054
[2019-03-24 07:14:46,191] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 994379.5867332105 W.
[2019-03-24 07:14:46,195] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.3, 91.5, 1.0, 2.0, 0.4116737323316588, 0.0, 2.0, 0.0, 1.0, 1.0, 0.6672901559549761, 6.9112, 6.9112, 121.9260426156618, 994379.5867332105, 994379.5867332105, 225851.3680837519], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7396200.0000, 
sim time next is 7396800.0000, 
raw observation next is [21.3, 91.33333333333334, 1.0, 2.0, 0.382304412318648, 1.0, 1.0, 0.382304412318648, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 919416.1196186207, 919416.1196186212, 203408.656343253], 
processed observation next is [1.0, 0.6086956521739131, 0.3444444444444445, 0.9133333333333334, 1.0, 1.0, 0.26464810990315235, 1.0, 0.5, 0.26464810990315235, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.32836289986379313, 0.3283628998637933, 0.39117049296779427], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.756671], dtype=float32), -0.85275185]. 
=============================================
[2019-03-24 07:14:49,850] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:14:49,859] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9942
[2019-03-24 07:14:49,863] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.28333333333333, 65.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6752554248084736, 6.9112, 6.9112, 121.9260426156618, 504448.5323179535, 504448.5323179535, 141234.9247283941], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7761000.0000, 
sim time next is 7761600.0000, 
raw observation next is [24.0, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.670469500102278, 6.911199999999999, 6.9112, 121.9260426156618, 500729.4896970252, 500729.4896970257, 140383.0492987827], 
processed observation next is [1.0, 0.8695652173913043, 0.4444444444444444, 0.66, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5880868751278475, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17883196060608045, 0.1788319606060806, 0.269967402497659], 
reward next is 0.7300, 
noisyNet noise sample is [array([0.16838054], dtype=float32), 1.0743022]. 
=============================================
[2019-03-24 07:14:52,909] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:14:52,914] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1923
[2019-03-24 07:14:52,916] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.9, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7149662351330287, 6.911200000000001, 6.9112, 121.9260426156618, 533976.355423836, 533976.3554238356, 147681.5675258927], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7528200.0000, 
sim time next is 7528800.0000, 
raw observation next is [20.9, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7153274178410772, 6.911199999999999, 6.9112, 121.9260426156618, 534246.1993203267, 534246.1993203271, 147722.2809204737], 
processed observation next is [0.0, 0.13043478260869565, 0.32962962962962955, 0.96, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6441592723013464, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19080221404297382, 0.19080221404297398, 0.28408130946244947], 
reward next is 0.7159, 
noisyNet noise sample is [array([1.1974148], dtype=float32), 0.09014029]. 
=============================================
[2019-03-24 07:14:52,939] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:14:52,943] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1841
[2019-03-24 07:14:52,951] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.48333333333333, 85.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7884920525495887, 6.911200000000001, 6.9112, 121.9260426156618, 584926.725679851, 584926.7256798506, 159244.2809900261], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7553400.0000, 
sim time next is 7554000.0000, 
raw observation next is [23.66666666666667, 84.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.794643001275642, 6.9112, 6.9112, 121.9260426156618, 589003.7397275171, 589003.7397275171, 160212.6843907672], 
processed observation next is [0.0, 0.43478260869565216, 0.43209876543209896, 0.8466666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7433037515945525, 0.0, 0.0, 0.8094621288201359, 0.21035847847411326, 0.21035847847411326, 0.30810131613609076], 
reward next is 0.6919, 
noisyNet noise sample is [array([-1.0198406], dtype=float32), 2.1395392]. 
=============================================
[2019-03-24 07:14:52,975] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[75.29383 ]
 [75.29743 ]
 [75.28513 ]
 [75.314804]
 [75.38496 ]], R is [[75.21086884]
 [75.15252686]
 [75.09660339]
 [75.04308319]
 [74.99204254]].
[2019-03-24 07:14:53,485] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:14:53,486] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8042
[2019-03-24 07:14:53,492] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.3, 90.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7490553244870091, 6.911199999999999, 6.9112, 121.9260426156618, 557904.6555819703, 557904.6555819708, 153211.0093605411], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7549800.0000, 
sim time next is 7550400.0000, 
raw observation next is [22.5, 89.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.755465911220325, 6.911199999999999, 6.9112, 121.9260426156618, 562353.8727247455, 562353.872724746, 154193.1757587889], 
processed observation next is [0.0, 0.391304347826087, 0.3888888888888889, 0.8933333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6943323890254063, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20084066883026627, 0.20084066883026644, 0.29652533799767095], 
reward next is 0.7035, 
noisyNet noise sample is [array([0.9286415], dtype=float32), 1.4451982]. 
=============================================
[2019-03-24 07:14:55,217] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-24 07:14:55,218] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:14:55,220] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:14:55,222] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:14:55,223] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:14:55,224] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:14:55,225] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:14:55,225] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:14:55,226] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:14:55,227] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:14:55,227] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:14:55,245] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run60
[2019-03-24 07:14:55,276] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run60
[2019-03-24 07:14:55,296] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run60
[2019-03-24 07:14:55,319] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run60
[2019-03-24 07:14:55,320] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run60
[2019-03-24 07:14:59,613] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.017958524]
[2019-03-24 07:14:59,615] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [18.9, 51.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3923235017067664, 6.9112, 6.9112, 121.9260426156618, 280108.7399827084, 280108.7399827084, 84617.23402997736]
[2019-03-24 07:14:59,617] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:14:59,619] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.8519673842279686
[2019-03-24 07:15:19,864] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.017958524]
[2019-03-24 07:15:19,866] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.94931929166667, 82.59689192833335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7974910591207796, 6.9112, 6.9112, 121.9260426156618, 590896.908531944, 590896.908531944, 160655.5902663087]
[2019-03-24 07:15:19,867] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:15:19,870] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.8327240723644351
[2019-03-24 07:15:28,813] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.017958524]
[2019-03-24 07:15:28,813] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [33.15, 50.0, 1.0, 2.0, 0.6242520144172732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 711430.639141508, 711430.639141508, 162302.3976197124]
[2019-03-24 07:15:28,814] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:15:28,819] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.9397694773626847
[2019-03-24 07:15:28,821] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 711430.639141508 W.
[2019-03-24 07:15:38,115] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.017958524]
[2019-03-24 07:15:38,116] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [32.49940943666667, 89.67695184, 1.0, 2.0, 0.7751015378010849, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1598522.651912261, 1598522.651912261, 331359.8127910947]
[2019-03-24 07:15:38,117] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:15:38,122] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.8842799548031639
[2019-03-24 07:15:38,123] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1598522.651912261 W.
[2019-03-24 07:15:42,328] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.017958524]
[2019-03-24 07:15:42,328] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.83333333333333, 84.83333333333333, 1.0, 2.0, 0.6850209608432362, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 780721.4158843375, 780721.4158843375, 173328.2983592988]
[2019-03-24 07:15:42,329] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:15:42,333] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.5422919283321498
[2019-03-24 07:15:42,335] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 780721.4158843375 W.
[2019-03-24 07:16:26,854] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.017958524]
[2019-03-24 07:16:26,855] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.5, 91.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8188878407854561, 6.9112, 6.9112, 121.9260426156618, 608076.5510840941, 608076.5510840941, 162781.5060897429]
[2019-03-24 07:16:26,856] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:16:26,859] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.7323442085080718
[2019-03-24 07:16:44,294] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 07:16:44,595] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 07:16:44,673] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 07:16:44,686] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 07:16:44,689] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 07:16:45,703] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1475000, evaluation results [1475000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 07:16:46,634] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:16:46,641] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7630
[2019-03-24 07:16:46,646] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.3, 86.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7456948580996983, 6.911199999999999, 6.9112, 121.9260426156618, 556406.579458837, 556406.5794588375, 151932.9415243846], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7604400.0000, 
sim time next is 7605000.0000, 
raw observation next is [22.2, 86.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7388006317258785, 6.911200000000001, 6.9112, 121.9260426156618, 551506.3924314546, 551506.3924314542, 150830.6422279449], 
processed observation next is [1.0, 0.0, 0.37777777777777777, 0.865, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.673500789657348, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19696656872551951, 0.19696656872551935, 0.29005892736143246], 
reward next is 0.7099, 
noisyNet noise sample is [array([-0.5267438], dtype=float32), 1.8860608]. 
=============================================
[2019-03-24 07:16:46,658] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[67.456696]
 [68.90997 ]
 [70.952   ]
 [74.14998 ]
 [74.09247 ]], R is [[67.11865997]
 [67.15529633]
 [67.18899536]
 [67.21971893]
 [67.24742126]].
[2019-03-24 07:16:49,500] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:16:49,507] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7667
[2019-03-24 07:16:49,509] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.7, 67.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4819216178358805, 6.911200000000001, 6.9112, 121.9260426156618, 344300.8392206779, 344300.8392206775, 112043.6595026664], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7693800.0000, 
sim time next is 7694400.0000, 
raw observation next is [19.7, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4691331103139398, 6.911200000000001, 6.9112, 121.9260426156618, 334976.5147017079, 334976.5147017075, 108560.8104443203], 
processed observation next is [1.0, 0.043478260869565216, 0.28518518518518515, 0.66, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3364163878924247, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.11963446953632426, 0.11963446953632412, 0.2087707893160006], 
reward next is 0.7912, 
noisyNet noise sample is [array([0.7424052], dtype=float32), -1.0430193]. 
=============================================
[2019-03-24 07:16:50,951] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:16:50,952] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:16:50,962] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:16:50,969] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8806
[2019-03-24 07:16:50,975] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.8, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4792850979824161, 6.911199999999999, 6.9112, 121.9260426156618, 345199.7661540575, 345199.7661540579, 114608.1735064262], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7702800.0000, 
sim time next is 7703400.0000, 
raw observation next is [18.7, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4863752174504613, 6.911200000000001, 6.9112, 121.9260426156618, 351324.8262137747, 351324.8262137743, 115522.0275432189], 
processed observation next is [1.0, 0.13043478260869565, 0.24814814814814812, 0.81, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3579690218130766, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12547315221920524, 0.1254731522192051, 0.22215774527542095], 
reward next is 0.7778, 
noisyNet noise sample is [array([1.7867852], dtype=float32), -0.46514753]. 
=============================================
[2019-03-24 07:16:51,006] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run8
[2019-03-24 07:16:53,081] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:16:53,085] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9100
[2019-03-24 07:16:53,093] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1541651.907852864 W.
[2019-03-24 07:16:53,099] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.1, 51.0, 1.0, 2.0, 0.7038234043852539, 0.0, 1.0, 0.0, 1.0, 1.0, 0.973079358805831, 6.911200000000001, 6.9112, 121.9260426156618, 1541651.907852864, 1541651.907852864, 313060.4054911469], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7749000.0000, 
sim time next is 7749600.0000, 
raw observation next is [29.06666666666667, 51.33333333333333, 1.0, 2.0, 0.6254321306344456, 0.0, 2.0, 0.0, 1.0, 2.0, 0.972290628697039, 6.911200000000002, 6.9112, 121.9260426156618, 1450317.141564516, 1450317.141564515, 298938.7523298251], 
processed observation next is [1.0, 0.6956521739130435, 0.6320987654320989, 0.5133333333333333, 1.0, 1.0, 0.5540858698029114, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9653632858712987, 1.7763568394002506e-16, 0.0, 0.8094621288201359, 0.5179704077016128, 0.5179704077016125, 0.5748822160188943], 
reward next is 0.4251, 
noisyNet noise sample is [array([-0.77224594], dtype=float32), -0.10081445]. 
=============================================
[2019-03-24 07:16:54,288] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:16:54,288] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:16:54,331] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run8
[2019-03-24 07:16:55,170] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:16:55,176] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9943
[2019-03-24 07:16:55,178] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.85, 63.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6879465091120633, 6.911200000000001, 6.9112, 121.9260426156618, 514082.9099625169, 514082.9099625164, 143261.3712528385], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7759800.0000, 
sim time next is 7760400.0000, 
raw observation next is [24.56666666666667, 64.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6808012758477296, 6.9112, 6.9112, 121.9260426156618, 508689.9362482735, 508689.9362482735, 142163.4124892705], 
processed observation next is [1.0, 0.8260869565217391, 0.46543209876543223, 0.6433333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.601001594809662, 0.0, 0.0, 0.8094621288201359, 0.18167497723152623, 0.18167497723152623, 0.2733911778639817], 
reward next is 0.7266, 
noisyNet noise sample is [array([0.08087452], dtype=float32), 0.025162969]. 
=============================================
[2019-03-24 07:17:02,840] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 2.5696633e-38 0.0000000e+00 5.5666038e-38 3.0057670e-37], sum to 1.0000
[2019-03-24 07:17:02,848] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0048
[2019-03-24 07:17:02,852] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1589597.30366299 W.
[2019-03-24 07:17:02,855] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.65, 47.5, 1.0, 2.0, 0.4571352108227168, 1.0, 1.0, 0.4571352108227168, 1.0, 2.0, 0.7290342570091377, 6.911199999999999, 6.9112, 121.94756008, 1589597.30366299, 1589597.303662991, 323129.257279528], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7911000.0000, 
sim time next is 7911600.0000, 
raw observation next is [29.8, 47.0, 1.0, 2.0, 0.4645071321000932, 1.0, 2.0, 0.4645071321000932, 1.0, 2.0, 0.7401546395586828, 6.911199999999999, 6.9112, 121.94756008, 1605929.18526512, 1605929.185265121, 326591.212771765], 
processed observation next is [1.0, 0.5652173913043478, 0.6592592592592593, 0.47, 1.0, 1.0, 0.362508490595349, 1.0, 1.0, 0.362508490595349, 1.0, 1.0, 0.6751932994483534, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5735461375946856, 0.5735461375946861, 0.6280600245610866], 
reward next is 0.3719, 
noisyNet noise sample is [array([0.88839525], dtype=float32), -0.1789405]. 
=============================================
[2019-03-24 07:17:02,981] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:17:02,981] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:17:03,037] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run8
[2019-03-24 07:17:03,174] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:17:03,175] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:17:03,203] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run8
[2019-03-24 07:17:03,869] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:17:03,870] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:17:03,899] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run8
[2019-03-24 07:17:03,923] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:17:03,929] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:17:03,958] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run8
[2019-03-24 07:17:03,981] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:17:03,981] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:17:04,005] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run8
[2019-03-24 07:17:04,253] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:17:04,253] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:17:04,256] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run8
[2019-03-24 07:17:04,549] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:17:04,549] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:17:04,563] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run8
[2019-03-24 07:17:04,594] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:17:04,594] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:17:04,609] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:17:04,609] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:17:04,610] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run8
[2019-03-24 07:17:04,656] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run8
[2019-03-24 07:17:04,867] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:17:04,868] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:17:04,872] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run8
[2019-03-24 07:17:04,965] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:17:04,965] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:17:04,968] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run8
[2019-03-24 07:17:05,109] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:17:05,109] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:17:05,113] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run8
[2019-03-24 07:17:05,153] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:17:05,153] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:17:05,157] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run8
[2019-03-24 07:17:05,290] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:17:05,290] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:17:05,294] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run8
[2019-03-24 07:17:06,684] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:17:06,691] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5709
[2019-03-24 07:17:06,694] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.8, 52.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5395750920798172, 6.911200000000001, 6.9112, 121.9260426156618, 385268.938554208, 385268.9385542075, 113876.6392314768], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 27000.0000, 
sim time next is 27600.0000, 
raw observation next is [22.13333333333333, 51.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5026531997221309, 6.9112, 6.9112, 121.9260426156618, 358899.6954481937, 358899.6954481937, 111491.665965874], 
processed observation next is [1.0, 0.30434782608695654, 0.3753086419753085, 0.51, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3783164996526635, 0.0, 0.0, 0.8094621288201359, 0.1281784626600692, 0.1281784626600692, 0.21440704993437307], 
reward next is 0.7856, 
noisyNet noise sample is [array([1.7155409], dtype=float32), 0.08189397]. 
=============================================
[2019-03-24 07:17:08,989] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:17:08,995] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9777
[2019-03-24 07:17:09,005] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1465368.043364013 W.
[2019-03-24 07:17:09,009] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.03333333333333, 36.83333333333334, 1.0, 2.0, 0.6070514775363928, 1.0, 2.0, 0.6070514775363928, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1465368.043364013, 1465368.043364013, 273955.630799206], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 53400.0000, 
sim time next is 54000.0000, 
raw observation next is [30.0, 37.0, 1.0, 2.0, 0.414111941201072, 1.0, 2.0, 0.414111941201072, 1.0, 1.0, 0.6673623445817771, 6.9112, 6.9112, 121.94756008, 1486054.798357318, 1486054.798357318, 302987.5466783535], 
processed observation next is [1.0, 0.6521739130434783, 0.6666666666666666, 0.37, 1.0, 1.0, 0.30251421571556186, 1.0, 1.0, 0.30251421571556186, 1.0, 0.5, 0.5842029307272214, 0.0, 0.0, 0.8096049824067558, 0.530733856556185, 0.530733856556185, 0.5826683589968337], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.54666823], dtype=float32), -0.65904665]. 
=============================================
[2019-03-24 07:17:09,021] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[60.25486 ]
 [59.964146]
 [59.454273]
 [59.15781 ]
 [59.288555]], R is [[59.8460083 ]
 [59.72071075]
 [59.12350464]
 [58.53226852]
 [57.94694519]].
[2019-03-24 07:17:09,943] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:17:09,948] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1330
[2019-03-24 07:17:09,951] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.75, 43.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6690132548698249, 6.911199999999999, 6.9112, 121.9260426156618, 499842.1861612416, 499842.1861612421, 140761.1246023503], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 66600.0000, 
sim time next is 67200.0000, 
raw observation next is [28.63333333333333, 44.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6671933585899196, 6.911200000000001, 6.9112, 121.9260426156618, 498484.3204522333, 498484.3204522328, 140577.1880480851], 
processed observation next is [1.0, 0.782608695652174, 0.6160493827160493, 0.44, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5839916982373994, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1780301144472262, 0.178030114447226, 0.27034074624631754], 
reward next is 0.7297, 
noisyNet noise sample is [array([1.7009804], dtype=float32), -0.0771134]. 
=============================================
[2019-03-24 07:17:10,686] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:17:10,694] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1264
[2019-03-24 07:17:10,697] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.4, 75.66666666666667, 1.0, 2.0, 0.4966753918833529, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.926042615611, 611937.6742071722, 611937.6742071722, 142985.3059253352], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 96000.0000, 
sim time next is 96600.0000, 
raw observation next is [22.3, 75.83333333333333, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7896310275336377, 6.911199999999999, 6.9112, 121.9260426156618, 589506.2856906326, 589506.2856906331, 153085.6607130476], 
processed observation next is [1.0, 0.08695652173913043, 0.38148148148148153, 0.7583333333333333, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.737038784417047, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21053795917522594, 0.2105379591752261, 0.29439550137124537], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2911907], dtype=float32), 0.33668002]. 
=============================================
[2019-03-24 07:17:19,218] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:17:19,230] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8411
[2019-03-24 07:17:19,234] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.36666666666667, 38.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5546772966581477, 6.9112, 6.9112, 121.9260426156618, 397677.9359154766, 397677.9359154766, 119909.2938115108], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 252600.0000, 
sim time next is 253200.0000, 
raw observation next is [25.03333333333333, 39.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.549508289029583, 6.9112, 6.9112, 121.9260426156618, 393567.2671975344, 393567.2671975344, 119357.5702640542], 
processed observation next is [0.0, 0.9565217391304348, 0.482716049382716, 0.3933333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.43688536128697875, 0.0, 0.0, 0.8094621288201359, 0.1405597382848337, 0.1405597382848337, 0.229533788969335], 
reward next is 0.7705, 
noisyNet noise sample is [array([0.0705386], dtype=float32), -0.22752614]. 
=============================================
[2019-03-24 07:17:23,624] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:17:23,631] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6873
[2019-03-24 07:17:23,638] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.56666666666667, 38.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5523188884656544, 6.9112, 6.9112, 121.9260426156618, 396999.1533287051, 396999.1533287051, 120065.8001078649], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 333600.0000, 
sim time next is 334200.0000, 
raw observation next is [25.43333333333334, 38.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5500951367691039, 6.911199999999999, 6.9112, 121.9260426156618, 395302.2177137018, 395302.2177137022, 119851.8760527041], 
processed observation next is [0.0, 0.8695652173913043, 0.4975308641975311, 0.385, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4376189209613799, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1411793634691792, 0.14117936346917934, 0.23048437702443098], 
reward next is 0.7695, 
noisyNet noise sample is [array([-1.2950222], dtype=float32), -0.6576889]. 
=============================================
[2019-03-24 07:17:27,009] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:17:27,015] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0912
[2019-03-24 07:17:27,020] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.9, 29.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6072223554700836, 6.9112, 6.9112, 121.9260426156618, 446919.7624988327, 446919.7624988327, 128854.6119656446], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 410400.0000, 
sim time next is 411000.0000, 
raw observation next is [29.75, 29.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6052667357509136, 6.911200000000001, 6.9112, 121.9260426156618, 445291.652077164, 445291.6520771636, 128581.7919100313], 
processed observation next is [1.0, 0.782608695652174, 0.6574074074074074, 0.2933333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.506583419688642, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15903273288470143, 0.1590327328847013, 0.2472726767500602], 
reward next is 0.7527, 
noisyNet noise sample is [array([1.2863079], dtype=float32), -2.2008102]. 
=============================================
[2019-03-24 07:17:27,034] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[68.28895 ]
 [67.68473 ]
 [67.12466 ]
 [66.97825 ]
 [64.540535]], R is [[69.03934479]
 [69.10115814]
 [69.16226196]
 [69.2223053 ]
 [69.28105164]].
[2019-03-24 07:17:28,102] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:17:28,109] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9584
[2019-03-24 07:17:28,114] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.9, 47.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5089222175006263, 6.911200000000001, 6.9112, 121.9260426156618, 367516.2610158193, 367516.2610158189, 117240.9347140959], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 432000.0000, 
sim time next is 432600.0000, 
raw observation next is [23.61666666666667, 48.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5043874635996134, 6.911200000000001, 6.9112, 121.9260426156618, 364102.415646111, 364102.4156461105, 116833.8893589421], 
processed observation next is [1.0, 0.0, 0.4302469135802471, 0.48333333333333345, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3804843294995167, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13003657701646823, 0.13003657701646804, 0.22468055645950405], 
reward next is 0.7753, 
noisyNet noise sample is [array([-0.15313856], dtype=float32), 0.17656381]. 
=============================================
[2019-03-24 07:17:35,019] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-24 07:17:35,021] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:17:35,021] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:17:35,022] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:17:35,023] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:17:35,024] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:17:35,025] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:17:35,025] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:17:35,025] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:17:35,026] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:17:35,027] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:17:35,048] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run61
[2019-03-24 07:17:35,075] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run61
[2019-03-24 07:17:35,099] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run61
[2019-03-24 07:17:35,124] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run61
[2019-03-24 07:17:35,125] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run61
[2019-03-24 07:17:39,396] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.018942231]
[2019-03-24 07:17:39,397] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [12.7, 77.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2851949901191976, 6.9112, 6.9112, 121.9260426156618, 203611.6271117143, 203611.6271117143, 69616.62202665253]
[2019-03-24 07:17:39,400] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:17:39,402] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.0030128522662520307
[2019-03-24 07:17:43,434] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.018942231]
[2019-03-24 07:17:43,439] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [18.7, 69.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5359305965445182, 6.9112, 6.9112, 121.9260426156618, 382666.0362716186, 382666.0362716186, 109171.9005079308]
[2019-03-24 07:17:43,440] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:17:43,444] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.2946752364039329
[2019-03-24 07:17:51,268] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.018942231]
[2019-03-24 07:17:51,269] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.17839759666667, 72.16941023333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6194585080241893, 6.911200000000001, 6.9112, 121.9260426156618, 460892.3631581333, 460892.3631581328, 133077.7256629917]
[2019-03-24 07:17:51,271] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:17:51,275] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.1586106292182916
[2019-03-24 07:17:53,966] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.018942231]
[2019-03-24 07:17:53,968] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.1, 71.0, 1.0, 2.0, 0.633987065917054, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156618, 794523.0118124159, 794523.011812415, 166635.0395660436]
[2019-03-24 07:17:53,969] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:17:53,973] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.00000000e+00 1.88141779e-32 1.08646405e-36 5.39584821e-32
 2.07329039e-31], sampled 0.4637390152688907
[2019-03-24 07:17:53,973] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 794523.0118124159 W.
[2019-03-24 07:18:29,863] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.018942231]
[2019-03-24 07:18:29,864] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [33.96666666666667, 48.66666666666666, 1.0, 2.0, 0.6932557219702795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 790111.4467162414, 790111.4467162414, 174872.3511836287]
[2019-03-24 07:18:29,865] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:18:29,868] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.8833892515845455
[2019-03-24 07:18:29,870] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 790111.4467162414 W.
[2019-03-24 07:18:45,329] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.018942231]
[2019-03-24 07:18:45,331] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.26666666666667, 97.0, 1.0, 2.0, 0.6460926127719354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 736333.2958018801, 736333.2958018805, 166187.753356479]
[2019-03-24 07:18:45,331] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:18:45,334] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.3144943e-38 1.2614405e-37], sampled 0.9998435430877645
[2019-03-24 07:18:45,334] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 736333.2958018801 W.
[2019-03-24 07:18:54,801] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.018942231]
[2019-03-24 07:18:54,802] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [28.53307095, 81.66131872666666, 1.0, 2.0, 0.7552730358108435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 860832.9787819084, 860832.9787819084, 186877.608749536]
[2019-03-24 07:18:54,803] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:18:54,806] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 9.4886381e-38 0.0000000e+00 2.3199671e-37 1.1161731e-36], sampled 0.3119115897596497
[2019-03-24 07:18:54,809] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 860832.9787819084 W.
[2019-03-24 07:19:06,939] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.018942231]
[2019-03-24 07:19:06,940] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.4847367, 90.65000679500001, 1.0, 2.0, 0.7293146779107957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 831230.5343579551, 831230.5343579556, 181769.9012207203]
[2019-03-24 07:19:06,940] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:19:06,944] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.3775101479040539
[2019-03-24 07:19:06,946] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 831230.5343579551 W.
[2019-03-24 07:19:16,507] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.018942231]
[2019-03-24 07:19:16,508] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.58333333333333, 86.83333333333333, 1.0, 2.0, 0.6828225276086151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 836973.9345719052, 836973.9345719047, 175331.3656214288]
[2019-03-24 07:19:16,508] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:19:16,513] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.3586898e-33 4.9618930e-38 3.7714362e-33 1.3771785e-32], sampled 0.38392555551595076
[2019-03-24 07:19:16,517] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 836973.9345719052 W.
[2019-03-24 07:19:24,275] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.018942231]
[2019-03-24 07:19:24,276] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [20.0, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6166392753783151, 6.9112, 6.9112, 121.9260426156618, 459635.4713996213, 459635.4713996213, 133606.6688753329]
[2019-03-24 07:19:24,277] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:19:24,280] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.6562827781698081
[2019-03-24 07:19:24,754] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 07:19:24,860] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 07:19:24,872] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 07:19:24,942] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 07:19:25,017] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 07:19:26,034] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1500000, evaluation results [1500000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 07:19:27,345] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:19:27,351] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8556
[2019-03-24 07:19:27,356] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.5, 37.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6341741107608978, 6.9112, 6.9112, 121.9260426156618, 472760.0555131723, 472760.0555131723, 135398.5156114662], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 590400.0000, 
sim time next is 591000.0000, 
raw observation next is [29.31666666666667, 37.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6320467512786772, 6.911200000000001, 6.9112, 121.9260426156618, 471075.2231353492, 471075.2231353488, 135079.1619169091], 
processed observation next is [1.0, 0.8695652173913043, 0.6413580246913582, 0.375, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5400584390983464, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1682411511197676, 0.16824115111976742, 0.25976761907097906], 
reward next is 0.7402, 
noisyNet noise sample is [array([-0.88435966], dtype=float32), -1.7927805]. 
=============================================
[2019-03-24 07:19:27,371] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[74.337524]
 [74.27147 ]
 [74.37581 ]
 [74.13647 ]
 [73.93151 ]], R is [[74.10380554]
 [74.10238647]
 [74.10048676]
 [74.09807587]
 [74.09507751]].
[2019-03-24 07:19:30,854] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:19:30,861] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4112
[2019-03-24 07:19:30,865] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [32.2, 23.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.648677136950556, 6.911200000000001, 6.9112, 121.9260426156618, 478355.2442662669, 478355.2442662664, 133193.6817922283], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 675000.0000, 
sim time next is 675600.0000, 
raw observation next is [31.96666666666667, 23.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6500824696860487, 6.9112, 6.9112, 121.9260426156618, 478975.5081222823, 478975.5081222823, 133111.7437829788], 
processed observation next is [1.0, 0.8260869565217391, 0.7395061728395063, 0.2333333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5626030871075608, 0.0, 0.0, 0.8094621288201359, 0.17106268147224368, 0.17106268147224368, 0.2559841226595746], 
reward next is 0.7440, 
noisyNet noise sample is [array([1.169817], dtype=float32), 2.166925]. 
=============================================
[2019-03-24 07:19:34,058] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 3.2162652e-37 0.0000000e+00 3.8783172e-35 4.4934920e-34], sum to 1.0000
[2019-03-24 07:19:34,061] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0844
[2019-03-24 07:19:34,067] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.7, 54.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7478377232701625, 6.911199999999999, 6.9112, 121.9260426156618, 548479.1884169162, 548479.1884169166, 141626.2740972278], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 715200.0000, 
sim time next is 715800.0000, 
raw observation next is [23.8, 54.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.786042862997888, 6.9112, 6.9112, 121.9260426156618, 577216.9097882496, 577216.9097882496, 145917.1917354672], 
processed observation next is [1.0, 0.2608695652173913, 0.43703703703703706, 0.54, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7325535787473599, 0.0, 0.0, 0.8094621288201359, 0.2061488963529463, 0.2061488963529463, 0.2806099841066677], 
reward next is 0.7194, 
noisyNet noise sample is [array([-1.4078951], dtype=float32), -0.8272007]. 
=============================================
[2019-03-24 07:19:50,743] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:19:50,751] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8457
[2019-03-24 07:19:50,762] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.4, 64.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5218644367380314, 6.9112, 6.9112, 121.9260426156618, 379786.1452795098, 379786.1452795098, 119394.4775238545], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1043400.0000, 
sim time next is 1044000.0000, 
raw observation next is [21.3, 65.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5232388268212232, 6.9112, 6.9112, 121.9260426156618, 380953.050154114, 380953.050154114, 119574.5291648363], 
processed observation next is [1.0, 0.08695652173913043, 0.3444444444444445, 0.65, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.40404853352652903, 0.0, 0.0, 0.8094621288201359, 0.13605466076932643, 0.13605466076932643, 0.2299510176246852], 
reward next is 0.7700, 
noisyNet noise sample is [array([0.6463609], dtype=float32), -0.6029321]. 
=============================================
[2019-03-24 07:19:50,781] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[58.706345]
 [59.08863 ]
 [59.273746]
 [59.63932 ]
 [60.021667]], R is [[58.68375397]
 [58.86730957]
 [59.04941559]
 [59.23018646]
 [59.40969467]].
[2019-03-24 07:19:50,963] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:19:50,973] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5103
[2019-03-24 07:19:50,976] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.31666666666667, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6216266552836511, 6.911199999999999, 6.9112, 121.9260426156618, 462496.6041883634, 462496.6041883638, 133280.8972569183], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1296600.0000, 
sim time next is 1297200.0000, 
raw observation next is [20.23333333333333, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6169267075209155, 6.911200000000001, 6.9112, 121.9260426156618, 458736.9680984318, 458736.9680984313, 132607.0822174789], 
processed observation next is [1.0, 0.0, 0.3049382716049382, 0.86, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5211583844011444, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16383463146372565, 0.16383463146372546, 0.2550136196489979], 
reward next is 0.7450, 
noisyNet noise sample is [array([-0.06506963], dtype=float32), -0.49490607]. 
=============================================
[2019-03-24 07:19:54,219] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:19:54,224] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0749
[2019-03-24 07:19:54,230] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.08333333333334, 74.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5787787890202587, 6.9112, 6.9112, 121.9260426156618, 414692.1080612357, 414692.1080612357, 121784.5474826109], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1131000.0000, 
sim time next is 1131600.0000, 
raw observation next is [19.06666666666667, 74.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5119528548275951, 6.9112, 6.9112, 121.9260426156618, 366840.3729134668, 366840.3729134668, 116465.5106997901], 
processed observation next is [1.0, 0.08695652173913043, 0.2617283950617285, 0.7433333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.38994106853449384, 0.0, 0.0, 0.8094621288201359, 0.1310144188976667, 0.1310144188976667, 0.2239721359611348], 
reward next is 0.7760, 
noisyNet noise sample is [array([0.64093184], dtype=float32), 0.033205453]. 
=============================================
[2019-03-24 07:19:54,400] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:19:54,405] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5462
[2019-03-24 07:19:54,411] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.8, 56.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5745382214064993, 6.9112, 6.9112, 121.9260426156618, 424338.2679815413, 424338.2679815413, 126689.6700224202], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1104000.0000, 
sim time next is 1104600.0000, 
raw observation next is [23.55, 57.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5730894275077566, 6.9112, 6.9112, 121.9260426156618, 423093.8315448696, 423093.8315448696, 126462.1617043654], 
processed observation next is [1.0, 0.782608695652174, 0.4277777777777778, 0.5783333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4663617843846957, 0.0, 0.0, 0.8094621288201359, 0.15110493983745343, 0.15110493983745343, 0.2431964648160873], 
reward next is 0.7568, 
noisyNet noise sample is [array([-0.5248492], dtype=float32), 0.90355027]. 
=============================================
[2019-03-24 07:20:02,708] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:20:02,716] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4677
[2019-03-24 07:20:02,719] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [33.2, 39.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8282414606510207, 6.911199999999999, 6.9112, 121.9260426156618, 610668.9214646199, 610668.9214646204, 165547.8253553041], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1528200.0000, 
sim time next is 1528800.0000, 
raw observation next is [33.03333333333334, 40.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8432483176199643, 6.9112, 6.9112, 121.9260426156618, 620386.7180681559, 620386.7180681559, 167803.2365047126], 
processed observation next is [0.0, 0.6956521739130435, 0.7790123456790126, 0.40333333333333327, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8040603970249555, 0.0, 0.0, 0.8094621288201359, 0.2215666850243414, 0.2215666850243414, 0.32269853173983193], 
reward next is 0.6773, 
noisyNet noise sample is [array([0.36196965], dtype=float32), 0.035457846]. 
=============================================
[2019-03-24 07:20:03,297] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:20:03,304] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3513
[2019-03-24 07:20:03,310] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.76666666666667, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5959452982565984, 6.9112, 6.9112, 121.9260426156618, 441391.2680962301, 441391.2680962301, 129369.9277918481], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1300800.0000, 
sim time next is 1301400.0000, 
raw observation next is [19.7, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5906244090155351, 6.911199999999999, 6.9112, 121.9260426156618, 437165.7858235734, 437165.7858235738, 128700.6743849932], 
processed observation next is [1.0, 0.043478260869565216, 0.28518518518518515, 0.86, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4882805112694189, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15613063779413336, 0.1561306377941335, 0.24750129689421768], 
reward next is 0.7525, 
noisyNet noise sample is [array([0.8596066], dtype=float32), -0.036526866]. 
=============================================
[2019-03-24 07:20:03,689] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:20:03,697] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5025
[2019-03-24 07:20:03,704] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1481909.203606661 W.
[2019-03-24 07:20:03,708] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.81666666666667, 31.66666666666667, 1.0, 2.0, 0.9667097520756995, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.463308708757911, 6.9112, 121.9237902010529, 1481909.203606661, 1199185.420832612, 237029.0203290212], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1350600.0000, 
sim time next is 1351200.0000, 
raw observation next is [30.83333333333334, 31.33333333333334, 1.0, 2.0, 0.3616868798510472, 1.0, 1.0, 0.3616868798510472, 1.0, 1.0, 0.5865907046376028, 6.9112, 6.9112, 121.94756008, 1311822.830272419, 1311822.830272419, 279951.3201418728], 
processed observation next is [1.0, 0.6521739130434783, 0.6975308641975311, 0.3133333333333334, 1.0, 1.0, 0.2401034283941038, 1.0, 0.5, 0.2401034283941038, 1.0, 0.5, 0.48323838079700343, 0.0, 0.0, 0.8096049824067558, 0.46850815366872106, 0.46850815366872106, 0.5383679233497554], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.39240816], dtype=float32), 0.18715788]. 
=============================================
[2019-03-24 07:20:08,981] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:20:08,988] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7992
[2019-03-24 07:20:08,991] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.83333333333333, 64.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5098329279506338, 6.9112, 6.9112, 121.9260426156618, 367865.5279997481, 367865.5279997481, 117199.1988547912], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1394400.0000, 
sim time next is 1395000.0000, 
raw observation next is [20.8, 64.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5051826558162543, 6.9112, 6.9112, 121.9260426156618, 363959.7611884105, 363959.7611884105, 116634.9898811867], 
processed observation next is [0.0, 0.13043478260869565, 0.32592592592592595, 0.64, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3814783197703179, 0.0, 0.0, 0.8094621288201359, 0.12998562899586089, 0.12998562899586089, 0.2242980574638206], 
reward next is 0.7757, 
noisyNet noise sample is [array([-0.7450252], dtype=float32), 1.1239289]. 
=============================================
[2019-03-24 07:20:09,008] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[80.117805]
 [80.11862 ]
 [79.96538 ]
 [79.891846]
 [79.65218 ]], R is [[80.14913177]
 [80.12226105]
 [80.09456635]
 [80.06620026]
 [80.03735352]].
[2019-03-24 07:20:14,308] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-24 07:20:14,309] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:20:14,310] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:20:14,312] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:20:14,313] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:20:14,314] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:20:14,313] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:20:14,316] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:20:14,311] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:20:14,316] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:20:14,319] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:20:14,335] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run62
[2019-03-24 07:20:14,364] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run62
[2019-03-24 07:20:14,391] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run62
[2019-03-24 07:20:14,392] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run62
[2019-03-24 07:20:14,392] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run62
[2019-03-24 07:20:18,485] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.019481879]
[2019-03-24 07:20:18,486] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [33.45637770166667, 17.999073825, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6530804150050482, 6.911200000000001, 6.9112, 121.9260426156618, 476949.7171770393, 476949.7171770388, 131442.6683587585]
[2019-03-24 07:20:18,487] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:20:18,491] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.9653653637258592
[2019-03-24 07:21:17,608] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.019481879]
[2019-03-24 07:21:17,610] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.29192422833333, 102.3402029333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8677326032277546, 6.911199999999999, 6.9112, 121.9260426156618, 638460.660807056, 638460.6608070565, 170920.603970957]
[2019-03-24 07:21:17,611] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:21:17,613] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.27423404247532723
[2019-03-24 07:21:17,814] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.019481879]
[2019-03-24 07:21:17,815] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.83333333333333, 79.83333333333334, 1.0, 2.0, 0.6280303602986449, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 715738.6523548639, 715738.6523548639, 162966.7378812082]
[2019-03-24 07:21:17,816] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:21:17,819] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.18478785148687937
[2019-03-24 07:21:17,822] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 715738.6523548639 W.
[2019-03-24 07:21:40,597] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.019481879]
[2019-03-24 07:21:40,600] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.3, 81.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7726952630302593, 6.911200000000001, 6.9112, 121.9260426156618, 575789.6235662407, 575789.6235662402, 155829.8978220792]
[2019-03-24 07:21:40,602] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:21:40,605] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.5188233239254192
[2019-03-24 07:21:42,576] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.019481879]
[2019-03-24 07:21:42,578] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.62966591666667, 91.71187087, 1.0, 2.0, 0.5723927325076114, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9112678716819821, 6.911200000000001, 6.9112, 121.9260426155546, 1305163.325146926, 1305163.325146926, 283274.9458801803]
[2019-03-24 07:21:42,580] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:21:42,582] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.5259113906401023
[2019-03-24 07:21:42,582] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1305163.325146926 W.
[2019-03-24 07:22:02,855] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 07:22:02,863] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 07:22:03,091] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 07:22:03,115] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 07:22:03,198] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 07:22:04,214] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1525000, evaluation results [1525000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 07:22:05,490] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:22:05,501] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3453
[2019-03-24 07:22:05,505] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [35.46666666666667, 22.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6886231326862997, 6.911200000000001, 6.9112, 121.9260426156618, 514422.4448261738, 514422.4448261734, 142615.7172743955], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1520400.0000, 
sim time next is 1521000.0000, 
raw observation next is [35.3, 23.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.682939524529749, 6.911200000000001, 6.9112, 121.9260426156618, 510323.920576083, 510323.9205760826, 142586.4413951468], 
processed observation next is [0.0, 0.6086956521739131, 0.8629629629629628, 0.235, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6036744056621862, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1822585430628868, 0.18225854306288664, 0.2742046949906669], 
reward next is 0.7258, 
noisyNet noise sample is [array([0.00798841], dtype=float32), -1.0682353]. 
=============================================
[2019-03-24 07:22:05,519] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[72.9291 ]
 [72.90528]
 [72.92919]
 [72.91198]
 [72.9019 ]], R is [[73.0199585 ]
 [73.0154953 ]
 [73.00724792]
 [73.00436401]
 [73.00137329]].
[2019-03-24 07:22:18,403] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 3.7108500e-36 0.0000000e+00 5.5439950e-37 3.7469396e-35], sum to 1.0000
[2019-03-24 07:22:18,409] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6440
[2019-03-24 07:22:18,417] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1588942.206044564 W.
[2019-03-24 07:22:18,421] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 58.0, 1.0, 2.0, 0.4633032322369888, 1.0, 2.0, 0.4633032322369888, 1.0, 2.0, 0.7376900559565721, 6.911200000000001, 6.9112, 121.94756008, 1588942.206044564, 1588942.206044564, 325952.3669719982], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1782000.0000, 
sim time next is 1782600.0000, 
raw observation next is [27.83333333333334, 59.33333333333334, 1.0, 2.0, 0.6273665096520092, 1.0, 2.0, 0.6273665096520092, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1451914.305343684, 1451914.305343684, 278623.2481207395], 
processed observation next is [1.0, 0.6521739130434783, 0.58641975308642, 0.5933333333333334, 1.0, 1.0, 0.5563887019666777, 1.0, 1.0, 0.5563887019666777, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.51854082333703, 0.51854082333703, 0.5358139386937297], 
reward next is 0.4642, 
noisyNet noise sample is [array([-0.73977345], dtype=float32), 0.8802626]. 
=============================================
[2019-03-24 07:22:25,608] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:22:25,614] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2125
[2019-03-24 07:22:25,617] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.13333333333333, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6482197405386063, 6.911200000000001, 6.9112, 121.9260426156618, 483685.6488156224, 483685.648815622, 137365.5213365554], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1903200.0000, 
sim time next is 1903800.0000, 
raw observation next is [20.06666666666667, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6439799311033717, 6.911200000000001, 6.9112, 121.9260426156618, 480389.1251618484, 480389.1251618479, 136758.4361212797], 
processed observation next is [1.0, 0.0, 0.29876543209876555, 0.92, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5549749138792146, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17156754470066013, 0.17156754470065996, 0.2629969925409225], 
reward next is 0.7370, 
noisyNet noise sample is [array([0.2223664], dtype=float32), -0.7561409]. 
=============================================
[2019-03-24 07:22:27,029] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:22:27,038] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1217
[2019-03-24 07:22:27,042] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.4, 90.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5998037344142494, 6.911200000000001, 6.9112, 121.9260426156618, 444737.4180582207, 444737.4180582202, 130044.0027167628], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1995000.0000, 
sim time next is 1995600.0000, 
raw observation next is [19.4, 90.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6001179481771226, 6.911200000000001, 6.9112, 121.9260426156618, 445117.7310259821, 445117.7310259817, 130172.1329776607], 
processed observation next is [0.0, 0.08695652173913043, 0.274074074074074, 0.9066666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5001474352214033, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15897061822356504, 0.1589706182235649, 0.2503310249570398], 
reward next is 0.7497, 
noisyNet noise sample is [array([0.25244263], dtype=float32), 0.9458215]. 
=============================================
[2019-03-24 07:22:31,486] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:22:31,491] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7064
[2019-03-24 07:22:31,496] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.53333333333333, 63.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9063810209935762, 6.9112, 6.9112, 121.9260426156618, 660437.3479950965, 660437.3479950965, 177335.2767437428], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2042400.0000, 
sim time next is 2043000.0000, 
raw observation next is [28.6, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9119084875813108, 6.9112, 6.9112, 121.9260426156618, 663793.2016338893, 663793.2016338893, 178190.6209366534], 
processed observation next is [0.0, 0.6521739130434783, 0.6148148148148148, 0.63, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8898856094766385, 0.0, 0.0, 0.8094621288201359, 0.23706900058353192, 0.23706900058353192, 0.34267427103202575], 
reward next is 0.6573, 
noisyNet noise sample is [array([0.33116373], dtype=float32), -2.051563]. 
=============================================
[2019-03-24 07:22:31,513] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[66.243454]
 [66.25139 ]
 [66.254974]
 [66.216515]
 [66.2222  ]], R is [[66.24559021]
 [66.24211121]
 [66.24055481]
 [66.24090576]
 [66.24275208]].
[2019-03-24 07:22:42,876] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:22:42,884] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3613
[2019-03-24 07:22:42,893] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1771879.264595419 W.
[2019-03-24 07:22:42,896] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.63333333333333, 30.83333333333334, 1.0, 2.0, 0.7520882994492899, 1.0, 2.0, 0.7520882994492899, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1771879.264595419, 1771879.264595419, 327109.7287014307], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2559000.0000, 
sim time next is 2559600.0000, 
raw observation next is [33.6, 31.0, 1.0, 2.0, 0.7551769835097101, 1.0, 2.0, 0.7551769835097101, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1778607.673420106, 1778607.673420107, 328326.2935983792], 
processed observation next is [1.0, 0.6521739130434783, 0.8, 0.31, 1.0, 1.0, 0.7085440279877501, 1.0, 1.0, 0.7085440279877501, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6352170262214665, 0.6352170262214668, 0.6313967184584215], 
reward next is 0.3686, 
noisyNet noise sample is [array([-0.5853123], dtype=float32), -0.15581599]. 
=============================================
[2019-03-24 07:22:48,502] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 2.8868644e-34 7.0036393e-38 8.6336852e-35 1.4274392e-35], sum to 1.0000
[2019-03-24 07:22:48,508] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4664
[2019-03-24 07:22:48,517] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 896720.4805142476 W.
[2019-03-24 07:22:48,522] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.9, 41.16666666666667, 1.0, 2.0, 0.7168316301181495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156324, 896720.4805142476, 896720.4805142476, 182362.5564302389], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2364600.0000, 
sim time next is 2365200.0000, 
raw observation next is [28.0, 41.0, 1.0, 2.0, 0.3947712601997711, 0.0, 2.0, 0.0, 1.0, 1.0, 0.6549522104566777, 6.911199999999999, 6.9112, 121.9260426156618, 978447.7609497218, 978447.7609497221, 218826.3596559447], 
processed observation next is [1.0, 0.391304347826087, 0.5925925925925926, 0.41, 1.0, 1.0, 0.279489595475918, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.5686902630708471, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3494456289106149, 0.34944562891061504, 0.42081992241527827], 
reward next is 0.5792, 
noisyNet noise sample is [array([-2.6380649], dtype=float32), 1.7219967]. 
=============================================
[2019-03-24 07:22:48,714] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 5.3935266e-38 0.0000000e+00], sum to 1.0000
[2019-03-24 07:22:48,724] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4866
[2019-03-24 07:22:48,731] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1146911.796155819 W.
[2019-03-24 07:22:48,738] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.58333333333334, 40.16666666666667, 1.0, 2.0, 0.8916369757473888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.983114554323725, 6.9112, 121.9256770075686, 1146911.796155819, 1110085.227120825, 219493.7342406838], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2368200.0000, 
sim time next is 2368800.0000, 
raw observation next is [28.7, 40.0, 1.0, 2.0, 0.4549987909900223, 1.0, 1.0, 0.4549987909900223, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9259993100358, 1115641.108580553, 1115641.108580552, 224885.7461133095], 
processed observation next is [1.0, 0.43478260869565216, 0.6185185185185185, 0.4, 1.0, 1.0, 0.3511890368928836, 1.0, 0.5, 0.3511890368928836, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.809461841315814, 0.3984432530644832, 0.39844325306448286, 0.4324725886794413], 
reward next is 0.5675, 
noisyNet noise sample is [array([-2.9185152], dtype=float32), 0.7554549]. 
=============================================
[2019-03-24 07:22:52,732] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-24 07:22:52,734] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:22:52,737] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:22:52,738] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:22:52,738] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:22:52,739] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:22:52,742] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:22:52,745] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:22:52,748] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:22:52,748] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:22:52,751] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:22:52,778] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run63
[2019-03-24 07:22:52,804] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run63
[2019-03-24 07:22:52,835] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run63
[2019-03-24 07:22:52,859] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run63
[2019-03-24 07:22:52,885] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run63
[2019-03-24 07:23:15,122] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.019590244]
[2019-03-24 07:23:15,123] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.16666666666667, 72.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6221867210193868, 6.911200000000001, 6.9112, 121.9260426156618, 462895.0925339468, 462895.0925339463, 133319.9563443216]
[2019-03-24 07:23:15,125] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:23:15,128] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.07510503429080362
[2019-03-24 07:23:52,368] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.019590244]
[2019-03-24 07:23:52,368] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.5, 85.66666666666667, 1.0, 2.0, 0.9656186760199822, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.932843368582311, 6.9112, 121.9258558400935, 1111840.832120344, 1100757.509922168, 232554.0917709031]
[2019-03-24 07:23:52,370] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:23:52,373] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.3208680352176987
[2019-03-24 07:23:52,374] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1111840.832120344 W.
[2019-03-24 07:23:59,361] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.019590244]
[2019-03-24 07:23:59,363] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.83333333333333, 94.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7120286119955777, 6.911200000000001, 6.9112, 121.9260426156618, 532022.676930663, 532022.6769306625, 146730.0762319505]
[2019-03-24 07:23:59,364] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:23:59,368] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.8606156034657407
[2019-03-24 07:24:04,856] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.019590244]
[2019-03-24 07:24:04,857] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.5, 60.0, 1.0, 2.0, 1.014860225752811, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.293950860678317, 6.9112, 121.9242266245379, 1363761.424686387, 1167761.693438451, 244939.3921883498]
[2019-03-24 07:24:04,858] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:24:04,862] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.4285972e-38 0.0000000e+00 2.3746653e-38 3.1316853e-37], sampled 0.8350065854343783
[2019-03-24 07:24:04,863] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1363761.424686387 W.
[2019-03-24 07:24:15,797] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.019590244]
[2019-03-24 07:24:15,798] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.5, 94.0, 1.0, 2.0, 0.8674268307053467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 122.4241069830289, 1050465.452847829, 1050465.452847829, 213196.7021751093]
[2019-03-24 07:24:15,798] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:24:15,803] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 5.5195408e-36 0.0000000e+00 9.1247957e-36 1.0371237e-34], sampled 0.6666085280054903
[2019-03-24 07:24:15,804] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1050465.452847829 W.
[2019-03-24 07:24:30,969] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.019590244]
[2019-03-24 07:24:30,970] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.82922812333333, 75.89943958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.700568395168335, 6.911200000000001, 6.9112, 121.9260426156618, 523508.1795344361, 523508.1795344357, 144543.5863798297]
[2019-03-24 07:24:30,975] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:24:30,977] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.5408546175371987
[2019-03-24 07:24:32,422] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.019590244]
[2019-03-24 07:24:32,425] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.81415921666667, 86.41205866333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6377567595951481, 6.9112, 6.9112, 121.9260426156618, 475956.8628184143, 475956.8628184143, 136418.7374263798]
[2019-03-24 07:24:32,427] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:24:32,429] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.8025816577651548
[2019-03-24 07:24:39,550] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.019590244]
[2019-03-24 07:24:39,551] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.00253056333333, 51.50576060499999, 1.0, 2.0, 0.5408205825104555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 664236.3140238004, 664236.3140238, 150073.9480930477]
[2019-03-24 07:24:39,552] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:24:39,555] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.9529992823971353
[2019-03-24 07:24:40,926] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 07:24:41,282] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 07:24:41,393] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 07:24:41,495] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 07:24:41,503] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 07:24:42,518] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1550000, evaluation results [1550000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 07:24:42,824] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:24:42,835] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4955
[2019-03-24 07:24:42,838] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.8, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5052881691212245, 6.911200000000001, 6.9112, 121.9260426156618, 365203.2071224242, 365203.2071224237, 117071.5247877105], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2439000.0000, 
sim time next is 2439600.0000, 
raw observation next is [20.36666666666667, 70.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5087682404219916, 6.911200000000001, 6.9112, 121.9260426156618, 368995.9036151805, 368995.9036151801, 117832.3476135621], 
processed observation next is [1.0, 0.21739130434782608, 0.3098765432098767, 0.7033333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.38596030052748953, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1317842512911359, 0.13178425129113575, 0.22660066848761942], 
reward next is 0.7734, 
noisyNet noise sample is [array([1.0538788], dtype=float32), 1.2044133]. 
=============================================
[2019-03-24 07:24:51,262] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:24:51,271] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6266
[2019-03-24 07:24:51,276] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.45, 92.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7469358679975173, 6.9112, 6.9112, 121.9260426156618, 557636.4679539811, 557636.4679539811, 151697.9270061144], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2601000.0000, 
sim time next is 2601600.0000, 
raw observation next is [21.36666666666667, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7450774947547472, 6.9112, 6.9112, 121.9260426156618, 556288.0730518443, 556288.0730518443, 151424.8584388788], 
processed observation next is [0.0, 0.08695652173913043, 0.3469135802469137, 0.93, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.681346868443434, 0.0, 0.0, 0.8094621288201359, 0.1986743118042301, 0.1986743118042301, 0.2912016508439977], 
reward next is 0.7088, 
noisyNet noise sample is [array([0.4835631], dtype=float32), -1.5226059]. 
=============================================
[2019-03-24 07:24:52,417] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 1.8668501e-37 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 07:24:52,426] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3209
[2019-03-24 07:24:52,433] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.26666666666667, 77.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8637524770489764, 6.9112, 6.9112, 121.9260426156618, 636590.766663223, 636590.766663223, 170120.3006784613], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2640000.0000, 
sim time next is 2640600.0000, 
raw observation next is [25.4, 77.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8675605464341807, 6.9112, 6.9112, 121.9260426156618, 638772.6183961874, 638772.6183961874, 170782.3910606586], 
processed observation next is [0.0, 0.5652173913043478, 0.49629629629629624, 0.77, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8344506830427258, 0.0, 0.0, 0.8094621288201359, 0.22813307799863836, 0.22813307799863836, 0.32842767511665116], 
reward next is 0.6716, 
noisyNet noise sample is [array([1.2677859], dtype=float32), 1.4258649]. 
=============================================
[2019-03-24 07:24:58,596] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 5.4570069e-28 4.1345075e-31 5.7822495e-27 8.0225663e-26], sum to 1.0000
[2019-03-24 07:24:58,604] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4140
[2019-03-24 07:24:58,614] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 768535.753355268 W.
[2019-03-24 07:24:58,618] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.53333333333333, 76.66666666666667, 1.0, 2.0, 0.337167184206925, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5367811380260069, 6.911199999999999, 6.9112, 121.9260426156618, 768535.753355268, 768535.7533552685, 205503.4089885774], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2752800.0000, 
sim time next is 2753400.0000, 
raw observation next is [27.26666666666667, 77.83333333333334, 1.0, 2.0, 0.2235810271780475, 1.0, 1.0, 0.2235810271780475, 1.0, 2.0, 0.355948276793157, 6.911199999999997, 6.9112, 121.94756008, 764440.6721332145, 764440.6721332159, 228452.5340436658], 
processed observation next is [0.0, 0.8695652173913043, 0.5654320987654322, 0.7783333333333334, 1.0, 1.0, 0.07569169902148513, 1.0, 0.5, 0.07569169902148513, 1.0, 1.0, 0.1949353459914462, -2.6645352591003756e-16, 0.0, 0.8096049824067558, 0.27301452576186236, 0.27301452576186286, 0.4393317962378189], 
reward next is 0.5607, 
noisyNet noise sample is [array([-1.0093356], dtype=float32), 1.2424718]. 
=============================================
[2019-03-24 07:25:09,696] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 3.8449958e-35 0.0000000e+00 3.7414834e-35 7.8447975e-34], sum to 1.0000
[2019-03-24 07:25:09,706] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0607
[2019-03-24 07:25:09,713] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.83333333333333, 76.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9081868504635648, 6.9112, 6.9112, 121.9260426156618, 665684.9126350995, 665684.9126350995, 176819.9962425422], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3269400.0000, 
sim time next is 3270000.0000, 
raw observation next is [25.86666666666667, 77.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9108991595836109, 6.9112, 6.9112, 121.9260426156618, 666670.6734874038, 666670.6734874038, 177393.4830172105], 
processed observation next is [0.0, 0.8695652173913043, 0.5135802469135804, 0.77, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8886239494795136, 0.0, 0.0, 0.8094621288201359, 0.2380966691026442, 0.2380966691026442, 0.34114131349463556], 
reward next is 0.6589, 
noisyNet noise sample is [array([1.0020564], dtype=float32), -1.0725275]. 
=============================================
[2019-03-24 07:25:09,728] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[50.992928]
 [51.103996]
 [51.2881  ]
 [50.879456]
 [50.78527 ]], R is [[50.90309143]
 [51.05402374]
 [51.20549774]
 [51.35555649]
 [51.50439072]].
[2019-03-24 07:25:15,155] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 1.2258854e-29 5.7475894e-35 2.1520285e-30 3.4496564e-28], sum to 1.0000
[2019-03-24 07:25:15,162] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8191
[2019-03-24 07:25:15,164] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.08333333333334, 58.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8446126679016802, 6.9112, 6.9112, 121.9260426156618, 624120.1705360747, 624120.1705360747, 167179.7901064669], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3109800.0000, 
sim time next is 3110400.0000, 
raw observation next is [28.0, 58.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8265160570624674, 6.9112, 6.9112, 121.9260426156618, 612130.9784376853, 612130.9784376853, 164419.9085496709], 
processed observation next is [1.0, 0.0, 0.5925925925925926, 0.58, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7831450713280843, 0.0, 0.0, 0.8094621288201359, 0.2186182065848876, 0.2186182065848876, 0.3161921318262902], 
reward next is 0.6838, 
noisyNet noise sample is [array([-0.42364106], dtype=float32), -0.44369376]. 
=============================================
[2019-03-24 07:25:15,416] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 5.8093774e-27 1.9297703e-32 1.8564973e-28 5.0944901e-28], sum to 1.0000
[2019-03-24 07:25:15,422] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2444
[2019-03-24 07:25:15,431] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.13333333333333, 53.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7808488929445739, 6.9112, 6.9112, 121.9260426156618, 581181.7074856109, 581181.7074856109, 157295.8848489734], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3115200.0000, 
sim time next is 3115800.0000, 
raw observation next is [28.2, 51.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7598894782491808, 6.911199999999999, 6.9112, 121.9260426156618, 566642.286481591, 566642.2864815915, 153961.3706502659], 
processed observation next is [1.0, 0.043478260869565216, 0.6, 0.515, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.699861847811476, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2023722451719968, 0.20237224517199698, 0.296079558942819], 
reward next is 0.7039, 
noisyNet noise sample is [array([0.24309371], dtype=float32), 0.9063646]. 
=============================================
[2019-03-24 07:25:22,843] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:25:22,851] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3405
[2019-03-24 07:25:22,858] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 687174.5202665643 W.
[2019-03-24 07:25:22,864] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.08333333333333, 76.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9568034823829538, 6.911200000000001, 6.9112, 121.9260426156618, 687174.5202665643, 687174.5202665639, 185548.9540163864], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3520200.0000, 
sim time next is 3520800.0000, 
raw observation next is [27.0, 79.0, 1.0, 1.0, 0.3106864398902839, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4946229306562804, 6.911200000000001, 6.9112, 121.9260426156618, 708147.9093340798, 708147.9093340794, 198139.9108375724], 
processed observation next is [1.0, 0.782608695652174, 0.5555555555555556, 0.79, 1.0, 0.5, 0.17938861891700464, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3682786633203504, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2529099676193142, 0.25290996761931406, 0.3810382900722546], 
reward next is 0.6190, 
noisyNet noise sample is [array([0.34681946], dtype=float32), -0.21833763]. 
=============================================
[2019-03-24 07:25:28,596] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 2.1930367e-35 4.3618359e-37 2.5659156e-35 3.8592240e-33], sum to 1.0000
[2019-03-24 07:25:28,606] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8483
[2019-03-24 07:25:28,613] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 746019.7305686548 W.
[2019-03-24 07:25:28,619] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.2181959524258974, 1.0, 2.0, 0.2181959524258974, 1.0, 2.0, 0.3473750624080932, 6.911200000000001, 6.9112, 121.94756008, 746019.7305686548, 746019.7305686544, 226630.6630377792], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3328200.0000, 
sim time next is 3328800.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.3280206324991698, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5222195298248677, 6.911199999999999, 6.9112, 121.9260426156618, 747677.0201858769, 747677.0201858773, 202927.8416110896], 
processed observation next is [0.0, 0.5217391304347826, 0.5555555555555556, 0.79, 1.0, 1.0, 0.20002456249901165, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.4027744122810846, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26702750720924173, 0.2670275072092419, 0.3902458492520954], 
reward next is 0.6098, 
noisyNet noise sample is [array([0.87186384], dtype=float32), 0.1950096]. 
=============================================
[2019-03-24 07:25:29,932] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.1824825e-26 7.7941303e-31 2.7785399e-25 2.2295120e-26], sum to 1.0000
[2019-03-24 07:25:29,945] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6981
[2019-03-24 07:25:29,956] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 793271.6051660809 W.
[2019-03-24 07:25:29,962] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.83333333333333, 74.0, 1.0, 2.0, 0.3480135293273813, 1.0, 1.0, 0.3480135293273813, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 793271.6051660809, 793271.6051660809, 192382.6939004837], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3345000.0000, 
sim time next is 3345600.0000, 
raw observation next is [28.86666666666667, 74.0, 1.0, 2.0, 0.3475601385146337, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5533270597587707, 6.911199999999999, 6.9112, 121.9260426156618, 792237.5995880456, 792237.5995880461, 208472.5024057148], 
processed observation next is [0.0, 0.7391304347826086, 0.6246913580246916, 0.74, 1.0, 1.0, 0.22328587918408774, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.44165882469846335, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.28294199985287344, 0.2829419998528736, 0.40090865847252843], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8837119], dtype=float32), 0.15571968]. 
=============================================
[2019-03-24 07:25:31,271] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-24 07:25:31,272] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:25:31,273] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:25:31,274] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:25:31,274] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:25:31,275] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:25:31,274] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:25:31,276] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:25:31,276] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:25:31,277] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:25:31,278] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:25:31,304] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run64
[2019-03-24 07:25:31,304] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run64
[2019-03-24 07:25:31,332] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run64
[2019-03-24 07:25:31,394] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run64
[2019-03-24 07:25:31,394] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run64
[2019-03-24 07:25:37,186] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.018977499]
[2019-03-24 07:25:37,188] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.22925107, 54.55725255, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4887153867297614, 6.9112, 6.9112, 121.9260426156618, 355933.4481671451, 355933.4481671451, 116852.2898475495]
[2019-03-24 07:25:37,189] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:25:37,194] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 5.2522217e-34 0.0000000e+00 3.7129778e-34 3.3394215e-33], sampled 0.5658988714291838
[2019-03-24 07:25:52,253] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.018977499]
[2019-03-24 07:25:52,255] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.4, 34.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6044439363503733, 6.911199999999999, 6.9112, 121.9260426156618, 450455.4810787014, 450455.4810787019, 132321.6619110703]
[2019-03-24 07:25:52,256] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:25:52,263] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 4.0431765e-36 0.0000000e+00 2.8088864e-36 2.9437676e-35], sampled 0.3129070902204908
[2019-03-24 07:26:16,142] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.018977499]
[2019-03-24 07:26:16,143] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [20.25, 94.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6762817739991428, 6.9112, 6.9112, 121.9260426156618, 505266.9008543638, 505266.9008543638, 141504.7751591764]
[2019-03-24 07:26:16,145] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:26:16,147] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 4.6674128e-35 0.0000000e+00 3.3525139e-35 3.0717387e-34], sampled 0.8180433590307742
[2019-03-24 07:26:28,564] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.018977499]
[2019-03-24 07:26:28,564] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [31.645184175, 73.69054048999999, 1.0, 2.0, 0.7241662215006115, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1540384.557893639, 1540384.55789364, 321672.8431400697]
[2019-03-24 07:26:28,565] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:26:28,568] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 6.0741901e-26 1.4516714e-29 5.2094223e-26 2.9210299e-25], sampled 0.006051461683646897
[2019-03-24 07:26:28,569] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1540384.557893639 W.
[2019-03-24 07:27:04,292] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.018977499]
[2019-03-24 07:27:04,295] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8715973352578968, 6.911200000000001, 6.9112, 121.9260426156618, 641708.8677490745, 641708.867749074, 171313.0878879708]
[2019-03-24 07:27:04,296] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:27:04,299] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 9.3418747e-33 1.7613865e-37 6.8142519e-33 5.6733389e-32], sampled 0.12555249712921102
[2019-03-24 07:27:07,062] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.018977499]
[2019-03-24 07:27:07,063] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.50448994833333, 87.90399067166668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8960314163969596, 6.911199999999999, 6.9112, 121.9260426156618, 653241.129409251, 653241.1294092515, 175892.340500986]
[2019-03-24 07:27:07,064] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:27:07,069] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 8.6893926e-35 0.0000000e+00 6.1989993e-35 5.6464311e-34], sampled 0.09845195175665078
[2019-03-24 07:27:12,583] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.018977499]
[2019-03-24 07:27:12,585] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.279271575, 66.05191860166667, 1.0, 2.0, 0.8803234349240326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1039283.789473167, 1039283.789473167, 214907.4778414053]
[2019-03-24 07:27:12,586] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:27:12,589] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 3.3784642e-25 1.2769537e-28 3.5139316e-25 1.9538371e-24], sampled 0.14440928046372414
[2019-03-24 07:27:12,589] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1039283.789473167 W.
[2019-03-24 07:27:13,454] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.018977499]
[2019-03-24 07:27:13,454] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.33333333333334, 32.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5718762726257126, 6.911200000000001, 6.9112, 121.9260426156618, 411445.5131261535, 411445.513126153, 121798.2500590354]
[2019-03-24 07:27:13,455] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:27:13,460] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 6.3667604e-35 0.0000000e+00 4.4806008e-35 4.3002674e-34], sampled 0.4205038964408784
[2019-03-24 07:27:15,351] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.018977499]
[2019-03-24 07:27:15,351] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [17.5, 84.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4670144065163693, 6.911199999999999, 6.9112, 121.9260426156618, 333447.6887338975, 333447.6887338979, 111056.3163740411]
[2019-03-24 07:27:15,352] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:27:15,353] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 3.6263978e-35 0.0000000e+00 2.5999280e-35 2.4106492e-34], sampled 0.10448363164197327
[2019-03-24 07:27:16,782] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.018977499]
[2019-03-24 07:27:16,783] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [16.33333333333334, 75.66666666666666, 1.0, 2.0, 0.5415510601778196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 698725.6255292383, 698725.6255292383, 138730.0046149864]
[2019-03-24 07:27:16,784] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:27:16,787] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.0381745e-23 5.1306119e-27 9.0467294e-24 4.1495664e-23], sampled 0.9038940165540238
[2019-03-24 07:27:16,787] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 698725.6255292383 W.
[2019-03-24 07:27:19,409] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 07:27:19,452] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 07:27:19,588] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 07:27:19,607] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 07:27:19,640] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 07:27:20,655] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1575000, evaluation results [1575000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 07:27:20,862] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 3.2804392e-29 9.5662887e-34 1.3956113e-29 1.8404326e-30], sum to 1.0000
[2019-03-24 07:27:20,870] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6874
[2019-03-24 07:27:20,877] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2132910.974597011 W.
[2019-03-24 07:27:20,882] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.06666666666667, 62.33333333333333, 1.0, 2.0, 0.6233021164068432, 1.0, 2.0, 0.6233021164068432, 1.0, 1.0, 0.9923172688524416, 6.9112, 6.9112, 121.94756008, 2132910.974597011, 2132910.974597011, 408217.8848365639], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3426000.0000, 
sim time next is 3426600.0000, 
raw observation next is [30.83333333333334, 63.16666666666666, 1.0, 2.0, 0.9233134926068137, 1.0, 2.0, 0.9233134926068137, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2106326.463953638, 2106326.463953638, 397344.5946085191], 
processed observation next is [1.0, 0.6521739130434783, 0.6975308641975311, 0.6316666666666666, 1.0, 1.0, 0.9087065388176354, 1.0, 1.0, 0.9087065388176354, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7522594514120136, 0.7522594514120136, 0.7641242204009983], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9883503], dtype=float32), 1.0603412]. 
=============================================
[2019-03-24 07:27:24,081] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 7.1374759e-29 9.5728376e-31 4.0851495e-26 1.3831275e-25], sum to 1.0000
[2019-03-24 07:27:24,084] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3761
[2019-03-24 07:27:24,090] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 719263.8730659173 W.
[2019-03-24 07:27:24,093] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.65, 67.5, 1.0, 2.0, 0.3155610708466656, 0.0, 1.0, 0.0, 1.0, 2.0, 0.502383501894487, 6.911199999999999, 6.9112, 121.9260426156618, 719263.8730659173, 719263.8730659178, 199475.9228904969], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3432600.0000, 
sim time next is 3433200.0000, 
raw observation next is [29.76666666666667, 67.0, 1.0, 2.0, 0.213490180275688, 1.0, 1.0, 0.213490180275688, 1.0, 2.0, 0.3398833198886603, 6.911199999999999, 6.9112, 121.94756008, 729922.8690772121, 729922.8690772125, 225051.8946211961], 
processed observation next is [1.0, 0.7391304347826086, 0.6580246913580248, 0.67, 1.0, 1.0, 0.06367878604248571, 1.0, 0.5, 0.06367878604248571, 1.0, 1.0, 0.17485414986082531, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2606867389561472, 0.26068673895614736, 0.4327921050407617], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3932941], dtype=float32), -1.223892]. 
=============================================
[2019-03-24 07:27:24,208] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.000000e+00 6.118181e-21 2.737928e-24 1.994863e-21 6.555045e-20], sum to 1.0000
[2019-03-24 07:27:24,214] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7932
[2019-03-24 07:27:24,218] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1761385.588949249 W.
[2019-03-24 07:27:24,222] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.9177841831918006, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426084082, 1761385.588949249, 1761385.588949248, 360837.9981197647], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3682800.0000, 
sim time next is 3683400.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.7192349815485027, 1.0, 1.0, 0.7192349815485027, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156596, 1640340.964185946, 1640340.964185946, 311512.0631232524], 
processed observation next is [1.0, 0.6521739130434783, 0.5555555555555556, 0.89, 1.0, 1.0, 0.6657559304148842, 1.0, 0.5, 0.6657559304148842, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201214, 0.5858360586378378, 0.5858360586378378, 0.5990616598524084], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.31690586], dtype=float32), 1.9464]. 
=============================================
[2019-03-24 07:27:36,978] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.8133025e-23 8.0932950e-26 4.6043461e-22 7.0043109e-22], sum to 1.0000
[2019-03-24 07:27:36,987] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1160
[2019-03-24 07:27:36,994] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 924013.1925869095 W.
[2019-03-24 07:27:36,998] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333333, 98.33333333333334, 1.0, 2.0, 0.4053361785818995, 1.0, 1.0, 0.4053361785818995, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 924013.1925869095, 924013.1925869095, 207659.6846958128], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3733800.0000, 
sim time next is 3734400.0000, 
raw observation next is [24.26666666666667, 98.66666666666667, 1.0, 2.0, 0.7338425944663457, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 836394.0066292302, 836394.0066292307, 182645.7016594996], 
processed observation next is [1.0, 0.21739130434782608, 0.4543209876543211, 0.9866666666666667, 1.0, 1.0, 0.6831459457932687, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.29871214522472506, 0.2987121452247252, 0.3512417339605762], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.1916497], dtype=float32), -0.4775444]. 
=============================================
[2019-03-24 07:27:38,925] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.7166273e-26 1.2721196e-30 2.4293884e-27 7.5797477e-27], sum to 1.0000
[2019-03-24 07:27:38,929] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5849
[2019-03-24 07:27:38,935] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 757088.5995622303 W.
[2019-03-24 07:27:38,939] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.01666666666667, 94.0, 1.0, 2.0, 0.6642952792282566, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 757088.5995622303, 757088.5995622303, 169493.6416350841], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3714600.0000, 
sim time next is 3715200.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.3321673218977283, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5288211943956184, 6.911199999999999, 6.9112, 121.9260426156618, 757133.4849990363, 757133.4849990368, 204091.5362925121], 
processed observation next is [1.0, 0.0, 0.48148148148148145, 0.94, 1.0, 1.0, 0.2049610974972956, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.41102649299452293, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2704048160710844, 0.2704048160710846, 0.39248372363944634], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.22757511], dtype=float32), 0.81461024]. 
=============================================
[2019-03-24 07:27:39,296] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 5.8213062e-29 1.3884293e-33 2.4276815e-29 3.5702411e-29], sum to 1.0000
[2019-03-24 07:27:39,301] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2020
[2019-03-24 07:27:39,307] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 798272.5105606926 W.
[2019-03-24 07:27:39,310] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.73333333333333, 51.0, 1.0, 2.0, 0.350206317919126, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5575398635507692, 6.9112, 6.9112, 121.9260426156618, 798272.5105606926, 798272.5105606926, 209235.382622121], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3779400.0000, 
sim time next is 3780000.0000, 
raw observation next is [34.0, 47.0, 1.0, 2.0, 0.3374803488509528, 1.0, 1.0, 0.3374803488509528, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 769249.936129175, 769249.9361291754, 189698.8098193491], 
processed observation next is [1.0, 0.782608695652174, 0.8148148148148148, 0.47, 1.0, 1.0, 0.2112861295844676, 1.0, 0.5, 0.2112861295844676, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27473212004613395, 0.27473212004613407, 0.36480540349874824], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5061672], dtype=float32), 1.0881389]. 
=============================================
[2019-03-24 07:27:39,329] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[41.31925 ]
 [41.59531 ]
 [41.91494 ]
 [42.32101 ]
 [42.578075]], R is [[40.37310791]
 [39.96937561]
 [40.19248199]
 [40.43714905]
 [40.61029053]].
[2019-03-24 07:27:40,021] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 2.9098262e-28 5.4059022e-32 6.3017598e-28 2.2685449e-28], sum to 1.0000
[2019-03-24 07:27:40,027] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4212
[2019-03-24 07:27:40,032] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 763030.6124596363 W.
[2019-03-24 07:27:40,035] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.66666666666667, 59.0, 1.0, 2.0, 0.2231688228138158, 1.0, 1.0, 0.2231688228138158, 1.0, 2.0, 0.3552920340207413, 6.9112, 6.9112, 121.94756008, 763030.6124596363, 763030.6124596363, 228312.5043717313], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3792000.0000, 
sim time next is 3792600.0000, 
raw observation next is [30.5, 59.0, 1.0, 2.0, 0.2212532707989075, 1.0, 2.0, 0.2212532707989075, 1.0, 2.0, 0.3522424128278334, 6.911200000000001, 6.9112, 121.94756008, 756477.9680523378, 756477.9680523374, 227663.0204045374], 
processed observation next is [1.0, 0.9130434782608695, 0.6851851851851852, 0.59, 1.0, 1.0, 0.07292056047488987, 1.0, 1.0, 0.07292056047488987, 1.0, 1.0, 0.19030301603479174, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2701707028758349, 0.2701707028758348, 0.43781350077795655], 
reward next is 0.5622, 
noisyNet noise sample is [array([-0.05073753], dtype=float32), 0.9211381]. 
=============================================
[2019-03-24 07:27:40,301] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 5.1961936e-30 1.2801786e-34 1.9204122e-27 9.5733687e-27], sum to 1.0000
[2019-03-24 07:27:40,309] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1072
[2019-03-24 07:27:40,318] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 911535.9239221277 W.
[2019-03-24 07:27:40,321] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.75, 68.5, 1.0, 2.0, 0.7997320752414524, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 911535.9239221277, 911535.9239221277, 195889.6571492708], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3789000.0000, 
sim time next is 3789600.0000, 
raw observation next is [30.83333333333333, 65.33333333333333, 1.0, 2.0, 0.2553517094151274, 1.0, 1.0, 0.2553517094151274, 1.0, 1.0, 0.4065282376134726, 6.9112, 6.9112, 121.94756008, 873128.9313868091, 873128.9313868091, 239531.1111813627], 
processed observation next is [1.0, 0.8695652173913043, 0.6975308641975307, 0.6533333333333333, 1.0, 1.0, 0.11351393977991359, 1.0, 0.5, 0.11351393977991359, 1.0, 0.5, 0.25816029701684073, 0.0, 0.0, 0.8096049824067558, 0.3118317612095747, 0.3118317612095747, 0.46063675227185136], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0525088], dtype=float32), -0.5501619]. 
=============================================
[2019-03-24 07:27:41,202] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.000000e+00 7.092672e-27 5.297888e-31 2.154915e-27 1.192307e-26], sum to 1.0000
[2019-03-24 07:27:41,207] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6763
[2019-03-24 07:27:41,217] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 766170.1390766624 W.
[2019-03-24 07:27:41,222] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.83333333333334, 59.0, 1.0, 2.0, 0.3361298751750711, 1.0, 1.0, 0.3361298751750711, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 766170.1390766624, 766170.1390766628, 189357.2431561253], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3791400.0000, 
sim time next is 3792000.0000, 
raw observation next is [30.66666666666667, 59.0, 1.0, 2.0, 0.669489475163272, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 763011.3027412394, 763011.3027412394, 170446.6248050352], 
processed observation next is [1.0, 0.9130434782608695, 0.6913580246913582, 0.59, 1.0, 1.0, 0.6065350894800856, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2725040366932998, 0.2725040366932998, 0.3277819707789138], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.9384062], dtype=float32), 0.7694965]. 
=============================================
[2019-03-24 07:27:41,245] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[36.955574]
 [36.817604]
 [37.013084]
 [36.996216]
 [37.365387]], R is [[36.54187775]
 [36.81231308]
 [36.44419098]
 [36.07975006]
 [35.71895218]].
[2019-03-24 07:27:41,839] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.7366146e-29 2.2114610e-34 1.6641263e-30 2.2142438e-29], sum to 1.0000
[2019-03-24 07:27:41,844] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0283
[2019-03-24 07:27:41,850] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 823312.2586701956 W.
[2019-03-24 07:27:41,857] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.58333333333334, 59.66666666666667, 1.0, 2.0, 0.2407903490910856, 1.0, 2.0, 0.2407903490910856, 1.0, 1.0, 0.3833460777472, 6.9112, 6.9112, 121.94756008, 823312.2586701956, 823312.2586701956, 234383.4803109012], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3784200.0000, 
sim time next is 3784800.0000, 
raw observation next is [32.16666666666667, 63.33333333333334, 1.0, 2.0, 0.2474637333821381, 1.0, 2.0, 0.2474637333821381, 1.0, 2.0, 0.3939703228755089, 6.9112, 6.9112, 121.94756008, 846142.5397765433, 846142.5397765433, 236727.9058193073], 
processed observation next is [1.0, 0.8260869565217391, 0.7469135802469138, 0.6333333333333334, 1.0, 1.0, 0.10412349212159297, 1.0, 1.0, 0.10412349212159297, 1.0, 1.0, 0.24246290359438613, 0.0, 0.0, 0.8096049824067558, 0.3021937642059083, 0.3021937642059083, 0.4552459727294371], 
reward next is 0.5448, 
noisyNet noise sample is [array([0.7209701], dtype=float32), -0.18717755]. 
=============================================
[2019-03-24 07:27:44,998] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 3.6428693e-35 0.0000000e+00 1.0074282e-37 4.3275802e-36], sum to 1.0000
[2019-03-24 07:27:45,003] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6403
[2019-03-24 07:27:45,010] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.5, 58.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9220949392631318, 6.9112, 6.9112, 121.9260426156618, 671609.8255706762, 671609.8255706762, 179501.5910464591], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3832200.0000, 
sim time next is 3832800.0000, 
raw observation next is [29.66666666666667, 58.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9368454526546379, 6.911200000000001, 6.9112, 121.9260426156618, 680264.0793679003, 680264.0793678998, 181844.4423360495], 
processed observation next is [0.0, 0.34782608695652173, 0.6543209876543211, 0.5866666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9210568158182975, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24295145691710723, 0.24295145691710707, 0.34970085064624906], 
reward next is 0.6503, 
noisyNet noise sample is [array([-0.21183385], dtype=float32), -0.05057234]. 
=============================================
[2019-03-24 07:27:45,901] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 2.4564683e-28 3.1980808e-32 2.8112252e-27 2.6427763e-27], sum to 1.0000
[2019-03-24 07:27:45,907] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0647
[2019-03-24 07:27:45,911] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 890863.3916394971 W.
[2019-03-24 07:27:45,913] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.66666666666666, 61.33333333333333, 1.0, 2.0, 0.2605352448386397, 1.0, 1.0, 0.2605352448386397, 1.0, 2.0, 0.4147805948236672, 6.911200000000001, 6.9112, 121.94756008, 890863.3916394971, 890863.3916394967, 241392.1398010983], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3868800.0000, 
sim time next is 3869400.0000, 
raw observation next is [32.33333333333334, 64.16666666666667, 1.0, 2.0, 0.8023894617990751, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 914566.6247676315, 914566.6247676315, 196443.0589737243], 
processed observation next is [0.0, 0.782608695652174, 0.7530864197530868, 0.6416666666666667, 1.0, 1.0, 0.7647493592846132, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.32663093741701127, 0.32663093741701127, 0.3777751134110083], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8768884], dtype=float32), 0.8466543]. 
=============================================
[2019-03-24 07:27:49,565] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 4.5600657e-24 2.1887404e-28 1.4137961e-24 4.0518010e-24], sum to 1.0000
[2019-03-24 07:27:49,570] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5509
[2019-03-24 07:27:49,580] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 925409.760700164 W.
[2019-03-24 07:27:49,587] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 0.4059484404074942, 1.0, 1.0, 0.4059484404074942, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 925409.760700164, 925409.760700164, 207831.2374355218], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3934800.0000, 
sim time next is 3935400.0000, 
raw observation next is [30.93333333333334, 69.5, 1.0, 2.0, 0.3899962278654591, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6208866960522292, 6.911199999999999, 6.9112, 121.9260426156618, 889023.6234806152, 889023.6234806157, 221039.7120297377], 
processed observation next is [0.0, 0.5652173913043478, 0.7012345679012348, 0.695, 1.0, 1.0, 0.2738050331731656, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.5261083700652865, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3175084369573626, 0.31750843695736275, 0.4250763692879571], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0333501], dtype=float32), 0.5406587]. 
=============================================
[2019-03-24 07:27:50,838] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 4.7413672e-27 3.0339797e-29 1.5698848e-26 4.8960800e-25], sum to 1.0000
[2019-03-24 07:27:50,845] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2461
[2019-03-24 07:27:50,850] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 897856.7381129679 W.
[2019-03-24 07:27:50,853] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.46666666666667, 93.66666666666667, 1.0, 2.0, 0.7877377271879917, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 897856.7381129679, 897856.7381129679, 193412.5611906598], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3998400.0000, 
sim time next is 3999000.0000, 
raw observation next is [24.43333333333333, 93.83333333333334, 1.0, 2.0, 0.3955880279960478, 1.0, 1.0, 0.3955880279960478, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 901778.0216165006, 901778.021616501, 204980.8588057412], 
processed observation next is [1.0, 0.2608695652173913, 0.4604938271604937, 0.9383333333333335, 1.0, 1.0, 0.2804619380905331, 1.0, 0.5, 0.2804619380905331, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3220635791487502, 0.3220635791487504, 0.39419395924181], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0333885], dtype=float32), 0.30718192]. 
=============================================
[2019-03-24 07:27:50,871] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[37.636208]
 [37.076492]
 [37.040756]
 [36.703003]
 [36.907677]], R is [[37.22613907]
 [36.85387802]
 [37.09722519]
 [37.35905838]
 [37.54508591]].
[2019-03-24 07:27:56,738] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.00000000e+00 2.07639555e-36 0.00000000e+00 2.34102886e-36
 1.32292225e-36], sum to 1.0000
[2019-03-24 07:27:56,743] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5087
[2019-03-24 07:27:56,751] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.8, 77.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8986131825685275, 6.911200000000001, 6.9112, 121.9260426156618, 658612.8718541508, 658612.8718541503, 175558.8356779023], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4317600.0000, 
sim time next is 4318200.0000, 
raw observation next is [25.85, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9192053499727941, 6.9112, 6.9112, 121.9260426156618, 670693.9883669729, 670693.9883669729, 178903.1887841807], 
processed observation next is [1.0, 1.0, 0.5129629629629631, 0.79, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8990066874659927, 0.0, 0.0, 0.8094621288201359, 0.2395335672739189, 0.2395335672739189, 0.3440445938157321], 
reward next is 0.6560, 
noisyNet noise sample is [array([-0.43337515], dtype=float32), -0.8565217]. 
=============================================
[2019-03-24 07:27:57,327] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.1710326e-31 1.1363581e-34 6.8798928e-32 1.6850572e-33], sum to 1.0000
[2019-03-24 07:27:57,336] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8739
[2019-03-24 07:27:57,345] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2085113.010076344 W.
[2019-03-24 07:27:57,350] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.2, 66.0, 1.0, 2.0, 0.9140253663555566, 1.0, 2.0, 0.9140253663555566, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2085113.010076344, 2085113.010076344, 393123.7590032946], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4122000.0000, 
sim time next is 4122600.0000, 
raw observation next is [28.0, 69.66666666666667, 1.0, 2.0, 0.2829142041506431, 1.0, 2.0, 0.2829142041506431, 1.0, 1.0, 0.4504086268801991, 6.911199999999999, 6.9112, 121.94756008, 967433.366947463, 967433.3669474635, 249598.9190493868], 
processed observation next is [1.0, 0.7391304347826086, 0.5925925925925926, 0.6966666666666668, 1.0, 1.0, 0.14632643351267038, 1.0, 1.0, 0.14632643351267038, 1.0, 0.5, 0.31301078360024887, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.3455119167669511, 0.34551191676695125, 0.4799979212488208], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.58809215], dtype=float32), 0.031751845]. 
=============================================
[2019-03-24 07:28:02,331] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:28:02,339] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1026
[2019-03-24 07:28:02,342] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.95, 99.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6768912826105159, 6.911199999999999, 6.9112, 121.9260426156618, 505816.4846602752, 505816.4846602757, 142046.9199353611], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4167000.0000, 
sim time next is 4167600.0000, 
raw observation next is [19.96666666666667, 99.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6795559027436523, 6.9112, 6.9112, 121.9260426156618, 507816.1344309823, 507816.1344309823, 142424.9655229332], 
processed observation next is [1.0, 0.21739130434782608, 0.2950617283950618, 0.9966666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5994448784295653, 0.0, 0.0, 0.8094621288201359, 0.18136290515392225, 0.18136290515392225, 0.27389416446717924], 
reward next is 0.7261, 
noisyNet noise sample is [array([-1.305322], dtype=float32), -0.5954821]. 
=============================================
[2019-03-24 07:28:03,744] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 2.7735973e-38 0.0000000e+00 0.0000000e+00 7.1539896e-38], sum to 1.0000
[2019-03-24 07:28:03,749] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3834
[2019-03-24 07:28:03,759] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1903672.278947968 W.
[2019-03-24 07:28:03,763] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.25, 29.0, 1.0, 2.0, 0.8120368712363158, 1.0, 2.0, 0.8120368712363158, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1903672.278947968, 1903672.278947968, 351356.2272665899], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4206600.0000, 
sim time next is 4207200.0000, 
raw observation next is [34.33333333333334, 27.33333333333334, 1.0, 2.0, 0.740771635527115, 1.0, 2.0, 0.740771635527115, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1754108.189903432, 1754108.189903433, 322977.1401706938], 
processed observation next is [1.0, 0.6956521739130435, 0.8271604938271608, 0.2733333333333334, 1.0, 1.0, 0.6913948041989464, 1.0, 1.0, 0.6913948041989464, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6264672106797972, 0.6264672106797975, 0.6211098849436419], 
reward next is 0.3789, 
noisyNet noise sample is [array([-0.21023141], dtype=float32), -0.9514345]. 
=============================================
[2019-03-24 07:28:03,780] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:28:03,785] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7225
[2019-03-24 07:28:03,792] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9351684933201923, 6.911200000000001, 6.9112, 121.9260426156618, 681251.422701855, 681251.4227018545, 181262.4208888213], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4515600.0000, 
sim time next is 4516200.0000, 
raw observation next is [23.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9352199261916548, 6.911200000000001, 6.9112, 121.9260426156618, 681285.2897258984, 681285.2897258981, 181270.0674080899], 
processed observation next is [0.0, 0.2608695652173913, 0.4074074074074074, 1.0, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9190249077395685, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24331617490210658, 0.24331617490210644, 0.348596283477096], 
reward next is 0.6514, 
noisyNet noise sample is [array([1.8536123], dtype=float32), -0.7798103]. 
=============================================
[2019-03-24 07:28:09,490] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-24 07:28:09,495] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:28:09,495] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:28:09,496] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:28:09,497] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:28:09,497] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:28:09,499] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:28:09,500] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:28:09,500] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:28:09,498] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:28:09,502] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:28:09,523] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run65
[2019-03-24 07:28:09,550] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run65
[2019-03-24 07:28:09,550] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run65
[2019-03-24 07:28:09,574] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run65
[2019-03-24 07:28:09,599] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run65
[2019-03-24 07:28:23,812] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.019093381]
[2019-03-24 07:28:23,814] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.0, 29.66666666666666, 1.0, 1.0, 0.4039352969644645, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 521109.2453232767, 521109.2453232767, 113576.8682086167]
[2019-03-24 07:28:23,817] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:28:23,818] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 3.3281133e-27 2.8283226e-31 1.6214670e-27 5.4512465e-27], sampled 0.28083506754537235
[2019-03-24 07:29:14,189] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.019093381]
[2019-03-24 07:29:14,191] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.272731055, 89.320919225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8799156983638973, 6.911199999999999, 6.9112, 121.9260426156618, 651364.9670210265, 651364.9670210269, 171276.4044375598]
[2019-03-24 07:29:14,192] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:29:14,196] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 2.9183829e-30 8.2698697e-35 1.2862217e-30 4.9936621e-30], sampled 0.06391438543284644
[2019-03-24 07:29:38,507] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.019093381]
[2019-03-24 07:29:38,509] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.15791199, 69.44454397166666, 1.0, 2.0, 0.6476962302286531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 738161.7727782611, 738161.7727782611, 166475.7042057358]
[2019-03-24 07:29:38,510] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:29:38,514] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 9.7959643e-31 2.4162361e-35 4.4688999e-31 1.8925626e-30], sampled 0.4423840338503081
[2019-03-24 07:29:38,515] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 738161.7727782611 W.
[2019-03-24 07:29:57,796] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 07:29:57,958] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 07:29:57,985] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 07:29:58,048] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 07:29:58,104] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 07:29:59,119] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1600000, evaluation results [1600000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 07:30:02,049] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 9.5101541e-25 3.3476677e-29 1.5354803e-25 1.8078976e-27], sum to 1.0000
[2019-03-24 07:30:02,056] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3791
[2019-03-24 07:30:02,063] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 749886.4508041443 W.
[2019-03-24 07:30:02,075] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 61.33333333333334, 1.0, 2.0, 0.3289894793158527, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5237619655101647, 6.9112, 6.9112, 121.9260426156618, 749886.4508041443, 749886.4508041443, 203201.2440152336], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4386000.0000, 
sim time next is 4386600.0000, 
raw observation next is [31.0, 62.5, 1.0, 2.0, 0.6813474211527055, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 776532.5456936986, 776532.5456936981, 172645.2896807051], 
processed observation next is [1.0, 0.782608695652174, 0.7037037037037037, 0.625, 1.0, 1.0, 0.6206516918484589, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27733305203346376, 0.2773330520334636, 0.3320101724628944], 
reward next is 0.6680, 
noisyNet noise sample is [array([0.80980796], dtype=float32), 1.6566056]. 
=============================================
[2019-03-24 07:30:02,675] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 1.7138857e-26 2.1448561e-31 8.2185155e-27 7.4269552e-29], sum to 1.0000
[2019-03-24 07:30:02,684] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6041
[2019-03-24 07:30:02,690] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 754174.5925542485 W.
[2019-03-24 07:30:02,699] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.8, 79.0, 1.0, 2.0, 0.6617396876100005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 754174.5925542485, 754174.5925542485, 169024.6339851164], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4398000.0000, 
sim time next is 4398600.0000, 
raw observation next is [26.5, 79.0, 1.0, 2.0, 0.3236951861507663, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5153332783682564, 6.911199999999999, 6.9112, 121.9260426156618, 737813.0270626085, 737813.027062609, 201720.5923313352], 
processed observation next is [1.0, 0.9130434782608695, 0.5370370370370371, 0.79, 1.0, 1.0, 0.19487522160805515, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.39416659796032044, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.26350465252236016, 0.2635046525223603, 0.3879242160217985], 
reward next is 0.6121, 
noisyNet noise sample is [array([0.50615746], dtype=float32), 0.5698878]. 
=============================================
[2019-03-24 07:30:16,695] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 2.8344350e-24 2.0936648e-27 8.1327053e-23 4.6424745e-23], sum to 1.0000
[2019-03-24 07:30:16,703] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6441
[2019-03-24 07:30:16,707] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1933994.202214395 W.
[2019-03-24 07:30:16,711] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.6, 65.0, 1.0, 2.0, 0.5652353918515743, 1.0, 1.0, 0.5652353918515743, 1.0, 2.0, 0.8998731522592595, 6.911200000000001, 6.9112, 121.94756008, 1933994.202214395, 1933994.202214394, 376759.6632915332], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4640400.0000, 
sim time next is 4641000.0000, 
raw observation next is [29.33333333333334, 67.33333333333334, 1.0, 2.0, 0.4290110576881938, 1.0, 2.0, 0.4290110576881938, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 978017.4024748988, 978017.4024748988, 214302.2331626247], 
processed observation next is [1.0, 0.7391304347826086, 0.6419753086419755, 0.6733333333333335, 1.0, 1.0, 0.32025125915261166, 1.0, 1.0, 0.32025125915261166, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.349291929455321, 0.349291929455321, 0.41211967915889364], 
reward next is 0.5879, 
noisyNet noise sample is [array([0.80148774], dtype=float32), -0.18038952]. 
=============================================
[2019-03-24 07:30:16,726] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[33.478962]
 [33.529636]
 [33.8061  ]
 [33.23743 ]
 [33.545643]], R is [[34.19933319]
 [33.85734177]
 [33.81414032]
 [33.47599792]
 [33.14123917]].
[2019-03-24 07:30:17,230] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 9.4090209e-22 1.0055377e-25 4.3970355e-22 4.6604361e-21], sum to 1.0000
[2019-03-24 07:30:17,238] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7317
[2019-03-24 07:30:17,242] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 760019.1037867883 W.
[2019-03-24 07:30:17,246] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.3257586271348457, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5202536736503903, 6.9112, 6.9112, 121.9260426156618, 760019.1037867883, 760019.1037867883, 201889.1779324513], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4678800.0000, 
sim time next is 4679400.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.6488336028193403, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 762589.1926027929, 762589.1926027929, 167767.5257337719], 
processed observation next is [1.0, 0.13043478260869565, 0.4074074074074074, 0.94, 1.0, 1.0, 0.5819447652611194, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.272353283072426, 0.272353283072426, 0.3226298571803306], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.32857898], dtype=float32), -1.5397077]. 
=============================================
[2019-03-24 07:30:17,313] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.0705216e-22 1.1638002e-24 2.8475745e-21 1.1687531e-22], sum to 1.0000
[2019-03-24 07:30:17,318] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1653
[2019-03-24 07:30:17,330] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 714170.6339466883 W.
[2019-03-24 07:30:17,334] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.58333333333333, 94.83333333333333, 1.0, 2.0, 0.20851659036897, 1.0, 1.0, 0.20851659036897, 1.0, 1.0, 0.3319936815897894, 6.9112, 6.9112, 121.94756008, 714170.6339466883, 714170.6339466883, 223401.892437406], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4683000.0000, 
sim time next is 4683600.0000, 
raw observation next is [23.7, 95.0, 1.0, 2.0, 0.2094863983451118, 1.0, 2.0, 0.2094863983451118, 1.0, 2.0, 0.3335091686611089, 6.9112, 6.9112, 121.94756008, 716227.5457698397, 716227.5457698397, 223718.3970126459], 
processed observation next is [1.0, 0.21739130434782608, 0.4333333333333333, 0.95, 1.0, 1.0, 0.05891237898227594, 1.0, 1.0, 0.05891237898227594, 1.0, 1.0, 0.1668864608263861, 0.0, 0.0, 0.8096049824067558, 0.255795552060657, 0.255795552060657, 0.4302276865627806], 
reward next is 0.5698, 
noisyNet noise sample is [array([0.6728681], dtype=float32), 1.0848086]. 
=============================================
[2019-03-24 07:30:23,098] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 3.3240793e-19 6.4077609e-22 2.5437549e-19 1.0096892e-17], sum to 1.0000
[2019-03-24 07:30:23,104] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4131
[2019-03-24 07:30:23,110] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1656919.808165423 W.
[2019-03-24 07:30:23,113] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.66666666666667, 88.16666666666666, 1.0, 2.0, 0.4843317583054246, 1.0, 1.0, 0.4843317583054246, 1.0, 2.0, 0.7710719328063927, 6.9112, 6.9112, 121.94756008, 1656919.808165423, 1656919.808165423, 335965.4528151046], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4791000.0000, 
sim time next is 4791600.0000, 
raw observation next is [26.0, 87.0, 1.0, 2.0, 0.4986205521828591, 1.0, 2.0, 0.4986205521828591, 1.0, 2.0, 0.7938201580127969, 6.911199999999999, 6.9112, 121.94756008, 1705849.050070035, 1705849.050070036, 342912.5003824758], 
processed observation next is [1.0, 0.4782608695652174, 0.5185185185185185, 0.87, 1.0, 1.0, 0.4031197049795942, 1.0, 1.0, 0.4031197049795942, 1.0, 1.0, 0.742275197515996, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6092318035964411, 0.6092318035964415, 0.6594471161201457], 
reward next is 0.3406, 
noisyNet noise sample is [array([1.2333179], dtype=float32), -0.14925474]. 
=============================================
[2019-03-24 07:30:26,928] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 8.3363084e-23 1.4662662e-26 2.8669168e-24 5.2396239e-23], sum to 1.0000
[2019-03-24 07:30:26,935] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1647
[2019-03-24 07:30:26,939] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 924817.5404832221 W.
[2019-03-24 07:30:26,947] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.66666666666667, 90.66666666666667, 1.0, 2.0, 0.811377617003288, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 924817.5404832221, 924817.5404832221, 198309.8286144401], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5088000.0000, 
sim time next is 5088600.0000, 
raw observation next is [27.5, 91.5, 1.0, 2.0, 0.2720380149635602, 1.0, 1.0, 0.2720380149635602, 1.0, 1.0, 0.4330933794816102, 6.911200000000001, 6.9112, 121.94756008, 930219.3523612674, 930219.352361267, 245575.5160339994], 
processed observation next is [0.0, 0.9130434782608695, 0.5740740740740741, 0.915, 1.0, 1.0, 0.13337858924233362, 1.0, 0.5, 0.13337858924233362, 1.0, 0.5, 0.2913667243520127, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.3322211972718812, 0.33222119727188104, 0.47226060775769113], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.99067307], dtype=float32), -0.2156816]. 
=============================================
[2019-03-24 07:30:38,166] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 4.6105869e-29 4.3000092e-32 1.2867966e-29 2.6311164e-28], sum to 1.0000
[2019-03-24 07:30:38,171] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1672
[2019-03-24 07:30:38,172] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1002238.150213282 W.
[2019-03-24 07:30:38,178] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.16666666666667, 74.33333333333333, 1.0, 2.0, 0.4396286374825809, 1.0, 1.0, 0.4396286374825809, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1002238.150213282, 1002238.150213282, 217346.8703677549], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5068200.0000, 
sim time next is 5068800.0000, 
raw observation next is [31.0, 75.0, 1.0, 2.0, 0.292571224860409, 1.0, 2.0, 0.292571224860409, 1.0, 1.0, 0.465782918357354, 6.911200000000001, 6.9112, 121.94756008, 1000477.384042254, 1000477.384042254, 253226.6083363771], 
processed observation next is [0.0, 0.6956521739130435, 0.7037037037037037, 0.75, 1.0, 1.0, 0.15782288673858214, 1.0, 1.0, 0.15782288673858214, 1.0, 0.5, 0.3322286479466925, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.3573133514436621, 0.3573133514436621, 0.4869742468007252], 
reward next is 0.5130, 
noisyNet noise sample is [array([0.61065805], dtype=float32), 0.6786937]. 
=============================================
[2019-03-24 07:30:38,269] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 7.4073192e-29 5.7900616e-35 7.0272181e-30 1.1634504e-30], sum to 1.0000
[2019-03-24 07:30:38,276] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0719
[2019-03-24 07:30:38,281] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 856101.057283507 W.
[2019-03-24 07:30:38,286] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.41666666666667, 92.33333333333333, 1.0, 2.0, 0.3755618426335872, 1.0, 1.0, 0.3755618426335872, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 856101.057283507, 856101.057283507, 199583.2213364597], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5093400.0000, 
sim time next is 5094000.0000, 
raw observation next is [26.3, 92.0, 1.0, 2.0, 0.2465580324433669, 1.0, 2.0, 0.2465580324433669, 1.0, 1.0, 0.3925284174843648, 6.9112, 6.9112, 121.94756008, 843044.0110165988, 843044.0110165988, 236408.2648925824], 
processed observation next is [0.0, 1.0, 0.5296296296296297, 0.92, 1.0, 1.0, 0.10304527671829394, 1.0, 1.0, 0.10304527671829394, 1.0, 0.5, 0.24066052185545597, 0.0, 0.0, 0.8096049824067558, 0.30108714679164245, 0.30108714679164245, 0.4546312786395815], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.13456555], dtype=float32), -0.96942693]. 
=============================================
[2019-03-24 07:30:38,306] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[42.091187]
 [42.74826 ]
 [42.904427]
 [42.272854]
 [43.111267]], R is [[41.7885437 ]
 [41.37065887]
 [40.95695114]
 [41.16176605]
 [41.38259888]].
[2019-03-24 07:30:42,106] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 5.7634461e-26 9.2648425e-30 4.2319679e-26 6.7432713e-25], sum to 1.0000
[2019-03-24 07:30:42,121] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5411
[2019-03-24 07:30:42,127] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 903056.1345333921 W.
[2019-03-24 07:30:42,132] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.53333333333333, 75.66666666666667, 1.0, 2.0, 0.3961483748245661, 0.0, 1.0, 0.0, 1.0, 1.0, 0.630681114372566, 6.9112, 6.9112, 121.9260426156618, 903056.1345333921, 903056.1345333921, 222923.1517254943], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5142000.0000, 
sim time next is 5142600.0000, 
raw observation next is [30.65, 75.5, 1.0, 2.0, 0.2682296607954802, 1.0, 1.0, 0.2682296607954802, 1.0, 2.0, 0.4270303556165905, 6.9112, 6.9112, 121.94756008, 917189.0988378049, 917189.0988378049, 244182.3005278517], 
processed observation next is [0.0, 0.5217391304347826, 0.6907407407407407, 0.755, 1.0, 1.0, 0.12884483428033358, 1.0, 0.5, 0.12884483428033358, 1.0, 1.0, 0.2837879445207381, 0.0, 0.0, 0.8096049824067558, 0.327567535299216, 0.327567535299216, 0.4695813471689456], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8412098], dtype=float32), -0.8706774]. 
=============================================
[2019-03-24 07:30:42,822] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.00000000e+00 1.27255906e-26 1.47965933e-29 6.32783049e-26
 7.18329739e-25], sum to 1.0000
[2019-03-24 07:30:42,831] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1603
[2019-03-24 07:30:42,837] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 814133.5094769918 W.
[2019-03-24 07:30:42,842] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.76666666666667, 85.66666666666666, 1.0, 2.0, 0.3571609274187566, 1.0, 2.0, 0.3571609274187566, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 814133.5094769918, 814133.5094769923, 194744.1262226514], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5172000.0000, 
sim time next is 5172600.0000, 
raw observation next is [26.63333333333333, 85.83333333333334, 1.0, 2.0, 0.7092656194179138, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 808367.7312074881, 808367.7312074881, 177905.0863423902], 
processed observation next is [0.0, 0.8695652173913043, 0.5419753086419752, 0.8583333333333334, 1.0, 1.0, 0.653887642164183, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28870276114553145, 0.28870276114553145, 0.34212516604305804], 
reward next is 0.6579, 
noisyNet noise sample is [array([1.1680157], dtype=float32), 1.4342351]. 
=============================================
[2019-03-24 07:30:47,674] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-24 07:30:47,676] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:30:47,676] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:30:47,677] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:30:47,677] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:30:47,679] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:30:47,680] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:30:47,682] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:30:47,683] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:30:47,682] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:30:47,683] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:30:47,708] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run66
[2019-03-24 07:30:47,734] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run66
[2019-03-24 07:30:47,759] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run66
[2019-03-24 07:30:47,784] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run66
[2019-03-24 07:30:47,785] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run66
[2019-03-24 07:30:51,055] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.018989133]
[2019-03-24 07:30:51,056] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.66666666666667, 20.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5486117206148479, 6.9112, 6.9112, 121.9260426156618, 391722.9456194183, 391722.9456194183, 98887.81281734718]
[2019-03-24 07:30:51,060] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:30:51,062] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 8.2860650e-36 0.0000000e+00 3.4348043e-36 1.7997225e-35], sampled 0.659047523661627
[2019-03-24 07:30:54,992] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.018989133]
[2019-03-24 07:30:54,994] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.61666666666667, 52.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6358011139889523, 6.911199999999999, 6.9112, 121.9260426156618, 463675.9452744444, 463675.9452744449, 129577.718139685]
[2019-03-24 07:30:54,995] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:30:54,998] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 4.8480011e-32 4.5390533e-37 2.2608342e-32 1.0194932e-31], sampled 0.7898281601213533
[2019-03-24 07:30:57,860] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.018989133]
[2019-03-24 07:30:57,861] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [32.14651369666667, 24.35554151166667, 1.0, 2.0, 0.6144173898202565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 773733.3329248761, 773733.3329248761, 163150.2068841794]
[2019-03-24 07:30:57,863] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:30:57,865] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 2.9387435e-26 2.3626754e-30 1.4567716e-26 6.1118435e-26], sampled 0.6321878384027557
[2019-03-24 07:30:57,866] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 773733.3329248761 W.
[2019-03-24 07:31:02,218] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.018989133]
[2019-03-24 07:31:02,220] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.1583119, 55.13248039666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4587539741551004, 6.911200000000001, 6.9112, 121.9260426156618, 329679.7679980193, 329679.7679980189, 112802.7154001057]
[2019-03-24 07:31:02,221] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:31:02,223] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 4.1480716e-34 0.0000000e+00 1.8200282e-34 9.0038542e-34], sampled 0.5904947718804902
[2019-03-24 07:31:04,734] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.018989133]
[2019-03-24 07:31:04,735] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.86666666666667, 65.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.780512683256855, 6.911200000000001, 6.9112, 121.9260426156618, 572770.6287694976, 572770.6287694972, 145154.1218205529]
[2019-03-24 07:31:04,737] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:31:04,740] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 2.6544649e-28 9.6916570e-33 1.3678304e-28 5.4377024e-28], sampled 0.9014619838707284
[2019-03-24 07:31:15,021] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.018989133]
[2019-03-24 07:31:15,022] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [19.63333333333333, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6253196407969076, 6.9112, 6.9112, 121.9260426156618, 465267.1523914566, 465267.1523914566, 133660.3203018587]
[2019-03-24 07:31:15,023] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:31:15,027] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.5761919e-33 0.0000000e+00 7.0327820e-34 3.4261858e-33], sampled 0.8475857769682376
[2019-03-24 07:31:24,898] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.018989133]
[2019-03-24 07:31:24,900] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [35.5, 39.0, 1.0, 2.0, 0.6396230653720437, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 728956.631628372, 728956.6316283715, 165027.8557305793]
[2019-03-24 07:31:24,902] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:31:24,905] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 5.3691436e-29 1.5836291e-33 2.5102348e-29 1.2054311e-28], sampled 0.6930765498649949
[2019-03-24 07:31:24,907] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 728956.631628372 W.
[2019-03-24 07:31:45,764] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.018989133]
[2019-03-24 07:31:45,766] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.1939782, 95.04918123666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8199832376078567, 6.911200000000001, 6.9112, 121.9260426156618, 607523.1816261752, 607523.1816261747, 163511.8622343605]
[2019-03-24 07:31:45,766] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:31:45,770] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 2.2338493e-30 3.9077812e-35 1.0963763e-30 4.8700637e-30], sampled 0.18978851330521185
[2019-03-24 07:32:18,914] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.018989133]
[2019-03-24 07:32:18,916] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.8, 90.0, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.505292927490181, 6.9112, 121.9236208155982, 1469495.508517655, 1165272.873071381, 245711.613729286]
[2019-03-24 07:32:18,918] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:32:18,921] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 2.9598073e-24 1.0143901e-27 2.3651805e-24 8.8878055e-24], sampled 0.034889583742623076
[2019-03-24 07:32:18,922] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1469495.508517655 W.
[2019-03-24 07:32:35,901] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 07:32:36,122] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 07:32:36,154] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 07:32:36,192] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 07:32:36,216] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 07:32:37,232] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1625000, evaluation results [1625000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 07:32:52,568] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 2.2772981e-24 5.5785365e-28 4.8251979e-24 8.0696582e-24], sum to 1.0000
[2019-03-24 07:32:52,575] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9269
[2019-03-24 07:32:52,583] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 778040.98128869 W.
[2019-03-24 07:32:52,590] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.58333333333334, 92.16666666666667, 1.0, 2.0, 0.3413351428320111, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5434166638980796, 6.911199999999999, 6.9112, 121.9260426156618, 778040.98128869, 778040.9812886905, 206688.7931735409], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5533800.0000, 
sim time next is 5534400.0000, 
raw observation next is [25.56666666666667, 92.33333333333334, 1.0, 2.0, 0.6825650015436382, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 777920.9278310244, 777920.9278310244, 172869.2801568973], 
processed observation next is [1.0, 0.043478260869565216, 0.5024691358024692, 0.9233333333333335, 1.0, 1.0, 0.622101192313855, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27782890279679445, 0.27782890279679445, 0.33244092337864867], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.7973745], dtype=float32), 0.7796491]. 
=============================================
[2019-03-24 07:33:00,972] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:33:00,976] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:33:00,981] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8370
[2019-03-24 07:33:00,987] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.25, 91.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7232536125270832, 6.9112, 6.9112, 121.9260426156618, 540358.0641941426, 540358.0641941426, 148177.2635004428], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5725800.0000, 
sim time next is 5726400.0000, 
raw observation next is [21.26666666666667, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7195369093866449, 6.9112, 6.9112, 121.9260426156618, 537615.466645261, 537615.466645261, 147643.2429877314], 
processed observation next is [0.0, 0.2608695652173913, 0.34320987654320995, 0.91, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.649421136733306, 0.0, 0.0, 0.8094621288201359, 0.19200552380187894, 0.19200552380187894, 0.28392931343794503], 
reward next is 0.7161, 
noisyNet noise sample is [array([0.03583395], dtype=float32), -0.1943002]. 
=============================================
[2019-03-24 07:33:00,987] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9039
[2019-03-24 07:33:00,993] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.0, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.869012422961598, 6.911200000000001, 6.9112, 121.9260426156618, 639104.0622599062, 639104.0622599057, 171162.4976189625], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5756400.0000, 
sim time next is 5757000.0000, 
raw observation next is [28.01666666666667, 62.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8772902416350613, 6.911200000000001, 6.9112, 121.9260426156618, 644600.8296743055, 644600.829674305, 172382.3986382607], 
processed observation next is [0.0, 0.6521739130434783, 0.59320987654321, 0.625, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8466128020438265, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2302145820265377, 0.23021458202653752, 0.33150461276588594], 
reward next is 0.6685, 
noisyNet noise sample is [array([-0.4428053], dtype=float32), -1.7455977]. 
=============================================
[2019-03-24 07:33:01,008] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[66.48266]
 [66.44268]
 [66.43841]
 [66.44634]
 [66.47444]], R is [[66.45122528]
 [66.45755768]
 [66.4650116 ]
 [66.4733429 ]
 [66.48209381]].
[2019-03-24 07:33:01,612] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:33:01,618] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0811
[2019-03-24 07:33:01,623] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.15, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8002579253850558, 6.911199999999999, 6.9112, 121.9260426156618, 593759.5009906864, 593759.5009906868, 160663.1481515953], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5749800.0000, 
sim time next is 5750400.0000, 
raw observation next is [27.3, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8091655354718458, 6.9112, 6.9112, 121.9260426156618, 599644.6440619748, 599644.6440619748, 162085.1529338203], 
processed observation next is [0.0, 0.5652173913043478, 0.5666666666666667, 0.62, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7614569193398071, 0.0, 0.0, 0.8094621288201359, 0.2141588014507053, 0.2141588014507053, 0.3117022171804236], 
reward next is 0.6883, 
noisyNet noise sample is [array([1.9709882], dtype=float32), -1.843845]. 
=============================================
[2019-03-24 07:33:03,999] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:33:04,008] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4282
[2019-03-24 07:33:04,015] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.51666666666667, 85.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.813197926643459, 6.9112, 6.9112, 121.9260426156618, 602931.3516543022, 602931.3516543022, 162473.5273976598], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5785800.0000, 
sim time next is 5786400.0000, 
raw observation next is [23.43333333333334, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8079363902272492, 6.911199999999999, 6.9112, 121.9260426156618, 599460.1674732896, 599460.1674732901, 161624.4376030997], 
processed observation next is [0.0, 1.0, 0.42345679012345705, 0.85, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7599204877840615, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2140929169547463, 0.21409291695474647, 0.31081622615980714], 
reward next is 0.6892, 
noisyNet noise sample is [array([0.7197275], dtype=float32), -0.7153318]. 
=============================================
[2019-03-24 07:33:06,360] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 5.6276126e-35 0.0000000e+00 3.7818629e-35 5.2626681e-35], sum to 1.0000
[2019-03-24 07:33:06,367] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9031
[2019-03-24 07:33:06,370] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.46666666666667, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7516477045855149, 6.911199999999999, 6.9112, 121.9260426156618, 561033.7989933798, 561033.7989933803, 152410.1731021016], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5812800.0000, 
sim time next is 5813400.0000, 
raw observation next is [22.58333333333334, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7512318470533713, 6.911200000000001, 6.9112, 121.9260426156618, 560754.3700962423, 560754.3700962418, 152321.4297997086], 
processed observation next is [1.0, 0.2608695652173913, 0.39197530864197555, 0.84, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.689039808816714, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2002694178915151, 0.20026941789151495, 0.29292582653790117], 
reward next is 0.7071, 
noisyNet noise sample is [array([0.85826546], dtype=float32), -0.1320725]. 
=============================================
[2019-03-24 07:33:06,481] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.9114415e-30 7.4057467e-34 3.7455914e-30 1.1724296e-27], sum to 1.0000
[2019-03-24 07:33:06,486] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9751
[2019-03-24 07:33:06,493] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1102394.259947837 W.
[2019-03-24 07:33:06,502] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.8, 46.0, 1.0, 2.0, 0.8793915397760641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.919301078023983, 6.9112, 121.925587634915, 1102394.259947837, 1098245.799413926, 216786.6228867585], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5832000.0000, 
sim time next is 5832600.0000, 
raw observation next is [26.88333333333334, 46.16666666666667, 1.0, 2.0, 0.2576307777356255, 1.0, 1.0, 0.2576307777356255, 1.0, 1.0, 0.4221392568869396, 6.9112, 6.9112, 121.94756008, 946468.5902245579, 946468.5902245579, 238917.6225396587], 
processed observation next is [1.0, 0.5217391304347826, 0.5512345679012348, 0.4616666666666667, 1.0, 1.0, 0.1162271163519351, 1.0, 0.5, 0.1162271163519351, 1.0, 0.5, 0.2776740711086745, 0.0, 0.0, 0.8096049824067558, 0.3380244965087707, 0.3380244965087707, 0.4594569664224206], 
reward next is 0.5405, 
noisyNet noise sample is [array([-1.2137764], dtype=float32), 0.794162]. 
=============================================
[2019-03-24 07:33:09,751] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 3.6042296e-38 0.0000000e+00 3.6835697e-38 1.0575412e-37], sum to 1.0000
[2019-03-24 07:33:09,760] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7641
[2019-03-24 07:33:09,764] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.0, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5682505442887696, 6.911200000000001, 6.9112, 121.9260426156618, 418852.2398602603, 418852.2398602599, 125667.8532247402], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5896800.0000, 
sim time next is 5897400.0000, 
raw observation next is [20.16666666666667, 80.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6501532467528328, 6.911199999999999, 6.9112, 121.9260426156618, 479729.0760221634, 479729.0760221639, 133486.8356401713], 
processed observation next is [1.0, 0.2608695652173913, 0.3024691358024693, 0.8033333333333332, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.562691558441041, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17133181286505836, 0.17133181286505852, 0.2567054531541756], 
reward next is 0.7433, 
noisyNet noise sample is [array([1.4392737], dtype=float32), -0.40315828]. 
=============================================
[2019-03-24 07:33:12,418] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:33:12,423] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7628
[2019-03-24 07:33:12,428] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.26666666666667, 53.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7275284826105701, 6.911199999999999, 6.9112, 121.9260426156618, 541382.421572308, 541382.4215723085, 151009.3227434081], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5938800.0000, 
sim time next is 5939400.0000, 
raw observation next is [28.13333333333333, 54.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7414070781817602, 6.911199999999999, 6.9112, 121.9260426156618, 551760.5064526057, 551760.5064526061, 152607.276536318], 
processed observation next is [1.0, 0.7391304347826086, 0.5975308641975308, 0.5433333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6767588477272002, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19705732373307347, 0.19705732373307358, 0.29347553180061153], 
reward next is 0.7065, 
noisyNet noise sample is [array([-0.51970696], dtype=float32), -0.9100158]. 
=============================================
[2019-03-24 07:33:17,820] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:33:17,828] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3069
[2019-03-24 07:33:17,834] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.56666666666667, 78.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8261315477564648, 6.9112, 6.9112, 121.9260426156618, 611769.8496030552, 611769.8496030552, 164401.7538917345], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6045000.0000, 
sim time next is 6045600.0000, 
raw observation next is [24.43333333333333, 79.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8243692817047338, 6.9112, 6.9112, 121.9260426156618, 610664.5473227815, 610664.5473227815, 164106.2607660861], 
processed observation next is [1.0, 1.0, 0.4604938271604937, 0.7933333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7804616021309171, 0.0, 0.0, 0.8094621288201359, 0.21809448118670768, 0.21809448118670768, 0.3155889630117041], 
reward next is 0.6844, 
noisyNet noise sample is [array([0.8308876], dtype=float32), 0.63696903]. 
=============================================
[2019-03-24 07:33:19,522] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 3.7997519e-27 3.0549977e-31 2.5808474e-27 2.3804583e-25], sum to 1.0000
[2019-03-24 07:33:19,529] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1368
[2019-03-24 07:33:19,534] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.6, 85.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8903695041530236, 6.911200000000001, 6.9112, 121.9260426071084, 658441.5993172125, 658441.599317212, 172865.4790546821], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6067800.0000, 
sim time next is 6068400.0000, 
raw observation next is [23.66666666666667, 84.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8775519790446296, 6.911199999999999, 6.9112, 121.9260426156592, 650177.7496542097, 650177.7496542102, 170755.0791391025], 
processed observation next is [1.0, 0.21739130434782608, 0.43209876543209896, 0.8466666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.846939973805787, -8.881784197001253e-17, 0.0, 0.8094621288201187, 0.23220633916221775, 0.23220633916221792, 0.3283751521905818], 
reward next is 0.6716, 
noisyNet noise sample is [array([-0.26388106], dtype=float32), 0.052145734]. 
=============================================
[2019-03-24 07:33:20,473] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.3017122e-28 9.9980497e-32 3.9840485e-28 1.0183720e-27], sum to 1.0000
[2019-03-24 07:33:20,481] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4549
[2019-03-24 07:33:20,481] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 760729.6726721859 W.
[2019-03-24 07:33:20,486] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.33333333333334, 73.16666666666667, 1.0, 2.0, 0.6674884960285467, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 760729.6726721859, 760729.6726721859, 170080.2779351994], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6343800.0000, 
sim time next is 6344400.0000, 
raw observation next is [28.56666666666667, 72.33333333333334, 1.0, 2.0, 0.6792899166113102, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 774186.4208586239, 774186.4208586239, 172260.0978947731], 
processed observation next is [0.0, 0.43478260869565216, 0.6135802469135804, 0.7233333333333334, 1.0, 1.0, 0.6182022816801312, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2764951503066514, 0.2764951503066514, 0.3312694190284098], 
reward next is 0.6687, 
noisyNet noise sample is [array([0.06345695], dtype=float32), 0.93844974]. 
=============================================
[2019-03-24 07:33:24,255] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 7.0673677e-34 7.3760793e-36 6.9136965e-33 1.4011196e-32], sum to 1.0000
[2019-03-24 07:33:24,262] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0303
[2019-03-24 07:33:24,266] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1906689.209954834 W.
[2019-03-24 07:33:24,272] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.98333333333333, 51.33333333333333, 1.0, 2.0, 0.8333472778688967, 1.0, 1.0, 0.8333472778688967, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9259455993919, 1906689.209954834, 1906689.209954834, 358040.8196828904], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6195000.0000, 
sim time next is 6195600.0000, 
raw observation next is [30.0, 51.0, 1.0, 2.0, 0.8135355242701123, 1.0, 2.0, 0.8135355242701123, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.926042586079, 1861710.648268475, 1861710.648268475, 349704.6602794146], 
processed observation next is [1.0, 0.7391304347826086, 0.6666666666666666, 0.51, 1.0, 1.0, 0.7780184812739432, 1.0, 1.0, 0.7780184812739432, 0.0, 1.0, -0.25, 0.0, 0.0, 0.809462128623737, 0.6648966600958839, 0.6648966600958839, 0.6725089620757974], 
reward next is 0.3275, 
noisyNet noise sample is [array([0.83390784], dtype=float32), -1.0334147]. 
=============================================
[2019-03-24 07:33:25,983] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-24 07:33:25,985] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:33:25,986] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:33:25,986] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:33:25,988] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:33:25,989] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:33:25,989] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:33:25,990] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:33:25,989] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:33:25,991] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:33:25,992] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:33:26,015] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run67
[2019-03-24 07:33:26,044] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run67
[2019-03-24 07:33:26,075] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run67
[2019-03-24 07:33:26,075] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run67
[2019-03-24 07:33:26,076] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run67
[2019-03-24 07:33:38,772] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.019108837]
[2019-03-24 07:33:38,773] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.46666666666667, 23.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5373756577950403, 6.9112, 6.9112, 121.9260426156618, 383698.0993757789, 383698.0993757789, 99778.30659758637]
[2019-03-24 07:33:38,774] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:33:38,777] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.00000000e+00 1.98016199e-36 0.00000000e+00 1.15552955e-36
 1.10076121e-35], sampled 0.2892799364950822
[2019-03-24 07:34:02,301] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.019108837]
[2019-03-24 07:34:02,304] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.04667486666666, 70.60745553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7674191742837102, 6.911199999999999, 6.9112, 121.9260426156618, 571625.8772084432, 571625.8772084437, 155370.2762991322]
[2019-03-24 07:34:02,305] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:34:02,309] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 2.2079858e-36 0.0000000e+00 1.2598013e-36 1.2322487e-35], sampled 0.7367296516130726
[2019-03-24 07:34:12,989] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.019108837]
[2019-03-24 07:34:12,990] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [36.26666666666667, 34.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8837819599960062, 6.9112, 6.9112, 121.9260426156618, 641855.7125221805, 641855.7125221805, 174665.4023690725]
[2019-03-24 07:34:12,991] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:34:12,995] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.0109411e-38], sampled 0.4059257822048681
[2019-03-24 07:34:35,775] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.019108837]
[2019-03-24 07:34:35,776] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.586747815, 90.41202085, 1.0, 2.0, 0.5904746879171916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 688841.5637252729, 688841.5637252729, 157195.4056957846]
[2019-03-24 07:34:35,778] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:34:35,781] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 4.0562982e-33 3.2542626e-38 2.1702693e-33 1.9698144e-32], sampled 0.4460381979297878
[2019-03-24 07:34:35,783] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 688841.5637252729 W.
[2019-03-24 07:34:39,049] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.019108837]
[2019-03-24 07:34:39,051] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.57406827, 86.28401858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.842604214775144, 6.911199999999999, 6.9112, 121.9260426156618, 623256.8163264, 623256.8163264005, 166714.6418497871]
[2019-03-24 07:34:39,053] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:34:39,057] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 8.0157303e-37 0.0000000e+00 4.4046403e-37 4.5575338e-36], sampled 0.25149820703433867
[2019-03-24 07:34:52,168] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.019108837]
[2019-03-24 07:34:52,171] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.78333333333333, 76.33333333333334, 1.0, 2.0, 0.6053060797173472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 695297.2116929818, 695297.2116929813, 159261.588736494]
[2019-03-24 07:34:52,174] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:34:52,177] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 3.0959623e-33 2.3084982e-38 1.6333505e-33 1.4720060e-32], sampled 0.8440654509029468
[2019-03-24 07:34:52,178] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 695297.2116929818 W.
[2019-03-24 07:34:52,624] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.019108837]
[2019-03-24 07:34:52,625] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.0, 88.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7208872829834966, 6.911199999999999, 6.9112, 121.9260426156618, 538180.3940983141, 538180.3940983146, 148705.6329746605]
[2019-03-24 07:34:52,626] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:34:52,629] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 6.8214006e-34 0.0000000e+00 4.0519814e-34 3.2942017e-33], sampled 0.5840313763343848
[2019-03-24 07:34:55,809] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.019108837]
[2019-03-24 07:34:55,810] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.98060711833333, 102.9993025383333, 1.0, 2.0, 0.766793821901687, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1589040.850478494, 1589040.850478494, 329734.9831704684]
[2019-03-24 07:34:55,811] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:34:55,814] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 4.7340706e-25 7.7734126e-29 3.0991887e-25 1.6228246e-24], sampled 0.8096710736179366
[2019-03-24 07:34:55,816] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1589040.850478494 W.
[2019-03-24 07:35:12,306] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 07:35:12,365] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 07:35:12,368] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 07:35:12,473] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 07:35:12,518] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 07:35:13,532] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1650000, evaluation results [1650000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 07:35:14,028] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:35:14,035] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4940
[2019-03-24 07:35:14,042] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.41666666666667, 55.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8325701282956536, 6.911199999999999, 6.9112, 121.9260426156618, 611975.0662026732, 611975.0662026737, 166593.9551675788], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6198600.0000, 
sim time next is 6199200.0000, 
raw observation next is [29.3, 56.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8470031811902542, 6.911200000000001, 6.9112, 121.9260426156618, 622167.1396483212, 622167.1396483207, 168524.3180330728], 
processed observation next is [1.0, 0.782608695652174, 0.6407407407407407, 0.56, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8087539764878177, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22220254987440044, 0.22220254987440027, 0.32408522698667847], 
reward next is 0.6759, 
noisyNet noise sample is [array([-0.58012146], dtype=float32), -0.41111007]. 
=============================================
[2019-03-24 07:35:17,107] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 7.5333723e-33 7.6764906e-37 2.9880333e-31 1.4567115e-32], sum to 1.0000
[2019-03-24 07:35:17,117] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9169
[2019-03-24 07:35:17,125] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 741513.0602085239 W.
[2019-03-24 07:35:17,129] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.65, 63.16666666666666, 1.0, 2.0, 0.3253176892291613, 1.0, 1.0, 0.3253176892291613, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 741513.0602085239, 741513.0602085243, 186647.4436844246], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6274200.0000, 
sim time next is 6274800.0000, 
raw observation next is [29.7, 63.0, 1.0, 2.0, 0.3256409667880585, 1.0, 2.0, 0.3256409667880585, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 742250.279854649, 742250.2798546494, 186727.8498762852], 
processed observation next is [0.0, 0.6521739130434783, 0.6555555555555556, 0.63, 1.0, 1.0, 0.19719162712864105, 1.0, 1.0, 0.19719162712864105, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2650893856623746, 0.2650893856623748, 0.3590920189928562], 
reward next is 0.6409, 
noisyNet noise sample is [array([0.55430114], dtype=float32), -0.4781145]. 
=============================================
[2019-03-24 07:35:19,693] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:35:19,698] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1641
[2019-03-24 07:35:19,701] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.2, 32.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5862500645924351, 6.911200000000001, 6.9112, 121.9260426156618, 433188.6717639939, 433188.6717639935, 127862.6756418782], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6628800.0000, 
sim time next is 6629400.0000, 
raw observation next is [28.9, 34.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5711139861919096, 6.911200000000001, 6.9112, 121.9260426156618, 422047.3704749407, 422047.3704749402, 126517.1011605009], 
processed observation next is [1.0, 0.7391304347826086, 0.6259259259259259, 0.345, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4638924827398869, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15073120374105026, 0.1507312037410501, 0.24330211761634787], 
reward next is 0.7567, 
noisyNet noise sample is [array([-1.6376281], dtype=float32), 0.6696174]. 
=============================================
[2019-03-24 07:35:24,203] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.1528327e-25 3.6447331e-27 9.5360553e-25 6.2782584e-24], sum to 1.0000
[2019-03-24 07:35:24,203] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8154
[2019-03-24 07:35:24,203] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2040946.765202319 W.
[2019-03-24 07:35:24,206] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.13333333333333, 79.16666666666667, 1.0, 2.0, 0.894686852276001, 1.0, 2.0, 0.894686852276001, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2040946.765202319, 2040946.765202319, 384434.4772917278], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6430200.0000, 
sim time next is 6430800.0000, 
raw observation next is [28.36666666666667, 78.33333333333334, 1.0, 2.0, 0.8940734075364258, 1.0, 2.0, 0.8940734075364258, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 2039545.785829757, 2039545.785829757, 384161.0034953705], 
processed observation next is [1.0, 0.43478260869565216, 0.606172839506173, 0.7833333333333334, 1.0, 1.0, 0.8738969137338403, 1.0, 1.0, 0.8738969137338403, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7284092092249133, 0.7284092092249133, 0.7387711605680202], 
reward next is 0.2612, 
noisyNet noise sample is [array([-2.611281], dtype=float32), -0.9341794]. 
=============================================
[2019-03-24 07:35:27,363] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.5449687e-18 7.9421981e-21 2.2659444e-18 1.1604351e-17], sum to 1.0000
[2019-03-24 07:35:27,369] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3515
[2019-03-24 07:35:27,377] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1052528.960900099 W.
[2019-03-24 07:35:27,382] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.36666666666667, 85.33333333333333, 1.0, 2.0, 0.4616734042471081, 1.0, 1.0, 0.4616734042471081, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1052528.960900099, 1052528.960900099, 223784.6184183749], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6496800.0000, 
sim time next is 6497400.0000, 
raw observation next is [26.33333333333334, 85.66666666666667, 1.0, 2.0, 0.4475848124725252, 1.0, 2.0, 0.4475848124725252, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1020388.221974462, 1020388.221974462, 219649.0938280095], 
processed observation next is [1.0, 0.17391304347826086, 0.5308641975308644, 0.8566666666666667, 1.0, 1.0, 0.34236287199110144, 1.0, 1.0, 0.34236287199110144, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3644243649908793, 0.3644243649908793, 0.42240210351540286], 
reward next is 0.5776, 
noisyNet noise sample is [array([-0.62798846], dtype=float32), 0.95025903]. 
=============================================
[2019-03-24 07:35:29,363] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.00000000e+00 1.19967426e-20 3.04284280e-24 5.27383944e-21
 2.08712431e-21], sum to 1.0000
[2019-03-24 07:35:29,371] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7977
[2019-03-24 07:35:29,377] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1923217.904469396 W.
[2019-03-24 07:35:29,381] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.18333333333334, 80.83333333333333, 1.0, 2.0, 0.8431337347017952, 1.0, 2.0, 0.8431337347017952, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260425269739, 1923217.904469396, 1923217.904469397, 361900.264321905], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6529800.0000, 
sim time next is 6530400.0000, 
raw observation next is [27.1, 81.0, 1.0, 2.0, 0.5752764388235669, 1.0, 2.0, 0.5752764388235669, 1.0, 1.0, 0.9158588260527415, 6.911200000000001, 6.9112, 121.94756008, 1968388.233015429, 1968388.233015429, 382069.567821684], 
processed observation next is [1.0, 0.6086956521739131, 0.5592592592592593, 0.81, 1.0, 1.0, 0.49437671288519874, 1.0, 1.0, 0.49437671288519874, 1.0, 0.5, 0.8948235325659267, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7029957975055103, 0.7029957975055103, 0.7347491688878538], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5088208], dtype=float32), -0.49547756]. 
=============================================
[2019-03-24 07:35:30,448] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 6.9454919e-27 3.7606653e-31 8.3484759e-28 6.4462391e-26], sum to 1.0000
[2019-03-24 07:35:30,453] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5208
[2019-03-24 07:35:30,459] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1316315.56650613 W.
[2019-03-24 07:35:30,463] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.0, 51.0, 1.0, 2.0, 0.5531110731584641, 1.0, 2.0, 0.5531110731584641, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260425241147, 1316315.56650613, 1316315.56650613, 254741.0683445972], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6793200.0000, 
sim time next is 6793800.0000, 
raw observation next is [28.0, 51.5, 1.0, 2.0, 0.3748301622120015, 1.0, 2.0, 0.3748301622120015, 1.0, 1.0, 0.6018374456756782, 6.911199999999999, 6.9112, 121.94756008, 1334286.249717045, 1334286.249717045, 286042.2520336946], 
processed observation next is [1.0, 0.6521739130434783, 0.5925925925925926, 0.515, 1.0, 1.0, 0.25575019310952557, 1.0, 1.0, 0.25575019310952557, 1.0, 0.5, 0.5022968070945977, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.47653080347037324, 0.47653080347037324, 0.5500812539109511], 
reward next is 0.4499, 
noisyNet noise sample is [array([-0.4719969], dtype=float32), 0.0032311883]. 
=============================================
[2019-03-24 07:35:33,118] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:35:33,124] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3606
[2019-03-24 07:35:33,133] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.6, 49.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7825379007439985, 6.9112, 6.9112, 121.9260426156618, 580078.5884446373, 580078.5884446373, 148505.2121703398], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6578400.0000, 
sim time next is 6579000.0000, 
raw observation next is [25.6, 49.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8239602124937541, 6.9112, 6.9112, 121.9260426156618, 610469.1675760496, 610469.1675760496, 152901.1912375607], 
processed observation next is [1.0, 0.13043478260869565, 0.5037037037037038, 0.49, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7799502656171925, 0.0, 0.0, 0.8094621288201359, 0.218024702705732, 0.218024702705732, 0.29404075237992444], 
reward next is 0.7060, 
noisyNet noise sample is [array([0.4822784], dtype=float32), -0.014987581]. 
=============================================
[2019-03-24 07:35:33,147] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[64.17874 ]
 [63.97836 ]
 [63.43072 ]
 [63.182537]
 [62.528023]], R is [[64.24406433]
 [64.31604004]
 [64.37805176]
 [64.4589386 ]
 [64.54139709]].
[2019-03-24 07:35:33,365] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:35:33,372] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0532
[2019-03-24 07:35:33,376] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.95, 49.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.625682069175264, 6.911199999999999, 6.9112, 121.9260426156618, 460631.6444091235, 460631.6444091239, 130621.1129554673], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6589800.0000, 
sim time next is 6590400.0000, 
raw observation next is [24.86666666666667, 49.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6093021351811286, 6.9112, 6.9112, 121.9260426156618, 448491.2238487536, 448491.2238487536, 129065.5517129291], 
processed observation next is [1.0, 0.2608695652173913, 0.47654320987654336, 0.4933333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5116276689764108, 0.0, 0.0, 0.8094621288201359, 0.16017543708884058, 0.16017543708884058, 0.2482029840633252], 
reward next is 0.7518, 
noisyNet noise sample is [array([0.0204755], dtype=float32), -0.7416066]. 
=============================================
[2019-03-24 07:35:35,498] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:35:35,506] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4679
[2019-03-24 07:35:35,514] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.5, 40.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5180074797415907, 6.9112, 6.9112, 121.9260426156618, 369865.4581442063, 369865.4581442063, 115378.9367628115], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6652200.0000, 
sim time next is 6652800.0000, 
raw observation next is [24.4, 41.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.515900990014553, 6.9112, 6.9112, 121.9260426156618, 368361.0294236391, 368361.0294236391, 115314.8380692874], 
processed observation next is [1.0, 0.0, 0.4592592592592592, 0.41, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.39487623751819123, 0.0, 0.0, 0.8094621288201359, 0.13155751050844255, 0.13155751050844255, 0.22175930397939886], 
reward next is 0.7782, 
noisyNet noise sample is [array([-1.011595], dtype=float32), 0.77529734]. 
=============================================
[2019-03-24 07:35:38,835] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 4.3259252e-38 0.0000000e+00 0.0000000e+00 3.1247300e-36], sum to 1.0000
[2019-03-24 07:35:38,851] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1257
[2019-03-24 07:35:38,857] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1297537.772622221 W.
[2019-03-24 07:35:38,861] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.45, 27.16666666666666, 1.0, 2.0, 0.5221387311275509, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8688471732716972, 6.911200000000001, 6.9112, 121.9260424965367, 1297537.772622221, 1297537.77262222, 260368.2204530064], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6713400.0000, 
sim time next is 6714000.0000, 
raw observation next is [30.5, 27.0, 1.0, 2.0, 0.3399700082048803, 1.0, 1.0, 0.3399700082048803, 1.0, 2.0, 0.5662797240885771, 6.9112, 6.9112, 121.94756008, 1268226.38589925, 1268226.38589925, 269428.7958572663], 
processed observation next is [1.0, 0.7391304347826086, 0.6851851851851852, 0.27, 1.0, 1.0, 0.2142500097677147, 1.0, 0.5, 0.2142500097677147, 1.0, 1.0, 0.4578496551107213, 0.0, 0.0, 0.8096049824067558, 0.4529379949640178, 0.4529379949640178, 0.5181322997255121], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.10011017], dtype=float32), 0.4914502]. 
=============================================
[2019-03-24 07:35:38,875] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[54.890583]
 [54.49323 ]
 [53.27429 ]
 [53.99319 ]
 [53.718906]], R is [[55.31362915]
 [54.76049423]
 [54.21289062]
 [53.67076111]
 [53.66669083]].
[2019-03-24 07:35:40,789] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 3.8429976e-37 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-24 07:35:40,796] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6955
[2019-03-24 07:35:40,799] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.5, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5701232469882446, 6.911199999999999, 6.9112, 121.9260426156618, 412862.3873046068, 412862.3873046073, 122621.3056290811], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6753600.0000, 
sim time next is 6754200.0000, 
raw observation next is [18.41666666666667, 83.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.667194401374777, 6.911199999999999, 6.9112, 121.9260426156618, 482822.4138636114, 482822.4138636118, 131021.757027772], 
processed observation next is [1.0, 0.17391304347826086, 0.2376543209876545, 0.8333333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5839930017184712, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1724365763798612, 0.17243657637986137, 0.2519649173611], 
reward next is 0.7480, 
noisyNet noise sample is [array([0.37662658], dtype=float32), 0.6532203]. 
=============================================
[2019-03-24 07:35:40,928] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.9777931e-38], sum to 1.0000
[2019-03-24 07:35:40,935] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7609
[2019-03-24 07:35:40,940] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.25, 76.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5739106579158402, 6.9112, 6.9112, 121.9260426156618, 421581.3066743876, 421581.3066743876, 125448.6660035972], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6741000.0000, 
sim time next is 6741600.0000, 
raw observation next is [20.16666666666666, 76.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5680481049792702, 6.911199999999999, 6.9112, 121.9260426156618, 416940.4669942584, 416940.4669942589, 124774.3568529334], 
processed observation next is [1.0, 0.0, 0.3024691358024689, 0.7666666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4600601312240877, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14890730964080656, 0.14890730964080676, 0.23995068625564114], 
reward next is 0.7600, 
noisyNet noise sample is [array([1.0557399], dtype=float32), -1.1148151]. 
=============================================
[2019-03-24 07:35:41,163] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.6910570e-35 1.5363789e-37 1.2531115e-34 1.8725454e-33], sum to 1.0000
[2019-03-24 07:35:41,171] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5937
[2019-03-24 07:35:41,180] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 775888.0938901574 W.
[2019-03-24 07:35:41,185] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.6, 83.66666666666667, 1.0, 1.0, 0.2133200500832185, 1.0, 1.0, 0.2133200500832185, 1.0, 2.0, 0.3467324038806623, 6.9112, 6.9112, 121.94756008, 775888.0938901574, 775888.0938901574, 224003.5795774311], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7009800.0000, 
sim time next is 7010400.0000, 
raw observation next is [21.5, 84.33333333333334, 1.0, 2.0, 0.2797896793921513, 0.0, 1.0, 0.0, 1.0, 2.0, 0.4571188215224697, 6.911200000000001, 6.9112, 121.9260426048146, 682867.8219465031, 682867.8219465027, 187723.6953161978], 
processed observation next is [1.0, 0.13043478260869565, 0.35185185185185186, 0.8433333333333334, 1.0, 1.0, 0.14260676118113252, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.32139852690308707, 8.881784197001253e-17, 0.0, 0.8094621287481218, 0.24388136498089397, 0.2438813649808938, 0.36100710637730343], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.06196759], dtype=float32), 0.7360128]. 
=============================================
[2019-03-24 07:35:41,613] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:35:41,622] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1619
[2019-03-24 07:35:41,626] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.6, 60.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5750608682934274, 6.9112, 6.9112, 121.9260426156618, 421589.7539467252, 421589.7539467252, 125158.3298244395], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6768000.0000, 
sim time next is 6768600.0000, 
raw observation next is [22.78333333333333, 59.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7577916490422822, 6.9112, 6.9112, 121.9260426156618, 556217.673863474, 556217.673863474, 142847.8281723875], 
processed observation next is [1.0, 0.34782608695652173, 0.39938271604938264, 0.595, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6972395613028528, 0.0, 0.0, 0.8094621288201359, 0.19864916923695503, 0.19864916923695503, 0.27470736186997596], 
reward next is 0.7253, 
noisyNet noise sample is [array([1.7372105], dtype=float32), 0.22223374]. 
=============================================
[2019-03-24 07:35:43,565] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:35:43,571] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6956
[2019-03-24 07:35:43,576] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1432524.132533913 W.
[2019-03-24 07:35:43,581] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.55, 48.5, 1.0, 2.0, 0.3999629735033058, 1.0, 2.0, 0.3999629735033058, 1.0, 1.0, 0.6439513550934721, 6.9112, 6.9112, 121.94756008, 1432524.132533913, 1432524.132533913, 296766.050773444], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6787800.0000, 
sim time next is 6788400.0000, 
raw observation next is [27.66666666666666, 48.33333333333334, 1.0, 2.0, 0.6052200194656175, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9591115546813073, 6.911200000000001, 6.9112, 121.9260426156618, 1445058.525118638, 1445058.525118637, 290772.8603954544], 
processed observation next is [1.0, 0.5652173913043478, 0.5802469135802467, 0.48333333333333345, 1.0, 1.0, 0.5300238326971637, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9488894433516339, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5160923303995136, 0.5160923303995132, 0.5591785776835662], 
reward next is 0.4408, 
noisyNet noise sample is [array([0.01830445], dtype=float32), 1.6088009]. 
=============================================
[2019-03-24 07:35:45,146] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:35:45,153] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3037
[2019-03-24 07:35:45,157] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.4, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.650116218311838, 6.9112, 6.9112, 121.9260426156618, 485315.3502119426, 485315.3502119426, 137880.0180238431], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6848400.0000, 
sim time next is 6849000.0000, 
raw observation next is [22.5, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.654921329625763, 6.911200000000001, 6.9112, 121.9260426156618, 489044.6079551654, 489044.607955165, 138622.2911169559], 
processed observation next is [0.0, 0.2608695652173913, 0.3888888888888889, 0.76, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5686516620322037, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1746587885554162, 0.17465878855541606, 0.266581329071069], 
reward next is 0.7334, 
noisyNet noise sample is [array([2.5217054], dtype=float32), 0.20450786]. 
=============================================
[2019-03-24 07:35:45,179] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[69.87483]
 [69.98073]
 [70.0648 ]
 [70.12941]
 [70.20827]], R is [[69.84246826]
 [69.87889099]
 [69.91632843]
 [69.95470428]
 [69.99384308]].
[2019-03-24 07:35:50,224] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:35:50,235] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9661
[2019-03-24 07:35:50,238] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.7, 93.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6252474938768661, 6.9112, 6.9112, 121.9260426156618, 465938.7995226177, 465938.7995226177, 134333.3570344052], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7183800.0000, 
sim time next is 7184400.0000, 
raw observation next is [19.7, 93.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6247480560458272, 6.9112, 6.9112, 121.9260426156618, 465517.0349470371, 465517.0349470371, 134232.8822226303], 
processed observation next is [1.0, 0.13043478260869565, 0.28518518518518515, 0.9333333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5309350700572839, 0.0, 0.0, 0.8094621288201359, 0.1662560839096561, 0.1662560839096561, 0.2581401581204429], 
reward next is 0.7419, 
noisyNet noise sample is [array([1.163121], dtype=float32), 1.3072628]. 
=============================================
[2019-03-24 07:35:51,309] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:35:51,315] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7164
[2019-03-24 07:35:51,319] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.0, 55.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.836975422598614, 6.9112, 6.9112, 121.9260426156618, 618219.214321502, 618219.214321502, 166304.1693507693], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6955200.0000, 
sim time next is 6955800.0000, 
raw observation next is [29.16666666666667, 54.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8404301560936183, 6.9112, 6.9112, 121.9260426156618, 620392.4114560533, 620392.4114560533, 166857.8034389305], 
processed observation next is [0.0, 0.5217391304347826, 0.6358024691358026, 0.545, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8005376951170229, 0.0, 0.0, 0.8094621288201359, 0.22156871837716188, 0.22156871837716188, 0.32088039122871254], 
reward next is 0.6791, 
noisyNet noise sample is [array([0.8738583], dtype=float32), 0.8561384]. 
=============================================
[2019-03-24 07:35:53,421] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:35:53,427] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7306
[2019-03-24 07:35:53,432] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.0, 50.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8972629680110097, 6.911200000000001, 6.9112, 121.9260426156618, 656211.5062457508, 656211.5062457504, 175672.0839729015], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6963600.0000, 
sim time next is 6964200.0000, 
raw observation next is [31.0, 50.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9017887392625364, 6.911200000000001, 6.9112, 121.9260426156618, 658506.7368153916, 658506.7368153911, 176468.3544146372], 
processed observation next is [0.0, 0.6086956521739131, 0.7037037037037037, 0.505, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8772359240781704, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2351809774340684, 0.23518097743406827, 0.3393622200281485], 
reward next is 0.6606, 
noisyNet noise sample is [array([-2.1624415], dtype=float32), 1.3832692]. 
=============================================
[2019-03-24 07:35:59,144] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:35:59,152] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5958
[2019-03-24 07:35:59,158] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.4, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6126987697082332, 6.9112, 6.9112, 121.9260426156618, 455206.5470928386, 455206.5470928386, 131898.6730818504], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7155000.0000, 
sim time next is 7155600.0000, 
raw observation next is [20.23333333333333, 85.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6123210572648347, 6.9112, 6.9112, 121.9260426156618, 454933.6551377579, 454933.6551377579, 131868.3329472643], 
processed observation next is [1.0, 0.8260869565217391, 0.3049382716049382, 0.8533333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5154013215810432, 0.0, 0.0, 0.8094621288201359, 0.16247630540634211, 0.16247630540634211, 0.2535929479755083], 
reward next is 0.7464, 
noisyNet noise sample is [array([0.41085893], dtype=float32), -0.12964505]. 
=============================================
[2019-03-24 07:36:00,667] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-24 07:36:00,668] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:36:00,669] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:36:00,669] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:36:00,669] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:36:00,670] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:36:00,672] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:36:00,673] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:36:00,673] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:36:00,674] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:36:00,673] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:36:00,698] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run68
[2019-03-24 07:36:00,728] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run68
[2019-03-24 07:36:00,755] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run68
[2019-03-24 07:36:00,783] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run68
[2019-03-24 07:36:00,784] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run68
[2019-03-24 07:36:02,720] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.019517252]
[2019-03-24 07:36:02,722] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [19.5, 55.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4251090771232457, 6.911200000000001, 6.9112, 121.9260426156618, 303521.4167343391, 303521.4167343386, 91788.08371436303]
[2019-03-24 07:36:02,723] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:36:02,725] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.09757199313423259
[2019-03-24 07:36:03,142] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.019517252]
[2019-03-24 07:36:03,143] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.6, 73.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6946790536821178, 6.911199999999999, 6.9112, 121.9260426156618, 518298.9091919371, 518298.9091919376, 142111.9704732226]
[2019-03-24 07:36:03,144] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:36:03,147] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.9594493978488943
[2019-03-24 07:36:11,134] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.019517252]
[2019-03-24 07:36:11,135] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.2, 35.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5798705942692681, 6.9112, 6.9112, 121.9260426156618, 426805.2562799744, 426805.2562799744, 126390.6280639236]
[2019-03-24 07:36:11,136] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:36:11,138] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.7356699285139177
[2019-03-24 07:36:22,938] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.019517252]
[2019-03-24 07:36:22,942] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.85759949, 68.266743555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7050481278148594, 6.911200000000001, 6.9112, 121.9260426156618, 526858.3219663758, 526858.3219663753, 145045.0708646661]
[2019-03-24 07:36:22,943] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:36:22,946] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.13786253441051577
[2019-03-24 07:36:43,564] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.019517252]
[2019-03-24 07:36:43,565] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.6, 89.33333333333333, 1.0, 2.0, 0.896974087371125, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426156208, 1737630.371829898, 1737630.371829898, 356315.5323850044]
[2019-03-24 07:36:43,568] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:36:43,572] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 2.3241959e-34 1.7108248e-38 5.3572025e-34 8.0624829e-33], sampled 0.5134655642936574
[2019-03-24 07:36:43,572] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1737630.371829898 W.
[2019-03-24 07:36:48,251] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.019517252]
[2019-03-24 07:36:48,252] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.0, 82.33333333333334, 1.0, 2.0, 0.860166784669735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 984644.4854469792, 984644.4854469792, 208906.5570230112]
[2019-03-24 07:36:48,253] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:36:48,256] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 9.3103355e-37 0.0000000e+00 1.8324267e-36 2.5452096e-35], sampled 0.010795286742352306
[2019-03-24 07:36:48,256] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 984644.4854469792 W.
[2019-03-24 07:36:50,656] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.019517252]
[2019-03-24 07:36:50,659] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.06666666666667, 92.33333333333334, 1.0, 1.0, 0.7688291670927166, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260267631364, 925363.4132703461, 925363.4132703461, 191815.4222471215]
[2019-03-24 07:36:50,661] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:36:50,666] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.000000e+00 1.495932e-35 0.000000e+00 1.897278e-35 1.900981e-34], sampled 0.2619212757307635
[2019-03-24 07:36:50,667] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 925363.4132703461 W.
[2019-03-24 07:36:52,063] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.019517252]
[2019-03-24 07:36:52,064] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.0, 94.0, 1.0, 2.0, 0.9833669215165541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.116198654416398, 6.9112, 121.9250868378778, 1239755.965932455, 1134779.155218712, 237503.9100787424]
[2019-03-24 07:36:52,064] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:36:52,066] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.1264562e-36 0.0000000e+00 1.8816150e-36 2.3157253e-35], sampled 0.678021362015421
[2019-03-24 07:36:52,069] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1239755.965932455 W.
[2019-03-24 07:36:52,462] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.019517252]
[2019-03-24 07:36:52,464] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.63333333333333, 66.83333333333334, 1.0, 2.0, 0.805648214750665, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 918283.1893653529, 918283.1893653529, 197107.516047043]
[2019-03-24 07:36:52,466] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:36:52,468] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 2.5989821e-38 0.0000000e+00 3.9580791e-38 4.8963673e-37], sampled 0.24429364326138026
[2019-03-24 07:36:52,470] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 918283.1893653529 W.
[2019-03-24 07:36:56,410] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.019517252]
[2019-03-24 07:36:56,411] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [32.58333333333334, 56.83333333333334, 1.0, 2.0, 0.7526964984219642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9259848239317, 857894.6910051755, 857894.691005175, 186362.8904663752]
[2019-03-24 07:36:56,411] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:36:56,414] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.9123039240138393
[2019-03-24 07:36:56,415] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 857894.6910051755 W.
[2019-03-24 07:36:58,221] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.019517252]
[2019-03-24 07:36:58,221] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [31.304507345, 67.45591973500001, 1.0, 2.0, 0.7241389737110118, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1540353.456829002, 1540353.456829002, 321663.6626606334]
[2019-03-24 07:36:58,222] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:36:58,225] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 8.1776668e-36 0.0000000e+00 1.3996163e-35 1.8453779e-34], sampled 0.004658884453445755
[2019-03-24 07:36:58,227] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1540353.456829002 W.
[2019-03-24 07:37:08,661] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.019517252]
[2019-03-24 07:37:08,662] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.00722934666667, 96.76428762666667, 1.0, 2.0, 0.6021602421716641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 688933.2354156167, 688933.2354156167, 158582.7026788904]
[2019-03-24 07:37:08,663] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:37:08,666] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 5.2687466e-38], sampled 0.8633966742553288
[2019-03-24 07:37:08,667] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 688933.2354156167 W.
[2019-03-24 07:37:11,112] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.019517252]
[2019-03-24 07:37:11,114] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.73333333333333, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7177375840608099, 6.9112, 6.9112, 121.9260426156618, 536128.3279743149, 536128.3279743149, 147829.213803271]
[2019-03-24 07:37:11,115] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:37:11,119] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.8487074350007873
[2019-03-24 07:37:48,344] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 07:37:48,546] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 07:37:48,571] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 07:37:48,636] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 07:37:48,724] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 07:37:49,740] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1675000, evaluation results [1675000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 07:37:50,804] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:37:50,815] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4026
[2019-03-24 07:37:50,819] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.33333333333334, 70.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6076318124040225, 6.911200000000001, 6.9112, 121.9260426156618, 451762.1644870634, 451762.1644870629, 131662.5483813453], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7148400.0000, 
sim time next is 7149000.0000, 
raw observation next is [22.16666666666667, 71.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6100176111780183, 6.9112, 6.9112, 121.9260426156618, 453553.2962301691, 453553.2962301691, 131904.9130013668], 
processed observation next is [1.0, 0.7391304347826086, 0.3765432098765434, 0.7183333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5125220139725228, 0.0, 0.0, 0.8094621288201359, 0.16198332008220323, 0.16198332008220323, 0.2536632942333977], 
reward next is 0.7463, 
noisyNet noise sample is [array([0.48065576], dtype=float32), -0.16564484]. 
=============================================
[2019-03-24 07:37:50,835] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[70.17707 ]
 [69.624596]
 [68.178635]
 [65.61721 ]
 [65.039604]], R is [[70.89631653]
 [70.93415833]
 [70.97221375]
 [70.26248932]
 [70.24241638]].
[2019-03-24 07:37:58,834] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.2916171e-38 1.7051954e-38], sum to 1.0000
[2019-03-24 07:37:58,839] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6979
[2019-03-24 07:37:58,843] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.76666666666667, 93.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6368476782525725, 6.9112, 6.9112, 121.9260426156618, 474673.5228734468, 474673.5228734468, 135578.4573232082], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7359600.0000, 
sim time next is 7360200.0000, 
raw observation next is [19.7, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6350311283239362, 6.911200000000001, 6.9112, 121.9260426156618, 473345.7990671538, 473345.7990671533, 135425.7060720485], 
processed observation next is [1.0, 0.17391304347826086, 0.28518518518518515, 0.94, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5437889104049202, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1690520710954121, 0.1690520710954119, 0.2604340501385548], 
reward next is 0.7396, 
noisyNet noise sample is [array([1.052985], dtype=float32), 1.8801577]. 
=============================================
[2019-03-24 07:37:59,295] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:37:59,305] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7912
[2019-03-24 07:37:59,312] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 688147.4236551115 W.
[2019-03-24 07:37:59,315] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 69.5, 1.0, 2.0, 0.1931335917126709, 1.0, 1.0, 0.1931335917126709, 1.0, 2.0, 0.3102786678637058, 6.9112, 6.9112, 121.94756008, 688147.4236551115, 688147.4236551115, 217997.65520015], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7302600.0000, 
sim time next is 7303200.0000, 
raw observation next is [25.2, 68.66666666666667, 1.0, 2.0, 0.315292876327542, 1.0, 2.0, 0.315292876327542, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 751423.2051234748, 751423.2051234748, 185626.8345728504], 
processed observation next is [1.0, 0.5217391304347826, 0.4888888888888889, 0.6866666666666668, 1.0, 1.0, 0.1848724718185024, 1.0, 1.0, 0.1848724718185024, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.268365430401241, 0.268365430401241, 0.3569746818708662], 
reward next is 0.6430, 
noisyNet noise sample is [array([0.17027828], dtype=float32), -0.7211529]. 
=============================================
[2019-03-24 07:38:02,262] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:38:02,271] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3467
[2019-03-24 07:38:02,275] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.33333333333333, 86.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6597317406394052, 6.9112, 6.9112, 121.9260426156618, 490905.4678988244, 490905.4678988244, 137101.1260399028], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7353600.0000, 
sim time next is 7354200.0000, 
raw observation next is [20.26666666666667, 87.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6536020549209346, 6.9112, 6.9112, 121.9260426156618, 486458.2937883403, 486458.2937883403, 136584.3995577675], 
processed observation next is [1.0, 0.08695652173913043, 0.3061728395061729, 0.8716666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5670025686511682, 0.0, 0.0, 0.8094621288201359, 0.17373510492440725, 0.17373510492440725, 0.2626623068418606], 
reward next is 0.7373, 
noisyNet noise sample is [array([0.2661538], dtype=float32), -0.44460407]. 
=============================================
[2019-03-24 07:38:03,143] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:38:03,148] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1358
[2019-03-24 07:38:03,152] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1147559.61431367 W.
[2019-03-24 07:38:03,154] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.2, 89.5, 1.0, 2.0, 0.3205795706346002, 1.0, 2.0, 0.3205795706346002, 1.0, 2.0, 0.5160482833057527, 6.911199999999999, 6.9112, 121.94756008, 1147559.61431367, 1147559.61431367, 263663.3616588744], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7403400.0000, 
sim time next is 7404000.0000, 
raw observation next is [21.2, 89.33333333333333, 1.0, 2.0, 0.9275828588915782, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.090347434328435, 6.9112, 121.9252562031074, 1221721.143799354, 1129982.237119134, 227079.7941279475], 
processed observation next is [1.0, 0.6956521739130435, 0.34074074074074073, 0.8933333333333333, 1.0, 1.0, 0.9137891177280693, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.017914743432843494, 0.0, 0.8094569078585861, 0.43632897992834074, 0.40356508468540503, 0.43669191178451444], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.1537204], dtype=float32), 0.17160732]. 
=============================================
[2019-03-24 07:38:03,167] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[66.35491 ]
 [65.87036 ]
 [65.49246 ]
 [65.086006]
 [64.494606]], R is [[65.955513  ]
 [65.78891754]
 [65.63713074]
 [65.55502319]
 [64.8994751 ]].
[2019-03-24 07:38:11,074] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:38:11,081] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4978
[2019-03-24 07:38:11,084] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.8, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7684585711716694, 6.911200000000001, 6.9112, 121.9260426156618, 571851.8609978136, 571851.8609978132, 155861.4446022288], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7513200.0000, 
sim time next is 7513800.0000, 
raw observation next is [21.75, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7666993729690407, 6.911200000000001, 6.9112, 121.9260426156618, 570676.8606803314, 570676.8606803309, 155564.6762105332], 
processed observation next is [0.0, 1.0, 0.3611111111111111, 0.95, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7083742162113007, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20381316452868978, 0.2038131645286896, 0.29916283886641], 
reward next is 0.7008, 
noisyNet noise sample is [array([0.13219574], dtype=float32), 0.4121183]. 
=============================================
[2019-03-24 07:38:16,257] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:38:16,258] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:38:16,306] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run9
[2019-03-24 07:38:17,817] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:38:17,822] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4608
[2019-03-24 07:38:17,830] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.83333333333334, 79.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5553598508348268, 6.9112, 6.9112, 121.9260426156618, 407419.7023545189, 407419.7023545189, 123574.1186747395], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7680000.0000, 
sim time next is 7680600.0000, 
raw observation next is [19.8, 80.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5567566585691041, 6.9112, 6.9112, 121.9260426156618, 408737.690563814, 408737.690563814, 123832.6771869006], 
processed observation next is [1.0, 0.9130434782608695, 0.2888888888888889, 0.8, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.44594582321138004, 0.0, 0.0, 0.8094621288201359, 0.14597774662993357, 0.14597774662993357, 0.2381397638209627], 
reward next is 0.7619, 
noisyNet noise sample is [array([-0.27990437], dtype=float32), -0.28465888]. 
=============================================
[2019-03-24 07:38:19,469] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:38:19,476] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:38:19,492] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run9
[2019-03-24 07:38:19,905] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:38:19,909] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1660
[2019-03-24 07:38:19,917] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1063877.496794929 W.
[2019-03-24 07:38:19,920] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.28333333333334, 37.66666666666667, 1.0, 2.0, 0.2919575662057526, 1.0, 2.0, 0.2919575662057526, 1.0, 2.0, 0.4751342590476998, 6.9112, 6.9112, 121.94756008, 1063877.496794929, 1063877.496794929, 251975.4313585724], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 47400.0000, 
sim time next is 48000.0000, 
raw observation next is [29.46666666666667, 37.33333333333334, 1.0, 2.0, 0.5222923739460734, 1.0, 2.0, 0.5222923739460734, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1272847.507728768, 1272847.507728769, 245687.7267443145], 
processed observation next is [1.0, 0.5652173913043478, 0.6469135802469137, 0.3733333333333334, 1.0, 1.0, 0.43130044517389693, 1.0, 1.0, 0.43130044517389693, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.45458839561741715, 0.4545883956174175, 0.4724763975852202], 
reward next is 0.5275, 
noisyNet noise sample is [array([0.1900057], dtype=float32), 0.58489084]. 
=============================================
[2019-03-24 07:38:19,938] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[65.19528 ]
 [65.05548 ]
 [64.30197 ]
 [63.944736]
 [63.10014 ]], R is [[65.04640198]
 [64.91136932]
 [64.26225281]
 [64.21538544]
 [64.12350464]].
[2019-03-24 07:38:20,052] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 1.6032432e-34 0.0000000e+00 6.2196066e-35 1.2134512e-33], sum to 1.0000
[2019-03-24 07:38:20,055] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6007
[2019-03-24 07:38:20,063] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 893425.4339314908 W.
[2019-03-24 07:38:20,075] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.8, 75.5, 1.0, 2.0, 0.3676446958019881, 1.0, 2.0, 0.3676446958019881, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 893425.4339314908, 893425.4339314912, 199744.4829710506], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7723800.0000, 
sim time next is 7724400.0000, 
raw observation next is [23.16666666666666, 74.0, 1.0, 2.0, 0.2585816836222326, 1.0, 2.0, 0.2585816836222326, 1.0, 1.0, 0.4184175898462655, 6.9112, 6.9112, 121.94756008, 934317.8847445217, 934317.8847445217, 239971.9720461354], 
processed observation next is [1.0, 0.391304347826087, 0.41358024691358003, 0.74, 1.0, 1.0, 0.11735914716932454, 1.0, 1.0, 0.11735914716932454, 1.0, 0.5, 0.27302198730783184, 0.0, 0.0, 0.8096049824067558, 0.3336849588373292, 0.3336849588373292, 0.4614845616271835], 
reward next is 0.5385, 
noisyNet noise sample is [array([-2.8825061], dtype=float32), 1.3099025]. 
=============================================
[2019-03-24 07:38:30,049] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:38:30,049] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:38:30,097] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run9
[2019-03-24 07:38:30,156] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:38:30,164] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1323
[2019-03-24 07:38:30,166] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.43333333333333, 52.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8086999683798131, 6.911199999999999, 6.9112, 121.9260426156618, 598077.8025370851, 598077.8025370856, 162477.9545347533], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7926000.0000, 
sim time next is 7926600.0000, 
raw observation next is [29.26666666666667, 52.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8060654972757338, 6.911200000000001, 6.9112, 121.9260426156618, 596595.9498476262, 596595.9498476257, 161979.7595267647], 
processed observation next is [1.0, 0.7391304347826086, 0.6395061728395063, 0.525, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7575818715946672, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21306998208843791, 0.21306998208843775, 0.3114995375514706], 
reward next is 0.6885, 
noisyNet noise sample is [array([0.17366184], dtype=float32), 1.1008852]. 
=============================================
[2019-03-24 07:38:30,462] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:38:30,462] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:38:30,518] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run9
[2019-03-24 07:38:31,107] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:38:31,108] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3064
[2019-03-24 07:38:31,110] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [33.36666666666667, 13.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6818299609688142, 6.9112, 6.9112, 121.9260426156618, 487123.8338677238, 487123.8338677238, 130210.5254146071], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 225600.0000, 
sim time next is 226200.0000, 
raw observation next is [33.38333333333333, 13.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6830621586145558, 6.9112, 6.9112, 121.9260426156618, 488537.4932761782, 488537.4932761782, 130493.4621486716], 
processed observation next is [0.0, 0.6086956521739131, 0.7919753086419753, 0.1383333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6038276982681947, 0.0, 0.0, 0.8094621288201359, 0.17447767617006363, 0.17447767617006363, 0.25094896567052233], 
reward next is 0.7491, 
noisyNet noise sample is [array([-0.00675561], dtype=float32), 0.21461697]. 
=============================================
[2019-03-24 07:38:31,343] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:38:31,344] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:38:31,357] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run9
[2019-03-24 07:38:31,376] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:38:31,378] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:38:31,392] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run9
[2019-03-24 07:38:31,456] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 9.1065047e-36 0.0000000e+00 8.2885224e-38 1.5394195e-35], sum to 1.0000
[2019-03-24 07:38:31,456] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6420
[2019-03-24 07:38:31,458] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.35, 75.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5580183241847506, 6.9112, 6.9112, 121.9260426156618, 398441.248475043, 398441.248475043, 115886.3469602881], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 10200.0000, 
sim time next is 10800.0000, 
raw observation next is [18.3, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5075790516326267, 6.911200000000001, 6.9112, 121.9260426156618, 362417.6367861002, 362417.6367860998, 111461.6805207655], 
processed observation next is [1.0, 0.13043478260869565, 0.23333333333333336, 0.76, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3844738145407834, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12943487028075007, 0.12943487028074993, 0.21434938561685674], 
reward next is 0.7857, 
noisyNet noise sample is [array([2.038195], dtype=float32), 0.62696934]. 
=============================================
[2019-03-24 07:38:31,502] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:38:31,503] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:38:31,513] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run9
[2019-03-24 07:38:31,724] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:38:31,725] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:38:31,736] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run9
[2019-03-24 07:38:31,872] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:38:31,873] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:38:31,885] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run9
[2019-03-24 07:38:31,905] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:38:31,906] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:38:31,926] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run9
[2019-03-24 07:38:31,954] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:38:31,955] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:38:31,957] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:38:31,957] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:38:31,967] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run9
[2019-03-24 07:38:31,996] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run9
[2019-03-24 07:38:32,129] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:38:32,129] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:38:32,135] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run9
[2019-03-24 07:38:32,211] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:38:32,212] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:38:32,216] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run9
[2019-03-24 07:38:32,264] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:38:32,264] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:38:32,272] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run9
[2019-03-24 07:38:32,331] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:38:32,331] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:38:32,336] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run9
[2019-03-24 07:38:35,215] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:38:35,222] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4959
[2019-03-24 07:38:35,230] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.35, 28.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.6092101461653389, 6.9112, 6.9112, 121.9260426156217, 449303.0761687083, 449303.0761687083, 129511.0472473335], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 408600.0000, 
sim time next is 409200.0000, 
raw observation next is [30.2, 28.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6081690358942831, 6.9112, 6.9112, 121.9260426156618, 448001.9721837812, 448001.9721837812, 129136.5588326175], 
processed observation next is [1.0, 0.7391304347826086, 0.674074074074074, 0.2833333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5102112948678538, 0.0, 0.0, 0.8094621288201359, 0.16000070435135044, 0.16000070435135044, 0.24833953621657212], 
reward next is 0.7517, 
noisyNet noise sample is [array([1.8546344], dtype=float32), 1.2141424]. 
=============================================
[2019-03-24 07:38:36,438] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 8.9972999e-33 1.7564750e-37 6.6718201e-36 1.1635557e-32], sum to 1.0000
[2019-03-24 07:38:36,447] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5034
[2019-03-24 07:38:36,459] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1168577.87229653 W.
[2019-03-24 07:38:36,462] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 33.0, 1.0, 2.0, 0.8731904956770361, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.014170994339795, 6.9112, 121.9255548346076, 1168577.87229653, 1115847.730706177, 215715.7254210031], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 380400.0000, 
sim time next is 381000.0000, 
raw observation next is [27.2, 32.5, 1.0, 2.0, 0.8811713424752321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.08075447024245, 6.9112, 121.9251871064344, 1215029.057156303, 1128202.623018323, 217528.4045066106], 
processed observation next is [1.0, 0.391304347826087, 0.5629629629629629, 0.325, 1.0, 1.0, 0.8585373124705143, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.016955447024245007, 0.0, 0.8094564491285329, 0.4339389489843939, 0.4029295082208296, 0.41832385482040496], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.8310272], dtype=float32), 0.1911171]. 
=============================================
[2019-03-24 07:38:36,477] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[57.299274]
 [57.102684]
 [56.600727]
 [56.125248]
 [55.227226]], R is [[57.15028   ]
 [56.649086  ]
 [56.64126587]
 [56.07485199]
 [55.51410294]].
[2019-03-24 07:38:38,327] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:38:38,333] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4290
[2019-03-24 07:38:38,337] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.6, 29.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.601866744878748, 6.911199999999999, 6.9112, 121.9260426156618, 442594.2863759515, 442594.286375952, 128175.5792247298], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 411600.0000, 
sim time next is 412200.0000, 
raw observation next is [29.45, 30.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5982908508739946, 6.911200000000001, 6.9112, 121.9260426156618, 439761.622480201, 439761.6224802005, 127752.5186937199], 
processed observation next is [1.0, 0.782608695652174, 0.6462962962962963, 0.3, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4978635635924932, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1570577223143575, 0.15705772231435733, 0.24567792056484597], 
reward next is 0.7543, 
noisyNet noise sample is [array([0.34791303], dtype=float32), -0.18887544]. 
=============================================
[2019-03-24 07:38:38,898] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 4.2885194e-35 1.7148123e-36 1.3042887e-33 2.8797774e-29], sum to 1.0000
[2019-03-24 07:38:38,912] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6236
[2019-03-24 07:38:38,918] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1391802.923464751 W.
[2019-03-24 07:38:38,924] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.98333333333333, 63.83333333333334, 1.0, 2.0, 0.9653246756363717, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.334147007647081, 6.9112, 121.9242808520923, 1391802.923464751, 1175219.382531909, 235997.9862536113], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 118200.0000, 
sim time next is 118800.0000, 
raw observation next is [25.4, 62.0, 1.0, 2.0, 0.5384880206473468, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8715106771272978, 6.911199999999999, 6.9112, 121.9257879242955, 1297840.349279111, 1297840.349279112, 268681.7733383375], 
processed observation next is [1.0, 0.391304347826087, 0.49629629629629624, 0.62, 1.0, 1.0, 0.45058097696112714, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.8393883464091223, -8.881784197001253e-17, 0.0, 0.8094604379343241, 0.46351441045682534, 0.4635144104568257, 0.5166957179583413], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.7720325], dtype=float32), 0.7764026]. 
=============================================
[2019-03-24 07:38:39,109] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-24 07:38:39,111] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:38:39,112] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:38:39,113] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:38:39,114] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:38:39,114] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:38:39,116] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:38:39,117] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:38:39,119] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:38:39,120] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:38:39,123] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:38:39,148] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run69
[2019-03-24 07:38:39,148] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run69
[2019-03-24 07:38:39,211] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run69
[2019-03-24 07:38:39,238] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run69
[2019-03-24 07:38:39,238] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run69
[2019-03-24 07:38:47,235] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.020591797]
[2019-03-24 07:38:47,237] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.25967732333334, 31.06810465333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6501283466437816, 6.911200000000001, 6.9112, 121.9260426156618, 477586.9280870936, 477586.9280870932, 132414.6455420044]
[2019-03-24 07:38:47,240] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:38:47,243] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.4225536768521073
[2019-03-24 07:39:06,023] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.020591797]
[2019-03-24 07:39:06,026] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.9, 91.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6893475962248483, 6.9112, 6.9112, 121.9260426156618, 515123.395589266, 515123.395589266, 143348.2088253432]
[2019-03-24 07:39:06,028] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:39:06,031] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.6639417e-38], sampled 0.2128567076840352
[2019-03-24 07:39:48,276] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.020591797]
[2019-03-24 07:39:48,276] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.01666666666667, 57.33333333333334, 1.0, 2.0, 0.8716328195402925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1002045.818597115, 1002045.818597115, 211639.3680497855]
[2019-03-24 07:39:48,279] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:39:48,282] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.7619103490510387
[2019-03-24 07:39:48,284] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1002045.818597115 W.
[2019-03-24 07:40:15,835] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.020591797]
[2019-03-24 07:40:15,837] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.6331355, 59.21950082, 1.0, 2.0, 0.6667711300654466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426149476, 759911.6929070881, 759911.6929070881, 169951.68931435]
[2019-03-24 07:40:15,839] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:40:15,841] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.19320798294080543
[2019-03-24 07:40:15,843] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 759911.6929070881 W.
[2019-03-24 07:40:20,919] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.020591797]
[2019-03-24 07:40:20,919] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.3, 91.16666666666667, 1.0, 2.0, 0.730305295330817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 891360.1030494439, 891360.1030494439, 184470.3430230363]
[2019-03-24 07:40:20,922] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:40:20,924] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 4.9889414e-37 0.0000000e+00 1.4985413e-36 1.9976512e-35], sampled 0.1511929660414646
[2019-03-24 07:40:20,924] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 891360.1030494439 W.
[2019-03-24 07:40:22,057] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.020591797]
[2019-03-24 07:40:22,058] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.61666666666667, 85.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8117724969253383, 6.911199999999999, 6.9112, 121.9260426156618, 601213.419354731, 601213.4193547314, 162556.3344246314]
[2019-03-24 07:40:22,059] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:40:22,061] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.1877885808891291
[2019-03-24 07:40:26,091] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 07:40:26,194] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 07:40:26,491] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 07:40:26,628] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 07:40:26,668] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 07:40:27,684] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1700000, evaluation results [1700000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 07:40:29,212] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:40:29,217] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2487
[2019-03-24 07:40:29,221] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.56666666666667, 24.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5292912322481297, 6.9112, 6.9112, 121.9260426156618, 377924.2184918665, 377924.2184918665, 97555.71632495962], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 183000.0000, 
sim time next is 183600.0000, 
raw observation next is [24.2, 26.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5228127120126892, 6.911200000000001, 6.9112, 121.9260426156618, 373297.3034100671, 373297.3034100666, 97041.27906292569], 
processed observation next is [0.0, 0.13043478260869565, 0.45185185185185184, 0.26, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.40351589001586147, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1333204655035954, 0.13332046550359522, 0.18661784435178017], 
reward next is 0.8134, 
noisyNet noise sample is [array([-1.152207], dtype=float32), -0.058701083]. 
=============================================
[2019-03-24 07:40:32,026] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:40:32,032] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7639
[2019-03-24 07:40:32,037] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.0, 45.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5791703157427398, 6.911200000000001, 6.9112, 121.9260426156618, 427834.8119614269, 427834.8119614264, 127149.9147986798], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 509400.0000, 
sim time next is 510000.0000, 
raw observation next is [25.73333333333333, 46.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5745448860013466, 6.9112, 6.9112, 121.9260426156618, 424082.740722004, 424082.740722004, 126545.674612595], 
processed observation next is [1.0, 0.9130434782608695, 0.5086419753086419, 0.46333333333333343, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4681811075016832, 0.0, 0.0, 0.8094621288201359, 0.15145812168643, 0.15145812168643, 0.2433570665626827], 
reward next is 0.7566, 
noisyNet noise sample is [array([0.12089922], dtype=float32), 0.40967134]. 
=============================================
[2019-03-24 07:40:32,052] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[67.99882]
 [68.08425]
 [68.22761]
 [68.37245]
 [68.25494]], R is [[67.86436462]
 [67.94120026]
 [68.01609039]
 [68.08924103]
 [68.161026  ]].
[2019-03-24 07:40:35,735] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:40:35,745] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2801
[2019-03-24 07:40:35,757] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.55, 44.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5239918434096792, 6.911200000000001, 6.9112, 121.9260426156618, 374139.5886065595, 374139.588606559, 114517.5248218611], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 256200.0000, 
sim time next is 256800.0000, 
raw observation next is [23.4, 44.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5204962167637406, 6.911200000000001, 6.9112, 121.9260426156618, 371642.8973881138, 371642.8973881133, 113480.1057446777], 
processed observation next is [0.0, 1.0, 0.42222222222222217, 0.4466666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4006202709546757, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13272960621004062, 0.13272960621004046, 0.21823097258591864], 
reward next is 0.7818, 
noisyNet noise sample is [array([0.43500748], dtype=float32), 0.20114589]. 
=============================================
[2019-03-24 07:40:47,432] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:40:47,440] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8917
[2019-03-24 07:40:47,447] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.33333333333334, 41.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5877964339586043, 6.9112, 6.9112, 121.9260426156618, 435555.0725421776, 435555.0725421776, 128742.3620915101], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 506400.0000, 
sim time next is 507000.0000, 
raw observation next is [27.06666666666667, 42.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5886606387142509, 6.911199999999999, 6.9112, 121.9260426156618, 435970.2174772233, 435970.2174772237, 128679.2899102257], 
processed observation next is [1.0, 0.8695652173913043, 0.5580246913580248, 0.4216666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4858257983928136, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15570364909900833, 0.15570364909900847, 0.2474601729042802], 
reward next is 0.7525, 
noisyNet noise sample is [array([-0.7419467], dtype=float32), 0.22426943]. 
=============================================
[2019-03-24 07:40:47,460] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[72.85687 ]
 [73.099655]
 [72.847855]
 [73.12742 ]
 [73.33629 ]], R is [[72.59587097]
 [72.62232971]
 [72.64847565]
 [72.67502594]
 [72.70111847]].
[2019-03-24 07:40:48,450] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:40:48,459] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2287
[2019-03-24 07:40:48,463] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.6, 53.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5456374568357817, 6.9112, 6.9112, 121.9260426156618, 399175.0892156783, 399175.0892156783, 122233.7905675023], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 514800.0000, 
sim time next is 515400.0000, 
raw observation next is [23.43333333333333, 54.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5448854892737051, 6.9112, 6.9112, 121.9260426156618, 398469.8502616474, 398469.8502616474, 122101.8171833823], 
processed observation next is [1.0, 1.0, 0.42345679012345666, 0.54, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4311068615921313, 0.0, 0.0, 0.8094621288201359, 0.14231066080773122, 0.14231066080773122, 0.2348111868911198], 
reward next is 0.7652, 
noisyNet noise sample is [array([1.5884365], dtype=float32), -0.2504019]. 
=============================================
[2019-03-24 07:40:55,255] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:40:55,262] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0211
[2019-03-24 07:40:55,267] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1658916.864381294 W.
[2019-03-24 07:40:55,273] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [35.7, 19.16666666666667, 1.0, 2.0, 0.4608751638169323, 1.0, 1.0, 0.4608751638169323, 1.0, 2.0, 0.7438910136122624, 6.9112, 6.9112, 121.94756008, 1658916.864381294, 1658916.864381294, 324394.4574940408], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 658200.0000, 
sim time next is 658800.0000, 
raw observation next is [35.7, 19.0, 1.0, 2.0, 0.4584571451356895, 1.0, 2.0, 0.4584571451356895, 1.0, 2.0, 0.7388023718926842, 6.911199999999999, 6.9112, 121.94756008, 1645243.801594055, 1645243.801594055, 323348.4025464657], 
processed observation next is [1.0, 0.6521739130434783, 0.8777777777777779, 0.19, 1.0, 1.0, 0.3553061251615352, 1.0, 1.0, 0.3553061251615352, 1.0, 1.0, 0.6735029648658553, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5875870719978767, 0.5875870719978767, 0.6218238510508955], 
reward next is 0.3782, 
noisyNet noise sample is [array([-0.08623138], dtype=float32), 0.32957795]. 
=============================================
[2019-03-24 07:40:59,593] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 3.5418211e-37 1.7939648e-35], sum to 1.0000
[2019-03-24 07:40:59,598] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7737
[2019-03-24 07:40:59,604] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1282513.723442741 W.
[2019-03-24 07:40:59,608] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.11666666666667, 23.0, 1.0, 2.0, 0.5166106866416961, 1.0, 1.0, 0.5166106866416961, 0.0, 1.0, 0.0, 6.911200000000003, 6.9112, 121.9260426156618, 1282513.723442741, 1282513.72344274, 244477.4900949448], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 744600.0000, 
sim time next is 745200.0000, 
raw observation next is [32.1, 23.0, 1.0, 2.0, 0.5015067318461126, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8376132313610534, 6.9112, 6.9112, 121.9260426156618, 1249764.198665212, 1249764.198665212, 252871.5758530872], 
processed observation next is [1.0, 0.6521739130434783, 0.7444444444444445, 0.23, 1.0, 1.0, 0.40655563315013404, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.7970165392013168, 0.0, 0.0, 0.8094621288201359, 0.44634435666614714, 0.44634435666614714, 0.4862914920251677], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.30574623], dtype=float32), -1.0447757]. 
=============================================
[2019-03-24 07:40:59,760] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 8.156535e-38], sum to 1.0000
[2019-03-24 07:40:59,767] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3820
[2019-03-24 07:40:59,773] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1226118.695909147 W.
[2019-03-24 07:40:59,776] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.08333333333334, 23.16666666666667, 1.0, 2.0, 0.4940563646163025, 1.0, 2.0, 0.4940563646163025, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1226118.695909147, 1226118.695909148, 237267.4299195581], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 745800.0000, 
sim time next is 746400.0000, 
raw observation next is [32.06666666666667, 23.33333333333334, 1.0, 2.0, 0.5071500640432139, 1.0, 2.0, 0.5071500640432139, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1258043.681958743, 1258043.681958744, 241412.6778780575], 
processed observation next is [1.0, 0.6521739130434783, 0.74320987654321, 0.2333333333333334, 1.0, 1.0, 0.4132738857657309, 1.0, 1.0, 0.4132738857657309, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4493013149852653, 0.44930131498526577, 0.4642551497654952], 
reward next is 0.5357, 
noisyNet noise sample is [array([-0.46554372], dtype=float32), 0.9219394]. 
=============================================
[2019-03-24 07:41:00,176] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:41:00,184] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9534
[2019-03-24 07:41:00,191] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.78333333333333, 24.16666666666666, 1.0, 2.0, 0.2519193563090921, 1.0, 1.0, 0.2519193563090921, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 628258.1270655274, 628258.1270655274, 171425.2029625261], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 753000.0000, 
sim time next is 753600.0000, 
raw observation next is [31.66666666666667, 24.33333333333333, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6207393940712526, 6.9112, 6.9112, 121.9260426156618, 459561.2971176266, 459561.2971176266, 131579.5201218622], 
processed observation next is [1.0, 0.7391304347826086, 0.7283950617283952, 0.2433333333333333, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.5259242425890657, 0.0, 0.0, 0.8094621288201359, 0.16412903468486664, 0.16412903468486664, 0.25303753869588885], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9801587], dtype=float32), 0.052518643]. 
=============================================
[2019-03-24 07:41:04,027] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:41:04,034] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0720
[2019-03-24 07:41:04,041] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.43333333333333, 46.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6871221776898827, 6.911200000000001, 6.9112, 121.9260426156618, 513477.1250751883, 513477.1250751878, 143360.8966228704], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 816000.0000, 
sim time next is 816600.0000, 
raw observation next is [28.71666666666667, 45.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6927365255464026, 6.911199999999999, 6.9112, 121.9260426156618, 517663.200393158, 517663.2003931585, 144245.5409290745], 
processed observation next is [0.0, 0.43478260869565216, 0.6191358024691359, 0.45666666666666655, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6159206569330032, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18487971442612786, 0.18487971442612802, 0.27739527101745093], 
reward next is 0.7226, 
noisyNet noise sample is [array([-0.58724505], dtype=float32), -0.662098]. 
=============================================
[2019-03-24 07:41:05,185] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:41:05,191] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5365
[2019-03-24 07:41:05,194] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.61666666666667, 40.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6478270937154513, 6.911199999999999, 6.9112, 121.9260426156618, 483111.1005097752, 483111.1005097757, 136965.5101814226], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 849000.0000, 
sim time next is 849600.0000, 
raw observation next is [28.4, 41.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6420806618832106, 6.9112, 6.9112, 121.9260426156618, 478574.355408374, 478574.355408374, 136102.1810817076], 
processed observation next is [0.0, 0.8695652173913043, 0.6074074074074074, 0.41, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5526008273540132, 0.0, 0.0, 0.8094621288201359, 0.17091941264584784, 0.17091941264584784, 0.26173496361866844], 
reward next is 0.7383, 
noisyNet noise sample is [array([-0.40595788], dtype=float32), 1.3654637]. 
=============================================
[2019-03-24 07:41:06,824] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:41:06,831] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9596
[2019-03-24 07:41:06,845] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.6, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5765128688046164, 6.911200000000001, 6.9112, 121.9260426156618, 422752.8919413677, 422752.8919413672, 125330.9529423414], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 878400.0000, 
sim time next is 879000.0000, 
raw observation next is [21.5, 65.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5722863309450227, 6.9112, 6.9112, 121.9260426156618, 418988.8651334851, 418988.8651334851, 124659.2267922776], 
processed observation next is [0.0, 0.17391304347826086, 0.35185185185185186, 0.6583333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4653579136812783, 0.0, 0.0, 0.8094621288201359, 0.1496388804048161, 0.1496388804048161, 0.23972928229284152], 
reward next is 0.7603, 
noisyNet noise sample is [array([-1.3369704], dtype=float32), 0.80746365]. 
=============================================
[2019-03-24 07:41:06,861] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[68.536446]
 [68.53312 ]
 [68.8028  ]
 [68.909035]
 [69.195595]], R is [[68.42829895]
 [68.50299835]
 [68.57602692]
 [68.64715576]
 [68.71578217]].
[2019-03-24 07:41:13,725] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 5.7601578e-38 0.0000000e+00 4.4623642e-36 2.4512550e-35], sum to 1.0000
[2019-03-24 07:41:13,731] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8502
[2019-03-24 07:41:13,736] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.36666666666667, 91.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5724805849913193, 6.9112, 6.9112, 121.9260426156618, 420364.8545599969, 420364.8545599969, 125243.5044501836], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1313400.0000, 
sim time next is 1314000.0000, 
raw observation next is [18.3, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5703948163395403, 6.9112, 6.9112, 121.9260426156618, 418665.7475361181, 418665.7475361181, 124981.0726042075], 
processed observation next is [1.0, 0.21739130434782608, 0.23333333333333336, 0.92, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.46299352042442526, 0.0, 0.0, 0.8094621288201359, 0.14952348126289933, 0.14952348126289933, 0.2403482165465529], 
reward next is 0.7597, 
noisyNet noise sample is [array([0.2178267], dtype=float32), -0.5747812]. 
=============================================
[2019-03-24 07:41:13,756] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[57.12298 ]
 [57.150234]
 [57.248398]
 [57.397198]
 [57.306267]], R is [[57.17359543]
 [57.36100769]
 [57.5450058 ]
 [57.72660446]
 [57.90881729]].
[2019-03-24 07:41:14,771] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:41:14,778] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4613
[2019-03-24 07:41:14,780] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.4, 55.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4978416277645797, 6.9112, 6.9112, 121.9260426156618, 359264.1537263697, 359264.1537263697, 116282.1332536731], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1037400.0000, 
sim time next is 1038000.0000, 
raw observation next is [22.3, 56.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5010888023857418, 6.9112, 6.9112, 121.9260426156618, 362053.7714594791, 362053.7714594791, 116699.7797708484], 
processed observation next is [1.0, 0.0, 0.38148148148148153, 0.56, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.37636100298217723, 0.0, 0.0, 0.8094621288201359, 0.1293049183783854, 0.1293049183783854, 0.22442265340547768], 
reward next is 0.7756, 
noisyNet noise sample is [array([0.74426556], dtype=float32), 0.6594474]. 
=============================================
[2019-03-24 07:41:14,794] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[71.70148 ]
 [73.689156]
 [76.76284 ]
 [76.69368 ]
 [76.5739  ]], R is [[70.73482513]
 [70.80386353]
 [70.87309265]
 [70.94267273]
 [71.01173401]].
[2019-03-24 07:41:16,166] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-24 07:41:16,168] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:41:16,170] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:41:16,170] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:41:16,173] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:41:16,174] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:41:16,176] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:41:16,174] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:41:16,177] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:41:16,180] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:41:16,180] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:41:16,201] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run70
[2019-03-24 07:41:16,228] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run70
[2019-03-24 07:41:16,229] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run70
[2019-03-24 07:41:16,229] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run70
[2019-03-24 07:41:16,311] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run70
[2019-03-24 07:41:26,953] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.021085562]
[2019-03-24 07:41:26,956] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [16.33333333333333, 78.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3676755731863726, 6.911200000000001, 6.9112, 121.9260426156618, 262507.750920389, 262507.7509203886, 86765.56495696843]
[2019-03-24 07:41:26,956] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:41:26,958] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.5970975338256536
[2019-03-24 07:41:34,813] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.021085562]
[2019-03-24 07:41:34,814] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.0, 29.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6024961809977427, 6.911200000000001, 6.9112, 121.9260426156618, 447181.0048172604, 447181.00481726, 130601.9860547676]
[2019-03-24 07:41:34,815] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:41:34,821] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.6558094723972725
[2019-03-24 07:41:38,709] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.021085562]
[2019-03-24 07:41:38,711] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.0, 72.33333333333334, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7999464712001552, 6.911199999999999, 6.9112, 121.9260426156242, 594838.4754886524, 594838.4754886528, 151753.2320192732]
[2019-03-24 07:41:38,713] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:41:38,715] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.43142308643409244
[2019-03-24 07:41:44,252] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.021085562]
[2019-03-24 07:41:44,254] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [19.25317849, 85.09586703666668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5376274138707036, 6.9112, 6.9112, 121.9260426156618, 394565.1279736998, 394565.1279736998, 122130.4517234981]
[2019-03-24 07:41:44,254] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:41:44,258] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.7344520489196844
[2019-03-24 07:41:47,762] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.021085562]
[2019-03-24 07:41:47,763] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [33.5, 35.0, 1.0, 2.0, 0.7506944272888666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426088589, 896102.474931527, 896102.474931527, 187842.018006013]
[2019-03-24 07:41:47,765] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:41:47,768] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.16542146384826995
[2019-03-24 07:41:47,771] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 896102.474931527 W.
[2019-03-24 07:42:44,290] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.021085562]
[2019-03-24 07:42:44,292] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.13333333333333, 86.16666666666667, 1.0, 2.0, 0.6061462578920578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 698458.272371653, 698458.272371653, 159512.3710833001]
[2019-03-24 07:42:44,293] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:42:44,296] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.3676624e-37 0.0000000e+00 4.7857172e-37 1.3424334e-36], sampled 0.9807688337999786
[2019-03-24 07:42:44,297] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 698458.272371653 W.
[2019-03-24 07:43:00,756] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.021085562]
[2019-03-24 07:43:00,756] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [19.58344874, 90.79679245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6094553401587849, 6.911200000000001, 6.9112, 121.9260426156618, 453494.5862868273, 453494.5862868268, 132149.0704675061]
[2019-03-24 07:43:00,756] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:43:00,760] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.38303457863244583
[2019-03-24 07:43:03,334] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 07:43:03,374] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 07:43:03,457] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 07:43:03,532] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 07:43:03,643] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 07:43:04,659] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1725000, evaluation results [1725000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 07:43:13,633] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:43:13,642] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5902
[2019-03-24 07:43:13,648] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.7, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5538918556284094, 6.911199999999999, 6.9112, 121.9260426156618, 406696.9006072097, 406696.9006072102, 123614.6964759605], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1234800.0000, 
sim time next is 1235400.0000, 
raw observation next is [18.76666666666667, 88.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5545833158666468, 6.911200000000001, 6.9112, 121.9260426156618, 407456.800549154, 407456.8005491535, 123795.4819237426], 
processed observation next is [1.0, 0.30434782608695654, 0.2506172839506174, 0.8883333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.44322914483330844, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14552028591041213, 0.14552028591041197, 0.23806823446873576], 
reward next is 0.7619, 
noisyNet noise sample is [array([-1.192284], dtype=float32), -0.10953984]. 
=============================================
[2019-03-24 07:43:16,500] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:43:16,507] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7073
[2019-03-24 07:43:16,511] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.91666666666666, 56.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6577890973312284, 6.9112, 6.9112, 121.9260426156618, 491389.3560768886, 491389.3560768886, 139378.5486966211], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1273800.0000, 
sim time next is 1274400.0000, 
raw observation next is [25.8, 57.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6655110498564433, 6.911200000000001, 6.9112, 121.9260426156618, 497168.0793034921, 497168.0793034917, 140210.6918647844], 
processed observation next is [1.0, 0.782608695652174, 0.5111111111111112, 0.57, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.581888812320554, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17756002832267576, 0.1775600283226756, 0.2696359458938162], 
reward next is 0.7304, 
noisyNet noise sample is [array([0.69692224], dtype=float32), -0.29348168]. 
=============================================
[2019-03-24 07:43:24,033] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:43:24,039] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6646
[2019-03-24 07:43:24,044] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.66666666666667, 32.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5874208266269587, 6.9112, 6.9112, 121.9260426156618, 434975.4651737784, 434975.4651737784, 128517.1818569846], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1417200.0000, 
sim time next is 1417800.0000, 
raw observation next is [29.83333333333333, 31.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5906947390562522, 6.9112, 6.9112, 121.9260426156618, 437305.0886046739, 437305.0886046739, 128760.6017544019], 
processed observation next is [0.0, 0.391304347826087, 0.6604938271604937, 0.3166666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.48836842382031526, 0.0, 0.0, 0.8094621288201359, 0.15618038878738355, 0.15618038878738355, 0.24761654183538825], 
reward next is 0.7524, 
noisyNet noise sample is [array([1.3343874], dtype=float32), -1.3926389]. 
=============================================
[2019-03-24 07:43:28,718] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:43:28,725] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8379
[2019-03-24 07:43:28,729] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [34.43333333333334, 29.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7218251704469459, 6.911200000000001, 6.9112, 121.9260426156618, 538243.576751917, 538243.5767519166, 149524.3465176099], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1524000.0000, 
sim time next is 1524600.0000, 
raw observation next is [34.25, 31.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7339981750501092, 6.9112, 6.9112, 121.9260426156618, 546709.0851057017, 546709.0851057017, 151425.7059715632], 
processed observation next is [0.0, 0.6521739130434783, 0.8240740740740741, 0.31, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6674977188126365, 0.0, 0.0, 0.8094621288201359, 0.19525324468060776, 0.19525324468060776, 0.2912032807145446], 
reward next is 0.7088, 
noisyNet noise sample is [array([-0.80103177], dtype=float32), 2.0196466]. 
=============================================
[2019-03-24 07:43:28,884] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:43:28,891] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3890
[2019-03-24 07:43:28,899] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.0, 91.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6952915442265003, 6.9112, 6.9112, 121.9260426156618, 519583.3863505457, 519583.3863505457, 144219.79510236], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1887000.0000, 
sim time next is 1887600.0000, 
raw observation next is [21.0, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6968559516960942, 6.9112, 6.9112, 121.9260426156618, 520752.8203539852, 520752.8203539852, 144389.5490981634], 
processed observation next is [1.0, 0.8695652173913043, 0.3333333333333333, 0.91, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6210699396201177, 0.0, 0.0, 0.8094621288201359, 0.18598315012642327, 0.18598315012642327, 0.2776722098041604], 
reward next is 0.7223, 
noisyNet noise sample is [array([-0.37057868], dtype=float32), 0.15014555]. 
=============================================
[2019-03-24 07:43:33,217] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 6.5285083e-38 0.0000000e+00 6.6424419e-35 3.2664544e-36], sum to 1.0000
[2019-03-24 07:43:33,224] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7277
[2019-03-24 07:43:33,231] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1156642.408383754 W.
[2019-03-24 07:43:33,242] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.3, 44.0, 1.0, 2.0, 0.3171213935945572, 1.0, 2.0, 0.3171213935945572, 1.0, 2.0, 0.516425534241275, 6.911200000000001, 6.9112, 121.94756008, 1156642.408383754, 1156642.408383754, 261645.3681608744], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1605600.0000, 
sim time next is 1606200.0000, 
raw observation next is [27.33333333333333, 43.83333333333334, 1.0, 2.0, 1.009359519879508, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.750936630763809, 6.9112, 121.9225736672043, 1682563.65782843, 1252555.682681958, 247505.9360210441], 
processed observation next is [1.0, 0.6086956521739131, 0.5679012345679011, 0.4383333333333334, 1.0, 1.0, 1.011142285570843, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.08397366307638085, 0.0, 0.8094390986098303, 0.6009155920815821, 0.4473413152435564, 0.47597295388662325], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.42725593], dtype=float32), -0.74763566]. 
=============================================
[2019-03-24 07:43:35,632] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:43:35,645] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2515
[2019-03-24 07:43:35,648] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.25, 50.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5839633114444918, 6.9112, 6.9112, 121.9260426156618, 432053.774165769, 432053.774165769, 127978.5640269658], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1629000.0000, 
sim time next is 1629600.0000, 
raw observation next is [25.1, 50.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.579576067675474, 6.9112, 6.9112, 121.9260426156618, 428492.6826276959, 428492.6826276959, 127391.8618650323], 
processed observation next is [1.0, 0.8695652173913043, 0.4851851851851852, 0.5033333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4744700845943424, 0.0, 0.0, 0.8094621288201359, 0.1530331009384628, 0.1530331009384628, 0.24498434974044675], 
reward next is 0.7550, 
noisyNet noise sample is [array([-1.2836735], dtype=float32), -0.037088938]. 
=============================================
[2019-03-24 07:43:38,250] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:43:38,256] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3003
[2019-03-24 07:43:38,260] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1192903.791286646 W.
[2019-03-24 07:43:38,268] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.9, 68.0, 1.0, 2.0, 0.4929615095055776, 1.0, 1.0, 0.4929615095055776, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260425756222, 1192903.791286646, 1192903.791286646, 236071.7956379703], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1702800.0000, 
sim time next is 1703400.0000, 
raw observation next is [23.85, 68.66666666666667, 1.0, 2.0, 0.1764777140105606, 1.0, 2.0, 0.1764777140105606, 1.0, 1.0, 0.2858607062233454, 6.911199999999999, 6.9112, 121.94756008, 638590.4886377695, 638590.4886377698, 212252.2457794027], 
processed observation next is [1.0, 0.7391304347826086, 0.43888888888888894, 0.6866666666666668, 1.0, 1.0, 0.019616326203048314, 1.0, 1.0, 0.019616326203048314, 1.0, 0.5, 0.10732588277918176, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.22806803165634623, 0.22806803165634637, 0.4081773957296206], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.22952422], dtype=float32), -1.7535293]. 
=============================================
[2019-03-24 07:43:45,758] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.3923874e-31 4.8606573e-36 4.2106852e-31 2.8931449e-29], sum to 1.0000
[2019-03-24 07:43:45,765] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0853
[2019-03-24 07:43:45,768] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 768213.0663990141 W.
[2019-03-24 07:43:45,774] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.56666666666667, 76.83333333333334, 1.0, 2.0, 0.3106892498045759, 1.0, 1.0, 0.3106892498045759, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260425698652, 768213.0663990141, 768213.0663990136, 185370.9023523086], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1846200.0000, 
sim time next is 1846800.0000, 
raw observation next is [21.6, 77.0, 1.0, 2.0, 0.6323461421151738, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156478, 786739.158105199, 786739.158105199, 166222.6727094947], 
processed observation next is [1.0, 0.391304347826087, 0.3555555555555556, 0.77, 1.0, 1.0, 0.5623168358513974, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.809462128820043, 0.2809782707518568, 0.2809782707518568, 0.3196589859797975], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9597276], dtype=float32), 1.937307]. 
=============================================
[2019-03-24 07:43:47,005] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 3.2766773e-35 0.0000000e+00 4.3975790e-34 1.6699696e-31], sum to 1.0000
[2019-03-24 07:43:47,011] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4852
[2019-03-24 07:43:47,017] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 938316.8896686756 W.
[2019-03-24 07:43:47,022] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.56666666666667, 87.33333333333334, 1.0, 2.0, 0.2612170507578981, 1.0, 2.0, 0.2612170507578981, 1.0, 1.0, 0.4212614674074132, 6.911199999999999, 6.9112, 121.94756008, 938316.8896686756, 938316.8896686761, 241109.4264043473], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1873200.0000, 
sim time next is 1873800.0000, 
raw observation next is [21.55, 87.5, 1.0, 2.0, 0.3883264444700474, 1.0, 2.0, 0.3883264444700474, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156484, 935624.0510632572, 935624.0510632567, 205120.7795824544], 
processed observation next is [1.0, 0.6956521739130435, 0.35370370370370374, 0.875, 1.0, 1.0, 0.27181719579767544, 1.0, 1.0, 0.27181719579767544, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.809462128820047, 0.3341514468083061, 0.33415144680830594, 0.3944630376585661], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0603133], dtype=float32), 1.0362523]. 
=============================================
[2019-03-24 07:43:53,314] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-24 07:43:53,316] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:43:53,316] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:43:53,317] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:43:53,320] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:43:53,322] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:43:53,323] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:43:53,324] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:43:53,325] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:43:53,326] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:43:53,326] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:43:53,343] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run71
[2019-03-24 07:43:53,375] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run71
[2019-03-24 07:43:53,402] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run71
[2019-03-24 07:43:53,427] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run71
[2019-03-24 07:43:53,428] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run71
[2019-03-24 07:44:11,693] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.021165937]
[2019-03-24 07:44:11,694] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.0, 30.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8435949629152656, 6.9112, 6.9112, 121.9260426156618, 630455.0388497919, 630455.0388497919, 161325.3249402516]
[2019-03-24 07:44:11,696] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:44:11,698] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.34285202102084367
[2019-03-24 07:44:30,213] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.021165937]
[2019-03-24 07:44:30,215] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.33333333333334, 68.66666666666667, 1.0, 2.0, 0.6180960005663233, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 705601.0378765805, 705601.0378765805, 161277.2070536027]
[2019-03-24 07:44:30,217] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:44:30,221] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 5.1771611e-37 0.0000000e+00 2.3264643e-36 5.2524971e-36], sampled 0.3001027453789138
[2019-03-24 07:44:30,222] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 705601.0378765805 W.
[2019-03-24 07:44:33,552] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.021165937]
[2019-03-24 07:44:33,554] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.0, 89.0, 1.0, 2.0, 0.6293832217551758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 721211.1169510114, 721211.1169510114, 163400.9191027124]
[2019-03-24 07:44:33,555] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:44:33,559] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.4345497e-38 3.5966755e-38], sampled 0.5670707171792679
[2019-03-24 07:44:33,560] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 721211.1169510114 W.
[2019-03-24 07:44:40,147] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.021165937]
[2019-03-24 07:44:40,148] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.66666666666667, 68.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9156658316606214, 6.9112, 6.9112, 121.9260426156618, 666394.2558405937, 666394.2558405937, 178719.6211053173]
[2019-03-24 07:44:40,148] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:44:40,152] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.6861113662377084
[2019-03-24 07:44:41,770] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.021165937]
[2019-03-24 07:44:41,771] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.30379649666667, 54.72548530833333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6612770636182211, 6.911199999999999, 6.9112, 121.9260426156618, 491094.9825063028, 491094.9825063032, 136502.9567693832]
[2019-03-24 07:44:41,771] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:44:41,774] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.056580679459262706
[2019-03-24 07:44:59,095] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.021165937]
[2019-03-24 07:44:59,096] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.0, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7460878057584092, 6.911199999999999, 6.9112, 121.9260426156618, 556954.1969189139, 556954.1969189143, 148097.3186082979]
[2019-03-24 07:44:59,098] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:44:59,102] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.15543466475489331
[2019-03-24 07:45:00,102] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.021165937]
[2019-03-24 07:45:00,105] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [28.62544742333333, 102.3713868333333, 1.0, 2.0, 0.999720855078718, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.142942024829009, 6.9112, 121.9250211851869, 1258412.88897656, 1139741.253572105, 240680.4283802875]
[2019-03-24 07:45:00,106] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:45:00,109] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.39501384743658463
[2019-03-24 07:45:00,110] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1258412.88897656 W.
[2019-03-24 07:45:00,195] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.021165937]
[2019-03-24 07:45:00,197] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.13333333333333, 94.33333333333334, 1.0, 2.0, 0.9240255559849359, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426155262, 1053303.201321383, 1053303.201321382, 222893.9586292439]
[2019-03-24 07:45:00,198] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:45:00,204] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 1.28501e-38], sampled 0.9067198796836365
[2019-03-24 07:45:00,205] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1053303.201321383 W.
[2019-03-24 07:45:03,742] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.021165937]
[2019-03-24 07:45:03,743] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.75, 95.0, 1.0, 2.0, 0.7200127191547645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 820623.0261661949, 820623.0261661945, 179968.615112035]
[2019-03-24 07:45:03,743] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:45:03,746] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.14852429765980235
[2019-03-24 07:45:03,748] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 820623.0261661949 W.
[2019-03-24 07:45:18,133] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.021165937]
[2019-03-24 07:45:18,134] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.91666666666667, 63.66666666666667, 1.0, 2.0, 0.6829425631389907, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156123, 778351.4541441904, 778351.4541441904, 172938.4725352048]
[2019-03-24 07:45:18,135] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:45:18,137] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.445041382043184
[2019-03-24 07:45:18,139] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 778351.4541441904 W.
[2019-03-24 07:45:22,780] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.021165937]
[2019-03-24 07:45:22,781] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.93333333333333, 92.66666666666666, 1.0, 2.0, 0.6407535762084324, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 730245.650033355, 730245.650033355, 165230.0394453335]
[2019-03-24 07:45:22,784] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:45:22,788] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.6688501232184942
[2019-03-24 07:45:22,790] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 730245.650033355 W.
[2019-03-24 07:45:24,572] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.021165937]
[2019-03-24 07:45:24,573] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6926322976150013, 6.9112, 6.9112, 121.9260426156618, 517443.0158551042, 517443.0158551042, 144849.6296606479]
[2019-03-24 07:45:24,573] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:45:24,576] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.6544162693815974
[2019-03-24 07:45:39,514] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 07:45:39,749] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 07:45:39,812] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 07:45:39,955] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 07:45:40,077] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 07:45:41,092] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1750000, evaluation results [1750000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 07:45:45,809] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 7.538787e-38], sum to 1.0000
[2019-03-24 07:45:45,818] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5704
[2019-03-24 07:45:45,824] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.26666666666667, 81.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7525664054922817, 6.9112, 6.9112, 121.9260426156618, 561003.944559554, 561003.944559554, 153251.181565351], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2076000.0000, 
sim time next is 2076600.0000, 
raw observation next is [23.18333333333334, 81.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7500118744265034, 6.9112, 6.9112, 121.9260426156618, 559198.8618241604, 559198.8618241604, 152863.2759661237], 
processed observation next is [0.0, 0.0, 0.4141975308641978, 0.8166666666666668, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6875148430331293, 0.0, 0.0, 0.8094621288201359, 0.19971387922291445, 0.19971387922291445, 0.29396783839639173], 
reward next is 0.7060, 
noisyNet noise sample is [array([-0.73884773], dtype=float32), -0.32072943]. 
=============================================
[2019-03-24 07:45:50,673] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 4.8278225e-35 0.0000000e+00 3.8933182e-35 7.4291183e-34], sum to 1.0000
[2019-03-24 07:45:50,683] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8400
[2019-03-24 07:45:50,690] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.7, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9149194137883284, 6.9112, 6.9112, 121.9260426156618, 667450.9282413019, 667450.9282413019, 178345.6056516154], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2156400.0000, 
sim time next is 2157000.0000, 
raw observation next is [25.61666666666667, 79.50000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9120097161485621, 6.9112, 6.9112, 121.9260426156618, 665720.6377520802, 665720.6377520802, 177882.9072512668], 
processed observation next is [0.0, 1.0, 0.5043209876543211, 0.7950000000000002, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8900121451857026, 0.0, 0.0, 0.8094621288201359, 0.23775737062574293, 0.23775737062574293, 0.3420825139447438], 
reward next is 0.6579, 
noisyNet noise sample is [array([0.92226034], dtype=float32), -0.036858637]. 
=============================================
[2019-03-24 07:45:50,709] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[50.334335]
 [49.37555 ]
 [49.5131  ]
 [49.064194]
 [47.157993]], R is [[50.11994934]
 [50.27577972]
 [50.42778778]
 [50.57593155]
 [50.71910095]].
[2019-03-24 07:45:54,964] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 5.3386959e-35 0.0000000e+00 4.1429575e-37 1.1889542e-35], sum to 1.0000
[2019-03-24 07:45:54,972] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1153
[2019-03-24 07:45:54,975] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1294155.596858012 W.
[2019-03-24 07:45:54,978] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.95, 98.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9766194991003011, 8.043130998252185, 6.9112, 121.9219127779227, 1294155.596858012, 714525.3886119861, 183484.9622089437], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2254200.0000, 
sim time next is 2254800.0000, 
raw observation next is [22.8, 98.0, 1.0, 1.0, 0.2484994925387933, 1.0, 1.0, 0.2484994925387933, 1.0, 2.0, 0.3956845086829697, 6.911199999999997, 6.9112, 121.94756008, 852308.7678188941, 852308.7678188954, 237105.4900038453], 
processed observation next is [1.0, 0.08695652173913043, 0.4, 0.98, 1.0, 0.5, 0.10535653873665869, 1.0, 0.5, 0.10535653873665869, 1.0, 1.0, 0.24460563585371214, -2.6645352591003756e-16, 0.0, 0.8096049824067558, 0.3043959885067479, 0.30439598850674837, 0.45597209616124096], 
reward next is 0.5440, 
noisyNet noise sample is [array([0.6886577], dtype=float32), -0.3478306]. 
=============================================
[2019-03-24 07:45:55,204] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:45:55,204] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4905
[2019-03-24 07:45:55,211] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.7, 97.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8711789599481433, 6.9112, 6.9112, 121.9260426156618, 640818.9780656846, 640818.9780656846, 171411.727909981], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2241600.0000, 
sim time next is 2242200.0000, 
raw observation next is [22.7, 97.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8759976678187557, 6.9112, 6.9112, 121.9260426156618, 644013.7464106596, 644013.7464106596, 172124.8887255527], 
processed observation next is [1.0, 0.9565217391304348, 0.39629629629629626, 0.9766666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8449970847734445, 0.0, 0.0, 0.8094621288201359, 0.23000490943237845, 0.23000490943237845, 0.33100940139529367], 
reward next is 0.6690, 
noisyNet noise sample is [array([0.8812841], dtype=float32), 0.47733915]. 
=============================================
[2019-03-24 07:46:01,750] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 2.0872257e-38 0.0000000e+00 1.6543359e-36 1.6957006e-36], sum to 1.0000
[2019-03-24 07:46:01,757] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2364
[2019-03-24 07:46:01,759] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.43333333333334, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5451990128755538, 6.911200000000001, 6.9112, 121.9260426156618, 392104.7157347788, 392104.7157347783, 119569.1869300454], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2428800.0000, 
sim time next is 2429400.0000, 
raw observation next is [20.26666666666667, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5363630067938296, 6.911199999999999, 6.9112, 121.9260426156618, 385601.4996371526, 385601.4996371531, 118808.8767646718], 
processed observation next is [1.0, 0.08695652173913043, 0.3061728395061729, 0.67, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.420453758492287, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13771482129898308, 0.13771482129898324, 0.2284786091628304], 
reward next is 0.7715, 
noisyNet noise sample is [array([0.95634305], dtype=float32), 0.36600998]. 
=============================================
[2019-03-24 07:46:10,776] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.0370422e-31 5.2409235e-38 5.8842355e-32 2.7716900e-33], sum to 1.0000
[2019-03-24 07:46:10,782] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0297
[2019-03-24 07:46:10,786] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1337582.515551355 W.
[2019-03-24 07:46:10,790] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.0, 30.0, 1.0, 2.0, 0.555954248366021, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8988037322889046, 6.9112, 6.9112, 121.9260426156618, 1337582.515551355, 1337582.515551355, 275177.8799898541], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2551200.0000, 
sim time next is 2551800.0000, 
raw observation next is [33.1, 30.0, 1.0, 2.0, 0.3803541834550328, 1.0, 1.0, 0.3803541834550328, 1.0, 2.0, 0.6107573590223628, 6.911199999999999, 6.9112, 121.94756008, 1354237.491536791, 1354237.491536791, 288395.529831191], 
processed observation next is [1.0, 0.5217391304347826, 0.7814814814814816, 0.3, 1.0, 1.0, 0.26232640887503905, 1.0, 0.5, 0.26232640887503905, 1.0, 1.0, 0.5134466987779535, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.4836562469774253, 0.4836562469774253, 0.5546067881369058], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.29982236], dtype=float32), 0.08273544]. 
=============================================
[2019-03-24 07:46:22,644] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 9.1789829e-20 1.1359891e-20 2.1305588e-18 1.2662076e-16], sum to 1.0000
[2019-03-24 07:46:22,652] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6092
[2019-03-24 07:46:22,660] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 800835.4775914615 W.
[2019-03-24 07:46:22,663] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.33333333333333, 89.0, 1.0, 2.0, 0.3496763560821715, 1.0, 2.0, 0.3496763560821715, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 800835.4775914615, 800835.477591462, 192992.4238782995], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2787600.0000, 
sim time next is 2788200.0000, 
raw observation next is [24.5, 89.0, 1.0, 2.0, 0.3583432678890522, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5707098528739212, 6.911199999999999, 6.9112, 121.9260426156618, 821656.8892946526, 821656.8892946531, 211515.355039767], 
processed observation next is [1.0, 0.2608695652173913, 0.46296296296296297, 0.89, 1.0, 1.0, 0.23612293796315736, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.4633873160924014, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2934488890338045, 0.29344888903380467, 0.40676029815339804], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.35943893], dtype=float32), -0.15071383]. 
=============================================
[2019-03-24 07:46:26,333] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 3.9819750e-24 6.7182782e-28 1.3198945e-26 2.6411779e-24], sum to 1.0000
[2019-03-24 07:46:26,340] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1560
[2019-03-24 07:46:26,348] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.91666666666667, 93.50000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.871314703716433, 6.9112, 6.9112, 121.9260426156618, 642447.5054091283, 642447.5054091283, 171011.9420296351], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2855400.0000, 
sim time next is 2856000.0000, 
raw observation next is [22.83333333333334, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8596329786717541, 6.9112, 6.9112, 121.9260426156618, 634877.629555001, 634877.629555001, 169193.8070688563], 
processed observation next is [1.0, 0.043478260869565216, 0.4012345679012348, 0.93, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8245412233396926, 0.0, 0.0, 0.8094621288201359, 0.2267420105553575, 0.2267420105553575, 0.3253727059016467], 
reward next is 0.6746, 
noisyNet noise sample is [array([-0.83468217], dtype=float32), -1.2346089]. 
=============================================
[2019-03-24 07:46:26,368] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[34.84194 ]
 [36.053333]
 [35.711468]
 [35.339535]
 [35.65887 ]], R is [[34.7644577 ]
 [35.08794403]
 [35.40594864]
 [35.72237015]
 [36.03720093]].
[2019-03-24 07:46:29,780] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-24 07:46:29,786] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:46:29,786] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:46:29,787] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:46:29,788] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:46:29,788] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:46:29,789] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:46:29,789] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:46:29,791] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:46:29,792] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:46:29,793] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:46:29,811] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 2.3312535e-28 9.3332856e-34 1.5384630e-27 5.4681759e-28], sum to 1.0000
[2019-03-24 07:46:29,812] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6264
[2019-03-24 07:46:29,813] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1862508.446221577 W.
[2019-03-24 07:46:29,815] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.5, 86.5, 1.0, 2.0, 1.006363851539735, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260362057049, 1862508.446221577, 1862508.446221577, 380919.7482455831], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2907000.0000, 
sim time next is 2907600.0000, 
raw observation next is [26.66666666666667, 85.66666666666667, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 7.202266850109385, 6.9112, 121.9249126891893, 2027284.14054723, 1878233.279344752, 383090.1576840929], 
processed observation next is [1.0, 0.6521739130434783, 0.5432098765432101, 0.8566666666666667, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 0.02910668501093854, 0.0, 0.8094546272833992, 0.7240300501954392, 0.6707975997659829, 0.7367118417001786], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.07452978], dtype=float32), 2.896036]. 
=============================================
[2019-03-24 07:46:29,820] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run72
[2019-03-24 07:46:29,846] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run72
[2019-03-24 07:46:29,886] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run72
[2019-03-24 07:46:29,887] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run72
[2019-03-24 07:46:29,912] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run72
[2019-03-24 07:47:07,219] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.021068448]
[2019-03-24 07:47:07,220] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.0, 71.5, 1.0, 2.0, 0.5884405230795798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 682595.3550382536, 682595.3550382536, 156674.1609335888]
[2019-03-24 07:47:07,222] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:47:07,225] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.5697579e-35 0.0000000e+00 5.5228926e-35 9.8043185e-35], sampled 0.840671007180631
[2019-03-24 07:47:21,655] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.021068448]
[2019-03-24 07:47:21,656] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.5, 68.83333333333333, 1.0, 2.0, 0.5913226647007513, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 698082.6163629391, 698082.6163629391, 157693.5914401136]
[2019-03-24 07:47:21,657] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:47:21,660] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 3.1602642e-34 0.0000000e+00 1.0006433e-33 1.7971997e-33], sampled 0.3690806188808695
[2019-03-24 07:47:21,661] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 698082.6163629391 W.
[2019-03-24 07:47:37,314] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.021068448]
[2019-03-24 07:47:37,315] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.2, 90.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6892934398785461, 6.911200000000001, 6.9112, 121.9260426156618, 515093.1310235496, 515093.1310235492, 143827.6994542469]
[2019-03-24 07:47:37,316] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:47:37,322] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.03121179832166021
[2019-03-24 07:47:54,877] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.021068448]
[2019-03-24 07:47:54,878] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.94300101166667, 53.51479921166667, 1.0, 2.0, 0.5456465594431239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 665011.8872181121, 665011.8872181118, 150728.10415058]
[2019-03-24 07:47:54,879] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:47:54,881] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 2.2075259e-33 6.1557954e-38 7.1857617e-33 1.2742845e-32], sampled 0.32548400968362046
[2019-03-24 07:47:58,734] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.021068448]
[2019-03-24 07:47:58,734] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.83333333333333, 76.66666666666667, 1.0, 2.0, 0.9145591702371692, 1.0, 2.0, 0.9145591702371692, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2086332.168487531, 2086332.168487532, 393366.7329146405]
[2019-03-24 07:47:58,736] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:47:58,740] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.00000000e+00 1.20768115e-29 9.65839882e-34 2.99611746e-29
 5.70592556e-29], sampled 0.21803526363976866
[2019-03-24 07:47:58,741] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2086332.168487531 W.
[2019-03-24 07:48:13,899] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.021068448]
[2019-03-24 07:48:13,900] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.65593897333333, 80.00395474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5617605935419704, 6.911199999999999, 6.9112, 121.9260426156618, 416170.397688319, 416170.3976883195, 126305.9676365451]
[2019-03-24 07:48:13,902] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:48:13,905] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.871803855728529
[2019-03-24 07:48:14,172] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.021068448]
[2019-03-24 07:48:14,173] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [19.65, 73.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5137047543533989, 6.911199999999999, 6.9112, 121.9260426156618, 371829.2498667939, 371829.2498667943, 117939.0794431213]
[2019-03-24 07:48:14,173] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:48:14,175] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.1311023482121726
[2019-03-24 07:48:16,694] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 07:48:17,004] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 07:48:17,101] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 07:48:17,151] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 07:48:17,175] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 07:48:18,189] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1775000, evaluation results [1775000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 07:48:18,405] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 3.5153114e-33 4.8788414e-37 6.0805439e-33 6.6010009e-32], sum to 1.0000
[2019-03-24 07:48:18,410] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8563
[2019-03-24 07:48:18,415] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 769244.5164109163 W.
[2019-03-24 07:48:18,419] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.65, 89.0, 1.0, 2.0, 0.337477972339762, 1.0, 2.0, 0.337477972339762, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 769244.5164109163, 769244.5164109167, 189697.7892758082], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2932200.0000, 
sim time next is 2932800.0000, 
raw observation next is [25.53333333333333, 89.0, 1.0, 2.0, 0.6683610974892721, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 761724.6615881516, 761724.6615881516, 170238.7720955113], 
processed observation next is [1.0, 0.9565217391304348, 0.5012345679012346, 0.89, 1.0, 1.0, 0.6051917827253239, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27204452199576845, 0.27204452199576845, 0.3273822540298294], 
reward next is 0.6726, 
noisyNet noise sample is [array([-0.27499598], dtype=float32), -1.6401266]. 
=============================================
[2019-03-24 07:48:19,010] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.0102748e-32 2.8781499e-38 4.8088585e-33 1.0028139e-33], sum to 1.0000
[2019-03-24 07:48:19,020] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4157
[2019-03-24 07:48:19,026] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 760355.4398091937 W.
[2019-03-24 07:48:19,030] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 86.33333333333334, 1.0, 2.0, 0.222386784436107, 1.0, 1.0, 0.222386784436107, 1.0, 1.0, 0.354047003454217, 6.9112, 6.9112, 121.94756008, 760355.4398091937, 760355.4398091937, 228047.0998041136], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2922000.0000, 
sim time next is 2922600.0000, 
raw observation next is [26.0, 85.66666666666667, 1.0, 2.0, 0.3302073925043814, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5257009229709659, 6.911199999999999, 6.9112, 121.9260426156618, 752663.8800075803, 752663.8800075807, 203540.4394147506], 
processed observation next is [1.0, 0.8260869565217391, 0.5185185185185185, 0.8566666666666667, 1.0, 1.0, 0.2026278482195017, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.40712615371370736, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2688085285741358, 0.26880852857413595, 0.3914239219514435], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3114076], dtype=float32), 0.39675575]. 
=============================================
[2019-03-24 07:48:20,318] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 6.0578656e-22 1.2748871e-25 8.1369914e-22 3.5676958e-21], sum to 1.0000
[2019-03-24 07:48:20,324] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1611
[2019-03-24 07:48:20,330] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1581971.666707402 W.
[2019-03-24 07:48:20,336] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.66666666666666, 80.66666666666667, 1.0, 2.0, 0.760599923537456, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426156618, 1581971.666707402, 1581971.666707401, 328543.1582479714], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2983200.0000, 
sim time next is 2983800.0000, 
raw observation next is [28.83333333333334, 79.83333333333334, 1.0, 2.0, 0.7594120751053931, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426156618, 1580615.798906079, 1580615.798906078, 328315.4615441121], 
processed observation next is [1.0, 0.5217391304347826, 0.623456790123457, 0.7983333333333335, 1.0, 1.0, 0.7135858036968965, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5645056424664568, 0.5645056424664565, 0.631375887584831], 
reward next is 0.3686, 
noisyNet noise sample is [array([0.6698958], dtype=float32), -0.2230553]. 
=============================================
[2019-03-24 07:48:23,001] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.3211941e-26 1.2892378e-30 9.8146114e-27 3.8457761e-26], sum to 1.0000
[2019-03-24 07:48:23,009] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8635
[2019-03-24 07:48:23,016] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 714885.500497163 W.
[2019-03-24 07:48:23,020] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.91666666666667, 96.66666666666666, 1.0, 2.0, 0.6253010813465111, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 714885.500497163, 714885.500497163, 162595.8165535453], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3019800.0000, 
sim time next is 3020400.0000, 
raw observation next is [23.9, 96.0, 1.0, 2.0, 0.6149624010775144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 706894.3493643057, 706894.3493643057, 160967.9464480747], 
processed observation next is [1.0, 1.0, 0.4407407407407407, 0.96, 1.0, 1.0, 0.54162190604466, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2524622676301092, 0.2524622676301092, 0.30955374316937445], 
reward next is 0.6904, 
noisyNet noise sample is [array([0.63206863], dtype=float32), -0.22852285]. 
=============================================
[2019-03-24 07:48:27,935] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 2.1887142e-29 5.2195457e-34 1.0216823e-29 2.7374196e-29], sum to 1.0000
[2019-03-24 07:48:27,945] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4311
[2019-03-24 07:48:27,950] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.16666666666667, 52.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8226540988855967, 6.911200000000001, 6.9112, 121.9260426156618, 614694.7138508662, 614694.7138508657, 159692.5226295012], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3127800.0000, 
sim time next is 3128400.0000, 
raw observation next is [27.2, 51.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9000578505751593, 6.9112, 6.9112, 121.9260426156618, 672668.2219693161, 672668.2219693161, 168077.4832077131], 
processed observation next is [1.0, 0.21739130434782608, 0.5629629629629629, 0.51, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8750723132189492, 0.0, 0.0, 0.8094621288201359, 0.2402386507033272, 0.2402386507033272, 0.3232259292456021], 
reward next is 0.6768, 
noisyNet noise sample is [array([-0.5515805], dtype=float32), 0.7944853]. 
=============================================
[2019-03-24 07:48:39,624] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.1718332e-30 3.3139000e-34 6.0952072e-30 2.0620292e-29], sum to 1.0000
[2019-03-24 07:48:39,630] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2032
[2019-03-24 07:48:39,644] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 751634.5122163635 W.
[2019-03-24 07:48:39,648] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.6595120227149743, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 751634.5122163635, 751634.5122163635, 168619.0976675715], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3330000.0000, 
sim time next is 3330600.0000, 
raw observation next is [27.01666666666667, 78.83333333333334, 1.0, 2.0, 0.2169650691366522, 1.0, 1.0, 0.2169650691366522, 1.0, 1.0, 0.3454154561245448, 6.911200000000001, 6.9112, 121.94756008, 741809.2607926123, 741809.2607926119, 226216.5099640892], 
processed observation next is [0.0, 0.5652173913043478, 0.5561728395061729, 0.7883333333333334, 1.0, 1.0, 0.06781555849601452, 1.0, 0.5, 0.06781555849601452, 1.0, 0.5, 0.18176932015568095, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2649318788545044, 0.26493187885450425, 0.4350317499309408], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0559561], dtype=float32), -1.2679609]. 
=============================================
[2019-03-24 07:48:42,747] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 1.9696021e-19 4.0522073e-22 8.6932092e-19 1.0120177e-18], sum to 1.0000
[2019-03-24 07:48:42,759] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1199
[2019-03-24 07:48:42,765] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1909520.710796062 W.
[2019-03-24 07:48:42,770] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.63333333333333, 71.0, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.972539344229045, 6.9112, 121.925715001435, 1909520.710796062, 1878109.568504112, 383911.9061208107], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3406800.0000, 
sim time next is 3407400.0000, 
raw observation next is [28.85, 70.0, 1.0, 2.0, 0.5851025900969417, 1.0, 1.0, 0.5851025900969417, 1.0, 2.0, 0.9315023788953596, 6.911199999999999, 6.9112, 121.94756008, 2002047.454527573, 2002047.454527574, 387318.4802560481], 
processed observation next is [1.0, 0.43478260869565216, 0.6240740740740741, 0.7, 1.0, 1.0, 0.5060745120201686, 1.0, 0.5, 0.5060745120201686, 1.0, 1.0, 0.9143779736191995, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7150169480455618, 0.7150169480455622, 0.744843231261631], 
reward next is 0.2552, 
noisyNet noise sample is [array([-2.369773], dtype=float32), -0.70726496]. 
=============================================
[2019-03-24 07:48:46,267] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 5.8456052e-22 1.7214236e-23 3.9960588e-20 1.4796549e-20], sum to 1.0000
[2019-03-24 07:48:46,273] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1616
[2019-03-24 07:48:46,279] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1343154.155126063 W.
[2019-03-24 07:48:46,283] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.41666666666667, 92.5, 1.0, 2.0, 1.009169816142841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.266816884624072, 6.9112, 122.7944335829488, 1343154.155126063, 1159749.504662291, 243596.9530295008], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3463800.0000, 
sim time next is 3464400.0000, 
raw observation next is [24.33333333333334, 94.0, 1.0, 2.0, 0.325228481793789, 1.0, 1.0, 0.325228481793789, 1.0, 1.0, 0.5177743349679015, 6.911200000000001, 6.9112, 121.94756008, 1112233.269931758, 1112233.269931757, 265879.3750605883], 
processed observation next is [1.0, 0.08695652173913043, 0.4567901234567903, 0.94, 1.0, 1.0, 0.19670057356403453, 1.0, 0.5, 0.19670057356403453, 1.0, 0.5, 0.3972179187098768, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.39722616783277076, 0.3972261678327703, 0.5113064905011313], 
reward next is 0.4887, 
noisyNet noise sample is [array([-0.49250114], dtype=float32), 1.9725175]. 
=============================================
[2019-03-24 07:48:50,649] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 7.4091695e-33 2.0472320e-36 2.0387814e-31 2.0782315e-31], sum to 1.0000
[2019-03-24 07:48:50,657] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6083
[2019-03-24 07:48:50,663] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.36666666666667, 80.0, 1.0, 2.0, 0.1995981744711684, 1.0, 2.0, 0.1995981744711684, 1.0, 2.0, 0.317766794216822, 6.911199999999999, 6.9112, 121.94756008, 682404.9678247893, 682404.9678247898, 220463.4719935261], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3536400.0000, 
sim time next is 3537000.0000, 
raw observation next is [24.55, 80.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8864936221155054, 6.9112, 6.9112, 121.9260426156618, 649455.579156667, 649455.579156667, 174017.5605578322], 
processed observation next is [1.0, 0.9565217391304348, 0.46481481481481485, 0.805, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.8581170276443817, 0.0, 0.0, 0.8094621288201359, 0.23194842112738107, 0.23194842112738107, 0.3346491549189081], 
reward next is 0.6654, 
noisyNet noise sample is [array([0.17607532], dtype=float32), -0.725604]. 
=============================================
[2019-03-24 07:48:50,689] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[49.088566]
 [48.529198]
 [48.530235]
 [48.03216 ]
 [48.177933]], R is [[50.17494583]
 [50.24922943]
 [50.31731796]
 [50.45551682]
 [50.63368988]].
[2019-03-24 07:48:52,686] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 5.8305519e-29 5.1320867e-32 5.3022662e-27 6.2173545e-27], sum to 1.0000
[2019-03-24 07:48:52,700] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7443
[2019-03-24 07:48:52,704] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.26666666666667, 93.33333333333334, 1.0, 2.0, 0.261952929400694, 0.0, 2.0, 0.0, 1.0, 1.0, 0.420701501352003, 6.9112, 6.9112, 121.9260426156569, 621726.7020888659, 621726.7020888659, 184464.6936770082], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3570000.0000, 
sim time next is 3570600.0000, 
raw observation next is [22.08333333333333, 93.16666666666666, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8021502240717516, 6.911199999999999, 6.9112, 121.9260426156618, 595416.5043666068, 595416.5043666073, 160785.3973601312], 
processed observation next is [1.0, 0.30434782608695654, 0.3734567901234566, 0.9316666666666665, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7526877800896894, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21264875155950244, 0.2126487515595026, 0.30920268723102157], 
reward next is 0.6908, 
noisyNet noise sample is [array([-1.7161137], dtype=float32), -1.572977]. 
=============================================
[2019-03-24 07:48:55,670] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 8.9121074e-33 3.3786239e-37 9.7431508e-32 1.8498845e-31], sum to 1.0000
[2019-03-24 07:48:55,674] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9930
[2019-03-24 07:48:55,679] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9047830622791535, 6.911200000000001, 6.9112, 121.9260426156618, 659829.4010331787, 659829.4010331782, 177024.5743231757], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3628800.0000, 
sim time next is 3629400.0000, 
raw observation next is [23.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9116521953689369, 6.911200000000001, 6.9112, 121.9260426156618, 664169.2329286152, 664169.2329286147, 178062.2002970587], 
processed observation next is [1.0, 0.0, 0.4074074074074074, 1.0, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8895652442111712, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23720329747450541, 0.23720329747450525, 0.3424273082635744], 
reward next is 0.6576, 
noisyNet noise sample is [array([0.18759204], dtype=float32), 0.828352]. 
=============================================
[2019-03-24 07:48:58,559] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 2.1282328e-28 2.8115386e-33 3.0705078e-27 1.2437911e-27], sum to 1.0000
[2019-03-24 07:48:58,567] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0355
[2019-03-24 07:48:58,573] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2025093.80651587 W.
[2019-03-24 07:48:58,577] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.8877452829253027, 1.0, 1.0, 0.8877452829253027, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9258117439537, 2025093.80651587, 2025093.80651587, 381346.9364454309], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3685800.0000, 
sim time next is 3686400.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.5824638116453564, 1.0, 2.0, 0.5824638116453564, 1.0, 1.0, 0.9273013576614215, 6.911199999999999, 6.9112, 121.94756008, 1993008.264098935, 1993008.264098935, 385903.7904251202], 
processed observation next is [1.0, 0.6956521739130435, 0.5555555555555556, 0.89, 1.0, 1.0, 0.5029331091016148, 1.0, 1.0, 0.5029331091016148, 1.0, 0.5, 0.909126697076777, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7117886657496196, 0.7117886657496196, 0.742122673894462], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.6938984], dtype=float32), -0.2057795]. 
=============================================
[2019-03-24 07:48:59,736] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.6553143e-21 1.0249366e-24 2.2237927e-21 5.9560154e-21], sum to 1.0000
[2019-03-24 07:48:59,741] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8933
[2019-03-24 07:48:59,746] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.13333333333333, 89.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8355265447245825, 6.911200000000001, 6.9112, 121.9260426156618, 622998.2585103157, 622998.2585103152, 163185.8285663444], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4088400.0000, 
sim time next is 4089000.0000, 
raw observation next is [22.41666666666667, 86.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8551260392670957, 6.911199999999999, 6.9112, 121.9260426156618, 637844.2624035253, 637844.2624035258, 165369.3019699634], 
processed observation next is [1.0, 0.30434782608695654, 0.38580246913580263, 0.8666666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8189075490838695, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2278015222869733, 0.22780152228697348, 0.31801788840377576], 
reward next is 0.6820, 
noisyNet noise sample is [array([0.0515265], dtype=float32), -1.7886184]. 
=============================================
[2019-03-24 07:48:59,769] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[31.24587 ]
 [31.573   ]
 [32.113594]
 [32.02195 ]
 [31.805584]], R is [[31.68426895]
 [32.05360794]
 [31.73307228]
 [32.08511353]
 [32.38923264]].
[2019-03-24 07:49:01,018] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 5.7174354e-27 1.8741215e-29 2.1387022e-25 3.1016842e-25], sum to 1.0000
[2019-03-24 07:49:01,024] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5203
[2019-03-24 07:49:01,029] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 745949.3245029291 W.
[2019-03-24 07:49:01,033] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.8, 95.33333333333334, 1.0, 2.0, 0.3272630270113424, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5210133972147583, 6.911199999999999, 6.9112, 121.9260426156618, 745949.3245029291, 745949.3245029296, 202716.3612857689], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3730800.0000, 
sim time next is 3731400.0000, 
raw observation next is [24.7, 96.0, 1.0, 2.0, 0.3300949397008499, 1.0, 1.0, 0.3300949397008499, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 752407.4329823904, 752407.4329823909, 187839.7320268136], 
processed observation next is [1.0, 0.17391304347826086, 0.4703703703703703, 0.96, 1.0, 1.0, 0.20249397583434514, 1.0, 0.5, 0.20249397583434514, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2687169403508537, 0.26871694035085386, 0.36123025389771846], 
reward next is 0.6388, 
noisyNet noise sample is [array([-0.09591357], dtype=float32), -1.3887082]. 
=============================================
[2019-03-24 07:49:06,991] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-24 07:49:06,992] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:49:06,992] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:49:06,993] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:49:06,993] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:49:06,994] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:49:06,994] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:49:06,995] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:49:06,995] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:49:06,996] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:49:06,996] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:49:07,024] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run73
[2019-03-24 07:49:07,052] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run73
[2019-03-24 07:49:07,053] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run73
[2019-03-24 07:49:07,108] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run73
[2019-03-24 07:49:07,130] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run73
[2019-03-24 07:49:30,176] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.020792503]
[2019-03-24 07:49:30,178] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.140875205, 58.11855776500001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5484241283443815, 6.9112, 6.9112, 121.9260426156618, 402319.6833617434, 402319.6833617434, 122972.4517803943]
[2019-03-24 07:49:30,179] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:49:30,183] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.000000e+00 7.509468e-34 0.000000e+00 3.945803e-33 7.011329e-33], sampled 0.7573183085954317
[2019-03-24 07:49:35,591] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.020792503]
[2019-03-24 07:49:35,594] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [18.85370888333333, 87.70192240666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5748819714289233, 6.9112, 6.9112, 121.9260426156618, 423454.6622688532, 423454.6622688532, 126109.8852646704]
[2019-03-24 07:49:35,595] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:49:35,598] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 2.8814047e-36 0.0000000e+00 1.7026955e-35 3.0199756e-35], sampled 0.6048482608716838
[2019-03-24 07:50:33,222] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.020792503]
[2019-03-24 07:50:33,223] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.33333333333334, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9268005653135152, 6.911199999999999, 6.9112, 121.9260426156618, 671384.7402752324, 671384.7402752328, 180696.9673318233]
[2019-03-24 07:50:33,226] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:50:33,228] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 5.3139133e-33 1.0603365e-37 2.6265181e-32 4.9128255e-32], sampled 0.8890742214159594
[2019-03-24 07:50:40,588] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.020792503]
[2019-03-24 07:50:40,589] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [19.632452895, 64.8855475, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4656334568347369, 6.9112, 6.9112, 121.9260426156618, 332599.4082101451, 332599.4082101451, 106423.137985121]
[2019-03-24 07:50:40,590] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:50:40,593] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.5856533e-34 0.0000000e+00 8.7277664e-34 1.5605051e-33], sampled 0.8197205135653769
[2019-03-24 07:50:48,752] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.020792503]
[2019-03-24 07:50:48,753] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.0, 47.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5055910753246768, 6.9112, 6.9112, 121.9260426156618, 366332.1609776005, 366332.1609776005, 117440.5395677407]
[2019-03-24 07:50:48,754] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:50:48,756] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 5.1643005e-37 0.0000000e+00 3.1733802e-36 5.6153650e-36], sampled 0.7362739212094367
[2019-03-24 07:50:52,844] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.020792503]
[2019-03-24 07:50:52,845] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.53333333333333, 58.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6537507508422862, 6.9112, 6.9112, 121.9260426156618, 486527.9977275862, 486527.9977275862, 136563.4993142876]
[2019-03-24 07:50:52,845] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:50:52,847] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 9.0610807e-35 0.0000000e+00 4.8918009e-34 8.6375435e-34], sampled 0.6648318128049926
[2019-03-24 07:50:54,089] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 07:50:54,245] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 07:50:54,377] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 07:50:54,381] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 07:50:54,394] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 07:50:55,412] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1800000, evaluation results [1800000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 07:51:00,037] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 1.3194830e-24 6.3505102e-27 7.0205983e-23 2.4968924e-22], sum to 1.0000
[2019-03-24 07:51:00,045] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9743
[2019-03-24 07:51:00,052] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1305818.544140766 W.
[2019-03-24 07:51:00,058] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.95, 91.16666666666667, 1.0, 2.0, 1.010748729295692, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.210894991435525, 6.9112, 121.9249360611534, 1305818.544140766, 1152349.314932544, 243323.8546797095], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3989400.0000, 
sim time next is 3990000.0000, 
raw observation next is [24.9, 91.33333333333334, 1.0, 2.0, 0.4649954367975538, 1.0, 1.0, 0.4649954367975538, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9258621446207, 1060107.813730555, 1060107.813730554, 224769.2644842429], 
processed observation next is [1.0, 0.17391304347826086, 0.47777777777777775, 0.9133333333333334, 1.0, 1.0, 0.3630898057113736, 1.0, 0.5, 0.3630898057113736, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094609306800996, 0.37860993347519817, 0.37860993347519784, 0.432248585546621], 
reward next is 0.5678, 
noisyNet noise sample is [array([-0.04455124], dtype=float32), -1.7800009]. 
=============================================
[2019-03-24 07:51:00,075] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[38.977844]
 [39.107594]
 [39.07517 ]
 [38.751877]
 [38.32398 ]], R is [[39.62263489]
 [39.22640991]
 [39.36268616]
 [38.96905899]
 [38.62322998]].
[2019-03-24 07:51:01,364] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.8018984e-22 3.7145872e-22 4.7297636e-22 2.3438269e-20], sum to 1.0000
[2019-03-24 07:51:01,368] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0287
[2019-03-24 07:51:01,374] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1330889.930512039 W.
[2019-03-24 07:51:01,377] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.3, 88.33333333333333, 1.0, 2.0, 0.3891104629383181, 1.0, 2.0, 0.3891104629383181, 1.0, 2.0, 0.6194765294408711, 6.911200000000001, 6.9112, 121.94756008, 1330889.930512039, 1330889.930512038, 292344.7770170117], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3984000.0000, 
sim time next is 3984600.0000, 
raw observation next is [25.25, 88.66666666666667, 1.0, 2.0, 0.3565297849318573, 1.0, 2.0, 0.3565297849318573, 1.0, 2.0, 0.5676070289759805, 6.9112, 6.9112, 121.94756008, 1219364.266998712, 1219364.266998712, 278563.8040601494], 
processed observation next is [1.0, 0.08695652173913043, 0.49074074074074076, 0.8866666666666667, 1.0, 1.0, 0.23396402968078248, 1.0, 1.0, 0.23396402968078248, 1.0, 1.0, 0.45950878621997554, 0.0, 0.0, 0.8096049824067558, 0.4354872382138257, 0.4354872382138257, 0.535699623192595], 
reward next is 0.4643, 
noisyNet noise sample is [array([1.1366692], dtype=float32), 1.8515022]. 
=============================================
[2019-03-24 07:51:10,528] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:51:10,535] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6170
[2019-03-24 07:51:10,540] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.91666666666666, 99.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7354280742112624, 6.9112, 6.9112, 121.9260426156618, 549560.020929381, 549560.020929381, 148355.4768353046], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4164600.0000, 
sim time next is 4165200.0000, 
raw observation next is [19.9, 99.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7291674209667005, 6.911200000000001, 6.9112, 121.9260426156618, 544863.2181051526, 544863.2181051521, 147552.2475310202], 
processed observation next is [1.0, 0.21739130434782608, 0.2925925925925925, 0.99, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6614592762083756, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19459400646612593, 0.19459400646612576, 0.2837543221750388], 
reward next is 0.7162, 
noisyNet noise sample is [array([-0.5730094], dtype=float32), 0.61943805]. 
=============================================
[2019-03-24 07:51:14,612] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 2.7302037e-36 0.0000000e+00 1.9548411e-34 4.8033326e-36], sum to 1.0000
[2019-03-24 07:51:14,624] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4434
[2019-03-24 07:51:14,632] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.4, 76.16666666666666, 1.0, 2.0, 0.1849786192990463, 1.0, 1.0, 0.1849786192990463, 1.0, 1.0, 0.301824523656355, 6.9112, 6.9112, 121.94756008, 676137.1483986554, 676137.1483986554, 214541.6149422388], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4243800.0000, 
sim time next is 4244400.0000, 
raw observation next is [22.0, 78.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8640048423380702, 6.9112, 6.9112, 121.9260426156618, 645649.2078376368, 645649.2078376368, 163175.6128871119], 
processed observation next is [1.0, 0.13043478260869565, 0.37037037037037035, 0.78, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.8300060529225878, 0.0, 0.0, 0.8094621288201359, 0.230589002799156, 0.230589002799156, 0.3137992555521383], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.4157894], dtype=float32), -0.46797407]. 
=============================================
[2019-03-24 07:51:15,168] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 5.8427930e-38 0.0000000e+00 2.8243677e-37 1.0999757e-36], sum to 1.0000
[2019-03-24 07:51:15,184] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5248
[2019-03-24 07:51:15,188] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.5, 81.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8273159966503473, 6.9112, 6.9112, 121.9260426156618, 617142.3220942385, 617142.3220942385, 156731.386085132], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4255800.0000, 
sim time next is 4256400.0000, 
raw observation next is [22.0, 80.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7405399661730447, 6.911199999999999, 6.9112, 121.9260426156618, 552954.4900603655, 552954.4900603659, 147724.3331216966], 
processed observation next is [1.0, 0.2608695652173913, 0.37037037037037035, 0.8, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6756749577163059, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19748374645013053, 0.19748374645013067, 0.2840852560032627], 
reward next is 0.7159, 
noisyNet noise sample is [array([-0.39993957], dtype=float32), -2.5926368]. 
=============================================
[2019-03-24 07:51:17,501] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 7.1295087e-35 0.0000000e+00 1.5127163e-36 8.7971208e-35], sum to 1.0000
[2019-03-24 07:51:17,512] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5722
[2019-03-24 07:51:17,524] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2205953.659545727 W.
[2019-03-24 07:51:17,529] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.66666666666667, 37.33333333333334, 1.0, 2.0, 0.6625128793415664, 1.0, 1.0, 0.644621101647218, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2205953.659545727, 2205953.659545727, 419318.5535374997], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4288800.0000, 
sim time next is 4289400.0000, 
raw observation next is [33.5, 39.0, 1.0, 2.0, 0.5945037245737219, 1.0, 2.0, 0.5945037245737219, 1.0, 2.0, 0.9464692911559686, 6.9112, 6.9112, 121.94756008, 2034251.979601311, 2034251.979601311, 392389.0724467717], 
processed observation next is [1.0, 0.6521739130434783, 0.7962962962962963, 0.39, 1.0, 1.0, 0.5172663387782404, 1.0, 1.0, 0.5172663387782404, 1.0, 1.0, 0.9330866139449606, 0.0, 0.0, 0.8096049824067558, 0.7265185641433254, 0.7265185641433254, 0.7545943700899456], 
reward next is 0.2454, 
noisyNet noise sample is [array([-0.7718699], dtype=float32), -0.73644495]. 
=============================================
[2019-03-24 07:51:19,726] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 6.9222121e-28 3.8083763e-32 1.4663270e-27 1.6202436e-26], sum to 1.0000
[2019-03-24 07:51:19,733] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1295
[2019-03-24 07:51:19,738] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2232757.100976555 W.
[2019-03-24 07:51:19,743] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.45, 53.0, 1.0, 2.0, 0.9786654707099852, 1.0, 2.0, 0.9786654707099852, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2232757.100976555, 2232757.100976556, 423112.5466598237], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4372200.0000, 
sim time next is 4372800.0000, 
raw observation next is [32.63333333333333, 53.0, 1.0, 2.0, 0.655671150289808, 1.0, 2.0, 0.6412002371213389, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2194232.758840202, 2194232.758840202, 417540.5728624042], 
processed observation next is [1.0, 0.6086956521739131, 0.7641975308641975, 0.53, 1.0, 1.0, 0.5900847027259619, 1.0, 1.0, 0.572857425144451, 1.0, 0.5, 0.9972168686025908, 0.0, 0.0, 0.8096049824067558, 0.7836545567286435, 0.7836545567286435, 0.8029626401200082], 
reward next is 0.1970, 
noisyNet noise sample is [array([-0.42691332], dtype=float32), 0.03822625]. 
=============================================
[2019-03-24 07:51:22,229] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.000000e+00 5.694046e-24 9.360199e-28 8.710714e-24 4.646481e-22], sum to 1.0000
[2019-03-24 07:51:22,236] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2990
[2019-03-24 07:51:22,243] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 703369.1158181584 W.
[2019-03-24 07:51:22,247] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.91666666666666, 78.83333333333334, 1.0, 2.0, 0.3076490356811681, 1.0, 1.0, 0.3076490356811681, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 703369.1158181584, 703369.1158181588, 182413.3668512661], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4399800.0000, 
sim time next is 4400400.0000, 
raw observation next is [25.63333333333333, 78.66666666666667, 1.0, 2.0, 0.2985566998976723, 1.0, 2.0, 0.2985566998976723, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 686725.2346648632, 686725.2346648632, 180423.1855804922], 
processed observation next is [1.0, 0.9565217391304348, 0.5049382716049381, 0.7866666666666667, 1.0, 1.0, 0.1649484522591337, 1.0, 1.0, 0.1649484522591337, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24525901238030828, 0.24525901238030828, 0.3469676645778696], 
reward next is 0.6530, 
noisyNet noise sample is [array([1.6481575], dtype=float32), -0.7378851]. 
=============================================
[2019-03-24 07:51:29,023] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 4.7136263e-29 7.5131853e-36 3.7971522e-30 4.9076607e-30], sum to 1.0000
[2019-03-24 07:51:29,030] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9588
[2019-03-24 07:51:29,034] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.2, 99.33333333333333, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8265695900283047, 6.911199999999999, 6.9112, 121.9260426155829, 614144.7781722744, 614144.7781722748, 163548.2185898541], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4588800.0000, 
sim time next is 4589400.0000, 
raw observation next is [21.1, 99.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8040629589640407, 6.911199999999999, 6.9112, 121.9260426156618, 598774.280879728, 598774.2808797285, 159942.1928352767], 
processed observation next is [1.0, 0.08695652173913043, 0.3370370370370371, 0.9966666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7550786987050508, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2138479574570457, 0.21384795745704588, 0.3075811400678398], 
reward next is 0.6924, 
noisyNet noise sample is [array([-0.4469369], dtype=float32), -0.98829085]. 
=============================================
[2019-03-24 07:51:31,342] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 6.2473323e-35 0.0000000e+00 2.8243275e-35 2.2078437e-35], sum to 1.0000
[2019-03-24 07:51:31,348] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9587
[2019-03-24 07:51:31,355] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 697663.0296351592 W.
[2019-03-24 07:51:31,359] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.2, 92.66666666666666, 1.0, 2.0, 0.3060884904462328, 1.0, 1.0, 0.3060884904462328, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 697663.0296351592, 697663.0296351596, 181928.0182499586], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4545600.0000, 
sim time next is 4546200.0000, 
raw observation next is [23.6, 96.33333333333334, 1.0, 2.0, 0.3022204107056568, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4812930315700522, 6.911199999999999, 6.9112, 121.9260426156618, 692333.2739733598, 692333.2739733603, 195784.2365885362], 
processed observation next is [0.0, 0.6086956521739131, 0.4296296296296297, 0.9633333333333334, 1.0, 1.0, 0.16931001274482954, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.35161628946256523, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24726188356191423, 0.2472618835619144, 0.3765081472856466], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.7775742], dtype=float32), -2.111019]. 
=============================================
[2019-03-24 07:51:31,856] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 4.6152383e-34 1.5221965e-38 1.6185336e-32 4.1954312e-34], sum to 1.0000
[2019-03-24 07:51:31,862] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7681
[2019-03-24 07:51:31,868] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 696462.2650096394 W.
[2019-03-24 07:51:31,876] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.93333333333333, 94.66666666666667, 1.0, 2.0, 0.605004752692475, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 696462.2650096394, 696462.2650096394, 159281.1913330851], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4555200.0000, 
sim time next is 4555800.0000, 
raw observation next is [23.95, 94.5, 1.0, 2.0, 0.2034473849787866, 1.0, 1.0, 0.2034473849787866, 1.0, 1.0, 0.3238948627049845, 6.9112, 6.9112, 121.94756008, 695570.9792677475, 695570.9792677475, 221724.0175826903], 
processed observation next is [0.0, 0.7391304347826086, 0.4425925925925926, 0.945, 1.0, 1.0, 0.05172307735569832, 1.0, 0.5, 0.05172307735569832, 1.0, 0.5, 0.15486857838123064, 0.0, 0.0, 0.8096049824067558, 0.2484182068813384, 0.2484182068813384, 0.4263923415051737], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.53856343], dtype=float32), -0.7022025]. 
=============================================
[2019-03-24 07:51:33,886] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 2.9365000e-35 1.9721411e-36 6.0941517e-33 5.4465138e-32], sum to 1.0000
[2019-03-24 07:51:33,894] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9121
[2019-03-24 07:51:33,897] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.53333333333333, 90.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8716980342996341, 6.9112, 6.9112, 121.9260426156618, 647868.8260791393, 647868.8260791393, 169074.1009571306], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4605000.0000, 
sim time next is 4605600.0000, 
raw observation next is [22.76666666666667, 89.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8805935641687134, 6.9112, 6.9112, 121.9260426156618, 654049.1174322304, 654049.1174322304, 170425.9549151479], 
processed observation next is [1.0, 0.30434782608695654, 0.3987654320987655, 0.8966666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8507419552108916, 0.0, 0.0, 0.8094621288201359, 0.23358897051151084, 0.23358897051151084, 0.327742220990669], 
reward next is 0.6723, 
noisyNet noise sample is [array([-1.4781439], dtype=float32), -0.029754154]. 
=============================================
[2019-03-24 07:51:44,351] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-24 07:51:44,353] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:51:44,353] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:51:44,353] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:51:44,354] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:51:44,355] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:51:44,356] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:51:44,356] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:51:44,356] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:51:44,355] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:51:44,359] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:51:44,378] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run74
[2019-03-24 07:51:44,408] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run74
[2019-03-24 07:51:44,434] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run74
[2019-03-24 07:51:44,435] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run74
[2019-03-24 07:51:44,501] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run74
[2019-03-24 07:51:48,925] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.020553133]
[2019-03-24 07:51:48,929] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.33333333333333, 51.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4599209789540021, 6.911199999999999, 6.9112, 121.9260426156618, 328381.9062604771, 328381.9062604776, 96046.90128172345]
[2019-03-24 07:51:48,929] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:51:48,933] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 8.4515004e-34 0.0000000e+00 2.0190432e-33 2.8086013e-33], sampled 0.0033058272691213197
[2019-03-24 07:51:53,889] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.020553133]
[2019-03-24 07:51:53,890] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.05, 47.16666666666667, 1.0, 2.0, 0.9219102968915989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.174695614779324, 6.9112, 121.9247714554252, 1280565.459335089, 1145633.560366891, 226437.4321824495]
[2019-03-24 07:51:53,892] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:51:53,895] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.000000e+00 2.865751e-21 1.522428e-24 3.714235e-21 6.671108e-21], sampled 0.17470274844451028
[2019-03-24 07:51:53,897] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1280565.459335089 W.
[2019-03-24 07:52:04,284] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.020553133]
[2019-03-24 07:52:04,285] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.99323849333333, 63.49967006000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5745897397208339, 6.9112, 6.9112, 121.9260426156618, 422251.843470865, 422251.843470865, 125591.1771744193]
[2019-03-24 07:52:04,285] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:52:04,287] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.3703240e-32 1.0141992e-37 3.1481628e-32 4.4609776e-32], sampled 0.6574260568919127
[2019-03-24 07:52:10,036] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.020553133]
[2019-03-24 07:52:10,038] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [17.26401370333333, 82.31272175333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.467443786389087, 6.9112, 6.9112, 121.9260426156618, 333778.5085627422, 333778.5085627422, 105522.9618118852]
[2019-03-24 07:52:10,042] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:52:10,045] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.3578428e-29 3.2108637e-34 2.9612340e-29 4.2837906e-29], sampled 0.35316840215425904
[2019-03-24 07:52:44,000] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.020553133]
[2019-03-24 07:52:44,001] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.50272947, 30.9681299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.603906913697299, 6.9112, 6.9112, 121.9260426156618, 435082.3690115627, 435082.3690115627, 121546.1536536379]
[2019-03-24 07:52:44,003] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:52:44,005] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 6.3482721e-30 1.2345972e-34 1.2911037e-29 1.8002910e-29], sampled 0.6329511855800978
[2019-03-24 07:53:05,948] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.020553133]
[2019-03-24 07:53:05,951] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.16208443666667, 66.27586885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6671504651151889, 6.911200000000001, 6.9112, 121.9260426156618, 498394.7797854242, 498394.7797854237, 140387.6743171109]
[2019-03-24 07:53:05,953] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:53:05,956] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 9.7228881e-30 2.1141066e-34 2.0964518e-29 2.9950660e-29], sampled 0.2470957388340026
[2019-03-24 07:53:13,340] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.020553133]
[2019-03-24 07:53:13,342] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.48643575666667, 88.46882651499999, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 9.178783089692937, 6.9112, 127.8176381997486, 2380870.329979726, 1163554.447205519, 246646.836366616]
[2019-03-24 07:53:13,345] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:53:13,350] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.3646345e-22 3.9423413e-26 1.7566225e-22 3.3761760e-22], sampled 0.8522340701597259
[2019-03-24 07:53:13,351] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2380870.329979726 W.
[2019-03-24 07:53:27,344] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.020553133]
[2019-03-24 07:53:27,345] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [17.0, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5042706154488901, 6.911200000000001, 6.9112, 121.9260426156618, 365852.4529408376, 365852.4529408371, 117521.6694005503]
[2019-03-24 07:53:27,346] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:53:27,350] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 3.7458324e-31 4.8470298e-36 8.2966814e-31 1.1823493e-30], sampled 0.6044835624600363
[2019-03-24 07:53:30,948] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 07:53:31,065] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 07:53:31,231] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 07:53:31,249] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 07:53:31,376] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 07:53:32,392] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1825000, evaluation results [1825000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 07:53:41,106] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 7.5683330e-20 2.2885857e-23 1.3798169e-19 1.8166364e-19], sum to 1.0000
[2019-03-24 07:53:41,114] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4283
[2019-03-24 07:53:41,120] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1686298.526920319 W.
[2019-03-24 07:53:41,126] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 84.83333333333333, 1.0, 2.0, 0.7393668447139762, 1.0, 2.0, 0.7393668447139762, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1686298.526920319, 1686298.526920319, 319336.2279620884], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4968600.0000, 
sim time next is 4969200.0000, 
raw observation next is [26.0, 85.66666666666667, 1.0, 2.0, 0.4481609521965955, 1.0, 2.0, 0.4481609521965955, 1.0, 1.0, 0.7134868314802224, 6.911200000000001, 6.9112, 121.94756008, 1533064.775888774, 1533064.775888774, 318821.4320516518], 
processed observation next is [1.0, 0.5217391304347826, 0.5185185185185185, 0.8566666666666667, 1.0, 1.0, 0.34304875261499473, 1.0, 1.0, 0.34304875261499473, 1.0, 0.5, 0.6418585393502779, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5475231342459908, 0.5475231342459908, 0.6131181385608688], 
reward next is 0.3869, 
noisyNet noise sample is [array([-1.1495944], dtype=float32), 0.7355935]. 
=============================================
[2019-03-24 07:53:42,906] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 6.0482564e-38 0.0000000e+00 3.5242314e-38 0.0000000e+00], sum to 1.0000
[2019-03-24 07:53:42,914] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4803
[2019-03-24 07:53:42,927] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 99.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.90478327676135, 6.9112, 6.9112, 121.9260426156618, 660950.1913278563, 660950.1913278563, 176820.2749007719], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5025000.0000, 
sim time next is 5025600.0000, 
raw observation next is [23.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9147900936432359, 6.9112, 6.9112, 121.9260426156618, 666934.0473178325, 666934.0473178325, 178402.8368770748], 
processed observation next is [0.0, 0.17391304347826086, 0.4074074074074074, 1.0, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8934876170540448, 0.0, 0.0, 0.8094621288201359, 0.23819073118494016, 0.23819073118494016, 0.3430823786097592], 
reward next is 0.6569, 
noisyNet noise sample is [array([0.6241655], dtype=float32), -1.1992749]. 
=============================================
[2019-03-24 07:53:45,194] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 2.3484087e-28 9.0766278e-32 3.2654460e-28 1.7462070e-29], sum to 1.0000
[2019-03-24 07:53:45,201] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5591
[2019-03-24 07:53:45,205] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 748935.8325791268 W.
[2019-03-24 07:53:45,207] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.91666666666667, 88.33333333333334, 1.0, 2.0, 0.3285726286225888, 1.0, 1.0, 0.3285726286225888, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 748935.8325791268, 748935.8325791273, 187459.1474206558], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5043000.0000, 
sim time next is 5043600.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.6682861769971913, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 761639.2330084594, 761639.2330084594, 170227.2367094006], 
processed observation next is [0.0, 0.391304347826087, 0.5185185185185185, 0.89, 1.0, 1.0, 0.6051025916633229, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2720140117887355, 0.2720140117887355, 0.32736007059500116], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.26593325], dtype=float32), -0.7553047]. 
=============================================
[2019-03-24 07:53:47,714] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 4.7171877e-29 1.7209757e-32 8.2756112e-28 2.2235229e-27], sum to 1.0000
[2019-03-24 07:53:47,719] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1835
[2019-03-24 07:53:47,723] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 864105.6007003039 W.
[2019-03-24 07:53:47,731] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.65, 93.0, 1.0, 2.0, 0.3790713667960476, 1.0, 1.0, 0.3790713667960476, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 864105.6007003039, 864105.6007003044, 200519.6873590878], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5092200.0000, 
sim time next is 5092800.0000, 
raw observation next is [26.53333333333333, 92.66666666666666, 1.0, 2.0, 0.3790435297762423, 1.0, 2.0, 0.3790435297762423, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 864042.109532363, 864042.1095323635, 200512.080859175], 
processed observation next is [0.0, 0.9565217391304348, 0.5382716049382715, 0.9266666666666665, 1.0, 1.0, 0.2607661068764789, 1.0, 1.0, 0.2607661068764789, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.30858646769012965, 0.3085864676901298, 0.3856001554984135], 
reward next is 0.6144, 
noisyNet noise sample is [array([-1.4025763], dtype=float32), -0.07703233]. 
=============================================
[2019-03-24 07:53:49,616] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 3.9446660e-22 1.4079466e-23 1.6238373e-20 7.1666710e-21], sum to 1.0000
[2019-03-24 07:53:49,623] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8682
[2019-03-24 07:53:49,632] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 892347.1981025812 W.
[2019-03-24 07:53:49,635] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.9, 93.66666666666667, 1.0, 2.0, 0.3914533628204481, 1.0, 2.0, 0.3914533628204481, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 892347.1981025812, 892347.1981025817, 203856.9425080232], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5128800.0000, 
sim time next is 5129400.0000, 
raw observation next is [26.95, 93.83333333333334, 1.0, 2.0, 0.3939969896832708, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6272560391619014, 6.9112, 6.9112, 121.9260426156618, 898148.9833049324, 898148.9833049324, 222261.0807219227], 
processed observation next is [0.0, 0.34782608695652173, 0.5537037037037037, 0.9383333333333335, 1.0, 1.0, 0.27856784486103664, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.5340700489523768, 0.0, 0.0, 0.8094621288201359, 0.32076749403747584, 0.32076749403747584, 0.4274251552344668], 
reward next is 0.5726, 
noisyNet noise sample is [array([-2.0446389], dtype=float32), 0.87989277]. 
=============================================
[2019-03-24 07:53:53,209] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 7.2884838e-19 5.5470047e-20 5.5534044e-18 7.8924115e-17], sum to 1.0000
[2019-03-24 07:53:53,215] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9132
[2019-03-24 07:53:53,221] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1083785.768603496 W.
[2019-03-24 07:53:53,225] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.06666666666667, 93.66666666666667, 1.0, 2.0, 0.4753739662485889, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7568108361169902, 6.911199999999999, 6.9112, 121.9260426156618, 1083785.768603496, 1083785.768603496, 248499.4184673258], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5194200.0000, 
sim time next is 5194800.0000, 
raw observation next is [24.0, 94.0, 1.0, 2.0, 0.457366823475097, 1.0, 1.0, 0.457366823475097, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1042704.082295731, 1042704.082295731, 222512.2057891806], 
processed observation next is [1.0, 0.13043478260869565, 0.4444444444444444, 0.94, 1.0, 1.0, 0.3540081231846393, 1.0, 0.5, 0.3540081231846393, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3723943151056182, 0.3723943151056182, 0.4279080880561165], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.59362453], dtype=float32), 0.7112919]. 
=============================================
[2019-03-24 07:53:55,478] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 4.0926250e-24 4.0566667e-27 1.6261523e-24 3.9667101e-23], sum to 1.0000
[2019-03-24 07:53:55,483] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4108
[2019-03-24 07:53:55,491] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 820438.921820025 W.
[2019-03-24 07:53:55,498] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.9, 87.0, 1.0, 2.0, 0.3599256364207234, 1.0, 1.0, 0.3599256364207234, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 820438.921820025, 820438.9218200253, 195463.9630663641], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5257800.0000, 
sim time next is 5258400.0000, 
raw observation next is [26.8, 87.33333333333334, 1.0, 2.0, 0.7171056983248564, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 817308.0289693426, 817308.0289693426, 179408.9504155138], 
processed observation next is [1.0, 0.8695652173913043, 0.5481481481481482, 0.8733333333333334, 1.0, 1.0, 0.6632210694343528, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.29189572463190805, 0.29189572463190805, 0.3450172123375265], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.37722662], dtype=float32), -1.7796059]. 
=============================================
[2019-03-24 07:53:57,915] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 2.2653803e-20 5.5803839e-22 1.3129584e-20 4.1706476e-20], sum to 1.0000
[2019-03-24 07:53:57,924] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7672
[2019-03-24 07:53:57,929] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1313467.663423117 W.
[2019-03-24 07:53:57,939] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.5, 77.33333333333334, 1.0, 2.0, 0.5738030182299428, 1.0, 2.0, 0.5738030182299428, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1313467.663423117, 1313467.663423117, 259401.2568562555], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5312400.0000, 
sim time next is 5313000.0000, 
raw observation next is [25.7, 76.16666666666666, 1.0, 2.0, 0.5666666342156834, 1.0, 2.0, 0.5666666342156834, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1300082.295998456, 1300082.295998457, 257161.405137166], 
processed observation next is [1.0, 0.4782608695652174, 0.5074074074074074, 0.7616666666666666, 1.0, 1.0, 0.4841269454948612, 1.0, 1.0, 0.4841269454948612, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.46431510571373424, 0.4643151057137346, 0.49454116372531925], 
reward next is 0.5055, 
noisyNet noise sample is [array([1.1737556], dtype=float32), 1.3127717]. 
=============================================
[2019-03-24 07:53:57,955] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[29.720089]
 [30.048952]
 [29.932022]
 [29.850529]
 [30.032215]], R is [[29.92376518]
 [29.62452698]
 [29.74415398]
 [29.92914009]
 [29.62984848]].
[2019-03-24 07:53:59,565] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.2748307e-22 8.5929859e-25 5.7908065e-22 1.6587585e-22], sum to 1.0000
[2019-03-24 07:53:59,570] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7254
[2019-03-24 07:53:59,574] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.95, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8885542817455301, 6.9112, 6.9112, 121.9260426156618, 658269.7610230258, 658269.7610230258, 172194.6889338979], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5293800.0000, 
sim time next is 5294400.0000, 
raw observation next is [22.83333333333334, 90.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8668120842148089, 6.9112, 6.9112, 121.9260426156618, 642602.1694311533, 642602.1694311533, 169227.3718707058], 
processed observation next is [1.0, 0.2608695652173913, 0.4012345679012348, 0.9033333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.833515105268511, 0.0, 0.0, 0.8094621288201359, 0.22950077479684047, 0.22950077479684047, 0.32543725359751113], 
reward next is 0.6746, 
noisyNet noise sample is [array([-1.2378409], dtype=float32), -0.5508995]. 
=============================================
[2019-03-24 07:54:14,610] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 6.2326140e-30 1.8004874e-32 2.7836599e-28 2.6602124e-28], sum to 1.0000
[2019-03-24 07:54:14,614] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3658
[2019-03-24 07:54:14,623] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 692504.3032924739 W.
[2019-03-24 07:54:14,631] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.6, 97.66666666666667, 1.0, 2.0, 0.3038262036461526, 1.0, 2.0, 0.3038262036461526, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 692504.3032924739, 692504.3032924739, 181381.3058220937], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5617200.0000, 
sim time next is 5617800.0000, 
raw observation next is [23.6, 97.5, 1.0, 2.0, 0.6012396097092861, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 691077.1802768047, 691077.1802768047, 158578.7682050295], 
processed observation next is [0.0, 0.0, 0.4296296296296297, 0.975, 1.0, 1.0, 0.5252852496539121, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2468132786702874, 0.2468132786702874, 0.30495916962505676], 
reward next is 0.6950, 
noisyNet noise sample is [array([0.2972353], dtype=float32), -0.18332608]. 
=============================================
[2019-03-24 07:54:20,415] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:54:20,425] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6031
[2019-03-24 07:54:20,433] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.53333333333334, 68.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7755254294896268, 6.911200000000001, 6.9112, 121.9260426156618, 577196.9155806795, 577196.9155806791, 156663.0003160033], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5743200.0000, 
sim time next is 5743800.0000, 
raw observation next is [25.65, 67.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7741931907247641, 6.911200000000001, 6.9112, 121.9260426156618, 576279.5072668893, 576279.5072668889, 156454.0255531305], 
processed observation next is [0.0, 0.4782608695652174, 0.5055555555555555, 0.675, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7177414884059552, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20581410973817477, 0.2058141097381746, 0.30087312606371247], 
reward next is 0.6991, 
noisyNet noise sample is [array([-1.4380195], dtype=float32), 1.0398281]. 
=============================================
[2019-03-24 07:54:20,990] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:54:20,996] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2501
[2019-03-24 07:54:21,001] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.46666666666667, 69.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8502326670584043, 6.9112, 6.9112, 121.9260426156618, 627201.4769939929, 627201.4769939929, 168226.1128006725], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6034800.0000, 
sim time next is 6035400.0000, 
raw observation next is [26.35, 69.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8493753862380214, 6.911200000000001, 6.9112, 121.9260426156618, 626787.68662295, 626787.6866229495, 168051.4120010264], 
processed observation next is [1.0, 0.8695652173913043, 0.5314814814814816, 0.695, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8117192327975267, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22385274522248214, 0.22385274522248197, 0.32317579230966614], 
reward next is 0.6768, 
noisyNet noise sample is [array([0.8637946], dtype=float32), 1.3585712]. 
=============================================
[2019-03-24 07:54:21,467] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-24 07:54:21,468] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:54:21,468] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:54:21,469] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:54:21,469] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:54:21,470] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:54:21,470] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:54:21,471] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:54:21,471] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:54:21,471] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:54:21,472] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:54:21,496] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run75
[2019-03-24 07:54:21,522] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run75
[2019-03-24 07:54:21,552] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run75
[2019-03-24 07:54:21,553] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run75
[2019-03-24 07:54:21,578] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run75
[2019-03-24 07:54:56,709] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.02085516]
[2019-03-24 07:54:56,712] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.53333333333333, 62.33333333333334, 1.0, 2.0, 0.6139439047522187, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 700601.5669351523, 700601.5669351523, 160538.4245148912]
[2019-03-24 07:54:56,713] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:54:56,718] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.44513983903566834
[2019-03-24 07:54:56,719] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 700601.5669351523 W.
[2019-03-24 07:54:57,304] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.02085516]
[2019-03-24 07:54:57,306] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.40380956, 35.63624974, 1.0, 2.0, 0.6477064424610223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 821042.4877703312, 821042.4877703312, 169287.1003802525]
[2019-03-24 07:54:57,307] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:54:57,311] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 6.1638034e-32 1.9066584e-36 2.7615823e-31 5.3666400e-31], sampled 0.05169239801787673
[2019-03-24 07:54:57,312] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 821042.4877703312 W.
[2019-03-24 07:54:58,133] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.02085516]
[2019-03-24 07:54:58,135] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.63321087, 102.5778491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8039246108104375, 6.9112, 6.9112, 121.9260426156618, 596734.1282441551, 596734.1282441551, 161007.3560025011]
[2019-03-24 07:54:58,135] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:54:58,139] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.2692637077460365
[2019-03-24 07:55:09,158] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.02085516]
[2019-03-24 07:55:09,160] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [30.86723577166667, 64.76489634666667, 1.0, 2.0, 0.7178707484463507, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1533198.837416457, 1533198.837416457, 320501.3506090968]
[2019-03-24 07:55:09,161] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:55:09,164] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 4.4618479e-31 1.7959780e-35 1.7880322e-30 3.7524274e-30], sampled 0.14106386365124401
[2019-03-24 07:55:09,165] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1533198.837416457 W.
[2019-03-24 07:55:17,201] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.02085516]
[2019-03-24 07:55:17,202] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.95, 69.5, 1.0, 2.0, 0.9048692484012745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1031452.094878453, 1031452.094878453, 218561.3575543494]
[2019-03-24 07:55:17,204] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:55:17,207] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 5.4730899e-32 1.6059962e-36 2.1453470e-31 4.9121346e-31], sampled 0.6800590571941287
[2019-03-24 07:55:17,208] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1031452.094878453 W.
[2019-03-24 07:55:18,595] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.02085516]
[2019-03-24 07:55:18,597] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.55, 75.0, 1.0, 2.0, 0.9852469566353838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.053766893830019, 6.9112, 121.9254467958655, 1196201.207940098, 1123194.572580298, 237191.1518477653]
[2019-03-24 07:55:18,597] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:55:18,600] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 4.0095613e-33 7.5077917e-38 1.6928732e-32 3.7393915e-32], sampled 0.9580327966111695
[2019-03-24 07:55:18,602] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1196201.207940098 W.
[2019-03-24 07:55:38,177] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.02085516]
[2019-03-24 07:55:38,178] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.06795852333333, 87.55393702666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8858992433103478, 6.911199999999999, 6.9112, 121.9260426156618, 650517.2490623386, 650517.2490623391, 173604.4319325535]
[2019-03-24 07:55:38,181] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:55:38,184] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.7253492403672785
[2019-03-24 07:55:38,352] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.02085516]
[2019-03-24 07:55:38,352] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.16452859, 83.5647443, 1.0, 2.0, 0.6313550267545459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 719529.4071274177, 719529.4071274177, 163555.0196071242]
[2019-03-24 07:55:38,354] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 07:55:38,358] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.00000000e+00 9.78279919e-35 0.00000000e+00 5.54580143e-34
 1.05889165e-33], sampled 0.8713689850620303
[2019-03-24 07:55:38,360] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 719529.4071274177 W.
[2019-03-24 07:55:38,374] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.02085516]
[2019-03-24 07:55:38,376] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.0, 78.0, 1.0, 2.0, 0.9288962221724115, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1774070.503288146, 1774070.503288146, 363281.1035132075]
[2019-03-24 07:55:38,376] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:55:38,378] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.1620311e-30 4.8983154e-35 4.2974554e-30 8.9753406e-30], sampled 0.5214367645537965
[2019-03-24 07:55:38,382] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1774070.503288146 W.
[2019-03-24 07:55:40,046] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.02085516]
[2019-03-24 07:55:40,047] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.25, 89.66666666666666, 1.0, 2.0, 0.6581740852846251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 750108.9418511656, 750108.9418511656, 168374.4787442558]
[2019-03-24 07:55:40,049] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:55:40,053] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.8718989e-37 0.0000000e+00 1.1890489e-36 2.4279599e-36], sampled 0.6589432383703213
[2019-03-24 07:55:40,056] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 750108.9418511656 W.
[2019-03-24 07:56:03,323] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.02085516]
[2019-03-24 07:56:03,324] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.1, 59.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6092056534426508, 6.911200000000001, 6.9112, 121.9260426156618, 452511.6416939645, 452511.641693964, 131490.2784898349]
[2019-03-24 07:56:03,324] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:56:03,327] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.49992664161289124
[2019-03-24 07:56:07,862] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.02085516]
[2019-03-24 07:56:07,863] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.33333333333334, 81.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7232580655889046, 6.911200000000001, 6.9112, 121.9260426156618, 540488.3310630231, 540488.3310630226, 147493.1368755457]
[2019-03-24 07:56:07,864] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:56:07,868] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.3284377898929658
[2019-03-24 07:56:08,197] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 07:56:08,280] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 07:56:08,315] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 07:56:08,332] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 07:56:08,356] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 07:56:09,368] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1850000, evaluation results [1850000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 07:56:10,945] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 5.2363536e-28 2.7569299e-31 2.3927125e-25 1.8468865e-25], sum to 1.0000
[2019-03-24 07:56:10,952] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6625
[2019-03-24 07:56:10,955] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.2, 82.0, 1.0, 1.0, 0.1843208946995212, 1.0, 1.0, 0.1843208946995212, 1.0, 2.0, 0.2943693781706911, 6.9112, 6.9112, 121.94756008, 644995.7741603919, 644995.7741603919, 215460.1584025397], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6073200.0000, 
sim time next is 6073800.0000, 
raw observation next is [24.25, 81.66666666666667, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9518823505615699, 6.9112, 6.9112, 121.9260425989863, 700834.331589154, 700834.331589154, 181976.495035493], 
processed observation next is [1.0, 0.30434782608695654, 0.4537037037037037, 0.8166666666666668, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9398529382019624, 0.0, 0.0, 0.8094621287094279, 0.250297975567555, 0.250297975567555, 0.3499547981451788], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.06672302], dtype=float32), -1.5306538]. 
=============================================
[2019-03-24 07:56:10,992] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:56:11,009] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1048
[2019-03-24 07:56:11,012] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.4, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8839617332758531, 6.911199999999999, 6.9112, 121.9260426156618, 649077.0246549468, 649077.0246549472, 173354.7613055901], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5774400.0000, 
sim time next is 5775000.0000, 
raw observation next is [25.3, 78.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8781134017565964, 6.911199999999999, 6.9112, 121.9260426156618, 645248.5802993374, 645248.5802993379, 172479.1207343412], 
processed observation next is [0.0, 0.8695652173913043, 0.49259259259259264, 0.7833333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8476417521957454, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23044592153547763, 0.2304459215354778, 0.33169061679681], 
reward next is 0.6683, 
noisyNet noise sample is [array([0.2710022], dtype=float32), 0.8322427]. 
=============================================
[2019-03-24 07:56:11,030] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[66.65679]
 [65.1973 ]
 [65.07016]
 [64.55442]
 [64.48803]], R is [[65.73649597]
 [65.74575806]
 [65.75302124]
 [65.75871277]
 [65.76353455]].
[2019-03-24 07:56:13,427] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:56:13,438] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4381
[2019-03-24 07:56:13,444] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.6, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5846582013413517, 6.911200000000001, 6.9112, 121.9260426156618, 431777.2474732111, 431777.2474732107, 127585.0974123476], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5886000.0000, 
sim time next is 5886600.0000, 
raw observation next is [19.55, 85.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8307023933526975, 6.9112, 6.9112, 121.9260426156618, 613202.2677670219, 613202.2677670219, 152319.1931580804], 
processed observation next is [1.0, 0.13043478260869565, 0.2796296296296297, 0.8500000000000001, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7883779916908717, 0.0, 0.0, 0.8094621288201359, 0.21900080991679355, 0.21900080991679355, 0.2929215253040008], 
reward next is 0.7071, 
noisyNet noise sample is [array([-0.55778754], dtype=float32), -0.2704595]. 
=============================================
[2019-03-24 07:56:20,482] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:56:20,489] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7454
[2019-03-24 07:56:20,492] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.68333333333333, 86.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7752494700025312, 6.911200000000001, 6.9112, 121.9260426156618, 577486.6641014894, 577486.6641014889, 156293.5247110492], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5958600.0000, 
sim time next is 5959200.0000, 
raw observation next is [22.66666666666667, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.76935604075264, 6.9112, 6.9112, 121.9260426156618, 573350.140502261, 573350.140502261, 155389.769727033], 
processed observation next is [1.0, 1.0, 0.39506172839506193, 0.86, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7116950509407999, 0.0, 0.0, 0.8094621288201359, 0.20476790732223607, 0.20476790732223607, 0.29882648024429426], 
reward next is 0.7012, 
noisyNet noise sample is [array([1.3827051], dtype=float32), -0.9051154]. 
=============================================
[2019-03-24 07:56:27,750] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 2.8492253e-29 7.3034093e-32 1.7579779e-28 8.1192271e-29], sum to 1.0000
[2019-03-24 07:56:27,757] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7566
[2019-03-24 07:56:27,763] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1379239.983107928 W.
[2019-03-24 07:56:27,771] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.73333333333333, 55.66666666666667, 1.0, 2.0, 0.6027399619573702, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9597664395085915, 6.911199999999999, 6.9112, 121.9260426156618, 1379239.983107928, 1379239.983107929, 294864.2513684646], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6082800.0000, 
sim time next is 6083400.0000, 
raw observation next is [29.51666666666667, 56.83333333333334, 1.0, 2.0, 0.3887932631140746, 1.0, 1.0, 0.3887932631140746, 1.0, 2.0, 0.6189715369901982, 6.911199999999999, 6.9112, 121.94756008, 1329804.057750879, 1329804.057750879, 292207.768616934], 
processed observation next is [1.0, 0.391304347826087, 0.6487654320987656, 0.5683333333333335, 1.0, 1.0, 0.2723729322786602, 1.0, 0.5, 0.2723729322786602, 1.0, 1.0, 0.5237144212377478, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.474930020625314, 0.474930020625314, 0.5619380165710269], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0068135], dtype=float32), 0.7495319]. 
=============================================
[2019-03-24 07:56:32,539] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 2.1547556e-30 1.9505719e-35 3.7791921e-29 2.4206165e-29], sum to 1.0000
[2019-03-24 07:56:32,546] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0004
[2019-03-24 07:56:32,556] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1554326.273602897 W.
[2019-03-24 07:56:32,561] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.53333333333333, 56.33333333333333, 1.0, 2.0, 0.45437002694912, 1.0, 1.0, 0.45437002694912, 1.0, 2.0, 0.7233718807016887, 6.911199999999999, 6.9112, 121.94756008, 1554326.273602897, 1554326.273602898, 321717.4968090361], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6183600.0000, 
sim time next is 6184200.0000, 
raw observation next is [29.66666666666667, 55.66666666666666, 1.0, 2.0, 0.4553215137194172, 1.0, 2.0, 0.4553215137194172, 1.0, 2.0, 0.7248866786277626, 6.911200000000001, 6.9112, 121.94756008, 1557584.465594453, 1557584.465594452, 322163.175730032], 
processed observation next is [1.0, 0.5652173913043478, 0.6543209876543211, 0.5566666666666665, 1.0, 1.0, 0.35157323061835377, 1.0, 1.0, 0.35157323061835377, 1.0, 1.0, 0.6561083482847032, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5562801662837332, 0.5562801662837329, 0.6195445687115999], 
reward next is 0.3805, 
noisyNet noise sample is [array([0.949483], dtype=float32), -0.5844218]. 
=============================================
[2019-03-24 07:56:39,210] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.6373132e-38 1.7253220e-38], sum to 1.0000
[2019-03-24 07:56:39,214] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1747
[2019-03-24 07:56:39,221] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.46666666666667, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9136168126468145, 6.911200000000001, 6.9112, 121.9260426156618, 667934.2820802875, 667934.282080287, 177902.4512983353], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6329400.0000, 
sim time next is 6330000.0000, 
raw observation next is [24.53333333333333, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9186834124609803, 6.9112, 6.9112, 121.9260426156618, 670954.2810144844, 670954.2810144844, 178714.9240269565], 
processed observation next is [0.0, 0.2608695652173913, 0.46419753086419746, 0.87, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8983542655762252, 0.0, 0.0, 0.8094621288201359, 0.23962652893374442, 0.23962652893374442, 0.34368254620568556], 
reward next is 0.6563, 
noisyNet noise sample is [array([0.5353964], dtype=float32), 1.6583778]. 
=============================================
[2019-03-24 07:56:39,240] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[55.37157 ]
 [55.468582]
 [55.524807]
 [55.600536]
 [55.696644]], R is [[55.36950684]
 [55.47369003]
 [55.57838821]
 [55.68339539]
 [55.78853989]].
[2019-03-24 07:56:41,723] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.3363108e-31 3.1410925e-35 1.7694811e-30 9.3623217e-32], sum to 1.0000
[2019-03-24 07:56:41,728] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9620
[2019-03-24 07:56:41,731] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.76666666666667, 74.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5607275473029907, 6.9112, 6.9112, 121.9260426156618, 407020.2715480354, 407020.2715480354, 122203.1069581928], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6761400.0000, 
sim time next is 6762000.0000, 
raw observation next is [20.03333333333333, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5388658312773006, 6.9112, 6.9112, 121.9260426156618, 391567.6815191884, 391567.6815191884, 120552.8971843553], 
processed observation next is [1.0, 0.2608695652173913, 0.2975308641975308, 0.73, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4235822890966257, 0.0, 0.0, 0.8094621288201359, 0.13984560054256728, 0.13984560054256728, 0.23183249458529864], 
reward next is 0.7682, 
noisyNet noise sample is [array([1.7006373], dtype=float32), 0.13648866]. 
=============================================
[2019-03-24 07:56:41,744] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[45.270794]
 [45.483192]
 [45.57581 ]
 [45.623993]
 [45.833286]], R is [[45.45987701]
 [45.77027512]
 [46.08565903]
 [46.39831543]
 [46.70841599]].
[2019-03-24 07:56:45,896] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 2.4293942e-30 1.3857096e-33 5.9337159e-31 6.3996734e-30], sum to 1.0000
[2019-03-24 07:56:45,901] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2667
[2019-03-24 07:56:45,912] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 744737.7468452697 W.
[2019-03-24 07:56:45,920] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.8, 59.5, 1.0, 2.0, 0.2178211796778655, 1.0, 1.0, 0.2178211796778655, 1.0, 2.0, 0.3467784119877302, 6.9112, 6.9112, 121.94756008, 744737.7468452697, 744737.7468452697, 226504.474183363], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6460200.0000, 
sim time next is 6460800.0000, 
raw observation next is [30.73333333333333, 60.0, 1.0, 2.0, 0.6516829428226155, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 742707.5218081893, 742707.5218081893, 167199.0157902563], 
processed observation next is [1.0, 0.782608695652174, 0.6938271604938271, 0.6, 1.0, 1.0, 0.5853368366935899, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2652526863600676, 0.2652526863600676, 0.32153656882741594], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2972028], dtype=float32), -0.7175176]. 
=============================================
[2019-03-24 07:56:53,497] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 5.1860199e-28 3.2454565e-33 9.8418204e-29 1.9179231e-27], sum to 1.0000
[2019-03-24 07:56:53,505] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8179
[2019-03-24 07:56:53,516] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 856616.8570440803 W.
[2019-03-24 07:56:53,522] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.63333333333334, 45.33333333333334, 1.0, 2.0, 0.2293910853165423, 1.0, 1.0, 0.2293910853165423, 1.0, 2.0, 0.3827481339214947, 6.9112, 6.9112, 121.94756008, 856616.8570440803, 856616.8570440803, 227988.3502465976], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6600000.0000, 
sim time next is 6600600.0000, 
raw observation next is [25.8, 44.5, 1.0, 2.0, 0.228858028680071, 1.0, 2.0, 0.228858028680071, 1.0, 2.0, 0.3811115040957855, 6.9112, 6.9112, 121.94756008, 853342.8319271489, 853342.8319271489, 227913.7439540834], 
processed observation next is [1.0, 0.391304347826087, 0.5111111111111112, 0.445, 1.0, 1.0, 0.08197384366675117, 1.0, 1.0, 0.08197384366675117, 1.0, 1.0, 0.22638938011973184, 0.0, 0.0, 0.8096049824067558, 0.30476529711683886, 0.30476529711683886, 0.43829566145016036], 
reward next is 0.5617, 
noisyNet noise sample is [array([-0.8327225], dtype=float32), -1.0599029]. 
=============================================
[2019-03-24 07:56:54,389] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:56:54,396] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1015
[2019-03-24 07:56:54,399] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.61666666666667, 59.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6484351399457954, 6.911200000000001, 6.9112, 121.9260426156618, 483599.4292004597, 483599.4292004593, 137068.8147830084], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6639000.0000, 
sim time next is 6639600.0000, 
raw observation next is [24.63333333333333, 58.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6444916767958533, 6.911200000000001, 6.9112, 121.9260426156618, 480206.2393641765, 480206.2393641761, 136171.8865760564], 
processed observation next is [1.0, 0.8695652173913043, 0.46790123456790106, 0.5833333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5556145959948166, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17150222834434875, 0.1715022283443486, 0.2618690126462623], 
reward next is 0.7381, 
noisyNet noise sample is [array([-0.20935273], dtype=float32), 0.63943315]. 
=============================================
[2019-03-24 07:56:57,255] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-24 07:56:57,256] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:56:57,257] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:56:57,258] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:56:57,260] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:56:57,260] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:56:57,261] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:56:57,262] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:56:57,264] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:56:57,266] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:56:57,268] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:56:57,287] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run76
[2019-03-24 07:56:57,287] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run76
[2019-03-24 07:56:57,339] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run76
[2019-03-24 07:56:57,364] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run76
[2019-03-24 07:56:57,400] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run76
[2019-03-24 07:57:12,262] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.020794123]
[2019-03-24 07:57:12,264] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [22.16666666666667, 48.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.463640397722994, 6.911200000000001, 6.9112, 121.9260426156618, 331038.1308633107, 331038.1308633103, 104900.1338503111]
[2019-03-24 07:57:12,266] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:57:12,270] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.9141538602639304
[2019-03-24 07:57:16,328] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.020794123]
[2019-03-24 07:57:16,329] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [19.85568854333333, 82.45861065666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.554322426410543, 6.911199999999999, 6.9112, 121.9260426156618, 409040.7853367895, 409040.78533679, 124683.5692211231]
[2019-03-24 07:57:16,331] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:57:16,334] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.6072344207237697
[2019-03-24 07:57:20,766] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.020794123]
[2019-03-24 07:57:20,767] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.40157201333333, 44.59644073333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.588261471431621, 6.911200000000001, 6.9112, 121.9260426156618, 437414.7250952366, 437414.7250952362, 129868.9587532644]
[2019-03-24 07:57:20,769] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:57:20,772] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.9068957173700104
[2019-03-24 07:57:36,306] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.020794123]
[2019-03-24 07:57:36,307] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.58333333333333, 84.83333333333333, 1.0, 2.0, 0.6940364668018307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 811602.884374147, 811602.884374147, 176011.2352288653]
[2019-03-24 07:57:36,308] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 07:57:36,311] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.00000000e+00 1.22702046e-32 4.65428662e-37 6.03440143e-32
 2.39657837e-31], sampled 0.2836704941965491
[2019-03-24 07:57:36,312] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 811602.884374147 W.
[2019-03-24 07:57:36,880] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.020794123]
[2019-03-24 07:57:36,881] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [23.0, 88.0, 1.0, 2.0, 0.8637178229965937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156601, 1032299.124398226, 1032299.124398226, 211768.6136423489]
[2019-03-24 07:57:36,883] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:57:36,886] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 4.3497006e-32 1.9032284e-36 1.9827750e-31 7.6887642e-31], sampled 0.054443371420303976
[2019-03-24 07:57:36,887] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1032299.124398226 W.
[2019-03-24 07:57:39,675] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.020794123]
[2019-03-24 07:57:39,676] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.15810157166667, 94.34442604166668, 1.0, 2.0, 0.7180115009886467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 818340.9520190434, 818340.9520190434, 179585.0774973084]
[2019-03-24 07:57:39,678] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 07:57:39,680] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 2.1626286e-37 0.0000000e+00 1.4711274e-36 6.4691657e-36], sampled 0.610161622776535
[2019-03-24 07:57:39,681] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 818340.9520190434 W.
[2019-03-24 07:58:08,277] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.020794123]
[2019-03-24 07:58:08,279] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.16666666666667, 51.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.851074566947438, 6.9112, 6.9112, 121.9260426156618, 626411.2741716845, 626411.2741716845, 168729.1400931205]
[2019-03-24 07:58:08,280] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 07:58:08,283] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.9774437633562226
[2019-03-24 07:58:09,032] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.020794123]
[2019-03-24 07:58:09,044] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.9, 82.0, 1.0, 2.0, 0.7406873351681603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 844199.5673995045, 844199.5673995045, 183992.3200284565]
[2019-03-24 07:58:09,046] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:58:09,049] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.3188798e-38 0.0000000e+00 9.6025379e-38 4.3717306e-37], sampled 0.5399364996529153
[2019-03-24 07:58:09,049] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 844199.5673995045 W.
[2019-03-24 07:58:25,065] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.020794123]
[2019-03-24 07:58:25,066] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.33333333333333, 87.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9038433646113281, 6.911200000000001, 6.9112, 121.9260426156618, 661804.0313810387, 661804.0313810383, 176389.6844928384]
[2019-03-24 07:58:25,067] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:58:25,071] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.03509038048132562
[2019-03-24 07:58:43,197] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.020794123]
[2019-03-24 07:58:43,199] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [30.5, 36.66666666666667, 1.0, 2.0, 0.6144612430164499, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9580175327906546, 6.911200000000001, 6.9112, 121.9260426156056, 1458801.415238904, 1458801.415238904, 291665.0133642373]
[2019-03-24 07:58:43,200] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 07:58:43,203] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 7.3595916e-33 2.5169751e-37 3.5993217e-32 1.4671577e-31], sampled 0.2644628100046402
[2019-03-24 07:58:43,204] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1458801.415238904 W.
[2019-03-24 07:58:43,937] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 07:58:44,049] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 07:58:44,052] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 07:58:44,115] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 07:58:44,210] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 07:58:45,225] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1875000, evaluation results [1875000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 07:58:45,485] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 2.2704425e-34 0.0000000e+00 7.8018745e-36 1.1981108e-34], sum to 1.0000
[2019-03-24 07:58:45,492] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1375
[2019-03-24 07:58:45,499] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1003273.013983695 W.
[2019-03-24 07:58:45,505] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.7, 29.0, 1.0, 2.0, 0.4000016554980958, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6745873101815096, 6.911199999999999, 6.9112, 121.9260426156618, 1003273.013983695, 1003273.013983695, 219254.9072209468], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6703200.0000, 
sim time next is 6703800.0000, 
raw observation next is [29.75, 28.83333333333334, 1.0, 2.0, 0.424079986629313, 0.0, 2.0, 0.0, 1.0, 2.0, 0.714458865130797, 6.911199999999999, 6.9112, 121.9260426156618, 1063010.555910002, 1063010.555910003, 226752.6091610791], 
processed observation next is [1.0, 0.6086956521739131, 0.6574074074074074, 0.2883333333333334, 1.0, 1.0, 0.3143809364634678, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6430735814134964, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.379646627110715, 0.37964662711071534, 0.4360627099251521], 
reward next is 0.5639, 
noisyNet noise sample is [array([-0.40861538], dtype=float32), -1.4918637]. 
=============================================
[2019-03-24 07:58:46,172] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:58:46,182] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2290
[2019-03-24 07:58:46,187] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.75, 29.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5883472636548951, 6.911199999999999, 6.9112, 121.926042615631, 433249.0684424573, 433249.0684424578, 127253.8832670207], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6715800.0000, 
sim time next is 6716400.0000, 
raw observation next is [29.5, 30.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5906013954075815, 6.911199999999999, 6.9112, 121.9260426156618, 434688.911672484, 434688.9116724845, 127346.008982379], 
processed observation next is [1.0, 0.7391304347826086, 0.6481481481481481, 0.3033333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4882517442594768, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15524603988303, 0.15524603988303018, 0.24489617111995962], 
reward next is 0.7551, 
noisyNet noise sample is [array([-1.2905735], dtype=float32), -0.8043931]. 
=============================================
[2019-03-24 07:58:59,016] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:58:59,026] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1887
[2019-03-24 07:58:59,032] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.55, 71.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.700319640585885, 6.911200000000001, 6.9112, 121.9260426156618, 523319.7025098918, 523319.7025098914, 144497.250212586], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6996600.0000, 
sim time next is 6997200.0000, 
raw observation next is [23.46666666666667, 72.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.699382355304618, 6.9112, 6.9112, 121.9260426156618, 522616.7208791316, 522616.7208791316, 144378.0840742151], 
processed observation next is [0.0, 1.0, 0.42469135802469143, 0.72, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6242279441307724, 0.0, 0.0, 0.8094621288201359, 0.18664882888540413, 0.18664882888540413, 0.27765016168118284], 
reward next is 0.7223, 
noisyNet noise sample is [array([-0.64080936], dtype=float32), -0.88026214]. 
=============================================
[2019-03-24 07:59:00,873] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:59:00,881] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3164
[2019-03-24 07:59:00,889] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.0, 51.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9098942239620676, 6.9112, 6.9112, 121.9260426156618, 663369.4204842262, 663369.4204842262, 177742.9399603261], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6964800.0000, 
sim time next is 6965400.0000, 
raw observation next is [31.0, 51.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9180309607660706, 6.911200000000001, 6.9112, 121.9260426156618, 668204.6193994812, 668204.6193994808, 179024.9872661335], 
processed observation next is [0.0, 0.6086956521739131, 0.7037037037037037, 0.515, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8975387009575883, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23864450692838615, 0.23864450692838599, 0.3442788216656414], 
reward next is 0.6557, 
noisyNet noise sample is [array([0.21240848], dtype=float32), 1.9349346]. 
=============================================
[2019-03-24 07:59:04,095] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:59:04,104] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9538
[2019-03-24 07:59:04,108] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.8, 78.5, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7480852131500759, 6.9112, 6.9112, 121.9260426156618, 557155.646062963, 557155.646062963, 153114.9734572766], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7061400.0000, 
sim time next is 7062000.0000, 
raw observation next is [23.76666666666667, 78.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7546436468181814, 6.911199999999999, 6.9112, 121.9260426156618, 562202.7925462706, 562202.7925462711, 153775.0082073899], 
processed observation next is [1.0, 0.7391304347826086, 0.43580246913580256, 0.7866666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6933045585227268, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2007867116236681, 0.20078671162366826, 0.295721169629596], 
reward next is 0.7043, 
noisyNet noise sample is [array([-1.410422], dtype=float32), 0.02089339]. 
=============================================
[2019-03-24 07:59:04,121] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[70.751045]
 [69.40994 ]
 [70.17812 ]
 [69.89207 ]
 [69.00354 ]], R is [[70.61160278]
 [70.61103821]
 [69.90493011]
 [69.85644531]
 [69.6489563 ]].
[2019-03-24 07:59:08,780] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 2.0442265e-37 0.0000000e+00 6.0308916e-36 2.1093124e-35], sum to 1.0000
[2019-03-24 07:59:08,786] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5331
[2019-03-24 07:59:08,791] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 827468.4568320606 W.
[2019-03-24 07:59:08,799] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.88333333333334, 78.33333333333333, 1.0, 2.0, 0.3363108973679345, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5535371024461493, 6.911199999999999, 6.9112, 121.9260426156618, 827468.4568320606, 827468.456832061, 202384.6521225683], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7120200.0000, 
sim time next is 7120800.0000, 
raw observation next is [22.0, 78.0, 1.0, 2.0, 0.3527895407215129, 1.0, 1.0, 0.3527895407215129, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 863330.2160413918, 863330.2160413923, 195967.491622612], 
processed observation next is [1.0, 0.43478260869565216, 0.37037037037037035, 0.78, 1.0, 1.0, 0.22951135800180109, 1.0, 0.5, 0.22951135800180109, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3083322200147828, 0.30833222001478294, 0.37686056081271535], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7499668], dtype=float32), 0.66638684]. 
=============================================
[2019-03-24 07:59:14,326] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:59:14,335] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0315
[2019-03-24 07:59:14,341] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 928657.3525628962 W.
[2019-03-24 07:59:14,343] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.85, 70.0, 1.0, 2.0, 0.7594030090338105, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.926042615658, 928657.3525628962, 928657.3525628957, 190387.9195137154], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7230600.0000, 
sim time next is 7231200.0000, 
raw observation next is [23.83333333333334, 70.0, 1.0, 2.0, 0.2264035672908185, 1.0, 1.0, 0.2264035672908185, 1.0, 1.0, 0.3665585222953341, 6.9112, 6.9112, 121.94756008, 818738.4722916876, 818738.4722916876, 228645.8654861974], 
processed observation next is [1.0, 0.6956521739130435, 0.43827160493827183, 0.7, 1.0, 1.0, 0.07905186582240298, 1.0, 0.5, 0.07905186582240298, 1.0, 0.5, 0.2081981528691676, 0.0, 0.0, 0.8096049824067558, 0.2924065972470313, 0.2924065972470313, 0.43970358747345656], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.14057797], dtype=float32), -0.42093349]. 
=============================================
[2019-03-24 07:59:14,958] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:59:14,965] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0372
[2019-03-24 07:59:14,973] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.33333333333334, 75.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6562472037556308, 6.9112, 6.9112, 121.9260426156618, 489786.027984399, 489786.027984399, 138342.9944397447], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7244400.0000, 
sim time next is 7245000.0000, 
raw observation next is [22.25, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6514441320695387, 6.911200000000001, 6.9112, 121.9260426156618, 486138.9148172616, 486138.9148172612, 137760.2533920689], 
processed observation next is [1.0, 0.8695652173913043, 0.37962962962962965, 0.76, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5643051650869233, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17362104100616488, 0.1736210410061647, 0.2649235642155171], 
reward next is 0.7351, 
noisyNet noise sample is [array([0.16428526], dtype=float32), 0.64603716]. 
=============================================
[2019-03-24 07:59:14,990] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[82.735794]
 [82.65001 ]
 [82.60017 ]
 [82.67218 ]
 [82.720085]], R is [[82.51956177]
 [82.42832184]
 [82.33667755]
 [82.24475098]
 [82.15298462]].
[2019-03-24 07:59:21,774] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:59:21,781] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1476
[2019-03-24 07:59:21,786] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.1, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5683369026859553, 6.911199999999999, 6.9112, 121.9260426156618, 419229.2225528349, 419229.2225528354, 125842.239810071], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7781400.0000, 
sim time next is 7782000.0000, 
raw observation next is [21.06666666666667, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.567293783225404, 6.9112, 6.9112, 121.9260426156618, 418304.4996521823, 418304.4996521823, 125666.2664981256], 
processed observation next is [1.0, 0.043478260869565216, 0.3358024691358026, 0.73, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.459117229031755, 0.0, 0.0, 0.8094621288201359, 0.14939446416149366, 0.14939446416149366, 0.24166589711178], 
reward next is 0.7583, 
noisyNet noise sample is [array([-1.4747416], dtype=float32), 1.0346818]. 
=============================================
[2019-03-24 07:59:21,799] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[68.53374 ]
 [68.626945]
 [68.88775 ]
 [69.34226 ]
 [69.570946]], R is [[68.57254791]
 [68.64482117]
 [68.7159729 ]
 [68.78585052]
 [68.85439301]].
[2019-03-24 07:59:22,426] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:59:22,432] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1299
[2019-03-24 07:59:22,440] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.2, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7119776658465957, 6.9112, 6.9112, 121.9260426156618, 531705.8446513924, 531705.8446513924, 147413.8606593129], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7466400.0000, 
sim time next is 7467000.0000, 
raw observation next is [22.36666666666667, 85.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7166410666458637, 6.911199999999999, 6.9112, 121.9260426156618, 535067.9468030124, 535067.9468030129, 148137.7681167486], 
processed observation next is [0.0, 0.43478260869565216, 0.38395061728395075, 0.8533333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6458013333073295, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19109569528679013, 0.1910956952867903, 0.28488032330143964], 
reward next is 0.7151, 
noisyNet noise sample is [array([-0.20979139], dtype=float32), -2.3939211]. 
=============================================
[2019-03-24 07:59:22,460] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[64.36378]
 [64.35876]
 [64.3988 ]
 [64.44675]
 [64.48064]], R is [[64.40882874]
 [64.48125458]
 [64.55516052]
 [64.63056183]
 [64.70674896]].
[2019-03-24 07:59:32,376] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 07:59:32,376] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:59:32,439] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run10
[2019-03-24 07:59:32,719] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 07:59:32,724] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8618
[2019-03-24 07:59:32,727] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.8, 72.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.826968981823254, 6.9112, 6.9112, 121.9260426156618, 611275.6934671998, 611275.6934671998, 164905.9564594883], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7583400.0000, 
sim time next is 7584000.0000, 
raw observation next is [25.63333333333333, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8265637950984941, 6.911199999999999, 6.9112, 121.9260426156618, 611009.6162898673, 611009.6162898678, 164844.2744955154], 
processed observation next is [0.0, 0.782608695652174, 0.5049382716049381, 0.73, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7832047438731177, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21821772010352405, 0.21821772010352422, 0.31700822018368346], 
reward next is 0.6830, 
noisyNet noise sample is [array([-2.6972153], dtype=float32), 2.2137928]. 
=============================================
[2019-03-24 07:59:32,740] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[71.96847 ]
 [71.97327 ]
 [71.96346 ]
 [71.955894]
 [71.88189 ]], R is [[71.91370392]
 [71.87744141]
 [71.84152222]
 [71.80601501]
 [71.77093506]].
[2019-03-24 07:59:34,093] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-24 07:59:34,095] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 07:59:34,098] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:59:34,100] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 07:59:34,101] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:59:34,102] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 07:59:34,103] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 07:59:34,103] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:59:34,104] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 07:59:34,105] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:59:34,108] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 07:59:34,125] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run77
[2019-03-24 07:59:34,152] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run77
[2019-03-24 07:59:34,177] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run77
[2019-03-24 07:59:34,200] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run77
[2019-03-24 07:59:34,201] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run77
[2019-03-24 08:00:00,151] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.02164617]
[2019-03-24 08:00:00,153] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [20.9, 87.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6427058729279539, 6.911200000000001, 6.9112, 121.9260426156618, 479801.144809882, 479801.1448098816, 137154.0674341512]
[2019-03-24 08:00:00,154] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:00:00,157] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.35172080022724606
[2019-03-24 08:00:09,759] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.02164617]
[2019-03-24 08:00:09,762] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.71666666666667, 39.83333333333333, 1.0, 2.0, 0.5653371207279306, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9179031796287509, 6.911200000000001, 6.9112, 121.9260426156393, 1369260.43089452, 1369260.430894519, 278228.0021495185]
[2019-03-24 08:00:09,763] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:00:09,768] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.30521977156926383
[2019-03-24 08:00:09,769] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1369260.43089452 W.
[2019-03-24 08:00:20,676] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.02164617]
[2019-03-24 08:00:20,678] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [29.0, 72.66666666666667, 1.0, 2.0, 0.6938222333815363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 790757.4392790014, 790757.4392790014, 174979.2189977539]
[2019-03-24 08:00:20,679] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:00:20,682] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.15584900024484283
[2019-03-24 08:00:20,682] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 790757.4392790014 W.
[2019-03-24 08:00:40,881] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.02164617]
[2019-03-24 08:00:40,882] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.70725326, 88.16547814, 1.0, 2.0, 0.8162041299122085, 1.0, 1.0, 0.8162041299122085, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9258614552014, 1861726.502975129, 1861726.502975129, 350497.0817972129]
[2019-03-24 08:00:40,884] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:00:40,887] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.29493575541002715
[2019-03-24 08:00:40,888] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1861726.502975129 W.
[2019-03-24 08:01:10,997] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.02164617]
[2019-03-24 08:01:10,999] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.91666666666667, 84.0, 1.0, 2.0, 0.6606900102900405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 752977.7038015592, 752977.7038015587, 168837.1324138328]
[2019-03-24 08:01:11,000] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:01:11,002] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.8063011622198426
[2019-03-24 08:01:11,003] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 752977.7038015592 W.
[2019-03-24 08:01:17,323] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.02164617]
[2019-03-24 08:01:17,323] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [19.85, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6462758006399626, 6.9112, 6.9112, 121.9260426156618, 481238.3611880452, 481238.3611880452, 136062.4459859309]
[2019-03-24 08:01:17,324] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:01:17,326] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.48016377794487675
[2019-03-24 08:01:18,873] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.02164617]
[2019-03-24 08:01:18,875] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.13829735, 58.06318643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.565119093177155, 6.9112, 6.9112, 121.9260426156618, 415557.1892911217, 415557.1892911217, 124887.9432484242]
[2019-03-24 08:01:18,875] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:01:18,878] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.8556796664702158
[2019-03-24 08:01:20,953] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 08:01:21,027] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 08:01:21,159] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 08:01:21,203] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 08:01:21,227] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 08:01:22,242] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1900000, evaluation results [1900000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 08:01:22,338] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:01:22,348] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5796
[2019-03-24 08:01:22,358] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.73333333333333, 87.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7807761718123482, 6.911200000000001, 6.9112, 121.9260426156618, 580955.5179806432, 580955.5179806427, 157394.3047690548], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7602000.0000, 
sim time next is 7602600.0000, 
raw observation next is [22.61666666666667, 87.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7724491888093227, 6.9112, 6.9112, 121.9260426156618, 575262.859258572, 575262.859258572, 156053.820487755], 
processed observation next is [0.0, 1.0, 0.39320987654321005, 0.8716666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7155614860116533, 0.0, 0.0, 0.8094621288201359, 0.2054510211637757, 0.2054510211637757, 0.3001035009379904], 
reward next is 0.6999, 
noisyNet noise sample is [array([0.59278893], dtype=float32), 0.08751607]. 
=============================================
[2019-03-24 08:01:24,186] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 7.5659815e-31 1.4383947e-33 3.5361232e-30 2.1587563e-28], sum to 1.0000
[2019-03-24 08:01:24,193] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5738
[2019-03-24 08:01:24,199] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1138296.798387839 W.
[2019-03-24 08:01:24,208] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.73333333333333, 82.66666666666667, 1.0, 2.0, 0.3259816840743348, 1.0, 1.0, 0.3259816840743348, 1.0, 2.0, 0.5203228177575308, 6.911199999999999, 6.9112, 121.94756008, 1138296.798387839, 1138296.798387839, 266193.0567681786], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7638600.0000, 
sim time next is 7639200.0000, 
raw observation next is [24.0, 82.0, 1.0, 2.0, 0.4962589673835175, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7935755471975686, 6.911199999999999, 6.9112, 121.9260426156618, 1163866.292552409, 1163866.292552409, 254999.0559253121], 
processed observation next is [1.0, 0.43478260869565216, 0.4444444444444444, 0.82, 1.0, 1.0, 0.4003082945041875, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.7419694339969607, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4156665330544318, 0.4156665330544318, 0.49038279985636946], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.23204665], dtype=float32), -0.71971226]. 
=============================================
[2019-03-24 08:01:24,556] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:01:24,556] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:01:24,591] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run10
[2019-03-24 08:01:28,392] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:01:28,398] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1346
[2019-03-24 08:01:28,406] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1502326.082135248 W.
[2019-03-24 08:01:28,411] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.0, 52.0, 1.0, 2.0, 0.6452858450058774, 1.0, 2.0, 0.6452858450058774, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1502326.082135248, 1502326.082135247, 285462.5924085376], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7750800.0000, 
sim time next is 7751400.0000, 
raw observation next is [28.71666666666667, 52.83333333333334, 1.0, 2.0, 0.3213018297624496, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5149150599065674, 6.911199999999999, 6.9112, 121.9260426156618, 758464.3510070795, 758464.3510070799, 200319.4999407924], 
processed observation next is [1.0, 0.7391304347826086, 0.6191358024691359, 0.5283333333333334, 1.0, 1.0, 0.19202598781243999, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.3936438248832092, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27088012535967126, 0.27088012535967143, 0.3852298075784469], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.38614407], dtype=float32), 1.4485497]. 
=============================================
[2019-03-24 08:01:31,866] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 7.210075e-37 3.212744e-38], sum to 1.0000
[2019-03-24 08:01:31,875] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1603
[2019-03-24 08:01:31,881] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 887115.0725852186 W.
[2019-03-24 08:01:31,884] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.13333333333333, 46.0, 1.0, 2.0, 0.3564450089440324, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5944888751493869, 6.911200000000001, 6.9112, 121.9260425814532, 887115.0725852186, 887115.0725852181, 207157.310080429], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7807200.0000, 
sim time next is 7807800.0000, 
raw observation next is [26.31666666666667, 45.5, 1.0, 2.0, 0.2441854677005103, 1.0, 1.0, 0.2441854677005103, 1.0, 2.0, 0.4035745546704652, 6.9112, 6.9112, 121.94756008, 904774.200977453, 904774.200977453, 233651.1657761729], 
processed observation next is [1.0, 0.34782608695652173, 0.530246913580247, 0.455, 1.0, 1.0, 0.10022079488155988, 1.0, 0.5, 0.10022079488155988, 1.0, 1.0, 0.25446819333808146, 0.0, 0.0, 0.8096049824067558, 0.3231336432062332, 0.3231336432062332, 0.44932916495417863], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.99862874], dtype=float32), -0.41279376]. 
=============================================
[2019-03-24 08:01:32,462] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 5.0770035e-38 0.0000000e+00 1.2230924e-36 6.0747215e-34], sum to 1.0000
[2019-03-24 08:01:32,468] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8379
[2019-03-24 08:01:32,473] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.4, 48.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7349333029322266, 6.9112, 6.9112, 121.9260426156618, 542343.472204287, 542343.472204287, 141960.7087233702], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7804800.0000, 
sim time next is 7805400.0000, 
raw observation next is [25.58333333333334, 47.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6918313004119458, 6.911200000000001, 6.9112, 121.9260426156618, 510828.2224026649, 510828.2224026644, 137749.1973044003], 
processed observation next is [1.0, 0.34782608695652173, 0.5030864197530867, 0.475, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6147891255149323, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1824386508580946, 0.18243865085809444, 0.2649023025084621], 
reward next is 0.7351, 
noisyNet noise sample is [array([0.22677484], dtype=float32), -0.24410976]. 
=============================================
[2019-03-24 08:01:35,670] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.6316651e-38], sum to 1.0000
[2019-03-24 08:01:35,678] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0060
[2019-03-24 08:01:35,682] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.46666666666667, 78.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6879668279910288, 6.911200000000001, 6.9112, 121.9260426156618, 514069.6578362684, 514069.6578362679, 143052.412657456], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7868400.0000, 
sim time next is 7869000.0000, 
raw observation next is [22.38333333333334, 79.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6867854574953617, 6.911200000000001, 6.9112, 121.9260426156618, 513190.7817546593, 513190.7817546589, 142949.5111601084], 
processed observation next is [1.0, 0.043478260869565216, 0.38456790123456813, 0.7933333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6084818218692021, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18328242205523546, 0.18328242205523532, 0.2749029060771315], 
reward next is 0.7251, 
noisyNet noise sample is [array([-0.08995017], dtype=float32), 0.5175282]. 
=============================================
[2019-03-24 08:01:35,704] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[59.62304 ]
 [59.660675]
 [59.657883]
 [59.862785]
 [60.104073]], R is [[59.51382065]
 [59.64358139]
 [59.77174759]
 [59.89869308]
 [60.02507019]].
[2019-03-24 08:01:35,827] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:01:35,832] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3225
[2019-03-24 08:01:35,835] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.23333333333333, 71.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7315108566211238, 6.911200000000001, 6.9112, 121.9260426156618, 546313.8712149034, 546313.871214903, 149602.1006845452], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7944600.0000, 
sim time next is 7945200.0000, 
raw observation next is [24.1, 72.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.729219853231598, 6.9112, 6.9112, 121.9260426156618, 544639.5900082911, 544639.5900082911, 149270.8281654638], 
processed observation next is [1.0, 1.0, 0.4481481481481482, 0.72, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6615248165394974, 0.0, 0.0, 0.8094621288201359, 0.1945141392886754, 0.1945141392886754, 0.28705928493358424], 
reward next is 0.7129, 
noisyNet noise sample is [array([-0.6729099], dtype=float32), -0.52371687]. 
=============================================
[2019-03-24 08:01:37,044] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:01:37,045] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:01:37,078] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run10
[2019-03-24 08:01:37,569] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:01:37,570] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:01:37,573] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run10
[2019-03-24 08:01:37,845] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.2962746e-38 4.2958829e-37], sum to 1.0000
[2019-03-24 08:01:37,846] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2432
[2019-03-24 08:01:37,847] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1126839.422218722 W.
[2019-03-24 08:01:37,853] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.2, 49.0, 1.0, 2.0, 0.4761418328316764, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7637092820322275, 6.9112, 6.9112, 121.9260426156618, 1126839.422218722, 1126839.422218722, 247774.733952975], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7909200.0000, 
sim time next is 7909800.0000, 
raw observation next is [29.35, 48.5, 1.0, 2.0, 0.466921293752404, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7497408244516806, 6.9112, 6.9112, 121.9260426156618, 1108046.518369471, 1108046.518369471, 244561.1694469795], 
processed observation next is [1.0, 0.5652173913043478, 0.6425925925925926, 0.485, 1.0, 1.0, 0.3653824925623857, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6871760305646007, 0.0, 0.0, 0.8094621288201359, 0.3957308994176682, 0.3957308994176682, 0.47030994124419134], 
reward next is 0.5297, 
noisyNet noise sample is [array([0.48708776], dtype=float32), 0.15515606]. 
=============================================
[2019-03-24 08:01:38,859] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:01:38,859] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:01:38,887] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run10
[2019-03-24 08:01:39,287] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:01:39,288] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:01:39,319] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run10
[2019-03-24 08:01:39,723] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:01:39,724] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:01:39,731] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run10
[2019-03-24 08:01:39,753] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:01:39,756] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:01:39,761] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run10
[2019-03-24 08:01:39,853] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:01:39,853] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:01:39,866] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:01:39,867] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2388
[2019-03-24 08:01:39,869] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.4, 40.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6289956960798416, 6.9112, 6.9112, 121.9260426156618, 469884.1350781145, 469884.1350781145, 136443.1857063039], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 63000.0000, 
sim time next is 63600.0000, 
raw observation next is [29.3, 41.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6385632292750021, 6.911200000000001, 6.9112, 121.9260426156618, 477036.4859898915, 477036.4859898911, 137429.2654149026], 
processed observation next is [1.0, 0.7391304347826086, 0.6407407407407407, 0.41, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5482040365937526, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1703701735678184, 0.17037017356781825, 0.2642870488748127], 
reward next is 0.7357, 
noisyNet noise sample is [array([2.559296], dtype=float32), 0.90361893]. 
=============================================
[2019-03-24 08:01:39,873] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run10
[2019-03-24 08:01:39,911] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:01:39,911] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:01:39,924] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run10
[2019-03-24 08:01:40,055] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:01:40,055] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:01:40,060] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run10
[2019-03-24 08:01:40,084] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:01:40,084] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:01:40,106] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run10
[2019-03-24 08:01:40,149] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:01:40,149] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:01:40,156] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run10
[2019-03-24 08:01:40,197] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:01:40,198] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:01:40,199] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:01:40,199] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:01:40,214] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run10
[2019-03-24 08:01:40,311] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run10
[2019-03-24 08:01:41,008] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:01:41,008] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:01:41,030] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run10
[2019-03-24 08:01:45,164] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:01:45,182] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3948
[2019-03-24 08:01:45,189] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [32.06666666666667, 14.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6538121158586255, 6.911200000000001, 6.9112, 121.9260426156618, 466861.6118118829, 466861.6118118825, 123309.2310285859], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 159600.0000, 
sim time next is 160200.0000, 
raw observation next is [32.0, 14.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.654455738294368, 6.9112, 6.9112, 121.9260426156618, 467321.3374159851, 467321.3374159851, 122675.5862768982], 
processed observation next is [1.0, 0.8695652173913043, 0.7407407407407407, 0.145, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.56806967286796, 0.0, 0.0, 0.8094621288201359, 0.1669004776485661, 0.1669004776485661, 0.235914588994035], 
reward next is 0.7641, 
noisyNet noise sample is [array([-0.84911555], dtype=float32), -0.8872021]. 
=============================================
[2019-03-24 08:01:52,462] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:01:52,468] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5463
[2019-03-24 08:01:52,471] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [32.83333333333334, 17.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6677159088924326, 6.911199999999999, 6.9112, 121.9260426156618, 483279.1046831366, 483279.104683137, 131098.6742327297], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 236400.0000, 
sim time next is 237000.0000, 
raw observation next is [32.61666666666667, 17.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6644262386868459, 6.911200000000001, 6.9112, 121.9260426156618, 480939.3448777338, 480939.3448777334, 130813.1601644613], 
processed observation next is [0.0, 0.7391304347826086, 0.7635802469135803, 0.175, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5805327983585573, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17176405174204779, 0.17176405174204765, 0.25156376954704096], 
reward next is 0.7484, 
noisyNet noise sample is [array([0.7693411], dtype=float32), 1.4475887]. 
=============================================
[2019-03-24 08:01:52,495] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[79.08542 ]
 [79.05072 ]
 [79.03361 ]
 [79.0995  ]
 [79.084404]], R is [[79.05354309]
 [79.01089478]
 [78.96810913]
 [78.92512512]
 [78.88153839]].
[2019-03-24 08:01:58,778] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.3793089e-38 0.0000000e+00 2.6035890e-36 2.3863116e-34], sum to 1.0000
[2019-03-24 08:01:58,787] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2666
[2019-03-24 08:01:58,792] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.63333333333333, 58.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5541328076994242, 6.9112, 6.9112, 121.9260426156618, 395666.1614399616, 395666.1614399616, 107716.0004968426], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 357000.0000, 
sim time next is 357600.0000, 
raw observation next is [19.46666666666667, 59.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5064371481505863, 6.9112, 6.9112, 121.9260426156618, 361602.111550251, 361602.111550251, 103222.7354829817], 
processed observation next is [1.0, 0.13043478260869565, 0.2765432098765433, 0.5966666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3830464351882328, 0.0, 0.0, 0.8094621288201359, 0.1291436112679468, 0.1291436112679468, 0.1985052605441956], 
reward next is 0.8015, 
noisyNet noise sample is [array([1.150516], dtype=float32), 0.2811226]. 
=============================================
[2019-03-24 08:02:06,381] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.6474737e-38], sum to 1.0000
[2019-03-24 08:02:06,384] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1433
[2019-03-24 08:02:06,389] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1291747.162840839 W.
[2019-03-24 08:02:06,394] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.16666666666667, 26.33333333333334, 1.0, 2.0, 0.3551274613706123, 1.0, 2.0, 0.3551274613706123, 1.0, 2.0, 0.5771121885265685, 6.911200000000001, 6.9112, 121.94756008, 1291747.162840839, 1291747.162840839, 277104.9276785161], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 485400.0000, 
sim time next is 486000.0000, 
raw observation next is [32.2, 26.0, 1.0, 2.0, 0.5553149056946552, 0.0, 1.0, 0.0, 1.0, 2.0, 0.913058412364046, 6.911199999999999, 6.9112, 121.9260426156618, 1365388.397079778, 1365388.397079779, 273341.0415093941], 
processed observation next is [1.0, 0.6521739130434783, 0.7481481481481482, 0.26, 1.0, 1.0, 0.4706129829698277, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.8913230154550574, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4876387132427778, 0.48763871324277824, 0.5256558490565272], 
reward next is 0.4743, 
noisyNet noise sample is [array([-0.27421474], dtype=float32), 0.050306674]. 
=============================================
[2019-03-24 08:02:06,411] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[68.13857 ]
 [67.74887 ]
 [66.90115 ]
 [66.525406]
 [66.409676]], R is [[67.9394455 ]
 [67.72715759]
 [67.51596069]
 [66.84080505]
 [66.68599701]].
[2019-03-24 08:02:07,623] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:02:07,629] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9986
[2019-03-24 08:02:07,635] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.8, 32.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5979703050552672, 6.911200000000001, 6.9112, 121.9260426156618, 442907.6813709493, 442907.6813709488, 129568.6681523227], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 500400.0000, 
sim time next is 501000.0000, 
raw observation next is [29.56666666666667, 33.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.594177732068266, 6.9112, 6.9112, 121.9260426156618, 440273.863345944, 440273.863345944, 129327.5453342329], 
processed observation next is [1.0, 0.8260869565217391, 0.6506172839506174, 0.33, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4927221650853324, 0.0, 0.0, 0.8094621288201359, 0.15724066548069426, 0.15724066548069426, 0.24870681795044788], 
reward next is 0.7513, 
noisyNet noise sample is [array([-0.36794904], dtype=float32), -0.5680655]. 
=============================================
[2019-03-24 08:02:07,661] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[72.93709]
 [73.07112]
 [73.10678]
 [73.36794]
 [72.77313]], R is [[72.51275635]
 [72.53845978]
 [72.56343079]
 [72.58760834]
 [72.61067963]].
[2019-03-24 08:02:12,028] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-24 08:02:12,031] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:02:12,032] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:02:12,033] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:02:12,035] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:02:12,037] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:02:12,039] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:02:12,041] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:02:12,042] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:02:12,040] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:02:12,045] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:02:12,058] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run78
[2019-03-24 08:02:12,088] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run78
[2019-03-24 08:02:12,114] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run78
[2019-03-24 08:02:12,114] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run78
[2019-03-24 08:02:12,115] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run78
[2019-03-24 08:02:30,985] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022445988]
[2019-03-24 08:02:30,987] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.66666666666667, 52.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6177642666545268, 6.911200000000001, 6.9112, 121.9260426156618, 451912.0672069283, 451912.0672069278, 128537.3229682687]
[2019-03-24 08:02:30,988] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:02:30,991] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.43010993030786016
[2019-03-24 08:02:33,943] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022445988]
[2019-03-24 08:02:33,944] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [32.2, 44.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9084922395419636, 6.911200000000001, 6.9112, 121.9260426156618, 665300.2775014894, 665300.2775014889, 176990.5974116302]
[2019-03-24 08:02:33,945] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:02:33,948] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.4243382624442755
[2019-03-24 08:03:02,636] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022445988]
[2019-03-24 08:03:02,637] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.0, 79.0, 1.0, 2.0, 0.9363578825978979, 1.0, 2.0, 0.9363578825978979, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 122.792994394682, 2136101.781781314, 2136101.781781315, 403450.9170885655]
[2019-03-24 08:03:02,638] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:03:02,641] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.8880865952832596
[2019-03-24 08:03:02,642] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2136101.781781314 W.
[2019-03-24 08:03:08,461] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022445988]
[2019-03-24 08:03:08,463] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.33333333333334, 87.33333333333334, 1.0, 2.0, 0.9038220199681121, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426156606, 1745447.379297141, 1745447.379297141, 357793.4926194381]
[2019-03-24 08:03:08,467] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:03:08,472] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.9129917765889531
[2019-03-24 08:03:08,473] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1745447.379297141 W.
[2019-03-24 08:03:14,691] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022445988]
[2019-03-24 08:03:14,692] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.869204573763351, 6.9112, 6.9112, 121.9260426156618, 637090.9299022375, 637090.9299022375, 171692.5960602272]
[2019-03-24 08:03:14,694] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:03:14,699] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.17689101703064103
[2019-03-24 08:03:19,244] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022445988]
[2019-03-24 08:03:19,248] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.93333333333333, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6823011761957768, 6.9112, 6.9112, 121.9260426156618, 509825.7466227241, 509825.7466227241, 142394.6961192688]
[2019-03-24 08:03:19,250] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:03:19,252] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.03938789805981735
[2019-03-24 08:03:38,799] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022445988]
[2019-03-24 08:03:38,800] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.04399648, 94.84400523, 1.0, 2.0, 0.6007469928923922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 690637.9854806704, 690637.9854806699, 158500.4316774926]
[2019-03-24 08:03:38,801] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:03:38,805] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.5002671e-38 0.0000000e+00 1.1568124e-37 6.5203234e-37], sampled 0.6309634446835896
[2019-03-24 08:03:38,806] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 690637.9854806704 W.
[2019-03-24 08:03:49,172] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022445988]
[2019-03-24 08:03:49,173] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.69285708, 94.52132774, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6940244424732654, 6.911200000000001, 6.9112, 121.9260426156618, 518590.2188267647, 518590.2188267643, 143666.9494890802]
[2019-03-24 08:03:49,173] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:03:49,177] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.3230147104957771
[2019-03-24 08:03:58,482] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 08:03:58,543] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 08:03:58,592] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 08:03:58,603] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 08:03:58,712] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 08:03:59,728] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1925000, evaluation results [1925000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 08:04:00,798] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.000000e+00 7.699550e-35 0.000000e+00 7.996437e-35 8.975489e-35], sum to 1.0000
[2019-03-24 08:04:00,804] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2679
[2019-03-24 08:04:00,809] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.26666666666667, 64.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6892681022983678, 6.911199999999999, 6.9112, 121.9260426156618, 507108.7213487814, 507108.7213487819, 136546.0470314593], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 627000.0000, 
sim time next is 627600.0000, 
raw observation next is [22.53333333333333, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6642490396843553, 6.911200000000001, 6.9112, 121.9260426156618, 489310.0803654932, 489310.0803654927, 134419.7497230876], 
processed observation next is [1.0, 0.2608695652173913, 0.3901234567901234, 0.63, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5803112996054441, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1747536001305333, 0.1747536001305331, 0.2584995186982454], 
reward next is 0.7415, 
noisyNet noise sample is [array([-0.93884027], dtype=float32), 0.38395816]. 
=============================================
[2019-03-24 08:04:07,851] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 8.6997317e-37 0.0000000e+00 1.1603708e-36 9.2499818e-36], sum to 1.0000
[2019-03-24 08:04:07,865] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5320
[2019-03-24 08:04:07,866] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1281046.629453575 W.
[2019-03-24 08:04:07,869] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.96666666666667, 24.0, 1.0, 2.0, 0.3476353284111749, 1.0, 2.0, 0.3476353284111749, 1.0, 1.0, 0.5711452861626479, 6.9112, 6.9112, 121.94756008, 1281046.629453575, 1281046.629453575, 273369.8507203722], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 750000.0000, 
sim time next is 750600.0000, 
raw observation next is [31.95, 24.0, 1.0, 2.0, 0.9593782742980228, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.479816424352816, 6.9112, 121.9236696139071, 1493425.414555536, 1202248.650104234, 235546.6047362252], 
processed observation next is [1.0, 0.6956521739130435, 0.7388888888888888, 0.24, 1.0, 1.0, 0.9516408027357415, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.05686164243528156, 0.0, 0.8094463745562326, 0.53336621948412, 0.42937451789436926, 0.4529742398773562], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6502587], dtype=float32), -1.1644427]. 
=============================================
[2019-03-24 08:04:08,137] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 3.3216598e-33 0.0000000e+00 5.7620593e-34 7.7233851e-33], sum to 1.0000
[2019-03-24 08:04:08,147] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2941
[2019-03-24 08:04:08,155] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 950389.7496128851 W.
[2019-03-24 08:04:08,157] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.33333333333334, 45.66666666666667, 1.0, 2.0, 0.7604966016988194, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 950389.7496128851, 950389.7496128847, 191137.0092331667], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1097400.0000, 
sim time next is 1098000.0000, 
raw observation next is [26.3, 46.0, 1.0, 2.0, 0.426336590855785, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7105834196400136, 6.9112, 6.9112, 121.9260426156618, 1060642.022274209, 1060642.022274209, 228233.0750717758], 
processed observation next is [1.0, 0.7391304347826086, 0.5296296296296297, 0.46, 1.0, 1.0, 0.3170673700664107, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.638229274550017, 0.0, 0.0, 0.8094621288201359, 0.3788007222407889, 0.3788007222407889, 0.438909759753415], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6332447], dtype=float32), -1.9808044]. 
=============================================
[2019-03-24 08:04:08,168] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[56.555485]
 [56.496967]
 [56.031506]
 [56.13931 ]
 [55.991154]], R is [[56.53478241]
 [55.96943665]
 [55.94591141]
 [55.95987701]
 [55.40028   ]].
[2019-03-24 08:04:09,839] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0570008e-37], sum to 1.0000
[2019-03-24 08:04:09,841] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:04:09,846] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9458
[2019-03-24 08:04:09,847] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3859
[2019-03-24 08:04:09,851] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.26666666666667, 93.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5585723268338015, 6.9112, 6.9112, 121.9260426156618, 410992.4739848207, 410992.4739848207, 124439.289871485], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1213800.0000, 
sim time next is 1214400.0000, 
raw observation next is [18.23333333333333, 93.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5575881634475158, 6.911200000000001, 6.9112, 121.9260426156618, 409989.282904302, 409989.2829043016, 124214.5859997004], 
processed observation next is [1.0, 0.043478260869565216, 0.2308641975308641, 0.9366666666666668, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.44698520430939476, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14642474389439358, 0.14642474389439342, 0.2388742038455777], 
reward next is 0.7611, 
noisyNet noise sample is [array([-1.0667316], dtype=float32), 1.6854973]. 
=============================================
[2019-03-24 08:04:09,857] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.1, 44.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5210345282377382, 6.9112, 6.9112, 121.9260426156618, 380038.7653004113, 380038.7653004113, 119682.2351564024], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 780000.0000, 
sim time next is 780600.0000, 
raw observation next is [24.95, 45.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5225166044957859, 6.911199999999999, 6.9112, 121.9260426156618, 381081.9299182885, 381081.929918289, 119787.7316230924], 
processed observation next is [0.0, 0.0, 0.47962962962962963, 0.4533333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.40314575561973226, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1361006892565316, 0.1361006892565318, 0.23036102235210076], 
reward next is 0.7696, 
noisyNet noise sample is [array([-0.3634009], dtype=float32), 0.19504917]. 
=============================================
[2019-03-24 08:04:13,004] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:04:13,012] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1304
[2019-03-24 08:04:13,018] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.6, 36.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7211583113568125, 6.9112, 6.9112, 121.9260426156618, 538442.299008973, 538442.299008973, 148649.5621115445], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 837600.0000, 
sim time next is 838200.0000, 
raw observation next is [31.5, 36.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7190120323128096, 6.9112, 6.9112, 121.9260426156618, 536902.7485832652, 536902.7485832652, 148306.3532651199], 
processed observation next is [0.0, 0.6956521739130435, 0.7222222222222222, 0.3683333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6487650403910119, 0.0, 0.0, 0.8094621288201359, 0.19175098163688045, 0.19175098163688045, 0.28520452550984593], 
reward next is 0.7148, 
noisyNet noise sample is [array([-1.611886], dtype=float32), 1.0168874]. 
=============================================
[2019-03-24 08:04:14,606] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:04:14,611] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9470
[2019-03-24 08:04:14,618] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.66666666666667, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5628023126390469, 6.911199999999999, 6.9112, 121.9260426156618, 412682.6512575391, 412682.6512575395, 124126.8572534501], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 888000.0000, 
sim time next is 888600.0000, 
raw observation next is [21.73333333333333, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5665432742332903, 6.9112, 6.9112, 121.9260426156618, 415783.3863912292, 415783.3863912292, 124618.1808920117], 
processed observation next is [0.0, 0.2608695652173913, 0.3604938271604937, 0.66, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.45817909279161284, 0.0, 0.0, 0.8094621288201359, 0.14849406656829614, 0.14849406656829614, 0.23965034786925327], 
reward next is 0.7603, 
noisyNet noise sample is [array([0.58129656], dtype=float32), 1.9441495]. 
=============================================
[2019-03-24 08:04:18,738] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:04:18,743] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2626
[2019-03-24 08:04:18,748] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.26666666666667, 53.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4940844123275477, 6.9112, 6.9112, 121.9260426156618, 354216.057343427, 354216.057343427, 115159.2178765103], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 952800.0000, 
sim time next is 953400.0000, 
raw observation next is [22.13333333333334, 53.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4912053098638681, 6.9112, 6.9112, 121.9260426156618, 351664.6980579814, 351664.6980579814, 114773.8825281213], 
processed observation next is [1.0, 0.0, 0.3753086419753089, 0.5366666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3640066373298351, 0.0, 0.0, 0.8094621288201359, 0.12559453502070764, 0.12559453502070764, 0.22071900486177173], 
reward next is 0.7793, 
noisyNet noise sample is [array([0.6511718], dtype=float32), -1.5227121]. 
=============================================
[2019-03-24 08:04:24,771] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.000000e+00 1.930648e-38 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-24 08:04:24,778] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0695
[2019-03-24 08:04:24,785] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.9, 60.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5104850680057899, 6.9112, 6.9112, 121.9260426156618, 370488.8197661703, 370488.8197661703, 118066.0107145544], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1040400.0000, 
sim time next is 1041000.0000, 
raw observation next is [21.8, 60.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5130185548728281, 6.9112, 6.9112, 121.9260426156618, 372597.1801059901, 372597.1801059901, 118375.0188526483], 
processed observation next is [1.0, 0.043478260869565216, 0.362962962962963, 0.6083333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3912731935910351, 0.0, 0.0, 0.8094621288201359, 0.13307042146642503, 0.13307042146642503, 0.22764426702432364], 
reward next is 0.7724, 
noisyNet noise sample is [array([-1.8918004], dtype=float32), -0.7367705]. 
=============================================
[2019-03-24 08:04:24,798] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[66.81609 ]
 [67.161835]
 [67.74488 ]
 [68.87314 ]
 [70.026985]], R is [[66.43729401]
 [66.54586792]
 [66.6540451 ]
 [66.76178741]
 [66.86906433]].
[2019-03-24 08:04:27,768] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:04:27,782] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6086
[2019-03-24 08:04:27,789] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.2, 74.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.501514030498716, 6.911200000000001, 6.9112, 121.9260426156618, 360694.153506063, 360694.1535060626, 116127.4131104397], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1124400.0000, 
sim time next is 1125000.0000, 
raw observation next is [19.2, 74.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5007522499381394, 6.9112, 6.9112, 121.9260426156618, 359990.1927918915, 359990.1927918915, 116013.4391569143], 
processed observation next is [1.0, 0.0, 0.26666666666666666, 0.745, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.37594031242267417, 0.0, 0.0, 0.8094621288201359, 0.12856792599710412, 0.12856792599710412, 0.22310276760945058], 
reward next is 0.7769, 
noisyNet noise sample is [array([0.8972937], dtype=float32), -0.41633677]. 
=============================================
[2019-03-24 08:04:27,811] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[67.79757 ]
 [69.681496]
 [72.63768 ]
 [76.83486 ]
 [76.810104]], R is [[66.52749634]
 [66.63890076]
 [66.74891663]
 [66.85752869]
 [66.96477509]].
[2019-03-24 08:04:32,054] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:04:32,061] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0950
[2019-03-24 08:04:32,066] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.83333333333334, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5305875858659511, 6.9112, 6.9112, 121.9260426156618, 387355.9842235419, 387355.9842235419, 120616.4175673662], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1226400.0000, 
sim time next is 1227000.0000, 
raw observation next is [17.81666666666667, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5290510956567452, 6.911200000000001, 6.9112, 121.9260426156618, 386130.5317378118, 386130.5317378113, 120444.8799882571], 
processed observation next is [1.0, 0.17391304347826086, 0.21543209876543223, 0.93, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4113138695709315, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1379037613349328, 0.1379037613349326, 0.23162476920818673], 
reward next is 0.7684, 
noisyNet noise sample is [array([-0.457028], dtype=float32), -0.5384659]. 
=============================================
[2019-03-24 08:04:32,082] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[69.42824 ]
 [69.532364]
 [69.62849 ]
 [69.77965 ]
 [69.977646]], R is [[69.44963837]
 [69.52318573]
 [69.59561157]
 [69.66690063]
 [69.73543549]].
[2019-03-24 08:04:33,337] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:04:33,344] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3869
[2019-03-24 08:04:33,351] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.86666666666667, 93.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5938681126709487, 6.9112, 6.9112, 121.9260426156618, 439595.796725734, 439595.796725734, 129017.9347640877], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1205400.0000, 
sim time next is 1206000.0000, 
raw observation next is [18.8, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5927611118586197, 6.9112, 6.9112, 121.9260426156618, 438816.0934933135, 438816.0934933135, 128939.930960829], 
processed observation next is [1.0, 1.0, 0.2518518518518519, 0.94, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4909513898232746, 0.0, 0.0, 0.8094621288201359, 0.1567200333904691, 0.1567200333904691, 0.24796140569390193], 
reward next is 0.7520, 
noisyNet noise sample is [array([0.9405891], dtype=float32), 1.6309288]. 
=============================================
[2019-03-24 08:04:33,370] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[82.12778 ]
 [82.034004]
 [81.89865 ]
 [81.739426]
 [81.61073 ]], R is [[82.32508087]
 [82.25372314]
 [82.18283081]
 [82.11243439]
 [82.04276276]].
[2019-03-24 08:04:34,391] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:04:34,397] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8851
[2019-03-24 08:04:34,402] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.03333333333333, 55.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6519596068071644, 6.9112, 6.9112, 121.9260426156618, 487025.7704779668, 487025.7704779668, 138751.2573771643], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1273200.0000, 
sim time next is 1273800.0000, 
raw observation next is [25.91666666666666, 56.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6577889045839102, 6.9112, 6.9112, 121.9260426156618, 491389.3560768886, 491389.3560768886, 139378.9331658926], 
processed observation next is [1.0, 0.7391304347826086, 0.5154320987654318, 0.5633333333333332, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5722361307298877, 0.0, 0.0, 0.8094621288201359, 0.1754961985988888, 0.1754961985988888, 0.26803640993440886], 
reward next is 0.7320, 
noisyNet noise sample is [array([0.12373352], dtype=float32), 1.8672616]. 
=============================================
[2019-03-24 08:04:37,568] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:04:37,574] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8690
[2019-03-24 08:04:37,589] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1140647.350625724 W.
[2019-03-24 08:04:37,593] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.4, 42.5, 1.0, 2.0, 0.4608800549196106, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7632373854116453, 6.911200000000001, 6.9112, 121.9260426156618, 1140647.350625724, 1140647.350625723, 239845.2526328979], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1336200.0000, 
sim time next is 1336800.0000, 
raw observation next is [27.6, 42.0, 1.0, 2.0, 0.317003066766069, 1.0, 1.0, 0.317003066766069, 1.0, 2.0, 0.5186074027930092, 6.9112, 6.9112, 121.94756008, 1162701.139654162, 1162701.139654162, 261330.0985664852], 
processed observation next is [1.0, 0.4782608695652174, 0.5777777777777778, 0.42, 1.0, 1.0, 0.1869084128167488, 1.0, 0.5, 0.1869084128167488, 1.0, 1.0, 0.39825925349126146, 0.0, 0.0, 0.8096049824067558, 0.4152504070193436, 0.4152504070193436, 0.5025578818586254], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.787174], dtype=float32), 0.46608067]. 
=============================================
[2019-03-24 08:04:45,143] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:04:45,152] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3017
[2019-03-24 08:04:45,155] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.61666666666667, 87.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5459373165034449, 6.9112, 6.9112, 121.9260426156618, 399148.0137608356, 399148.0137608356, 122150.8679106706], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1807800.0000, 
sim time next is 1808400.0000, 
raw observation next is [18.63333333333333, 87.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5464505379349595, 6.911199999999999, 6.9112, 121.9260426156618, 399744.3680305286, 399744.3680305291, 122291.3759523319], 
processed observation next is [1.0, 0.9565217391304348, 0.24567901234567888, 0.8733333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4330631724186993, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14276584572518877, 0.14276584572518897, 0.23517572298525366], 
reward next is 0.7648, 
noisyNet noise sample is [array([-0.1553647], dtype=float32), 0.09343889]. 
=============================================
[2019-03-24 08:04:45,261] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:04:45,267] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0638
[2019-03-24 08:04:45,274] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.0, 35.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5932741185805187, 6.9112, 6.9112, 121.9260426156618, 439541.4368777158, 439541.4368777158, 129203.3978902978], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1461600.0000, 
sim time next is 1462200.0000, 
raw observation next is [28.83333333333334, 35.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.590939983086482, 6.911199999999999, 6.9112, 121.9260426156618, 437833.3222552243, 437833.3222552248, 129000.5316271427], 
processed observation next is [0.0, 0.9565217391304348, 0.623456790123457, 0.3566666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.48867497885810246, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1563690436625801, 0.15636904366258028, 0.24807794543681289], 
reward next is 0.7519, 
noisyNet noise sample is [array([-0.16847757], dtype=float32), -0.6084497]. 
=============================================
[2019-03-24 08:04:48,659] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-24 08:04:48,661] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:04:48,662] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:04:48,662] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:04:48,664] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:04:48,665] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:04:48,666] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:04:48,667] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:04:48,667] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:04:48,669] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:04:48,670] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:04:48,691] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run79
[2019-03-24 08:04:48,691] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run79
[2019-03-24 08:04:48,738] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run79
[2019-03-24 08:04:48,760] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run79
[2019-03-24 08:04:48,783] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run79
[2019-03-24 08:05:07,522] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022613674]
[2019-03-24 08:05:07,523] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [37.5, 16.5, 1.0, 2.0, 0.595499231174611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 737786.8153841486, 737786.8153841486, 159556.7969009427]
[2019-03-24 08:05:07,525] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:05:07,529] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 3.9546380e-38 3.1310642e-37], sampled 0.7970813530688386
[2019-03-24 08:05:07,530] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 737786.8153841486 W.
[2019-03-24 08:05:16,829] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022613674]
[2019-03-24 08:05:16,830] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.08833216, 87.10246255, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.758912027297085, 6.9112, 6.9112, 121.9260426156618, 566151.9752332856, 566151.9752332856, 153612.5703099326]
[2019-03-24 08:05:16,830] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:05:16,834] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.8915917638798619
[2019-03-24 08:05:19,206] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022613674]
[2019-03-24 08:05:19,207] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.66666666666666, 46.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8626434787957169, 6.911200000000001, 6.9112, 121.9260426156618, 642638.528687912, 642638.5286879116, 166993.391095505]
[2019-03-24 08:05:19,208] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:05:19,212] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.5094562717437358
[2019-03-24 08:05:21,320] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022613674]
[2019-03-24 08:05:21,321] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.65, 74.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7882440274882203, 6.9112, 6.9112, 121.9260426156618, 586341.7672865008, 586341.7672865008, 158409.892071734]
[2019-03-24 08:05:21,322] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:05:21,325] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.1975114349229531
[2019-03-24 08:05:42,434] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022613674]
[2019-03-24 08:05:42,435] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [32.29974975333333, 46.52749192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8926971128967504, 6.9112, 6.9112, 121.9260426156618, 650802.8134055188, 650802.8134055188, 175450.3058858482]
[2019-03-24 08:05:42,436] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:05:42,439] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.5658816921308808
[2019-03-24 08:06:14,943] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022613674]
[2019-03-24 08:06:14,946] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.46666666666667, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8914659310285381, 6.9112, 6.9112, 121.9260426156618, 653079.0110695905, 653079.0110695905, 174677.0702773435]
[2019-03-24 08:06:14,948] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:06:14,951] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.8148698852466025
[2019-03-24 08:06:26,297] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022613674]
[2019-03-24 08:06:26,298] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.0, 100.0, 1.0, 2.0, 0.8196864317420085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 934293.7960549453, 934293.7960549453, 200040.6759436377]
[2019-03-24 08:06:26,298] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:06:26,300] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 5.0867793e-36 0.0000000e+00 2.4172503e-35 1.7060707e-34], sampled 0.4981745732477526
[2019-03-24 08:06:26,300] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 934293.7960549453 W.
[2019-03-24 08:06:34,497] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 08:06:34,739] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 08:06:34,821] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 08:06:34,895] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 08:06:35,060] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 08:06:36,078] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1950000, evaluation results [1950000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 08:06:40,018] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 4.7179087e-36 0.0000000e+00 1.3939897e-35 1.3246955e-35], sum to 1.0000
[2019-03-24 08:06:40,024] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4654
[2019-03-24 08:06:40,032] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.86666666666667, 41.50000000000001, 1.0, 2.0, 0.2309857000815485, 0.0, 1.0, 0.0, 1.0, 1.0, 0.3827156808789753, 6.911200000000001, 6.9112, 121.9260426156602, 571711.2269639677, 571711.2269639672, 174719.8634347039], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1617000.0000, 
sim time next is 1617600.0000, 
raw observation next is [27.73333333333333, 42.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5883718184058451, 6.9112, 6.9112, 121.9260426156618, 438276.055957176, 438276.055957176, 130570.9996415436], 
processed observation next is [1.0, 0.7391304347826086, 0.5827160493827159, 0.42, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4854647730073063, 0.0, 0.0, 0.8094621288201359, 0.1565271628418486, 0.1565271628418486, 0.2510980762337377], 
reward next is 0.7489, 
noisyNet noise sample is [array([-0.8810569], dtype=float32), -0.036230534]. 
=============================================
[2019-03-24 08:06:47,700] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 1.7628654e-37 0.0000000e+00 0.0000000e+00 8.9379255e-38], sum to 1.0000
[2019-03-24 08:06:47,706] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5343
[2019-03-24 08:06:47,709] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.25, 81.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6400179861749434, 6.9112, 6.9112, 121.9260426156618, 477044.036739402, 477044.036739402, 135903.2784872981], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1751400.0000, 
sim time next is 1752000.0000, 
raw observation next is [21.4, 80.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6472135857573399, 6.911199999999999, 6.9112, 121.9260426156618, 482502.2868317083, 482502.2868317088, 136729.4305696], 
processed observation next is [1.0, 0.2608695652173913, 0.3481481481481481, 0.8066666666666668, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5590169821966748, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17232224529703866, 0.17232224529703885, 0.2629412126338461], 
reward next is 0.7371, 
noisyNet noise sample is [array([0.09595715], dtype=float32), 0.32156363]. 
=============================================
[2019-03-24 08:06:47,719] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[59.329437]
 [59.314884]
 [59.358227]
 [59.63736 ]
 [59.936573]], R is [[59.34693909]
 [59.49211884]
 [59.63427353]
 [59.76072311]
 [59.89997864]].
[2019-03-24 08:06:51,050] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:06:51,055] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6900
[2019-03-24 08:06:51,059] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.65, 87.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5478762701391061, 6.9112, 6.9112, 121.9260426156618, 401003.8854131815, 401003.8854131815, 122508.2989446502], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1809000.0000, 
sim time next is 1809600.0000, 
raw observation next is [18.66666666666666, 87.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5496127664811414, 6.911199999999999, 6.9112, 121.9260426156618, 402489.3337260498, 402489.3337260502, 122752.0782749065], 
processed observation next is [1.0, 0.9565217391304348, 0.24691358024691337, 0.8766666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.43701595810142674, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14374619061644636, 0.1437461906164465, 0.2360616889902048], 
reward next is 0.7639, 
noisyNet noise sample is [array([-0.14695767], dtype=float32), 0.54687655]. 
=============================================
[2019-03-24 08:06:53,217] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 2.9763841e-31 2.3038755e-34 3.6881526e-31 4.1618651e-32], sum to 1.0000
[2019-03-24 08:06:53,232] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6577
[2019-03-24 08:06:53,241] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 784965.3679187446 W.
[2019-03-24 08:06:53,245] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.0, 78.0, 1.0, 2.0, 0.2148918280292008, 1.0, 1.0, 0.2148918280292008, 1.0, 2.0, 0.3504288733401457, 6.9112, 6.9112, 121.94756008, 784965.3679187446, 784965.3679187446, 224348.3367297947], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1854000.0000, 
sim time next is 1854600.0000, 
raw observation next is [21.98333333333333, 78.33333333333333, 1.0, 2.0, 0.3460059331429113, 1.0, 2.0, 0.3460059331429113, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 845240.2257061244, 845240.2257061249, 194139.9178495191], 
processed observation next is [1.0, 0.4782608695652174, 0.36975308641975296, 0.7833333333333333, 1.0, 1.0, 0.221435634693942, 1.0, 1.0, 0.221435634693942, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3018715091807587, 0.3018715091807589, 0.37334599586445977], 
reward next is 0.6267, 
noisyNet noise sample is [array([0.52414507], dtype=float32), 0.72680926]. 
=============================================
[2019-03-24 08:06:54,842] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:06:54,850] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3002
[2019-03-24 08:06:54,854] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.3, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6970389547817777, 6.911199999999999, 6.9112, 121.9260426156618, 520889.5199799223, 520889.5199799227, 144557.0386725199], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1879200.0000, 
sim time next is 1879800.0000, 
raw observation next is [21.28333333333333, 89.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7008003790616513, 6.911200000000001, 6.9112, 121.9260426156618, 523701.4883292301, 523701.4883292296, 144964.582366942], 
processed observation next is [1.0, 0.782608695652174, 0.3438271604938271, 0.8916666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6260004738270641, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1870362458318679, 0.1870362458318677, 0.27877804301334996], 
reward next is 0.7212, 
noisyNet noise sample is [array([-0.4408539], dtype=float32), 0.6758794]. 
=============================================
[2019-03-24 08:06:57,782] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 6.3863597e-37 0.0000000e+00 3.5791484e-35 8.1439645e-33], sum to 1.0000
[2019-03-24 08:06:57,788] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0407
[2019-03-24 08:06:57,795] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1030797.33416265 W.
[2019-03-24 08:06:57,798] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.01666666666667, 86.83333333333333, 1.0, 2.0, 0.4298271211600578, 1.0, 1.0, 0.4298271211600578, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1030797.33416265, 1030797.33416265, 216698.2055241267], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1937400.0000, 
sim time next is 1938000.0000, 
raw observation next is [22.13333333333333, 86.66666666666667, 1.0, 2.0, 0.2636009164497191, 1.0, 2.0, 0.2636009164497191, 1.0, 1.0, 0.4235940472104643, 6.9112, 6.9112, 121.94756008, 939925.1010948652, 939925.1010948652, 242164.4614029301], 
processed observation next is [1.0, 0.43478260869565216, 0.3753086419753085, 0.8666666666666667, 1.0, 1.0, 0.1233344243449037, 1.0, 1.0, 0.1233344243449037, 1.0, 0.5, 0.27949255901308034, 0.0, 0.0, 0.8096049824067558, 0.335687536105309, 0.335687536105309, 0.4657008873133271], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.47439584], dtype=float32), 0.24190311]. 
=============================================
[2019-03-24 08:06:57,811] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[56.736885]
 [56.541   ]
 [56.150967]
 [56.067753]
 [56.12531 ]], R is [[56.71516037]
 [56.14801025]
 [55.58653259]
 [55.03066635]
 [54.48036194]].
[2019-03-24 08:07:06,607] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 7.087926e-38 8.756266e-37], sum to 1.0000
[2019-03-24 08:07:06,614] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7340
[2019-03-24 08:07:06,617] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.0, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9249986585342167, 6.9112, 6.9112, 121.9260426156618, 671722.1807989436, 671722.1807989436, 180214.3600950204], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2116200.0000, 
sim time next is 2116800.0000, 
raw observation next is [28.2, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9262946993216947, 6.9112, 6.9112, 121.9260426156618, 672432.0957850489, 672432.0957850489, 180425.6275336518], 
processed observation next is [0.0, 0.5217391304347826, 0.6, 0.66, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9078683741521184, 0.0, 0.0, 0.8094621288201359, 0.24015431992323175, 0.24015431992323175, 0.34697236064163806], 
reward next is 0.6530, 
noisyNet noise sample is [array([0.48364958], dtype=float32), 0.7800547]. 
=============================================
[2019-03-24 08:07:08,707] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:07:08,712] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5942
[2019-03-24 08:07:08,716] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.1, 41.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.621898220730557, 6.9112, 6.9112, 121.9260426156618, 462691.6438727525, 462691.6438727525, 133301.3775756721], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2498400.0000, 
sim time next is 2499000.0000, 
raw observation next is [27.93333333333333, 41.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6243977780183678, 6.9112, 6.9112, 121.9260426156618, 464610.7189233045, 464610.7189233045, 133595.601863884], 
processed observation next is [1.0, 0.9565217391304348, 0.5901234567901233, 0.41833333333333345, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5304972225229597, 0.0, 0.0, 0.8094621288201359, 0.1659323996154659, 0.1659323996154659, 0.2569146189690077], 
reward next is 0.7431, 
noisyNet noise sample is [array([-1.5947838], dtype=float32), 0.1869262]. 
=============================================
[2019-03-24 08:07:08,727] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[66.88759 ]
 [66.746155]
 [66.781395]
 [66.829315]
 [66.75516 ]], R is [[67.03023529]
 [67.10358429]
 [67.17629242]
 [67.24833679]
 [67.31954956]].
[2019-03-24 08:07:12,704] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:07:12,712] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0717
[2019-03-24 08:07:12,719] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.95, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8740096775201277, 6.9112, 6.9112, 121.9260426156618, 642914.3163847816, 642914.3163847816, 171775.0390019104], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2227800.0000, 
sim time next is 2228400.0000, 
raw observation next is [22.9, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.870691492486991, 6.9112, 6.9112, 121.9260426156618, 640891.8095727265, 640891.8095727265, 171236.1149237471], 
processed observation next is [1.0, 0.8260869565217391, 0.4037037037037037, 0.95, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8383643656087386, 0.0, 0.0, 0.8094621288201359, 0.22888993199025945, 0.22888993199025945, 0.32930022100720596], 
reward next is 0.6707, 
noisyNet noise sample is [array([2.665033], dtype=float32), 0.5972296]. 
=============================================
[2019-03-24 08:07:24,727] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:07:24,738] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9309
[2019-03-24 08:07:24,743] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.4, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5723117674433318, 6.911199999999999, 6.9112, 121.9260426156618, 421277.0515240226, 421277.0515240231, 125736.0464251605], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2421000.0000, 
sim time next is 2421600.0000, 
raw observation next is [22.26666666666667, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5650299437548958, 6.911200000000001, 6.9112, 121.9260426156618, 415265.6291910117, 415265.6291910112, 124769.5059427987], 
processed observation next is [1.0, 0.0, 0.38024691358024704, 0.63, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4562874296936197, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14830915328250419, 0.148309153282504, 0.2399413575823052], 
reward next is 0.7601, 
noisyNet noise sample is [array([-1.7224618], dtype=float32), -0.51373667]. 
=============================================
[2019-03-24 08:07:25,060] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-24 08:07:25,061] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:07:25,062] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:07:25,062] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:07:25,063] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:07:25,063] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:07:25,064] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:07:25,066] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:07:25,069] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:07:25,069] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:07:25,071] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:07:25,096] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run80
[2019-03-24 08:07:25,125] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run80
[2019-03-24 08:07:25,126] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run80
[2019-03-24 08:07:25,126] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run80
[2019-03-24 08:07:25,154] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run80
[2019-03-24 08:07:45,227] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022616737]
[2019-03-24 08:07:45,230] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.27661603, 65.70574066333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6836002062703765, 6.9112, 6.9112, 121.9260426156618, 510794.2644818272, 510794.2644818272, 142521.5352538102]
[2019-03-24 08:07:45,232] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:07:45,237] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 3.2483589e-38 0.0000000e+00 3.1431030e-37 1.8253803e-36], sampled 0.7212981271676474
[2019-03-24 08:07:47,057] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022616737]
[2019-03-24 08:07:47,059] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.33333333333334, 71.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6185227752069374, 6.9112, 6.9112, 121.9260426156618, 459958.9593121287, 459958.9593121287, 132789.7672315898]
[2019-03-24 08:07:47,061] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:07:47,065] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 4.9818834e-38], sampled 0.11385761327490174
[2019-03-24 08:08:07,619] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022616737]
[2019-03-24 08:08:07,620] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [26.16666666666667, 90.66666666666667, 1.0, 2.0, 0.7090194773584387, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 808087.0490750058, 808087.0490750053, 177859.1836290068]
[2019-03-24 08:08:07,622] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:08:07,624] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.6099271e-37 0.0000000e+00 9.7321681e-37 6.1677422e-36], sampled 0.4520694405252672
[2019-03-24 08:08:07,624] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 808087.0490750058 W.
[2019-03-24 08:08:31,400] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022616737]
[2019-03-24 08:08:31,402] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.83333333333333, 94.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7120286119955777, 6.911200000000001, 6.9112, 121.9260426156618, 532022.676930663, 532022.6769306625, 146730.0762319505]
[2019-03-24 08:08:31,406] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:08:31,410] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 5.0590072e-37 0.0000000e+00 4.2578875e-36 2.3749496e-35], sampled 0.1892566107101772
[2019-03-24 08:08:33,055] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022616737]
[2019-03-24 08:08:33,057] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [28.0, 74.0, 1.0, 2.0, 0.6641298749884352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 756899.9974524825, 756899.9974524825, 169463.5709205102]
[2019-03-24 08:08:33,059] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:08:33,064] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 5.1207672e-38 0.0000000e+00 3.3629623e-37 2.2272056e-36], sampled 0.8064497390490017
[2019-03-24 08:08:33,067] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 756899.9974524825 W.
[2019-03-24 08:09:00,203] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022616737]
[2019-03-24 08:09:00,204] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.2, 92.66666666666667, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9232400415297992, 6.911199999999999, 6.9112, 121.9260426156618, 668698.1545525899, 668698.1545525903, 180225.4424732025]
[2019-03-24 08:09:00,204] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:09:00,206] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 2.6292797e-36 0.0000000e+00 1.9346396e-35 1.1032799e-34], sampled 0.9576592750981665
[2019-03-24 08:09:04,688] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022616737]
[2019-03-24 08:09:04,689] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.70745244, 74.50211874, 1.0, 2.0, 0.5793500488601158, 0.0, 2.0, 0.0, 1.0, 2.0, 0.922344145899144, 6.911199999999999, 6.9112, 121.9260426156618, 1321040.997976737, 1321040.997976738, 285910.5051390993]
[2019-03-24 08:09:04,690] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:09:04,692] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.0001887e-34 0.0000000e+00 4.8151155e-34 3.1553391e-33], sampled 0.3889127274669033
[2019-03-24 08:09:04,693] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1321040.997976737 W.
[2019-03-24 08:09:10,682] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 08:09:11,083] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 08:09:11,222] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 08:09:11,354] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 08:09:11,361] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 08:09:12,380] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1975000, evaluation results [1975000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 08:09:16,589] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 6.1831897e-38], sum to 1.0000
[2019-03-24 08:09:16,596] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9451
[2019-03-24 08:09:16,600] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.7, 52.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6269192935815305, 6.9112, 6.9112, 121.9260426156618, 466770.3559294539, 466770.3559294539, 134093.7257342258], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2511000.0000, 
sim time next is 2511600.0000, 
raw observation next is [25.6, 53.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6272964020201451, 6.9112, 6.9112, 121.9260426156618, 467048.5919820008, 467048.5919820008, 134128.4215202085], 
processed observation next is [1.0, 0.043478260869565216, 0.5037037037037038, 0.53, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5341205025251814, 0.0, 0.0, 0.8094621288201359, 0.1668030685650003, 0.1668030685650003, 0.2579392721542471], 
reward next is 0.7421, 
noisyNet noise sample is [array([-0.11859504], dtype=float32), 1.2474127]. 
=============================================
[2019-03-24 08:09:23,558] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 2.531496e-37], sum to 1.0000
[2019-03-24 08:09:23,567] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0935
[2019-03-24 08:09:23,571] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.05, 92.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8684000129657603, 6.911200000000001, 6.9112, 121.9260426156618, 640015.9270082418, 640015.9270082413, 170717.7337926153], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2682600.0000, 
sim time next is 2683200.0000, 
raw observation next is [23.1, 91.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8594304563247155, 6.9112, 6.9112, 121.9260426156618, 634155.9320299699, 634155.9320299699, 169346.2901304416], 
processed observation next is [0.0, 0.043478260869565216, 0.41111111111111115, 0.9166666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8242880704058944, 0.0, 0.0, 0.8094621288201359, 0.22648426143927494, 0.22648426143927494, 0.32566594255854153], 
reward next is 0.6743, 
noisyNet noise sample is [array([1.5648515], dtype=float32), -0.42800775]. 
=============================================
[2019-03-24 08:09:33,770] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.4368365e-19 2.6901106e-22 7.9336290e-21 1.2388242e-19], sum to 1.0000
[2019-03-24 08:09:33,776] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8141
[2019-03-24 08:09:33,781] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1525736.179478295 W.
[2019-03-24 08:09:33,785] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.65, 86.5, 1.0, 2.0, 0.7101029090769809, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9961321606264095, 6.911199999999999, 6.9112, 121.9260426156618, 1525736.179478295, 1525736.179478296, 318798.0266366812], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2892600.0000, 
sim time next is 2893200.0000, 
raw observation next is [24.76666666666667, 87.33333333333333, 1.0, 2.0, 0.6291391943258849, 1.0, 1.0, 0.6291391943258849, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1434677.141842289, 1434677.141842288, 278208.8381555458], 
processed observation next is [1.0, 0.4782608695652174, 0.4728395061728396, 0.8733333333333333, 1.0, 1.0, 0.5584990408641487, 1.0, 0.5, 0.5584990408641487, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5123846935151032, 0.5123846935151029, 0.5350169964529727], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.47894496], dtype=float32), -0.8857151]. 
=============================================
[2019-03-24 08:09:36,954] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.2135975e-21 1.1694087e-22 6.1908226e-20 2.0358007e-20], sum to 1.0000
[2019-03-24 08:09:36,958] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7569
[2019-03-24 08:09:36,964] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 813419.3866511891 W.
[2019-03-24 08:09:36,968] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.9, 92.66666666666667, 1.0, 2.0, 0.2378985605274693, 1.0, 1.0, 0.2378985605274693, 1.0, 2.0, 0.3787422561749443, 6.9112, 6.9112, 121.94756008, 813419.3866511891, 813419.3866511891, 233375.2946635489], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2953200.0000, 
sim time next is 2953800.0000, 
raw observation next is [24.85, 92.0, 1.0, 2.0, 0.6997555896646661, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 797523.2739768284, 797523.2739768284, 176093.1110678664], 
processed observation next is [1.0, 0.17391304347826086, 0.475925925925926, 0.92, 1.0, 1.0, 0.6425661781722215, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.28482974070601014, 0.28482974070601014, 0.3386405982074354], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9790315], dtype=float32), -0.56262195]. 
=============================================
[2019-03-24 08:09:45,928] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 4.3562631e-38 0.0000000e+00 2.2338498e-37 1.8367115e-34], sum to 1.0000
[2019-03-24 08:09:45,934] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8632
[2019-03-24 08:09:45,938] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.16666666666666, 59.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.863227512963409, 6.9112, 6.9112, 121.9260426156618, 636270.5159193099, 636270.5159193099, 170033.9273779286], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3109200.0000, 
sim time next is 3109800.0000, 
raw observation next is [28.08333333333334, 58.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8446126679016774, 6.9112, 6.9112, 121.9260426156618, 624120.1705360747, 624120.1705360747, 167179.7901064659], 
processed observation next is [1.0, 1.0, 0.5956790123456792, 0.5883333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8057658348770969, 0.0, 0.0, 0.8094621288201359, 0.22290006090574097, 0.22290006090574097, 0.32149959635858827], 
reward next is 0.6785, 
noisyNet noise sample is [array([0.35282588], dtype=float32), 0.36824512]. 
=============================================
[2019-03-24 08:09:49,274] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 1.0925545e-33 0.0000000e+00 1.5641594e-32 7.1573654e-33], sum to 1.0000
[2019-03-24 08:09:49,287] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3710
[2019-03-24 08:09:49,291] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 694737.7016339886 W.
[2019-03-24 08:09:49,298] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.66666666666667, 81.50000000000001, 1.0, 1.0, 0.3042148410421568, 1.0, 1.0, 0.3042148410421568, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 694737.7016339886, 694737.7016339891, 181542.7349119677], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3273000.0000, 
sim time next is 3273600.0000, 
raw observation next is [25.33333333333334, 84.0, 1.0, 2.0, 0.3051334362629969, 1.0, 2.0, 0.3051334362629969, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 695763.7260453556, 695763.726045356, 181710.9705942876], 
processed observation next is [0.0, 0.9130434782608695, 0.49382716049382736, 0.84, 1.0, 1.0, 0.17277790031309154, 1.0, 1.0, 0.17277790031309154, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24848704501619842, 0.2484870450161986, 0.3494441742197838], 
reward next is 0.6506, 
noisyNet noise sample is [array([-0.1650045], dtype=float32), -1.0455378]. 
=============================================
[2019-03-24 08:09:52,665] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:09:52,675] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9677
[2019-03-24 08:09:52,679] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.1, 46.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7913834830199886, 6.911200000000001, 6.9112, 121.9260426156618, 588478.5271636195, 588478.5271636191, 158909.9330193475], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3236400.0000, 
sim time next is 3237000.0000, 
raw observation next is [30.08333333333334, 47.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8022166098561423, 6.911200000000001, 6.9112, 121.9260426156618, 595881.1991561264, 595881.1991561259, 160595.3865608297], 
processed observation next is [0.0, 0.4782608695652174, 0.6697530864197533, 0.475, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7527707623201779, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21281471398433086, 0.2128147139843307, 0.30883728184774945], 
reward next is 0.6912, 
noisyNet noise sample is [array([0.12231959], dtype=float32), -0.6608442]. 
=============================================
[2019-03-24 08:09:52,703] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[67.54436]
 [67.54277]
 [67.58731]
 [67.67156]
 [67.72332]], R is [[67.46918488]
 [67.48889923]
 [67.506073  ]
 [67.5210495 ]
 [67.53421021]].
[2019-03-24 08:09:53,959] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 3.4450397e-36 0.0000000e+00 1.4769882e-34 2.5131975e-35], sum to 1.0000
[2019-03-24 08:09:53,965] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3459
[2019-03-24 08:09:53,970] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [32.41666666666666, 47.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9335834874657354, 6.9112, 6.9112, 121.9260426156618, 676364.577180131, 676364.577180131, 181617.3476970602], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3255000.0000, 
sim time next is 3255600.0000, 
raw observation next is [31.83333333333334, 50.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9471625175014479, 6.9112, 6.9112, 121.9260426156618, 683919.2214098941, 683919.2214098941, 183788.7555930463], 
processed observation next is [0.0, 0.6956521739130435, 0.7345679012345682, 0.5033333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9339531468768097, 0.0, 0.0, 0.8094621288201359, 0.24425686478924788, 0.24425686478924788, 0.35343991460201213], 
reward next is 0.6466, 
noisyNet noise sample is [array([1.2291799], dtype=float32), -0.46344748]. 
=============================================
[2019-03-24 08:09:54,381] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:09:54,391] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9119
[2019-03-24 08:09:54,395] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.75, 48.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7993159795317779, 6.911200000000001, 6.9112, 121.9260426156618, 593939.5730822767, 593939.5730822763, 160126.2476406116], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3235800.0000, 
sim time next is 3236400.0000, 
raw observation next is [30.1, 46.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7913834830199886, 6.911200000000001, 6.9112, 121.9260426156618, 588478.5271636195, 588478.5271636191, 158909.9330193475], 
processed observation next is [0.0, 0.4782608695652174, 0.6703703703703704, 0.46, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7392293537749858, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21017090255843554, 0.21017090255843537, 0.30559602503720673], 
reward next is 0.6944, 
noisyNet noise sample is [array([-0.6269494], dtype=float32), -0.3474299]. 
=============================================
[2019-03-24 08:10:01,502] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-24 08:10:01,503] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:10:01,504] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:10:01,505] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:10:01,506] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:10:01,506] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:10:01,507] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:10:01,517] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:10:01,518] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:10:01,519] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:10:01,519] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:10:01,534] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run81
[2019-03-24 08:10:01,535] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run81
[2019-03-24 08:10:01,561] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run81
[2019-03-24 08:10:01,608] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run81
[2019-03-24 08:10:01,635] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run81
[2019-03-24 08:10:24,170] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022187881]
[2019-03-24 08:10:24,172] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [32.66666666666666, 31.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6639089879649049, 6.911199999999999, 6.9112, 121.9260426156618, 496122.1579839765, 496122.157983977, 141026.1894293053]
[2019-03-24 08:10:24,173] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:10:24,174] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 3.0510814e-33 1.1674252e-37 1.5935379e-32 4.4769002e-32], sampled 0.918474032080459
[2019-03-24 08:11:09,968] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022187881]
[2019-03-24 08:11:09,970] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.1, 92.33333333333334, 1.0, 2.0, 0.6517325000101698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 742764.028317804, 742764.028317804, 167206.4870051115]
[2019-03-24 08:11:09,971] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:11:09,973] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.6806456e-27 3.0504095e-31 4.1140005e-27 1.3540378e-26], sampled 0.4165205997992234
[2019-03-24 08:11:09,976] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 742764.028317804 W.
[2019-03-24 08:11:31,930] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022187881]
[2019-03-24 08:11:31,933] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [31.8, 56.66666666666667, 1.0, 2.0, 0.6706835469251736, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 764372.8544254999, 764372.8544254994, 170669.2806698438]
[2019-03-24 08:11:31,934] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:11:31,937] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 4.0289246e-26 1.1914186e-29 9.5220553e-26 2.9885668e-25], sampled 0.5848649369716016
[2019-03-24 08:11:31,938] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 764372.8544254999 W.
[2019-03-24 08:11:49,131] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 08:11:49,301] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 08:11:49,446] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 08:11:49,489] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 08:11:49,522] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 08:11:50,540] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 2000000, evaluation results [2000000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 08:11:52,837] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 6.6316903e-25 5.8280417e-28 9.4128532e-24 6.5108684e-25], sum to 1.0000
[2019-03-24 08:11:52,843] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7870
[2019-03-24 08:11:52,851] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 743717.8374559552 W.
[2019-03-24 08:11:52,856] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.66666666666667, 86.33333333333334, 1.0, 2.0, 0.3262845032959227, 1.0, 1.0, 0.3262845032959227, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 743717.8374559552, 743717.8374559552, 186887.9499188398], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3451200.0000, 
sim time next is 3451800.0000, 
raw observation next is [25.58333333333333, 85.66666666666667, 1.0, 2.0, 0.3216549081002595, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5120850892646324, 6.911199999999999, 6.9112, 121.9260426156618, 733160.3053609648, 733160.3053609653, 201154.3964305431], 
processed observation next is [1.0, 0.9565217391304348, 0.5030864197530862, 0.8566666666666667, 1.0, 1.0, 0.19244631916697558, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.39010636158079043, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2618429662003446, 0.26184296620034475, 0.38683537775104443], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.0475089], dtype=float32), 1.0570251]. 
=============================================
[2019-03-24 08:12:04,364] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 2.9732097e-29 7.2754983e-30 3.0411802e-26 2.8570443e-26], sum to 1.0000
[2019-03-24 08:12:04,371] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4193
[2019-03-24 08:12:04,378] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1594669.647013341 W.
[2019-03-24 08:12:04,383] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.0, 100.0, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.67893334189918, 6.9112, 121.9230364294966, 1594669.647013341, 1201531.250120787, 247661.9880624572], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3664800.0000, 
sim time next is 3665400.0000, 
raw observation next is [22.16666666666667, 100.0, 1.0, 2.0, 0.5484638220671209, 1.0, 1.0, 0.5484638220671209, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.92558029916, 1270816.041923383, 1270816.041923383, 251743.838229483], 
processed observation next is [1.0, 0.43478260869565216, 0.3765432098765434, 1.0, 1.0, 1.0, 0.4624569310322867, 1.0, 0.5, 0.4624569310322867, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094590595193393, 0.4538628721154939, 0.4538628721154939, 0.48412276582592884], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.32983676], dtype=float32), 2.0975199]. 
=============================================
[2019-03-24 08:12:08,217] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.0052375e-27 2.5403841e-31 1.0013108e-27 5.5055875e-25], sum to 1.0000
[2019-03-24 08:12:08,226] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4353
[2019-03-24 08:12:08,234] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2192061.462296809 W.
[2019-03-24 08:12:08,241] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.33333333333334, 45.33333333333334, 1.0, 2.0, 0.6544037103065405, 1.0, 2.0, 0.6405665171297049, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2192061.462296809, 2192061.462296809, 417212.3104225961], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3770400.0000, 
sim time next is 3771000.0000, 
raw observation next is [34.5, 44.5, 1.0, 2.0, 0.9618478917862211, 1.0, 2.0, 0.9618478917862211, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 2194341.815836769, 2194341.815836768, 415170.9939824233], 
processed observation next is [1.0, 0.6521739130434783, 0.8333333333333334, 0.445, 1.0, 1.0, 0.9545808235550252, 1.0, 1.0, 0.9545808235550252, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7836935056559889, 0.7836935056559886, 0.7984057576585063], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.682976], dtype=float32), 0.6150082]. 
=============================================
[2019-03-24 08:12:08,251] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[40.984447]
 [40.844685]
 [40.216866]
 [39.9256  ]
 [39.728703]], R is [[40.97534561]
 [40.7632637 ]
 [40.53461075]
 [40.30183029]
 [40.05450439]].
[2019-03-24 08:12:11,973] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 2.0978140e-27 1.9407406e-32 2.9292285e-27 4.3926844e-26], sum to 1.0000
[2019-03-24 08:12:11,982] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5828
[2019-03-24 08:12:11,988] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 713747.2076932864 W.
[2019-03-24 08:12:11,994] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.6, 49.66666666666667, 1.0, 2.0, 0.6262837650601795, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 713747.2076932864, 713747.2076932859, 162657.9787079347], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3842400.0000, 
sim time next is 3843000.0000, 
raw observation next is [32.7, 52.0, 1.0, 2.0, 0.2189454861074214, 1.0, 1.0, 0.2189454861074214, 1.0, 1.0, 0.3485683444396873, 6.9112, 6.9112, 121.94756008, 748583.6640323299, 748583.6640323299, 226883.2724790527], 
processed observation next is [0.0, 0.4782608695652174, 0.7666666666666667, 0.52, 1.0, 1.0, 0.07017319774693023, 1.0, 0.5, 0.07017319774693023, 1.0, 0.5, 0.18571043054960912, 0.0, 0.0, 0.8096049824067558, 0.26735130858297496, 0.26735130858297496, 0.43631398553663986], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9016383], dtype=float32), 0.71212566]. 
=============================================
[2019-03-24 08:12:12,009] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[41.1656  ]
 [42.26394 ]
 [43.35516 ]
 [41.990982]
 [41.54979 ]], R is [[39.66862106]
 [39.27193451]
 [39.52845383]
 [39.75833893]
 [39.97828674]].
[2019-03-24 08:12:17,723] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 4.6947960e-24 6.8262180e-26 2.2450396e-23 3.6134118e-23], sum to 1.0000
[2019-03-24 08:12:17,730] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1153
[2019-03-24 08:12:17,739] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 841968.0702269567 W.
[2019-03-24 08:12:17,748] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.21666666666667, 92.83333333333334, 1.0, 2.0, 0.7387305297020432, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 841968.0702269567, 841968.0702269577, 183607.7929028052], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3913800.0000, 
sim time next is 3914400.0000, 
raw observation next is [26.43333333333334, 91.66666666666667, 1.0, 2.0, 0.3621012177817878, 1.0, 1.0, 0.3621012177817878, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 825400.7598968407, 825400.7598968407, 196032.1752549204], 
processed observation next is [0.0, 0.30434782608695654, 0.5345679012345682, 0.9166666666666667, 1.0, 1.0, 0.24059668783546165, 1.0, 0.5, 0.24059668783546165, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2947859856774431, 0.2947859856774431, 0.3769849524133085], 
reward next is 0.6230, 
noisyNet noise sample is [array([-1.5021644], dtype=float32), 0.5784273]. 
=============================================
[2019-03-24 08:12:21,002] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 7.0983838e-27 9.7842152e-28 6.0778984e-26 1.5488587e-24], sum to 1.0000
[2019-03-24 08:12:21,010] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7621
[2019-03-24 08:12:21,015] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 874607.7536717886 W.
[2019-03-24 08:12:21,017] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.2, 75.0, 1.0, 2.0, 0.2557839531299291, 1.0, 1.0, 0.2557839531299291, 1.0, 2.0, 0.407216383684632, 6.911199999999999, 6.9112, 121.94756008, 874607.7536717886, 874607.7536717891, 239685.7249301525], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3958800.0000, 
sim time next is 3959400.0000, 
raw observation next is [29.25, 74.0, 1.0, 2.0, 0.2532422268864469, 1.0, 2.0, 0.2532422268864469, 1.0, 2.0, 0.4031698727267635, 6.911199999999999, 6.9112, 121.94756008, 865911.8638578698, 865911.8638578702, 238778.0455397881], 
processed observation next is [0.0, 0.8260869565217391, 0.6388888888888888, 0.74, 1.0, 1.0, 0.1110026510552939, 1.0, 1.0, 0.1110026510552939, 1.0, 1.0, 0.2539623409084544, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.3092542370920963, 0.3092542370920965, 0.4591885491149771], 
reward next is 0.5408, 
noisyNet noise sample is [array([0.18150382], dtype=float32), 0.6459099]. 
=============================================
[2019-03-24 08:12:22,098] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 4.4678227e-25 1.9180088e-29 1.8749396e-26 2.7181035e-24], sum to 1.0000
[2019-03-24 08:12:22,105] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2076
[2019-03-24 08:12:22,110] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 696535.2405958814 W.
[2019-03-24 08:12:22,114] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.35, 83.5, 1.0, 2.0, 0.3055939157432214, 0.0, 1.0, 0.0, 1.0, 2.0, 0.486515466362224, 6.911199999999999, 6.9112, 121.9260426156618, 696535.2405958814, 696535.2405958817, 196756.0718073205], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4037400.0000, 
sim time next is 4038000.0000, 
raw observation next is [26.23333333333333, 85.33333333333333, 1.0, 2.0, 0.2075167054581458, 1.0, 1.0, 0.2075167054581458, 1.0, 2.0, 0.3303733534366401, 6.9112, 6.9112, 121.94756008, 709490.1105352363, 709490.1105352363, 223065.6643422428], 
processed observation next is [1.0, 0.7391304347826086, 0.5271604938271603, 0.8533333333333333, 1.0, 1.0, 0.05656750649779261, 1.0, 0.5, 0.05656750649779261, 1.0, 1.0, 0.1629666917958001, 0.0, 0.0, 0.8096049824067558, 0.2533893251911558, 0.2533893251911558, 0.42897243142739], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.7629895], dtype=float32), 0.6434111]. 
=============================================
[2019-03-24 08:12:22,133] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[36.856476]
 [36.752064]
 [36.90439 ]
 [36.29267 ]
 [36.217968]], R is [[36.74245834]
 [36.99665833]
 [37.20041656]
 [37.44000626]
 [37.06560516]].
[2019-03-24 08:12:27,238] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 2.1504035e-30 1.5148494e-33 1.9566825e-28 8.0650826e-29], sum to 1.0000
[2019-03-24 08:12:27,244] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0949
[2019-03-24 08:12:27,253] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 704570.2512268468 W.
[2019-03-24 08:12:27,264] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.7, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9442663197058422, 6.9112, 6.9112, 121.9260417037204, 704570.2512268468, 704570.2512268468, 176453.6090828256], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4089600.0000, 
sim time next is 4090200.0000, 
raw observation next is [22.91666666666667, 83.83333333333333, 1.0, 1.0, 0.39754716154636, 1.0, 1.0, 0.39754716154636, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 948710.7236110084, 948710.7236110084, 207353.1425636808], 
processed observation next is [1.0, 0.34782608695652173, 0.4043209876543212, 0.8383333333333333, 1.0, 0.5, 0.28279423993614283, 1.0, 0.5, 0.28279423993614283, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.338825258432503, 0.338825258432503, 0.39875604339169385], 
reward next is 0.6012, 
noisyNet noise sample is [array([1.8012354], dtype=float32), -0.85505766]. 
=============================================
[2019-03-24 08:12:31,242] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.6573750e-35 2.5820751e-37 4.0456801e-34 8.7653073e-33], sum to 1.0000
[2019-03-24 08:12:31,248] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5176
[2019-03-24 08:12:31,254] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1618548.274796142 W.
[2019-03-24 08:12:31,259] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.91666666666666, 36.33333333333334, 1.0, 2.0, 0.6841503641821891, 1.0, 1.0, 0.6841503641821891, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1618548.274796142, 1618548.274796142, 300946.5700956198], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4273800.0000, 
sim time next is 4274400.0000, 
raw observation next is [31.93333333333334, 36.66666666666667, 1.0, 2.0, 0.6295375818852833, 1.0, 2.0, 0.6295375818852833, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1487125.862071081, 1487125.862071081, 280737.5873730222], 
processed observation next is [1.0, 0.4782608695652174, 0.7382716049382719, 0.3666666666666667, 1.0, 1.0, 0.5589733117681944, 1.0, 1.0, 0.5589733117681944, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.5311163793111003, 0.5311163793111003, 0.5398799757173505], 
reward next is 0.4601, 
noisyNet noise sample is [array([0.2766125], dtype=float32), -0.5993834]. 
=============================================
[2019-03-24 08:12:32,566] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:12:32,575] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7442
[2019-03-24 08:12:32,581] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.6, 46.66666666666667, 1.0, 2.0, 0.2598509017471791, 1.0, 1.0, 0.2598509017471791, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 601041.866786201, 601041.8667862015, 171549.1273837844], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4296000.0000, 
sim time next is 4296600.0000, 
raw observation next is [31.45, 48.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8206411269465856, 6.911200000000001, 6.9112, 121.9260426156618, 598648.0094826877, 598648.0094826873, 165983.3393780877], 
processed observation next is [1.0, 0.7391304347826086, 0.7203703703703703, 0.48, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.7758014086832321, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21380286052953132, 0.21380286052953118, 0.3191987295732456], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.95873153], dtype=float32), 0.7808889]. 
=============================================
[2019-03-24 08:12:33,104] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 5.9759940e-37 0.0000000e+00 1.2634782e-36 1.2920754e-35], sum to 1.0000
[2019-03-24 08:12:33,111] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9450
[2019-03-24 08:12:33,123] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1660239.89072714 W.
[2019-03-24 08:12:33,132] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [34.01666666666667, 33.5, 1.0, 2.0, 0.7144792752732773, 1.0, 2.0, 0.7144792752732773, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1660239.89072714, 1660239.890727141, 311216.7598008077], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4204200.0000, 
sim time next is 4204800.0000, 
raw observation next is [34.0, 34.0, 1.0, 2.0, 0.7908547526802198, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9773262343388329, 6.911199999999999, 6.9112, 121.9260426156618, 1638459.819927595, 1638459.819927595, 330733.171264854], 
processed observation next is [1.0, 0.6956521739130435, 0.8148148148148148, 0.34, 1.0, 1.0, 0.7510175627145473, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9716577929235412, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5851642214027125, 0.5851642214027125, 0.6360253293554885], 
reward next is 0.3640, 
noisyNet noise sample is [array([-0.1192573], dtype=float32), -0.87213343]. 
=============================================
[2019-03-24 08:12:33,278] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.7291019e-33 1.0776144e-36 9.2878336e-32 1.7155877e-32], sum to 1.0000
[2019-03-24 08:12:33,289] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7682
[2019-03-24 08:12:33,299] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 710386.886997393 W.
[2019-03-24 08:12:33,304] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.6, 78.0, 1.0, 2.0, 0.6213398431667163, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 710386.886997393, 710386.886997393, 161899.7970981125], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4543200.0000, 
sim time next is 4543800.0000, 
raw observation next is [26.0, 81.66666666666666, 1.0, 2.0, 0.309972660999036, 1.0, 1.0, 0.309972660999036, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 706520.2426680947, 706520.2426680952, 182871.0952233579], 
processed observation next is [0.0, 0.6086956521739131, 0.5185185185185185, 0.8166666666666665, 1.0, 1.0, 0.1785388821417095, 1.0, 0.5, 0.1785388821417095, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2523286580957481, 0.2523286580957483, 0.3516751831218421], 
reward next is 0.6483, 
noisyNet noise sample is [array([-1.1996884], dtype=float32), -0.709332]. 
=============================================
[2019-03-24 08:12:39,825] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-24 08:12:39,828] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:12:39,830] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:12:39,831] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:12:39,832] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:12:39,832] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:12:39,833] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:12:39,834] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:12:39,835] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:12:39,837] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:12:39,837] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:12:39,859] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run82
[2019-03-24 08:12:39,885] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run82
[2019-03-24 08:12:39,910] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run82
[2019-03-24 08:12:39,911] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run82
[2019-03-24 08:12:39,934] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run82
[2019-03-24 08:12:45,724] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022224912]
[2019-03-24 08:12:45,725] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.35, 43.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.490898391877258, 6.9112, 6.9112, 121.9260426156618, 352393.952226231, 352393.952226231, 115077.8295473365]
[2019-03-24 08:12:45,726] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:12:45,729] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 4.2178465e-35 0.0000000e+00 3.5431103e-34 8.1032712e-34], sampled 0.21326223960670343
[2019-03-24 08:13:16,980] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022224912]
[2019-03-24 08:13:16,981] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [35.16666666666667, 44.33333333333334, 1.0, 2.0, 0.6979044190120917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 795412.3687712266, 795412.3687712266, 175748.9111542495]
[2019-03-24 08:13:16,983] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:13:16,987] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 4.5414121e-28 8.9067078e-32 1.8468493e-27 4.4325420e-27], sampled 0.7707214059234747
[2019-03-24 08:13:16,988] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 795412.3687712266 W.
[2019-03-24 08:13:24,713] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022224912]
[2019-03-24 08:13:24,716] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [20.33333333333334, 98.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.689642649078794, 6.9112, 6.9112, 121.9260426156618, 515350.8388726615, 515350.8388726615, 143904.0404963738]
[2019-03-24 08:13:24,718] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:13:24,720] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 3.6911692e-36 0.0000000e+00 3.2582052e-35 7.5994619e-35], sampled 0.03244032423131071
[2019-03-24 08:13:40,127] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022224912]
[2019-03-24 08:13:40,128] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.0, 96.0, 1.0, 2.0, 0.6659420640715787, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 758966.3477669894, 758966.3477669889, 169796.6273238391]
[2019-03-24 08:13:40,129] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:13:40,133] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 6.6876016e-26 3.9716037e-29 2.3718111e-25 6.3867880e-25], sampled 0.03220118464360622
[2019-03-24 08:13:40,134] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 758966.3477669894 W.
[2019-03-24 08:13:55,956] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022224912]
[2019-03-24 08:13:55,958] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.50099753666667, 85.71481816666667, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8298394919977837, 6.9112, 6.9112, 121.9260426156618, 613062.8047395602, 613062.8047395602, 165374.1825804886]
[2019-03-24 08:13:55,960] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:13:55,962] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 2.9099691e-29 4.3810215e-33 1.3753752e-28 3.4610714e-28], sampled 0.31526750245643387
[2019-03-24 08:14:21,565] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022224912]
[2019-03-24 08:14:21,567] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [17.08333333333334, 99.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5026524892803049, 6.911200000000001, 6.9112, 121.9260426156618, 366400.3879395082, 366400.3879395078, 118092.7122350474]
[2019-03-24 08:14:21,568] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:14:21,573] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 2.5977866e-35 0.0000000e+00 2.1841796e-34 5.2543863e-34], sampled 0.450787584636535
[2019-03-24 08:14:24,913] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 08:14:25,296] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 08:14:25,436] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 08:14:25,480] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 08:14:25,536] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 08:14:26,554] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 2025000, evaluation results [2025000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 08:14:32,401] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 2.6275998e-25 5.0013424e-31 3.6294452e-26 1.4173378e-25], sum to 1.0000
[2019-03-24 08:14:32,408] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0122
[2019-03-24 08:14:32,415] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 829796.2168828713 W.
[2019-03-24 08:14:32,423] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.46666666666667, 82.66666666666667, 1.0, 2.0, 0.3640284503458231, 1.0, 1.0, 0.3640284503458231, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 829796.2168828713, 829796.2168828718, 196536.503230614], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4477200.0000, 
sim time next is 4477800.0000, 
raw observation next is [27.33333333333334, 82.33333333333334, 1.0, 2.0, 0.2396052570433566, 1.0, 2.0, 0.2396052570433566, 1.0, 1.0, 0.381459372611462, 6.9112, 6.9112, 121.94756008, 819258.0173770176, 819258.0173770176, 233969.7477332497], 
processed observation next is [0.0, 0.8260869565217391, 0.5679012345679014, 0.8233333333333335, 1.0, 1.0, 0.09476816314685312, 1.0, 1.0, 0.09476816314685312, 1.0, 0.5, 0.22682421576432749, 0.0, 0.0, 0.8096049824067558, 0.29259214906322056, 0.29259214906322056, 0.4499418225639417], 
reward next is 0.5501, 
noisyNet noise sample is [array([-0.49706867], dtype=float32), 1.9035573]. 
=============================================
[2019-03-24 08:14:37,056] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 2.8287115e-38 0.0000000e+00 4.9133404e-36 5.0919603e-37], sum to 1.0000
[2019-03-24 08:14:37,061] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4134
[2019-03-24 08:14:37,067] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.13333333333333, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8973741168601995, 6.911200000000001, 6.9112, 121.9260426156618, 657772.7668545742, 657772.7668545737, 175379.8467933818], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4566000.0000, 
sim time next is 4566600.0000, 
raw observation next is [23.1, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9023438571945774, 6.9112, 6.9112, 121.9260426156618, 660526.4577357398, 660526.4577357398, 176227.1868047765], 
processed observation next is [0.0, 0.8695652173913043, 0.41111111111111115, 0.97, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8779298214932219, 0.0, 0.0, 0.8094621288201359, 0.23590230633419276, 0.23590230633419276, 0.3388984361630317], 
reward next is 0.6611, 
noisyNet noise sample is [array([1.8461725], dtype=float32), -0.79626536]. 
=============================================
[2019-03-24 08:14:38,441] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.6534887e-38 0.0000000e+00], sum to 1.0000
[2019-03-24 08:14:38,447] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8818
[2019-03-24 08:14:38,452] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.5, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9029573341968605, 6.911199999999999, 6.9112, 121.9260426156618, 661016.2750577002, 661016.2750577007, 176300.4882865002], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4537800.0000, 
sim time next is 4538400.0000, 
raw observation next is [23.66666666666667, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9166564257853853, 6.9112, 6.9112, 121.9260426156618, 669307.845886586, 669307.845886586, 178472.5180500204], 
processed observation next is [0.0, 0.5217391304347826, 0.43209876543209896, 0.94, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8958205322317316, 0.0, 0.0, 0.8094621288201359, 0.23903851638806642, 0.23903851638806642, 0.34321638086542383], 
reward next is 0.6568, 
noisyNet noise sample is [array([0.5098109], dtype=float32), -0.7060901]. 
=============================================
[2019-03-24 08:14:43,344] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.0131292e-20 3.1029641e-24 7.4379297e-21 8.2464592e-21], sum to 1.0000
[2019-03-24 08:14:43,347] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3493
[2019-03-24 08:14:43,353] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 713655.9125132425 W.
[2019-03-24 08:14:43,357] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 95.0, 1.0, 2.0, 0.3068874156108864, 1.0, 1.0, 0.3068874156108864, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 713655.9125132425, 713655.9125132428, 182800.2639196777], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4687800.0000, 
sim time next is 4688400.0000, 
raw observation next is [23.0, 96.0, 1.0, 2.0, 0.5966525913728024, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 697633.9532020235, 697633.9532020235, 158330.6012190695], 
processed observation next is [1.0, 0.2608695652173913, 0.4074074074074074, 0.96, 1.0, 1.0, 0.5198245135390505, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.24915498328643698, 0.24915498328643698, 0.3044819254212875], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3436836], dtype=float32), -0.6847468]. 
=============================================
[2019-03-24 08:14:53,306] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.1468051e-19 8.7556887e-24 1.4369673e-20 1.0357162e-19], sum to 1.0000
[2019-03-24 08:14:53,311] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3632
[2019-03-24 08:14:53,317] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 800196.0338372948 W.
[2019-03-24 08:14:53,320] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.0, 96.0, 1.0, 2.0, 0.3510497373625763, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5588826147729956, 6.9112, 6.9112, 121.9260426156618, 800196.0338372948, 800196.0338372948, 209476.4899668797], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4856400.0000, 
sim time next is 4857000.0000, 
raw observation next is [25.0, 95.66666666666667, 1.0, 2.0, 0.3482959242983273, 0.0, 2.0, 0.0, 1.0, 2.0, 0.554498454689281, 6.911199999999999, 6.9112, 121.9260426156618, 793915.6373929976, 793915.6373929981, 208682.2313705729], 
processed observation next is [1.0, 0.21739130434782608, 0.48148148148148145, 0.9566666666666667, 1.0, 1.0, 0.22416181464086582, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.44312306836160126, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2835412990689277, 0.2835412990689279, 0.4013119834049479], 
reward next is 0.5987, 
noisyNet noise sample is [array([-1.0720327], dtype=float32), -0.52316624]. 
=============================================
[2019-03-24 08:14:53,331] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[28.072407]
 [27.859547]
 [27.909153]
 [28.138817]
 [27.923592]], R is [[28.76741409]
 [29.07690048]
 [29.33980942]
 [29.67493629]
 [30.00705338]].
[2019-03-24 08:14:56,724] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 3.5888865e-18 7.0256456e-20 6.1712617e-17 1.9085553e-16], sum to 1.0000
[2019-03-24 08:14:56,733] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6751
[2019-03-24 08:14:56,739] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 749880.6678238562 W.
[2019-03-24 08:14:56,744] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 88.0, 1.0, 2.0, 0.3235182245464152, 1.0, 1.0, 0.3235182245464152, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 749880.6678238562, 749880.6678238562, 186797.0884355517], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4949400.0000, 
sim time next is 4950000.0000, 
raw observation next is [24.0, 89.0, 1.0, 2.0, 0.6401625607981483, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 746987.9504900149, 746987.9504900149, 165955.2097964206], 
processed observation next is [1.0, 0.30434782608695654, 0.4444444444444444, 0.89, 1.0, 1.0, 0.5716220961882718, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.266781410889291, 0.266781410889291, 0.3191446342238857], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.05505228], dtype=float32), -0.024685154]. 
=============================================
[2019-03-24 08:14:56,763] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[25.426758]
 [25.394306]
 [25.503033]
 [25.478952]
 [27.002443]], R is [[24.71674728]
 [24.4695797 ]
 [24.84153557]
 [24.59312057]
 [25.00128174]].
[2019-03-24 08:15:03,100] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.2347990e-35 2.5650603e-38 2.8383714e-33 1.3252484e-32], sum to 1.0000
[2019-03-24 08:15:03,108] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3618
[2019-03-24 08:15:03,114] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.75, 97.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.876586282590244, 6.9112, 6.9112, 121.9260426156618, 644090.9369702337, 644090.9369702337, 172288.9741263871], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5029800.0000, 
sim time next is 5030400.0000, 
raw observation next is [22.8, 96.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.873260097868298, 6.911199999999999, 6.9112, 121.9260426156618, 641934.8327374614, 641934.8327374619, 171785.9670937347], 
processed observation next is [0.0, 0.21739130434782608, 0.4, 0.9666666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8415751223353723, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.22926244026337908, 0.22926244026337925, 0.3303576290264129], 
reward next is 0.6696, 
noisyNet noise sample is [array([-0.03095759], dtype=float32), 0.77099645]. 
=============================================
[2019-03-24 08:15:03,935] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.00000000e+00 8.24692531e-30 1.12885015e-32 1.32878453e-28
 3.67252037e-27], sum to 1.0000
[2019-03-24 08:15:03,940] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8916
[2019-03-24 08:15:03,947] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 951602.5016673493 W.
[2019-03-24 08:15:03,953] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.0, 84.0, 1.0, 2.0, 0.4174312507202846, 1.0, 1.0, 0.4174312507202846, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 951602.5016673493, 951602.5016673497, 211031.3033030673], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5079600.0000, 
sim time next is 5080200.0000, 
raw observation next is [28.96666666666667, 83.66666666666667, 1.0, 2.0, 0.4025812178222681, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6409224099279779, 6.911199999999999, 6.9112, 121.9260426156618, 917729.1635830363, 917729.1635830367, 224905.8936208205], 
processed observation next is [0.0, 0.8260869565217391, 0.6283950617283951, 0.8366666666666667, 1.0, 1.0, 0.2887871640741287, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.5511530124099723, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3277604155653701, 0.3277604155653703, 0.4325113338861933], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.95955235], dtype=float32), 0.5688336]. 
=============================================
[2019-03-24 08:15:05,111] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 4.9198448e-30 2.8039246e-32 5.1765553e-27 2.2527560e-27], sum to 1.0000
[2019-03-24 08:15:05,121] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6435
[2019-03-24 08:15:05,128] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 894724.4730229309 W.
[2019-03-24 08:15:05,131] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.66666666666666, 83.16666666666667, 1.0, 2.0, 0.3924956133772692, 0.0, 2.0, 0.0, 1.0, 1.0, 0.6248657991863342, 6.911199999999999, 6.9112, 121.9260426156618, 894724.4730229309, 894724.4730229314, 221802.4411952995], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5083800.0000, 
sim time next is 5084400.0000, 
raw observation next is [28.53333333333333, 84.33333333333334, 1.0, 2.0, 0.8031391150066346, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 915421.5927297543, 915421.5927297538, 196596.9402619141], 
processed observation next is [0.0, 0.8695652173913043, 0.6123456790123456, 0.8433333333333334, 1.0, 1.0, 0.7656418035793269, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3269362831177694, 0.32693628311776923, 0.37807103896521943], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.40586513], dtype=float32), -0.84531397]. 
=============================================
[2019-03-24 08:15:08,186] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 9.6249677e-26 1.1415230e-28 5.0369921e-24 2.0378798e-23], sum to 1.0000
[2019-03-24 08:15:08,194] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0499
[2019-03-24 08:15:08,213] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 904156.9804037453 W.
[2019-03-24 08:15:08,220] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.9, 69.0, 1.0, 2.0, 0.2644206968142119, 1.0, 1.0, 0.2644206968142119, 1.0, 2.0, 0.4209663609091148, 6.911199999999999, 6.9112, 121.94756008, 904156.9804037453, 904156.9804037458, 242796.9578845562], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5158800.0000, 
sim time next is 5159400.0000, 
raw observation next is [30.7, 69.83333333333333, 1.0, 2.0, 0.3920094042244389, 0.0, 1.0, 0.0, 1.0, 2.0, 0.6240917383803019, 6.911199999999999, 6.9112, 121.9260426156618, 893615.4750244136, 893615.4750244139, 221653.1948261283], 
processed observation next is [0.0, 0.7391304347826086, 0.6925925925925925, 0.6983333333333333, 1.0, 1.0, 0.2762016716957606, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.5301146729753773, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.31914838393729056, 0.31914838393729067, 0.4262561438964006], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2338382], dtype=float32), 0.1743862]. 
=============================================
[2019-03-24 08:15:08,612] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.5633432e-23 1.5087532e-26 6.1473242e-23 5.4955448e-22], sum to 1.0000
[2019-03-24 08:15:08,625] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5346
[2019-03-24 08:15:08,629] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2125720.584350713 W.
[2019-03-24 08:15:08,635] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.33333333333334, 69.33333333333334, 1.0, 2.0, 0.6212033612761748, 1.0, 2.0, 0.6212033612761748, 1.0, 1.0, 0.9889759823327349, 6.911199999999999, 6.9112, 121.94756008, 2125720.584350713, 2125720.584350714, 407049.2498849484], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5235600.0000, 
sim time next is 5236200.0000, 
raw observation next is [29.25, 70.5, 1.0, 2.0, 0.6450114618021332, 1.0, 2.0, 0.6358703928775012, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2175971.431632131, 2175971.431632131, 414790.5738953926], 
processed observation next is [1.0, 0.6086956521739131, 0.6388888888888888, 0.705, 1.0, 1.0, 0.5773945973834919, 1.0, 1.0, 0.5665123724732157, 1.0, 1.0, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7771326541543324, 0.7771326541543324, 0.7976741805680627], 
reward next is 0.2023, 
noisyNet noise sample is [array([1.3859656], dtype=float32), -0.1286272]. 
=============================================
[2019-03-24 08:15:13,307] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 4.1034407e-25 6.4279911e-27 6.3461122e-24 1.2130593e-23], sum to 1.0000
[2019-03-24 08:15:13,313] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3221
[2019-03-24 08:15:13,319] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 803778.1095693308 W.
[2019-03-24 08:15:13,323] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.43333333333334, 88.66666666666667, 1.0, 2.0, 0.3526203871730032, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5613831404236884, 6.9112, 6.9112, 121.9260426156618, 803778.1095693308, 803778.1095693308, 209932.1707131888], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5260800.0000, 
sim time next is 5261400.0000, 
raw observation next is [26.35, 89.0, 1.0, 2.0, 0.3541337122107148, 1.0, 1.0, 0.3541337122107148, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 807229.4643704293, 807229.4643704297, 193959.4129111514], 
processed observation next is [1.0, 0.9130434782608695, 0.5314814814814816, 0.89, 1.0, 1.0, 0.23111156215561288, 1.0, 0.5, 0.23111156215561288, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2882962372751533, 0.28829623727515347, 0.37299887098298345], 
reward next is 0.6270, 
noisyNet noise sample is [array([-1.7529032], dtype=float32), -1.6483319]. 
=============================================
[2019-03-24 08:15:15,840] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-24 08:15:15,841] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:15:15,842] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:15:15,842] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:15:15,843] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:15:15,844] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:15:15,844] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:15:15,845] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:15:15,846] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:15:15,846] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:15:15,845] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:15:15,873] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run83
[2019-03-24 08:15:15,873] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run83
[2019-03-24 08:15:15,924] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run83
[2019-03-24 08:15:15,925] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run83
[2019-03-24 08:15:15,925] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run83
[2019-03-24 08:15:28,250] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022162572]
[2019-03-24 08:15:28,251] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [30.507781115, 57.47423004666667, 1.0, 2.0, 0.629478012680756, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 717389.2502685972, 717389.2502685972, 163221.4587898219]
[2019-03-24 08:15:28,252] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:15:28,257] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 5.9872373e-24 5.6967748e-27 2.9912047e-23 6.5238532e-23], sampled 0.8857340771899969
[2019-03-24 08:15:28,259] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 717389.2502685972 W.
[2019-03-24 08:15:29,552] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022162572]
[2019-03-24 08:15:29,554] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.310280375, 56.772085815, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5985262750071976, 6.911200000000001, 6.9112, 121.9260426156618, 443604.9159970031, 443604.9159970027, 129802.7635056217]
[2019-03-24 08:15:29,557] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:15:29,560] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.1112907e-30 1.2323104e-34 9.8251226e-30 2.2590186e-29], sampled 0.04181444839635329
[2019-03-24 08:15:50,405] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022162572]
[2019-03-24 08:15:50,406] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.86666666666667, 75.33333333333334, 1.0, 2.0, 0.9038355972991851, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1079506.565994309, 1079506.565994309, 220755.5864995923]
[2019-03-24 08:15:50,406] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:15:50,410] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 2.3384215e-22 4.2257435e-25 8.7117204e-22 2.2168812e-21], sampled 0.5930626935859328
[2019-03-24 08:15:50,412] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1079506.565994309 W.
[2019-03-24 08:16:18,824] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022162572]
[2019-03-24 08:16:18,825] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [22.58696239666667, 82.55631748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7136587832372692, 6.911200000000001, 6.9112, 121.9260426156618, 533146.1862546442, 533146.1862546437, 147213.3827019608]
[2019-03-24 08:16:18,825] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:16:18,828] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 5.0049901e-30 6.6923212e-34 4.1730794e-29 9.3505223e-29], sampled 0.07239457956487327
[2019-03-24 08:16:31,296] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022162572]
[2019-03-24 08:16:31,298] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.17746419, 91.171967105, 1.0, 1.0, 0.623291419661238, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 710335.3872913424, 710335.3872913424, 162130.6610220605]
[2019-03-24 08:16:31,302] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:16:31,304] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 7.6536894e-28 1.8499269e-31 4.9278912e-27 1.1870427e-26], sampled 0.478345057058596
[2019-03-24 08:16:31,306] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 710335.3872913424 W.
[2019-03-24 08:16:42,713] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022162572]
[2019-03-24 08:16:42,714] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.42975455, 75.57781955, 1.0, 2.0, 0.8015972309603423, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 913663.0987081259, 913663.0987081259, 196280.4134083502]
[2019-03-24 08:16:42,715] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:16:42,716] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 3.6815993e-25 2.4886308e-28 1.7640543e-24 4.5077820e-24], sampled 0.11821936984531434
[2019-03-24 08:16:42,718] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 913663.0987081259 W.
[2019-03-24 08:16:48,058] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022162572]
[2019-03-24 08:16:48,059] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.66666666666667, 67.33333333333334, 1.0, 2.0, 0.8315650520024044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260425932161, 947841.6408360241, 947841.6408360241, 202541.8493963109]
[2019-03-24 08:16:48,060] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:16:48,064] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 3.2180552e-23 4.2551490e-26 1.2622348e-22 3.2791123e-22], sampled 0.06654403378872398
[2019-03-24 08:16:48,064] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 947841.6408360241 W.
[2019-03-24 08:16:55,532] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022162572]
[2019-03-24 08:16:55,532] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.58787163333334, 92.03528338000001, 1.0, 1.0, 0.6105433435753076, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9259942169983, 742623.5761556743, 742623.5761556738, 161840.0437748748]
[2019-03-24 08:16:55,532] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:16:55,534] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.9634092e-23 2.2446680e-26 9.0551235e-23 2.1668648e-22], sampled 0.5207617141275345
[2019-03-24 08:16:55,536] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 742623.5761556743 W.
[2019-03-24 08:16:59,460] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022162572]
[2019-03-24 08:16:59,461] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [27.86666666666667, 55.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7372480344857183, 6.9112, 6.9112, 121.9260426156618, 548774.6980035397, 548774.6980035397, 152047.6366676014]
[2019-03-24 08:16:59,462] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:16:59,464] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.9073790e-28 3.7157303e-32 1.3550190e-27 3.1472222e-27], sampled 0.5563235133346637
[2019-03-24 08:17:01,152] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 08:17:01,256] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 08:17:01,375] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 08:17:01,438] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 08:17:01,439] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 08:17:02,455] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 2050000, evaluation results [2050000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 08:17:07,742] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 5.4264863e-30 1.9639171e-32 1.0482035e-29 1.2455378e-28], sum to 1.0000
[2019-03-24 08:17:07,754] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8871
[2019-03-24 08:17:07,762] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.35, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.890402606430741, 6.911199999999999, 6.9112, 121.9260426156618, 653673.2517928962, 653673.2517928967, 174231.0192976015], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5700600.0000, 
sim time next is 5701200.0000, 
raw observation next is [23.26666666666667, 93.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8878936504871326, 6.911199999999999, 6.9112, 121.9260426156618, 652200.691570417, 652200.6915704175, 173813.9406556357], 
processed observation next is [0.0, 1.0, 0.41728395061728407, 0.9333333333333335, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8598670631089158, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23292881841800608, 0.23292881841800625, 0.3342575781839148], 
reward next is 0.6657, 
noisyNet noise sample is [array([-1.2719002], dtype=float32), 0.35489902]. 
=============================================
[2019-03-24 08:17:11,124] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 5.9946222e-23 1.1047800e-25 6.8232933e-21 1.3994128e-21], sum to 1.0000
[2019-03-24 08:17:11,130] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3139
[2019-03-24 08:17:11,134] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 782486.3043986722 W.
[2019-03-24 08:17:11,143] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.76666666666667, 91.16666666666667, 1.0, 2.0, 0.3432843600755565, 1.0, 1.0, 0.3432843600755565, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 782486.3043986722, 782486.3043986722, 191172.7014140848], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5530200.0000, 
sim time next is 5530800.0000, 
raw observation next is [25.73333333333333, 91.33333333333334, 1.0, 2.0, 0.3430189929409401, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5460974081106643, 6.911199999999999, 6.9112, 121.9260426156618, 781881.1150001894, 781881.1150001897, 207169.361305225], 
processed observation next is [1.0, 0.0, 0.5086419753086419, 0.9133333333333334, 1.0, 1.0, 0.2178797535011192, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.43262176013833037, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2792432553572105, 0.2792432553572106, 0.39840261789466347], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.51635903], dtype=float32), -0.2633657]. 
=============================================
[2019-03-24 08:17:22,096] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 6.3022167e-28 1.7903997e-31 3.9065876e-28 7.1143236e-27], sum to 1.0000
[2019-03-24 08:17:22,103] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4404
[2019-03-24 08:17:22,108] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 714263.106201372 W.
[2019-03-24 08:17:22,111] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.2, 96.0, 1.0, 2.0, 0.3133681169724425, 0.0, 2.0, 0.0, 1.0, 1.0, 0.4988922479072021, 6.9112, 6.9112, 121.9260426156618, 714263.106201372, 714263.106201372, 198871.5913340085], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5641200.0000, 
sim time next is 5641800.0000, 
raw observation next is [24.26666666666667, 95.83333333333333, 1.0, 2.0, 0.3146646434835754, 1.0, 1.0, 0.3146646434835754, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 717219.6746213129, 717219.6746213133, 184017.1220154801], 
processed observation next is [0.0, 0.30434782608695654, 0.4543209876543211, 0.9583333333333333, 1.0, 1.0, 0.18412457557568504, 1.0, 0.5, 0.18412457557568504, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.25614988379332604, 0.2561498837933262, 0.3538790807990002], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0736979], dtype=float32), 0.09780422]. 
=============================================
[2019-03-24 08:17:24,766] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:17:24,774] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5256
[2019-03-24 08:17:24,783] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.7, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8282293564352019, 6.9112, 6.9112, 121.9260426156618, 613157.5309905872, 613157.5309905872, 164724.5386300599], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6044400.0000, 
sim time next is 6045000.0000, 
raw observation next is [24.56666666666667, 78.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8261315477564648, 6.9112, 6.9112, 121.9260426156618, 611769.8496030552, 611769.8496030552, 164401.7538917345], 
processed observation next is [1.0, 1.0, 0.46543209876543223, 0.7866666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.782664434695581, 0.0, 0.0, 0.8094621288201359, 0.21848923200109113, 0.21848923200109113, 0.3161572190225663], 
reward next is 0.6838, 
noisyNet noise sample is [array([0.5390906], dtype=float32), -0.020395176]. 
=============================================
[2019-03-24 08:17:24,800] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[65.389   ]
 [65.14241 ]
 [65.094444]
 [64.99087 ]
 [64.89954 ]], R is [[65.5707016 ]
 [65.5982132 ]
 [65.62480164]
 [65.65044403]
 [65.67457581]].
[2019-03-24 08:17:26,797] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:17:26,804] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2368
[2019-03-24 08:17:26,810] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.8, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8083664426886341, 6.911200000000001, 6.9112, 121.9260426156618, 600404.4032058716, 600404.4032058711, 161386.9074793129], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5712000.0000, 
sim time next is 5712600.0000, 
raw observation next is [21.75, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8038036963747627, 6.911199999999999, 6.9112, 121.9260426156618, 597255.6836664496, 597255.6836664501, 160694.9805393542], 
processed observation next is [0.0, 0.08695652173913043, 0.3611111111111111, 0.97, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7547546204684532, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21330560130944629, 0.21330560130944645, 0.3090288087295273], 
reward next is 0.6910, 
noisyNet noise sample is [array([1.8095928], dtype=float32), 0.81925285]. 
=============================================
[2019-03-24 08:17:27,335] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:17:27,340] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0715
[2019-03-24 08:17:27,347] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.8, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8225188065138573, 6.911199999999999, 6.9112, 121.9260426156618, 609122.8329825962, 609122.8329825966, 163942.9149673101], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5784000.0000, 
sim time next is 5784600.0000, 
raw observation next is [23.7, 84.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8200986995371892, 6.9112, 6.9112, 121.9260426156618, 607509.8423786379, 607509.8423786379, 163565.1805882084], 
processed observation next is [0.0, 0.9565217391304348, 0.4333333333333333, 0.845, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7751233744214864, 0.0, 0.0, 0.8094621288201359, 0.21696780084951353, 0.21696780084951353, 0.3145484242080931], 
reward next is 0.6855, 
noisyNet noise sample is [array([-0.972666], dtype=float32), -0.64823705]. 
=============================================
[2019-03-24 08:17:35,483] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 5.828368e-38 1.141052e-37], sum to 1.0000
[2019-03-24 08:17:35,493] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1354
[2019-03-24 08:17:35,500] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1481022.779426357 W.
[2019-03-24 08:17:35,502] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.2, 46.5, 1.0, 2.0, 0.4214604486585856, 1.0, 2.0, 0.4214604486585856, 1.0, 1.0, 0.6737174087888871, 6.9112, 6.9112, 121.94756008, 1481022.779426357, 1481022.779426357, 306657.1580696942], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5931000.0000, 
sim time next is 5931600.0000, 
raw observation next is [29.16666666666666, 47.0, 1.0, 2.0, 0.4243222722912079, 1.0, 2.0, 0.4243222722912079, 1.0, 2.0, 0.6776019060408971, 6.9112, 6.9112, 121.94756008, 1485075.799835751, 1485075.799835751, 307976.856788812], 
processed observation next is [1.0, 0.6521739130434783, 0.6358024691358023, 0.47, 1.0, 1.0, 0.31466937177524745, 1.0, 1.0, 0.31466937177524745, 1.0, 1.0, 0.5970023825511214, 0.0, 0.0, 0.8096049824067558, 0.530384214227054, 0.530384214227054, 0.5922631861323308], 
reward next is 0.4077, 
noisyNet noise sample is [array([-0.00676837], dtype=float32), 0.47528988]. 
=============================================
[2019-03-24 08:17:36,179] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 3.9355335e-34 0.0000000e+00 1.8653101e-32 6.1052073e-32], sum to 1.0000
[2019-03-24 08:17:36,186] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0477
[2019-03-24 08:17:36,196] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1092418.532112734 W.
[2019-03-24 08:17:36,199] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.35, 61.16666666666667, 1.0, 2.0, 0.4533467651090781, 1.0, 2.0, 0.4533467651090781, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1092418.532112734, 1092418.532112734, 223796.2442874695], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5911800.0000, 
sim time next is 5912400.0000, 
raw observation next is [25.6, 60.33333333333334, 1.0, 2.0, 0.4376277785901084, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7099924837808722, 6.911200000000001, 6.9112, 121.9260426156618, 1058525.100032181, 1058525.10003218, 233982.2590664668], 
processed observation next is [1.0, 0.43478260869565216, 0.5037037037037038, 0.6033333333333334, 1.0, 1.0, 0.3305092602263195, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.6374906047260903, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3780446785829218, 0.37804467858292146, 0.44996588282012845], 
reward next is 0.5500, 
noisyNet noise sample is [array([0.90031826], dtype=float32), 0.5753204]. 
=============================================
[2019-03-24 08:17:42,722] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 3.1946814e-38 0.0000000e+00 2.4483366e-37 3.3081513e-35], sum to 1.0000
[2019-03-24 08:17:42,730] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9075
[2019-03-24 08:17:42,743] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.93333333333333, 76.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.833195187998984, 6.911199999999999, 6.9112, 121.9260426156618, 616638.670052224, 616638.6700522244, 165414.1307233541], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6043200.0000, 
sim time next is 6043800.0000, 
raw observation next is [24.81666666666666, 77.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8306518416507949, 6.9112, 6.9112, 121.9260426156618, 614851.3761995302, 614851.3761995302, 165062.4927183819], 
processed observation next is [1.0, 0.9565217391304348, 0.4746913580246911, 0.7733333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7883148020634936, 0.0, 0.0, 0.8094621288201359, 0.21958977721411793, 0.21958977721411793, 0.3174278706122729], 
reward next is 0.6826, 
noisyNet noise sample is [array([-0.83100533], dtype=float32), 0.7080772]. 
=============================================
[2019-03-24 08:17:50,507] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 4.5721598e-29 3.8880554e-32 9.3631983e-28 1.0528922e-29], sum to 1.0000
[2019-03-24 08:17:50,512] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5309
[2019-03-24 08:17:50,521] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1732250.49360382 W.
[2019-03-24 08:17:50,526] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.06666666666667, 63.66666666666666, 1.0, 2.0, 0.89226111814847, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426156618, 1732250.49360382, 1732250.49360382, 355295.2926014297], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6177000.0000, 
sim time next is 6177600.0000, 
raw observation next is [28.2, 63.0, 1.0, 2.0, 0.5185250229525861, 1.0, 1.0, 0.5185250229525861, 1.0, 2.0, 0.8255087237215591, 6.9112, 6.9112, 121.94756008, 1774012.569876625, 1774012.569876625, 352774.385298643], 
processed observation next is [1.0, 0.5217391304347826, 0.6, 0.63, 1.0, 1.0, 0.4268155035149834, 1.0, 0.5, 0.4268155035149834, 1.0, 1.0, 0.7818859046519488, 0.0, 0.0, 0.8096049824067558, 0.6335759178130803, 0.6335759178130803, 0.6784122794204673], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.999462], dtype=float32), 0.7001747]. 
=============================================
[2019-03-24 08:17:51,897] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-24 08:17:51,899] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:17:51,899] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:17:51,900] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:17:51,900] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:17:51,902] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:17:51,903] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:17:51,903] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:17:51,904] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:17:51,906] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:17:51,907] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:17:51,925] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run84
[2019-03-24 08:17:51,956] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run84
[2019-03-24 08:17:51,982] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run84
[2019-03-24 08:17:52,019] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run84
[2019-03-24 08:17:52,020] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run84
[2019-03-24 08:18:01,919] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022523863]
[2019-03-24 08:18:01,921] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.68333333333334, 18.66666666666667, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9700152661382588, 6.989150788584729, 6.9112, 121.9256738399186, 754191.4761144624, 714273.8259313689, 167150.9695918817]
[2019-03-24 08:18:01,922] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:18:01,924] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 6.6527592e-36 0.0000000e+00 8.6798514e-35 6.4526099e-34], sampled 0.2604767237330192
[2019-03-24 08:18:01,927] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 754191.4761144624 W.
[2019-03-24 08:18:07,191] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022523863]
[2019-03-24 08:18:07,192] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.8, 60.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5130185548728281, 6.9112, 6.9112, 121.9260426156618, 372597.1801059901, 372597.1801059901, 118375.0188526483]
[2019-03-24 08:18:07,193] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:18:07,198] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 5.586686e-38], sampled 0.15609950260438266
[2019-03-24 08:18:16,042] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022523863]
[2019-03-24 08:18:16,043] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [20.91775410166667, 77.77978829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.853605436778048, 6.911200000000001, 6.9112, 121.9260426156618, 633737.5612794467, 633737.5612794462, 157037.7369906951]
[2019-03-24 08:18:16,044] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:18:16,047] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 4.8626120e-33 8.3488511e-37 5.4494237e-32 3.0664397e-31], sampled 0.8156764455869466
[2019-03-24 08:18:29,188] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022523863]
[2019-03-24 08:18:29,189] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.36666666666667, 86.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.912417944820674, 6.9112, 6.9112, 121.9260426156618, 668196.9893764633, 668196.9893764633, 177511.1644413038]
[2019-03-24 08:18:29,190] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:18:29,195] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.4957869e-38 0.0000000e+00 2.6379683e-37 2.0002352e-36], sampled 0.2617232578295401
[2019-03-24 08:18:45,737] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022523863]
[2019-03-24 08:18:45,738] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [31.66683463, 54.87472731333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9665517962512727, 6.9112, 6.9112, 121.9260426156618, 693211.5889007386, 693211.5889007386, 187017.5194563991]
[2019-03-24 08:18:45,739] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:18:45,741] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 3.245931e-38], sampled 0.39945426546947027
[2019-03-24 08:18:45,742] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 693211.5889007386 W.
[2019-03-24 08:18:58,524] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022523863]
[2019-03-24 08:18:58,525] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [21.47509011166667, 92.63039131666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9566833665025378, 6.932313844038153, 6.9112, 121.925865454087, 725072.4247982478, 714260.2652271072, 177564.0806373575]
[2019-03-24 08:18:58,527] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:18:58,529] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 2.1633804e-36 0.0000000e+00 3.2154586e-35 2.0816480e-34], sampled 0.5469202303689413
[2019-03-24 08:18:58,530] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 725072.4247982478 W.
[2019-03-24 08:19:21,737] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.022523863]
[2019-03-24 08:19:21,739] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.95, 93.0, 1.0, 2.0, 0.6442232481354949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 734201.8140354776, 734201.8140354776, 165852.5077151091]
[2019-03-24 08:19:21,740] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:19:21,744] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 9.2322029e-31 2.8222719e-34 7.8350043e-30 4.5650492e-29], sampled 0.6010434871064118
[2019-03-24 08:19:21,745] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 734201.8140354776 W.
[2019-03-24 08:19:35,457] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 08:19:35,836] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 08:19:35,897] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 08:19:36,007] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 08:19:36,015] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 08:19:37,033] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 2075000, evaluation results [2075000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 08:19:39,420] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 2.1624702e-31 8.9870303e-36 1.3418640e-30 4.1647599e-30], sum to 1.0000
[2019-03-24 08:19:39,422] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0272
[2019-03-24 08:19:39,431] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 793203.6512101679 W.
[2019-03-24 08:19:39,436] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.06666666666667, 58.83333333333334, 1.0, 2.0, 0.3479837328924882, 1.0, 2.0, 0.3479837328924882, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 793203.6512101679, 793203.6512101684, 192374.5093080551], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6354600.0000, 
sim time next is 6355200.0000, 
raw observation next is [31.13333333333333, 58.66666666666667, 1.0, 2.0, 0.2230463924556013, 1.0, 2.0, 0.2230463924556013, 1.0, 1.0, 0.3550971209031853, 6.9112, 6.9112, 121.94756008, 762611.8058675457, 762611.8058675457, 228270.9319398214], 
processed observation next is [0.0, 0.5652173913043478, 0.7086419753086418, 0.5866666666666667, 1.0, 1.0, 0.07505522911381106, 1.0, 1.0, 0.07505522911381106, 1.0, 0.5, 0.1938714011289816, 0.0, 0.0, 0.8096049824067558, 0.27236135923840915, 0.27236135923840915, 0.43898256142273345], 
reward next is 0.5610, 
noisyNet noise sample is [array([-0.2331345], dtype=float32), -0.9624777]. 
=============================================
[2019-03-24 08:19:41,296] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 9.7757960e-33 4.2071764e-35 1.9894811e-30 4.1897980e-28], sum to 1.0000
[2019-03-24 08:19:41,302] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6940
[2019-03-24 08:19:41,309] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 740203.2742919014 W.
[2019-03-24 08:19:41,313] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.8, 62.66666666666667, 1.0, 2.0, 0.6494866707118648, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 740203.2742919014, 740203.2742919014, 166800.3875535477], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6276000.0000, 
sim time next is 6276600.0000, 
raw observation next is [29.85, 62.5, 1.0, 2.0, 0.2172860992362984, 1.0, 1.0, 0.2172860992362984, 1.0, 1.0, 0.3459265464984019, 6.911200000000001, 6.9112, 121.94756008, 742907.4029153973, 742907.4029153968, 226324.444678133], 
processed observation next is [0.0, 0.6521739130434783, 0.6611111111111112, 0.625, 1.0, 1.0, 0.06819773718606953, 1.0, 0.5, 0.06819773718606953, 1.0, 0.5, 0.18240818312300233, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.26532407246978473, 0.26532407246978457, 0.4352393166887173], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.3066952], dtype=float32), 0.15127318]. 
=============================================
[2019-03-24 08:19:51,303] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.000000e+00 9.670771e-22 5.314201e-24 5.444571e-21 8.664265e-21], sum to 1.0000
[2019-03-24 08:19:51,309] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4312
[2019-03-24 08:19:51,315] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1633409.85863439 W.
[2019-03-24 08:19:51,325] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.4, 80.0, 1.0, 2.0, 0.8056680717304151, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.9260426156618, 1633409.85863439, 1633409.85863439, 337361.881048131], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6534000.0000, 
sim time next is 6534600.0000, 
raw observation next is [27.43333333333333, 79.83333333333334, 1.0, 2.0, 0.4711620047806325, 1.0, 1.0, 0.4711620047806325, 1.0, 2.0, 0.7501052562859951, 6.9112, 6.9112, 121.94756008, 1611824.878622025, 1611824.878622025, 329656.3549059342], 
processed observation next is [1.0, 0.6521739130434783, 0.5716049382716049, 0.7983333333333335, 1.0, 1.0, 0.37043095807218157, 1.0, 0.5, 0.37043095807218157, 1.0, 1.0, 0.6876315703574939, 0.0, 0.0, 0.8096049824067558, 0.5756517423650089, 0.5756517423650089, 0.633954528665258], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.10375913], dtype=float32), 0.14384352]. 
=============================================
[2019-03-24 08:19:57,283] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.4779884e-38 0.0000000e+00], sum to 1.0000
[2019-03-24 08:19:57,290] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6471
[2019-03-24 08:19:57,294] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.6, 48.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.760338164529831, 6.9112, 6.9112, 121.9260426156618, 562999.0103894902, 562999.0103894902, 145705.5509552161], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6579600.0000, 
sim time next is 6580200.0000, 
raw observation next is [25.6, 48.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7304469586063199, 6.911200000000001, 6.9112, 121.9260426156618, 540539.7301076353, 540539.7301076348, 142351.7912855183], 
processed observation next is [1.0, 0.13043478260869565, 0.5037037037037038, 0.4833333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6630586982578998, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19304990360986973, 0.19304990360986957, 0.27375344477984287], 
reward next is 0.7262, 
noisyNet noise sample is [array([1.0568215], dtype=float32), -0.4264019]. 
=============================================
[2019-03-24 08:20:00,579] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.0835312e-33 1.3546296e-37 5.0617370e-34 8.1428192e-32], sum to 1.0000
[2019-03-24 08:20:00,580] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3325
[2019-03-24 08:20:00,587] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 832510.5006604427 W.
[2019-03-24 08:20:00,592] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.78333333333333, 37.83333333333334, 1.0, 2.0, 0.3299949592157441, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5621787596405694, 6.911199999999999, 6.9112, 121.9260426156618, 832510.5006604427, 832510.5006604432, 198350.7114480021], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6691800.0000, 
sim time next is 6692400.0000, 
raw observation next is [27.0, 37.0, 1.0, 2.0, 0.3601183122308168, 1.0, 1.0, 0.3601183122308168, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 905593.5176126278, 905593.5176126283, 198458.3553251925], 
processed observation next is [1.0, 0.4782608695652174, 0.5555555555555556, 0.37, 1.0, 1.0, 0.23823608598906762, 1.0, 0.5, 0.23823608598906762, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3234262562902242, 0.32342625629022437, 0.3816506833176779], 
reward next is 0.6183, 
noisyNet noise sample is [array([-1.0775758], dtype=float32), 1.4793333]. 
=============================================
[2019-03-24 08:20:01,111] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 9.1255404e-33 8.9614825e-38 2.0654505e-32 1.5612026e-32], sum to 1.0000
[2019-03-24 08:20:01,119] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6687
[2019-03-24 08:20:01,126] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 817888.5092123813 W.
[2019-03-24 08:20:01,132] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.8, 31.0, 1.0, 2.0, 0.3256276000777431, 1.0, 2.0, 0.3256276000777431, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 817888.5092123813, 817888.5092123818, 189404.1039661845], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6699600.0000, 
sim time next is 6700200.0000, 
raw observation next is [28.95, 30.66666666666667, 1.0, 2.0, 0.1867634503861553, 1.0, 2.0, 0.1867634503861553, 1.0, 1.0, 0.3139055237082911, 6.9112, 6.9112, 121.94756008, 700974.3542782062, 700974.3542782062, 213515.9053002375], 
processed observation next is [1.0, 0.5652173913043478, 0.6277777777777778, 0.3066666666666667, 1.0, 1.0, 0.03186125045970869, 1.0, 1.0, 0.03186125045970869, 1.0, 0.5, 0.14238190463536388, 0.0, 0.0, 0.8096049824067558, 0.2503479836707879, 0.2503479836707879, 0.4106075101927644], 
reward next is 0.5894, 
noisyNet noise sample is [array([-0.7630782], dtype=float32), 0.4348167]. 
=============================================
[2019-03-24 08:20:02,995] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 2.0886179e-32 3.5829852e-36 1.3342675e-32 3.7738454e-30], sum to 1.0000
[2019-03-24 08:20:03,000] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2590
[2019-03-24 08:20:03,004] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1068222.939991082 W.
[2019-03-24 08:20:03,008] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.23333333333333, 43.66666666666667, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9750790971070178, 7.602113937648307, 6.9112, 121.9236805323094, 1068222.939991082, 714420.1051126431, 164801.0745448816], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6687600.0000, 
sim time next is 6688200.0000, 
raw observation next is [25.46666666666667, 42.83333333333333, 1.0, 1.0, 0.3853639727799239, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6583687297424239, 6.911199999999998, 6.9112, 121.9256265587048, 973757.0250139937, 973757.0250139947, 214006.4384362953], 
processed observation next is [1.0, 0.391304347826087, 0.4987654320987655, 0.4283333333333333, 1.0, 0.5, 0.2682904437856237, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5729609121780298, -1.7763568394002506e-16, 0.0, 0.8094593666346103, 0.3477703660764263, 0.34777036607642664, 0.41155084314672175], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5214342], dtype=float32), -0.38543868]. 
=============================================
[2019-03-24 08:20:05,116] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.5442269e-37], sum to 1.0000
[2019-03-24 08:20:05,119] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8981
[2019-03-24 08:20:05,123] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 843570.4476104314 W.
[2019-03-24 08:20:05,128] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.9, 49.5, 1.0, 2.0, 0.6857874195080633, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.92604252365, 843570.4476104314, 843570.4476104314, 175979.6054591722], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6784200.0000, 
sim time next is 6784800.0000, 
raw observation next is [27.0, 49.33333333333333, 1.0, 2.0, 0.8064795303008914, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000002, 6.9112, 121.9260426156338, 997376.5930838478, 997376.5930838468, 200519.6921324348], 
processed observation next is [1.0, 0.5217391304347826, 0.5555555555555556, 0.4933333333333333, 1.0, 1.0, 0.769618488453442, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 1.7763568394002506e-16, 0.0, 0.80946212881995, 0.3562059261013742, 0.35620592610137386, 0.38561479256237463], 
reward next is 0.6144, 
noisyNet noise sample is [array([1.3449159], dtype=float32), 0.7670556]. 
=============================================
[2019-03-24 08:20:08,756] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:20:08,764] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2152
[2019-03-24 08:20:08,775] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.83333333333334, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.632257242129019, 6.9112, 6.9112, 121.9260426156618, 470924.6257695958, 470924.6257695958, 134788.460707444], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6841200.0000, 
sim time next is 6841800.0000, 
raw observation next is [21.8, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6301369454416992, 6.9112, 6.9112, 121.9260426156618, 469256.3173579851, 469256.3173579851, 134494.0701076902], 
processed observation next is [0.0, 0.17391304347826086, 0.362962962962963, 0.76, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5376711818021239, 0.0, 0.0, 0.8094621288201359, 0.16759154191356612, 0.16759154191356612, 0.25864244251478885], 
reward next is 0.7414, 
noisyNet noise sample is [array([0.12552634], dtype=float32), 0.7096914]. 
=============================================
[2019-03-24 08:20:12,568] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:20:12,577] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6088
[2019-03-24 08:20:12,581] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.95, 81.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6861714129901094, 6.9112, 6.9112, 121.9260426156618, 512658.361617891, 512658.361617891, 142561.3067772582], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6924600.0000, 
sim time next is 6925200.0000, 
raw observation next is [21.86666666666667, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6851003310296235, 6.911200000000001, 6.9112, 121.9260426156618, 511845.703803802, 511845.7038038016, 142405.5076089894], 
processed observation next is [0.0, 0.13043478260869565, 0.36543209876543226, 0.82, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6063754137870294, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18280203707278644, 0.1828020370727863, 0.2738567454019027], 
reward next is 0.7261, 
noisyNet noise sample is [array([-1.5611285], dtype=float32), -0.3815283]. 
=============================================
[2019-03-24 08:20:17,206] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:20:17,216] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1679
[2019-03-24 08:20:17,219] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.0, 49.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9114187744212014, 6.9112, 6.9112, 121.9260426156618, 667550.7551293127, 667550.7551293127, 177359.4288296512], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6963000.0000, 
sim time next is 6963600.0000, 
raw observation next is [31.0, 50.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8972629680110097, 6.911200000000001, 6.9112, 121.9260426156618, 656211.5062457508, 656211.5062457504, 175672.0839729015], 
processed observation next is [0.0, 0.6086956521739131, 0.7037037037037037, 0.5, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.871578710013762, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2343612522306253, 0.23436125223062512, 0.3378309307171183], 
reward next is 0.6622, 
noisyNet noise sample is [array([0.23401274], dtype=float32), -1.399509]. 
=============================================
[2019-03-24 08:20:19,910] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:20:19,920] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5006
[2019-03-24 08:20:19,923] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.55, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7879345272015995, 6.9112, 6.9112, 121.9260426156618, 586136.9490772858, 586136.9490772858, 158356.9443129673], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7079400.0000, 
sim time next is 7080000.0000, 
raw observation next is [23.56666666666667, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7872684849844322, 6.9112, 6.9112, 121.9260426156618, 585574.7585487652, 585574.7585487652, 158314.2349654699], 
processed observation next is [1.0, 0.9565217391304348, 0.4283950617283952, 0.82, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7340856062305403, 0.0, 0.0, 0.8094621288201359, 0.20913384233884472, 0.20913384233884472, 0.30445045185667285], 
reward next is 0.6955, 
noisyNet noise sample is [array([-0.9946679], dtype=float32), -0.20896536]. 
=============================================
[2019-03-24 08:20:19,948] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[74.08079]
 [73.90339]
 [73.7382 ]
 [73.53382]
 [73.21953]], R is [[74.20384216]
 [74.15727234]
 [74.11122894]
 [74.0659256 ]
 [74.02150726]].
[2019-03-24 08:20:24,548] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:20:24,554] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6825
[2019-03-24 08:20:24,557] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.08333333333334, 78.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6128548690520593, 6.9112, 6.9112, 121.9260426156618, 455387.9376790201, 455387.9376790201, 131963.1122281569], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7152600.0000, 
sim time next is 7153200.0000, 
raw observation next is [20.9, 80.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6162216919576117, 6.911200000000001, 6.9112, 121.9260426156618, 457800.4138376751, 457800.4138376746, 132218.900881838], 
processed observation next is [1.0, 0.8260869565217391, 0.32962962962962955, 0.8, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5202771149470146, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1635001477991697, 0.1635001477991695, 0.2542671170804577], 
reward next is 0.7457, 
noisyNet noise sample is [array([-0.50662607], dtype=float32), 0.97464305]. 
=============================================
[2019-03-24 08:20:26,006] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-24 08:20:26,008] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:20:26,009] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:20:26,010] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:20:26,011] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:20:26,013] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:20:26,013] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:20:26,013] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:20:26,014] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:20:26,014] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:20:26,015] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:20:26,034] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run85
[2019-03-24 08:20:26,063] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run85
[2019-03-24 08:20:26,064] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run85
[2019-03-24 08:20:26,113] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run85
[2019-03-24 08:20:26,115] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run85
[2019-03-24 08:20:34,162] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.02298845]
[2019-03-24 08:20:34,164] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [16.18333333333333, 86.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4052503927620965, 6.9112, 6.9112, 121.9260426156618, 289339.9436403713, 289339.9436403713, 94974.61344311463]
[2019-03-24 08:20:34,168] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:20:34,171] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.1610102179299392
[2019-03-24 08:20:47,084] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.02298845]
[2019-03-24 08:20:47,085] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.75645361666667, 20.27148801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5983132074599737, 6.9112, 6.9112, 121.9260426156618, 427221.2563054871, 427221.2563054871, 118213.2912751219]
[2019-03-24 08:20:47,086] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:20:47,091] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.09385004514615614
[2019-03-24 08:21:04,432] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.02298845]
[2019-03-24 08:21:04,433] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [31.83333333333333, 47.33333333333333, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9237874038998206, 6.911200000000001, 6.9112, 121.9260426156618, 672647.1510512321, 672647.1510512317, 179763.8931838265]
[2019-03-24 08:21:04,433] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:21:04,437] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.9749464305661021
[2019-03-24 08:21:08,973] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.02298845]
[2019-03-24 08:21:08,974] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.64091109, 86.00016975, 1.0, 2.0, 0.8389894488860987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 956309.4611050747, 956309.4611050747, 204131.1179751004]
[2019-03-24 08:21:08,975] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:21:08,979] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.5971204020676945
[2019-03-24 08:21:08,981] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 956309.4611050747 W.
[2019-03-24 08:21:10,803] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.02298845]
[2019-03-24 08:21:10,806] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.25, 88.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6894877079791268, 6.9112, 6.9112, 121.9260426156618, 515212.96801879, 515212.96801879, 143254.999662507]
[2019-03-24 08:21:10,807] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:21:10,811] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.47932562087034136
[2019-03-24 08:21:13,472] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.02298845]
[2019-03-24 08:21:13,473] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.23333333333333, 98.50000000000001, 1.0, 2.0, 0.6896862700068765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 799706.8882846346, 799706.8882846346, 174872.2165600625]
[2019-03-24 08:21:13,474] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:21:13,479] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.3568429496140475
[2019-03-24 08:21:13,481] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 799706.8882846346 W.
[2019-03-24 08:21:39,250] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.02298845]
[2019-03-24 08:21:39,251] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.4, 85.0, 1.0, 2.0, 0.6143475667390514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 705876.7895116246, 705876.7895116241, 160845.3542501543]
[2019-03-24 08:21:39,252] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:21:39,256] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.9336259237005756
[2019-03-24 08:21:39,257] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 705876.7895116246 W.
[2019-03-24 08:22:06,491] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.02298845]
[2019-03-24 08:22:06,492] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [19.42434218333333, 90.46931685833334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6189671002077102, 6.911200000000001, 6.9112, 121.9260426156618, 460325.5033822221, 460325.5033822216, 132862.0758785491]
[2019-03-24 08:22:06,493] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:22:06,495] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.18048151296684067
[2019-03-24 08:22:11,615] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 08:22:11,687] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 08:22:11,786] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 08:22:11,829] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 08:22:11,927] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 08:22:12,944] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 2100000, evaluation results [2100000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 08:22:17,158] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:22:17,169] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8201
[2019-03-24 08:22:17,176] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.56666666666667, 62.33333333333334, 1.0, 2.0, 0.2327589808066071, 1.0, 1.0, 0.2327589808066071, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 553929.537002964, 553929.5370029644, 166233.2607684508], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7320000.0000, 
sim time next is 7320600.0000, 
raw observation next is [26.4, 63.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7385031787120139, 6.911199999999999, 6.9112, 121.9260426156618, 548827.9773185707, 548827.9773185712, 152705.0915137773], 
processed observation next is [1.0, 0.7391304347826086, 0.5333333333333333, 0.63, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.6731289733900172, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19600999189948953, 0.1960099918994897, 0.2936636375264948], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.4306705], dtype=float32), -2.191379]. 
=============================================
[2019-03-24 08:22:22,460] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:22:22,468] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5224
[2019-03-24 08:22:22,471] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.13333333333333, 72.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.622974804530405, 6.9112, 6.9112, 121.9260426156618, 463228.866198112, 463228.866198112, 133188.3734552425], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7770000.0000, 
sim time next is 7770600.0000, 
raw observation next is [22.0, 72.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6194652884858165, 6.911200000000001, 6.9112, 121.9260426156618, 460428.1532035113, 460428.1532035109, 132697.105600418], 
processed observation next is [1.0, 0.9565217391304348, 0.37037037037037035, 0.725, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5243316106072706, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16443862614411117, 0.16443862614411103, 0.2551867415392654], 
reward next is 0.7448, 
noisyNet noise sample is [array([0.47605285], dtype=float32), -0.93092376]. 
=============================================
[2019-03-24 08:22:25,275] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:22:25,281] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7030
[2019-03-24 08:22:25,286] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.33333333333333, 86.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6597317406394052, 6.9112, 6.9112, 121.9260426156618, 490905.4678988244, 490905.4678988244, 137101.1260399028], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7353600.0000, 
sim time next is 7354200.0000, 
raw observation next is [20.26666666666667, 87.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6536020549209346, 6.9112, 6.9112, 121.9260426156618, 486458.2937883403, 486458.2937883403, 136584.3995577675], 
processed observation next is [1.0, 0.08695652173913043, 0.3061728395061729, 0.8716666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5670025686511682, 0.0, 0.0, 0.8094621288201359, 0.17373510492440725, 0.17373510492440725, 0.2626623068418606], 
reward next is 0.7373, 
noisyNet noise sample is [array([-0.5634977], dtype=float32), -0.13740556]. 
=============================================
[2019-03-24 08:22:27,038] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.3808988e-38], sum to 1.0000
[2019-03-24 08:22:27,044] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2797
[2019-03-24 08:22:27,052] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1059712.853891144 W.
[2019-03-24 08:22:27,057] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.2, 89.0, 1.0, 2.0, 0.4389258723822313, 1.0, 1.0, 0.4389258723822313, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1059712.853891144, 1059712.853891144, 219595.1832778975], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7405200.0000, 
sim time next is 7405800.0000, 
raw observation next is [21.13333333333333, 89.16666666666667, 1.0, 2.0, 0.2540073089060187, 1.0, 2.0, 0.2540073089060187, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 615899.4700016781, 615899.4700016786, 171412.6685274065], 
processed observation next is [1.0, 0.7391304347826086, 0.33827160493827146, 0.8916666666666667, 1.0, 1.0, 0.11191346298335558, 1.0, 1.0, 0.11191346298335558, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21996409642917075, 0.21996409642917092, 0.3296397471680894], 
reward next is 0.6704, 
noisyNet noise sample is [array([0.9886824], dtype=float32), 0.6936875]. 
=============================================
[2019-03-24 08:22:28,101] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:22:28,108] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9413
[2019-03-24 08:22:28,112] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.33333333333334, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6315435452943309, 6.9112, 6.9112, 121.9260426156618, 469420.3639292245, 469420.3639292245, 133881.1993404438], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7882800.0000, 
sim time next is 7883400.0000, 
raw observation next is [20.46666666666667, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6272473593162975, 6.9112, 6.9112, 121.9260426156618, 466250.8473440806, 466250.8473440806, 133481.156309253], 
processed observation next is [1.0, 0.21739130434782608, 0.31358024691358033, 0.84, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5340591991453718, 0.0, 0.0, 0.8094621288201359, 0.16651815976574308, 0.16651815976574308, 0.2566945313639481], 
reward next is 0.7433, 
noisyNet noise sample is [array([0.9291854], dtype=float32), -0.4879833]. 
=============================================
[2019-03-24 08:22:32,668] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:22:32,668] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:22:32,686] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run11
[2019-03-24 08:22:34,092] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:22:34,099] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5337
[2019-03-24 08:22:34,112] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.8, 72.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.826968981823254, 6.9112, 6.9112, 121.9260426156618, 611275.6934671998, 611275.6934671998, 164905.9564594883], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7583400.0000, 
sim time next is 7584000.0000, 
raw observation next is [25.63333333333333, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8265637950984941, 6.911199999999999, 6.9112, 121.9260426156618, 611009.6162898673, 611009.6162898678, 164844.2744955154], 
processed observation next is [0.0, 0.782608695652174, 0.5049382716049381, 0.73, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7832047438731177, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21821772010352405, 0.21821772010352422, 0.31700822018368346], 
reward next is 0.6830, 
noisyNet noise sample is [array([-0.34745142], dtype=float32), -0.64798987]. 
=============================================
[2019-03-24 08:22:34,132] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[72.50055 ]
 [72.49244 ]
 [72.476685]
 [72.467545]
 [72.36424 ]], R is [[72.43282318]
 [72.39137268]
 [72.35031128]
 [72.30971527]
 [72.26959229]].
[2019-03-24 08:22:34,540] A3C_AGENT_WORKER-Thread-12 INFO:Local step 132500, global step 2111177: loss 7.1673
[2019-03-24 08:22:34,541] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 132500, global step 2111178: learning rate 0.0000
[2019-03-24 08:22:37,501] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:22:37,502] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:22:37,534] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run11
[2019-03-24 08:22:39,296] A3C_AGENT_WORKER-Thread-21 INFO:Local step 132500, global step 2113682: loss 7.3064
[2019-03-24 08:22:39,300] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 132500, global step 2113683: learning rate 0.0000
[2019-03-24 08:22:47,382] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.9174916e-38], sum to 1.0000
[2019-03-24 08:22:47,390] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3162
[2019-03-24 08:22:47,397] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 852574.2745041958 W.
[2019-03-24 08:22:47,402] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.7, 37.0, 1.0, 2.0, 0.2338875428486693, 1.0, 2.0, 0.2338875428486693, 1.0, 1.0, 0.3807720527335241, 6.9112, 6.9112, 121.94756008, 852574.2745041958, 852574.2745041958, 230911.5762893636], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7821000.0000, 
sim time next is 7821600.0000, 
raw observation next is [29.8, 36.33333333333334, 1.0, 2.0, 0.3663391297161198, 0.0, 1.0, 0.0, 1.0, 2.0, 0.601196554243975, 6.9112, 6.9112, 121.9260426156618, 898699.2945783989, 898699.2945783989, 211183.6285642309], 
processed observation next is [1.0, 0.5217391304347826, 0.6592592592592593, 0.36333333333333345, 1.0, 1.0, 0.24564182109061883, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.5014956928049688, 0.0, 0.0, 0.8094621288201359, 0.3209640337779996, 0.3209640337779996, 0.40612236262352097], 
reward next is 0.5939, 
noisyNet noise sample is [array([0.03315321], dtype=float32), 2.2830815]. 
=============================================
[2019-03-24 08:22:49,327] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:22:49,328] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:22:49,378] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run11
[2019-03-24 08:22:49,682] A3C_AGENT_WORKER-Thread-12 INFO:Local step 133000, global step 2118967: loss 0.0152
[2019-03-24 08:22:49,689] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 133000, global step 2118969: learning rate 0.0000
[2019-03-24 08:22:50,252] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:22:50,253] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:22:50,293] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run11
[2019-03-24 08:22:51,042] A3C_AGENT_WORKER-Thread-3 INFO:Local step 132500, global step 2119701: loss 4.2718
[2019-03-24 08:22:51,045] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 132500, global step 2119702: learning rate 0.0000
[2019-03-24 08:22:52,130] A3C_AGENT_WORKER-Thread-15 INFO:Local step 132500, global step 2120285: loss 3.3510
[2019-03-24 08:22:52,131] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 132500, global step 2120285: learning rate 0.0000
[2019-03-24 08:22:52,195] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.00000000e+00 2.34053658e-37 0.00000000e+00 1.23633026e-36
 1.74390424e-36], sum to 1.0000
[2019-03-24 08:22:52,201] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6729
[2019-03-24 08:22:52,205] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.16666666666667, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5086241913503703, 6.911199999999999, 6.9112, 121.9260426156618, 363164.055985422, 363164.0559854225, 110112.7284844288], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 13200.0000, 
sim time next is 13800.0000, 
raw observation next is [18.13333333333334, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4993495425639302, 6.911200000000001, 6.9112, 121.9260426156618, 356540.3010203586, 356540.3010203582, 109038.710709725], 
processed observation next is [1.0, 0.13043478260869565, 0.22716049382716075, 0.76, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3741869282049127, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1273358217929852, 0.12733582179298508, 0.2096898282879327], 
reward next is 0.7903, 
noisyNet noise sample is [array([0.29630154], dtype=float32), -3.0980225]. 
=============================================
[2019-03-24 08:22:52,701] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:22:52,701] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:22:52,717] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run11
[2019-03-24 08:22:53,033] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:22:53,034] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:22:53,067] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run11
[2019-03-24 08:22:53,153] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:22:53,153] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:22:53,184] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run11
[2019-03-24 08:22:53,408] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:22:53,416] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8660
[2019-03-24 08:22:53,421] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.6, 30.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5677456200456463, 6.9112, 6.9112, 121.9260426156618, 405388.655299316, 405388.655299316, 115668.6235319195], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 302400.0000, 
sim time next is 303000.0000, 
raw observation next is [26.7, 30.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5773364406843375, 6.9112, 6.9112, 121.9260426156618, 412238.6507264663, 412238.6507264663, 117507.1809514926], 
processed observation next is [0.0, 0.5217391304347826, 0.5444444444444444, 0.3016666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.47167055085542187, 0.0, 0.0, 0.8094621288201359, 0.14722808954516656, 0.14722808954516656, 0.2259753479836396], 
reward next is 0.7740, 
noisyNet noise sample is [array([-0.32213956], dtype=float32), 0.82601416]. 
=============================================
[2019-03-24 08:22:53,437] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[78.17358 ]
 [78.133644]
 [78.17533 ]
 [78.2429  ]
 [78.257744]], R is [[78.11720276]
 [78.11358643]
 [78.11191559]
 [78.1121521 ]
 [78.11428833]].
[2019-03-24 08:22:53,519] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:22:53,519] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:22:53,550] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:22:53,552] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:22:53,557] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run11
[2019-03-24 08:22:53,622] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run11
[2019-03-24 08:22:53,656] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:22:53,662] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:22:53,676] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run11
[2019-03-24 08:22:53,791] A3C_AGENT_WORKER-Thread-21 INFO:Local step 133000, global step 2121000: loss 0.0021
[2019-03-24 08:22:53,792] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 133000, global step 2121000: learning rate 0.0000
[2019-03-24 08:22:54,191] A3C_AGENT_WORKER-Thread-2 INFO:Local step 132500, global step 2121217: loss 2.7258
[2019-03-24 08:22:54,191] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 132500, global step 2121217: learning rate 0.0000
[2019-03-24 08:22:54,375] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:22:54,375] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:22:54,398] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run11
[2019-03-24 08:22:54,632] A3C_AGENT_WORKER-Thread-11 INFO:Local step 132500, global step 2121440: loss 2.3946
[2019-03-24 08:22:54,637] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 132500, global step 2121440: learning rate 0.0000
[2019-03-24 08:22:54,666] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:22:54,666] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:22:54,680] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run11
[2019-03-24 08:22:54,721] A3C_AGENT_WORKER-Thread-22 INFO:Local step 132500, global step 2121472: loss 2.2272
[2019-03-24 08:22:54,725] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 132500, global step 2121472: learning rate 0.0000
[2019-03-24 08:22:54,760] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:22:54,760] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:22:54,768] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run11
[2019-03-24 08:22:55,111] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:22:55,114] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:22:55,142] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run11
[2019-03-24 08:22:55,171] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:22:55,172] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:22:55,205] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run11
[2019-03-24 08:22:55,262] A3C_AGENT_WORKER-Thread-9 INFO:Local step 132500, global step 2121681: loss 1.9251
[2019-03-24 08:22:55,264] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 132500, global step 2121681: learning rate 0.0000
[2019-03-24 08:22:55,326] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:22:55,326] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:22:55,334] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run11
[2019-03-24 08:22:55,465] A3C_AGENT_WORKER-Thread-14 INFO:Local step 132500, global step 2121766: loss 2.1631
[2019-03-24 08:22:55,468] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 132500, global step 2121766: learning rate 0.0000
[2019-03-24 08:22:55,599] A3C_AGENT_WORKER-Thread-16 INFO:Local step 132500, global step 2121827: loss 2.1272
[2019-03-24 08:22:55,601] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 132500, global step 2121827: learning rate 0.0000
[2019-03-24 08:22:55,994] A3C_AGENT_WORKER-Thread-18 INFO:Local step 132500, global step 2122047: loss 1.7775
[2019-03-24 08:22:55,996] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 132500, global step 2122047: learning rate 0.0000
[2019-03-24 08:22:56,308] A3C_AGENT_WORKER-Thread-10 INFO:Local step 132500, global step 2122234: loss 1.4486
[2019-03-24 08:22:56,313] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 132500, global step 2122234: learning rate 0.0000
[2019-03-24 08:22:56,430] A3C_AGENT_WORKER-Thread-19 INFO:Local step 132500, global step 2122303: loss 1.3701
[2019-03-24 08:22:56,430] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 132500, global step 2122303: learning rate 0.0000
[2019-03-24 08:22:56,908] A3C_AGENT_WORKER-Thread-20 INFO:Local step 132500, global step 2122564: loss 1.0637
[2019-03-24 08:22:56,911] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 132500, global step 2122565: learning rate 0.0000
[2019-03-24 08:22:57,022] A3C_AGENT_WORKER-Thread-17 INFO:Local step 132500, global step 2122618: loss 1.1014
[2019-03-24 08:22:57,024] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 132500, global step 2122618: learning rate 0.0000
[2019-03-24 08:22:57,175] A3C_AGENT_WORKER-Thread-13 INFO:Local step 132500, global step 2122695: loss 1.6548
[2019-03-24 08:22:57,177] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 132500, global step 2122695: learning rate 0.0000
[2019-03-24 08:22:58,837] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:22:58,844] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4546
[2019-03-24 08:22:58,852] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1486019.685196415 W.
[2019-03-24 08:22:58,858] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.0, 37.0, 1.0, 2.0, 0.6341112909732363, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9569063499531139, 6.911199999999999, 6.9112, 121.9260426156618, 1486019.685196415, 1486019.685196415, 294183.7534927558], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 54000.0000, 
sim time next is 54600.0000, 
raw observation next is [29.98333333333333, 37.16666666666667, 1.0, 2.0, 0.5302474631858869, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8643708641876509, 6.911199999999999, 6.9112, 121.9260426156618, 1291107.116998773, 1291107.116998774, 265025.248138429], 
processed observation next is [1.0, 0.6521739130434783, 0.6660493827160493, 0.3716666666666667, 1.0, 1.0, 0.4407707895070082, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8304635802345636, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.46110968464241897, 0.4611096846424193, 0.5096639387277481], 
reward next is 0.4903, 
noisyNet noise sample is [array([0.39636645], dtype=float32), 0.3661823]. 
=============================================
[2019-03-24 08:23:01,878] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-24 08:23:01,880] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:23:01,881] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:23:01,882] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:23:01,885] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:23:01,887] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:23:01,888] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:23:01,888] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:23:01,890] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:23:01,891] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:23:01,891] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:23:01,910] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run86
[2019-03-24 08:23:01,941] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run86
[2019-03-24 08:23:01,942] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run86
[2019-03-24 08:23:01,942] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run86
[2019-03-24 08:23:01,942] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run86
[2019-03-24 08:23:37,822] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.023786552]
[2019-03-24 08:23:37,823] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [33.26666666666667, 33.66666666666666, 1.0, 2.0, 0.8650593077902743, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9699151796451215, 6.911200000000001, 6.9112, 121.9260426156618, 1736249.673626621, 1736249.67362662, 344297.7482981486]
[2019-03-24 08:23:37,824] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:23:37,829] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.7906731941654505
[2019-03-24 08:23:37,830] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1736249.673626621 W.
[2019-03-24 08:23:38,225] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.023786552]
[2019-03-24 08:23:38,227] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.7783434, 50.92684934, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8177703983157315, 6.911200000000001, 6.9112, 121.9260426156618, 605136.2180603424, 605136.2180603419, 163509.9339787964]
[2019-03-24 08:23:38,228] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:23:38,231] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.06271139420226768
[2019-03-24 08:23:48,779] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.023786552]
[2019-03-24 08:23:48,782] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [29.98609522333333, 62.49290363166666, 1.0, 2.0, 0.6532952775388682, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 744545.9536792933, 744545.9536792933, 167489.8539276661]
[2019-03-24 08:23:48,784] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:23:48,787] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.8943128e-38 2.4016227e-37], sampled 0.3707029711946319
[2019-03-24 08:23:48,788] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 744545.9536792933 W.
[2019-03-24 08:23:49,057] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.023786552]
[2019-03-24 08:23:49,060] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.1, 87.0, 1.0, 2.0, 0.7833182056393195, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 900901.8779115956, 900901.8779115956, 192934.3025829533]
[2019-03-24 08:23:49,062] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:23:49,064] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 6.0025287e-34 3.0191661e-37 7.2027770e-33 4.5282902e-32], sampled 0.08615611716971439
[2019-03-24 08:23:49,066] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 900901.8779115956 W.
[2019-03-24 08:24:02,476] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.023786552]
[2019-03-24 08:24:02,477] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.0, 100.0, 1.0, 2.0, 0.6560855296817246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 747727.4923592726, 747727.4923592721, 167995.074213821]
[2019-03-24 08:24:02,479] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:24:02,483] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.2141166e-35 0.0000000e+00 1.5360356e-34 1.0781958e-33], sampled 0.7450558682678406
[2019-03-24 08:24:02,484] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 747727.4923592726 W.
[2019-03-24 08:24:20,700] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.023786552]
[2019-03-24 08:24:20,701] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.6, 95.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8619275886657339, 6.9112, 6.9112, 121.9260426156618, 636104.9230310883, 636104.9230310883, 169632.9742956282]
[2019-03-24 08:24:20,703] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:24:20,707] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.8632660044160786
[2019-03-24 08:24:21,619] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.023786552]
[2019-03-24 08:24:21,620] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8864253176060233, 6.9112, 6.9112, 121.9260426156618, 650073.9902788935, 650073.9902788935, 173863.4743425449]
[2019-03-24 08:24:21,621] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:24:21,624] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.000000e+00 0.000000e+00 0.000000e+00 7.036256e-38 5.504672e-37], sampled 0.06932426579496698
[2019-03-24 08:24:47,052] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 08:24:47,221] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 08:24:47,433] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 08:24:47,435] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 08:24:47,475] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 08:24:48,489] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 2125000, evaluation results [2125000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 08:24:48,605] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:24:48,606] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3631
[2019-03-24 08:24:48,611] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [33.05, 13.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6710122389091843, 6.9112, 6.9112, 121.9260426156618, 479147.3829352704, 479147.3829352704, 127082.60904995], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 156600.0000, 
sim time next is 157200.0000, 
raw observation next is [32.76666666666667, 14.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6665555907611509, 6.911200000000001, 6.9112, 121.9260426156618, 475964.0519821966, 475964.0519821961, 126462.9368568816], 
processed observation next is [1.0, 0.8260869565217391, 0.769135802469136, 0.14, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5831944884514386, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16998716142221307, 0.1699871614222129, 0.24319795549400308], 
reward next is 0.7568, 
noisyNet noise sample is [array([0.0116833], dtype=float32), 0.2381922]. 
=============================================
[2019-03-24 08:24:49,179] A3C_AGENT_WORKER-Thread-12 INFO:Local step 133500, global step 2125350: loss 0.0985
[2019-03-24 08:24:49,180] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 133500, global step 2125351: learning rate 0.0000
[2019-03-24 08:24:50,401] A3C_AGENT_WORKER-Thread-3 INFO:Local step 133000, global step 2125985: loss 0.0015
[2019-03-24 08:24:50,402] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 133000, global step 2125985: learning rate 0.0000
[2019-03-24 08:24:50,673] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:24:50,705] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8158
[2019-03-24 08:24:50,711] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.23333333333333, 11.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6418072096868641, 6.911199999999999, 6.9112, 121.9260426156618, 458286.8171439078, 458286.8171439083, 113765.2129151091], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 166200.0000, 
sim time next is 166800.0000, 
raw observation next is [31.16666666666667, 11.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6406821273726322, 6.911199999999999, 6.9112, 121.9260426156618, 457483.2047960588, 457483.2047960592, 113025.5174408313], 
processed observation next is [1.0, 0.9565217391304348, 0.7098765432098767, 0.1133333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5508526592157902, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16338685885573528, 0.16338685885573542, 0.21735676430929096], 
reward next is 0.7826, 
noisyNet noise sample is [array([-2.324063], dtype=float32), 1.011357]. 
=============================================
[2019-03-24 08:24:51,666] A3C_AGENT_WORKER-Thread-15 INFO:Local step 133000, global step 2126640: loss 0.0100
[2019-03-24 08:24:51,668] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 133000, global step 2126641: learning rate 0.0000
[2019-03-24 08:24:51,908] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:24:51,917] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5246
[2019-03-24 08:24:51,922] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [33.1, 13.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6732920729718485, 6.9112, 6.9112, 121.9260426156618, 481007.7906979043, 481007.7906979043, 128745.7770284046], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 222600.0000, 
sim time next is 223200.0000, 
raw observation next is [33.3, 13.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6766962069534387, 6.9112, 6.9112, 121.9260426156618, 483225.5931543391, 483225.5931543391, 127787.563014626], 
processed observation next is [0.0, 0.6086956521739131, 0.7888888888888888, 0.13, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5958702586917983, 0.0, 0.0, 0.8094621288201359, 0.17258056898369253, 0.17258056898369253, 0.24574531348966538], 
reward next is 0.7543, 
noisyNet noise sample is [array([-1.2738733], dtype=float32), -0.31934127]. 
=============================================
[2019-03-24 08:24:52,054] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:24:52,065] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9577
[2019-03-24 08:24:52,069] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.06666666666667, 56.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4447411830289272, 6.911199999999999, 6.9112, 121.9260426156618, 317541.343493779, 317541.3434937794, 97294.4931599919], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 192000.0000, 
sim time next is 192600.0000, 
raw observation next is [20.25, 57.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4472671453639023, 6.911200000000001, 6.9112, 121.9260426156618, 319345.2341425893, 319345.2341425888, 99689.70034969428], 
processed observation next is [0.0, 0.21739130434782608, 0.3055555555555556, 0.57, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3090839317048778, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.11405186933663905, 0.11405186933663886, 0.19171096221095055], 
reward next is 0.8083, 
noisyNet noise sample is [array([0.8986363], dtype=float32), -0.12490463]. 
=============================================
[2019-03-24 08:24:53,176] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:24:53,184] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2574
[2019-03-24 08:24:53,193] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [33.34999999999999, 13.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6811945783753443, 6.911199999999999, 6.9112, 121.9260426156618, 486420.5655855506, 486420.565585551, 129850.6577482379], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 225000.0000, 
sim time next is 225600.0000, 
raw observation next is [33.36666666666667, 13.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6818299609688142, 6.9112, 6.9112, 121.9260426156618, 487123.8338677238, 487123.8338677238, 130210.5254146071], 
processed observation next is [0.0, 0.6086956521739131, 0.7913580246913581, 0.1366666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6022874512110177, 0.0, 0.0, 0.8094621288201359, 0.17397279780990135, 0.17397279780990135, 0.2504048565665521], 
reward next is 0.7496, 
noisyNet noise sample is [array([-1.4354167], dtype=float32), 0.37067926]. 
=============================================
[2019-03-24 08:24:54,099] A3C_AGENT_WORKER-Thread-21 INFO:Local step 133500, global step 2127911: loss 0.3513
[2019-03-24 08:24:54,099] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 133500, global step 2127911: learning rate 0.0000
[2019-03-24 08:24:54,870] A3C_AGENT_WORKER-Thread-2 INFO:Local step 133000, global step 2128310: loss 0.0044
[2019-03-24 08:24:54,874] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 133000, global step 2128313: learning rate 0.0000
[2019-03-24 08:24:56,224] A3C_AGENT_WORKER-Thread-11 INFO:Local step 133000, global step 2129012: loss 0.0196
[2019-03-24 08:24:56,227] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 133000, global step 2129012: learning rate 0.0000
[2019-03-24 08:24:56,466] A3C_AGENT_WORKER-Thread-22 INFO:Local step 133000, global step 2129135: loss 0.0614
[2019-03-24 08:24:56,471] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 133000, global step 2129135: learning rate 0.0000
[2019-03-24 08:24:56,855] A3C_AGENT_WORKER-Thread-9 INFO:Local step 133000, global step 2129339: loss 0.0040
[2019-03-24 08:24:56,857] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 133000, global step 2129339: learning rate 0.0000
[2019-03-24 08:24:57,175] A3C_AGENT_WORKER-Thread-14 INFO:Local step 133000, global step 2129507: loss 0.0400
[2019-03-24 08:24:57,177] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 133000, global step 2129507: learning rate 0.0000
[2019-03-24 08:24:57,435] A3C_AGENT_WORKER-Thread-16 INFO:Local step 133000, global step 2129643: loss 0.0015
[2019-03-24 08:24:57,444] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 133000, global step 2129643: learning rate 0.0000
[2019-03-24 08:24:57,993] A3C_AGENT_WORKER-Thread-18 INFO:Local step 133000, global step 2129932: loss 0.0031
[2019-03-24 08:24:57,996] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 133000, global step 2129932: learning rate 0.0000
[2019-03-24 08:24:58,470] A3C_AGENT_WORKER-Thread-10 INFO:Local step 133000, global step 2130182: loss 0.0241
[2019-03-24 08:24:58,474] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 133000, global step 2130182: learning rate 0.0000
[2019-03-24 08:24:58,639] A3C_AGENT_WORKER-Thread-19 INFO:Local step 133000, global step 2130268: loss 0.0011
[2019-03-24 08:24:58,641] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 133000, global step 2130268: learning rate 0.0000
[2019-03-24 08:24:58,949] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 5.3445361e-38 3.2314547e-36], sum to 1.0000
[2019-03-24 08:24:58,957] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1015
[2019-03-24 08:24:58,964] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.36666666666667, 49.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5405747472628124, 6.9112, 6.9112, 121.9260426156618, 390191.9027488406, 390191.9027488406, 119701.4320572867], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 706800.0000, 
sim time next is 707400.0000, 
raw observation next is [23.2, 50.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5265463445117445, 6.911200000000001, 6.9112, 121.9260426156618, 379998.5811926209, 379998.5811926204, 118548.7738895071], 
processed observation next is [1.0, 0.17391304347826086, 0.4148148148148148, 0.505, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.40818293063968064, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.13571377899736461, 0.13571377899736442, 0.22797841132597518], 
reward next is 0.7720, 
noisyNet noise sample is [array([2.8799536], dtype=float32), 0.6068636]. 
=============================================
[2019-03-24 08:24:59,277] A3C_AGENT_WORKER-Thread-20 INFO:Local step 133000, global step 2130599: loss 0.0010
[2019-03-24 08:24:59,279] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 133000, global step 2130599: learning rate 0.0000
[2019-03-24 08:24:59,572] A3C_AGENT_WORKER-Thread-17 INFO:Local step 133000, global step 2130752: loss 0.0038
[2019-03-24 08:24:59,574] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 133000, global step 2130752: learning rate 0.0000
[2019-03-24 08:24:59,698] A3C_AGENT_WORKER-Thread-13 INFO:Local step 133000, global step 2130820: loss 0.0151
[2019-03-24 08:24:59,701] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 133000, global step 2130821: learning rate 0.0000
[2019-03-24 08:25:04,733] A3C_AGENT_WORKER-Thread-12 INFO:Local step 134000, global step 2133444: loss 0.0081
[2019-03-24 08:25:04,734] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 134000, global step 2133444: learning rate 0.0000
[2019-03-24 08:25:05,891] A3C_AGENT_WORKER-Thread-3 INFO:Local step 133500, global step 2134050: loss 0.0062
[2019-03-24 08:25:05,892] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 133500, global step 2134050: learning rate 0.0000
[2019-03-24 08:25:07,161] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:25:07,168] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9594
[2019-03-24 08:25:07,175] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.55, 29.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6123655687681343, 6.911199999999999, 6.9112, 121.9260426156618, 452962.0783216755, 452962.078321676, 130547.7878595321], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 498600.0000, 
sim time next is 499200.0000, 
raw observation next is [30.3, 30.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6061150396237337, 6.911200000000001, 6.9112, 121.9260426156618, 448567.9705709944, 448567.9705709939, 130100.4194091397], 
processed observation next is [1.0, 0.782608695652174, 0.6777777777777778, 0.3, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5076437995296671, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.160202846632498, 0.16020284663249781, 0.25019311424834556], 
reward next is 0.7498, 
noisyNet noise sample is [array([-0.00976175], dtype=float32), 1.8806846]. 
=============================================
[2019-03-24 08:25:07,306] A3C_AGENT_WORKER-Thread-15 INFO:Local step 133500, global step 2134771: loss 0.4065
[2019-03-24 08:25:07,309] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 133500, global step 2134775: learning rate 0.0000
[2019-03-24 08:25:09,331] A3C_AGENT_WORKER-Thread-21 INFO:Local step 134000, global step 2135821: loss 0.0043
[2019-03-24 08:25:09,332] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 134000, global step 2135821: learning rate 0.0000
[2019-03-24 08:25:10,141] A3C_AGENT_WORKER-Thread-2 INFO:Local step 133500, global step 2136246: loss 0.0108
[2019-03-24 08:25:10,143] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 133500, global step 2136247: learning rate 0.0000
[2019-03-24 08:25:11,906] A3C_AGENT_WORKER-Thread-11 INFO:Local step 133500, global step 2137159: loss 0.1749
[2019-03-24 08:25:11,907] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 133500, global step 2137159: learning rate 0.0000
[2019-03-24 08:25:11,964] A3C_AGENT_WORKER-Thread-22 INFO:Local step 133500, global step 2137186: loss 0.1776
[2019-03-24 08:25:11,966] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 133500, global step 2137188: learning rate 0.0000
[2019-03-24 08:25:12,305] A3C_AGENT_WORKER-Thread-9 INFO:Local step 133500, global step 2137363: loss 0.1881
[2019-03-24 08:25:12,310] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 133500, global step 2137364: learning rate 0.0000
[2019-03-24 08:25:12,884] A3C_AGENT_WORKER-Thread-16 INFO:Local step 133500, global step 2137671: loss 0.0609
[2019-03-24 08:25:12,885] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 133500, global step 2137671: learning rate 0.0000
[2019-03-24 08:25:12,919] A3C_AGENT_WORKER-Thread-14 INFO:Local step 133500, global step 2137687: loss 0.0962
[2019-03-24 08:25:12,922] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 133500, global step 2137687: learning rate 0.0000
[2019-03-24 08:25:13,419] A3C_AGENT_WORKER-Thread-18 INFO:Local step 133500, global step 2137942: loss 0.2217
[2019-03-24 08:25:13,422] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 133500, global step 2137942: learning rate 0.0000
[2019-03-24 08:25:13,755] A3C_AGENT_WORKER-Thread-10 INFO:Local step 133500, global step 2138115: loss 0.0404
[2019-03-24 08:25:13,757] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 133500, global step 2138115: learning rate 0.0000
[2019-03-24 08:25:13,894] A3C_AGENT_WORKER-Thread-19 INFO:Local step 133500, global step 2138187: loss 0.0654
[2019-03-24 08:25:13,895] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 133500, global step 2138187: learning rate 0.0000
[2019-03-24 08:25:14,726] A3C_AGENT_WORKER-Thread-20 INFO:Local step 133500, global step 2138615: loss 0.4066
[2019-03-24 08:25:14,728] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 133500, global step 2138616: learning rate 0.0000
[2019-03-24 08:25:14,983] A3C_AGENT_WORKER-Thread-17 INFO:Local step 133500, global step 2138748: loss 0.1020
[2019-03-24 08:25:14,988] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 133500, global step 2138749: learning rate 0.0000
[2019-03-24 08:25:15,036] A3C_AGENT_WORKER-Thread-13 INFO:Local step 133500, global step 2138776: loss 0.0314
[2019-03-24 08:25:15,038] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 133500, global step 2138776: learning rate 0.0000
[2019-03-24 08:25:15,453] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.4384685e-37 0.0000000e+00 3.5698370e-34 1.2602694e-33], sum to 1.0000
[2019-03-24 08:25:15,462] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0232
[2019-03-24 08:25:15,466] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.03333333333333, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5473977836426978, 6.911199999999999, 6.9112, 121.9260426156618, 398861.2292857512, 398861.2292857517, 121699.9577830677], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 620400.0000, 
sim time next is 621000.0000, 
raw observation next is [20.85, 68.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5430986749146617, 6.911200000000001, 6.9112, 121.9260426156618, 395514.2240803881, 395514.2240803877, 121252.6013658842], 
processed observation next is [1.0, 0.17391304347826086, 0.32777777777777783, 0.68, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4288733436433271, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14125508002871004, 0.14125508002870987, 0.23317807954977732], 
reward next is 0.7668, 
noisyNet noise sample is [array([0.3156156], dtype=float32), -0.21538384]. 
=============================================
[2019-03-24 08:25:15,491] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[58.75375 ]
 [58.833946]
 [58.29063 ]
 [58.72249 ]
 [58.90643 ]], R is [[59.31210327]
 [59.48494339]
 [59.65257263]
 [59.80932617]
 [59.96059036]].
[2019-03-24 08:25:19,967] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:25:19,974] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9650
[2019-03-24 08:25:19,980] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.26666666666667, 58.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5634548317860715, 6.9112, 6.9112, 121.9260426156618, 415059.6748664608, 415059.6748664608, 125108.5686451104], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 801600.0000, 
sim time next is 802200.0000, 
raw observation next is [23.33333333333333, 58.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5678124810341437, 6.9112, 6.9112, 121.9260426156618, 418698.7183731867, 418698.7183731867, 125718.6227809744], 
processed observation next is [0.0, 0.2608695652173913, 0.4197530864197529, 0.5883333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4597656012926796, 0.0, 0.0, 0.8094621288201359, 0.1495352565618524, 0.1495352565618524, 0.24176658227110462], 
reward next is 0.7582, 
noisyNet noise sample is [array([1.3121184], dtype=float32), -0.23081225]. 
=============================================
[2019-03-24 08:25:20,000] A3C_AGENT_WORKER-Thread-12 INFO:Local step 134500, global step 2141357: loss 29.0710
[2019-03-24 08:25:20,004] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 134500, global step 2141358: learning rate 0.0000
[2019-03-24 08:25:20,016] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.3705018e-38 5.1903705e-37], sum to 1.0000
[2019-03-24 08:25:20,020] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2010
[2019-03-24 08:25:20,025] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.53333333333333, 48.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.593890767766682, 6.911200000000001, 6.9112, 121.9260426156618, 428747.2011372604, 428747.20113726, 124153.2610608629], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 706200.0000, 
sim time next is 706800.0000, 
raw observation next is [23.36666666666667, 49.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5405747472570095, 6.9112, 6.9112, 121.9260426156618, 390191.9027488406, 390191.9027488406, 119701.4320583403], 
processed observation next is [1.0, 0.17391304347826086, 0.4209876543209878, 0.4966666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4257184340712618, 0.0, 0.0, 0.8094621288201359, 0.1393542509817288, 0.1393542509817288, 0.23019506165065443], 
reward next is 0.7698, 
noisyNet noise sample is [array([-1.6222466], dtype=float32), 0.64094055]. 
=============================================
[2019-03-24 08:25:21,053] A3C_AGENT_WORKER-Thread-3 INFO:Local step 134000, global step 2141870: loss 0.0628
[2019-03-24 08:25:21,055] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 134000, global step 2141870: learning rate 0.0000
[2019-03-24 08:25:22,567] A3C_AGENT_WORKER-Thread-15 INFO:Local step 134000, global step 2142608: loss 0.0727
[2019-03-24 08:25:22,569] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 134000, global step 2142609: learning rate 0.0000
[2019-03-24 08:25:23,023] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:25:23,031] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2861
[2019-03-24 08:25:23,035] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.8, 36.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.72093816513979, 6.9112, 6.9112, 121.9260426156618, 538263.2760473841, 538263.2760473841, 148646.3754300961], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 826200.0000, 
sim time next is 826800.0000, 
raw observation next is [31.73333333333333, 36.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7180039543460496, 6.911200000000001, 6.9112, 121.9260426156618, 536153.3300571903, 536153.3300571898, 148186.2870138104], 
processed observation next is [0.0, 0.5652173913043478, 0.7308641975308641, 0.36, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6475049429325619, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19148333216328223, 0.19148333216328206, 0.28497362887271227], 
reward next is 0.7150, 
noisyNet noise sample is [array([-2.5753279], dtype=float32), -1.9833531]. 
=============================================
[2019-03-24 08:25:23,149] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:25:23,160] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8864
[2019-03-24 08:25:23,166] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.8, 52.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4999962773617797, 6.911199999999999, 6.9112, 121.9260426156618, 360203.8783045569, 360203.8783045574, 116225.4293405314], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 950400.0000, 
sim time next is 951000.0000, 
raw observation next is [22.66666666666667, 52.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4986815544843628, 6.911200000000001, 6.9112, 121.9260426156618, 358913.9781439044, 358913.978143904, 116000.5908430403], 
processed observation next is [1.0, 0.0, 0.39506172839506193, 0.5233333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.37335194310545344, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12818356362282302, 0.12818356362282285, 0.22307805931353905], 
reward next is 0.7769, 
noisyNet noise sample is [array([-1.6525751], dtype=float32), 0.55597293]. 
=============================================
[2019-03-24 08:25:23,193] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[70.487076]
 [75.59131 ]
 [75.54578 ]
 [75.5057  ]
 [75.44444 ]], R is [[67.29104614]
 [67.3946228 ]
 [67.49677277]
 [67.59738922]
 [67.6964035 ]].
[2019-03-24 08:25:24,830] A3C_AGENT_WORKER-Thread-21 INFO:Local step 134500, global step 2143706: loss 34.8978
[2019-03-24 08:25:24,834] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 134500, global step 2143707: learning rate 0.0000
[2019-03-24 08:25:25,388] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.8820663e-37], sum to 1.0000
[2019-03-24 08:25:25,396] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3004
[2019-03-24 08:25:25,404] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.03333333333333, 88.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5863377930101583, 6.911200000000001, 6.9112, 121.9260426156618, 432090.3678296309, 432090.3678296304, 127238.2936997471], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1307400.0000, 
sim time next is 1308000.0000, 
raw observation next is [18.96666666666667, 88.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5682352006466289, 6.911200000000001, 6.9112, 121.9260426156618, 418607.9252199156, 418607.9252199151, 125544.9236273155], 
processed observation next is [1.0, 0.13043478260869565, 0.25802469135802475, 0.8866666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4602940008082861, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14950283043568413, 0.14950283043568396, 0.24143254543714518], 
reward next is 0.7586, 
noisyNet noise sample is [array([0.5842387], dtype=float32), 1.1486254]. 
=============================================
[2019-03-24 08:25:25,419] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[66.38682 ]
 [66.174866]
 [65.92567 ]
 [65.98677 ]
 [66.157005]], R is [[66.3613739 ]
 [66.45307159]
 [66.54576111]
 [66.63673401]
 [66.72566223]].
[2019-03-24 08:25:25,998] A3C_AGENT_WORKER-Thread-2 INFO:Local step 134000, global step 2144214: loss 0.0756
[2019-03-24 08:25:26,001] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 134000, global step 2144215: learning rate 0.0000
[2019-03-24 08:25:26,113] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:25:26,119] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3373
[2019-03-24 08:25:26,125] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.0, 45.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6983576067071728, 6.9112, 6.9112, 121.9260426156618, 521824.0932029079, 521824.0932029079, 145128.0660479516], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 817200.0000, 
sim time next is 817800.0000, 
raw observation next is [29.33333333333334, 43.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7029482772520211, 6.9112, 6.9112, 121.9260426156618, 525214.684342132, 525214.684342132, 145799.685148417], 
processed observation next is [0.0, 0.4782608695652174, 0.6419753086419755, 0.4383333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6286853465650263, 0.0, 0.0, 0.8094621288201359, 0.18757667297933284, 0.18757667297933284, 0.2803840099008019], 
reward next is 0.7196, 
noisyNet noise sample is [array([-0.04955615], dtype=float32), -1.8732761]. 
=============================================
[2019-03-24 08:25:27,790] A3C_AGENT_WORKER-Thread-22 INFO:Local step 134000, global step 2145097: loss 0.0025
[2019-03-24 08:25:27,792] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 134000, global step 2145098: learning rate 0.0000
[2019-03-24 08:25:28,024] A3C_AGENT_WORKER-Thread-11 INFO:Local step 134000, global step 2145213: loss 0.0133
[2019-03-24 08:25:28,029] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 134000, global step 2145214: learning rate 0.0000
[2019-03-24 08:25:28,155] A3C_AGENT_WORKER-Thread-9 INFO:Local step 134000, global step 2145274: loss 0.0291
[2019-03-24 08:25:28,159] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 134000, global step 2145274: learning rate 0.0000
[2019-03-24 08:25:29,060] A3C_AGENT_WORKER-Thread-16 INFO:Local step 134000, global step 2145721: loss 0.0114
[2019-03-24 08:25:29,061] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 134000, global step 2145721: learning rate 0.0000
[2019-03-24 08:25:29,263] A3C_AGENT_WORKER-Thread-14 INFO:Local step 134000, global step 2145822: loss 0.0018
[2019-03-24 08:25:29,265] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 134000, global step 2145822: learning rate 0.0000
[2019-03-24 08:25:29,441] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:25:29,448] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0040
[2019-03-24 08:25:29,451] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.8, 51.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6246553265801777, 6.9112, 6.9112, 121.9260426156618, 464671.8909849736, 464671.8909849736, 133510.1729620296], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 934200.0000, 
sim time next is 934800.0000, 
raw observation next is [25.63333333333333, 51.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6229905834115014, 6.9112, 6.9112, 121.9260426156618, 463343.5782282517, 463343.5782282517, 133273.5669107612], 
processed observation next is [0.0, 0.8260869565217391, 0.5049382716049381, 0.5166666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5287382292643766, 0.0, 0.0, 0.8094621288201359, 0.16547984936723276, 0.16547984936723276, 0.25629532098223307], 
reward next is 0.7437, 
noisyNet noise sample is [array([0.6420291], dtype=float32), 1.7101213]. 
=============================================
[2019-03-24 08:25:29,663] A3C_AGENT_WORKER-Thread-18 INFO:Local step 134000, global step 2146017: loss 0.0295
[2019-03-24 08:25:29,666] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 134000, global step 2146020: learning rate 0.0000
[2019-03-24 08:25:29,813] A3C_AGENT_WORKER-Thread-10 INFO:Local step 134000, global step 2146093: loss 0.0325
[2019-03-24 08:25:29,819] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 134000, global step 2146093: learning rate 0.0000
[2019-03-24 08:25:29,997] A3C_AGENT_WORKER-Thread-19 INFO:Local step 134000, global step 2146184: loss 0.0146
[2019-03-24 08:25:30,001] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 134000, global step 2146185: learning rate 0.0000
[2019-03-24 08:25:30,910] A3C_AGENT_WORKER-Thread-20 INFO:Local step 134000, global step 2146633: loss 0.0032
[2019-03-24 08:25:30,913] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 134000, global step 2146633: learning rate 0.0000
[2019-03-24 08:25:31,070] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:25:31,082] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1624
[2019-03-24 08:25:31,092] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.46666666666667, 52.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6211595496833996, 6.911200000000001, 6.9112, 121.9260426156618, 461885.0981395599, 461885.0981395594, 133017.1296804022], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 935400.0000, 
sim time next is 936000.0000, 
raw observation next is [25.3, 53.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6193364296906178, 6.911200000000001, 6.9112, 121.9260426156618, 460425.8846916248, 460425.8846916244, 132757.9276326433], 
processed observation next is [0.0, 0.8695652173913043, 0.49259259259259264, 0.53, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5241705371132721, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16443781596129456, 0.16443781596129442, 0.2553037069858525], 
reward next is 0.7447, 
noisyNet noise sample is [array([-0.6284636], dtype=float32), 0.15136868]. 
=============================================
[2019-03-24 08:25:31,102] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[78.17633 ]
 [78.204834]
 [78.25963 ]
 [78.28902 ]
 [78.3098  ]], R is [[78.18994141]
 [78.15223694]
 [78.11441803]
 [78.07652283]
 [78.03858948]].
[2019-03-24 08:25:31,141] A3C_AGENT_WORKER-Thread-17 INFO:Local step 134000, global step 2146740: loss 0.0087
[2019-03-24 08:25:31,143] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 134000, global step 2146740: learning rate 0.0000
[2019-03-24 08:25:31,361] A3C_AGENT_WORKER-Thread-13 INFO:Local step 134000, global step 2146850: loss 0.0144
[2019-03-24 08:25:31,363] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 134000, global step 2146851: learning rate 0.0000
[2019-03-24 08:25:35,627] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.2191131e-38 0.0000000e+00 1.0136356e-35 7.9690567e-36], sum to 1.0000
[2019-03-24 08:25:35,632] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4201
[2019-03-24 08:25:35,638] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 785466.2092447741 W.
[2019-03-24 08:25:35,643] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.86666666666667, 43.66666666666666, 1.0, 2.0, 0.3137861271252045, 1.0, 2.0, 0.3137861271252045, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 785466.2092447741, 785466.2092447741, 186352.8502541854], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1083000.0000, 
sim time next is 1083600.0000, 
raw observation next is [26.0, 43.0, 1.0, 2.0, 0.1771646763061684, 1.0, 2.0, 0.1771646763061684, 1.0, 1.0, 0.2970875424215203, 6.9112, 6.9112, 121.94756008, 663893.669455749, 663893.669455749, 210609.2654689858], 
processed observation next is [1.0, 0.5652173913043478, 0.5185185185185185, 0.43, 1.0, 1.0, 0.02043413845972427, 1.0, 1.0, 0.02043413845972427, 1.0, 0.5, 0.12135942802690036, 0.0, 0.0, 0.8096049824067558, 0.23710488194848178, 0.23710488194848178, 0.4050178182095881], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.20930712], dtype=float32), -0.25401154]. 
=============================================
[2019-03-24 08:25:36,450] A3C_AGENT_WORKER-Thread-12 INFO:Local step 135000, global step 2149344: loss 0.1504
[2019-03-24 08:25:36,454] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 135000, global step 2149344: learning rate 0.0000
[2019-03-24 08:25:37,783] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-24 08:25:37,785] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:25:37,787] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:25:37,788] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:25:37,790] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:25:37,791] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:25:37,793] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:25:37,792] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:25:37,793] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:25:37,795] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:25:37,796] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:25:37,819] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run87
[2019-03-24 08:25:37,851] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run87
[2019-03-24 08:25:37,852] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run87
[2019-03-24 08:25:37,904] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run87
[2019-03-24 08:25:37,904] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run87
[2019-03-24 08:25:44,105] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.024259368]
[2019-03-24 08:25:44,106] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.46138306, 26.4857802, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.96269974361585, 6.9112, 6.9112, 121.9260426156618, 687525.0563092581, 687525.0563092581, 150290.0898297242]
[2019-03-24 08:25:44,107] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:25:44,111] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.4512863603428805
[2019-03-24 08:25:44,114] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 687525.0563092581 W.
[2019-03-24 08:25:48,004] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.024259368]
[2019-03-24 08:25:48,005] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [21.78958285833333, 57.82791695, 1.0, 2.0, 0.8991015518844927, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.190484181865046, 6.9112, 121.9248341648795, 1291579.753046921, 1148562.707300088, 221625.8622293141]
[2019-03-24 08:25:48,007] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:25:48,010] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 2.5071132e-38 0.0000000e+00 3.7307619e-37 4.4616834e-36], sampled 0.9694403502116945
[2019-03-24 08:25:48,011] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1291579.753046921 W.
[2019-03-24 08:27:19,349] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.024259368]
[2019-03-24 08:27:19,349] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [17.13333333333333, 94.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5146130522260222, 6.911200000000001, 6.9112, 121.9260426156618, 372413.5772246312, 372413.5772246307, 117983.6419744184]
[2019-03-24 08:27:19,350] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:27:19,351] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.7389152794302931
[2019-03-24 08:27:21,446] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.024259368]
[2019-03-24 08:27:21,447] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.33333333333334, 73.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5882159233752197, 6.9112, 6.9112, 121.9260426156618, 435395.7419680901, 435395.7419680901, 128486.6039794474]
[2019-03-24 08:27:21,447] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:27:21,450] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.35270442038667993
[2019-03-24 08:27:22,667] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 08:27:22,789] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.024259368]
[2019-03-24 08:27:22,790] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [18.71414105833333, 93.36193884333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5577008638684632, 6.9112, 6.9112, 121.9260426156618, 411633.459800638, 411633.459800638, 125036.0853791314]
[2019-03-24 08:27:22,791] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:27:22,793] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.07543674741926276
[2019-03-24 08:27:22,973] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 08:27:23,048] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 08:27:23,113] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 08:27:23,176] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 08:27:24,193] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 2150000, evaluation results [2150000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 08:27:24,276] A3C_AGENT_WORKER-Thread-3 INFO:Local step 134500, global step 2150048: loss 59.3163
[2019-03-24 08:27:24,279] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 134500, global step 2150049: learning rate 0.0000
[2019-03-24 08:27:25,500] A3C_AGENT_WORKER-Thread-15 INFO:Local step 134500, global step 2150669: loss 59.0360
[2019-03-24 08:27:25,505] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 134500, global step 2150669: learning rate 0.0000
[2019-03-24 08:27:26,487] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:27:26,494] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6004
[2019-03-24 08:27:26,497] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.55, 57.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.573089427519653, 6.9112, 6.9112, 121.9260426156618, 423093.8315448696, 423093.8315448696, 126462.1617005741], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1104600.0000, 
sim time next is 1105200.0000, 
raw observation next is [23.3, 59.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5718714137534386, 6.9112, 6.9112, 121.9260426156618, 421999.3553529106, 421999.3553529106, 126245.7044222109], 
processed observation next is [1.0, 0.8260869565217391, 0.41851851851851857, 0.59, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.46483926719179824, 0.0, 0.0, 0.8094621288201359, 0.15071405548318234, 0.15071405548318234, 0.24278020081194404], 
reward next is 0.7572, 
noisyNet noise sample is [array([-0.30309463], dtype=float32), 0.15492178]. 
=============================================
[2019-03-24 08:27:27,486] A3C_AGENT_WORKER-Thread-21 INFO:Local step 135000, global step 2151699: loss 0.0299
[2019-03-24 08:27:27,489] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 135000, global step 2151700: learning rate 0.0000
[2019-03-24 08:27:28,156] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 9.8313486e-37 0.0000000e+00 4.3625058e-35 1.3321461e-33], sum to 1.0000
[2019-03-24 08:27:28,164] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3398
[2019-03-24 08:27:28,170] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 768020.6159490346 W.
[2019-03-24 08:27:28,175] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.1, 65.0, 1.0, 2.0, 0.6027039715733201, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 768020.6159490346, 768020.6159490346, 161147.4770795145], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1162800.0000, 
sim time next is 1163400.0000, 
raw observation next is [21.16666666666667, 65.0, 1.0, 2.0, 0.5449528661700652, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 695799.2911000764, 695799.2911000759, 151196.6054226144], 
processed observation next is [1.0, 0.4782608695652174, 0.33950617283950635, 0.65, 1.0, 1.0, 0.45827722163103, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24849974682145587, 0.2484997468214557, 0.2907627027357969], 
reward next is 0.7092, 
noisyNet noise sample is [array([0.4004059], dtype=float32), -0.23604798]. 
=============================================
[2019-03-24 08:27:28,766] A3C_AGENT_WORKER-Thread-2 INFO:Local step 134500, global step 2152357: loss 68.5488
[2019-03-24 08:27:28,770] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 134500, global step 2152358: learning rate 0.0000
[2019-03-24 08:27:29,668] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:27:29,680] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7640
[2019-03-24 08:27:29,688] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.6, 81.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6576795810007297, 6.911200000000001, 6.9112, 121.9260426156618, 490937.0195801846, 490937.0195801841, 138616.3835236553], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1290000.0000, 
sim time next is 1290600.0000, 
raw observation next is [21.4, 82.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6562055980888103, 6.9112, 6.9112, 121.9260426156618, 489764.0622078954, 489764.0622078954, 138352.3403371726], 
processed observation next is [1.0, 0.9565217391304348, 0.3481481481481481, 0.825, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5702569976110128, 0.0, 0.0, 0.8094621288201359, 0.17491573650281977, 0.17491573650281977, 0.2660621929561011], 
reward next is 0.7339, 
noisyNet noise sample is [array([-0.77060103], dtype=float32), -0.3550933]. 
=============================================
[2019-03-24 08:27:30,488] A3C_AGENT_WORKER-Thread-22 INFO:Local step 134500, global step 2153245: loss 75.6089
[2019-03-24 08:27:30,493] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 134500, global step 2153247: learning rate 0.0000
[2019-03-24 08:27:30,504] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:27:30,514] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0465
[2019-03-24 08:27:30,526] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.46666666666667, 79.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5982992005990521, 6.9112, 6.9112, 121.9260426156618, 442487.2357288289, 442487.2357288289, 129195.7646365754], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1191000.0000, 
sim time next is 1191600.0000, 
raw observation next is [20.4, 80.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.59531998810649, 6.911200000000001, 6.9112, 121.9260426156618, 440279.0627883213, 440279.0627883208, 128917.6636000957], 
processed observation next is [1.0, 0.8260869565217391, 0.31111111111111106, 0.8, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4941499851331125, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15724252242440045, 0.1572425224244003, 0.24791858384633786], 
reward next is 0.7521, 
noisyNet noise sample is [array([-0.03016267], dtype=float32), -0.120079204]. 
=============================================
[2019-03-24 08:27:30,542] A3C_AGENT_WORKER-Thread-9 INFO:Local step 134500, global step 2153270: loss 78.5294
[2019-03-24 08:27:30,543] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 134500, global step 2153270: learning rate 0.0000
[2019-03-24 08:27:30,654] A3C_AGENT_WORKER-Thread-11 INFO:Local step 134500, global step 2153326: loss 77.0013
[2019-03-24 08:27:30,655] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 134500, global step 2153326: learning rate 0.0000
[2019-03-24 08:27:31,338] A3C_AGENT_WORKER-Thread-16 INFO:Local step 134500, global step 2153685: loss 83.7868
[2019-03-24 08:27:31,340] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 134500, global step 2153686: learning rate 0.0000
[2019-03-24 08:27:31,533] A3C_AGENT_WORKER-Thread-14 INFO:Local step 134500, global step 2153786: loss 75.3526
[2019-03-24 08:27:31,543] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 134500, global step 2153786: learning rate 0.0000
[2019-03-24 08:27:31,994] A3C_AGENT_WORKER-Thread-18 INFO:Local step 134500, global step 2154022: loss 82.4090
[2019-03-24 08:27:31,996] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 134500, global step 2154024: learning rate 0.0000
[2019-03-24 08:27:32,009] A3C_AGENT_WORKER-Thread-10 INFO:Local step 134500, global step 2154029: loss 84.4115
[2019-03-24 08:27:32,011] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 134500, global step 2154029: learning rate 0.0000
[2019-03-24 08:27:32,206] A3C_AGENT_WORKER-Thread-19 INFO:Local step 134500, global step 2154125: loss 85.4297
[2019-03-24 08:27:32,208] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 134500, global step 2154127: learning rate 0.0000
[2019-03-24 08:27:33,188] A3C_AGENT_WORKER-Thread-17 INFO:Local step 134500, global step 2154637: loss 81.0616
[2019-03-24 08:27:33,189] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 134500, global step 2154637: learning rate 0.0000
[2019-03-24 08:27:33,254] A3C_AGENT_WORKER-Thread-20 INFO:Local step 134500, global step 2154667: loss 79.9896
[2019-03-24 08:27:33,255] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 134500, global step 2154667: learning rate 0.0000
[2019-03-24 08:27:33,323] A3C_AGENT_WORKER-Thread-13 INFO:Local step 134500, global step 2154707: loss 77.1113
[2019-03-24 08:27:33,332] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 134500, global step 2154707: learning rate 0.0000
[2019-03-24 08:27:36,089] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0055512e-36], sum to 1.0000
[2019-03-24 08:27:36,096] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5992
[2019-03-24 08:27:36,100] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.43333333333333, 86.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7288265096036928, 6.911199999999999, 6.9112, 121.9260426156618, 538146.7482948789, 538146.7482948793, 141500.3221865387], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1303800.0000, 
sim time next is 1304400.0000, 
raw observation next is [19.36666666666667, 86.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6341308296394051, 6.911200000000001, 6.9112, 121.9260426156618, 468066.5162850841, 468066.5162850836, 132045.8752188075], 
processed observation next is [1.0, 0.08695652173913043, 0.27283950617283964, 0.8666666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5426635370492564, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1671666129589586, 0.16716661295895843, 0.2539343754207836], 
reward next is 0.7461, 
noisyNet noise sample is [array([0.05626415], dtype=float32), 0.22123787]. 
=============================================
[2019-03-24 08:27:38,362] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:27:38,368] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5896
[2019-03-24 08:27:38,374] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.93333333333334, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.667294756529491, 6.9112, 6.9112, 121.9260426156618, 498175.0483971646, 498175.0483971646, 139708.6422180807], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1722000.0000, 
sim time next is 1722600.0000, 
raw observation next is [21.85, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6652099873995092, 6.9112, 6.9112, 121.9260426156618, 496483.3991097205, 496483.3991097205, 139277.9294462682], 
processed observation next is [1.0, 0.9565217391304348, 0.36481481481481487, 0.79, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5815124842493865, 0.0, 0.0, 0.8094621288201359, 0.17731549968204302, 0.17731549968204302, 0.2678421720120542], 
reward next is 0.7322, 
noisyNet noise sample is [array([1.4792703], dtype=float32), -0.5656665]. 
=============================================
[2019-03-24 08:27:38,412] A3C_AGENT_WORKER-Thread-12 INFO:Local step 135500, global step 2157342: loss 0.8153
[2019-03-24 08:27:38,414] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 135500, global step 2157344: learning rate 0.0000
[2019-03-24 08:27:38,954] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.1039391e-37 0.0000000e+00 3.7474665e-36 2.9044181e-33], sum to 1.0000
[2019-03-24 08:27:38,962] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1172
[2019-03-24 08:27:38,971] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1399905.867432234 W.
[2019-03-24 08:27:38,977] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.1, 34.5, 1.0, 2.0, 0.3858908393379076, 1.0, 1.0, 0.3858908393379076, 1.0, 2.0, 0.6259100979950715, 6.9112, 6.9112, 121.94756008, 1399905.867432234, 1399905.867432234, 290225.1160100974], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1344600.0000, 
sim time next is 1345200.0000, 
raw observation next is [30.3, 34.0, 1.0, 2.0, 0.5591672405398169, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9141762132287042, 6.911199999999999, 6.9112, 121.9260426156618, 1366412.174487927, 1366412.174487927, 275277.6790668084], 
processed observation next is [1.0, 0.5652173913043478, 0.6777777777777778, 0.34, 1.0, 1.0, 0.4751990958807344, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.8927202665358802, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4880043480314025, 0.4880043480314025, 0.5293801520515546], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.59421444], dtype=float32), -0.8250758]. 
=============================================
[2019-03-24 08:27:39,362] A3C_AGENT_WORKER-Thread-3 INFO:Local step 135000, global step 2157836: loss 0.0499
[2019-03-24 08:27:39,365] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 135000, global step 2157836: learning rate 0.0000
[2019-03-24 08:27:41,003] A3C_AGENT_WORKER-Thread-15 INFO:Local step 135000, global step 2158691: loss 0.0953
[2019-03-24 08:27:41,005] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 135000, global step 2158691: learning rate 0.0000
[2019-03-24 08:27:43,146] A3C_AGENT_WORKER-Thread-21 INFO:Local step 135500, global step 2159804: loss 0.3685
[2019-03-24 08:27:43,150] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 135500, global step 2159804: learning rate 0.0000
[2019-03-24 08:27:44,230] A3C_AGENT_WORKER-Thread-2 INFO:Local step 135000, global step 2160367: loss 0.1784
[2019-03-24 08:27:44,231] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 135000, global step 2160367: learning rate 0.0000
[2019-03-24 08:27:44,431] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:27:44,439] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2267
[2019-03-24 08:27:44,443] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [32.5, 25.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6355959975418665, 6.911200000000001, 6.9112, 121.9260426156618, 471851.5421017581, 471851.5421017576, 133846.4101061578], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1427400.0000, 
sim time next is 1428000.0000, 
raw observation next is [32.66666666666667, 24.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6379705816703415, 6.911200000000001, 6.9112, 121.9260426156618, 473729.491588981, 473729.4915889805, 134160.2240243525], 
processed observation next is [0.0, 0.5217391304347826, 0.7654320987654323, 0.2466666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5474632270879268, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1691891041389218, 0.1691891041389216, 0.2580004308160625], 
reward next is 0.7420, 
noisyNet noise sample is [array([-0.36683977], dtype=float32), 0.42552355]. 
=============================================
[2019-03-24 08:27:44,459] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[74.37742 ]
 [74.3718  ]
 [74.37398 ]
 [74.455925]
 [74.37879 ]], R is [[74.34142303]
 [74.34060669]
 [74.33982849]
 [74.33608246]
 [74.33744812]].
[2019-03-24 08:27:44,503] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:27:44,511] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3985
[2019-03-24 08:27:44,514] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [35.13333333333333, 23.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6943367918999912, 6.9112, 6.9112, 121.9260426156618, 518829.0113772424, 518829.0113772424, 143729.3197096301], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1516200.0000, 
sim time next is 1516800.0000, 
raw observation next is [35.26666666666667, 22.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.683363055499391, 6.9112, 6.9112, 121.9260426156618, 510569.1311850894, 510569.1311850894, 142294.8169153382], 
processed observation next is [0.0, 0.5652173913043478, 0.8617283950617286, 0.2266666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6042038193742387, 0.0, 0.0, 0.8094621288201359, 0.18234611828038907, 0.18234611828038907, 0.27364387868334267], 
reward next is 0.7264, 
noisyNet noise sample is [array([-1.4641275], dtype=float32), 1.222585]. 
=============================================
[2019-03-24 08:27:45,207] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:27:45,215] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6221
[2019-03-24 08:27:45,223] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.8, 68.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5829369220402939, 6.9112, 6.9112, 121.9260426156618, 429709.7266107418, 429709.7266107418, 126997.6806524677], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1483200.0000, 
sim time next is 1483800.0000, 
raw observation next is [21.71666666666667, 69.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5852074084916945, 6.911199999999999, 6.9112, 121.9260426156618, 431632.8994712498, 431632.8994712502, 127334.5642169373], 
processed observation next is [0.0, 0.17391304347826086, 0.3598765432098766, 0.69, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4815092606146181, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15415460695401778, 0.15415460695401792, 0.24487416195564865], 
reward next is 0.7551, 
noisyNet noise sample is [array([-0.6194455], dtype=float32), -1.7000002]. 
=============================================
[2019-03-24 08:27:45,708] A3C_AGENT_WORKER-Thread-11 INFO:Local step 135000, global step 2161129: loss 0.3037
[2019-03-24 08:27:45,711] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 135000, global step 2161130: learning rate 0.0000
[2019-03-24 08:27:45,912] A3C_AGENT_WORKER-Thread-9 INFO:Local step 135000, global step 2161240: loss 0.3205
[2019-03-24 08:27:45,914] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 135000, global step 2161241: learning rate 0.0000
[2019-03-24 08:27:45,975] A3C_AGENT_WORKER-Thread-22 INFO:Local step 135000, global step 2161265: loss 0.2328
[2019-03-24 08:27:45,976] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 135000, global step 2161265: learning rate 0.0000
[2019-03-24 08:27:46,698] A3C_AGENT_WORKER-Thread-16 INFO:Local step 135000, global step 2161641: loss 0.2522
[2019-03-24 08:27:46,700] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 135000, global step 2161642: learning rate 0.0000
[2019-03-24 08:27:46,816] A3C_AGENT_WORKER-Thread-14 INFO:Local step 135000, global step 2161699: loss 0.2524
[2019-03-24 08:27:46,821] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 135000, global step 2161700: learning rate 0.0000
[2019-03-24 08:27:47,366] A3C_AGENT_WORKER-Thread-18 INFO:Local step 135000, global step 2161985: loss 0.1787
[2019-03-24 08:27:47,370] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 135000, global step 2161986: learning rate 0.0000
[2019-03-24 08:27:47,649] A3C_AGENT_WORKER-Thread-10 INFO:Local step 135000, global step 2162130: loss 0.1436
[2019-03-24 08:27:47,655] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 135000, global step 2162131: learning rate 0.0000
[2019-03-24 08:27:47,704] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:27:47,723] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6163
[2019-03-24 08:27:47,728] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [34.1, 27.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6838808550268088, 6.9112, 6.9112, 121.9260426156618, 511041.1909135991, 511041.1909135991, 143303.6000659147], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1512000.0000, 
sim time next is 1512600.0000, 
raw observation next is [34.25, 26.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6823003392513746, 6.911200000000001, 6.9112, 121.9260426156618, 509869.0754663933, 509869.0754663928, 143017.8914601427], 
processed observation next is [0.0, 0.5217391304347826, 0.8240740740740741, 0.265, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6028754240642181, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18209609838085475, 0.18209609838085458, 0.2750344066541206], 
reward next is 0.7250, 
noisyNet noise sample is [array([0.21578407], dtype=float32), -0.9652171]. 
=============================================
[2019-03-24 08:27:47,771] A3C_AGENT_WORKER-Thread-19 INFO:Local step 135000, global step 2162193: loss 0.1612
[2019-03-24 08:27:47,775] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 135000, global step 2162194: learning rate 0.0000
[2019-03-24 08:27:48,655] A3C_AGENT_WORKER-Thread-17 INFO:Local step 135000, global step 2162652: loss 0.2036
[2019-03-24 08:27:48,659] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 135000, global step 2162653: learning rate 0.0000
[2019-03-24 08:27:48,787] A3C_AGENT_WORKER-Thread-13 INFO:Local step 135000, global step 2162717: loss 0.1757
[2019-03-24 08:27:48,789] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 135000, global step 2162717: learning rate 0.0000
[2019-03-24 08:27:49,014] A3C_AGENT_WORKER-Thread-20 INFO:Local step 135000, global step 2162827: loss 0.0906
[2019-03-24 08:27:49,016] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 135000, global step 2162828: learning rate 0.0000
[2019-03-24 08:27:53,984] A3C_AGENT_WORKER-Thread-12 INFO:Local step 136000, global step 2165439: loss 0.1647
[2019-03-24 08:27:53,988] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 136000, global step 2165439: learning rate 0.0000
[2019-03-24 08:27:54,934] A3C_AGENT_WORKER-Thread-3 INFO:Local step 135500, global step 2165901: loss 0.6199
[2019-03-24 08:27:54,935] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 135500, global step 2165902: learning rate 0.0000
[2019-03-24 08:27:56,619] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:27:56,627] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8925
[2019-03-24 08:27:56,632] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.66666666666666, 87.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5496127664811414, 6.911199999999999, 6.9112, 121.9260426156618, 402489.3337260498, 402489.3337260502, 122752.0782749065], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1809600.0000, 
sim time next is 1810200.0000, 
raw observation next is [18.68333333333333, 87.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5503479327414736, 6.9112, 6.9112, 121.9260426156618, 403239.4775545163, 403239.4775545163, 122910.6791178796], 
processed observation next is [1.0, 0.9565217391304348, 0.24753086419753073, 0.8783333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.437934915926842, 0.0, 0.0, 0.8094621288201359, 0.14401409912661295, 0.14401409912661295, 0.2363666906113069], 
reward next is 0.7636, 
noisyNet noise sample is [array([-1.1796467], dtype=float32), 0.72100663]. 
=============================================
[2019-03-24 08:27:56,712] A3C_AGENT_WORKER-Thread-15 INFO:Local step 135500, global step 2166768: loss 0.4281
[2019-03-24 08:27:56,715] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 135500, global step 2166768: learning rate 0.0000
[2019-03-24 08:27:58,813] A3C_AGENT_WORKER-Thread-21 INFO:Local step 136000, global step 2167795: loss 0.0109
[2019-03-24 08:27:58,816] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 136000, global step 2167795: learning rate 0.0000
[2019-03-24 08:28:00,242] A3C_AGENT_WORKER-Thread-2 INFO:Local step 135500, global step 2168490: loss 0.5065
[2019-03-24 08:28:00,242] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 135500, global step 2168490: learning rate 0.0000
[2019-03-24 08:28:00,685] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.2183665e-35 0.0000000e+00 4.0521538e-33 7.8578895e-33], sum to 1.0000
[2019-03-24 08:28:00,693] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9651
[2019-03-24 08:28:00,698] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.83333333333334, 83.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6720161734770572, 6.9112, 6.9112, 121.9260426156618, 500494.5412398362, 500494.5412398362, 138747.8847528074], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1737600.0000, 
sim time next is 1738200.0000, 
raw observation next is [20.76666666666667, 83.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6606732512116497, 6.9112, 6.9112, 121.9260426156618, 491973.3718124601, 491973.3718124601, 137523.7821116887], 
processed observation next is [1.0, 0.08695652173913043, 0.32469135802469146, 0.8366666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.575841564014562, 0.0, 0.0, 0.8094621288201359, 0.17570477564730716, 0.17570477564730716, 0.2644688117532475], 
reward next is 0.7355, 
noisyNet noise sample is [array([1.15596], dtype=float32), -1.0811374]. 
=============================================
[2019-03-24 08:28:01,373] A3C_AGENT_WORKER-Thread-11 INFO:Local step 135500, global step 2169052: loss 0.5820
[2019-03-24 08:28:01,380] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 135500, global step 2169053: learning rate 0.0000
[2019-03-24 08:28:01,540] A3C_AGENT_WORKER-Thread-9 INFO:Local step 135500, global step 2169136: loss 0.4699
[2019-03-24 08:28:01,542] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 135500, global step 2169136: learning rate 0.0000
[2019-03-24 08:28:01,878] A3C_AGENT_WORKER-Thread-22 INFO:Local step 135500, global step 2169297: loss 0.8407
[2019-03-24 08:28:01,879] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 135500, global step 2169297: learning rate 0.0000
[2019-03-24 08:28:02,224] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:28:02,233] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9471
[2019-03-24 08:28:02,241] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1588976.716806656 W.
[2019-03-24 08:28:02,246] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 58.0, 1.0, 2.0, 0.4621226296819375, 1.0, 2.0, 0.4621226296819375, 1.0, 1.0, 0.7359443121503433, 6.911200000000001, 6.9112, 121.94756008, 1588976.716806656, 1588976.716806656, 325420.7902872549], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1782000.0000, 
sim time next is 1782600.0000, 
raw observation next is [27.83333333333334, 59.33333333333334, 1.0, 2.0, 0.6273040534545855, 1.0, 2.0, 0.6273040534545855, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1451914.316349377, 1451914.316349377, 278607.8736077295], 
processed observation next is [1.0, 0.6521739130434783, 0.58641975308642, 0.5933333333333334, 1.0, 1.0, 0.556314349350697, 1.0, 1.0, 0.556314349350697, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5185408272676346, 0.5185408272676346, 0.5357843723225567], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0237467], dtype=float32), -1.3844467]. 
=============================================
[2019-03-24 08:28:02,611] A3C_AGENT_WORKER-Thread-16 INFO:Local step 135500, global step 2169651: loss 0.6873
[2019-03-24 08:28:02,612] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 135500, global step 2169651: learning rate 0.0000
[2019-03-24 08:28:02,771] A3C_AGENT_WORKER-Thread-14 INFO:Local step 135500, global step 2169726: loss 0.5412
[2019-03-24 08:28:02,772] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 135500, global step 2169727: learning rate 0.0000
[2019-03-24 08:28:03,248] A3C_AGENT_WORKER-Thread-18 INFO:Local step 135500, global step 2169960: loss 1.0531
[2019-03-24 08:28:03,250] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 135500, global step 2169960: learning rate 0.0000
[2019-03-24 08:28:03,481] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:28:03,489] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0757
[2019-03-24 08:28:03,496] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1404575.346896092 W.
[2019-03-24 08:28:03,504] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.7, 64.5, 1.0, 2.0, 0.5991717422217192, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9579775536293282, 6.911199999999999, 6.9112, 121.9260426156618, 1404575.346896092, 1404575.346896092, 292806.8391281153], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1787400.0000, 
sim time next is 1788000.0000, 
raw observation next is [26.6, 64.0, 1.0, 2.0, 0.5603751604366746, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8969522009560238, 6.911199999999999, 6.9112, 121.9260426156618, 1318501.114447502, 1318501.114447502, 277920.7135055372], 
processed observation next is [1.0, 0.6956521739130435, 0.5407407407407407, 0.64, 1.0, 1.0, 0.4766370957579459, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8711902511950298, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4708932551598221, 0.4708932551598221, 0.5344629105875716], 
reward next is 0.4655, 
noisyNet noise sample is [array([-0.36831906], dtype=float32), -2.3875966]. 
=============================================
[2019-03-24 08:28:03,523] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[68.456215]
 [67.906715]
 [67.1795  ]
 [66.69289 ]
 [66.43752 ]], R is [[68.3456192 ]
 [68.09907532]
 [67.84985352]
 [67.57561493]
 [67.2961731 ]].
[2019-03-24 08:28:03,741] A3C_AGENT_WORKER-Thread-19 INFO:Local step 135500, global step 2170199: loss 0.6790
[2019-03-24 08:28:03,744] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 135500, global step 2170200: learning rate 0.0000
[2019-03-24 08:28:03,772] A3C_AGENT_WORKER-Thread-10 INFO:Local step 135500, global step 2170214: loss 0.6177
[2019-03-24 08:28:03,774] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 135500, global step 2170215: learning rate 0.0000
[2019-03-24 08:28:04,531] A3C_AGENT_WORKER-Thread-17 INFO:Local step 135500, global step 2170580: loss 0.6021
[2019-03-24 08:28:04,532] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 135500, global step 2170580: learning rate 0.0000
[2019-03-24 08:28:04,780] A3C_AGENT_WORKER-Thread-13 INFO:Local step 135500, global step 2170705: loss 0.5683
[2019-03-24 08:28:04,783] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 135500, global step 2170705: learning rate 0.0000
[2019-03-24 08:28:05,046] A3C_AGENT_WORKER-Thread-20 INFO:Local step 135500, global step 2170833: loss 0.7515
[2019-03-24 08:28:05,048] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 135500, global step 2170833: learning rate 0.0000
[2019-03-24 08:28:08,220] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 3.6139808e-36 0.0000000e+00 1.0635019e-34 8.1192993e-34], sum to 1.0000
[2019-03-24 08:28:08,228] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5788
[2019-03-24 08:28:08,231] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.45, 90.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6771310682200667, 6.911200000000001, 6.9112, 121.9260426156618, 505378.1535866513, 505378.1535866508, 140512.8723827846], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1929000.0000, 
sim time next is 1929600.0000, 
raw observation next is [20.5, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6989323925450355, 6.911199999999999, 6.9112, 121.9260426156618, 521710.344377889, 521710.3443778895, 142903.5491819217], 
processed observation next is [1.0, 0.34782608695652173, 0.3148148148148148, 0.9, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6236654906812943, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18632512299210321, 0.18632512299210338, 0.2748145176575417], 
reward next is 0.7252, 
noisyNet noise sample is [array([0.5512282], dtype=float32), 1.4328339]. 
=============================================
[2019-03-24 08:28:10,768] A3C_AGENT_WORKER-Thread-12 INFO:Local step 136500, global step 2173649: loss 0.0152
[2019-03-24 08:28:10,770] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 136500, global step 2173650: learning rate 0.0000
[2019-03-24 08:28:10,943] A3C_AGENT_WORKER-Thread-3 INFO:Local step 136000, global step 2173732: loss 0.1035
[2019-03-24 08:28:10,945] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 136000, global step 2173732: learning rate 0.0000
[2019-03-24 08:28:12,868] A3C_AGENT_WORKER-Thread-15 INFO:Local step 136000, global step 2174672: loss 0.0059
[2019-03-24 08:28:12,871] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 136000, global step 2174674: learning rate 0.0000
[2019-03-24 08:28:13,553] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-24 08:28:13,554] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:28:13,555] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:28:13,555] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:28:13,556] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:28:13,558] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:28:13,555] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:28:13,556] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:28:13,561] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:28:13,561] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:28:13,563] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:28:13,581] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run88
[2019-03-24 08:28:13,613] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run88
[2019-03-24 08:28:13,641] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run88
[2019-03-24 08:28:13,641] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run88
[2019-03-24 08:28:13,642] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run88
[2019-03-24 08:28:22,988] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.02447855]
[2019-03-24 08:28:22,990] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.881587695, 49.77781248666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.520063498970894, 6.9112, 6.9112, 121.9260426156618, 382462.2972416728, 382462.2972416728, 121035.8532489548]
[2019-03-24 08:28:22,991] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:28:22,994] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 5.365986e-38], sampled 0.37067150687170014
[2019-03-24 08:28:32,133] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.02447855]
[2019-03-24 08:28:32,134] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [38.0, 14.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7154537363927003, 6.911200000000001, 6.9112, 121.9260426156618, 532949.8083641382, 532949.8083641378, 143376.3864828224]
[2019-03-24 08:28:32,134] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:28:32,139] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.5223728299555384
[2019-03-24 08:28:36,445] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.02447855]
[2019-03-24 08:28:36,446] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [26.47795792666667, 56.76503526, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8736710473637013, 6.9112, 6.9112, 121.9260426156618, 652724.5087200695, 652724.5087200695, 166141.2820717686]
[2019-03-24 08:28:36,447] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:28:36,452] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.1912783e-37 1.6404602e-36], sampled 0.17703323287653383
[2019-03-24 08:28:38,859] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.02447855]
[2019-03-24 08:28:38,862] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.33375477833333, 60.76187595166667, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8838435379034036, 6.9112, 6.9112, 121.9260426156618, 657541.751013871, 657541.751013871, 170251.1896447769]
[2019-03-24 08:28:38,863] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:28:38,865] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 3.1996955e-37 0.0000000e+00 6.4627028e-36 4.4717217e-35], sampled 0.48878417904199634
[2019-03-24 08:28:39,544] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.02447855]
[2019-03-24 08:28:39,545] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [20.8, 86.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6585784425797495, 6.911200000000001, 6.9112, 121.9260426156618, 491327.5186655175, 491327.518665517, 138305.4533337943]
[2019-03-24 08:28:39,545] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:28:39,549] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.2892405e-38], sampled 0.15577582449498262
[2019-03-24 08:29:05,269] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.02447855]
[2019-03-24 08:29:05,275] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [33.0, 69.5, 1.0, 2.0, 0.9188902506511024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1047445.429719688, 1047445.429719688, 221746.1648233199]
[2019-03-24 08:29:05,275] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:29:05,277] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.9127089484909942
[2019-03-24 08:29:05,281] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1047445.429719688 W.
[2019-03-24 08:29:58,702] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 08:29:58,706] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 08:29:58,757] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 08:29:58,762] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 08:29:58,928] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 08:29:59,945] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 2175000, evaluation results [2175000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 08:30:01,611] A3C_AGENT_WORKER-Thread-21 INFO:Local step 136500, global step 2175865: loss 0.0979
[2019-03-24 08:30:01,614] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 136500, global step 2175865: learning rate 0.0000
[2019-03-24 08:30:02,594] A3C_AGENT_WORKER-Thread-2 INFO:Local step 136000, global step 2176379: loss 0.0555
[2019-03-24 08:30:02,598] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 136000, global step 2176379: learning rate 0.0000
[2019-03-24 08:30:03,706] A3C_AGENT_WORKER-Thread-11 INFO:Local step 136000, global step 2176958: loss 0.0520
[2019-03-24 08:30:03,707] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 136000, global step 2176958: learning rate 0.0000
[2019-03-24 08:30:03,787] A3C_AGENT_WORKER-Thread-9 INFO:Local step 136000, global step 2176999: loss 0.0555
[2019-03-24 08:30:03,788] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 136000, global step 2176999: learning rate 0.0000
[2019-03-24 08:30:04,361] A3C_AGENT_WORKER-Thread-22 INFO:Local step 136000, global step 2177297: loss 0.0285
[2019-03-24 08:30:04,362] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 136000, global step 2177298: learning rate 0.0000
[2019-03-24 08:30:05,100] A3C_AGENT_WORKER-Thread-14 INFO:Local step 136000, global step 2177680: loss 0.0400
[2019-03-24 08:30:05,103] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 136000, global step 2177680: learning rate 0.0000
[2019-03-24 08:30:05,167] A3C_AGENT_WORKER-Thread-16 INFO:Local step 136000, global step 2177717: loss 0.0223
[2019-03-24 08:30:05,169] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 136000, global step 2177717: learning rate 0.0000
[2019-03-24 08:30:05,599] A3C_AGENT_WORKER-Thread-18 INFO:Local step 136000, global step 2177939: loss 0.0102
[2019-03-24 08:30:05,601] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 136000, global step 2177940: learning rate 0.0000
[2019-03-24 08:30:06,035] A3C_AGENT_WORKER-Thread-19 INFO:Local step 136000, global step 2178166: loss 0.0041
[2019-03-24 08:30:06,039] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 136000, global step 2178168: learning rate 0.0000
[2019-03-24 08:30:06,116] A3C_AGENT_WORKER-Thread-10 INFO:Local step 136000, global step 2178214: loss 0.0023
[2019-03-24 08:30:06,118] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 136000, global step 2178215: learning rate 0.0000
[2019-03-24 08:30:06,919] A3C_AGENT_WORKER-Thread-17 INFO:Local step 136000, global step 2178617: loss 0.0706
[2019-03-24 08:30:06,923] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 136000, global step 2178617: learning rate 0.0000
[2019-03-24 08:30:07,099] A3C_AGENT_WORKER-Thread-13 INFO:Local step 136000, global step 2178710: loss 0.0546
[2019-03-24 08:30:07,103] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 136000, global step 2178711: learning rate 0.0000
[2019-03-24 08:30:07,279] A3C_AGENT_WORKER-Thread-20 INFO:Local step 136000, global step 2178805: loss 0.0287
[2019-03-24 08:30:07,282] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 136000, global step 2178808: learning rate 0.0000
[2019-03-24 08:30:07,961] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 6.7239053e-32 4.0442871e-36 5.2023366e-32 9.8844668e-33], sum to 1.0000
[2019-03-24 08:30:07,967] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9132
[2019-03-24 08:30:07,973] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.56666666666667, 96.50000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7861467177826175, 6.9112, 6.9112, 121.9260426156618, 587468.9349572144, 587468.9349572144, 155040.2448637293], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2275800.0000, 
sim time next is 2276400.0000, 
raw observation next is [20.73333333333333, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9558459702366593, 7.441255983885576, 6.9112, 121.9243435458354, 985813.9684396953, 714381.7113529743, 175299.1622657585], 
processed observation next is [1.0, 0.34782608695652173, 0.3234567901234567, 0.96, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9448074627958242, 0.05300559838855756, 0.0, 0.8094508487633967, 0.3520764172998912, 0.2551363254832051, 0.3371137735879971], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.2907841], dtype=float32), -0.9652921]. 
=============================================
[2019-03-24 08:30:08,218] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:30:08,226] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0976
[2019-03-24 08:30:08,233] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.6, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8026892386555224, 6.911200000000001, 6.9112, 121.9260426156618, 596105.1368709797, 596105.1368709792, 160716.5821991902], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2311200.0000, 
sim time next is 2311800.0000, 
raw observation next is [25.5, 70.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7971570743804112, 6.9112, 6.9112, 121.9260426156618, 592101.8856008622, 592101.8856008622, 159975.561335406], 
processed observation next is [1.0, 0.782608695652174, 0.5, 0.705, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7464463429755138, 0.0, 0.0, 0.8094621288201359, 0.21146495914316507, 0.21146495914316507, 0.30764531026039615], 
reward next is 0.6924, 
noisyNet noise sample is [array([0.19547375], dtype=float32), 0.44248578]. 
=============================================
[2019-03-24 08:30:08,260] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:30:08,268] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9679
[2019-03-24 08:30:08,271] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.75, 46.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8797118421845408, 6.911200000000001, 6.9112, 121.9260426156618, 643850.1647604437, 643850.1647604433, 173260.3469926669], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2133000.0000, 
sim time next is 2133600.0000, 
raw observation next is [31.83333333333334, 46.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8766498084584513, 6.9112, 6.9112, 121.9260426156618, 641942.7650608324, 641942.7650608324, 172790.7286782751], 
processed observation next is [0.0, 0.6956521739130435, 0.7345679012345682, 0.46, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8458122605730641, 0.0, 0.0, 0.8094621288201359, 0.22926527323601156, 0.22926527323601156, 0.33228986284283674], 
reward next is 0.6677, 
noisyNet noise sample is [array([2.0706437], dtype=float32), -0.29551774]. 
=============================================
[2019-03-24 08:30:12,580] A3C_AGENT_WORKER-Thread-12 INFO:Local step 137000, global step 2181498: loss 0.0048
[2019-03-24 08:30:12,585] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 137000, global step 2181499: learning rate 0.0000
[2019-03-24 08:30:13,252] A3C_AGENT_WORKER-Thread-3 INFO:Local step 136500, global step 2181847: loss 0.0143
[2019-03-24 08:30:13,256] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 136500, global step 2181847: learning rate 0.0000
[2019-03-24 08:30:14,967] A3C_AGENT_WORKER-Thread-15 INFO:Local step 136500, global step 2182738: loss 0.0306
[2019-03-24 08:30:14,968] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 136500, global step 2182738: learning rate 0.0000
[2019-03-24 08:30:16,965] A3C_AGENT_WORKER-Thread-21 INFO:Local step 137000, global step 2183771: loss 0.0068
[2019-03-24 08:30:16,967] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 137000, global step 2183771: learning rate 0.0000
[2019-03-24 08:30:17,398] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:30:17,407] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8484
[2019-03-24 08:30:17,408] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1175848.079702306 W.
[2019-03-24 08:30:17,412] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.4, 38.83333333333334, 1.0, 2.0, 0.4820054071919349, 0.0, 1.0, 0.0, 1.0, 2.0, 0.786974428350859, 6.911199999999999, 6.9112, 121.9260426156618, 1175848.079702306, 1175848.079702307, 248072.9027060981], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2373000.0000, 
sim time next is 2373600.0000, 
raw observation next is [29.5, 38.66666666666667, 1.0, 2.0, 0.465293489968377, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7610029320916398, 6.911199999999999, 6.9112, 121.9260426156618, 1137365.999717639, 1137365.999717639, 242321.0642594678], 
processed observation next is [1.0, 0.4782608695652174, 0.6481481481481481, 0.3866666666666667, 1.0, 1.0, 0.36344463091473456, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7012536651145498, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4062021427562997, 0.4062021427562997, 0.4660020466528227], 
reward next is 0.5340, 
noisyNet noise sample is [array([-2.1024292], dtype=float32), 1.4452394]. 
=============================================
[2019-03-24 08:30:18,268] A3C_AGENT_WORKER-Thread-2 INFO:Local step 136500, global step 2184445: loss 0.0247
[2019-03-24 08:30:18,270] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 136500, global step 2184445: learning rate 0.0000
[2019-03-24 08:30:18,958] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 2.0665792e-38 0.0000000e+00 3.0640685e-37 4.3634336e-37], sum to 1.0000
[2019-03-24 08:30:18,964] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9217
[2019-03-24 08:30:18,969] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.96666666666667, 92.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7670867109898121, 6.9112, 6.9112, 121.9260426156618, 571345.3749862874, 571345.3749862874, 155353.9780332947], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2335200.0000, 
sim time next is 2335800.0000, 
raw observation next is [21.98333333333333, 92.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7696128799898301, 6.9112, 6.9112, 121.9260426156618, 573097.7536010707, 573097.7536010707, 155748.4371881188], 
processed observation next is [1.0, 0.0, 0.36975308641975296, 0.9283333333333332, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7120160999872877, 0.0, 0.0, 0.8094621288201359, 0.20467776914323954, 0.20467776914323954, 0.299516225361767], 
reward next is 0.7005, 
noisyNet noise sample is [array([2.5844529], dtype=float32), 0.33329055]. 
=============================================
[2019-03-24 08:30:19,346] A3C_AGENT_WORKER-Thread-11 INFO:Local step 136500, global step 2185000: loss 0.0166
[2019-03-24 08:30:19,348] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 136500, global step 2185000: learning rate 0.0000
[2019-03-24 08:30:19,405] A3C_AGENT_WORKER-Thread-9 INFO:Local step 136500, global step 2185037: loss 0.0167
[2019-03-24 08:30:19,407] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 136500, global step 2185037: learning rate 0.0000
[2019-03-24 08:30:20,092] A3C_AGENT_WORKER-Thread-22 INFO:Local step 136500, global step 2185392: loss 0.0475
[2019-03-24 08:30:20,098] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 136500, global step 2185392: learning rate 0.0000
[2019-03-24 08:30:20,673] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:30:20,680] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5579
[2019-03-24 08:30:20,683] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.4, 51.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6423256327217352, 6.911200000000001, 6.9112, 121.9260426156618, 479083.2010563755, 479083.2010563751, 136501.0841734361], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2408400.0000, 
sim time next is 2409000.0000, 
raw observation next is [26.16666666666666, 52.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6418676532747241, 6.9112, 6.9112, 121.9260426156618, 478702.532537809, 478702.532537809, 136407.186325114], 
processed observation next is [1.0, 0.9130434782608695, 0.5246913580246911, 0.52, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5523345665934051, 0.0, 0.0, 0.8094621288201359, 0.17096519019207465, 0.17096519019207465, 0.26232151216368077], 
reward next is 0.7377, 
noisyNet noise sample is [array([1.3820751], dtype=float32), -0.050669465]. 
=============================================
[2019-03-24 08:30:20,699] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[72.707634]
 [72.74339 ]
 [72.47687 ]
 [72.51795 ]
 [72.16633 ]], R is [[72.68200684]
 [72.69268036]
 [72.70321655]
 [72.71372223]
 [72.72425079]].
[2019-03-24 08:30:20,842] A3C_AGENT_WORKER-Thread-16 INFO:Local step 136500, global step 2185775: loss 0.0862
[2019-03-24 08:30:20,843] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 136500, global step 2185775: learning rate 0.0000
[2019-03-24 08:30:20,957] A3C_AGENT_WORKER-Thread-14 INFO:Local step 136500, global step 2185829: loss 0.0638
[2019-03-24 08:30:20,959] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 136500, global step 2185829: learning rate 0.0000
[2019-03-24 08:30:21,134] A3C_AGENT_WORKER-Thread-18 INFO:Local step 136500, global step 2185922: loss 0.0268
[2019-03-24 08:30:21,136] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 136500, global step 2185923: learning rate 0.0000
[2019-03-24 08:30:21,449] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.6648406e-38], sum to 1.0000
[2019-03-24 08:30:21,454] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7116
[2019-03-24 08:30:21,461] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1439738.839981023 W.
[2019-03-24 08:30:21,468] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.76666666666667, 37.33333333333334, 1.0, 2.0, 0.6021500100474266, 1.0, 2.0, 0.6021500100474266, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1439738.839981023, 1439738.839981024, 271731.4615146231], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2391600.0000, 
sim time next is 2392200.0000, 
raw observation next is [30.75, 37.5, 1.0, 2.0, 0.5786957993514842, 1.0, 2.0, 0.5786957993514842, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1386134.587770801, 1386134.587770801, 263703.3195521056], 
processed observation next is [1.0, 0.6956521739130435, 0.6944444444444444, 0.375, 1.0, 1.0, 0.4984473801803383, 1.0, 1.0, 0.4984473801803383, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.49504806706100035, 0.49504806706100035, 0.5071217683694339], 
reward next is 0.4929, 
noisyNet noise sample is [array([-0.06585668], dtype=float32), 0.9646602]. 
=============================================
[2019-03-24 08:30:21,473] A3C_AGENT_WORKER-Thread-19 INFO:Local step 136500, global step 2186099: loss 0.0109
[2019-03-24 08:30:21,478] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 136500, global step 2186099: learning rate 0.0000
[2019-03-24 08:30:21,752] A3C_AGENT_WORKER-Thread-10 INFO:Local step 136500, global step 2186244: loss 0.0118
[2019-03-24 08:30:21,752] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 136500, global step 2186244: learning rate 0.0000
[2019-03-24 08:30:21,988] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:30:21,994] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0590
[2019-03-24 08:30:21,998] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.55, 63.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6329488932906757, 6.9112, 6.9112, 121.9260426156618, 471155.3520282395, 471155.3520282395, 134592.6633695357], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2416200.0000, 
sim time next is 2416800.0000, 
raw observation next is [23.4, 63.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6237334614433071, 6.9112, 6.9112, 121.9260426156618, 463800.1068928704, 463800.1068928704, 133267.7701344848], 
processed observation next is [1.0, 1.0, 0.42222222222222217, 0.6366666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5296668268041338, 0.0, 0.0, 0.8094621288201359, 0.1656428953188823, 0.1656428953188823, 0.2562841733355477], 
reward next is 0.7437, 
noisyNet noise sample is [array([0.5544334], dtype=float32), -1.0665619]. 
=============================================
[2019-03-24 08:30:22,400] A3C_AGENT_WORKER-Thread-17 INFO:Local step 136500, global step 2186573: loss 0.0463
[2019-03-24 08:30:22,401] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 136500, global step 2186573: learning rate 0.0000
[2019-03-24 08:30:22,505] A3C_AGENT_WORKER-Thread-13 INFO:Local step 136500, global step 2186635: loss 0.0189
[2019-03-24 08:30:22,507] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 136500, global step 2186636: learning rate 0.0000
[2019-03-24 08:30:22,823] A3C_AGENT_WORKER-Thread-20 INFO:Local step 136500, global step 2186799: loss 0.0252
[2019-03-24 08:30:22,824] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 136500, global step 2186799: learning rate 0.0000
[2019-03-24 08:30:23,358] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 6.0434519e-33 2.4340620e-36 5.0328226e-32 5.1645303e-32], sum to 1.0000
[2019-03-24 08:30:23,380] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4223
[2019-03-24 08:30:23,385] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1054630.452786243 W.
[2019-03-24 08:30:23,389] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.55, 40.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9579701877603664, 7.575581331833416, 6.9112, 121.9239129933196, 1054630.452786243, 714413.7716595014, 170628.7237346017], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2448600.0000, 
sim time next is 2449200.0000, 
raw observation next is [28.8, 39.66666666666667, 1.0, 1.0, 0.4898780169316238, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8062905840384561, 6.9112, 6.9112, 121.9256425362521, 1205600.485798243, 1205600.485798243, 250063.0604454084], 
processed observation next is [1.0, 0.34782608695652173, 0.6222222222222222, 0.3966666666666667, 1.0, 0.5, 0.39271192491859974, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.75786323004807, 0.0, 0.0, 0.8094594727089088, 0.4305716020708011, 0.4305716020708011, 0.4808905008565546], 
reward next is 0.5191, 
noisyNet noise sample is [array([-1.5559524], dtype=float32), 1.3612227]. 
=============================================
[2019-03-24 08:30:28,258] A3C_AGENT_WORKER-Thread-3 INFO:Local step 137000, global step 2189655: loss 0.0054
[2019-03-24 08:30:28,259] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 137000, global step 2189655: learning rate 0.0000
[2019-03-24 08:30:28,963] A3C_AGENT_WORKER-Thread-12 INFO:Local step 137500, global step 2190005: loss -68.8327
[2019-03-24 08:30:28,966] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 137500, global step 2190006: learning rate 0.0000
[2019-03-24 08:30:29,925] A3C_AGENT_WORKER-Thread-15 INFO:Local step 137000, global step 2190481: loss 0.0061
[2019-03-24 08:30:29,927] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 137000, global step 2190482: learning rate 0.0000
[2019-03-24 08:30:30,131] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:30:30,139] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2152
[2019-03-24 08:30:30,145] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.08333333333334, 61.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8695797073923387, 6.9112, 6.9112, 121.9260426156618, 639303.133515033, 639303.133515033, 171290.7729896925], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2715000.0000, 
sim time next is 2715600.0000, 
raw observation next is [28.16666666666667, 61.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8722095449037007, 6.9112, 6.9112, 121.9260426156618, 640840.8514795783, 640840.8514795783, 171728.6722146193], 
processed observation next is [0.0, 0.43478260869565216, 0.5987654320987656, 0.6166666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8402619311296258, 0.0, 0.0, 0.8094621288201359, 0.22887173267127797, 0.22887173267127797, 0.33024744656657556], 
reward next is 0.6698, 
noisyNet noise sample is [array([0.0131969], dtype=float32), 0.4010487]. 
=============================================
[2019-03-24 08:30:32,604] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 4.5778456e-38 2.4224252e-38], sum to 1.0000
[2019-03-24 08:30:32,610] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6554
[2019-03-24 08:30:32,615] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.86666666666667, 98.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8364779591093051, 6.9112, 6.9112, 121.9260426156618, 619200.6196697115, 619200.6196697115, 165774.5209609397], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2693400.0000, 
sim time next is 2694000.0000, 
raw observation next is [21.73333333333333, 97.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8189208057183333, 6.911200000000001, 6.9112, 121.9260426156618, 607734.6242354264, 607734.624235426, 162956.3124079623], 
processed observation next is [0.0, 0.17391304347826086, 0.3604938271604937, 0.9766666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7736510071479166, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.21704808008408086, 0.2170480800840807, 0.313377523861466], 
reward next is 0.6866, 
noisyNet noise sample is [array([-0.2980899], dtype=float32), 0.55547535]. 
=============================================
[2019-03-24 08:30:32,630] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[70.34803 ]
 [70.499504]
 [70.39061 ]
 [70.64858 ]
 [70.75132 ]], R is [[70.30738068]
 [70.28551483]
 [70.25949097]
 [70.23236084]
 [70.20431519]].
[2019-03-24 08:30:33,604] A3C_AGENT_WORKER-Thread-2 INFO:Local step 137000, global step 2192274: loss 0.0227
[2019-03-24 08:30:33,607] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 137000, global step 2192274: learning rate 0.0000
[2019-03-24 08:30:33,713] A3C_AGENT_WORKER-Thread-21 INFO:Local step 137500, global step 2192331: loss -27.7445
[2019-03-24 08:30:33,716] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 137500, global step 2192332: learning rate 0.0000
[2019-03-24 08:30:34,727] A3C_AGENT_WORKER-Thread-11 INFO:Local step 137000, global step 2192817: loss 0.0224
[2019-03-24 08:30:34,732] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 137000, global step 2192818: learning rate 0.0000
[2019-03-24 08:30:34,777] A3C_AGENT_WORKER-Thread-9 INFO:Local step 137000, global step 2192838: loss 0.0211
[2019-03-24 08:30:34,780] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 137000, global step 2192838: learning rate 0.0000
[2019-03-24 08:30:35,374] A3C_AGENT_WORKER-Thread-22 INFO:Local step 137000, global step 2193132: loss 0.0030
[2019-03-24 08:30:35,377] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 137000, global step 2193133: learning rate 0.0000
[2019-03-24 08:30:36,479] A3C_AGENT_WORKER-Thread-16 INFO:Local step 137000, global step 2193677: loss 0.0500
[2019-03-24 08:30:36,480] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 137000, global step 2193677: learning rate 0.0000
[2019-03-24 08:30:36,599] A3C_AGENT_WORKER-Thread-14 INFO:Local step 137000, global step 2193737: loss 0.0383
[2019-03-24 08:30:36,605] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 137000, global step 2193737: learning rate 0.0000
[2019-03-24 08:30:36,818] A3C_AGENT_WORKER-Thread-18 INFO:Local step 137000, global step 2193840: loss 0.0010
[2019-03-24 08:30:36,820] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 137000, global step 2193841: learning rate 0.0000
[2019-03-24 08:30:37,080] A3C_AGENT_WORKER-Thread-19 INFO:Local step 137000, global step 2193967: loss 0.0058
[2019-03-24 08:30:37,081] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 137000, global step 2193967: learning rate 0.0000
[2019-03-24 08:30:37,288] A3C_AGENT_WORKER-Thread-10 INFO:Local step 137000, global step 2194062: loss 0.0028
[2019-03-24 08:30:37,290] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 137000, global step 2194062: learning rate 0.0000
[2019-03-24 08:30:38,107] A3C_AGENT_WORKER-Thread-17 INFO:Local step 137000, global step 2194466: loss 0.0218
[2019-03-24 08:30:38,110] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 137000, global step 2194467: learning rate 0.0000
[2019-03-24 08:30:38,143] A3C_AGENT_WORKER-Thread-13 INFO:Local step 137000, global step 2194478: loss 0.0064
[2019-03-24 08:30:38,146] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 137000, global step 2194479: learning rate 0.0000
[2019-03-24 08:30:38,400] A3C_AGENT_WORKER-Thread-20 INFO:Local step 137000, global step 2194609: loss 0.0010
[2019-03-24 08:30:38,403] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 137000, global step 2194610: learning rate 0.0000
[2019-03-24 08:30:45,520] A3C_AGENT_WORKER-Thread-12 INFO:Local step 138000, global step 2198035: loss 0.0132
[2019-03-24 08:30:45,521] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 138000, global step 2198035: learning rate 0.0000
[2019-03-24 08:30:45,575] A3C_AGENT_WORKER-Thread-3 INFO:Local step 137500, global step 2198058: loss 75.3134
[2019-03-24 08:30:45,576] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 137500, global step 2198058: learning rate 0.0000
[2019-03-24 08:30:46,287] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 7.1112305e-27 5.1658529e-31 4.3302775e-26 4.8001308e-27], sum to 1.0000
[2019-03-24 08:30:46,291] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1641
[2019-03-24 08:30:46,296] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1639044.739811614 W.
[2019-03-24 08:30:46,299] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.33333333333334, 92.33333333333334, 1.0, 2.0, 0.7186671511342773, 1.0, 2.0, 0.7186671511342773, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1639044.739811614, 1639044.739811614, 311292.2531019634], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2992800.0000, 
sim time next is 2993400.0000, 
raw observation next is [25.5, 91.5, 1.0, 2.0, 0.8616071670723943, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1697259.643945594, 1697259.643945594, 348801.0231070989], 
processed observation next is [1.0, 0.6521739130434783, 0.5, 0.915, 1.0, 1.0, 0.8352466274671361, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, 0.0, 0.0, 0.8094621288201359, 0.6061641585519979, 0.6061641585519979, 0.6707711982828825], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3582364], dtype=float32), -1.2722397]. 
=============================================
[2019-03-24 08:30:47,406] A3C_AGENT_WORKER-Thread-15 INFO:Local step 137500, global step 2198951: loss 42.5748
[2019-03-24 08:30:47,408] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 137500, global step 2198951: learning rate 0.0000
[2019-03-24 08:30:49,558] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-24 08:30:49,561] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:30:49,562] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:30:49,563] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:30:49,563] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:30:49,564] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:30:49,565] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:30:49,565] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:30:49,567] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:30:49,564] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:30:49,569] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:30:49,593] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run89
[2019-03-24 08:30:49,618] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run89
[2019-03-24 08:30:49,660] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run89
[2019-03-24 08:30:49,683] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run89
[2019-03-24 08:30:49,684] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run89
[2019-03-24 08:30:54,253] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.024307745]
[2019-03-24 08:30:54,254] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.131669875, 36.947864575, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5501068721649479, 6.911199999999999, 6.9112, 121.9260426156618, 396866.99566111, 396866.9956611104, 120402.356371056]
[2019-03-24 08:30:54,255] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:30:54,257] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 3.3767170e-37 2.4273858e-36], sampled 0.006537700737051844
[2019-03-24 08:31:08,231] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.024307745]
[2019-03-24 08:31:08,232] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [38.0, 14.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7154537363927003, 6.911200000000001, 6.9112, 121.9260426156618, 532949.8083641382, 532949.8083641378, 143376.3864828224]
[2019-03-24 08:31:08,234] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:31:08,237] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.4043641e-37 0.0000000e+00 3.6026387e-36 2.5128140e-35], sampled 0.6997415525417685
[2019-03-24 08:31:22,774] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.024307745]
[2019-03-24 08:31:22,777] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.16666666666667, 82.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7609120121419186, 6.911200000000001, 6.9112, 121.9260426156618, 567264.78505932, 567264.7850593197, 154207.5808267188]
[2019-03-24 08:31:22,778] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:31:22,781] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 8.3629403e-37 0.0000000e+00 2.1189256e-35 1.3437874e-34], sampled 0.09419144964423021
[2019-03-24 08:31:30,339] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.024307745]
[2019-03-24 08:31:30,340] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.23333333333333, 75.33333333333333, 1.0, 2.0, 0.7555932201705589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 861198.1184049137, 861198.1184049132, 186934.2533673787]
[2019-03-24 08:31:30,341] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:31:30,344] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 7.1970278e-28 8.7182297e-31 6.3364990e-27 2.6350062e-26], sampled 0.23189670408887242
[2019-03-24 08:31:30,345] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 861198.1184049137 W.
[2019-03-24 08:32:12,416] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.024307745]
[2019-03-24 08:32:12,418] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.16666666666667, 92.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7001418018848791, 6.911200000000001, 6.9112, 121.9260426156618, 523053.8584889029, 523053.8584889024, 145682.2498812418]
[2019-03-24 08:32:12,418] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:32:12,421] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 2.3083926e-38 0.0000000e+00 6.7420985e-37 4.5503071e-36], sampled 0.9043307555369304
[2019-03-24 08:32:14,450] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.024307745]
[2019-03-24 08:32:14,452] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.785736275, 73.9776207, 1.0, 2.0, 0.6591994918727523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 751278.1516393148, 751278.1516393148, 168562.1373396125]
[2019-03-24 08:32:14,453] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:32:14,456] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 3.4964197e-30 2.0908729e-33 3.7215948e-29 1.7943545e-28], sampled 0.9642104817348529
[2019-03-24 08:32:14,462] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 751278.1516393148 W.
[2019-03-24 08:32:18,096] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.024307745]
[2019-03-24 08:32:18,097] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [30.14691594666667, 54.92712749, 1.0, 2.0, 0.7795366509823023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 906920.0691452497, 906920.0691452497, 192677.0862475413]
[2019-03-24 08:32:18,098] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:32:18,100] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.9986579e-27 2.3218789e-30 1.5246640e-26 6.1742713e-26], sampled 0.3162578636750959
[2019-03-24 08:32:18,101] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 906920.0691452497 W.
[2019-03-24 08:32:34,576] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 08:32:34,606] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 08:32:34,641] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 08:32:34,691] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 08:32:34,739] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 08:32:35,755] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 2200000, evaluation results [2200000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 08:32:35,774] A3C_AGENT_WORKER-Thread-21 INFO:Local step 138000, global step 2200014: loss 0.0068
[2019-03-24 08:32:35,778] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 138000, global step 2200016: learning rate 0.0000
[2019-03-24 08:32:36,645] A3C_AGENT_WORKER-Thread-2 INFO:Local step 137500, global step 2200458: loss 2.3167
[2019-03-24 08:32:36,648] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 137500, global step 2200459: learning rate 0.0000
[2019-03-24 08:32:36,909] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 6.6541604e-27 2.1161463e-28 2.3006103e-25 4.0889110e-24], sum to 1.0000
[2019-03-24 08:32:36,917] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0460
[2019-03-24 08:32:36,925] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1594372.086275872 W.
[2019-03-24 08:32:36,928] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.23333333333333, 88.0, 1.0, 2.0, 0.699097125700938, 1.0, 2.0, 0.699097125700938, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1594372.086275872, 1594372.086275872, 303823.8249694155], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2996400.0000, 
sim time next is 2997000.0000, 
raw observation next is [26.35, 87.5, 1.0, 2.0, 0.7284330825113011, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1545254.837162214, 1545254.837162215, 322457.2797624255], 
processed observation next is [1.0, 0.6956521739130435, 0.5314814814814816, 0.875, 1.0, 1.0, 0.6767060506086918, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5518767275579336, 0.5518767275579339, 0.6201101533892799], 
reward next is 0.3799, 
noisyNet noise sample is [array([-0.44471204], dtype=float32), 0.21786723]. 
=============================================
[2019-03-24 08:32:36,942] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[39.71719 ]
 [39.71898 ]
 [39.461018]
 [39.619938]
 [39.464016]], R is [[39.8890686 ]
 [39.90589905]
 [39.84123611]
 [39.44282532]
 [39.04839706]].
[2019-03-24 08:32:37,708] A3C_AGENT_WORKER-Thread-9 INFO:Local step 137500, global step 2201000: loss -74.0122
[2019-03-24 08:32:37,711] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 137500, global step 2201003: learning rate 0.0000
[2019-03-24 08:32:37,794] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.2758884e-19 3.6179947e-21 3.7786924e-19 8.0371143e-19], sum to 1.0000
[2019-03-24 08:32:37,803] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1252
[2019-03-24 08:32:37,809] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 805232.3758602766 W.
[2019-03-24 08:32:37,816] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.8, 91.33333333333334, 1.0, 2.0, 0.3532580441464361, 1.0, 1.0, 0.3532580441464361, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 805232.3758602766, 805232.3758602766, 193731.9663841164], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2954400.0000, 
sim time next is 2955000.0000, 
raw observation next is [24.75, 90.66666666666666, 1.0, 2.0, 0.350143812444966, 1.0, 2.0, 0.350143812444966, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 798129.9592200132, 798129.9592200137, 192928.7520095108], 
processed observation next is [1.0, 0.17391304347826086, 0.4722222222222222, 0.9066666666666666, 1.0, 1.0, 0.2263616814821024, 1.0, 1.0, 0.2263616814821024, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2850464140071476, 0.28504641400714775, 0.37101683078752073], 
reward next is 0.6290, 
noisyNet noise sample is [array([1.1591264], dtype=float32), -0.91765785]. 
=============================================
[2019-03-24 08:32:37,829] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[29.928888]
 [29.782028]
 [30.013466]
 [29.94584 ]
 [30.047457]], R is [[29.83293915]
 [29.53461075]
 [29.90061951]
 [30.22727203]
 [30.4666748 ]].
[2019-03-24 08:32:37,854] A3C_AGENT_WORKER-Thread-11 INFO:Local step 137500, global step 2201075: loss -54.0855
[2019-03-24 08:32:37,856] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 137500, global step 2201075: learning rate 0.0000
[2019-03-24 08:32:37,997] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.4027746e-21 3.0690034e-23 2.4239727e-20 3.2345042e-19], sum to 1.0000
[2019-03-24 08:32:38,007] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0958
[2019-03-24 08:32:38,011] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1993065.024073381 W.
[2019-03-24 08:32:38,015] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.26666666666667, 81.33333333333333, 1.0, 2.0, 0.8737204003546261, 1.0, 2.0, 0.8737204003546261, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156496, 1993065.024073381, 1993065.024073381, 375159.4416106606], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2976000.0000, 
sim time next is 2976600.0000, 
raw observation next is [28.33333333333334, 80.66666666666667, 1.0, 2.0, 0.8520061854600377, 1.0, 2.0, 0.8520061854600377, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1943478.299382929, 1943478.299382929, 365713.7383390254], 
processed observation next is [1.0, 0.43478260869565216, 0.6049382716049385, 0.8066666666666668, 1.0, 1.0, 0.8238168874524259, 1.0, 1.0, 0.8238168874524259, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.6940993926367603, 0.6940993926367603, 0.703295650651972], 
reward next is 0.2967, 
noisyNet noise sample is [array([0.49680644], dtype=float32), 1.6909811]. 
=============================================
[2019-03-24 08:32:38,139] A3C_AGENT_WORKER-Thread-22 INFO:Local step 137500, global step 2201222: loss -44.2976
[2019-03-24 08:32:38,143] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 137500, global step 2201226: learning rate 0.0000
[2019-03-24 08:32:39,220] A3C_AGENT_WORKER-Thread-16 INFO:Local step 137500, global step 2201779: loss 95.1832
[2019-03-24 08:32:39,221] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 137500, global step 2201779: learning rate 0.0000
[2019-03-24 08:32:39,239] A3C_AGENT_WORKER-Thread-14 INFO:Local step 137500, global step 2201786: loss 37.6506
[2019-03-24 08:32:39,244] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 137500, global step 2201787: learning rate 0.0000
[2019-03-24 08:32:39,444] A3C_AGENT_WORKER-Thread-18 INFO:Local step 137500, global step 2201888: loss 0.8252
[2019-03-24 08:32:39,447] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 137500, global step 2201890: learning rate 0.0000
[2019-03-24 08:32:39,684] A3C_AGENT_WORKER-Thread-19 INFO:Local step 137500, global step 2202016: loss 78.2967
[2019-03-24 08:32:39,686] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 137500, global step 2202016: learning rate 0.0000
[2019-03-24 08:32:39,868] A3C_AGENT_WORKER-Thread-10 INFO:Local step 137500, global step 2202107: loss 70.3068
[2019-03-24 08:32:39,870] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 137500, global step 2202107: learning rate 0.0000
[2019-03-24 08:32:40,477] A3C_AGENT_WORKER-Thread-17 INFO:Local step 137500, global step 2202423: loss 143.4237
[2019-03-24 08:32:40,484] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 137500, global step 2202423: learning rate 0.0000
[2019-03-24 08:32:40,785] A3C_AGENT_WORKER-Thread-13 INFO:Local step 137500, global step 2202582: loss -3.9099
[2019-03-24 08:32:40,786] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 137500, global step 2202582: learning rate 0.0000
[2019-03-24 08:32:40,961] A3C_AGENT_WORKER-Thread-20 INFO:Local step 137500, global step 2202669: loss 66.0184
[2019-03-24 08:32:40,965] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 137500, global step 2202671: learning rate 0.0000
[2019-03-24 08:32:43,642] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.00000000e+00 1.32848074e-20 3.28849290e-23 3.38808785e-20
 1.07681422e-19], sum to 1.0000
[2019-03-24 08:32:43,646] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9841
[2019-03-24 08:32:43,652] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2385640.042433196 W.
[2019-03-24 08:32:43,657] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.66666666666666, 78.16666666666667, 1.0, 2.0, 0.7673882487690431, 1.0, 2.0, 0.6970587863609562, 1.0, 1.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2385640.042433196, 2385640.042433196, 447839.3193579992], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3063000.0000, 
sim time next is 3063600.0000, 
raw observation next is [30.0, 76.0, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 7.311076709387724, 6.9112, 121.9243985001236, 2532218.699011174, 2327448.844492685, 443049.4781047471], 
processed observation next is [1.0, 0.4782608695652174, 0.6666666666666666, 0.76, 1.0, 1.0, 1.0238095238095237, 1.0, 1.0, 1.0238095238095237, 0.0, 0.5, -0.25, 0.039987670938772354, 0.0, 0.809451213602722, 0.9043638210754193, 0.831231730175959, 0.8520182271245136], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.33205664], dtype=float32), -0.2243277]. 
=============================================
[2019-03-24 08:32:43,718] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.3606438e-20 2.7738195e-23 2.9167729e-20 9.8397257e-20], sum to 1.0000
[2019-03-24 08:32:43,732] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1783
[2019-03-24 08:32:43,742] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2145937.334993764 W.
[2019-03-24 08:32:43,749] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.33333333333334, 77.0, 1.0, 2.0, 0.6274791779845023, 1.0, 2.0, 0.6271042509686858, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2145937.334993764, 2145937.334993764, 410321.0031254041], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3064800.0000, 
sim time next is 3065400.0000, 
raw observation next is [30.5, 77.5, 1.0, 2.0, 0.7164523447117203, 1.0, 2.0, 0.6715908343322947, 1.0, 2.0, 0.9977734948820727, 6.911200000000001, 6.9112, 121.94756008, 2298365.384301953, 2298365.384301953, 433690.3565301244], 
processed observation next is [1.0, 0.4782608695652174, 0.6851851851851852, 0.775, 1.0, 1.0, 0.6624432675139527, 1.0, 1.0, 0.6090367075384461, 1.0, 1.0, 0.9972168686025908, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.8208447801078403, 0.8208447801078403, 0.8340199164040853], 
reward next is 0.1660, 
noisyNet noise sample is [array([0.33205664], dtype=float32), -0.2243277]. 
=============================================
[2019-03-24 08:32:47,002] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 2.8005858e-27 3.0026919e-32 3.3086586e-26 1.1725012e-27], sum to 1.0000
[2019-03-24 08:32:47,008] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3789
[2019-03-24 08:32:47,013] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1908780.991535186 W.
[2019-03-24 08:32:47,018] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.45, 31.5, 1.0, 2.0, 0.5577625859174432, 1.0, 2.0, 0.5577625859174432, 1.0, 2.0, 0.8879838126500434, 6.911200000000001, 6.9112, 121.94756008, 1908780.991535186, 1908780.991535185, 372846.3130251566], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3162600.0000, 
sim time next is 3163200.0000, 
raw observation next is [34.5, 31.66666666666666, 1.0, 2.0, 0.7985538631925456, 1.0, 2.0, 0.7985538631925456, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1846879.471375996, 1846879.471375996, 344483.2661553634], 
processed observation next is [1.0, 0.6086956521739131, 0.8333333333333334, 0.3166666666666666, 1.0, 1.0, 0.7601831704673162, 1.0, 1.0, 0.7601831704673162, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6595998112057129, 0.6595998112057129, 0.662467819529545], 
reward next is 0.3375, 
noisyNet noise sample is [array([0.26900446], dtype=float32), -0.35451245]. 
=============================================
[2019-03-24 08:32:47,119] A3C_AGENT_WORKER-Thread-3 INFO:Local step 138000, global step 2205846: loss 0.0283
[2019-03-24 08:32:47,123] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 138000, global step 2205846: learning rate 0.0000
[2019-03-24 08:32:47,452] A3C_AGENT_WORKER-Thread-12 INFO:Local step 138500, global step 2206014: loss 1.8480
[2019-03-24 08:32:47,452] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 138500, global step 2206014: learning rate 0.0000
[2019-03-24 08:32:48,801] A3C_AGENT_WORKER-Thread-15 INFO:Local step 138000, global step 2206716: loss 0.0150
[2019-03-24 08:32:48,805] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 138000, global step 2206717: learning rate 0.0000
[2019-03-24 08:32:48,868] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 3.5054904e-36 5.9353077e-36], sum to 1.0000
[2019-03-24 08:32:48,874] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9321
[2019-03-24 08:32:48,881] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.33333333333334, 60.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8741281211260211, 6.911200000000001, 6.9112, 121.9260426156618, 642802.8364693229, 642802.8364693224, 171841.0001576731], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3189000.0000, 
sim time next is 3189600.0000, 
raw observation next is [28.0, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8732161847093721, 6.9112, 6.9112, 121.9260426156618, 642219.1395899634, 642219.1395899634, 171700.6821634506], 
processed observation next is [1.0, 0.9565217391304348, 0.5925925925925926, 0.62, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.841520230886715, 0.0, 0.0, 0.8094621288201359, 0.2293639784249869, 0.2293639784249869, 0.3301936195450973], 
reward next is 0.6698, 
noisyNet noise sample is [array([-0.32411605], dtype=float32), -0.62339735]. 
=============================================
[2019-03-24 08:32:51,383] A3C_AGENT_WORKER-Thread-21 INFO:Local step 138500, global step 2208052: loss 0.5853
[2019-03-24 08:32:51,384] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 138500, global step 2208052: learning rate 0.0000
[2019-03-24 08:32:51,927] A3C_AGENT_WORKER-Thread-2 INFO:Local step 138000, global step 2208338: loss 0.0042
[2019-03-24 08:32:51,935] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 138000, global step 2208338: learning rate 0.0000
[2019-03-24 08:32:53,010] A3C_AGENT_WORKER-Thread-9 INFO:Local step 138000, global step 2208893: loss 0.0070
[2019-03-24 08:32:53,014] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 138000, global step 2208894: learning rate 0.0000
[2019-03-24 08:32:53,395] A3C_AGENT_WORKER-Thread-11 INFO:Local step 138000, global step 2209098: loss 0.0797
[2019-03-24 08:32:53,399] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 138000, global step 2209099: learning rate 0.0000
[2019-03-24 08:32:53,521] A3C_AGENT_WORKER-Thread-22 INFO:Local step 138000, global step 2209164: loss 0.0458
[2019-03-24 08:32:53,524] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 138000, global step 2209164: learning rate 0.0000
[2019-03-24 08:32:54,427] A3C_AGENT_WORKER-Thread-16 INFO:Local step 138000, global step 2209631: loss 0.0242
[2019-03-24 08:32:54,431] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 138000, global step 2209631: learning rate 0.0000
[2019-03-24 08:32:54,511] A3C_AGENT_WORKER-Thread-14 INFO:Local step 138000, global step 2209677: loss 0.0452
[2019-03-24 08:32:54,513] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 138000, global step 2209677: learning rate 0.0000
[2019-03-24 08:32:54,746] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 3.511831e-38 0.000000e+00], sum to 1.0000
[2019-03-24 08:32:54,753] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8808
[2019-03-24 08:32:54,756] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.9, 97.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8124762232499523, 6.911199999999999, 6.9112, 121.9260426156618, 603024.7782398058, 603024.7782398063, 162108.1513063015], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3303600.0000, 
sim time next is 3304200.0000, 
raw observation next is [21.95, 98.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8258164527609045, 6.9112, 6.9112, 121.9260426156618, 611861.3777230855, 611861.3777230855, 164235.7192461581], 
processed observation next is [0.0, 0.21739130434782608, 0.36851851851851847, 0.9883333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7822705659511305, 0.0, 0.0, 0.8094621288201359, 0.21852192061538767, 0.21852192061538767, 0.3158379216272271], 
reward next is 0.6842, 
noisyNet noise sample is [array([0.9274886], dtype=float32), -0.5197269]. 
=============================================
[2019-03-24 08:32:55,078] A3C_AGENT_WORKER-Thread-19 INFO:Local step 138000, global step 2209969: loss 0.0113
[2019-03-24 08:32:55,081] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 138000, global step 2209969: learning rate 0.0000
[2019-03-24 08:32:55,149] A3C_AGENT_WORKER-Thread-18 INFO:Local step 138000, global step 2210001: loss 0.0155
[2019-03-24 08:32:55,151] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 138000, global step 2210001: learning rate 0.0000
[2019-03-24 08:32:55,353] A3C_AGENT_WORKER-Thread-10 INFO:Local step 138000, global step 2210106: loss 0.0457
[2019-03-24 08:32:55,355] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 138000, global step 2210108: learning rate 0.0000
[2019-03-24 08:32:55,508] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.7185865e-26 1.3103912e-28 3.8089567e-25 1.6316392e-24], sum to 1.0000
[2019-03-24 08:32:55,515] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4915
[2019-03-24 08:32:55,524] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 903413.7613333048 W.
[2019-03-24 08:32:55,530] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.16666666666667, 97.0, 1.0, 2.0, 0.3963051644372959, 0.0, 1.0, 0.0, 1.0, 2.0, 0.630930728542313, 6.9112, 6.9112, 121.9260426156419, 903413.7613333048, 903413.7613333048, 222961.8253393829], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3465600.0000, 
sim time next is 3466200.0000, 
raw observation next is [24.08333333333333, 98.5, 1.0, 2.0, 0.3877816713694001, 1.0, 1.0, 0.3877816713694001, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 883972.4760013582, 883972.4760013582, 202859.8389964047], 
processed observation next is [1.0, 0.08695652173913043, 0.4475308641975307, 0.985, 1.0, 1.0, 0.271168656392143, 1.0, 0.5, 0.271168656392143, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3157044557147708, 0.3157044557147708, 0.39011507499308595], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.67497635], dtype=float32), -0.7516984]. 
=============================================
[2019-03-24 08:32:55,756] A3C_AGENT_WORKER-Thread-17 INFO:Local step 138000, global step 2210315: loss 0.0260
[2019-03-24 08:32:55,758] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 138000, global step 2210318: learning rate 0.0000
[2019-03-24 08:32:55,972] A3C_AGENT_WORKER-Thread-13 INFO:Local step 138000, global step 2210429: loss 0.0566
[2019-03-24 08:32:55,975] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 138000, global step 2210429: learning rate 0.0000
[2019-03-24 08:32:56,012] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 2.6686670e-22 5.5717210e-24 1.5279051e-21 8.5550630e-21], sum to 1.0000
[2019-03-24 08:32:56,019] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1909
[2019-03-24 08:32:56,026] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 796678.8618579126 W.
[2019-03-24 08:32:56,033] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.2330050474006116, 1.0, 2.0, 0.2330050474006116, 1.0, 1.0, 0.3709516239063907, 6.9112, 6.9112, 121.94756008, 796678.8618579126, 796678.8618579126, 231679.8795520046], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3475200.0000, 
sim time next is 3475800.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.6657740067196278, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 758774.7199782819, 758774.7199782819, 169764.5098759437], 
processed observation next is [1.0, 0.21739130434782608, 0.48148148148148145, 0.94, 1.0, 1.0, 0.6021119127614617, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.27099097142081496, 0.27099097142081496, 0.32647021129989173], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3539697], dtype=float32), 0.03851297]. 
=============================================
[2019-03-24 08:32:56,457] A3C_AGENT_WORKER-Thread-20 INFO:Local step 138000, global step 2210685: loss 0.1641
[2019-03-24 08:32:56,458] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 138000, global step 2210686: learning rate 0.0000
[2019-03-24 08:32:58,376] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 2.8200392e-30 3.2597643e-32 1.7574960e-27 1.5754332e-27], sum to 1.0000
[2019-03-24 08:32:58,382] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9300
[2019-03-24 08:32:58,386] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.25, 72.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9023247889585818, 6.911200000000001, 6.9112, 121.9260426156618, 652371.6432497714, 652371.643249771, 177548.014167614], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3519000.0000, 
sim time next is 3519600.0000, 
raw observation next is [27.16666666666667, 74.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.927610243075494, 6.911200000000001, 6.9112, 121.9260426156618, 669763.5517666655, 669763.5517666651, 181094.5907061915], 
processed observation next is [1.0, 0.7391304347826086, 0.5617283950617286, 0.7433333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9095128038443675, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23920126848809484, 0.23920126848809467, 0.34825882828113747], 
reward next is 0.6517, 
noisyNet noise sample is [array([-0.7545174], dtype=float32), 0.7073736]. 
=============================================
[2019-03-24 08:32:58,696] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 8.0347698e-30 1.1657327e-32 5.3691667e-28 7.1109586e-27], sum to 1.0000
[2019-03-24 08:32:58,707] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1902
[2019-03-24 08:32:58,717] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 758680.7003277724 W.
[2019-03-24 08:32:58,724] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.73333333333333, 87.33333333333334, 1.0, 2.0, 0.332845775789046, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5299013150862967, 6.911199999999999, 6.9112, 121.9260426156618, 758680.7003277724, 758680.7003277729, 204282.0221344449], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3363600.0000, 
sim time next is 3364200.0000, 
raw observation next is [25.6, 86.5, 1.0, 2.0, 0.2188575156659972, 1.0, 1.0, 0.2188575156659972, 1.0, 2.0, 0.3484282926319428, 6.911199999999999, 6.9112, 121.94756008, 748282.7426767903, 748282.7426767908, 226853.6082149887], 
processed observation next is [0.0, 0.9565217391304348, 0.5037037037037038, 0.865, 1.0, 1.0, 0.07006847103094906, 1.0, 0.5, 0.07006847103094906, 1.0, 1.0, 0.1855353657899285, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.2672438366702823, 0.26724383667028245, 0.43625693887497824], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.83274674], dtype=float32), -1.2656702]. 
=============================================
[2019-03-24 08:32:59,018] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 9.5158369e-28 1.1038426e-29 3.4969904e-24 2.5220049e-27], sum to 1.0000
[2019-03-24 08:32:59,024] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6508
[2019-03-24 08:32:59,029] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2083760.025356716 W.
[2019-03-24 08:32:59,035] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.33333333333333, 59.83333333333333, 1.0, 2.0, 0.9134329662796745, 1.0, 2.0, 0.9134329662796745, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156442, 2083760.025356716, 2083760.025356716, 392855.5942338827], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3419400.0000, 
sim time next is 3420000.0000, 
raw observation next is [30.2, 60.0, 1.0, 2.0, 0.9165871124442948, 1.0, 2.0, 0.9165871124442948, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2090963.815023437, 2090963.815023438, 394284.5690234495], 
processed observation next is [1.0, 0.6086956521739131, 0.674074074074074, 0.6, 1.0, 1.0, 0.9006989433860653, 1.0, 1.0, 0.9006989433860653, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.7467727910797989, 0.7467727910797993, 0.758239555814326], 
reward next is 0.2418, 
noisyNet noise sample is [array([0.29521975], dtype=float32), 0.22477502]. 
=============================================
[2019-03-24 08:32:59,062] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[42.095627]
 [41.78638 ]
 [41.431442]
 [40.988583]
 [40.453648]], R is [[42.291008  ]
 [41.86809921]
 [41.44941711]
 [41.03492355]
 [40.62457657]].
[2019-03-24 08:33:01,374] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 2.2647068e-27 1.1928465e-29 6.6048966e-27 2.2894367e-27], sum to 1.0000
[2019-03-24 08:33:01,379] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5259
[2019-03-24 08:33:01,393] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 785358.8397206649 W.
[2019-03-24 08:33:01,397] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.6890878480145702, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 785358.8397206649, 785358.8397206644, 174087.7992303205], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3447000.0000, 
sim time next is 3447600.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.2301848497729828, 1.0, 1.0, 0.2301848497729828, 1.0, 1.0, 0.3664617774357811, 6.911199999999999, 6.9112, 121.94756008, 787031.2376376296, 787031.23763763, 230708.869326417], 
processed observation next is [1.0, 0.9130434782608695, 0.5185185185185185, 0.89, 1.0, 1.0, 0.0835533925868843, 1.0, 0.5, 0.0835533925868843, 1.0, 0.5, 0.20807722179472637, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.281082584870582, 0.28108258487058213, 0.44367090255080194], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.26015815], dtype=float32), -0.11025377]. 
=============================================
[2019-03-24 08:33:02,785] A3C_AGENT_WORKER-Thread-3 INFO:Local step 138500, global step 2214034: loss 1.4063
[2019-03-24 08:33:02,786] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 138500, global step 2214034: learning rate 0.0000
[2019-03-24 08:33:03,239] A3C_AGENT_WORKER-Thread-12 INFO:Local step 139000, global step 2214270: loss -131.9225
[2019-03-24 08:33:03,240] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 139000, global step 2214270: learning rate 0.0000
[2019-03-24 08:33:04,405] A3C_AGENT_WORKER-Thread-15 INFO:Local step 138500, global step 2214834: loss 1.7446
[2019-03-24 08:33:04,407] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 138500, global step 2214835: learning rate 0.0000
[2019-03-24 08:33:04,786] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.2231323e-32 6.5247588e-35 1.2083211e-30 2.5000261e-31], sum to 1.0000
[2019-03-24 08:33:04,792] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3032
[2019-03-24 08:33:04,795] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.25, 83.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7255084183401794, 6.9112, 6.9112, 121.9260426156618, 542147.8418780201, 542147.8418780201, 147988.5492299245], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3539400.0000, 
sim time next is 3540000.0000, 
raw observation next is [22.4, 84.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7345793964282591, 6.9112, 6.9112, 121.9260426156618, 548721.7756624157, 548721.7756624157, 149722.0801213568], 
processed observation next is [1.0, 1.0, 0.38518518518518513, 0.8433333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6682242455353238, 0.0, 0.0, 0.8094621288201359, 0.19597206273657702, 0.19597206273657702, 0.2879270771564554], 
reward next is 0.7121, 
noisyNet noise sample is [array([0.12693745], dtype=float32), -0.05890658]. 
=============================================
[2019-03-24 08:33:04,813] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[48.34476]
 [48.51876]
 [48.66985]
 [47.35617]
 [46.97715]], R is [[49.63155365]
 [49.85064697]
 [50.06570053]
 [50.26443863]
 [50.44583893]].
[2019-03-24 08:33:07,086] A3C_AGENT_WORKER-Thread-21 INFO:Local step 139000, global step 2216145: loss 170.2338
[2019-03-24 08:33:07,090] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 139000, global step 2216147: learning rate 0.0000
[2019-03-24 08:33:07,614] A3C_AGENT_WORKER-Thread-2 INFO:Local step 138500, global step 2216398: loss 5.5598
[2019-03-24 08:33:07,616] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 138500, global step 2216398: learning rate 0.0000
[2019-03-24 08:33:08,670] A3C_AGENT_WORKER-Thread-9 INFO:Local step 138500, global step 2216903: loss 0.8551
[2019-03-24 08:33:08,672] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 138500, global step 2216903: learning rate 0.0000
[2019-03-24 08:33:08,852] A3C_AGENT_WORKER-Thread-11 INFO:Local step 138500, global step 2216991: loss 3.9025
[2019-03-24 08:33:08,855] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 138500, global step 2216992: learning rate 0.0000
[2019-03-24 08:33:09,084] A3C_AGENT_WORKER-Thread-22 INFO:Local step 138500, global step 2217107: loss 1.2118
[2019-03-24 08:33:09,086] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 138500, global step 2217107: learning rate 0.0000
[2019-03-24 08:33:10,104] A3C_AGENT_WORKER-Thread-16 INFO:Local step 138500, global step 2217607: loss 1.6955
[2019-03-24 08:33:10,106] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 138500, global step 2217607: learning rate 0.0000
[2019-03-24 08:33:10,464] A3C_AGENT_WORKER-Thread-14 INFO:Local step 138500, global step 2217782: loss 1.4745
[2019-03-24 08:33:10,466] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 138500, global step 2217782: learning rate 0.0000
[2019-03-24 08:33:10,778] A3C_AGENT_WORKER-Thread-19 INFO:Local step 138500, global step 2217930: loss 3.9698
[2019-03-24 08:33:10,782] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 138500, global step 2217930: learning rate 0.0000
[2019-03-24 08:33:11,026] A3C_AGENT_WORKER-Thread-18 INFO:Local step 138500, global step 2218055: loss 2.2537
[2019-03-24 08:33:11,027] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 138500, global step 2218055: learning rate 0.0000
[2019-03-24 08:33:11,131] A3C_AGENT_WORKER-Thread-10 INFO:Local step 138500, global step 2218103: loss 1.4079
[2019-03-24 08:33:11,132] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 138500, global step 2218104: learning rate 0.0000
[2019-03-24 08:33:11,419] A3C_AGENT_WORKER-Thread-17 INFO:Local step 138500, global step 2218243: loss 2.1032
[2019-03-24 08:33:11,421] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 138500, global step 2218243: learning rate 0.0000
[2019-03-24 08:33:12,016] A3C_AGENT_WORKER-Thread-13 INFO:Local step 138500, global step 2218538: loss 0.3733
[2019-03-24 08:33:12,018] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 138500, global step 2218539: learning rate 0.0000
[2019-03-24 08:33:12,518] A3C_AGENT_WORKER-Thread-20 INFO:Local step 138500, global step 2218780: loss 1.5506
[2019-03-24 08:33:12,521] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 138500, global step 2218781: learning rate 0.0000
[2019-03-24 08:33:12,842] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.6215515e-37 0.0000000e+00 4.4630688e-33 2.4526685e-34], sum to 1.0000
[2019-03-24 08:33:12,848] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8425
[2019-03-24 08:33:12,853] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8739782628562902, 6.911200000000001, 6.9112, 121.9260426156618, 641054.2755806273, 641054.2755806268, 172211.3378645033], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3618000.0000, 
sim time next is 3618600.0000, 
raw observation next is [23.83333333333333, 90.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8829010636994679, 6.9112, 6.9112, 121.9260426156618, 646712.2266507584, 646712.2266507584, 173569.4583038826], 
processed observation next is [1.0, 0.9130434782608695, 0.43827160493827144, 0.9083333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8536263296243348, 0.0, 0.0, 0.8094621288201359, 0.23096865237527087, 0.23096865237527087, 0.33378741981515886], 
reward next is 0.6662, 
noisyNet noise sample is [array([-2.0551484], dtype=float32), 0.2934823]. 
=============================================
[2019-03-24 08:33:17,043] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 2.5717006e-25 1.1715534e-27 1.0560440e-25 8.6784383e-25], sum to 1.0000
[2019-03-24 08:33:17,054] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9031
[2019-03-24 08:33:17,061] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2149612.941651369 W.
[2019-03-24 08:33:17,067] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.33333333333333, 77.66666666666667, 1.0, 2.0, 0.6296248303385796, 1.0, 2.0, 0.6281770771457246, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.94756008, 2149612.941651369, 2149612.941651369, 410864.4336047283], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3759000.0000, 
sim time next is 3759600.0000, 
raw observation next is [30.66666666666667, 76.33333333333334, 1.0, 2.0, 0.4718305838631616, 1.0, 2.0, 0.4718305838631616, 1.0, 2.0, 0.7511696559594819, 6.911199999999999, 6.9112, 121.94756008, 1614114.124538617, 1614114.124538617, 329975.6661204734], 
processed observation next is [1.0, 0.5217391304347826, 0.6913580246913582, 0.7633333333333334, 1.0, 1.0, 0.37122688555138295, 1.0, 1.0, 0.37122688555138295, 1.0, 1.0, 0.6889620699493523, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5764693301923632, 0.5764693301923632, 0.6345685886932181], 
reward next is 0.3654, 
noisyNet noise sample is [array([-1.3050191], dtype=float32), -1.4309074]. 
=============================================
[2019-03-24 08:33:17,662] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 5.4828111e-23 3.3396261e-25 6.5188557e-22 3.1862016e-21], sum to 1.0000
[2019-03-24 08:33:17,669] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5639
[2019-03-24 08:33:17,677] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1495793.548211186 W.
[2019-03-24 08:33:17,680] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.55, 73.5, 1.0, 2.0, 0.4372760801536612, 1.0, 2.0, 0.4372760801536612, 1.0, 1.0, 0.6961577606923371, 6.911200000000001, 6.9112, 121.94756008, 1495793.548211186, 1495793.548211186, 313795.8799575012], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4098600.0000, 
sim time next is 4099200.0000, 
raw observation next is [26.73333333333333, 71.66666666666666, 1.0, 2.0, 0.7329819046762727, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9968641342720028, 6.9112, 6.9112, 121.9260426156618, 1551246.653390684, 1551246.653390684, 323154.8761212688], 
processed observation next is [1.0, 0.43478260869565216, 0.545679012345679, 0.7166666666666666, 1.0, 1.0, 0.6821213150908008, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9960801678400035, 0.0, 0.0, 0.8094621288201359, 0.5540166619252442, 0.5540166619252442, 0.6214516848485938], 
reward next is 0.3785, 
noisyNet noise sample is [array([-0.5299971], dtype=float32), 0.42143407]. 
=============================================
[2019-03-24 08:33:19,214] A3C_AGENT_WORKER-Thread-3 INFO:Local step 139000, global step 2222057: loss 20.1100
[2019-03-24 08:33:19,216] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 139000, global step 2222057: learning rate 0.0000
[2019-03-24 08:33:19,682] A3C_AGENT_WORKER-Thread-12 INFO:Local step 139500, global step 2222288: loss 41.6683
[2019-03-24 08:33:19,683] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 139500, global step 2222289: learning rate 0.0000
[2019-03-24 08:33:20,393] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.0145684e-34 2.1533007e-38 4.5782440e-32 1.2795495e-33], sum to 1.0000
[2019-03-24 08:33:20,400] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8987
[2019-03-24 08:33:20,405] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 942160.5049592999 W.
[2019-03-24 08:33:20,410] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.66666666666667, 71.66666666666667, 1.0, 2.0, 0.2755280005886061, 1.0, 1.0, 0.2755280005886061, 1.0, 2.0, 0.43864955025758, 6.911199999999999, 6.9112, 121.94756008, 942160.5049592999, 942160.5049593004, 246859.3683615546], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3788400.0000, 
sim time next is 3789000.0000, 
raw observation next is [30.75, 68.5, 1.0, 2.0, 0.3998572313869195, 1.0, 2.0, 0.3998572313869195, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 911515.8372643967, 911515.8372643972, 206151.9301728936], 
processed observation next is [1.0, 0.8695652173913043, 0.6944444444444444, 0.685, 1.0, 1.0, 0.28554432307966604, 1.0, 1.0, 0.28554432307966604, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3255413704515703, 0.32554137045157044, 0.3964460195632569], 
reward next is 0.6036, 
noisyNet noise sample is [array([-0.75415057], dtype=float32), -0.5309021]. 
=============================================
[2019-03-24 08:33:20,432] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[50.294235]
 [49.95653 ]
 [49.169216]
 [49.52857 ]
 [49.711227]], R is [[49.6995163 ]
 [49.20252228]
 [48.71049881]
 [48.74235535]
 [48.81498718]].
[2019-03-24 08:33:20,918] A3C_AGENT_WORKER-Thread-15 INFO:Local step 139000, global step 2222901: loss -171.0755
[2019-03-24 08:33:20,919] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 139000, global step 2222901: learning rate 0.0000
[2019-03-24 08:33:21,710] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 2.7232574e-27 4.9125094e-31 3.0638871e-26 3.8418778e-25], sum to 1.0000
[2019-03-24 08:33:21,720] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1133
[2019-03-24 08:33:21,725] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 733574.5613766143 W.
[2019-03-24 08:33:21,735] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 84.0, 1.0, 2.0, 0.321836565170444, 1.0, 1.0, 0.321836565170444, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 733574.5613766143, 733574.5613766147, 185783.5112106853], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3805200.0000, 
sim time next is 3805800.0000, 
raw observation next is [26.11666666666667, 82.0, 1.0, 2.0, 0.212281396124297, 1.0, 2.0, 0.212281396124297, 1.0, 1.0, 0.3379588961522944, 6.9112, 6.9112, 121.94756008, 725788.0802032991, 725788.0802032991, 224648.3522828522], 
processed observation next is [0.0, 0.043478260869565216, 0.5228395061728397, 0.82, 1.0, 1.0, 0.06223975729082976, 1.0, 1.0, 0.06223975729082976, 1.0, 0.5, 0.172448620190368, 0.0, 0.0, 0.8096049824067558, 0.25921002864403536, 0.25921002864403536, 0.43201606208240806], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.65490013], dtype=float32), 1.1402365]. 
=============================================
[2019-03-24 08:33:23,481] A3C_AGENT_WORKER-Thread-21 INFO:Local step 139500, global step 2224152: loss 116.6388
[2019-03-24 08:33:23,483] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 139500, global step 2224152: learning rate 0.0000
[2019-03-24 08:33:24,171] A3C_AGENT_WORKER-Thread-2 INFO:Local step 139000, global step 2224480: loss -120.9911
[2019-03-24 08:33:24,173] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 139000, global step 2224481: learning rate 0.0000
[2019-03-24 08:33:25,129] A3C_AGENT_WORKER-Thread-9 INFO:Local step 139000, global step 2224950: loss 120.6459
[2019-03-24 08:33:25,130] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 139000, global step 2224950: learning rate 0.0000
[2019-03-24 08:33:25,132] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.3158441e-31 5.2550278e-34 1.9925190e-30 1.1550318e-28], sum to 1.0000
[2019-03-24 08:33:25,140] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6318
[2019-03-24 08:33:25,144] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.35, 74.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9255849750873809, 6.911200000000001, 6.9112, 121.9260426156618, 674267.8275329418, 674267.8275329414, 179955.8164315205], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4314600.0000, 
sim time next is 4315200.0000, 
raw observation next is [26.13333333333333, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9068679506113217, 6.911200000000001, 6.9112, 121.9260426156618, 664399.0395054026, 664399.0395054021, 176712.8271672135], 
processed observation next is [1.0, 0.9565217391304348, 0.5234567901234567, 0.74, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8835849382641522, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23728537125192947, 0.2372853712519293, 0.339832359936949], 
reward next is 0.6602, 
noisyNet noise sample is [array([-1.5855954], dtype=float32), 2.0785985]. 
=============================================
[2019-03-24 08:33:25,248] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-24 08:33:25,250] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:33:25,251] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:33:25,251] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:33:25,252] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:33:25,252] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:33:25,253] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:33:25,254] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:33:25,255] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:33:25,254] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:33:25,258] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:33:25,275] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run90
[2019-03-24 08:33:25,303] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run90
[2019-03-24 08:33:25,304] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run90
[2019-03-24 08:33:25,361] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run90
[2019-03-24 08:33:25,389] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run90
[2019-03-24 08:33:32,860] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.024409177]
[2019-03-24 08:33:32,862] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [17.05, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4305714365626257, 6.9112, 6.9112, 121.9260426156618, 307422.239929176, 307422.239929176, 100955.7694793297]
[2019-03-24 08:33:32,864] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:33:32,867] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.000000e+00 6.339299e-36 0.000000e+00 1.180373e-34 3.048462e-34], sampled 0.24288723915790233
[2019-03-24 08:33:46,105] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.024409177]
[2019-03-24 08:33:46,106] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [35.99187407666667, 1.759506713166667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7371313110427155, 6.9112, 6.9112, 121.9260426156618, 526377.0051423459, 526377.0051423459, 120414.8041020001]
[2019-03-24 08:33:46,108] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:33:46,112] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.00000000e+00 8.78256829e-35 1.34290327e-38 1.40344585e-33
 3.77152256e-33], sampled 0.5294729523799659
[2019-03-24 08:33:50,517] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.024409177]
[2019-03-24 08:33:50,518] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.83333333333334, 43.0, 1.0, 2.0, 0.8246369952769639, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 974614.4921956595, 974614.4921956595, 202790.4971735056]
[2019-03-24 08:33:50,519] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:33:50,524] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.00000000e+00 1.68319922e-27 1.89490329e-30 1.26821686e-26
 2.89899357e-26], sampled 0.6292957532184226
[2019-03-24 08:33:50,525] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 974614.4921956595 W.
[2019-03-24 08:34:03,134] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.024409177]
[2019-03-24 08:34:03,135] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.0, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9290309569790074, 6.9112, 6.9112, 121.9260426156618, 674854.7361428775, 674854.7361428775, 180733.713676709]
[2019-03-24 08:34:03,136] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:34:03,138] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 9.8166681e-35 1.5692466e-38 1.6065562e-33 4.1304991e-33], sampled 0.8655593943179238
[2019-03-24 08:34:11,327] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.024409177]
[2019-03-24 08:34:11,328] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [21.93333333333333, 92.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7867418711086012, 6.911200000000001, 6.9112, 121.9260426156618, 586115.8351730895, 586115.835173089, 157638.8282880463]
[2019-03-24 08:34:11,328] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:34:11,333] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.7094044e-36 0.0000000e+00 3.2281422e-35 8.4994435e-35], sampled 0.8565877085497176
[2019-03-24 08:34:20,122] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.024409177]
[2019-03-24 08:34:20,122] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [30.12766503, 84.02636920666666, 1.0, 2.0, 0.8535855816343878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 972957.2044969111, 972957.2044969111, 207276.1398121114]
[2019-03-24 08:34:20,125] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:34:20,129] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.5680884e-27 1.4139105e-30 1.0668911e-26 2.5474553e-26], sampled 0.5423748231277161
[2019-03-24 08:34:20,130] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 972957.2044969111 W.
[2019-03-24 08:34:20,983] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.024409177]
[2019-03-24 08:34:20,985] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.46666666666667, 69.33333333333333, 1.0, 2.0, 0.8519726471899604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 971117.540618647, 971117.5406186465, 206911.1116907617]
[2019-03-24 08:34:20,986] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:34:20,995] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 9.9529483e-26 2.4436731e-28 7.6246473e-25 1.5388644e-24], sampled 0.9025138050450962
[2019-03-24 08:34:20,996] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 971117.540618647 W.
[2019-03-24 08:34:31,171] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.024409177]
[2019-03-24 08:34:31,173] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.49704010666667, 99.75434395666667, 1.0, 2.0, 0.6467114088355622, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260425548304, 737038.8590409321, 737038.8590409321, 166302.0211607458]
[2019-03-24 08:34:31,174] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:34:31,179] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 2.1223804e-27 2.7975599e-30 1.8086849e-26 3.6948790e-26], sampled 0.9304435802735871
[2019-03-24 08:34:31,181] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 737038.8590409321 W.
[2019-03-24 08:34:35,272] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.024409177]
[2019-03-24 08:34:35,274] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.68980298, 77.32923228666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9400991404668231, 6.911200000000001, 6.9112, 121.9260426156618, 680478.4719617792, 680478.4719617787, 182596.7567216258]
[2019-03-24 08:34:35,275] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:34:35,280] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.0366965e-34 1.5814578e-38 1.6500212e-33 4.3694385e-33], sampled 0.47025586295952904
[2019-03-24 08:34:47,670] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.024409177]
[2019-03-24 08:34:47,670] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.76666666666667, 73.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7872085603991934, 6.9112, 6.9112, 121.9260426156618, 585736.4319147958, 585736.4319147958, 158184.1813045467]
[2019-03-24 08:34:47,671] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:34:47,672] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 2.6628773e-32 7.6011688e-36 3.3334175e-31 8.8368945e-31], sampled 0.24022525228912994
[2019-03-24 08:34:51,783] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.024409177]
[2019-03-24 08:34:51,786] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.13333333333333, 92.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8352564119783923, 6.911199999999999, 6.9112, 121.9260426156618, 615564.4896764627, 615564.4896764632, 166506.511590857]
[2019-03-24 08:34:51,787] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:34:51,789] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.00000000e+00 1.43307115e-33 3.06881763e-37 2.05040936e-32
 5.49560125e-32], sampled 0.358808134614758
[2019-03-24 08:34:52,847] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.024409177]
[2019-03-24 08:34:52,850] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.28708544666667, 95.85279835666667, 1.0, 2.0, 0.7318033482221726, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 834068.5196637844, 834068.5196637844, 182251.4224074345]
[2019-03-24 08:34:52,851] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:34:52,853] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.8123946e-25 3.3504671e-28 1.1919990e-24 2.4804662e-24], sampled 0.5965654896382021
[2019-03-24 08:34:52,854] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 834068.5196637844 W.
[2019-03-24 08:35:09,319] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 08:35:09,615] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 08:35:09,685] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 08:35:09,834] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 08:35:09,862] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 08:35:10,877] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 2225000, evaluation results [2225000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 08:35:10,950] A3C_AGENT_WORKER-Thread-11 INFO:Local step 139000, global step 2225041: loss -147.2833
[2019-03-24 08:35:10,952] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 139000, global step 2225043: learning rate 0.0000
[2019-03-24 08:35:11,119] A3C_AGENT_WORKER-Thread-22 INFO:Local step 139000, global step 2225126: loss -52.4223
[2019-03-24 08:35:11,120] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 139000, global step 2225126: learning rate 0.0000
[2019-03-24 08:35:12,107] A3C_AGENT_WORKER-Thread-16 INFO:Local step 139000, global step 2225630: loss 111.0383
[2019-03-24 08:35:12,109] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 139000, global step 2225630: learning rate 0.0000
[2019-03-24 08:35:12,459] A3C_AGENT_WORKER-Thread-14 INFO:Local step 139000, global step 2225810: loss -49.4392
[2019-03-24 08:35:12,461] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 139000, global step 2225810: learning rate 0.0000
[2019-03-24 08:35:12,513] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 2.1933289e-28 1.8611105e-31 1.2096096e-27 7.6498443e-26], sum to 1.0000
[2019-03-24 08:35:12,521] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0558
[2019-03-24 08:35:12,526] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 837566.8910175321 W.
[2019-03-24 08:35:12,530] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.15, 73.16666666666667, 1.0, 2.0, 0.3674355539588915, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5849693684431201, 6.911199999999999, 6.9112, 121.9260426156618, 837566.8910175321, 837566.8910175326, 214267.1640416355], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3876600.0000, 
sim time next is 3877200.0000, 
raw observation next is [29.0, 74.0, 1.0, 2.0, 0.3663676994983095, 1.0, 1.0, 0.3663676994983095, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 835131.3977482726, 835131.3977482731, 197150.7500867514], 
processed observation next is [0.0, 0.9130434782608695, 0.6296296296296297, 0.74, 1.0, 1.0, 0.24567583273608273, 1.0, 0.5, 0.24567583273608273, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.29826121348152596, 0.2982612134815261, 0.3791360578591373], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1327369], dtype=float32), 1.8888915]. 
=============================================
[2019-03-24 08:35:12,599] A3C_AGENT_WORKER-Thread-19 INFO:Local step 139000, global step 2225879: loss -43.9613
[2019-03-24 08:35:12,602] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 139000, global step 2225880: learning rate 0.0000
[2019-03-24 08:35:12,899] A3C_AGENT_WORKER-Thread-18 INFO:Local step 139000, global step 2226031: loss -7.2953
[2019-03-24 08:35:12,900] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 139000, global step 2226031: learning rate 0.0000
[2019-03-24 08:35:13,043] A3C_AGENT_WORKER-Thread-10 INFO:Local step 139000, global step 2226102: loss 24.4975
[2019-03-24 08:35:13,045] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 139000, global step 2226102: learning rate 0.0000
[2019-03-24 08:35:13,429] A3C_AGENT_WORKER-Thread-17 INFO:Local step 139000, global step 2226306: loss -22.0036
[2019-03-24 08:35:13,430] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 139000, global step 2226306: learning rate 0.0000
[2019-03-24 08:35:13,520] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 3.6698352e-25 9.2746113e-28 8.3014918e-24 5.6254574e-23], sum to 1.0000
[2019-03-24 08:35:13,525] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8627
[2019-03-24 08:35:13,530] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 871931.1702673566 W.
[2019-03-24 08:35:13,534] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.66666666666667, 85.66666666666667, 1.0, 2.0, 0.255001616219438, 1.0, 2.0, 0.255001616219438, 1.0, 2.0, 0.4059708778441957, 6.911200000000001, 6.9112, 121.94756008, 871931.1702673566, 871931.1702673561, 239405.9591794029], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3964800.0000, 
sim time next is 3965400.0000, 
raw observation next is [27.5, 86.5, 1.0, 2.0, 0.2509550099609128, 1.0, 2.0, 0.2509550099609128, 1.0, 2.0, 0.3995285488918584, 6.911199999999999, 6.9112, 121.94756008, 858086.7992644198, 858086.7992644203, 237964.3384798531], 
processed observation next is [0.0, 0.9130434782608695, 0.5740740740740741, 0.865, 1.0, 1.0, 0.10827977376299143, 1.0, 1.0, 0.10827977376299143, 1.0, 1.0, 0.24941068611482298, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.3064595711658642, 0.30645957116586436, 0.45762372784587135], 
reward next is 0.5424, 
noisyNet noise sample is [array([-0.07673652], dtype=float32), -0.05497808]. 
=============================================
[2019-03-24 08:35:13,774] A3C_AGENT_WORKER-Thread-13 INFO:Local step 139000, global step 2226475: loss 25.7286
[2019-03-24 08:35:13,777] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 139000, global step 2226476: learning rate 0.0000
[2019-03-24 08:35:14,437] A3C_AGENT_WORKER-Thread-20 INFO:Local step 139000, global step 2226817: loss 50.8680
[2019-03-24 08:35:14,439] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 139000, global step 2226817: learning rate 0.0000
[2019-03-24 08:35:20,573] A3C_AGENT_WORKER-Thread-3 INFO:Local step 139500, global step 2229992: loss 166.4127
[2019-03-24 08:35:20,574] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 139500, global step 2229992: learning rate 0.0000
[2019-03-24 08:35:20,806] A3C_AGENT_WORKER-Thread-12 INFO:Local step 140000, global step 2230106: loss 7.3932
[2019-03-24 08:35:20,809] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 140000, global step 2230106: learning rate 0.0000
[2019-03-24 08:35:22,495] A3C_AGENT_WORKER-Thread-15 INFO:Local step 139500, global step 2230942: loss 183.1597
[2019-03-24 08:35:22,497] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 139500, global step 2230942: learning rate 0.0000
[2019-03-24 08:35:23,597] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 2.4902099e-26 7.3466163e-30 3.4571575e-25 2.8430860e-25], sum to 1.0000
[2019-03-24 08:35:23,601] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8820
[2019-03-24 08:35:23,608] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2139987.638099178 W.
[2019-03-24 08:35:23,615] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.1, 68.0, 1.0, 2.0, 0.9380512920330182, 1.0, 2.0, 0.9380512920330182, 0.0, 2.0, 0.0, 6.911199999999997, 6.9112, 121.9260426156618, 2139987.638099178, 2139987.638099179, 404101.2096277873], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4120200.0000, 
sim time next is 4120800.0000, 
raw observation next is [29.13333333333333, 67.33333333333334, 1.0, 2.0, 0.6197888162166122, 1.0, 2.0, 0.6197888162166122, 1.0, 1.0, 0.9867239805293947, 6.911200000000001, 6.9112, 121.94756008, 2120874.34845226, 2120874.348452259, 406262.9345204791], 
processed observation next is [1.0, 0.6956521739130435, 0.6345679012345677, 0.6733333333333335, 1.0, 1.0, 0.5473676383531098, 1.0, 1.0, 0.5473676383531098, 1.0, 0.5, 0.9834049756617432, 8.881784197001253e-17, 0.0, 0.8096049824067558, 0.7574551244472356, 0.7574551244472353, 0.7812748740778445], 
reward next is 0.2187, 
noisyNet noise sample is [array([-0.5155651], dtype=float32), -1.026436]. 
=============================================
[2019-03-24 08:35:23,853] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 6.1327633e-28 1.6806165e-31 8.4345886e-27 5.7551162e-27], sum to 1.0000
[2019-03-24 08:35:23,865] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4289
[2019-03-24 08:35:23,868] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.93333333333333, 91.33333333333334, 1.0, 2.0, 0.2973911923344869, 1.0, 1.0, 0.2973911923344869, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 684607.1271207177, 684607.1271207181, 180170.7121463831], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4498800.0000, 
sim time next is 4499400.0000, 
raw observation next is [23.91666666666667, 90.66666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9322558042542516, 6.9112, 6.9112, 121.9260426156618, 678815.6525776641, 678815.6525776641, 180916.9580368899], 
processed observation next is [0.0, 0.043478260869565216, 0.4413580246913582, 0.9066666666666666, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9153197553178144, 0.0, 0.0, 0.8094621288201359, 0.24243416163488005, 0.24243416163488005, 0.34791722699401906], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.13553584], dtype=float32), -0.6115334]. 
=============================================
[2019-03-24 08:35:24,509] A3C_AGENT_WORKER-Thread-21 INFO:Local step 140000, global step 2231981: loss 7.3968
[2019-03-24 08:35:24,510] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 140000, global step 2231982: learning rate 0.0000
[2019-03-24 08:35:25,492] A3C_AGENT_WORKER-Thread-2 INFO:Local step 139500, global step 2232489: loss 161.4127
[2019-03-24 08:35:25,494] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 139500, global step 2232489: learning rate 0.0000
[2019-03-24 08:35:26,218] A3C_AGENT_WORKER-Thread-9 INFO:Local step 139500, global step 2232864: loss 186.2859
[2019-03-24 08:35:26,219] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 139500, global step 2232864: learning rate 0.0000
[2019-03-24 08:35:26,584] A3C_AGENT_WORKER-Thread-11 INFO:Local step 139500, global step 2233052: loss 189.3765
[2019-03-24 08:35:26,585] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 139500, global step 2233052: learning rate 0.0000
[2019-03-24 08:35:26,747] A3C_AGENT_WORKER-Thread-22 INFO:Local step 139500, global step 2233135: loss 208.5722
[2019-03-24 08:35:26,752] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 139500, global step 2233135: learning rate 0.0000
[2019-03-24 08:35:27,638] A3C_AGENT_WORKER-Thread-16 INFO:Local step 139500, global step 2233595: loss 156.6759
[2019-03-24 08:35:27,640] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 139500, global step 2233595: learning rate 0.0000
[2019-03-24 08:35:28,308] A3C_AGENT_WORKER-Thread-19 INFO:Local step 139500, global step 2233950: loss 138.8979
[2019-03-24 08:35:28,310] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 139500, global step 2233951: learning rate 0.0000
[2019-03-24 08:35:28,375] A3C_AGENT_WORKER-Thread-14 INFO:Local step 139500, global step 2233982: loss 126.3937
[2019-03-24 08:35:28,377] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 139500, global step 2233982: learning rate 0.0000
[2019-03-24 08:35:28,404] A3C_AGENT_WORKER-Thread-18 INFO:Local step 139500, global step 2233996: loss 122.6597
[2019-03-24 08:35:28,406] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 139500, global step 2233996: learning rate 0.0000
[2019-03-24 08:35:28,608] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.1210887e-29 1.2703974e-31 2.2271731e-27 2.1178999e-27], sum to 1.0000
[2019-03-24 08:35:28,621] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2779
[2019-03-24 08:35:28,630] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 796797.3480477565 W.
[2019-03-24 08:35:28,634] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.9, 62.5, 1.0, 2.0, 0.3318729712171354, 1.0, 1.0, 0.3318729712171354, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 796797.3480477565, 796797.3480477569, 190021.5100005974], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4260600.0000, 
sim time next is 4261200.0000, 
raw observation next is [26.53333333333333, 58.66666666666667, 1.0, 2.0, 0.3414129250942022, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5520377943025394, 6.9112, 6.9112, 121.9260426156618, 821336.3357851495, 821336.3357851495, 205179.3045974169], 
processed observation next is [1.0, 0.30434782608695654, 0.5382716049382715, 0.5866666666666667, 1.0, 1.0, 0.21596776796928832, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.4400472428781742, 0.0, 0.0, 0.8094621288201359, 0.29333440563755336, 0.29333440563755336, 0.39457558576426327], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.49182737], dtype=float32), 0.22067457]. 
=============================================
[2019-03-24 08:35:28,889] A3C_AGENT_WORKER-Thread-10 INFO:Local step 139500, global step 2234250: loss 185.2414
[2019-03-24 08:35:28,891] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 139500, global step 2234250: learning rate 0.0000
[2019-03-24 08:35:29,096] A3C_AGENT_WORKER-Thread-17 INFO:Local step 139500, global step 2234355: loss 181.7316
[2019-03-24 08:35:29,098] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 139500, global step 2234355: learning rate 0.0000
[2019-03-24 08:35:29,605] A3C_AGENT_WORKER-Thread-13 INFO:Local step 139500, global step 2234618: loss 161.4687
[2019-03-24 08:35:29,608] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 139500, global step 2234621: learning rate 0.0000
[2019-03-24 08:35:30,072] A3C_AGENT_WORKER-Thread-20 INFO:Local step 139500, global step 2234865: loss 86.4950
[2019-03-24 08:35:30,074] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 139500, global step 2234866: learning rate 0.0000
[2019-03-24 08:35:32,391] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 9.9727343e-29 3.2053356e-32 1.4769314e-27 2.1448687e-27], sum to 1.0000
[2019-03-24 08:35:32,397] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1083
[2019-03-24 08:35:32,408] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1495283.885946798 W.
[2019-03-24 08:35:32,415] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.98333333333333, 37.66666666666666, 1.0, 2.0, 0.6593169075277246, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9681920672665175, 6.911199999999999, 6.9112, 121.9260426156618, 1495283.885946798, 1495283.885946798, 303686.3447020235], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4276200.0000, 
sim time next is 4276800.0000, 
raw observation next is [32.0, 38.0, 1.0, 2.0, 0.4728128887837408, 1.0, 1.0, 0.4728128887837408, 1.0, 2.0, 0.7541915499174571, 6.9112, 6.9112, 121.94756008, 1646057.191198916, 1646057.191198916, 330553.1598141865], 
processed observation next is [1.0, 0.5217391304347826, 0.7407407407407407, 0.38, 1.0, 1.0, 0.37239629617112, 1.0, 0.5, 0.37239629617112, 1.0, 1.0, 0.6927394373968212, 0.0, 0.0, 0.8096049824067558, 0.5878775682853271, 0.5878775682853271, 0.6356791534888202], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.565471], dtype=float32), 0.36720538]. 
=============================================
[2019-03-24 08:35:36,022] A3C_AGENT_WORKER-Thread-3 INFO:Local step 140000, global step 2237934: loss 8.9473
[2019-03-24 08:35:36,027] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 140000, global step 2237934: learning rate 0.0000
[2019-03-24 08:35:36,857] A3C_AGENT_WORKER-Thread-12 INFO:Local step 140500, global step 2238400: loss -6.3425
[2019-03-24 08:35:36,858] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 140500, global step 2238400: learning rate 0.0000
[2019-03-24 08:35:37,776] A3C_AGENT_WORKER-Thread-15 INFO:Local step 140000, global step 2238876: loss 13.1895
[2019-03-24 08:35:37,777] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 140000, global step 2238876: learning rate 0.0000
[2019-03-24 08:35:40,348] A3C_AGENT_WORKER-Thread-21 INFO:Local step 140500, global step 2240140: loss 43.3060
[2019-03-24 08:35:40,351] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 140500, global step 2240141: learning rate 0.0000
[2019-03-24 08:35:41,082] A3C_AGENT_WORKER-Thread-2 INFO:Local step 140000, global step 2240494: loss 21.2130
[2019-03-24 08:35:41,086] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 140000, global step 2240494: learning rate 0.0000
[2019-03-24 08:35:41,605] A3C_AGENT_WORKER-Thread-9 INFO:Local step 140000, global step 2240759: loss 10.1781
[2019-03-24 08:35:41,609] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 140000, global step 2240759: learning rate 0.0000
[2019-03-24 08:35:42,143] A3C_AGENT_WORKER-Thread-22 INFO:Local step 140000, global step 2241015: loss 14.0834
[2019-03-24 08:35:42,146] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 140000, global step 2241016: learning rate 0.0000
[2019-03-24 08:35:42,161] A3C_AGENT_WORKER-Thread-11 INFO:Local step 140000, global step 2241029: loss 10.1137
[2019-03-24 08:35:42,165] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 140000, global step 2241029: learning rate 0.0000
[2019-03-24 08:35:43,294] A3C_AGENT_WORKER-Thread-16 INFO:Local step 140000, global step 2241572: loss 11.0412
[2019-03-24 08:35:43,295] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 140000, global step 2241572: learning rate 0.0000
[2019-03-24 08:35:43,868] A3C_AGENT_WORKER-Thread-19 INFO:Local step 140000, global step 2241860: loss 13.8594
[2019-03-24 08:35:43,869] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 140000, global step 2241860: learning rate 0.0000
[2019-03-24 08:35:43,973] A3C_AGENT_WORKER-Thread-18 INFO:Local step 140000, global step 2241911: loss 2.2430
[2019-03-24 08:35:43,974] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 140000, global step 2241911: learning rate 0.0000
[2019-03-24 08:35:44,024] A3C_AGENT_WORKER-Thread-14 INFO:Local step 140000, global step 2241940: loss 12.0541
[2019-03-24 08:35:44,026] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 140000, global step 2241940: learning rate 0.0000
[2019-03-24 08:35:44,543] A3C_AGENT_WORKER-Thread-10 INFO:Local step 140000, global step 2242198: loss 7.9227
[2019-03-24 08:35:44,545] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 140000, global step 2242198: learning rate 0.0000
[2019-03-24 08:35:44,852] A3C_AGENT_WORKER-Thread-17 INFO:Local step 140000, global step 2242342: loss 13.5470
[2019-03-24 08:35:44,856] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 140000, global step 2242346: learning rate 0.0000
[2019-03-24 08:35:45,515] A3C_AGENT_WORKER-Thread-13 INFO:Local step 140000, global step 2242665: loss 3.5900
[2019-03-24 08:35:45,516] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 140000, global step 2242666: learning rate 0.0000
[2019-03-24 08:35:46,088] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 7.6743223e-30 1.5121308e-32 1.0231843e-28 1.7709018e-27], sum to 1.0000
[2019-03-24 08:35:46,093] A3C_AGENT_WORKER-Thread-20 INFO:Local step 140000, global step 2242951: loss 8.0263
[2019-03-24 08:35:46,094] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 140000, global step 2242951: learning rate 0.0000
[2019-03-24 08:35:46,095] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3365
[2019-03-24 08:35:46,099] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.13333333333333, 99.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7826714147659718, 6.911200000000001, 6.9112, 121.9260426156618, 582815.624805106, 582815.6248051055, 157334.7328036972], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4599600.0000, 
sim time next is 4600200.0000, 
raw observation next is [21.06666666666667, 99.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7761458282786416, 6.911200000000001, 6.9112, 121.9260426156618, 578124.1239498281, 578124.1239498276, 156423.8798786789], 
processed observation next is [1.0, 0.21739130434782608, 0.3358024691358026, 0.9983333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.720182285348302, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2064729014106529, 0.20647290141065272, 0.30081515361284406], 
reward next is 0.6992, 
noisyNet noise sample is [array([0.5365978], dtype=float32), 2.1818774]. 
=============================================
[2019-03-24 08:35:52,390] A3C_AGENT_WORKER-Thread-3 INFO:Local step 140500, global step 2246034: loss 17.3642
[2019-03-24 08:35:52,398] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 140500, global step 2246037: learning rate 0.0000
[2019-03-24 08:35:53,429] A3C_AGENT_WORKER-Thread-12 INFO:Local step 141000, global step 2246550: loss -233.6146
[2019-03-24 08:35:53,431] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 141000, global step 2246550: learning rate 0.0000
[2019-03-24 08:35:54,240] A3C_AGENT_WORKER-Thread-15 INFO:Local step 140500, global step 2246946: loss 40.4778
[2019-03-24 08:35:54,242] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 140500, global step 2246947: learning rate 0.0000
[2019-03-24 08:35:57,018] A3C_AGENT_WORKER-Thread-21 INFO:Local step 141000, global step 2248302: loss -109.0266
[2019-03-24 08:35:57,019] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 141000, global step 2248302: learning rate 0.0000
[2019-03-24 08:35:57,322] A3C_AGENT_WORKER-Thread-2 INFO:Local step 140500, global step 2248452: loss 16.9885
[2019-03-24 08:35:57,323] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 140500, global step 2248452: learning rate 0.0000
[2019-03-24 08:35:57,742] A3C_AGENT_WORKER-Thread-9 INFO:Local step 140500, global step 2248667: loss 30.2604
[2019-03-24 08:35:57,744] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 140500, global step 2248667: learning rate 0.0000
[2019-03-24 08:35:58,289] A3C_AGENT_WORKER-Thread-11 INFO:Local step 140500, global step 2248927: loss -33.1255
[2019-03-24 08:35:58,291] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 140500, global step 2248927: learning rate 0.0000
[2019-03-24 08:35:58,423] A3C_AGENT_WORKER-Thread-22 INFO:Local step 140500, global step 2248995: loss 5.7245
[2019-03-24 08:35:58,424] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 140500, global step 2248995: learning rate 0.0000
[2019-03-24 08:35:58,629] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 4.1404390e-25 9.4485527e-29 3.0608527e-24 6.7011721e-23], sum to 1.0000
[2019-03-24 08:35:58,638] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3217
[2019-03-24 08:35:58,645] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 823608.8117485198 W.
[2019-03-24 08:35:58,652] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 93.83333333333334, 1.0, 2.0, 0.3613155168239157, 1.0, 2.0, 0.3613155168239157, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 823608.8117485198, 823608.8117485202, 195826.6762312431], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4828200.0000, 
sim time next is 4828800.0000, 
raw observation next is [26.0, 93.66666666666667, 1.0, 2.0, 0.239899823704387, 1.0, 2.0, 0.239899823704387, 1.0, 1.0, 0.3819283323291888, 6.9112, 6.9112, 121.94756008, 820265.7382118768, 820265.7382118768, 234072.5118694836], 
processed observation next is [1.0, 0.9130434782608695, 0.5185185185185185, 0.9366666666666668, 1.0, 1.0, 0.09511883774331786, 1.0, 1.0, 0.09511883774331786, 1.0, 0.5, 0.22741041541148602, 0.0, 0.0, 0.8096049824067558, 0.2929520493613846, 0.2929520493613846, 0.4501394459028531], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.18510276], dtype=float32), -0.7463412]. 
=============================================
[2019-03-24 08:35:59,387] A3C_AGENT_WORKER-Thread-16 INFO:Local step 140500, global step 2249468: loss 42.2251
[2019-03-24 08:35:59,390] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 140500, global step 2249470: learning rate 0.0000
[2019-03-24 08:36:00,241] A3C_AGENT_WORKER-Thread-18 INFO:Local step 140500, global step 2249879: loss -20.8486
[2019-03-24 08:36:00,245] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 140500, global step 2249880: learning rate 0.0000
[2019-03-24 08:36:00,319] A3C_AGENT_WORKER-Thread-19 INFO:Local step 140500, global step 2249914: loss -19.9864
[2019-03-24 08:36:00,323] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 140500, global step 2249914: learning rate 0.0000
[2019-03-24 08:36:00,446] A3C_AGENT_WORKER-Thread-14 INFO:Local step 140500, global step 2249979: loss 34.1223
[2019-03-24 08:36:00,447] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 140500, global step 2249979: learning rate 0.0000
[2019-03-24 08:36:00,493] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-24 08:36:00,495] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:36:00,497] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:36:00,498] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:36:00,498] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:36:00,499] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:36:00,501] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:36:00,501] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:36:00,502] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:36:00,502] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:36:00,503] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:36:00,526] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run91
[2019-03-24 08:36:00,558] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run91
[2019-03-24 08:36:00,558] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run91
[2019-03-24 08:36:00,559] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run91
[2019-03-24 08:36:00,584] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run91
[2019-03-24 08:36:11,606] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.024057982]
[2019-03-24 08:36:11,607] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.0, 42.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6738914325165164, 6.911200000000001, 6.9112, 121.9260426156618, 498432.5741158109, 498432.5741158105, 136454.5471474032]
[2019-03-24 08:36:11,607] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:36:11,610] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 8.5107316e-28 3.2715132e-31 7.9274635e-27 5.9254035e-27], sampled 0.33614592023502565
[2019-03-24 08:36:15,137] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.024057982]
[2019-03-24 08:36:15,138] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.46872388166667, 44.23240521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7392484862884404, 6.9112, 6.9112, 121.9260426156618, 543024.1540965217, 543024.1540965217, 141146.0583784711]
[2019-03-24 08:36:15,138] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:36:15,140] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.5197465e-25 1.1051282e-28 1.1272195e-24 9.2781284e-25], sampled 0.35908723136129583
[2019-03-24 08:36:29,760] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.024057982]
[2019-03-24 08:36:29,761] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.95, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8448109431189701, 6.9112, 6.9112, 121.9260426156618, 623539.8240002125, 623539.8240002125, 167436.8368320284]
[2019-03-24 08:36:29,763] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:36:29,767] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.5833206e-26 8.0021020e-30 1.2180473e-25 1.0053229e-25], sampled 0.04595370945282806
[2019-03-24 08:36:34,918] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.024057982]
[2019-03-24 08:36:34,920] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [25.5, 74.0, 1.0, 2.0, 0.5699659355203383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 674430.3990646513, 674430.3990646513, 154109.7601317775]
[2019-03-24 08:36:34,921] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:36:34,928] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.00000000e+00 1.01065485e-20 5.07154511e-23 4.12712461e-20
 3.87336434e-20], sampled 0.14950340900160564
[2019-03-24 08:36:42,900] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.024057982]
[2019-03-24 08:36:42,900] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [30.26666666666667, 68.33333333333333, 1.0, 2.0, 0.722510085244408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 823470.8884123401, 823470.8884123401, 180452.5209965075]
[2019-03-24 08:36:42,901] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:36:42,905] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 8.0138389e-21 2.2573285e-23 3.1433939e-20 2.9449921e-20], sampled 0.3055678921717526
[2019-03-24 08:36:42,906] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 823470.8884123401 W.
[2019-03-24 08:36:57,158] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.024057982]
[2019-03-24 08:36:57,160] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [31.95, 62.5, 1.0, 2.0, 0.5580244454114055, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8883930906823805, 6.9112, 6.9112, 121.9260426156618, 1272373.711625352, 1272373.711625352, 277890.6121158852]
[2019-03-24 08:36:57,161] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:36:57,168] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 6.5719209e-20 2.5772434e-22 2.2716380e-19 2.0828315e-19], sampled 0.4918982444409553
[2019-03-24 08:36:57,169] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1272373.711625352 W.
[2019-03-24 08:37:10,214] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.024057982]
[2019-03-24 08:37:10,215] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [22.8, 96.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.873260097868298, 6.911199999999999, 6.9112, 121.9260426156618, 641934.8327374614, 641934.8327374619, 171785.9670937347]
[2019-03-24 08:37:10,217] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:37:10,222] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.5162994e-27 6.3473728e-31 1.3687086e-26 1.0247010e-26], sampled 0.5024325121430027
[2019-03-24 08:37:35,297] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.024057982]
[2019-03-24 08:37:35,299] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [23.33333333333334, 75.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7110086255213769, 6.911200000000001, 6.9112, 121.9260426156618, 531282.5229864849, 531282.5229864845, 146518.7432120871]
[2019-03-24 08:37:35,299] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:37:35,302] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.0514403e-27 4.0184462e-31 9.5741352e-27 7.1709421e-27], sampled 0.6874148217263802
[2019-03-24 08:37:36,688] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.024057982]
[2019-03-24 08:37:36,690] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [18.56368057, 75.80516678500001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4949326108566505, 6.911199999999999, 6.9112, 121.9260426156618, 353854.5538030933, 353854.5538030938, 113174.7204177197]
[2019-03-24 08:37:36,691] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:37:36,693] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.00000000e+00 1.12149193e-27 4.49276198e-31 1.03742466e-26
 7.74825575e-27], sampled 0.4525912064120031
[2019-03-24 08:37:45,044] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 08:37:45,048] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 08:37:45,114] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 08:37:45,162] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 08:37:45,165] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 08:37:46,183] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 2250000, evaluation results [2250000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 08:37:46,466] A3C_AGENT_WORKER-Thread-10 INFO:Local step 140500, global step 2250145: loss 14.5208
[2019-03-24 08:37:46,470] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 140500, global step 2250146: learning rate 0.0000
[2019-03-24 08:37:46,636] A3C_AGENT_WORKER-Thread-17 INFO:Local step 140500, global step 2250230: loss 7.6460
[2019-03-24 08:37:46,639] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 140500, global step 2250230: learning rate 0.0000
[2019-03-24 08:37:47,253] A3C_AGENT_WORKER-Thread-13 INFO:Local step 140500, global step 2250547: loss -6.2629
[2019-03-24 08:37:47,254] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 140500, global step 2250547: learning rate 0.0000
[2019-03-24 08:37:47,813] A3C_AGENT_WORKER-Thread-20 INFO:Local step 140500, global step 2250838: loss -13.8974
[2019-03-24 08:37:47,816] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 140500, global step 2250839: learning rate 0.0000
[2019-03-24 08:37:50,826] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 2.2350328e-31 4.3209017e-35 2.7090984e-31 9.3509410e-31], sum to 1.0000
[2019-03-24 08:37:50,835] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5877
[2019-03-24 08:37:50,842] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8632021155011205, 6.9112, 6.9112, 121.9260426156618, 635675.5588871599, 635675.5588871599, 170191.1714353747], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5022000.0000, 
sim time next is 5022600.0000, 
raw observation next is [23.0, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8668085277150269, 6.9112, 6.9112, 121.9260426156618, 637724.9725979008, 637724.9725979008, 170815.8961995634], 
processed observation next is [0.0, 0.13043478260869565, 0.4074074074074074, 0.95, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8335106596437836, 0.0, 0.0, 0.8094621288201359, 0.22775891878496457, 0.22775891878496457, 0.3284921080760835], 
reward next is 0.6715, 
noisyNet noise sample is [array([0.06012668], dtype=float32), -0.5503896]. 
=============================================
[2019-03-24 08:37:52,906] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 3.0391468e-21 9.6074114e-23 1.2081798e-20 3.0955457e-20], sum to 1.0000
[2019-03-24 08:37:52,913] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0621
[2019-03-24 08:37:52,921] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2052632.051270304 W.
[2019-03-24 08:37:52,927] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.5998690771745542, 1.0, 1.0, 0.5998690771745542, 1.0, 2.0, 0.9550111072338286, 6.911199999999999, 6.9112, 121.94756008, 2052632.051270304, 2052632.051270304, 395304.2657947563], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4982400.0000, 
sim time next is 4983000.0000, 
raw observation next is [27.78333333333333, 79.83333333333334, 1.0, 2.0, 0.8577483477653172, 1.0, 2.0, 0.8577483477653172, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260425486062, 1956590.871416335, 1956590.871416335, 368195.0850133373], 
processed observation next is [1.0, 0.6956521739130435, 0.5845679012345678, 0.7983333333333335, 1.0, 1.0, 0.8306527949587109, 1.0, 1.0, 0.8306527949587109, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621283749566, 0.6987824540772625, 0.6987824540772625, 0.7080674711794949], 
reward next is 0.2919, 
noisyNet noise sample is [array([-3.1797683], dtype=float32), -0.07936814]. 
=============================================
[2019-03-24 08:37:52,937] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[31.618422]
 [31.23249 ]
 [31.027107]
 [31.02651 ]
 [31.132063]], R is [[31.77377892]
 [31.45604134]
 [31.1414814 ]
 [30.83006668]
 [30.52176666]].
[2019-03-24 08:37:53,034] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 5.1768898e-20 4.9660021e-23 3.8626814e-20 4.9577758e-20], sum to 1.0000
[2019-03-24 08:37:53,040] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4012
[2019-03-24 08:37:53,047] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 687251.3439942336 W.
[2019-03-24 08:37:53,051] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.16666666666667, 81.66666666666666, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9300195825603567, 6.911199999999999, 6.9112, 121.9260426156405, 687251.3439942336, 687251.3439942341, 178260.713996962], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4945200.0000, 
sim time next is 4945800.0000, 
raw observation next is [24.08333333333333, 82.33333333333334, 1.0, 1.0, 0.5751531303753393, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 683753.412259713, 683753.412259713, 155114.4157598036], 
processed observation next is [1.0, 0.21739130434782608, 0.4475308641975307, 0.8233333333333335, 1.0, 0.5, 0.4942299171134992, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2441976472356118, 0.2441976472356118, 0.29829695338423773], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2105899], dtype=float32), -0.5467461]. 
=============================================
[2019-03-24 08:37:53,762] A3C_AGENT_WORKER-Thread-3 INFO:Local step 141000, global step 2253905: loss -118.9927
[2019-03-24 08:37:53,766] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 141000, global step 2253906: learning rate 0.0000
[2019-03-24 08:37:53,779] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 9.9439792e-21 8.7392803e-22 7.8532372e-20 6.7653664e-21], sum to 1.0000
[2019-03-24 08:37:53,786] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0310
[2019-03-24 08:37:53,795] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 930457.2542544152 W.
[2019-03-24 08:37:53,798] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.65, 80.83333333333334, 1.0, 2.0, 0.2721075459840469, 1.0, 1.0, 0.2721075459840469, 1.0, 1.0, 0.4332040751306923, 6.911200000000001, 6.9112, 121.94756008, 930457.2542544152, 930457.2542544147, 245601.0278916345], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4935000.0000, 
sim time next is 4935600.0000, 
raw observation next is [25.4, 82.0, 1.0, 2.0, 0.4054000154067667, 1.0, 2.0, 0.4054000154067667, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 924158.8041497577, 924158.8041497582, 207676.4280534144], 
processed observation next is [1.0, 0.13043478260869565, 0.49629629629629624, 0.82, 1.0, 1.0, 0.29214287548424606, 1.0, 1.0, 0.29214287548424606, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3300567157677706, 0.3300567157677708, 0.39937774625656614], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.36307415], dtype=float32), 0.22495216]. 
=============================================
[2019-03-24 08:37:54,392] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 8.2535086e-36 0.0000000e+00 4.8671722e-35 3.9976445e-35], sum to 1.0000
[2019-03-24 08:37:54,398] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4167
[2019-03-24 08:37:54,401] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.73333333333333, 96.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8714991264298775, 6.9112, 6.9112, 121.9260426156618, 641266.3154803858, 641266.3154803858, 171398.3847015333], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5019600.0000, 
sim time next is 5020200.0000, 
raw observation next is [22.8, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8691201708293826, 6.9112, 6.9112, 121.9260426156618, 639641.646869958, 639641.646869958, 171057.8947554177], 
processed observation next is [0.0, 0.08695652173913043, 0.4, 0.96, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8364002135367282, 0.0, 0.0, 0.8094621288201359, 0.2284434453106993, 0.2284434453106993, 0.3289574899142648], 
reward next is 0.6710, 
noisyNet noise sample is [array([-0.36372536], dtype=float32), -0.9535042]. 
=============================================
[2019-03-24 08:37:54,607] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 7.6322135e-25 3.0885503e-28 4.4855680e-24 2.1703372e-24], sum to 1.0000
[2019-03-24 08:37:54,617] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1995
[2019-03-24 08:37:54,620] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.41666666666667, 80.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9088345797786702, 6.9112, 6.9112, 121.9260426156618, 671590.0826642559, 671590.0826642559, 175451.9304771106], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4942200.0000, 
sim time next is 4942800.0000, 
raw observation next is [24.5, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8946739889369962, 6.911200000000001, 6.9112, 121.9260426156618, 662364.918886, 662364.9188859996, 173156.8070279491], 
processed observation next is [1.0, 0.21739130434782608, 0.46296296296296297, 0.79, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8683424861712452, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23655889960214288, 0.2365588996021427, 0.3329938596691329], 
reward next is 0.6670, 
noisyNet noise sample is [array([-0.8064641], dtype=float32), -0.47516876]. 
=============================================
[2019-03-24 08:37:55,041] A3C_AGENT_WORKER-Thread-12 INFO:Local step 141500, global step 2254563: loss -48.8111
[2019-03-24 08:37:55,042] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 141500, global step 2254563: learning rate 0.0000
[2019-03-24 08:37:55,512] A3C_AGENT_WORKER-Thread-15 INFO:Local step 141000, global step 2254801: loss -65.0474
[2019-03-24 08:37:55,513] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 141000, global step 2254801: learning rate 0.0000
[2019-03-24 08:37:56,744] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 7.1979340e-28 3.4791499e-30 7.3914919e-27 1.7094913e-26], sum to 1.0000
[2019-03-24 08:37:56,750] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4268
[2019-03-24 08:37:56,754] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 930579.6919836564 W.
[2019-03-24 08:37:56,759] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.66666666666667, 72.33333333333334, 1.0, 2.0, 0.4082149521333779, 1.0, 2.0, 0.4082149521333779, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 930579.6919836564, 930579.6919836568, 208460.1527130932], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5066400.0000, 
sim time next is 5067000.0000, 
raw observation next is [31.5, 73.0, 1.0, 2.0, 0.2883188123970324, 1.0, 2.0, 0.2883188123970324, 1.0, 1.0, 0.4590129392242531, 6.911199999999999, 6.9112, 121.94756008, 985926.4692587507, 985926.4692587511, 251622.7699777084], 
processed observation next is [0.0, 0.6521739130434783, 0.7222222222222222, 0.73, 1.0, 1.0, 0.15276049094884808, 1.0, 1.0, 0.15276049094884808, 1.0, 0.5, 0.3237661740303164, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.3521165961638395, 0.35211659616383967, 0.48388994226482385], 
reward next is 0.5161, 
noisyNet noise sample is [array([-0.9745979], dtype=float32), 0.2864351]. 
=============================================
[2019-03-24 08:37:56,794] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[40.587   ]
 [40.564857]
 [40.140522]
 [39.74641 ]
 [40.21374 ]], R is [[40.7148056 ]
 [40.90677261]
 [41.09359741]
 [41.26908875]
 [41.45552444]].
[2019-03-24 08:37:58,363] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 7.5353174e-28 4.1919840e-30 2.4730563e-26 1.6967583e-25], sum to 1.0000
[2019-03-24 08:37:58,367] A3C_AGENT_WORKER-Thread-21 INFO:Local step 141500, global step 2256275: loss -14.8081
[2019-03-24 08:37:58,369] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 141500, global step 2256275: learning rate 0.0000
[2019-03-24 08:37:58,371] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3265
[2019-03-24 08:37:58,380] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1001789.809680125 W.
[2019-03-24 08:37:58,389] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.33333333333333, 73.66666666666667, 1.0, 2.0, 0.8788642055522323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1001789.809680125, 1001789.809680125, 212785.9960968558], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5067600.0000, 
sim time next is 5068200.0000, 
raw observation next is [31.16666666666667, 74.33333333333333, 1.0, 2.0, 0.8792572749651618, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 1002238.150213282, 1002238.150213282, 212872.3312922512], 
processed observation next is [0.0, 0.6521739130434783, 0.7098765432098767, 0.7433333333333333, 1.0, 1.0, 0.8562586606728116, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.35794219650474357, 0.35794219650474357, 0.40936986786971385], 
reward next is 0.5906, 
noisyNet noise sample is [array([-0.02411185], dtype=float32), -0.7282608]. 
=============================================
[2019-03-24 08:37:58,827] A3C_AGENT_WORKER-Thread-2 INFO:Local step 141000, global step 2256513: loss -91.0090
[2019-03-24 08:37:58,832] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 141000, global step 2256513: learning rate 0.0000
[2019-03-24 08:37:59,289] A3C_AGENT_WORKER-Thread-9 INFO:Local step 141000, global step 2256749: loss -121.1219
[2019-03-24 08:37:59,294] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 141000, global step 2256750: learning rate 0.0000
[2019-03-24 08:37:59,496] A3C_AGENT_WORKER-Thread-11 INFO:Local step 141000, global step 2256847: loss 94.5906
[2019-03-24 08:37:59,499] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 141000, global step 2256847: learning rate 0.0000
[2019-03-24 08:37:59,745] A3C_AGENT_WORKER-Thread-22 INFO:Local step 141000, global step 2256979: loss -28.3608
[2019-03-24 08:37:59,746] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 141000, global step 2256979: learning rate 0.0000
[2019-03-24 08:38:00,712] A3C_AGENT_WORKER-Thread-16 INFO:Local step 141000, global step 2257467: loss -47.7120
[2019-03-24 08:38:00,713] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 141000, global step 2257467: learning rate 0.0000
[2019-03-24 08:38:01,160] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.00000000e+00 1.97832845e-20 1.34820686e-21 1.03775294e-19
 1.26305542e-19], sum to 1.0000
[2019-03-24 08:38:01,165] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7071
[2019-03-24 08:38:01,169] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 808838.900250225 W.
[2019-03-24 08:38:01,176] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 100.0, 1.0, 2.0, 0.3548394036603304, 1.0, 1.0, 0.3548394036603304, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 808838.900250225, 808838.9002502254, 194142.1753767283], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5119800.0000, 
sim time next is 5120400.0000, 
raw observation next is [25.0, 100.0, 1.0, 2.0, 0.7102827148667457, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 809527.5524440173, 809527.5524440173, 178100.7261709841], 
processed observation next is [0.0, 0.2608695652173913, 0.48148148148148145, 1.0, 1.0, 1.0, 0.6550984700794591, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2891169830157205, 0.2891169830157205, 0.3425013964826617], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4303232], dtype=float32), -0.8456244]. 
=============================================
[2019-03-24 08:38:01,524] A3C_AGENT_WORKER-Thread-19 INFO:Local step 141000, global step 2257886: loss 71.1573
[2019-03-24 08:38:01,525] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 141000, global step 2257886: learning rate 0.0000
[2019-03-24 08:38:01,615] A3C_AGENT_WORKER-Thread-18 INFO:Local step 141000, global step 2257937: loss -21.5045
[2019-03-24 08:38:01,617] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 141000, global step 2257938: learning rate 0.0000
[2019-03-24 08:38:01,805] A3C_AGENT_WORKER-Thread-14 INFO:Local step 141000, global step 2258032: loss -20.6265
[2019-03-24 08:38:01,808] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 141000, global step 2258032: learning rate 0.0000
[2019-03-24 08:38:01,934] A3C_AGENT_WORKER-Thread-10 INFO:Local step 141000, global step 2258096: loss 95.9296
[2019-03-24 08:38:01,935] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 141000, global step 2258096: learning rate 0.0000
[2019-03-24 08:38:02,213] A3C_AGENT_WORKER-Thread-17 INFO:Local step 141000, global step 2258241: loss 9.7144
[2019-03-24 08:38:02,217] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 141000, global step 2258241: learning rate 0.0000
[2019-03-24 08:38:02,762] A3C_AGENT_WORKER-Thread-13 INFO:Local step 141000, global step 2258518: loss -59.0143
[2019-03-24 08:38:02,764] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 141000, global step 2258519: learning rate 0.0000
[2019-03-24 08:38:03,334] A3C_AGENT_WORKER-Thread-20 INFO:Local step 141000, global step 2258814: loss -110.9612
[2019-03-24 08:38:03,335] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 141000, global step 2258814: learning rate 0.0000
[2019-03-24 08:38:04,344] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 3.7317867e-22 2.9317274e-23 1.2733982e-20 2.0952142e-20], sum to 1.0000
[2019-03-24 08:38:04,350] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1275
[2019-03-24 08:38:04,355] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 973699.1907083469 W.
[2019-03-24 08:38:04,359] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.1, 84.0, 1.0, 2.0, 0.2847454054452571, 1.0, 1.0, 0.2847454054452571, 1.0, 1.0, 0.4533239589792871, 6.9112, 6.9112, 121.94756008, 973699.1907083469, 973699.1907083469, 250282.8203433861], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5281200.0000, 
sim time next is 5281800.0000, 
raw observation next is [25.01666666666667, 84.16666666666667, 1.0, 2.0, 0.8785064919921987, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1012667.42351807, 1012667.42351807, 213296.2748330396], 
processed observation next is [1.0, 0.13043478260869565, 0.48209876543209884, 0.8416666666666667, 1.0, 1.0, 0.8553648714192841, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3616669369707393, 0.3616669369707393, 0.4101851439096916], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.4353238], dtype=float32), -0.44774425]. 
=============================================
[2019-03-24 08:38:06,285] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 2.4564138e-34 4.9512667e-38 2.1904756e-30 5.4293616e-31], sum to 1.0000
[2019-03-24 08:38:06,293] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9237
[2019-03-24 08:38:06,297] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.5, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.932896516034581, 6.911199999999999, 6.9112, 121.9260426156618, 678000.0683245219, 678000.0683245223, 181210.6203710551], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5626200.0000, 
sim time next is 5626800.0000, 
raw observation next is [23.5, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9328778082938524, 6.911199999999999, 6.9112, 121.9260426156618, 677986.4820682266, 677986.482068227, 181208.0577169397], 
processed observation next is [0.0, 0.13043478260869565, 0.42592592592592593, 0.97, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9160972603673153, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2421380293100809, 0.24213802931008108, 0.34847703407103786], 
reward next is 0.6515, 
noisyNet noise sample is [array([0.02616968], dtype=float32), 0.19853148]. 
=============================================
[2019-03-24 08:38:06,759] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 4.8583242e-20 1.2871847e-21 1.0318555e-19 8.5246080e-20], sum to 1.0000
[2019-03-24 08:38:06,767] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2463
[2019-03-24 08:38:06,777] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 872261.965737222 W.
[2019-03-24 08:38:06,780] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.0, 100.0, 1.0, 2.0, 0.7652948363136911, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 872261.965737222, 872261.965737222, 188868.6493722848], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5209200.0000, 
sim time next is 5209800.0000, 
raw observation next is [24.08333333333333, 98.50000000000001, 1.0, 2.0, 0.2793790978684444, 1.0, 1.0, 0.2793790978684444, 1.0, 1.0, 0.4447806225485648, 6.9112, 6.9112, 121.94756008, 955337.434250349, 955337.434250349, 248283.9476944453], 
processed observation next is [1.0, 0.30434782608695654, 0.4475308641975307, 0.9850000000000001, 1.0, 1.0, 0.14211797365290998, 1.0, 0.5, 0.14211797365290998, 1.0, 0.5, 0.305975778185706, 0.0, 0.0, 0.8096049824067558, 0.341191940803696, 0.341191940803696, 0.47746913018162557], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.00321153], dtype=float32), 1.1028024]. 
=============================================
[2019-03-24 08:38:07,080] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 6.0746238e-28 1.6796240e-30 3.1121124e-26 1.7795234e-26], sum to 1.0000
[2019-03-24 08:38:07,085] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3793
[2019-03-24 08:38:07,091] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 797679.1979810663 W.
[2019-03-24 08:38:07,094] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.51666666666667, 88.33333333333334, 1.0, 2.0, 0.3499461639644688, 1.0, 1.0, 0.3499461639644688, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 797679.1979810663, 797679.1979810667, 192879.1513525604], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5260200.0000, 
sim time next is 5260800.0000, 
raw observation next is [26.43333333333334, 88.66666666666667, 1.0, 2.0, 0.7052407743444286, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 803778.1095675315, 803778.1095675315, 177139.1819987897], 
processed observation next is [1.0, 0.9130434782608695, 0.5345679012345682, 0.8866666666666667, 1.0, 1.0, 0.6490961599338435, 0.0, 0.5, -0.1904761904761905, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2870636105598327, 0.2870636105598327, 0.34065227307459556], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.718848], dtype=float32), 0.95876646]. 
=============================================
[2019-03-24 08:38:09,361] A3C_AGENT_WORKER-Thread-3 INFO:Local step 141500, global step 2261928: loss 6.3832
[2019-03-24 08:38:09,364] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 141500, global step 2261930: learning rate 0.0000
[2019-03-24 08:38:10,569] A3C_AGENT_WORKER-Thread-12 INFO:Local step 142000, global step 2262561: loss 0.5073
[2019-03-24 08:38:10,572] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 142000, global step 2262561: learning rate 0.0000
[2019-03-24 08:38:10,952] A3C_AGENT_WORKER-Thread-15 INFO:Local step 141500, global step 2262775: loss 11.1398
[2019-03-24 08:38:10,954] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 141500, global step 2262777: learning rate 0.0000
[2019-03-24 08:38:13,779] A3C_AGENT_WORKER-Thread-21 INFO:Local step 142000, global step 2264230: loss 1.0513
[2019-03-24 08:38:13,782] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 142000, global step 2264230: learning rate 0.0000
[2019-03-24 08:38:14,741] A3C_AGENT_WORKER-Thread-2 INFO:Local step 141500, global step 2264706: loss -19.9736
[2019-03-24 08:38:14,745] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 141500, global step 2264709: learning rate 0.0000
[2019-03-24 08:38:14,825] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.6132284e-22 5.8373291e-25 3.4500127e-20 2.4988483e-20], sum to 1.0000
[2019-03-24 08:38:14,832] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5151
[2019-03-24 08:38:14,836] A3C_AGENT_WORKER-Thread-9 INFO:Local step 141500, global step 2264749: loss -40.3576
[2019-03-24 08:38:14,837] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 696186.2646207544 W.
[2019-03-24 08:38:14,838] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 141500, global step 2264749: learning rate 0.0000
[2019-03-24 08:38:14,842] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.76666666666667, 82.0, 1.0, 2.0, 0.6060382369356673, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 696186.2646207544, 696186.2646207544, 159390.2043851007], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5358000.0000, 
sim time next is 5358600.0000, 
raw observation next is [25.7, 82.5, 1.0, 2.0, 0.3043880935242898, 0.0, 2.0, 0.0, 1.0, 1.0, 0.4846516362528674, 6.9112, 6.9112, 121.9260426156618, 695371.5113546202, 695371.5113546202, 196403.2608256764], 
processed observation next is [1.0, 0.0, 0.5074074074074074, 0.825, 1.0, 1.0, 0.17189058752891645, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.3558145453160842, 0.0, 0.0, 0.8094621288201359, 0.24834696834093578, 0.24834696834093578, 0.37769857851091615], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.63586986], dtype=float32), 0.07190002]. 
=============================================
[2019-03-24 08:38:15,161] A3C_AGENT_WORKER-Thread-22 INFO:Local step 141500, global step 2264910: loss -61.0162
[2019-03-24 08:38:15,162] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 141500, global step 2264910: learning rate 0.0000
[2019-03-24 08:38:15,230] A3C_AGENT_WORKER-Thread-11 INFO:Local step 141500, global step 2264945: loss -25.6432
[2019-03-24 08:38:15,232] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 141500, global step 2264945: learning rate 0.0000
[2019-03-24 08:38:15,486] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.00000000e+00 1.23728676e-23 2.87901162e-27 1.44639130e-23
 7.82783205e-23], sum to 1.0000
[2019-03-24 08:38:15,491] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4671
[2019-03-24 08:38:15,497] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 784401.7855293088 W.
[2019-03-24 08:38:15,502] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.9, 90.0, 1.0, 2.0, 0.3441242705309054, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5478570460302671, 6.911199999999999, 6.9112, 121.9260426156618, 784401.7855293088, 784401.7855293093, 207485.3576999822], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5526000.0000, 
sim time next is 5526600.0000, 
raw observation next is [25.88333333333333, 90.16666666666667, 1.0, 2.0, 0.2295890698036852, 1.0, 1.0, 0.2295890698036852, 1.0, 2.0, 0.3655132763214602, 6.9112, 6.9112, 121.94756008, 784993.147328594, 784993.147328594, 230504.3077770322], 
processed observation next is [1.0, 1.0, 0.5141975308641974, 0.9016666666666667, 1.0, 1.0, 0.08284413071867287, 1.0, 0.5, 0.08284413071867287, 1.0, 1.0, 0.20689159540182522, 0.0, 0.0, 0.8096049824067558, 0.2803546954744979, 0.2803546954744979, 0.4432775149558312], 
reward next is 0.5567, 
noisyNet noise sample is [array([0.84085894], dtype=float32), 0.06411796]. 
=============================================
[2019-03-24 08:38:16,153] A3C_AGENT_WORKER-Thread-16 INFO:Local step 141500, global step 2265385: loss -16.7904
[2019-03-24 08:38:16,155] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 141500, global step 2265385: learning rate 0.0000
[2019-03-24 08:38:17,350] A3C_AGENT_WORKER-Thread-18 INFO:Local step 141500, global step 2265968: loss 19.7840
[2019-03-24 08:38:17,354] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 141500, global step 2265969: learning rate 0.0000
[2019-03-24 08:38:17,427] A3C_AGENT_WORKER-Thread-19 INFO:Local step 141500, global step 2266009: loss 25.8385
[2019-03-24 08:38:17,429] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 141500, global step 2266009: learning rate 0.0000
[2019-03-24 08:38:17,584] A3C_AGENT_WORKER-Thread-14 INFO:Local step 141500, global step 2266087: loss -0.3575
[2019-03-24 08:38:17,586] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 141500, global step 2266088: learning rate 0.0000
[2019-03-24 08:38:17,800] A3C_AGENT_WORKER-Thread-10 INFO:Local step 141500, global step 2266188: loss 0.0663
[2019-03-24 08:38:17,805] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 141500, global step 2266188: learning rate 0.0000
[2019-03-24 08:38:17,897] A3C_AGENT_WORKER-Thread-17 INFO:Local step 141500, global step 2266234: loss 31.3356
[2019-03-24 08:38:17,900] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 141500, global step 2266234: learning rate 0.0000
[2019-03-24 08:38:18,516] A3C_AGENT_WORKER-Thread-13 INFO:Local step 141500, global step 2266530: loss 23.4262
[2019-03-24 08:38:18,518] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 141500, global step 2266531: learning rate 0.0000
[2019-03-24 08:38:19,483] A3C_AGENT_WORKER-Thread-20 INFO:Local step 141500, global step 2267007: loss 40.2782
[2019-03-24 08:38:19,485] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 141500, global step 2267007: learning rate 0.0000
[2019-03-24 08:38:21,531] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 5.6566356e-24 1.2587893e-26 2.6723812e-25 1.4260389e-22], sum to 1.0000
[2019-03-24 08:38:21,537] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9411
[2019-03-24 08:38:21,544] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 733615.0289092322 W.
[2019-03-24 08:38:21,548] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.9, 81.0, 1.0, 2.0, 0.6437086214910698, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 733615.0289092322, 733615.0289092322, 165761.2656767442], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5508000.0000, 
sim time next is 5508600.0000, 
raw observation next is [26.86666666666667, 81.0, 1.0, 2.0, 0.3265930522529601, 1.0, 1.0, 0.3265930522529601, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 744421.4712094929, 744421.4712094929, 186965.1368350302], 
processed observation next is [1.0, 0.782608695652174, 0.5506172839506175, 0.81, 1.0, 1.0, 0.19832506220590487, 1.0, 0.5, 0.19832506220590487, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.26586481114624744, 0.26586481114624744, 0.35954834006736575], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6800237], dtype=float32), -0.3284623]. 
=============================================
[2019-03-24 08:38:25,423] A3C_AGENT_WORKER-Thread-12 INFO:Local step 142500, global step 2269906: loss 24.9101
[2019-03-24 08:38:25,424] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 142500, global step 2269907: learning rate 0.0000
[2019-03-24 08:38:25,593] A3C_AGENT_WORKER-Thread-3 INFO:Local step 142000, global step 2269987: loss 1.3770
[2019-03-24 08:38:25,597] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 142000, global step 2269987: learning rate 0.0000
[2019-03-24 08:38:27,258] A3C_AGENT_WORKER-Thread-15 INFO:Local step 142000, global step 2270806: loss 0.2051
[2019-03-24 08:38:27,260] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 142000, global step 2270807: learning rate 0.0000
[2019-03-24 08:38:27,856] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.3106668e-27 1.4808823e-32 3.1971741e-27 4.8570655e-27], sum to 1.0000
[2019-03-24 08:38:27,864] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7025
[2019-03-24 08:38:27,871] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2041366.183696723 W.
[2019-03-24 08:38:27,875] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.5, 86.00000000000001, 1.0, 2.0, 0.5965804550059227, 1.0, 2.0, 0.5965804550059227, 1.0, 1.0, 0.9497755136384207, 6.911199999999999, 6.9112, 121.94756008, 2041366.183696723, 2041366.183696724, 393515.597509194], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5587800.0000, 
sim time next is 5588400.0000, 
raw observation next is [26.2, 87.0, 1.0, 2.0, 0.8804713890573888, 1.0, 2.0, 0.8804713890573888, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 2008482.187598865, 2008482.187598865, 378128.3374698862], 
processed observation next is [1.0, 0.6956521739130435, 0.5259259259259259, 0.87, 1.0, 1.0, 0.8577040345921295, 1.0, 1.0, 0.8577040345921295, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.7173150669995947, 0.7173150669995947, 0.7271698797497811], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.38457853], dtype=float32), -0.2865961]. 
=============================================
[2019-03-24 08:38:28,953] A3C_AGENT_WORKER-Thread-21 INFO:Local step 142500, global step 2271636: loss 17.5324
[2019-03-24 08:38:28,962] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 142500, global step 2271636: learning rate 0.0000
[2019-03-24 08:38:30,427] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 2.5235152e-35 0.0000000e+00 1.6875861e-32 1.1274030e-34], sum to 1.0000
[2019-03-24 08:38:30,434] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4914
[2019-03-24 08:38:30,443] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.56666666666667, 96.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9389556802722607, 6.911200000000001, 6.9112, 121.9260426156618, 682047.184714673, 682047.1847146725, 182096.5957800805], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5634600.0000, 
sim time next is 5635200.0000, 
raw observation next is [23.63333333333333, 96.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9435519529544991, 6.911200000000001, 6.9112, 121.9260426156618, 684833.329458428, 684833.3294584275, 182812.535216767], 
processed observation next is [0.0, 0.21739130434782608, 0.430864197530864, 0.9666666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9294399411931239, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24458333194943857, 0.2445833319494384, 0.3515625677245519], 
reward next is 0.6484, 
noisyNet noise sample is [array([1.5876769], dtype=float32), -0.9302814]. 
=============================================
[2019-03-24 08:38:31,262] A3C_AGENT_WORKER-Thread-9 INFO:Local step 142000, global step 2272753: loss 0.0628
[2019-03-24 08:38:31,264] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 142000, global step 2272753: learning rate 0.0000
[2019-03-24 08:38:31,298] A3C_AGENT_WORKER-Thread-2 INFO:Local step 142000, global step 2272770: loss 0.2243
[2019-03-24 08:38:31,300] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 142000, global step 2272772: learning rate 0.0000
[2019-03-24 08:38:31,571] A3C_AGENT_WORKER-Thread-22 INFO:Local step 142000, global step 2272903: loss 0.2821
[2019-03-24 08:38:31,571] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 142000, global step 2272903: learning rate 0.0000
[2019-03-24 08:38:31,944] A3C_AGENT_WORKER-Thread-11 INFO:Local step 142000, global step 2273078: loss 0.6613
[2019-03-24 08:38:31,946] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 142000, global step 2273078: learning rate 0.0000
[2019-03-24 08:38:32,964] A3C_AGENT_WORKER-Thread-16 INFO:Local step 142000, global step 2273578: loss 0.8098
[2019-03-24 08:38:32,968] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 142000, global step 2273578: learning rate 0.0000
[2019-03-24 08:38:33,958] A3C_AGENT_WORKER-Thread-18 INFO:Local step 142000, global step 2274071: loss 0.0840
[2019-03-24 08:38:33,960] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 142000, global step 2274071: learning rate 0.0000
[2019-03-24 08:38:34,259] A3C_AGENT_WORKER-Thread-19 INFO:Local step 142000, global step 2274224: loss 0.1580
[2019-03-24 08:38:34,263] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 142000, global step 2274224: learning rate 0.0000
[2019-03-24 08:38:34,345] A3C_AGENT_WORKER-Thread-14 INFO:Local step 142000, global step 2274259: loss 0.5116
[2019-03-24 08:38:34,348] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 142000, global step 2274259: learning rate 0.0000
[2019-03-24 08:38:34,610] A3C_AGENT_WORKER-Thread-10 INFO:Local step 142000, global step 2274390: loss 1.0552
[2019-03-24 08:38:34,611] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 142000, global step 2274390: learning rate 0.0000
[2019-03-24 08:38:34,974] A3C_AGENT_WORKER-Thread-17 INFO:Local step 142000, global step 2274569: loss 0.3187
[2019-03-24 08:38:34,975] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 142000, global step 2274569: learning rate 0.0000
[2019-03-24 08:38:35,293] A3C_AGENT_WORKER-Thread-13 INFO:Local step 142000, global step 2274720: loss 0.2311
[2019-03-24 08:38:35,296] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 142000, global step 2274720: learning rate 0.0000
[2019-03-24 08:38:35,853] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-24 08:38:35,856] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:38:35,856] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:38:35,856] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:38:35,858] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:38:35,858] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:38:35,859] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:38:35,859] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:38:35,861] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:38:35,862] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:38:35,863] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:38:35,885] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run92
[2019-03-24 08:38:35,913] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run92
[2019-03-24 08:38:35,914] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run92
[2019-03-24 08:38:35,989] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run92
[2019-03-24 08:38:35,990] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run92
[2019-03-24 08:38:58,401] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.024779407]
[2019-03-24 08:38:58,402] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [23.76113119333333, 72.39467758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.735432007205852, 6.911200000000001, 6.9112, 121.9260426156618, 549382.799945916, 549382.7999459156, 149764.3061808893]
[2019-03-24 08:38:58,404] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:38:58,407] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.22009979478800723
[2019-03-24 08:39:19,160] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.024779407]
[2019-03-24 08:39:19,163] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [27.20103429666666, 56.63191534666667, 1.0, 2.0, 0.6734621664173791, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9672120507008694, 6.9112, 6.9112, 121.9260426153972, 1513390.323276301, 1513390.323276301, 305913.0261164942]
[2019-03-24 08:39:19,164] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:39:19,166] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 9.4123935e-30 6.3848621e-33 1.0549552e-28 4.7643183e-28], sampled 0.3076935420413993
[2019-03-24 08:39:19,168] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1513390.323276301 W.
[2019-03-24 08:39:57,552] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.024779407]
[2019-03-24 08:39:57,554] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [32.13333333333333, 53.0, 1.0, 2.0, 0.8762868619482111, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1714016.0403004, 1714016.040300401, 351892.5935548593]
[2019-03-24 08:39:57,556] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:39:57,558] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.5715413e-30 1.0363689e-33 1.7839930e-29 7.7596067e-29], sampled 0.9284839267489513
[2019-03-24 08:39:57,559] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1714016.0403004 W.
[2019-03-24 08:40:14,204] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.024779407]
[2019-03-24 08:40:14,205] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.72767125833333, 82.04058826333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7755735730784554, 6.911199999999999, 6.9112, 121.9260426156618, 576054.8404626142, 576054.8404626147, 157322.9114315162]
[2019-03-24 08:40:14,206] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:40:14,209] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.02845204139224622
[2019-03-24 08:40:19,493] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 08:40:19,508] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 08:40:19,722] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 08:40:19,886] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 08:40:19,995] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 08:40:21,012] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 2275000, evaluation results [2275000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 08:40:21,487] A3C_AGENT_WORKER-Thread-20 INFO:Local step 142000, global step 2275247: loss 0.3555
[2019-03-24 08:40:21,489] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 142000, global step 2275249: learning rate 0.0000
[2019-03-24 08:40:24,017] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 7.3963656e-36 3.4607633e-38 2.1936916e-33 8.2650213e-33], sum to 1.0000
[2019-03-24 08:40:24,027] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2510
[2019-03-24 08:40:24,037] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 706392.8618395447 W.
[2019-03-24 08:40:24,039] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.43333333333333, 72.33333333333333, 1.0, 2.0, 0.3099168007590063, 1.0, 1.0, 0.3099168007590063, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 706392.8618395447, 706392.8618395447, 182857.4531481093], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6262800.0000, 
sim time next is 6263400.0000, 
raw observation next is [27.56666666666666, 71.66666666666667, 1.0, 2.0, 0.2071000204508784, 1.0, 2.0, 0.2071000204508784, 1.0, 1.0, 0.329709977334587, 6.9112, 6.9112, 121.94756008, 708064.825749033, 708064.825749033, 222927.8581781232], 
processed observation next is [0.0, 0.4782608695652174, 0.576543209876543, 0.7166666666666667, 1.0, 1.0, 0.05607145291771239, 1.0, 1.0, 0.05607145291771239, 1.0, 0.5, 0.16213747166823375, 0.0, 0.0, 0.8096049824067558, 0.25288029491036895, 0.25288029491036895, 0.4287074195733138], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.10090141], dtype=float32), -0.038704578]. 
=============================================
[2019-03-24 08:40:26,317] A3C_AGENT_WORKER-Thread-3 INFO:Local step 142500, global step 2277810: loss -14.4061
[2019-03-24 08:40:26,322] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 142500, global step 2277811: learning rate 0.0000
[2019-03-24 08:40:26,484] A3C_AGENT_WORKER-Thread-12 INFO:Local step 143000, global step 2277897: loss 1.5093
[2019-03-24 08:40:26,490] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 143000, global step 2277897: learning rate 0.0000
[2019-03-24 08:40:27,928] A3C_AGENT_WORKER-Thread-15 INFO:Local step 142500, global step 2278652: loss 16.9835
[2019-03-24 08:40:27,932] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 142500, global step 2278652: learning rate 0.0000
[2019-03-24 08:40:28,500] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 3.3029888e-38 2.1436297e-38], sum to 1.0000
[2019-03-24 08:40:28,501] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2960
[2019-03-24 08:40:28,501] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 826385.8833383368 W.
[2019-03-24 08:40:28,507] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.86666666666667, 55.66666666666667, 1.0, 2.0, 0.3561976727947891, 1.0, 1.0, 0.3561976727947891, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 826385.8833383368, 826385.8833383373, 195175.0683411728], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6023400.0000, 
sim time next is 6024000.0000, 
raw observation next is [28.73333333333333, 56.33333333333334, 1.0, 2.0, 0.2522692998177321, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4033204733117026, 6.911199999999999, 6.9112, 121.9260426156618, 590965.9627999014, 590965.9627999018, 182424.4473526014], 
processed observation next is [1.0, 0.7391304347826086, 0.619753086419753, 0.5633333333333335, 1.0, 1.0, 0.10984440454491917, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.2541505916396282, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2110592724285362, 0.21105927242853637, 0.35081624490884883], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.72327644], dtype=float32), -1.0989802]. 
=============================================
[2019-03-24 08:40:28,527] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[67.760864]
 [66.90639 ]
 [66.059235]
 [66.00213 ]
 [65.29676 ]], R is [[68.08444214]
 [68.02825928]
 [67.67543793]
 [67.31930542]
 [66.95933533]].
[2019-03-24 08:40:29,611] A3C_AGENT_WORKER-Thread-21 INFO:Local step 143000, global step 2279557: loss 2.5910
[2019-03-24 08:40:29,613] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 143000, global step 2279557: learning rate 0.0000
[2019-03-24 08:40:31,568] A3C_AGENT_WORKER-Thread-9 INFO:Local step 142500, global step 2280590: loss 63.3079
[2019-03-24 08:40:31,569] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 142500, global step 2280590: learning rate 0.0000
[2019-03-24 08:40:31,738] A3C_AGENT_WORKER-Thread-2 INFO:Local step 142500, global step 2280693: loss -33.7391
[2019-03-24 08:40:31,739] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 142500, global step 2280693: learning rate 0.0000
[2019-03-24 08:40:32,008] A3C_AGENT_WORKER-Thread-22 INFO:Local step 142500, global step 2280845: loss 8.6677
[2019-03-24 08:40:32,009] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 142500, global step 2280845: learning rate 0.0000
[2019-03-24 08:40:32,437] A3C_AGENT_WORKER-Thread-11 INFO:Local step 142500, global step 2281063: loss -0.4234
[2019-03-24 08:40:32,440] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 142500, global step 2281063: learning rate 0.0000
[2019-03-24 08:40:33,370] A3C_AGENT_WORKER-Thread-16 INFO:Local step 142500, global step 2281568: loss 18.6669
[2019-03-24 08:40:33,373] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 142500, global step 2281569: learning rate 0.0000
[2019-03-24 08:40:34,050] A3C_AGENT_WORKER-Thread-18 INFO:Local step 142500, global step 2281961: loss 19.2139
[2019-03-24 08:40:34,052] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 142500, global step 2281962: learning rate 0.0000
[2019-03-24 08:40:34,559] A3C_AGENT_WORKER-Thread-19 INFO:Local step 142500, global step 2282224: loss -17.4376
[2019-03-24 08:40:34,561] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 142500, global step 2282224: learning rate 0.0000
[2019-03-24 08:40:34,685] A3C_AGENT_WORKER-Thread-14 INFO:Local step 142500, global step 2282295: loss 36.0151
[2019-03-24 08:40:34,688] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 142500, global step 2282296: learning rate 0.0000
[2019-03-24 08:40:34,691] A3C_AGENT_WORKER-Thread-10 INFO:Local step 142500, global step 2282297: loss -52.4822
[2019-03-24 08:40:34,694] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 142500, global step 2282298: learning rate 0.0000
[2019-03-24 08:40:34,928] A3C_AGENT_WORKER-Thread-17 INFO:Local step 142500, global step 2282423: loss 56.0410
[2019-03-24 08:40:34,929] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 142500, global step 2282423: learning rate 0.0000
[2019-03-24 08:40:35,272] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.4793226e-34 2.0135166e-37 9.6128519e-35 6.7866207e-34], sum to 1.0000
[2019-03-24 08:40:35,276] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4595
[2019-03-24 08:40:35,281] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1683681.079656711 W.
[2019-03-24 08:40:35,285] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 58.0, 1.0, 2.0, 0.8448896489740958, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9924699164995674, 6.911200000000001, 6.9112, 121.9260426156618, 1683681.079656711, 1683681.07965671, 344498.7641196051], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6018000.0000, 
sim time next is 6018600.0000, 
raw observation next is [29.0, 58.0, 1.0, 2.0, 0.7441744385928954, 1.0, 1.0, 0.7441744385928954, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1697273.78221427, 1697273.782214271, 321224.6967789053], 
processed observation next is [1.0, 0.6521739130434783, 0.6296296296296297, 0.58, 1.0, 1.0, 0.6954457602296374, 1.0, 0.5, 0.6954457602296374, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.6061692079336678, 0.6061692079336681, 0.6177398014978948], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.14615172], dtype=float32), 0.06772466]. 
=============================================
[2019-03-24 08:40:35,391] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.0398953e-37 1.3552809e-37], sum to 1.0000
[2019-03-24 08:40:35,395] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1331
[2019-03-24 08:40:35,399] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.7, 72.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8394377583848545, 6.911200000000001, 6.9112, 121.9260426156618, 620516.0628820707, 620516.0628820702, 166455.3614450999], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6039000.0000, 
sim time next is 6039600.0000, 
raw observation next is [25.6, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.842642432828262, 6.9112, 6.9112, 121.9260426156618, 623012.3025667333, 623012.3025667333, 166814.4552496911], 
processed observation next is [1.0, 0.9130434782608695, 0.5037037037037038, 0.73, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8033030410353276, 0.0, 0.0, 0.8094621288201359, 0.22250439377383333, 0.22250439377383333, 0.32079702932632903], 
reward next is 0.6792, 
noisyNet noise sample is [array([-0.39531818], dtype=float32), 0.335446]. 
=============================================
[2019-03-24 08:40:35,413] A3C_AGENT_WORKER-Thread-13 INFO:Local step 142500, global step 2282690: loss 9.8073
[2019-03-24 08:40:35,414] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 142500, global step 2282690: learning rate 0.0000
[2019-03-24 08:40:36,211] A3C_AGENT_WORKER-Thread-20 INFO:Local step 142500, global step 2283164: loss 51.1899
[2019-03-24 08:40:36,213] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 142500, global step 2283164: learning rate 0.0000
[2019-03-24 08:40:40,896] A3C_AGENT_WORKER-Thread-3 INFO:Local step 143000, global step 2285794: loss 2.2141
[2019-03-24 08:40:40,897] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 143000, global step 2285794: learning rate 0.0000
[2019-03-24 08:40:41,376] A3C_AGENT_WORKER-Thread-12 INFO:Local step 143500, global step 2286065: loss 72.0920
[2019-03-24 08:40:41,384] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 143500, global step 2286066: learning rate 0.0000
[2019-03-24 08:40:42,173] A3C_AGENT_WORKER-Thread-15 INFO:Local step 143000, global step 2286516: loss 2.1349
[2019-03-24 08:40:42,175] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 143000, global step 2286517: learning rate 0.0000
[2019-03-24 08:40:44,260] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.0946022e-34 0.0000000e+00 2.2740114e-36 8.4916933e-36], sum to 1.0000
[2019-03-24 08:40:44,271] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6800
[2019-03-24 08:40:44,275] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.06666666666667, 77.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7825735042684349, 6.9112, 6.9112, 121.9260426156618, 582480.7396602271, 582480.7396602271, 157496.3813015276], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6227400.0000, 
sim time next is 6228000.0000, 
raw observation next is [24.0, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7816126220592624, 6.911200000000001, 6.9112, 121.9260426156618, 581829.6582714102, 581829.6582714097, 157337.8430745528], 
processed observation next is [0.0, 0.08695652173913043, 0.4444444444444444, 0.78, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7270157775740779, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20779630652550363, 0.20779630652550346, 0.3025727751433708], 
reward next is 0.6974, 
noisyNet noise sample is [array([1.2350696], dtype=float32), 1.537379]. 
=============================================
[2019-03-24 08:40:44,300] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[57.283573]
 [57.220234]
 [57.676674]
 [57.841694]
 [57.80454 ]], R is [[57.42383194]
 [57.54671478]
 [57.66759491]
 [57.78602219]
 [57.90253448]].
[2019-03-24 08:40:44,381] A3C_AGENT_WORKER-Thread-21 INFO:Local step 143500, global step 2287716: loss 33.8698
[2019-03-24 08:40:44,383] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 143500, global step 2287716: learning rate 0.0000
[2019-03-24 08:40:45,853] A3C_AGENT_WORKER-Thread-9 INFO:Local step 143000, global step 2288544: loss 1.9875
[2019-03-24 08:40:45,854] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 143000, global step 2288545: learning rate 0.0000
[2019-03-24 08:40:45,934] A3C_AGENT_WORKER-Thread-2 INFO:Local step 143000, global step 2288581: loss 1.9038
[2019-03-24 08:40:45,937] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 143000, global step 2288581: learning rate 0.0000
[2019-03-24 08:40:46,389] A3C_AGENT_WORKER-Thread-22 INFO:Local step 143000, global step 2288811: loss 1.5007
[2019-03-24 08:40:46,390] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 143000, global step 2288811: learning rate 0.0000
[2019-03-24 08:40:46,844] A3C_AGENT_WORKER-Thread-11 INFO:Local step 143000, global step 2289032: loss 1.3627
[2019-03-24 08:40:46,854] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 143000, global step 2289033: learning rate 0.0000
[2019-03-24 08:40:47,592] A3C_AGENT_WORKER-Thread-16 INFO:Local step 143000, global step 2289395: loss 1.3507
[2019-03-24 08:40:47,594] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 143000, global step 2289395: learning rate 0.0000
[2019-03-24 08:40:48,499] A3C_AGENT_WORKER-Thread-18 INFO:Local step 143000, global step 2289841: loss 1.3437
[2019-03-24 08:40:48,502] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 143000, global step 2289841: learning rate 0.0000
[2019-03-24 08:40:49,287] A3C_AGENT_WORKER-Thread-19 INFO:Local step 143000, global step 2290224: loss 1.0594
[2019-03-24 08:40:49,290] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 143000, global step 2290224: learning rate 0.0000
[2019-03-24 08:40:49,449] A3C_AGENT_WORKER-Thread-14 INFO:Local step 143000, global step 2290299: loss 1.6038
[2019-03-24 08:40:49,450] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 143000, global step 2290299: learning rate 0.0000
[2019-03-24 08:40:49,561] A3C_AGENT_WORKER-Thread-10 INFO:Local step 143000, global step 2290349: loss 1.2004
[2019-03-24 08:40:49,563] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 143000, global step 2290351: learning rate 0.0000
[2019-03-24 08:40:49,729] A3C_AGENT_WORKER-Thread-17 INFO:Local step 143000, global step 2290431: loss 1.9794
[2019-03-24 08:40:49,731] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 143000, global step 2290432: learning rate 0.0000
[2019-03-24 08:40:49,988] A3C_AGENT_WORKER-Thread-13 INFO:Local step 143000, global step 2290559: loss 1.5932
[2019-03-24 08:40:49,989] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 143000, global step 2290559: learning rate 0.0000
[2019-03-24 08:40:51,288] A3C_AGENT_WORKER-Thread-20 INFO:Local step 143000, global step 2291188: loss 1.6838
[2019-03-24 08:40:51,290] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 143000, global step 2291189: learning rate 0.0000
[2019-03-24 08:40:55,958] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 5.6133575e-34 1.1538205e-36 1.0288531e-33 2.7196779e-33], sum to 1.0000
[2019-03-24 08:40:55,966] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4808
[2019-03-24 08:40:55,972] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.46666666666667, 46.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6410294480767323, 6.9112, 6.9112, 121.9260426156618, 472059.9371589424, 472059.9371589424, 132125.7898653015], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6585600.0000, 
sim time next is 6586200.0000, 
raw observation next is [25.4, 47.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.644445757696689, 6.911200000000001, 6.9112, 121.9260426156618, 474594.7289764844, 474594.728976484, 132458.8119480344], 
processed observation next is [1.0, 0.21739130434782608, 0.49629629629629624, 0.47, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5555571971208612, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16949811749160157, 0.16949811749160143, 0.25472848451545077], 
reward next is 0.7453, 
noisyNet noise sample is [array([-0.87257785], dtype=float32), -2.205029]. 
=============================================
[2019-03-24 08:40:56,357] A3C_AGENT_WORKER-Thread-12 INFO:Local step 144000, global step 2293650: loss 4.5597
[2019-03-24 08:40:56,358] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 144000, global step 2293650: learning rate 0.0000
[2019-03-24 08:40:57,311] A3C_AGENT_WORKER-Thread-3 INFO:Local step 143500, global step 2294120: loss 54.7086
[2019-03-24 08:40:57,314] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 143500, global step 2294120: learning rate 0.0000
[2019-03-24 08:40:58,556] A3C_AGENT_WORKER-Thread-15 INFO:Local step 143500, global step 2294723: loss -36.3199
[2019-03-24 08:40:58,558] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 143500, global step 2294725: learning rate 0.0000
[2019-03-24 08:40:59,074] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.5355201e-19 4.1500617e-21 3.3117641e-19 1.0553349e-18], sum to 1.0000
[2019-03-24 08:40:59,080] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8349
[2019-03-24 08:40:59,086] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 993111.7899242351 W.
[2019-03-24 08:40:59,091] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.3, 87.16666666666667, 1.0, 2.0, 0.8712559609446957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 993111.7899242351, 993111.7899242351, 211099.5376051185], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6502200.0000, 
sim time next is 6502800.0000, 
raw observation next is [26.3, 87.33333333333334, 1.0, 2.0, 0.7906252302713106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 901149.8244381959, 901149.8244381964, 194008.4818080244], 
processed observation next is [1.0, 0.2608695652173913, 0.5296296296296297, 0.8733333333333334, 1.0, 1.0, 0.7507443217515603, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3218392230136414, 0.32183922301364154, 0.3730932342462008], 
reward next is 0.6269, 
noisyNet noise sample is [array([0.5480711], dtype=float32), -0.47471353]. 
=============================================
[2019-03-24 08:40:59,414] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.5167687e-26 1.8181644e-31 1.0427179e-25 1.8381350e-26], sum to 1.0000
[2019-03-24 08:40:59,420] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8322
[2019-03-24 08:40:59,428] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 750460.5208440956 W.
[2019-03-24 08:40:59,432] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.86666666666667, 59.0, 1.0, 2.0, 0.3292412115568754, 1.0, 2.0, 0.3292412115568754, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 750460.5208440956, 750460.5208440961, 187626.2401409687], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6459600.0000, 
sim time next is 6460200.0000, 
raw observation next is [30.8, 59.5, 1.0, 2.0, 0.3267234562091994, 1.0, 2.0, 0.3267234562091994, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 744718.8524938053, 744718.8524938058, 186997.7083477651], 
processed observation next is [1.0, 0.782608695652174, 0.6962962962962963, 0.595, 1.0, 1.0, 0.19848030501095168, 1.0, 1.0, 0.19848030501095168, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2659710187477876, 0.2659710187477878, 0.35961097759185595], 
reward next is 0.6404, 
noisyNet noise sample is [array([0.46243453], dtype=float32), -0.8813203]. 
=============================================
[2019-03-24 08:40:59,499] A3C_AGENT_WORKER-Thread-21 INFO:Local step 144000, global step 2295187: loss 3.5685
[2019-03-24 08:40:59,501] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 144000, global step 2295187: learning rate 0.0000
[2019-03-24 08:41:02,395] A3C_AGENT_WORKER-Thread-9 INFO:Local step 143500, global step 2296590: loss 124.5256
[2019-03-24 08:41:02,400] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 143500, global step 2296592: learning rate 0.0000
[2019-03-24 08:41:02,562] A3C_AGENT_WORKER-Thread-2 INFO:Local step 143500, global step 2296674: loss 81.6728
[2019-03-24 08:41:02,564] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 143500, global step 2296676: learning rate 0.0000
[2019-03-24 08:41:03,206] A3C_AGENT_WORKER-Thread-22 INFO:Local step 143500, global step 2296986: loss -26.1907
[2019-03-24 08:41:03,207] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 143500, global step 2296986: learning rate 0.0000
[2019-03-24 08:41:03,370] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.4622970e-38 0.0000000e+00 6.9665922e-33 2.4361452e-34], sum to 1.0000
[2019-03-24 08:41:03,380] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0059
[2019-03-24 08:41:03,386] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 770936.0161183394 W.
[2019-03-24 08:41:03,390] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.46666666666667, 84.0, 1.0, 2.0, 0.2254798087571675, 1.0, 1.0, 0.2254798087571675, 1.0, 2.0, 0.3589711989061148, 6.9112, 6.9112, 121.94756008, 770936.0161183394, 770936.0161183394, 229098.7949155409], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6558000.0000, 
sim time next is 6558600.0000, 
raw observation next is [26.43333333333333, 83.5, 1.0, 2.0, 0.3358301894617738, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5346525988488473, 6.9112, 6.9112, 121.9260426156618, 765486.6982015917, 765486.6982015917, 205124.7014221712], 
processed observation next is [1.0, 0.9130434782608695, 0.5345679012345678, 0.835, 1.0, 1.0, 0.20932165412115927, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.4183157485610591, 0.0, 0.0, 0.8094621288201359, 0.2733881065005685, 0.2733881065005685, 0.3944705796580215], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.8369286], dtype=float32), -1.7126192]. 
=============================================
[2019-03-24 08:41:03,668] A3C_AGENT_WORKER-Thread-11 INFO:Local step 143500, global step 2297218: loss -11.6216
[2019-03-24 08:41:03,673] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 143500, global step 2297218: learning rate 0.0000
[2019-03-24 08:41:04,307] A3C_AGENT_WORKER-Thread-16 INFO:Local step 143500, global step 2297524: loss 78.2165
[2019-03-24 08:41:04,309] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 143500, global step 2297524: learning rate 0.0000
[2019-03-24 08:41:04,361] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 1.4090248e-33 2.8800610e-38 1.7934192e-33 1.9563650e-32], sum to 1.0000
[2019-03-24 08:41:04,375] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8111
[2019-03-24 08:41:04,381] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1295595.821363024 W.
[2019-03-24 08:41:04,387] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.0, 37.0, 1.0, 2.0, 0.5291160697394547, 1.0, 2.0, 0.5291160697394547, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156163, 1295595.821363024, 1295595.821363024, 248087.0814333689], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6622800.0000, 
sim time next is 6623400.0000, 
raw observation next is [29.0, 37.0, 1.0, 2.0, 0.52493958980651, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8638682717285067, 6.9112, 6.9112, 121.9260426156618, 1291767.888691137, 1291767.888691137, 262286.1871340982], 
processed observation next is [1.0, 0.6521739130434783, 0.6296296296296297, 0.37, 1.0, 1.0, 0.4344518926267976, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.8298353396606334, 0.0, 0.0, 0.8094621288201359, 0.46134567453254893, 0.46134567453254893, 0.5043965137194196], 
reward next is 0.4956, 
noisyNet noise sample is [array([-0.18824504], dtype=float32), -0.3312052]. 
=============================================
[2019-03-24 08:41:05,192] A3C_AGENT_WORKER-Thread-18 INFO:Local step 143500, global step 2297967: loss 74.6052
[2019-03-24 08:41:05,193] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 143500, global step 2297967: learning rate 0.0000
[2019-03-24 08:41:06,024] A3C_AGENT_WORKER-Thread-19 INFO:Local step 143500, global step 2298371: loss -3.8022
[2019-03-24 08:41:06,026] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 143500, global step 2298371: learning rate 0.0000
[2019-03-24 08:41:06,330] A3C_AGENT_WORKER-Thread-14 INFO:Local step 143500, global step 2298522: loss 54.8534
[2019-03-24 08:41:06,332] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 143500, global step 2298522: learning rate 0.0000
[2019-03-24 08:41:06,484] A3C_AGENT_WORKER-Thread-17 INFO:Local step 143500, global step 2298598: loss 64.3174
[2019-03-24 08:41:06,488] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 143500, global step 2298598: learning rate 0.0000
[2019-03-24 08:41:06,543] A3C_AGENT_WORKER-Thread-10 INFO:Local step 143500, global step 2298624: loss 78.7508
[2019-03-24 08:41:06,545] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 143500, global step 2298624: learning rate 0.0000
[2019-03-24 08:41:06,657] A3C_AGENT_WORKER-Thread-13 INFO:Local step 143500, global step 2298683: loss 89.7852
[2019-03-24 08:41:06,658] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 143500, global step 2298684: learning rate 0.0000
[2019-03-24 08:41:08,019] A3C_AGENT_WORKER-Thread-20 INFO:Local step 143500, global step 2299359: loss 68.3197
[2019-03-24 08:41:08,020] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 143500, global step 2299359: learning rate 0.0000
[2019-03-24 08:41:09,342] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-24 08:41:09,343] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:41:09,344] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:41:09,344] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:41:09,346] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:41:09,347] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:41:09,348] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:41:09,349] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:41:09,350] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:41:09,351] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:41:09,351] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:41:09,380] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run93
[2019-03-24 08:41:09,407] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run93
[2019-03-24 08:41:09,408] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run93
[2019-03-24 08:41:09,479] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run93
[2019-03-24 08:41:09,480] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run93
[2019-03-24 08:41:15,620] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.024797931]
[2019-03-24 08:41:15,621] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [24.78333333333333, 40.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5883546956481125, 6.911200000000001, 6.9112, 121.9260426156618, 421392.5066284123, 421392.5066284118, 122522.4289005273]
[2019-03-24 08:41:15,622] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:41:15,625] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.19493061282184332
[2019-03-24 08:41:26,008] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.024797931]
[2019-03-24 08:41:26,008] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [16.41085190333333, 60.25044137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4516680830652868, 6.911200000000001, 6.9112, 121.9260426156618, 322488.1297660842, 322488.1297660838, 89075.22915290977]
[2019-03-24 08:41:26,012] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:41:26,015] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.5071911811370606
[2019-03-24 08:42:23,560] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.024797931]
[2019-03-24 08:42:23,561] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.48333333333333, 66.83333333333333, 1.0, 2.0, 0.9883403312505198, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1841931.80497601, 1841931.80497601, 376720.0712329359]
[2019-03-24 08:42:23,562] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:42:23,565] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 8.0808443e-38], sampled 0.23201757090810016
[2019-03-24 08:42:23,566] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1841931.80497601 W.
[2019-03-24 08:42:32,618] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.024797931]
[2019-03-24 08:42:32,619] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.48680801, 91.81479394, 1.0, 1.0, 0.6288054167657586, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 716622.3630878603, 716622.3630878598, 163105.6555319317]
[2019-03-24 08:42:32,621] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:42:32,624] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.7165605e-35 0.0000000e+00 3.4651560e-34 4.0859919e-33], sampled 0.3549886872161133
[2019-03-24 08:42:32,627] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 716622.3630878603 W.
[2019-03-24 08:42:37,150] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.024797931]
[2019-03-24 08:42:37,152] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [23.5, 90.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8256135926625313, 6.9112, 6.9112, 121.9260426156618, 607669.4982388638, 607669.4982388638, 165502.7735700058]
[2019-03-24 08:42:37,153] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:42:37,155] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 9.674161e-38], sampled 0.05975404557367103
[2019-03-24 08:42:53,762] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 08:42:53,765] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 08:42:53,765] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 08:42:53,974] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 08:42:54,024] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 08:42:55,039] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 2300000, evaluation results [2300000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 08:42:57,603] A3C_AGENT_WORKER-Thread-12 INFO:Local step 144500, global step 2301320: loss -50.5906
[2019-03-24 08:42:57,605] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 144500, global step 2301321: learning rate 0.0000
[2019-03-24 08:42:57,719] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:42:57,725] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0821
[2019-03-24 08:42:57,729] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.75, 41.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5547936051822221, 6.911200000000001, 6.9112, 121.9260426156618, 408677.2588036188, 408677.2588036184, 124346.7449465508], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6723000.0000, 
sim time next is 6723600.0000, 
raw observation next is [26.5, 42.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5493673967890585, 6.9112, 6.9112, 121.9260426156618, 404617.4127628652, 404617.4127628652, 123840.9033696994], 
processed observation next is [1.0, 0.8260869565217391, 0.5370370370370371, 0.42, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.43670924598632316, 0.0, 0.0, 0.8094621288201359, 0.14450621884388043, 0.14450621884388043, 0.2381555834032681], 
reward next is 0.7618, 
noisyNet noise sample is [array([1.472173], dtype=float32), -0.09895106]. 
=============================================
[2019-03-24 08:42:58,687] A3C_AGENT_WORKER-Thread-3 INFO:Local step 144000, global step 2301883: loss 8.9634
[2019-03-24 08:42:58,691] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 144000, global step 2301883: learning rate 0.0000
[2019-03-24 08:43:00,053] A3C_AGENT_WORKER-Thread-15 INFO:Local step 144000, global step 2302586: loss 8.8758
[2019-03-24 08:43:00,054] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 144000, global step 2302586: learning rate 0.0000
[2019-03-24 08:43:00,825] A3C_AGENT_WORKER-Thread-21 INFO:Local step 144500, global step 2302985: loss 40.9618
[2019-03-24 08:43:00,826] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 144500, global step 2302985: learning rate 0.0000
[2019-03-24 08:43:02,355] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:43:02,360] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3298
[2019-03-24 08:43:02,370] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.43333333333334, 59.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7548072786369272, 6.9112, 6.9112, 121.9260426156618, 560584.5781229226, 560584.5781229226, 154829.1676662401], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6802800.0000, 
sim time next is 6803400.0000, 
raw observation next is [27.26666666666667, 60.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7613219703778614, 6.911200000000001, 6.9112, 121.9260426156618, 565535.0668583444, 565535.0668583439, 155559.0101968953], 
processed observation next is [1.0, 0.7391304347826086, 0.5654320987654322, 0.6016666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7016524629723266, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20197680959226585, 0.2019768095922657, 0.29915194268633716], 
reward next is 0.7008, 
noisyNet noise sample is [array([-0.8521685], dtype=float32), -0.97323745]. 
=============================================
[2019-03-24 08:43:03,683] A3C_AGENT_WORKER-Thread-9 INFO:Local step 144000, global step 2304444: loss 11.9175
[2019-03-24 08:43:03,684] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 144000, global step 2304444: learning rate 0.0000
[2019-03-24 08:43:04,098] A3C_AGENT_WORKER-Thread-2 INFO:Local step 144000, global step 2304661: loss 12.3521
[2019-03-24 08:43:04,100] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 144000, global step 2304662: learning rate 0.0000
[2019-03-24 08:43:04,485] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:43:04,491] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6521
[2019-03-24 08:43:04,494] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.5, 84.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6876518879709499, 6.9112, 6.9112, 121.9260426156618, 513701.0939351938, 513701.0939351938, 142523.9128175051], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6927600.0000, 
sim time next is 6928200.0000, 
raw observation next is [21.4, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.686012809863391, 6.911200000000001, 6.9112, 121.9260426156618, 512463.4884140966, 512463.4884140962, 142313.8035682489], 
processed observation next is [0.0, 0.17391304347826086, 0.3481481481481481, 0.85, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6075160123292387, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18302267443360593, 0.1830226744336058, 0.27368039147740175], 
reward next is 0.7263, 
noisyNet noise sample is [array([-0.49511704], dtype=float32), -0.56551176]. 
=============================================
[2019-03-24 08:43:04,734] A3C_AGENT_WORKER-Thread-22 INFO:Local step 144000, global step 2304994: loss 12.6792
[2019-03-24 08:43:04,737] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 144000, global step 2304994: learning rate 0.0000
[2019-03-24 08:43:05,113] A3C_AGENT_WORKER-Thread-11 INFO:Local step 144000, global step 2305186: loss 16.5572
[2019-03-24 08:43:05,116] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 144000, global step 2305186: learning rate 0.0000
[2019-03-24 08:43:05,753] A3C_AGENT_WORKER-Thread-16 INFO:Local step 144000, global step 2305514: loss 10.8550
[2019-03-24 08:43:05,756] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 144000, global step 2305514: learning rate 0.0000
[2019-03-24 08:43:06,000] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:43:06,010] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1804
[2019-03-24 08:43:06,013] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.25, 62.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7096876053874992, 6.9112, 6.9112, 121.9260426156618, 530333.20189525, 530333.20189525, 146125.0715145734], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6901800.0000, 
sim time next is 6902400.0000, 
raw observation next is [25.1, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7066999311397091, 6.911200000000001, 6.9112, 121.9260426156618, 528110.4046949175, 528110.404694917, 145649.1846605656], 
processed observation next is [0.0, 0.9130434782608695, 0.4851851851851852, 0.63, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6333749139246364, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1886108588196134, 0.18861085881961323, 0.2800945858857031], 
reward next is 0.7199, 
noisyNet noise sample is [array([-0.79424495], dtype=float32), -1.4750835]. 
=============================================
[2019-03-24 08:43:06,073] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:43:06,079] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3917
[2019-03-24 08:43:06,083] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.8, 50.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8219590207203451, 6.9112, 6.9112, 121.9260426156618, 608463.372543937, 608463.372543937, 163962.7002248305], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6881400.0000, 
sim time next is 6882000.0000, 
raw observation next is [29.66666666666666, 50.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8186370994994645, 6.911200000000001, 6.9112, 121.9260426156618, 606300.4927374483, 606300.4927374478, 163427.565695052], 
processed observation next is [0.0, 0.6521739130434783, 0.6543209876543208, 0.5033333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7732963743743306, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2165358902633744, 0.21653589026337422, 0.3142837801827923], 
reward next is 0.6857, 
noisyNet noise sample is [array([-0.06249822], dtype=float32), -0.29895547]. 
=============================================
[2019-03-24 08:43:06,097] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[77.88171 ]
 [77.794426]
 [77.70886 ]
 [77.62471 ]
 [77.43896 ]], R is [[77.84668732]
 [77.7529068 ]
 [77.65912628]
 [77.56541443]
 [77.47147369]].
[2019-03-24 08:43:06,499] A3C_AGENT_WORKER-Thread-18 INFO:Local step 144000, global step 2305901: loss 11.1184
[2019-03-24 08:43:06,501] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 144000, global step 2305901: learning rate 0.0000
[2019-03-24 08:43:07,410] A3C_AGENT_WORKER-Thread-14 INFO:Local step 144000, global step 2306375: loss 14.5787
[2019-03-24 08:43:07,414] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 144000, global step 2306376: learning rate 0.0000
[2019-03-24 08:43:07,563] A3C_AGENT_WORKER-Thread-17 INFO:Local step 144000, global step 2306453: loss 12.8710
[2019-03-24 08:43:07,565] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 144000, global step 2306453: learning rate 0.0000
[2019-03-24 08:43:07,631] A3C_AGENT_WORKER-Thread-19 INFO:Local step 144000, global step 2306482: loss 9.9919
[2019-03-24 08:43:07,633] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 144000, global step 2306482: learning rate 0.0000
[2019-03-24 08:43:07,963] A3C_AGENT_WORKER-Thread-13 INFO:Local step 144000, global step 2306659: loss 9.8015
[2019-03-24 08:43:07,965] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 144000, global step 2306659: learning rate 0.0000
[2019-03-24 08:43:08,043] A3C_AGENT_WORKER-Thread-10 INFO:Local step 144000, global step 2306700: loss 10.0870
[2019-03-24 08:43:08,046] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 144000, global step 2306700: learning rate 0.0000
[2019-03-24 08:43:09,472] A3C_AGENT_WORKER-Thread-20 INFO:Local step 144000, global step 2307439: loss 9.3139
[2019-03-24 08:43:09,473] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 144000, global step 2307440: learning rate 0.0000
[2019-03-24 08:43:09,569] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:43:09,579] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2663
[2019-03-24 08:43:09,581] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.83333333333333, 92.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.631585163465439, 6.9112, 6.9112, 121.9260426156618, 470794.3461529621, 470794.3461529621, 135101.5251439088], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7437000.0000, 
sim time next is 7437600.0000, 
raw observation next is [19.8, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6291228051678012, 6.911199999999999, 6.9112, 121.9260426156618, 468924.6951272133, 468924.6951272137, 134820.0112529979], 
processed observation next is [0.0, 0.08695652173913043, 0.2888888888888889, 0.93, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5364035064597514, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16747310540257618, 0.16747310540257632, 0.25926925240961135], 
reward next is 0.7407, 
noisyNet noise sample is [array([-1.3205115], dtype=float32), -1.4661952]. 
=============================================
[2019-03-24 08:43:13,382] A3C_AGENT_WORKER-Thread-12 INFO:Local step 145000, global step 2309464: loss 0.0143
[2019-03-24 08:43:13,385] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 145000, global step 2309465: learning rate 0.0000
[2019-03-24 08:43:13,802] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.00000000e+00 2.56663176e-34 1.34274515e-37 3.65523421e-33
 1.22161215e-32], sum to 1.0000
[2019-03-24 08:43:13,816] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3041
[2019-03-24 08:43:13,821] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1045705.460891916 W.
[2019-03-24 08:43:13,826] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.83333333333333, 81.33333333333333, 1.0, 2.0, 0.4380412888702771, 1.0, 2.0, 0.4380412888702771, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260424539181, 1045705.460891916, 1045705.460891917, 218917.9007364867], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7029600.0000, 
sim time next is 7030200.0000, 
raw observation next is [23.01666666666667, 80.66666666666667, 1.0, 2.0, 0.4417953241397908, 1.0, 2.0, 0.4417953241397908, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156125, 1054792.044192782, 1054792.044192781, 220022.8365952444], 
processed observation next is [1.0, 0.34782608695652173, 0.40802469135802477, 0.8066666666666668, 1.0, 1.0, 0.33547062397594146, 1.0, 1.0, 0.33547062397594146, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288198086, 0.37671144435456494, 0.3767114443545646, 0.4231208396062392], 
reward next is 0.5769, 
noisyNet noise sample is [array([0.11463732], dtype=float32), 1.0705044]. 
=============================================
[2019-03-24 08:43:14,373] A3C_AGENT_WORKER-Thread-3 INFO:Local step 144500, global step 2309975: loss 44.0215
[2019-03-24 08:43:14,374] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 144500, global step 2309976: learning rate 0.0000
[2019-03-24 08:43:15,424] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:43:15,430] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0764
[2019-03-24 08:43:15,433] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.66666666666667, 79.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7846105616141502, 6.9112, 6.9112, 121.9260426156618, 584578.575163657, 584578.575163657, 157341.1430730236], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7064400.0000, 
sim time next is 7065000.0000, 
raw observation next is [23.65, 79.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7811888538528398, 6.911200000000001, 6.9112, 121.9260426156618, 582005.471393356, 582005.4713933555, 156943.2469220454], 
processed observation next is [1.0, 0.782608695652174, 0.4314814814814814, 0.795, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7264860673160497, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20785909692619856, 0.2078590969261984, 0.3018139363885488], 
reward next is 0.6982, 
noisyNet noise sample is [array([-0.4950745], dtype=float32), 0.19585493]. 
=============================================
[2019-03-24 08:43:15,451] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[73.881294]
 [74.05329 ]
 [73.72822 ]
 [73.994316]
 [73.71696 ]], R is [[73.813591  ]
 [73.77287292]
 [73.73298645]
 [73.6949234 ]
 [73.65966797]].
[2019-03-24 08:43:15,648] A3C_AGENT_WORKER-Thread-15 INFO:Local step 144500, global step 2310640: loss 30.5406
[2019-03-24 08:43:15,650] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 144500, global step 2310640: learning rate 0.0000
[2019-03-24 08:43:16,410] A3C_AGENT_WORKER-Thread-21 INFO:Local step 145000, global step 2311034: loss 0.0185
[2019-03-24 08:43:16,411] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 145000, global step 2311034: learning rate 0.0000
[2019-03-24 08:43:19,127] A3C_AGENT_WORKER-Thread-9 INFO:Local step 144500, global step 2312463: loss 51.9934
[2019-03-24 08:43:19,129] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 144500, global step 2312463: learning rate 0.0000
[2019-03-24 08:43:19,388] A3C_AGENT_WORKER-Thread-2 INFO:Local step 144500, global step 2312608: loss 85.4259
[2019-03-24 08:43:19,390] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 144500, global step 2312609: learning rate 0.0000
[2019-03-24 08:43:19,927] A3C_AGENT_WORKER-Thread-22 INFO:Local step 144500, global step 2312927: loss 6.4824
[2019-03-24 08:43:19,929] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 144500, global step 2312927: learning rate 0.0000
[2019-03-24 08:43:20,452] A3C_AGENT_WORKER-Thread-11 INFO:Local step 144500, global step 2313192: loss 4.3682
[2019-03-24 08:43:20,453] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 144500, global step 2313192: learning rate 0.0000
[2019-03-24 08:43:21,240] A3C_AGENT_WORKER-Thread-16 INFO:Local step 144500, global step 2313579: loss 79.3382
[2019-03-24 08:43:21,242] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 144500, global step 2313579: learning rate 0.0000
[2019-03-24 08:43:21,802] A3C_AGENT_WORKER-Thread-18 INFO:Local step 144500, global step 2313858: loss 15.5445
[2019-03-24 08:43:21,806] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 144500, global step 2313858: learning rate 0.0000
[2019-03-24 08:43:22,953] A3C_AGENT_WORKER-Thread-17 INFO:Local step 144500, global step 2314425: loss -19.0031
[2019-03-24 08:43:22,955] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 144500, global step 2314426: learning rate 0.0000
[2019-03-24 08:43:23,029] A3C_AGENT_WORKER-Thread-14 INFO:Local step 144500, global step 2314461: loss -41.2067
[2019-03-24 08:43:23,034] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 144500, global step 2314461: learning rate 0.0000
[2019-03-24 08:43:23,316] A3C_AGENT_WORKER-Thread-19 INFO:Local step 144500, global step 2314602: loss -8.3975
[2019-03-24 08:43:23,319] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 144500, global step 2314603: learning rate 0.0000
[2019-03-24 08:43:23,340] A3C_AGENT_WORKER-Thread-13 INFO:Local step 144500, global step 2314611: loss 32.7445
[2019-03-24 08:43:23,341] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 144500, global step 2314611: learning rate 0.0000
[2019-03-24 08:43:23,447] A3C_AGENT_WORKER-Thread-10 INFO:Local step 144500, global step 2314634: loss 19.6534
[2019-03-24 08:43:23,448] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 144500, global step 2314634: learning rate 0.0000
[2019-03-24 08:43:24,000] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:43:24,007] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6408
[2019-03-24 08:43:24,014] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 751438.2428461508 W.
[2019-03-24 08:43:24,018] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.2, 68.66666666666667, 1.0, 2.0, 0.3147716589785562, 1.0, 1.0, 0.3147716589785562, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156555, 751438.2428461508, 751438.2428461508, 185544.9778266083], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7303200.0000, 
sim time next is 7303800.0000, 
raw observation next is [25.4, 67.83333333333333, 1.0, 2.0, 0.3275084435205717, 0.0, 1.0, 0.0, 1.0, 1.0, 0.527635398829119, 6.911199999999999, 6.9112, 121.9260426156618, 782688.7222960864, 782688.7222960868, 201579.3038917746], 
processed observation next is [1.0, 0.5217391304347826, 0.49629629629629624, 0.6783333333333332, 1.0, 1.0, 0.19941481371496628, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.40954424853639876, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27953168653431654, 0.2795316865343167, 0.3876525074841819], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8548185], dtype=float32), 0.69734687]. 
=============================================
[2019-03-24 08:43:24,644] A3C_AGENT_WORKER-Thread-20 INFO:Local step 144500, global step 2315218: loss 39.1594
[2019-03-24 08:43:24,647] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 144500, global step 2315219: learning rate 0.0000
[2019-03-24 08:43:29,100] A3C_AGENT_WORKER-Thread-12 INFO:Local step 145500, global step 2317405: loss -11.3525
[2019-03-24 08:43:29,102] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 145500, global step 2317405: learning rate 0.0000
[2019-03-24 08:43:30,282] A3C_AGENT_WORKER-Thread-3 INFO:Local step 145000, global step 2317997: loss 0.0268
[2019-03-24 08:43:30,284] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 145000, global step 2317997: learning rate 0.0000
[2019-03-24 08:43:31,412] A3C_AGENT_WORKER-Thread-15 INFO:Local step 145000, global step 2318547: loss 0.0021
[2019-03-24 08:43:31,418] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 145000, global step 2318552: learning rate 0.0000
[2019-03-24 08:43:31,437] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:43:31,454] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6870
[2019-03-24 08:43:31,458] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.18333333333333, 90.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6399576178290964, 6.911200000000001, 6.9112, 121.9260426156618, 477107.5915609545, 477107.591560954, 136016.5344047993], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7419000.0000, 
sim time next is 7419600.0000, 
raw observation next is [20.2, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6392625058418745, 6.911200000000001, 6.9112, 121.9260426156618, 476581.1530218248, 476581.1530218244, 135937.6897934691], 
processed observation next is [1.0, 0.9130434782608695, 0.3037037037037037, 0.9, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.549078132302343, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1702075546506517, 0.17020755465065157, 0.2614186342182098], 
reward next is 0.7386, 
noisyNet noise sample is [array([-1.0801148], dtype=float32), -1.2330407]. 
=============================================
[2019-03-24 08:43:32,204] A3C_AGENT_WORKER-Thread-21 INFO:Local step 145500, global step 2318934: loss 92.8593
[2019-03-24 08:43:32,205] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 145500, global step 2318934: learning rate 0.0000
[2019-03-24 08:43:35,404] A3C_AGENT_WORKER-Thread-9 INFO:Local step 145000, global step 2320492: loss 0.0168
[2019-03-24 08:43:35,406] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 145000, global step 2320493: learning rate 0.0000
[2019-03-24 08:43:35,578] A3C_AGENT_WORKER-Thread-2 INFO:Local step 145000, global step 2320577: loss 0.0452
[2019-03-24 08:43:35,581] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 145000, global step 2320578: learning rate 0.0000
[2019-03-24 08:43:36,346] A3C_AGENT_WORKER-Thread-22 INFO:Local step 145000, global step 2320954: loss 0.0174
[2019-03-24 08:43:36,347] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 145000, global step 2320954: learning rate 0.0000
[2019-03-24 08:43:36,855] A3C_AGENT_WORKER-Thread-11 INFO:Local step 145000, global step 2321209: loss 0.0035
[2019-03-24 08:43:36,859] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 145000, global step 2321210: learning rate 0.0000
[2019-03-24 08:43:37,656] A3C_AGENT_WORKER-Thread-16 INFO:Local step 145000, global step 2321604: loss 0.0051
[2019-03-24 08:43:37,657] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 145000, global step 2321604: learning rate 0.0000
[2019-03-24 08:43:37,753] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:43:37,754] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:43:37,818] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res7/Eplus-env-sub_run12
[2019-03-24 08:43:37,963] A3C_AGENT_WORKER-Thread-18 INFO:Local step 145000, global step 2321733: loss 0.0229
[2019-03-24 08:43:37,965] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 145000, global step 2321733: learning rate 0.0000
[2019-03-24 08:43:38,970] A3C_AGENT_WORKER-Thread-14 INFO:Local step 145000, global step 2322292: loss 0.0026
[2019-03-24 08:43:38,971] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 145000, global step 2322293: learning rate 0.0000
[2019-03-24 08:43:39,144] A3C_AGENT_WORKER-Thread-17 INFO:Local step 145000, global step 2322390: loss 0.0045
[2019-03-24 08:43:39,147] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 145000, global step 2322391: learning rate 0.0000
[2019-03-24 08:43:39,323] A3C_AGENT_WORKER-Thread-13 INFO:Local step 145000, global step 2322479: loss 0.0039
[2019-03-24 08:43:39,325] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 145000, global step 2322480: learning rate 0.0000
[2019-03-24 08:43:39,373] A3C_AGENT_WORKER-Thread-19 INFO:Local step 145000, global step 2322504: loss 0.0124
[2019-03-24 08:43:39,375] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 145000, global step 2322504: learning rate 0.0000
[2019-03-24 08:43:39,528] A3C_AGENT_WORKER-Thread-10 INFO:Local step 145000, global step 2322583: loss 0.0037
[2019-03-24 08:43:39,531] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 145000, global step 2322583: learning rate 0.0000
[2019-03-24 08:43:40,688] A3C_AGENT_WORKER-Thread-20 INFO:Local step 145000, global step 2323161: loss 0.0052
[2019-03-24 08:43:40,691] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 145000, global step 2323161: learning rate 0.0000
[2019-03-24 08:43:40,818] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:43:40,819] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:43:40,867] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res16/Eplus-env-sub_run12
[2019-03-24 08:43:43,775] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:43:43,785] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0386
[2019-03-24 08:43:43,792] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.06666666666667, 69.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6503166635332086, 6.9112, 6.9112, 121.9260426156618, 484996.2882412744, 484996.2882412744, 137251.7838168626], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7765800.0000, 
sim time next is 7766400.0000, 
raw observation next is [22.93333333333333, 69.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6434386967258949, 6.911199999999999, 6.9112, 121.9260426156618, 479693.6041783358, 479693.6041783362, 136355.5764195777], 
processed observation next is [1.0, 0.9130434782608695, 0.40493827160493817, 0.6966666666666668, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5542983709073687, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17131914434940565, 0.1713191443494058, 0.26222226234534174], 
reward next is 0.7378, 
noisyNet noise sample is [array([-1.1165837], dtype=float32), 0.054207813]. 
=============================================
[2019-03-24 08:43:44,329] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-24 08:43:44,329] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:43:44,330] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:43:44,330] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:43:44,331] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:43:44,332] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:43:44,333] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:43:44,334] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:43:44,334] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:43:44,336] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:43:44,339] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:43:44,360] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run94
[2019-03-24 08:43:44,389] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run94
[2019-03-24 08:43:44,390] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run94
[2019-03-24 08:43:44,450] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run94
[2019-03-24 08:43:44,451] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run94
[2019-03-24 08:44:24,694] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.02537633]
[2019-03-24 08:44:24,695] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [28.66666666666667, 72.33333333333334, 1.0, 2.0, 0.648284285542868, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 738832.286404235, 738832.2864042355, 166586.2697060319]
[2019-03-24 08:44:24,697] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:44:24,700] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.07318779042565138
[2019-03-24 08:44:24,702] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 738832.286404235 W.
[2019-03-24 08:44:52,775] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.02537633]
[2019-03-24 08:44:52,776] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [30.33333333333334, 53.0, 1.0, 2.0, 0.4196946702683679, 0.0, 2.0, 0.0, 1.0, 1.0, 0.6687238793911398, 6.9112, 6.9112, 121.9258409048549, 966630.2173336064, 966630.2173336064, 230094.8469937773]
[2019-03-24 08:44:52,776] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:44:52,779] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.0113277e-38 3.9048265e-37], sampled 0.38627708326200216
[2019-03-24 08:44:52,779] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 966630.2173336064 W.
[2019-03-24 08:45:04,271] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.02537633]
[2019-03-24 08:45:04,273] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [32.6, 35.0, 1.0, 2.0, 0.5166028568900793, 0.0, 2.0, 0.0, 1.0, 2.0, 0.829935237140856, 6.911200000000001, 6.9112, 121.9260426156618, 1227513.790205049, 1227513.790205048, 261605.2753583483]
[2019-03-24 08:45:04,274] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:45:04,278] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 6.2566956e-38], sampled 0.2162149643951934
[2019-03-24 08:45:04,279] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1227513.790205049 W.
[2019-03-24 08:45:27,847] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 08:45:27,890] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 08:45:27,928] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 08:45:27,987] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 08:45:28,016] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 08:45:29,031] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 2325000, evaluation results [2325000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 08:45:30,761] A3C_AGENT_WORKER-Thread-3 INFO:Local step 145500, global step 2325891: loss 33.0496
[2019-03-24 08:45:30,763] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 145500, global step 2325891: learning rate 0.0000
[2019-03-24 08:45:31,795] A3C_AGENT_WORKER-Thread-15 INFO:Local step 145500, global step 2326428: loss 39.1457
[2019-03-24 08:45:31,796] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 145500, global step 2326428: learning rate 0.0000
[2019-03-24 08:45:33,925] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:45:33,929] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8384
[2019-03-24 08:45:33,935] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 758448.7251337564 W.
[2019-03-24 08:45:33,939] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.71666666666667, 52.83333333333334, 1.0, 2.0, 0.2176450895677361, 1.0, 2.0, 0.2176450895677361, 1.0, 2.0, 0.347271269782805, 6.9112, 6.9112, 121.94756008, 758448.7251337564, 758448.7251337564, 226414.589777359], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7751400.0000, 
sim time next is 7752000.0000, 
raw observation next is [28.43333333333334, 53.66666666666667, 1.0, 2.0, 0.2352606279458092, 1.0, 2.0, 0.2352606279458092, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 556577.1177653917, 556577.1177653922, 166644.414995451], 
processed observation next is [1.0, 0.7391304347826086, 0.6086419753086423, 0.5366666666666667, 1.0, 1.0, 0.08959598564977286, 1.0, 1.0, 0.08959598564977286, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.19877754205906847, 0.19877754205906864, 0.3204700288374058], 
reward next is 0.6795, 
noisyNet noise sample is [array([-0.49286965], dtype=float32), 0.2583101]. 
=============================================
[2019-03-24 08:45:33,955] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[75.4148  ]
 [73.595055]
 [73.37217 ]
 [73.08697 ]
 [71.97371 ]], R is [[74.95727539]
 [74.77229309]
 [74.42399597]
 [74.1111908 ]
 [73.79519653]].
[2019-03-24 08:45:34,775] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 2.2414661e-35 0.0000000e+00 2.9864091e-35 7.3897418e-35], sum to 1.0000
[2019-03-24 08:45:34,783] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2616
[2019-03-24 08:45:34,788] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.7, 64.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5418309743358782, 6.911199999999999, 6.9112, 121.9260426156618, 396009.3658356674, 396009.3658356679, 121745.0146619021], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7794000.0000, 
sim time next is 7794600.0000, 
raw observation next is [21.9, 63.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5827251795834314, 6.911200000000001, 6.9112, 121.9260426156618, 426073.1871111949, 426073.1871111945, 125326.8320464344], 
processed observation next is [1.0, 0.21739130434782608, 0.36666666666666664, 0.6316666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4784064744792892, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15216899539685533, 0.15216899539685516, 0.2410131385508354], 
reward next is 0.7590, 
noisyNet noise sample is [array([0.9598811], dtype=float32), 0.40294665]. 
=============================================
[2019-03-24 08:45:35,673] A3C_AGENT_WORKER-Thread-9 INFO:Local step 145500, global step 2328441: loss 17.3651
[2019-03-24 08:45:35,677] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 145500, global step 2328441: learning rate 0.0000
[2019-03-24 08:45:35,778] A3C_AGENT_WORKER-Thread-2 INFO:Local step 145500, global step 2328493: loss -52.6437
[2019-03-24 08:45:35,783] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 145500, global step 2328494: learning rate 0.0000
[2019-03-24 08:45:36,061] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 6.7015846e-37 0.0000000e+00 4.4464595e-36 9.8636319e-34], sum to 1.0000
[2019-03-24 08:45:36,072] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6842
[2019-03-24 08:45:36,074] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.9, 63.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5827251795834314, 6.911200000000001, 6.9112, 121.9260426156618, 426073.1871111949, 426073.1871111945, 125326.8320464344], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7794600.0000, 
sim time next is 7795200.0000, 
raw observation next is [22.1, 62.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5574454775378448, 6.911199999999999, 6.9112, 121.9260426156618, 407942.9510283779, 407942.9510283783, 123296.2718058399], 
processed observation next is [1.0, 0.21739130434782608, 0.3740740740740741, 0.6233333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.44680684692230593, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.14569391108156354, 0.14569391108156368, 0.23710821501123058], 
reward next is 0.7629, 
noisyNet noise sample is [array([1.1353112], dtype=float32), 0.52095145]. 
=============================================
[2019-03-24 08:45:36,469] A3C_AGENT_WORKER-Thread-22 INFO:Local step 145500, global step 2328850: loss -39.7877
[2019-03-24 08:45:36,471] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 145500, global step 2328850: learning rate 0.0000
[2019-03-24 08:45:36,879] A3C_AGENT_WORKER-Thread-11 INFO:Local step 145500, global step 2329064: loss -45.9901
[2019-03-24 08:45:36,882] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 145500, global step 2329066: learning rate 0.0000
[2019-03-24 08:45:36,984] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:45:36,993] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6875
[2019-03-24 08:45:36,995] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.28333333333333, 65.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6752554248084737, 6.9112, 6.9112, 121.9260426156618, 504448.5323179535, 504448.5323179535, 141234.9247283943], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7761000.0000, 
sim time next is 7761600.0000, 
raw observation next is [24.0, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.670469500102278, 6.911199999999999, 6.9112, 121.9260426156618, 500729.4896970252, 500729.4896970257, 140383.0492987827], 
processed observation next is [1.0, 0.8695652173913043, 0.4444444444444444, 0.66, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5880868751278475, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17883196060608045, 0.1788319606060806, 0.269967402497659], 
reward next is 0.7300, 
noisyNet noise sample is [array([-0.96795017], dtype=float32), 0.08224022]. 
=============================================
[2019-03-24 08:45:37,428] A3C_AGENT_WORKER-Thread-16 INFO:Local step 145500, global step 2329347: loss -26.6377
[2019-03-24 08:45:37,429] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 145500, global step 2329348: learning rate 0.0000
[2019-03-24 08:45:37,733] A3C_AGENT_WORKER-Thread-18 INFO:Local step 145500, global step 2329506: loss 72.7746
[2019-03-24 08:45:37,735] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 145500, global step 2329506: learning rate 0.0000
[2019-03-24 08:45:38,886] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:45:38,886] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:45:38,919] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res3/Eplus-env-sub_run12
[2019-03-24 08:45:39,104] A3C_AGENT_WORKER-Thread-14 INFO:Local step 145500, global step 2330193: loss 32.7931
[2019-03-24 08:45:39,105] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 145500, global step 2330193: learning rate 0.0000
[2019-03-24 08:45:39,200] A3C_AGENT_WORKER-Thread-17 INFO:Local step 145500, global step 2330244: loss -20.0898
[2019-03-24 08:45:39,201] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 145500, global step 2330244: learning rate 0.0000
[2019-03-24 08:45:39,265] A3C_AGENT_WORKER-Thread-13 INFO:Local step 145500, global step 2330279: loss -73.2822
[2019-03-24 08:45:39,268] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 145500, global step 2330279: learning rate 0.0000
[2019-03-24 08:45:39,446] A3C_AGENT_WORKER-Thread-10 INFO:Local step 145500, global step 2330372: loss -93.2804
[2019-03-24 08:45:39,449] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 145500, global step 2330374: learning rate 0.0000
[2019-03-24 08:45:39,628] A3C_AGENT_WORKER-Thread-19 INFO:Local step 145500, global step 2330469: loss 33.7260
[2019-03-24 08:45:39,629] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 145500, global step 2330469: learning rate 0.0000
[2019-03-24 08:45:39,845] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:45:39,847] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:45:39,882] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res10/Eplus-env-sub_run12
[2019-03-24 08:45:40,377] A3C_AGENT_WORKER-Thread-20 INFO:Local step 145500, global step 2330871: loss -26.7962
[2019-03-24 08:45:40,379] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 145500, global step 2330871: learning rate 0.0000
[2019-03-24 08:45:42,897] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:45:42,902] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8890
[2019-03-24 08:45:42,905] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.56666666666667, 34.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5694669086861435, 6.911200000000001, 6.9112, 121.9260426156618, 410521.6753973818, 410521.6753973814, 121884.4517610748], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 328800.0000, 
sim time next is 329400.0000, 
raw observation next is [26.45, 35.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5674756505151738, 6.9112, 6.9112, 121.9260426156618, 408891.7977637899, 408891.7977637899, 121650.4748461188], 
processed observation next is [0.0, 0.8260869565217391, 0.5351851851851852, 0.35, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4593445631439672, 0.0, 0.0, 0.8094621288201359, 0.14603278491563926, 0.14603278491563926, 0.23394322085792077], 
reward next is 0.7661, 
noisyNet noise sample is [array([-2.3330252], dtype=float32), -0.047266938]. 
=============================================
[2019-03-24 08:45:43,345] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:45:43,345] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:45:43,367] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res4/Eplus-env-sub_run12
[2019-03-24 08:45:43,623] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:45:43,623] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:45:43,654] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res2/Eplus-env-sub_run12
[2019-03-24 08:45:44,185] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:45:44,185] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:45:44,211] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res17/Eplus-env-sub_run12
[2019-03-24 08:45:44,460] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:45:44,461] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:45:44,494] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res6/Eplus-env-sub_run12
[2019-03-24 08:45:44,938] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:45:44,938] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:45:44,962] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res11/Eplus-env-sub_run12
[2019-03-24 08:45:45,068] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:45:45,071] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:45:45,078] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res13/Eplus-env-sub_run12
[2019-03-24 08:45:46,270] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:45:46,270] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:45:46,272] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:45:46,273] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:45:46,297] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res12/Eplus-env-sub_run12
[2019-03-24 08:45:46,299] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res9/Eplus-env-sub_run12
[2019-03-24 08:45:46,415] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:45:46,417] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:45:46,450] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res5/Eplus-env-sub_run12
[2019-03-24 08:45:46,479] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:45:46,486] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:45:46,504] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res14/Eplus-env-sub_run12
[2019-03-24 08:45:46,505] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:45:46,505] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:45:46,557] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res8/Eplus-env-sub_run12
[2019-03-24 08:45:46,743] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.6451173e-35 1.9255749e-36], sum to 1.0000
[2019-03-24 08:45:46,743] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8005
[2019-03-24 08:45:46,746] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.4, 60.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5025904604247828, 6.9112, 6.9112, 121.9260426156618, 361810.0666512928, 361810.0666512928, 116332.1803878362], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 437400.0000, 
sim time next is 438000.0000, 
raw observation next is [21.13333333333333, 61.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5026598743143018, 6.9112, 6.9112, 121.9260426156618, 361867.7113618223, 361867.7113618223, 116340.302195368], 
processed observation next is [1.0, 0.043478260869565216, 0.33827160493827146, 0.6166666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3783248428928772, 0.0, 0.0, 0.8094621288201359, 0.12923846834350797, 0.12923846834350797, 0.22373135037570768], 
reward next is 0.7763, 
noisyNet noise sample is [array([1.561666], dtype=float32), -2.018065]. 
=============================================
[2019-03-24 08:45:46,766] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[62.503136]
 [62.937885]
 [63.428307]
 [64.185844]
 [64.92243 ]], R is [[62.39875412]
 [62.55105209]
 [62.70191574]
 [62.85143661]
 [62.9995842 ]].
[2019-03-24 08:45:47,101] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-24 08:45:47,101] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:45:47,111] EPLUS_ENV_Part3-NA-Bej-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res15/Eplus-env-sub_run12
[2019-03-24 08:45:47,861] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:45:47,866] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8658
[2019-03-24 08:45:47,877] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.61666666666667, 59.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4527851292489107, 6.9112, 6.9112, 121.9260426156618, 323285.8617084854, 323285.8617084854, 105723.5467934822], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 193800.0000, 
sim time next is 194400.0000, 
raw observation next is [20.8, 60.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4558988277119903, 6.9112, 6.9112, 121.9260426156618, 325509.4954776079, 325509.4954776079, 109595.2946348971], 
processed observation next is [0.0, 0.2608695652173913, 0.32592592592592595, 0.6, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.31987353463998786, 0.0, 0.0, 0.8094621288201359, 0.11625339124200282, 0.11625339124200282, 0.21076018199018673], 
reward next is 0.7892, 
noisyNet noise sample is [array([-0.17064638], dtype=float32), 1.3701524]. 
=============================================
[2019-03-24 08:45:50,308] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 4.6275386e-36 0.0000000e+00 2.0976293e-35 5.4834732e-33], sum to 1.0000
[2019-03-24 08:45:50,316] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9662
[2019-03-24 08:45:50,319] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 928420.6177372134 W.
[2019-03-24 08:45:50,323] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.96666666666667, 42.33333333333334, 1.0, 2.0, 0.3700130732796211, 1.0, 1.0, 0.3700130732796211, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 928420.6177372134, 928420.6177372137, 201097.0626819218], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 37200.0000, 
sim time next is 37800.0000, 
raw observation next is [26.2, 42.0, 1.0, 2.0, 0.2537475265228818, 1.0, 2.0, 0.2537475265228818, 1.0, 1.0, 0.4237606199453658, 6.911199999999999, 6.9112, 121.94756008, 948251.2193953083, 948251.2193953088, 236450.3794216443], 
processed observation next is [1.0, 0.43478260869565216, 0.5259259259259259, 0.42, 1.0, 1.0, 0.11160419824152594, 1.0, 1.0, 0.11160419824152594, 1.0, 0.5, 0.2797007749317072, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.33866114978403866, 0.33866114978403883, 0.4547122681185467], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.76437396], dtype=float32), -0.29187325]. 
=============================================
[2019-03-24 08:45:55,077] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:45:55,085] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4021
[2019-03-24 08:45:55,092] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1668079.774637752 W.
[2019-03-24 08:45:55,097] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [37.36666666666667, 11.0, 1.0, 2.0, 0.6731155964000433, 1.0, 1.0, 0.6731155964000433, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1668079.774637752, 1668079.774637752, 299354.792236744], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 141600.0000, 
sim time next is 142200.0000, 
raw observation next is [37.34999999999999, 10.5, 1.0, 2.0, 0.4397956976045392, 1.0, 2.0, 0.4397956976045392, 1.0, 1.0, 0.7226733810631509, 6.911199999999999, 6.9112, 121.94756008, 1621276.246870738, 1621276.246870739, 313514.129843904], 
processed observation next is [1.0, 0.6521739130434783, 0.9388888888888884, 0.105, 1.0, 1.0, 0.33309011619587997, 1.0, 1.0, 0.33309011619587997, 1.0, 0.5, 0.6533417263289387, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.5790272310252635, 0.5790272310252639, 0.6029117881613538], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.18281761], dtype=float32), 0.455878]. 
=============================================
[2019-03-24 08:46:05,888] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 2.6519817e-38 0.0000000e+00 5.6039321e-38 6.4731649e-36], sum to 1.0000
[2019-03-24 08:46:05,896] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0210
[2019-03-24 08:46:05,896] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1055000.018994865 W.
[2019-03-24 08:46:05,903] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.95, 30.5, 1.0, 2.0, 0.4182220477151161, 1.0, 2.0, 0.4182220477151161, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1055000.018994865, 1055000.018994866, 214690.6281582236], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 383400.0000, 
sim time next is 384000.0000, 
raw observation next is [28.13333333333333, 30.0, 1.0, 2.0, 0.4202930943824481, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7195445869560403, 6.911199999999999, 6.9112, 121.9260426156618, 1063225.461331616, 1063225.461331617, 224486.3942962185], 
processed observation next is [1.0, 0.43478260869565216, 0.5975308641975308, 0.3, 1.0, 1.0, 0.3098727314076763, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.6494307336950502, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3797233790470057, 0.3797233790470061, 0.4317046044158048], 
reward next is 0.5683, 
noisyNet noise sample is [array([-0.61165756], dtype=float32), -0.060351532]. 
=============================================
[2019-03-24 08:46:05,919] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[64.98295 ]
 [64.29184 ]
 [64.74751 ]
 [63.68277 ]
 [63.231186]], R is [[64.85817719]
 [64.79673004]
 [64.14876556]
 [64.03746796]
 [63.96613693]].
[2019-03-24 08:46:07,562] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:46:07,569] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2702
[2019-03-24 08:46:07,575] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.83333333333333, 36.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7356408577939448, 6.911200000000001, 6.9112, 121.9260426156618, 549252.22961249, 549252.2296124897, 150316.4083818728], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 832200.0000, 
sim time next is 832800.0000, 
raw observation next is [31.86666666666667, 36.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7253129565426378, 6.9112, 6.9112, 121.9260426156618, 541494.6762637255, 541494.6762637255, 149197.0589378052], 
processed observation next is [0.0, 0.6521739130434783, 0.7358024691358026, 0.36, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6566411956782972, 0.0, 0.0, 0.8094621288201359, 0.1933909558084734, 0.1933909558084734, 0.2869174210342408], 
reward next is 0.7131, 
noisyNet noise sample is [array([1.2734294], dtype=float32), 0.32601961]. 
=============================================
[2019-03-24 08:46:07,692] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 2.4380919e-31 3.1451348e-34 3.4454857e-29 2.8600372e-30], sum to 1.0000
[2019-03-24 08:46:07,700] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7780
[2019-03-24 08:46:07,708] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 858313.1279359425 W.
[2019-03-24 08:46:07,714] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.46666666666667, 37.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9989992107185565, 7.192385041118566, 6.9112, 121.9251412767745, 858313.1279359425, 714322.3193100959, 161991.7365567531], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 375600.0000, 
sim time next is 376200.0000, 
raw observation next is [25.65, 36.5, 1.0, 1.0, 0.3592103585492796, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6287864392334183, 6.911200000000001, 6.9112, 121.925873291013, 917602.8927672261, 917602.8927672256, 204929.3072897581], 
processed observation next is [1.0, 0.34782608695652173, 0.5055555555555555, 0.365, 1.0, 0.5, 0.23715518874914235, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5359830490417727, 8.881784197001253e-17, 0.0, 0.8094610046805532, 0.32771531884543786, 0.3277153188454377, 0.39409482171107324], 
reward next is 0.6059, 
noisyNet noise sample is [array([0.43453568], dtype=float32), 0.29556286]. 
=============================================
[2019-03-24 08:46:11,849] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.7328938e-31 9.1256308e-36 3.4144579e-32 7.2079209e-32], sum to 1.0000
[2019-03-24 08:46:11,855] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1631
[2019-03-24 08:46:11,862] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.98333333333333, 60.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5124486977116692, 6.9112, 6.9112, 121.9260426156618, 366104.5798217494, 366104.5798217494, 116137.5662645925], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 971400.0000, 
sim time next is 972000.0000, 
raw observation next is [21.1, 60.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4898277039805555, 6.9112, 6.9112, 121.9260426156618, 350437.1718881117, 350437.1718881117, 114588.0768141119], 
processed observation next is [1.0, 0.2608695652173913, 0.3370370370370371, 0.6, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.36228462997569433, 0.0, 0.0, 0.8094621288201359, 0.12515613281718274, 0.12515613281718274, 0.22036168618098442], 
reward next is 0.7796, 
noisyNet noise sample is [array([0.23063758], dtype=float32), 1.7630962]. 
=============================================
[2019-03-24 08:46:11,878] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[55.1089  ]
 [55.30889 ]
 [55.629105]
 [55.687702]
 [55.88091 ]], R is [[55.1712265 ]
 [55.39617157]
 [55.62254715]
 [55.85264969]
 [56.08253479]].
[2019-03-24 08:46:17,678] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 6.2596071e-31 2.8821582e-32 3.7555205e-30 3.8752660e-30], sum to 1.0000
[2019-03-24 08:46:17,684] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2460
[2019-03-24 08:46:17,692] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 880315.311625433 W.
[2019-03-24 08:46:17,696] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.75, 49.0, 1.0, 2.0, 0.3516010399364909, 1.0, 1.0, 0.3516010399364909, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 880315.311625433, 880315.3116254335, 196122.8136954146], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1078200.0000, 
sim time next is 1078800.0000, 
raw observation next is [24.9, 48.33333333333334, 1.0, 2.0, 0.3260855141907403, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5509187335503193, 6.911199999999999, 6.9112, 121.9260426156618, 818695.0292837069, 818695.0292837073, 197795.424641774], 
processed observation next is [1.0, 0.4782608695652174, 0.47777777777777775, 0.48333333333333345, 1.0, 1.0, 0.19772085022707175, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.4386484169378991, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.29239108188703816, 0.29239108188703833, 0.38037581661879616], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.82413423], dtype=float32), 0.5320325]. 
=============================================
[2019-03-24 08:46:18,800] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-24 08:46:18,801] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:46:18,802] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:46:18,803] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:46:18,804] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:46:18,804] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:46:18,805] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:46:18,806] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:46:18,807] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:46:18,810] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:46:18,811] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:46:18,826] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run95
[2019-03-24 08:46:18,857] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run95
[2019-03-24 08:46:18,858] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run95
[2019-03-24 08:46:18,882] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run95
[2019-03-24 08:46:18,932] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run95
[2019-03-24 08:46:38,160] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026187984]
[2019-03-24 08:46:38,162] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [36.4, 19.0, 1.0, 2.0, 0.6340828586027654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 784708.3050950164, 784708.3050950164, 166444.3695825657]
[2019-03-24 08:46:38,162] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:46:38,165] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.7608530131533193
[2019-03-24 08:46:38,167] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 784708.3050950164 W.
[2019-03-24 08:47:14,783] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026187984]
[2019-03-24 08:47:14,784] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [27.66666666666667, 80.66666666666667, 1.0, 2.0, 0.7087734788172062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 807806.5307027694, 807806.5307027689, 177812.4678942591]
[2019-03-24 08:47:14,786] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:47:14,788] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.000000e+00 0.000000e+00 0.000000e+00 7.520838e-37 8.658054e-36], sampled 0.5379008393127352
[2019-03-24 08:47:14,791] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 807806.5307027694 W.
[2019-03-24 08:47:25,727] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026187984]
[2019-03-24 08:47:25,728] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.4, 86.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6622312172648409, 6.9112, 6.9112, 121.9260426156618, 494812.1205560488, 494812.1205560488, 140202.1841068471]
[2019-03-24 08:47:25,729] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:47:25,735] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.20512471443383185
[2019-03-24 08:47:41,119] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026187984]
[2019-03-24 08:47:41,121] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.896280831855569, 6.911200000000001, 6.9112, 121.9260426156618, 656977.5761496203, 656977.5761496199, 175233.7589126722]
[2019-03-24 08:47:41,122] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:47:41,125] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.018417373910139312
[2019-03-24 08:47:59,455] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026187984]
[2019-03-24 08:47:59,455] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.001187175, 76.131956705, 1.0, 2.0, 0.7019637868560796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426025146, 830426.3727246508, 830426.3727246511, 177937.865082513]
[2019-03-24 08:47:59,456] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:47:59,459] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 4.5917524e-37 4.9073090e-36], sampled 0.31024063536767243
[2019-03-24 08:47:59,460] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 830426.3727246508 W.
[2019-03-24 08:48:02,514] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 08:48:02,593] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 08:48:02,626] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 08:48:02,706] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 08:48:02,774] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 08:48:03,791] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 2350000, evaluation results [2350000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 08:48:04,572] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:48:04,577] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4918
[2019-03-24 08:48:04,580] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.95, 38.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6274885749134478, 6.911200000000001, 6.9112, 121.9260426156618, 467474.8147864618, 467474.8147864613, 134418.0112674322], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 592200.0000, 
sim time next is 592800.0000, 
raw observation next is [28.76666666666667, 39.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6252239300335717, 6.9112, 6.9112, 121.9260426156618, 465675.0894467799, 465675.0894467799, 134084.5966336226], 
processed observation next is [1.0, 0.8695652173913043, 0.6209876543209878, 0.39, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5315299125419646, 0.0, 0.0, 0.8094621288201359, 0.16631253194527854, 0.16631253194527854, 0.2578549935261973], 
reward next is 0.7421, 
noisyNet noise sample is [array([1.364737], dtype=float32), 1.076813]. 
=============================================
[2019-03-24 08:48:05,194] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 4.4848560e-36 0.0000000e+00 1.7669682e-34 8.5730441e-33], sum to 1.0000
[2019-03-24 08:48:05,201] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8500
[2019-03-24 08:48:05,208] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.2, 74.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4985133644913359, 6.911199999999999, 6.9112, 121.9260426156618, 358066.6381955387, 358066.6381955391, 115730.7350033581], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1126200.0000, 
sim time next is 1126800.0000, 
raw observation next is [19.2, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4962766184866422, 6.911200000000001, 6.9112, 121.9260426156618, 356301.6846647697, 356301.6846647692, 115504.0216236869], 
processed observation next is [1.0, 0.043478260869565216, 0.26666666666666666, 0.74, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.3703457731083027, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.12725060166598917, 0.127250601665989, 0.22212311850709018], 
reward next is 0.7779, 
noisyNet noise sample is [array([0.41367987], dtype=float32), 0.43460456]. 
=============================================
[2019-03-24 08:48:10,360] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 6.543147e-37], sum to 1.0000
[2019-03-24 08:48:10,367] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1090
[2019-03-24 08:48:10,370] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.53333333333333, 43.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7594337131743938, 6.9112, 6.9112, 121.9260426156618, 548200.8541776899, 548200.8541776899, 139297.0785887018], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 702600.0000, 
sim time next is 703200.0000, 
raw observation next is [24.36666666666667, 44.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6887460505020673, 6.911200000000001, 6.9112, 121.9260426156618, 497219.293020276, 497219.2930202755, 132576.6237370426], 
processed observation next is [1.0, 0.13043478260869565, 0.4580246913580248, 0.4466666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.610932563127584, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17757831893581286, 0.17757831893581266, 0.25495504564815885], 
reward next is 0.7450, 
noisyNet noise sample is [array([0.53445584], dtype=float32), -1.8319658]. 
=============================================
[2019-03-24 08:48:13,283] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:48:13,290] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1933
[2019-03-24 08:48:13,294] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.7, 35.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.568122490422954, 6.9112, 6.9112, 121.9260426156618, 415985.3842173752, 415985.3842173752, 124317.6867325106], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 770400.0000, 
sim time next is 771000.0000, 
raw observation next is [27.53333333333333, 35.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5652713335445406, 6.911200000000001, 6.9112, 121.9260426156618, 413866.4897098139, 413866.4897098134, 124056.8006176957], 
processed observation next is [1.0, 0.9565217391304348, 0.5753086419753086, 0.3566666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.45658916693067575, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1478094606106478, 0.14780946061064765, 0.23857077041864558], 
reward next is 0.7614, 
noisyNet noise sample is [array([-1.4402335], dtype=float32), 1.0239478]. 
=============================================
[2019-03-24 08:48:13,306] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[78.92277 ]
 [78.654274]
 [78.644485]
 [78.59057 ]
 [78.452225]], R is [[79.03541565]
 [79.00598907]
 [78.97612   ]
 [78.94590759]
 [78.91558838]].
[2019-03-24 08:48:13,582] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:48:13,590] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1662
[2019-03-24 08:48:13,593] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.13333333333333, 36.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7040923759505604, 6.911200000000001, 6.9112, 121.9260426156618, 526124.9856398134, 526124.9856398129, 145687.892451637], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 841200.0000, 
sim time next is 841800.0000, 
raw observation next is [31.06666666666667, 36.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6996832007224499, 6.911200000000001, 6.9112, 121.9260426156618, 522858.8693675246, 522858.8693675242, 144975.0933572643], 
processed observation next is [0.0, 0.7391304347826086, 0.7061728395061729, 0.3616666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6246040009030623, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.18673531048840164, 0.1867353104884015, 0.2787982564562775], 
reward next is 0.7212, 
noisyNet noise sample is [array([-1.6055996], dtype=float32), -0.12081412]. 
=============================================
[2019-03-24 08:48:13,872] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:48:13,881] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4172
[2019-03-24 08:48:13,889] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.73333333333333, 59.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5923803960601757, 6.9112, 6.9112, 121.9260426156618, 438676.9477939233, 438676.9477939233, 128993.0030111595], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 805800.0000, 
sim time next is 806400.0000, 
raw observation next is [23.8, 59.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.595836555166231, 6.9112, 6.9112, 121.9260426156618, 441489.2453051695, 441489.2453051695, 129473.0126240474], 
processed observation next is [0.0, 0.34782608695652173, 0.43703703703703706, 0.59, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4947956939577887, 0.0, 0.0, 0.8094621288201359, 0.15767473046613195, 0.15767473046613195, 0.2489865627385527], 
reward next is 0.7510, 
noisyNet noise sample is [array([-0.9481806], dtype=float32), 1.453125]. 
=============================================
[2019-03-24 08:48:18,777] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:48:18,787] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7293
[2019-03-24 08:48:18,795] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.65, 50.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6588379479483861, 6.911200000000001, 6.9112, 121.9260426156618, 491583.2046836598, 491583.2046836594, 138414.931589701], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 856200.0000, 
sim time next is 856800.0000, 
raw observation next is [26.5, 51.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6592906582361996, 6.9112, 6.9112, 121.9260426156618, 491960.3757269894, 491960.3757269894, 138515.6007396842], 
processed observation next is [0.0, 0.9565217391304348, 0.5370370370370371, 0.51, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5741133227952494, 0.0, 0.0, 0.8094621288201359, 0.1757001341882105, 0.1757001341882105, 0.26637615526862346], 
reward next is 0.7336, 
noisyNet noise sample is [array([-1.6207017], dtype=float32), -0.9035436]. 
=============================================
[2019-03-24 08:48:20,204] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 3.6912096e-37 5.4932182e-37 7.3197464e-34 2.3939888e-34], sum to 1.0000
[2019-03-24 08:48:20,217] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1818
[2019-03-24 08:48:20,227] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 724441.6878121339 W.
[2019-03-24 08:48:20,235] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.03333333333333, 57.0, 1.0, 1.0, 0.287743180397258, 1.0, 1.0, 0.287743180397258, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9259350002359, 724441.6878121339, 724441.6878121336, 179992.6464761226], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1068000.0000, 
sim time next is 1068600.0000, 
raw observation next is [23.11666666666666, 56.5, 1.0, 2.0, 0.2810509278647956, 1.0, 2.0, 0.2810509278647956, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.926042582847, 706807.8235875408, 706807.8235875412, 178365.8721369568], 
processed observation next is [1.0, 0.34782608695652173, 0.41172839506172815, 0.565, 1.0, 1.0, 0.14410824745808998, 1.0, 1.0, 0.14410824745808998, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621286022798, 0.25243136556697887, 0.25243136556697904, 0.34301129257107077], 
reward next is 0.6570, 
noisyNet noise sample is [array([-0.06505511], dtype=float32), -1.376654]. 
=============================================
[2019-03-24 08:48:30,915] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 4.2079105e-37], sum to 1.0000
[2019-03-24 08:48:30,921] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6762
[2019-03-24 08:48:30,925] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 815809.6880796287 W.
[2019-03-24 08:48:30,932] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.7, 69.5, 1.0, 2.0, 0.6486394288687469, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999998, 6.9112, 121.9260426156618, 815809.6880796287, 815809.6880796297, 169380.0851124224], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1179000.0000, 
sim time next is 1179600.0000, 
raw observation next is [21.63333333333333, 70.0, 1.0, 2.0, 0.3254667167312768, 1.0, 1.0, 0.3254667167312768, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 812800.0308235734, 812800.0308235734, 189279.579493287], 
processed observation next is [1.0, 0.6521739130434783, 0.35679012345678995, 0.7, 1.0, 1.0, 0.19698418658485334, 1.0, 0.5, 0.19698418658485334, 0.0, 1.0, -0.25, 0.0, 0.0, 0.8094621288201359, 0.2902857252941333, 0.2902857252941333, 0.3639991913332442], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.71770245], dtype=float32), 1.3504511]. 
=============================================
[2019-03-24 08:48:34,698] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.5333461e-37 0.0000000e+00 1.2794798e-35 1.5583518e-33], sum to 1.0000
[2019-03-24 08:48:34,705] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8539
[2019-03-24 08:48:34,713] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 777744.5981004527 W.
[2019-03-24 08:48:34,717] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [20.95, 65.5, 1.0, 2.0, 0.2054990255771409, 1.0, 1.0, 0.2054990255771409, 1.0, 2.0, 0.3501902970292265, 6.9112, 6.9112, 121.94756008, 777744.5981004527, 777744.5981004527, 218850.0842447578], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1161000.0000, 
sim time next is 1161600.0000, 
raw observation next is [21.0, 65.33333333333333, 1.0, 2.0, 0.2049212481900409, 1.0, 2.0, 0.2049212481900409, 1.0, 2.0, 0.3478236153521819, 6.9112, 6.9112, 121.94756008, 773842.8546389494, 773842.8546389494, 218866.6965505993], 
processed observation next is [1.0, 0.43478260869565216, 0.3333333333333333, 0.6533333333333333, 1.0, 1.0, 0.05347767641671536, 1.0, 1.0, 0.05347767641671536, 1.0, 1.0, 0.1847795191902274, 0.0, 0.0, 0.8096049824067558, 0.27637244808533906, 0.27637244808533906, 0.4208974933665371], 
reward next is 0.5791, 
noisyNet noise sample is [array([-1.4895335], dtype=float32), -1.9566]. 
=============================================
[2019-03-24 08:48:38,961] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:48:38,969] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7174
[2019-03-24 08:48:38,974] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.71666666666667, 61.66666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8777940700699777, 6.9112, 6.9112, 121.9260426156618, 655927.222024825, 655927.222024825, 164693.6766889474], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1255800.0000, 
sim time next is 1256400.0000, 
raw observation next is [24.9, 61.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9562509870098377, 6.976238291124108, 6.9112, 121.9257390615481, 747576.0802321989, 714270.7450392494, 173493.5416775323], 
processed observation next is [1.0, 0.5652173913043478, 0.47777777777777775, 0.61, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.9453137337622971, 0.006503829112410831, 0.0, 0.809460113536495, 0.2669914572257853, 0.2550966946568748, 0.33364142630294674], 
reward next is 0.3412, 
noisyNet noise sample is [array([-0.45640343], dtype=float32), -0.843036]. 
=============================================
[2019-03-24 08:48:39,269] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:48:39,279] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5615
[2019-03-24 08:48:39,284] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.4, 80.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6337407249785879, 6.9112, 6.9112, 121.9260426156618, 472291.0501568273, 472291.0501568273, 135198.0993733448], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1728000.0000, 
sim time next is 1728600.0000, 
raw observation next is [21.38333333333333, 80.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6338686310606348, 6.911199999999999, 6.9112, 121.9260426156618, 472385.686931045, 472385.6869310454, 135210.0964830338], 
processed observation next is [1.0, 0.0, 0.3475308641975307, 0.8016666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5423357888257935, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16870917390394466, 0.16870917390394477, 0.26001941631352654], 
reward next is 0.7400, 
noisyNet noise sample is [array([0.6026001], dtype=float32), 0.47725025]. 
=============================================
[2019-03-24 08:48:41,591] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:48:41,599] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3269
[2019-03-24 08:48:41,605] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.06666666666667, 50.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.616752042387009, 6.911200000000001, 6.9112, 121.9260426156618, 458853.6674072257, 458853.6674072252, 132793.9566646983], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1369200.0000, 
sim time next is 1369800.0000, 
raw observation next is [25.85, 51.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.616629812874071, 6.911199999999999, 6.9112, 121.9260426156618, 458734.3650415058, 458734.3650415063, 132758.1460775471], 
processed observation next is [1.0, 0.8695652173913043, 0.5129629629629631, 0.51, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5207872660925887, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.16383370180053777, 0.16383370180053797, 0.25530412707220596], 
reward next is 0.7447, 
noisyNet noise sample is [array([-0.9219526], dtype=float32), -2.36435]. 
=============================================
[2019-03-24 08:48:45,446] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:48:45,453] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4095
[2019-03-24 08:48:45,459] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.66666666666667, 77.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7827718317905221, 6.911199999999999, 6.9112, 121.9260426156618, 583778.3188610269, 583778.3188610274, 156636.5583495413], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1542000.0000, 
sim time next is 1542600.0000, 
raw observation next is [23.65, 77.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7757964547227674, 6.911200000000001, 6.9112, 121.9260426156618, 578849.1649084615, 578849.164908461, 155517.1760205028], 
processed observation next is [0.0, 0.8695652173913043, 0.4314814814814814, 0.77, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7197455684034593, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.20673184461016483, 0.20673184461016467, 0.29907149234712077], 
reward next is 0.7009, 
noisyNet noise sample is [array([-1.2160324], dtype=float32), 0.3464054]. 
=============================================
[2019-03-24 08:48:45,966] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:48:45,979] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3807
[2019-03-24 08:48:45,982] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.56666666666666, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6737876446718452, 6.911199999999999, 6.9112, 121.9260426156618, 503384.7211880754, 503384.7211880759, 141179.5190225899], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1899600.0000, 
sim time next is 1900200.0000, 
raw observation next is [20.48333333333333, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6700497137596068, 6.911200000000001, 6.9112, 121.9260426156618, 500514.6344258654, 500514.634425865, 140566.5897577401], 
processed observation next is [1.0, 1.0, 0.31419753086419744, 0.92, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5875621421995084, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.17875522658066623, 0.1787552265806661, 0.27032036491873096], 
reward next is 0.7297, 
noisyNet noise sample is [array([0.7557264], dtype=float32), -0.25759754]. 
=============================================
[2019-03-24 08:48:48,756] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:48:48,770] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2074
[2019-03-24 08:48:48,779] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [32.25, 34.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7210333913608912, 6.9112, 6.9112, 121.9260426156618, 538562.0845029608, 538562.0845029608, 148263.0248607234], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1506600.0000, 
sim time next is 1507200.0000, 
raw observation next is [32.59999999999999, 33.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7184804917065639, 6.911200000000001, 6.9112, 121.9260426156618, 536615.5587882494, 536615.5587882489, 148052.2871801122], 
processed observation next is [0.0, 0.43478260869565216, 0.7629629629629625, 0.33, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6481006146332049, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1916484138529462, 0.19164841385294604, 0.28471593688483116], 
reward next is 0.7153, 
noisyNet noise sample is [array([0.15166374], dtype=float32), 0.5230064]. 
=============================================
[2019-03-24 08:48:53,410] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-24 08:48:53,413] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:48:53,414] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:48:53,414] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:48:53,416] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:48:53,416] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:48:53,418] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:48:53,418] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:48:53,419] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:48:53,419] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:48:53,419] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:48:53,442] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run96
[2019-03-24 08:48:53,469] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run96
[2019-03-24 08:48:53,507] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run96
[2019-03-24 08:48:53,508] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run96
[2019-03-24 08:48:53,531] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run96
[2019-03-24 08:49:32,515] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026600702]
[2019-03-24 08:49:32,516] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [26.55, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9255507001452979, 6.911200000000001, 6.9112, 121.9260426156618, 675956.343632179, 675956.3436321785, 179646.2215791557]
[2019-03-24 08:49:32,516] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:49:32,519] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.4673633006404022
[2019-03-24 08:49:47,077] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026600702]
[2019-03-24 08:49:47,079] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [32.93181831, 46.45335197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9345956529760546, 6.911199999999999, 6.9112, 121.9260426156618, 675161.7228392023, 675161.7228392027, 182010.9558864771]
[2019-03-24 08:49:47,080] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:49:47,083] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.1818696931161985
[2019-03-24 08:50:10,770] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026600702]
[2019-03-24 08:50:10,771] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [29.52932591, 81.84962208, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 7.985868027098597, 6.9112, 121.9220992215355, 2428963.665083164, 1878655.381396631, 380277.2499054411]
[2019-03-24 08:50:10,773] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:50:10,776] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.23154199212567073
[2019-03-24 08:50:10,777] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2428963.665083164 W.
[2019-03-24 08:50:25,291] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026600702]
[2019-03-24 08:50:25,293] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.0, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9414768890126728, 6.911199999999999, 6.9112, 121.9260426156618, 681170.8907797077, 681170.8907797082, 182827.4553439342]
[2019-03-24 08:50:25,294] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:50:25,297] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.08354794227484175
[2019-03-24 08:50:26,974] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026600702]
[2019-03-24 08:50:26,974] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.95195883333333, 75.77815646, 1.0, 2.0, 0.9781269674797747, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.259367674632729, 6.9112, 121.9243988150365, 1339635.198020935, 1161344.633471951, 237885.7040557157]
[2019-03-24 08:50:26,976] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:50:26,980] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 7.0809845e-37 0.0000000e+00 1.6906958e-35 2.8239734e-34], sampled 0.11935382499687364
[2019-03-24 08:50:26,982] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1339635.198020935 W.
[2019-03-24 08:50:30,728] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026600702]
[2019-03-24 08:50:30,729] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [18.16666666666667, 67.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3980090092250558, 6.9112, 6.9112, 121.9260426156618, 284168.7959271842, 284168.7959271842, 92290.83776884095]
[2019-03-24 08:50:30,730] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:50:30,734] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.7767235297803285
[2019-03-24 08:50:36,485] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 08:50:36,852] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 08:50:36,954] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 08:50:36,984] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 08:50:37,110] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 08:50:38,127] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 2375000, evaluation results [2375000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 08:50:42,726] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.4390441e-38], sum to 1.0000
[2019-03-24 08:50:42,736] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8685
[2019-03-24 08:50:42,746] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.83333333333333, 52.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9173005925717893, 6.911199999999999, 6.9112, 121.9260426156618, 666944.4972653025, 666944.4972653029, 179043.0603411371], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2126400.0000, 
sim time next is 2127000.0000, 
raw observation next is [30.91666666666667, 51.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9122302531767811, 6.911200000000001, 6.9112, 121.9260426156618, 663924.7592124519, 663924.7592124514, 178250.7826747206], 
processed observation next is [0.0, 0.6086956521739131, 0.7006172839506175, 0.5166666666666666, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8902878164709762, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23711598543301854, 0.23711598543301837, 0.342789966682155], 
reward next is 0.6572, 
noisyNet noise sample is [array([-0.15937193], dtype=float32), 2.044771]. 
=============================================
[2019-03-24 08:50:42,766] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[66.49204 ]
 [66.47344 ]
 [66.437035]
 [66.43226 ]
 [66.447784]], R is [[66.51209259]
 [66.50265503]
 [66.49181366]
 [66.4797287 ]
 [66.46663666]].
[2019-03-24 08:50:44,873] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 4.8174462e-35 0.0000000e+00 2.3275596e-33 5.2875859e-33], sum to 1.0000
[2019-03-24 08:50:44,881] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3329
[2019-03-24 08:50:44,895] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 801544.2244172236 W.
[2019-03-24 08:50:44,902] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [19.76666666666667, 80.66666666666666, 1.0, 2.0, 0.3200522082722843, 1.0, 2.0, 0.3200522082722843, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 801544.2244172236, 801544.2244172236, 187943.1256378114], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1680000.0000, 
sim time next is 1680600.0000, 
raw observation next is [19.83333333333333, 80.33333333333334, 1.0, 2.0, 0.3111675695045252, 1.0, 2.0, 0.3111675695045252, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 779621.7673896962, 779621.7673896967, 185708.2339860527], 
processed observation next is [1.0, 0.43478260869565216, 0.2901234567901233, 0.8033333333333335, 1.0, 1.0, 0.17996139226729188, 1.0, 1.0, 0.17996139226729188, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27843634549632007, 0.27843634549632024, 0.3571312192039475], 
reward next is 0.6429, 
noisyNet noise sample is [array([0.21964438], dtype=float32), -0.9092907]. 
=============================================
[2019-03-24 08:50:47,334] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:50:47,340] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3801
[2019-03-24 08:50:47,347] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 734554.0014198081 W.
[2019-03-24 08:50:47,350] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.18333333333334, 72.33333333333334, 1.0, 2.0, 0.2968449797920951, 1.0, 1.0, 0.2968449797920951, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 734554.0014198081, 734554.0014198081, 181959.6916024887], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1689000.0000, 
sim time next is 1689600.0000, 
raw observation next is [22.36666666666667, 71.66666666666667, 1.0, 2.0, 0.2521401827350625, 1.0, 2.0, 0.2521401827350625, 1.0, 1.0, 0.4136274279452556, 6.911199999999999, 6.9112, 121.94756008, 927462.4745157684, 927462.4745157688, 236887.1401940668], 
processed observation next is [1.0, 0.5652173913043478, 0.38395061728395075, 0.7166666666666667, 1.0, 1.0, 0.10969069373221726, 1.0, 1.0, 0.10969069373221726, 1.0, 0.5, 0.26703428493156944, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.33123659804134586, 0.33123659804134603, 0.4555521926808977], 
reward next is 0.5444, 
noisyNet noise sample is [array([0.59407437], dtype=float32), 0.7859343]. 
=============================================
[2019-03-24 08:50:48,182] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:50:48,189] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2251
[2019-03-24 08:50:48,197] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.5, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7008053595126502, 6.911200000000001, 6.9112, 121.9260426156618, 523705.7989789845, 523705.7989789841, 144940.4756322923], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1707600.0000, 
sim time next is 1708200.0000, 
raw observation next is [23.45, 73.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7028170578565475, 6.9112, 6.9112, 121.9260426156618, 525207.6507338602, 525207.6507338602, 145224.2844208794], 
processed observation next is [1.0, 0.782608695652174, 0.42407407407407405, 0.735, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6285213223206843, 0.0, 0.0, 0.8094621288201359, 0.18757416097637863, 0.18757416097637863, 0.27927747004015274], 
reward next is 0.7207, 
noisyNet noise sample is [array([0.6316327], dtype=float32), -0.47094098]. 
=============================================
[2019-03-24 08:50:49,616] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:50:49,633] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9694
[2019-03-24 08:50:49,637] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.36666666666667, 85.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5263975516813798, 6.911199999999999, 6.9112, 121.9260426156618, 382194.8284535994, 382194.8284535998, 119408.2665603744], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1802400.0000, 
sim time next is 1803000.0000, 
raw observation next is [18.38333333333333, 85.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5263789350702899, 6.911200000000001, 6.9112, 121.9260426156618, 382421.7175127527, 382421.7175127523, 119501.7172774599], 
processed observation next is [1.0, 0.8695652173913043, 0.2364197530864196, 0.8583333333333334, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.4079736688378623, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1365791848259831, 0.13657918482598297, 0.22981099476434597], 
reward next is 0.7702, 
noisyNet noise sample is [array([0.65256715], dtype=float32), -0.51937246]. 
=============================================
[2019-03-24 08:50:49,651] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[70.15373 ]
 [70.16286 ]
 [70.02472 ]
 [70.24495 ]
 [70.388245]], R is [[69.92214966]
 [69.99330139]
 [70.06377411]
 [70.13352203]
 [70.20245361]].
[2019-03-24 08:50:57,307] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:50:57,313] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4419
[2019-03-24 08:50:57,318] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.56666666666667, 85.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7693735573642324, 6.9112, 6.9112, 121.9260426156618, 573557.1371860858, 573557.1371860858, 155231.715576881], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1978800.0000, 
sim time next is 1979400.0000, 
raw observation next is [22.18333333333333, 86.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7501984794990528, 6.911200000000001, 6.9112, 121.9260426156618, 559958.4664700337, 559958.4664700333, 152232.1357722257], 
processed observation next is [1.0, 0.9130434782608695, 0.3771604938271604, 0.8633333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6877480993738161, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1999851665964406, 0.19998516659644044, 0.2927541072542802], 
reward next is 0.7072, 
noisyNet noise sample is [array([-0.10853505], dtype=float32), -1.6853274]. 
=============================================
[2019-03-24 08:51:01,802] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:51:01,807] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6006
[2019-03-24 08:51:01,814] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 719136.219604616 W.
[2019-03-24 08:51:01,822] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.36666666666667, 74.0, 1.0, 2.0, 0.2103367453871219, 1.0, 2.0, 0.2103367453871219, 1.0, 2.0, 0.3348629488458587, 6.9112, 6.9112, 121.94756008, 719136.219604616, 719136.219604616, 224000.8628829683], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2150400.0000, 
sim time next is 2151000.0000, 
raw observation next is [27.2, 74.5, 1.0, 2.0, 0.3131421212970198, 1.0, 2.0, 0.3131421212970198, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 713747.7521703355, 713747.752170336, 183644.357460168], 
processed observation next is [0.0, 0.9130434782608695, 0.5629629629629629, 0.745, 1.0, 1.0, 0.1823120491631188, 1.0, 1.0, 0.1823120491631188, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.25490991148940556, 0.2549099114894057, 0.35316222588493845], 
reward next is 0.6468, 
noisyNet noise sample is [array([0.49848166], dtype=float32), -1.128887]. 
=============================================
[2019-03-24 08:51:01,843] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[67.308815]
 [66.48976 ]
 [66.53299 ]
 [66.416824]
 [65.630714]], R is [[66.40625   ]
 [66.31141663]
 [65.64830017]
 [64.99182129]
 [64.34190369]].
[2019-03-24 08:51:03,577] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 9.163265e-37], sum to 1.0000
[2019-03-24 08:51:03,587] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7395
[2019-03-24 08:51:03,592] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.4, 86.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6187265328223499, 6.9112, 6.9112, 121.9260426156618, 460643.6963706793, 460643.6963706793, 133267.74574119], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2010600.0000, 
sim time next is 2011200.0000, 
raw observation next is [20.53333333333333, 85.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6208970943772758, 6.9112, 6.9112, 121.9260426156618, 462342.7359038572, 462342.7359038572, 133556.1915840799], 
processed observation next is [0.0, 0.2608695652173913, 0.3160493827160493, 0.8566666666666667, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5261213679715947, 0.0, 0.0, 0.8094621288201359, 0.165122405679949, 0.165122405679949, 0.25683882996938445], 
reward next is 0.7432, 
noisyNet noise sample is [array([1.555711], dtype=float32), 0.5931651]. 
=============================================
[2019-03-24 08:51:11,280] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 3.146294e-37], sum to 1.0000
[2019-03-24 08:51:11,288] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2062
[2019-03-24 08:51:11,298] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 709685.8225743677 W.
[2019-03-24 08:51:11,307] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.03333333333333, 75.0, 1.0, 2.0, 0.3113608579169441, 1.0, 2.0, 0.3113608579169441, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 709685.8225743677, 709685.8225743682, 183209.3055054154], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2151600.0000, 
sim time next is 2152200.0000, 
raw observation next is [26.86666666666667, 75.5, 1.0, 2.0, 0.3090578555911532, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4920301714127765, 6.911199999999999, 6.9112, 121.9260426156618, 704434.1699644424, 704434.1699644428, 197694.3755381683], 
processed observation next is [0.0, 0.9130434782608695, 0.5506172839506175, 0.755, 1.0, 1.0, 0.17744982808470616, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.3650377142659706, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.251583632130158, 0.25158363213015816, 0.38018149141955443], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.23273], dtype=float32), -1.5289124]. 
=============================================
[2019-03-24 08:51:19,901] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 3.0858793e-34 7.7983295e-37 3.4151499e-31 8.6858594e-32], sum to 1.0000
[2019-03-24 08:51:19,908] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4671
[2019-03-24 08:51:19,913] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.13333333333334, 52.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7206154589374821, 6.911200000000001, 6.9112, 121.9260426156618, 537490.3124129922, 537490.3124129918, 144679.9198777069], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2359200.0000, 
sim time next is 2359800.0000, 
raw observation next is [26.45, 49.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7397589174325225, 6.9112, 6.9112, 121.9260426156618, 551330.5886220585, 551330.5886220585, 146264.1808522944], 
processed observation next is [1.0, 0.30434782608695654, 0.5351851851851852, 0.495, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6746986467906532, 0.0, 0.0, 0.8094621288201359, 0.1969037816507352, 0.1969037816507352, 0.2812772708697969], 
reward next is 0.7187, 
noisyNet noise sample is [array([0.8999177], dtype=float32), -0.19639131]. 
=============================================
[2019-03-24 08:51:22,762] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 2.6230171e-37 0.0000000e+00 9.9068035e-35 4.4293656e-34], sum to 1.0000
[2019-03-24 08:51:22,768] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7549
[2019-03-24 08:51:22,772] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8229312703560574, 6.911199999999999, 6.9112, 121.9260426156618, 611960.9638264467, 611960.9638264471, 162820.6249656811], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2872800.0000, 
sim time next is 2873400.0000, 
raw observation next is [22.0, 94.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9184213051331618, 6.911199999999999, 6.9112, 121.9260426156618, 683119.485250628, 683119.4852506284, 174789.7481931785], 
processed observation next is [1.0, 0.2608695652173913, 0.37037037037037035, 0.9400000000000002, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8980266314164522, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.24397124473236714, 0.2439712447323673, 0.3361341311407279], 
reward next is 0.6639, 
noisyNet noise sample is [array([-0.12726568], dtype=float32), -2.0053818]. 
=============================================
[2019-03-24 08:51:27,737] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-24 08:51:27,739] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:51:27,740] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:51:27,741] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:51:27,741] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:51:27,741] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:51:27,742] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:51:27,742] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:51:27,743] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:51:27,744] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:51:27,748] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:51:27,770] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run97
[2019-03-24 08:51:27,798] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run97
[2019-03-24 08:51:27,829] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run97
[2019-03-24 08:51:27,830] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run97
[2019-03-24 08:51:27,830] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run97
[2019-03-24 08:51:41,427] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026736077]
[2019-03-24 08:51:41,428] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.45, 47.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7160886733440897, 6.911200000000001, 6.9112, 121.9260426156618, 535068.6616440361, 535068.6616440356, 147136.4776365505]
[2019-03-24 08:51:41,429] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:51:41,435] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.2769944074258728
[2019-03-24 08:51:45,615] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026736077]
[2019-03-24 08:51:45,616] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [22.221777565, 87.36112632000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7313854262941463, 6.9112, 6.9112, 121.9260426156618, 545669.1848548205, 545669.1848548205, 150335.4202501232]
[2019-03-24 08:51:45,617] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:51:45,623] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.5064379e-38 4.2210612e-37], sampled 0.028094845143566638
[2019-03-24 08:51:55,136] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026736077]
[2019-03-24 08:51:55,138] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [19.68333333333333, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6352656621577787, 6.911200000000001, 6.9112, 121.9260426156618, 472823.0166646215, 472823.016664621, 134770.7084833345]
[2019-03-24 08:51:55,138] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:51:55,144] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 4.366112e-38], sampled 0.18276130736443152
[2019-03-24 08:51:56,423] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026736077]
[2019-03-24 08:51:56,423] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [19.88333333333333, 89.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6143019122175601, 6.9112, 6.9112, 121.9260426156618, 457040.9047525676, 457040.9047525676, 132565.5103156318]
[2019-03-24 08:51:56,424] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:51:56,428] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.6193615670445088
[2019-03-24 08:52:25,717] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026736077]
[2019-03-24 08:52:25,719] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.85, 95.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7239301476417982, 6.9112, 6.9112, 121.9260426156618, 540810.4722571144, 540810.4722571144, 148400.1265774934]
[2019-03-24 08:52:25,720] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:52:25,724] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.6268676e-37], sampled 0.17676677447877243
[2019-03-24 08:52:27,514] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026736077]
[2019-03-24 08:52:27,515] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [32.66666666666666, 71.5, 1.0, 2.0, 0.9728983052973901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.977686313792678, 6.9112, 121.9255359449283, 1143125.349755963, 1109078.556098829, 234270.0895889173]
[2019-03-24 08:52:27,516] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:52:27,519] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.028632433092259713
[2019-03-24 08:52:27,520] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1143125.349755963 W.
[2019-03-24 08:52:28,771] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026736077]
[2019-03-24 08:52:28,773] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [31.9, 53.0, 1.0, 2.0, 0.9365111867080825, 1.0, 2.0, 0.9365111867080825, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 2136469.973953895, 2136469.973953896, 403391.3702124649]
[2019-03-24 08:52:28,774] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:52:28,778] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 2.1272746e-36 0.0000000e+00 5.7220379e-35 1.1524454e-33], sampled 0.1993161053346848
[2019-03-24 08:52:28,780] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2136469.973953895 W.
[2019-03-24 08:52:33,435] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026736077]
[2019-03-24 08:52:33,437] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [25.49719341666667, 87.48894029333333, 1.0, 1.0, 0.6191358271229654, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 706707.52376501, 706707.52376501, 161455.9816624041]
[2019-03-24 08:52:33,438] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:52:33,442] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 2.8331609e-38 0.0000000e+00 1.1244640e-36 2.8950348e-35], sampled 0.024279377134159064
[2019-03-24 08:52:33,443] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 706707.52376501 W.
[2019-03-24 08:52:43,393] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026736077]
[2019-03-24 08:52:43,393] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [27.41666666666666, 87.16666666666667, 1.0, 2.0, 0.7508831821987435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 855826.7883560732, 855826.7883560727, 186004.7076165926]
[2019-03-24 08:52:43,394] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:52:43,397] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.5387772e-38 4.8017364e-37], sampled 0.4014983482592678
[2019-03-24 08:52:43,398] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 855826.7883560732 W.
[2019-03-24 08:52:45,953] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026736077]
[2019-03-24 08:52:45,954] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.03861098333334, 83.67442850833332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8095516885757532, 6.911200000000001, 6.9112, 121.9260426156618, 599438.7226922722, 599438.7226922717, 162324.2346879328]
[2019-03-24 08:52:45,956] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:52:45,958] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.9491933378493589
[2019-03-24 08:52:53,135] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026736077]
[2019-03-24 08:52:53,137] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.82226154333333, 84.40555032333333, 1.0, 2.0, 0.6526725028025254, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 743835.8469285504, 743835.8469285499, 167379.5806422331]
[2019-03-24 08:52:53,138] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:52:53,141] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.9916640e-34 6.8186808e-38 4.4384165e-33 7.4406976e-32], sampled 0.5291685117936059
[2019-03-24 08:52:53,142] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 743835.8469285504 W.
[2019-03-24 08:52:53,725] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026736077]
[2019-03-24 08:52:53,726] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.59684251333333, 86.40529439833333, 1.0, 2.0, 0.639898899972878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 729271.1404678753, 729271.1404678748, 165076.1807878022]
[2019-03-24 08:52:53,726] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:52:53,729] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 2.6946454e-33 1.1064904e-36 5.4037993e-32 8.4056319e-31], sampled 0.012398948599306792
[2019-03-24 08:52:53,731] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 729271.1404678753 W.
[2019-03-24 08:53:00,903] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026736077]
[2019-03-24 08:53:00,903] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [20.76666666666667, 89.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8127415354421111, 6.9112, 6.9112, 121.9260426156618, 607111.8351685051, 607111.8351685051, 156450.5930529162]
[2019-03-24 08:53:00,904] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:53:00,907] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 3.4958872e-37 8.9106317e-36], sampled 0.9910105482302889
[2019-03-24 08:53:03,881] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026736077]
[2019-03-24 08:53:03,881] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [25.25, 85.0, 1.0, 2.0, 0.6000754304140118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 692017.0543704722, 692017.0543704722, 158487.068496483]
[2019-03-24 08:53:03,883] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:53:03,888] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.9881418e-34 6.2367748e-38 4.2007338e-33 7.0222804e-32], sampled 0.8706605217204456
[2019-03-24 08:53:03,889] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 692017.0543704722 W.
[2019-03-24 08:53:04,106] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026736077]
[2019-03-24 08:53:04,107] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [24.0, 92.66666666666666, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.36382888110908, 6.9112, 121.9241650127955, 1410213.687013499, 1178430.813775917, 246462.3926654379]
[2019-03-24 08:53:04,110] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:53:04,113] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 4.7569064e-29 5.6869465e-32 5.2503951e-28 4.6373500e-27], sampled 0.8348986045749042
[2019-03-24 08:53:04,113] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1410213.687013499 W.
[2019-03-24 08:53:10,972] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 08:53:11,063] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 08:53:11,144] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 08:53:11,186] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 08:53:11,258] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 08:53:12,274] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 2400000, evaluation results [2400000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 08:53:16,315] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 5.2779195e-38 0.0000000e+00 1.1832351e-35 1.7629748e-35], sum to 1.0000
[2019-03-24 08:53:16,323] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2853
[2019-03-24 08:53:16,329] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.65, 96.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7286253089542005, 6.911199999999999, 6.9112, 121.9260426156618, 544345.2075842349, 544345.2075842354, 148864.1171219919], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2609400.0000, 
sim time next is 2610000.0000, 
raw observation next is [20.6, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7265967900468963, 6.911200000000001, 6.9112, 121.9260426156618, 542857.3420342486, 542857.3420342482, 148553.1899915311], 
processed observation next is [0.0, 0.21739130434782608, 0.3185185185185186, 0.97, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6582459875586202, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.1938776221550888, 0.19387762215508864, 0.2856792115221752], 
reward next is 0.7143, 
noisyNet noise sample is [array([0.7770443], dtype=float32), -0.2673271]. 
=============================================
[2019-03-24 08:53:16,354] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[60.618202]
 [60.716892]
 [60.844612]
 [60.941265]
 [61.0301  ]], R is [[60.69808197]
 [60.80482483]
 [60.90995407]
 [61.01355362]
 [61.11563492]].
[2019-03-24 08:53:25,101] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 9.0351064e-24 2.6873564e-26 2.4178173e-24 6.7124328e-22], sum to 1.0000
[2019-03-24 08:53:25,112] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5147
[2019-03-24 08:53:25,119] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2088235.475824178 W.
[2019-03-24 08:53:25,125] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.75, 81.5, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 7.321169484400069, 6.9112, 121.9243811179747, 2088235.475824178, 1878297.318040697, 382662.0560665882], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2901000.0000, 
sim time next is 2901600.0000, 
raw observation next is [27.1, 80.0, 1.0, 2.0, 0.8307863436309264, 1.0, 1.0, 0.8307863436309264, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9257957391467, 1895023.192115261, 1895023.192115261, 356639.7790910895], 
processed observation next is [1.0, 0.6086956521739131, 0.5592592592592593, 0.8, 1.0, 1.0, 0.7985551709891981, 1.0, 0.5, 0.7985551709891981, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094604898168091, 0.6767939971840218, 0.6767939971840218, 0.685845729021326], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8270514], dtype=float32), 0.9236658]. 
=============================================
[2019-03-24 08:53:35,697] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.5581679e-25 6.6219726e-28 1.6355402e-24 3.2755242e-22], sum to 1.0000
[2019-03-24 08:53:35,707] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5345
[2019-03-24 08:53:35,716] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1580652.951097739 W.
[2019-03-24 08:53:35,720] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.83333333333334, 79.83333333333334, 1.0, 2.0, 0.4620580662507668, 1.0, 1.0, 0.4620580662507668, 1.0, 2.0, 0.7356114896518704, 6.9112, 6.9112, 121.94756008, 1580652.951097739, 1580652.951097739, 325332.898151714], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2983800.0000, 
sim time next is 2984400.0000, 
raw observation next is [29.0, 79.0, 1.0, 2.0, 0.69057231488103, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.9112, 6.9112, 121.9260426156618, 1502040.892607447, 1502040.892607447, 315532.021725521], 
processed observation next is [1.0, 0.5652173913043478, 0.6296296296296297, 0.79, 1.0, 1.0, 0.6316337081917024, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.9972168686025908, 0.0, 0.0, 0.8094621288201359, 0.536443175931231, 0.536443175931231, 0.6067923494721558], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3221368], dtype=float32), 0.2997851]. 
=============================================
[2019-03-24 08:53:50,977] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.000000e+00 2.015556e-34 0.000000e+00 7.582269e-33 5.025226e-32], sum to 1.0000
[2019-03-24 08:53:50,982] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5008
[2019-03-24 08:53:50,988] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 732599.7387066834 W.
[2019-03-24 08:53:50,995] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.83333333333333, 78.16666666666667, 1.0, 2.0, 0.3214090916076495, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5116937414027131, 6.911199999999999, 6.9112, 121.9260426156618, 732599.7387066834, 732599.7387066839, 201086.6266321712], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3193800.0000, 
sim time next is 3194400.0000, 
raw observation next is [26.66666666666667, 77.33333333333334, 1.0, 2.0, 0.2117856167561064, 1.0, 1.0, 0.2117856167561064, 1.0, 2.0, 0.3371695992517283, 6.911199999999999, 6.9112, 121.94756008, 724092.2148014673, 724092.2148014676, 224483.0769858282], 
processed observation next is [1.0, 1.0, 0.5432098765432101, 0.7733333333333334, 1.0, 1.0, 0.06164954375726953, 1.0, 0.5, 0.06164954375726953, 1.0, 1.0, 0.17146199906466034, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.25860436242909546, 0.25860436242909557, 0.4316982249727465], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0325515], dtype=float32), 1.3238105]. 
=============================================
[2019-03-24 08:53:53,477] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 2.1873770e-23 1.1190956e-25 1.1857558e-21 6.0733222e-22], sum to 1.0000
[2019-03-24 08:53:53,488] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8799
[2019-03-24 08:53:53,497] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 770745.4183399322 W.
[2019-03-24 08:53:53,502] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.3381361074273954, 1.0, 2.0, 0.3381361074273954, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 770745.4183399322, 770745.4183399327, 189864.3377040848], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3729600.0000, 
sim time next is 3730200.0000, 
raw observation next is [24.9, 94.66666666666667, 1.0, 2.0, 0.3638222382106145, 1.0, 2.0, 0.3638222382106145, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 829325.9057703759, 829325.9057703763, 196481.5791390959], 
processed observation next is [1.0, 0.17391304347826086, 0.47777777777777775, 0.9466666666666668, 1.0, 1.0, 0.24264552167930298, 1.0, 1.0, 0.24264552167930298, 0.0, 1.0, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.29618782348941997, 0.29618782348942013, 0.37784919065210754], 
reward next is 0.6222, 
noisyNet noise sample is [array([1.2775133], dtype=float32), -0.9393021]. 
=============================================
[2019-03-24 08:53:58,147] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.7474709e-24 7.0367751e-28 3.7944707e-24 7.0194973e-24], sum to 1.0000
[2019-03-24 08:53:58,154] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8959
[2019-03-24 08:53:58,164] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2436879.31434329 W.
[2019-03-24 08:53:58,170] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.4, 67.5, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 7.125137977600304, 6.9112, 121.9252157860045, 2436879.31434329, 2327324.691191589, 443050.1831672398], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3763800.0000, 
sim time next is 3764400.0000, 
raw observation next is [32.53333333333333, 66.33333333333333, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 2.0, 0.0, 8.649904404794198, 6.9112, 121.9189080497946, 3218663.134494158, 2328343.176187876, 443050.2745391559], 
processed observation next is [1.0, 0.5652173913043478, 0.7604938271604937, 0.6633333333333333, 1.0, 1.0, 1.0238095238095237, 1.0, 1.0, 1.0238095238095237, 0.0, 1.0, -0.25, 0.17387044047941974, 0.0, 0.8094147627222033, 1.1495225480336277, 0.8315511343528129, 0.8520197587291459], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1246591], dtype=float32), -0.7054449]. 
=============================================
[2019-03-24 08:54:01,548] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 8.9340534e-20 8.8364962e-22 9.7183770e-20 3.6656628e-19], sum to 1.0000
[2019-03-24 08:54:01,556] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0321
[2019-03-24 08:54:01,564] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 866011.312407828 W.
[2019-03-24 08:54:01,567] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.0, 94.0, 1.0, 2.0, 0.3792733196112238, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6038640856738775, 6.911199999999999, 6.9112, 121.9260426156618, 866011.312407828, 866011.3124078285, 217767.9346969839], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3384000.0000, 
sim time next is 3384600.0000, 
raw observation next is [23.81666666666667, 94.00000000000001, 1.0, 2.0, 0.3692493811864744, 1.0, 1.0, 0.3692493811864744, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 842697.089597497, 842697.089597497, 197956.7830775422], 
processed observation next is [1.0, 0.17391304347826086, 0.43765432098765444, 0.9400000000000002, 1.0, 1.0, 0.24910640617437427, 1.0, 0.5, 0.24910640617437427, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.30096324628482035, 0.30096324628482035, 0.38068612130296575], 
reward next is 0.6193, 
noisyNet noise sample is [array([0.77831125], dtype=float32), 1.466643]. 
=============================================
[2019-03-24 08:54:02,008] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-24 08:54:02,009] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:54:02,010] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:54:02,010] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:54:02,011] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:54:02,011] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:54:02,012] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:54:02,012] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:54:02,012] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:54:02,014] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:54:02,016] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:54:02,030] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run98
[2019-03-24 08:54:02,030] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run98
[2019-03-24 08:54:02,081] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run98
[2019-03-24 08:54:02,114] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run98
[2019-03-24 08:54:02,137] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run98
[2019-03-24 08:54:13,799] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026237838]
[2019-03-24 08:54:13,805] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [22.0, 33.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4624617635654284, 6.911200000000001, 6.9112, 121.9260426156618, 330196.4077487737, 330196.4077487732, 90351.5085121791]
[2019-03-24 08:54:13,806] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:54:13,809] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 6.2683668e-34 1.9142147e-37 2.3614656e-32 1.7832563e-31], sampled 0.8660117350830918
[2019-03-24 08:54:40,299] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026237838]
[2019-03-24 08:54:40,301] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [26.840594025, 50.31138751166667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6916017526052861, 6.911200000000001, 6.9112, 121.9260426156618, 516703.2289631919, 516703.2289631914, 143098.8461722585]
[2019-03-24 08:54:40,302] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:54:40,305] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.2078971e-30 8.5472756e-34 3.1579705e-29 2.0026560e-28], sampled 0.0017372910148613085
[2019-03-24 08:55:10,691] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026237838]
[2019-03-24 08:55:10,693] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.91284318333334, 68.2778907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7478246695199561, 6.9112, 6.9112, 121.9260426156618, 558457.9819957584, 558457.9819957584, 151557.0712623632]
[2019-03-24 08:55:10,694] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:55:10,696] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.2509864e-26 2.3177473e-29 2.0513789e-25 1.0989171e-24], sampled 0.10458350520437354
[2019-03-24 08:55:14,546] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026237838]
[2019-03-24 08:55:14,547] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.86666666666667, 93.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7565672962657016, 6.9112, 6.9112, 121.9260426156618, 563522.4023191892, 563522.4023191892, 154086.8228108569]
[2019-03-24 08:55:14,548] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:55:14,551] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 1.6983673e-29 1.5956791e-32 3.9431494e-28 2.3391559e-27], sampled 0.38306778121157437
[2019-03-24 08:55:16,137] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026237838]
[2019-03-24 08:55:16,138] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [25.66979895, 62.65432856, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.744042757173639, 6.911200000000001, 6.9112, 121.9260426156618, 555494.4097212186, 555494.4097212182, 151335.2989983623]
[2019-03-24 08:55:16,140] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:55:16,144] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 8.1772010e-28 1.0091588e-30 1.4671614e-26 8.1966032e-26], sampled 0.29369706300692244
[2019-03-24 08:55:36,561] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026237838]
[2019-03-24 08:55:36,561] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [20.97053312333333, 68.15932388333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5708227614402575, 6.911200000000001, 6.9112, 121.9260426156618, 417946.8528752853, 417946.8528752848, 124545.0707098714]
[2019-03-24 08:55:36,562] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:55:36,565] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 9.9051284e-30 8.8315611e-33 2.3187479e-28 1.4511136e-27], sampled 0.3243685971224409
[2019-03-24 08:55:45,270] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 08:55:45,323] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 08:55:45,410] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 08:55:45,481] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 08:55:45,590] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 08:55:46,608] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 2425000, evaluation results [2425000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 08:55:57,143] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 2.1470215e-27 1.6933068e-31 2.8234678e-26 9.5712602e-25], sum to 1.0000
[2019-03-24 08:55:57,148] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8396
[2019-03-24 08:55:57,153] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1204732.384443708 W.
[2019-03-24 08:55:57,158] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 89.0, 1.0, 2.0, 0.3467121344082887, 1.0, 1.0, 0.3467121344082887, 1.0, 2.0, 0.5528864882257041, 6.9112, 6.9112, 121.94756008, 1204732.384443708, 1204732.384443708, 274574.5321458096], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3578400.0000, 
sim time next is 3579000.0000, 
raw observation next is [23.11666666666667, 87.83333333333334, 1.0, 2.0, 0.5356987196707325, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8565398991672523, 6.911200000000001, 6.9112, 121.9260426156618, 1255897.925517267, 1255897.925517266, 268991.2807029732], 
processed observation next is [1.0, 0.43478260869565216, 0.41172839506172854, 0.8783333333333334, 1.0, 1.0, 0.44726038056039574, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.8206748739590652, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.448534973399024, 0.44853497339902354, 0.5172909244287947], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.6493388], dtype=float32), 0.26230335]. 
=============================================
[2019-03-24 08:55:57,181] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[46.287045]
 [45.789875]
 [45.908207]
 [45.82813 ]
 [46.38653 ]], R is [[46.01803589]
 [45.55785751]
 [45.60081482]
 [45.62359238]
 [45.1673584 ]].
[2019-03-24 08:56:01,374] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 4.7197868e-26 1.4538341e-27 3.1476337e-25 1.5284398e-23], sum to 1.0000
[2019-03-24 08:56:01,380] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2071
[2019-03-24 08:56:01,388] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 970264.2582709669 W.
[2019-03-24 08:56:01,391] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.5, 97.0, 1.0, 2.0, 0.4256122631686176, 0.0, 1.0, 0.0, 1.0, 2.0, 0.6775885841881483, 6.9112, 6.9112, 121.9260424099517, 970264.2582709669, 970264.2582709669, 232133.1393198871], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3673800.0000, 
sim time next is 3674400.0000, 
raw observation next is [23.66666666666667, 96.0, 1.0, 2.0, 0.3152370851705233, 1.0, 1.0, 0.3152370851705233, 1.0, 2.0, 0.5018677061465916, 6.9112, 6.9112, 121.94756008, 1078040.138181346, 1078040.138181346, 261945.2418056017], 
processed observation next is [1.0, 0.5217391304347826, 0.43209876543209896, 0.96, 1.0, 1.0, 0.1848060537744325, 1.0, 0.5, 0.1848060537744325, 1.0, 1.0, 0.37733463268323947, 0.0, 0.0, 0.8096049824067558, 0.38501433506476646, 0.38501433506476646, 0.5037408496261571], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2938411], dtype=float32), 0.44672617]. 
=============================================
[2019-03-24 08:56:03,756] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 2.8063801e-21 2.9409825e-21 2.5860220e-19 6.1466299e-20], sum to 1.0000
[2019-03-24 08:56:03,763] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7979
[2019-03-24 08:56:03,776] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 905607.9833021703 W.
[2019-03-24 08:56:03,783] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.93333333333333, 96.0, 1.0, 2.0, 0.2648447920645097, 1.0, 2.0, 0.2648447920645097, 1.0, 1.0, 0.4216415343594069, 6.9112, 6.9112, 121.94756008, 905607.9833021703, 905607.9833021703, 242950.80322161], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3742800.0000, 
sim time next is 3743400.0000, 
raw observation next is [25.16666666666667, 95.0, 1.0, 2.0, 0.4156265191997689, 1.0, 2.0, 0.4156265191997689, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 947485.7789468871, 947485.7789468876, 210523.2045434933], 
processed observation next is [1.0, 0.30434782608695654, 0.4876543209876545, 0.95, 1.0, 1.0, 0.3043172847616296, 1.0, 1.0, 0.3043172847616296, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.33838777819531685, 0.338387778195317, 0.4048523164297948], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.0597111], dtype=float32), 0.120633215]. 
=============================================
[2019-03-24 08:56:03,788] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 2.4500639e-23 8.8560508e-26 3.1933165e-23 5.3960403e-22], sum to 1.0000
[2019-03-24 08:56:03,804] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4123
[2019-03-24 08:56:03,810] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [32.66666666666666, 65.16666666666667, 1.0, 2.0, 1.02, 1.0, 2.0, 1.02, 0.0, 1.0, 0.0, 8.871100858212571, 6.9112, 121.9180883067145, 3332069.935436849, 2328490.998640193, 443050.2338261729], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3765000.0000, 
sim time next is 3765600.0000, 
raw observation next is [32.8, 64.0, 1.0, 2.0, 1.02, 1.0, 2.0, 0.8328388556489742, 1.0, 1.0, 0.9977734948820727, 6.953416008825759, 6.9112, 121.94756008, 2851081.008362543, 2829458.823417552, 528071.6928703211], 
processed observation next is [1.0, 0.6086956521739131, 0.7703703703703703, 0.64, 1.0, 1.0, 1.0238095238095237, 1.0, 1.0, 0.8009986376773502, 1.0, 0.5, 0.9972168686025908, 0.00422160088257586, 0.0, 0.8096049824067558, 1.0182432172723368, 1.0105210083634113, 1.015522486289079], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.60243857], dtype=float32), -1.2244339]. 
=============================================
[2019-03-24 08:56:10,851] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.00000000e+00 1.15896994e-26 6.20341794e-29 4.25719480e-26
 1.91232887e-25], sum to 1.0000
[2019-03-24 08:56:10,857] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0841
[2019-03-24 08:56:10,862] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 808534.0564904286 W.
[2019-03-24 08:56:10,866] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [33.66666666666667, 52.83333333333334, 1.0, 2.0, 0.2364705143511399, 1.0, 1.0, 0.2364705143511399, 1.0, 2.0, 0.3764687601540109, 6.911200000000001, 6.9112, 121.94756008, 808534.0564904286, 808534.0564904282, 232879.1482069005], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3867000.0000, 
sim time next is 3867600.0000, 
raw observation next is [33.33333333333334, 55.66666666666667, 1.0, 2.0, 0.362829458175242, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5776363139454832, 6.911199999999999, 6.9112, 121.9260426156618, 827061.6614789679, 827061.6614789683, 212912.2186787677], 
processed observation next is [0.0, 0.782608695652174, 0.7901234567901239, 0.5566666666666668, 1.0, 1.0, 0.24146364068481188, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.47204539243185395, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.29537916481391707, 0.29537916481391724, 0.4094465743822456], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.098968], dtype=float32), 0.589514]. 
=============================================
[2019-03-24 08:56:13,666] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.00000000e+00 1.19446276e-22 2.46383324e-22 1.29284945e-20
 4.12474776e-20], sum to 1.0000
[2019-03-24 08:56:13,672] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0240
[2019-03-24 08:56:13,679] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1554116.68012991 W.
[2019-03-24 08:56:13,686] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.45, 87.33333333333333, 1.0, 2.0, 0.6814705980015667, 1.0, 2.0, 0.6814705980015667, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 123.2625599297625, 1554116.68012991, 1554116.68012991, 297410.0482661059], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3982200.0000, 
sim time next is 3982800.0000, 
raw observation next is [25.4, 87.66666666666667, 1.0, 2.0, 0.5035347090408688, 1.0, 2.0, 0.5035347090408688, 1.0, 1.0, 0.8016436557736643, 6.9112, 6.9112, 122.6498136504825, 1722667.750874816, 1722667.750874816, 345484.4889292052], 
processed observation next is [1.0, 0.08695652173913043, 0.49629629629629624, 0.8766666666666667, 1.0, 1.0, 0.40896989171532, 1.0, 1.0, 0.40896989171532, 1.0, 0.5, 0.7520545697170802, 0.0, 0.0, 0.8142672158225174, 0.6152384824552914, 0.6152384824552914, 0.6643932479407793], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.63196176], dtype=float32), 0.507352]. 
=============================================
[2019-03-24 08:56:22,272] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 08:56:22,279] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6373
[2019-03-24 08:56:22,283] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.15, 95.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8937401338100057, 6.9112, 6.9112, 121.9260426156618, 655716.6029313749, 655716.6029313749, 174764.1761515407], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4512600.0000, 
sim time next is 4513200.0000, 
raw observation next is [23.1, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9032672638555783, 6.9112, 6.9112, 121.9260426156618, 661380.609349485, 661380.609349485, 176313.3122673156], 
processed observation next is [0.0, 0.21739130434782608, 0.41111111111111115, 0.97, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8790840798194729, 0.0, 0.0, 0.8094621288201359, 0.23620736048195892, 0.23620736048195892, 0.33906406205253], 
reward next is 0.6609, 
noisyNet noise sample is [array([-0.92064565], dtype=float32), -0.44771463]. 
=============================================
[2019-03-24 08:56:25,175] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 1.4292356e-37 0.0000000e+00 9.6837803e-34 2.7674730e-34], sum to 1.0000
[2019-03-24 08:56:25,181] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7544
[2019-03-24 08:56:25,184] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.66666666666667, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7659848723262008, 6.9112, 6.9112, 121.9260426156618, 570796.6174283976, 570796.6174283976, 155018.1615792754], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4171800.0000, 
sim time next is 4172400.0000, 
raw observation next is [22.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7903257943964879, 6.9112, 6.9112, 121.9260426156618, 588175.851417082, 588175.851417082, 158492.7215390412], 
processed observation next is [1.0, 0.30434782608695654, 0.37037037037037035, 0.94, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7379072429956098, 0.0, 0.0, 0.8094621288201359, 0.21006280407752928, 0.21006280407752928, 0.3047936952673869], 
reward next is 0.6952, 
noisyNet noise sample is [array([-0.6395363], dtype=float32), -0.062717944]. 
=============================================
[2019-03-24 08:56:27,123] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 1.465079e-36], sum to 1.0000
[2019-03-24 08:56:27,129] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6896
[2019-03-24 08:56:27,133] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.9, 94.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7271033453765205, 6.911199999999999, 6.9112, 121.9260426156618, 543218.0077763866, 543218.007776387, 148663.0233789782], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4131600.0000, 
sim time next is 4132200.0000, 
raw observation next is [20.8, 95.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7285957288691178, 6.9112, 6.9112, 121.9260426156618, 544351.9553416269, 544351.9553416269, 148777.7002073735], 
processed observation next is [1.0, 0.8260869565217391, 0.32592592592592595, 0.9533333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6607446610863973, 0.0, 0.0, 0.8094621288201359, 0.19441141262200962, 0.19441141262200962, 0.28611096193725677], 
reward next is 0.7139, 
noisyNet noise sample is [array([-1.5801241], dtype=float32), -0.6243539]. 
=============================================
[2019-03-24 08:56:36,596] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-24 08:56:36,601] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:56:36,603] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:56:36,605] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:56:36,607] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:56:36,608] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:56:36,607] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:56:36,610] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:56:36,608] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:56:36,612] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:56:36,612] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:56:36,637] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run99
[2019-03-24 08:56:36,668] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run99
[2019-03-24 08:56:36,669] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run99
[2019-03-24 08:56:36,670] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run99
[2019-03-24 08:56:36,695] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run99
[2019-03-24 08:56:42,926] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026590995]
[2019-03-24 08:56:42,929] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.364156865, 33.51146984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9047031100619553, 6.9112, 6.9112, 121.9260426156618, 653963.5622198203, 653963.5622198203, 154498.5717632947]
[2019-03-24 08:56:42,930] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:56:42,934] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.9181781e-28 2.7948812e-31 2.7625888e-27 1.7201738e-26], sampled 0.7715438156987113
[2019-03-24 08:56:47,821] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026590995]
[2019-03-24 08:56:47,826] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.86968478333333, 50.45466227166667, 1.0, 2.0, 0.8763249256883923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426138456, 1068202.434507559, 1068202.43450756, 215357.9042577792]
[2019-03-24 08:56:47,827] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:56:47,830] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 9.5260034e-21 9.2409085e-23 5.3383090e-20 1.9587899e-19], sampled 0.8062416665604446
[2019-03-24 08:56:47,832] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1068202.434507559 W.
[2019-03-24 08:56:57,374] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026590995]
[2019-03-24 08:56:57,374] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [29.33333333333333, 34.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5731818492818256, 6.9112, 6.9112, 121.9260426156618, 424865.7640416131, 424865.7640416131, 127492.0416263456]
[2019-03-24 08:56:57,376] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:56:57,379] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 9.6554930e-33 5.2026437e-36 2.1124734e-31 1.7959071e-30], sampled 0.0718950456425359
[2019-03-24 08:57:00,136] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026590995]
[2019-03-24 08:57:00,137] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [18.98333333333333, 82.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6063269537041386, 6.9112, 6.9112, 121.9260426156618, 442165.939018779, 442165.939018779, 126922.8904854066]
[2019-03-24 08:57:00,137] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:57:00,140] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.000000e+00 4.044463e-33 1.990310e-36 9.143072e-32 7.741150e-31], sampled 0.23134211991003917
[2019-03-24 08:57:04,035] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026590995]
[2019-03-24 08:57:04,036] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [18.47044091, 86.84878033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5081713060264457, 6.9112, 6.9112, 121.9260426156618, 369467.3712031979, 369467.3712031979, 118143.6108642831]
[2019-03-24 08:57:04,037] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:57:04,040] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 3.3377402e-33 1.6285262e-36 7.6065211e-32 6.4545153e-31], sampled 0.4168910520563732
[2019-03-24 08:57:15,409] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026590995]
[2019-03-24 08:57:15,410] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [25.66666666666667, 87.33333333333333, 1.0, 2.0, 0.6565376815850593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 748243.0523033865, 748243.052303386, 168077.2728401512]
[2019-03-24 08:57:15,411] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 08:57:15,414] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.00000000e+00 2.36062839e-24 7.46915461e-27 2.01999336e-23
 1.01328275e-22], sampled 0.1723044437194341
[2019-03-24 08:57:15,415] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 748243.0523033865 W.
[2019-03-24 08:57:16,688] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026590995]
[2019-03-24 08:57:16,690] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.66666666666667, 63.33333333333334, 1.0, 2.0, 0.6265627970884519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 714065.3559536244, 714065.3559536244, 162707.4165982682]
[2019-03-24 08:57:16,691] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:57:16,693] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.000000e+00 8.075417e-24 3.008824e-26 6.696547e-23 3.005400e-22], sampled 0.2797996480388748
[2019-03-24 08:57:16,694] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 714065.3559536244 W.
[2019-03-24 08:57:20,628] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026590995]
[2019-03-24 08:57:20,630] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.65, 93.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.735421541504883, 6.9112, 6.9112, 121.9260426156618, 548192.0471620238, 548192.0471620238, 151264.3855978074]
[2019-03-24 08:57:20,631] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 08:57:20,634] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 3.5005683e-31 2.7689513e-34 6.5272895e-30 4.8923547e-29], sampled 0.6403656242643785
[2019-03-24 08:57:44,004] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026590995]
[2019-03-24 08:57:44,005] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [21.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7117655594010612, 6.911200000000001, 6.9112, 121.9260426156618, 531741.7327381112, 531741.7327381107, 146973.6311644469]
[2019-03-24 08:57:44,006] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 08:57:44,009] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 1.7455982e-32 1.0101306e-35 3.7606940e-31 3.0875341e-30], sampled 0.032349581685654605
[2019-03-24 08:57:46,214] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026590995]
[2019-03-24 08:57:46,214] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [27.47253515333333, 91.66945114166667, 1.0, 2.0, 0.7790746765854483, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 887976.9466546287, 887976.9466546283, 191662.2281631083]
[2019-03-24 08:57:46,216] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 08:57:46,219] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.0536071e-22 5.2027319e-25 7.6399439e-22 3.1937585e-21], sampled 0.013199624586989644
[2019-03-24 08:57:46,220] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 887976.9466546287 W.
[2019-03-24 08:58:19,993] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 08:58:20,005] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 08:58:20,035] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 08:58:20,048] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 08:58:20,123] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 08:58:21,140] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 2450000, evaluation results [2450000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 08:58:24,155] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 3.8483286e-34 6.1222664e-36 5.3970367e-34 2.2550878e-33], sum to 1.0000
[2019-03-24 08:58:24,160] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7241
[2019-03-24 08:58:24,167] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8023834337983048, 6.9112, 6.9112, 121.9260426156618, 596799.5503907937, 596799.5503907937, 160191.62171598], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4408200.0000, 
sim time next is 4408800.0000, 
raw observation next is [22.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8024640515354126, 6.9112, 6.9112, 121.9260426156618, 596859.4299680429, 596859.4299680429, 160201.6892821571], 
processed observation next is [0.0, 0.0, 0.37037037037037035, 0.94, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7530800644192656, 0.0, 0.0, 0.8094621288201359, 0.2131640821314439, 0.2131640821314439, 0.30808017169645596], 
reward next is 0.6919, 
noisyNet noise sample is [array([-0.46024466], dtype=float32), 1.5811721]. 
=============================================
[2019-03-24 08:58:29,544] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 3.4266527e-35 0.0000000e+00 5.2703829e-35 9.4143543e-33], sum to 1.0000
[2019-03-24 08:58:29,553] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1035
[2019-03-24 08:58:29,560] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.31666666666667, 99.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8009673314466034, 6.911200000000001, 6.9112, 121.9260426156618, 595537.9283003111, 595537.9283003106, 160133.6173379797], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4578600.0000, 
sim time next is 4579200.0000, 
raw observation next is [21.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.785631186009043, 6.9112, 6.9112, 121.9260426156618, 585090.7789500315, 585090.7789500315, 157646.2218834291], 
processed observation next is [1.0, 0.0, 0.3333333333333333, 1.0, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7320389825113038, 0.0, 0.0, 0.8094621288201359, 0.2089609924821541, 0.2089609924821541, 0.3031658113142867], 
reward next is 0.6968, 
noisyNet noise sample is [array([-0.5840865], dtype=float32), -1.1445568]. 
=============================================
[2019-03-24 08:58:36,518] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 6.6904564e-27 3.7414785e-30 2.2710941e-25 3.5405307e-26], sum to 1.0000
[2019-03-24 08:58:36,528] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0836
[2019-03-24 08:58:36,533] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 922936.7457749209 W.
[2019-03-24 08:58:36,586] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 75.66666666666666, 1.0, 2.0, 0.2699095344154994, 1.0, 2.0, 0.2699095344154994, 1.0, 2.0, 0.4297047691293253, 6.9112, 6.9112, 121.94756008, 922936.7457749209, 922936.7457749209, 244795.8534107243], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5057400.0000, 
sim time next is 5058000.0000, 
raw observation next is [30.0, 75.0, 1.0, 2.0, 0.804475229426833, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 916945.4130567843, 916945.4130567843, 196873.6130922464], 
processed observation next is [0.0, 0.5652173913043478, 0.6666666666666666, 0.75, 1.0, 1.0, 0.767232415984325, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.3274805046631373, 0.3274805046631373, 0.3786031021004739], 
reward next is 0.6214, 
noisyNet noise sample is [array([0.17802128], dtype=float32), -1.6463072]. 
=============================================
[2019-03-24 08:58:36,613] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[41.421745]
 [41.144966]
 [41.3023  ]
 [40.477257]
 [40.55674 ]], R is [[40.6473999 ]
 [40.77016449]
 [40.89054489]
 [41.0799942 ]
 [41.2682457 ]].
[2019-03-24 08:58:52,115] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 4.6293077e-27 5.7435305e-29 1.7838683e-24 1.9179039e-24], sum to 1.0000
[2019-03-24 08:58:52,121] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3328
[2019-03-24 08:58:52,130] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 906699.4330010765 W.
[2019-03-24 08:58:52,134] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.58333333333333, 89.0, 1.0, 2.0, 0.2651637975372632, 1.0, 1.0, 0.2651637975372632, 1.0, 1.0, 0.4221494014613135, 6.911200000000001, 6.9112, 121.94756008, 906699.4330010765, 906699.433001076, 243066.5922135015], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4921800.0000, 
sim time next is 4922400.0000, 
raw observation next is [27.46666666666667, 88.0, 1.0, 2.0, 0.3903262795689923, 0.0, 1.0, 0.0, 1.0, 2.0, 0.6214121491132877, 6.9112, 6.9112, 121.9260426156618, 889776.4361300183, 889776.4361300183, 221138.9760235109], 
processed observation next is [1.0, 1.0, 0.5728395061728396, 0.88, 1.0, 1.0, 0.27419795186784796, 0.0, 0.5, -0.1904761904761905, 1.0, 1.0, 0.5267651863916095, 0.0, 0.0, 0.8094621288201359, 0.3177772986178637, 0.3177772986178637, 0.42526726158367484], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7692863], dtype=float32), -0.022671644]. 
=============================================
[2019-03-24 08:58:52,668] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.1737527e-22 1.9828943e-25 1.0442963e-21 1.0906088e-20], sum to 1.0000
[2019-03-24 08:58:52,675] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1246
[2019-03-24 08:58:52,682] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 986893.2463058467 W.
[2019-03-24 08:58:52,687] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.2, 85.0, 1.0, 2.0, 0.2886013493549255, 1.0, 1.0, 0.2886013493549255, 1.0, 2.0, 0.4594627472628053, 6.911199999999999, 6.9112, 121.94756008, 986893.2463058467, 986893.2463058472, 251729.018877443], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5134800.0000, 
sim time next is 5135400.0000, 
raw observation next is [29.3, 83.0, 1.0, 2.0, 0.8620947676362649, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 982662.5958701833, 982662.5958701833, 209113.9461293016], 
processed observation next is [0.0, 0.43478260869565216, 0.6407407407407407, 0.83, 1.0, 1.0, 0.8358271043288868, 0.0, 0.5, -0.1904761904761905, 0.0, 0.5, -0.25, 0.0, 0.0, 0.8094621288201359, 0.35095092709649406, 0.35095092709649406, 0.4021422040948108], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.6472051], dtype=float32), -0.12990658]. 
=============================================
[2019-03-24 08:58:53,204] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.3599335e-19 6.0979296e-22 6.1699846e-19 3.3444188e-18], sum to 1.0000
[2019-03-24 08:58:53,210] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8673
[2019-03-24 08:58:53,215] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 924178.6115872455 W.
[2019-03-24 08:58:53,220] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.4, 82.0, 1.0, 2.0, 0.7995245614985698, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 924178.6115872455, 924178.611587245, 196504.4969395855], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4935600.0000, 
sim time next is 4936200.0000, 
raw observation next is [25.16666666666667, 83.16666666666667, 1.0, 2.0, 0.4920200824444865, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7836870134693846, 6.911199999999999, 6.9112, 121.9260426156618, 1129642.077666019, 1129642.07766602, 254083.9839061626], 
processed observation next is [1.0, 0.13043478260869565, 0.4876543209876545, 0.8316666666666667, 1.0, 1.0, 0.39526200291010294, 0.0, 1.0, -0.1904761904761905, 1.0, 0.5, 0.7296087668367307, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.4034435991664354, 0.40344359916643574, 0.4886230459733896], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.58513343], dtype=float32), -1.003403]. 
=============================================
[2019-03-24 08:58:54,272] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 6.1664958e-21 6.7311986e-23 7.8020532e-21 7.7679089e-19], sum to 1.0000
[2019-03-24 08:58:54,279] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4688
[2019-03-24 08:58:54,285] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1328675.86458696 W.
[2019-03-24 08:58:54,294] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.0, 83.0, 1.0, 2.0, 0.5808634275689177, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9249101116622214, 6.911199999999999, 6.9112, 121.9260426156618, 1328675.86458696, 1328675.86458696, 286433.3163645287], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4959600.0000, 
sim time next is 4960200.0000, 
raw observation next is [25.0, 83.0, 1.0, 2.0, 0.3828047205207744, 1.0, 1.0, 0.3828047205207744, 1.0, 2.0, 0.6094375821484481, 6.9112, 6.9112, 121.94756008, 1309303.719573941, 1309303.719573941, 289631.6035284076], 
processed observation next is [1.0, 0.391304347826087, 0.48148148148148145, 0.83, 1.0, 1.0, 0.2652437149056838, 1.0, 0.5, 0.2652437149056838, 1.0, 1.0, 0.5117969776855601, 0.0, 0.0, 0.8096049824067558, 0.46760847127640753, 0.46760847127640753, 0.5569838529392453], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6489875], dtype=float32), -1.672593]. 
=============================================
[2019-03-24 08:59:05,033] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 1.5192981e-20 9.2658688e-22 2.1844713e-19 3.0570796e-19], sum to 1.0000
[2019-03-24 08:59:05,041] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6349
[2019-03-24 08:59:05,050] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1787054.547673699 W.
[2019-03-24 08:59:05,063] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.41666666666667, 66.16666666666667, 1.0, 2.0, 0.5223332457277952, 1.0, 1.0, 0.5223332457277952, 1.0, 2.0, 0.8315715384048491, 6.911200000000001, 6.9112, 121.94756008, 1787054.547673699, 1787054.547673699, 354685.6755172008], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5328600.0000, 
sim time next is 5329200.0000, 
raw observation next is [28.43333333333333, 66.33333333333334, 1.0, 2.0, 0.5324332747267891, 1.0, 2.0, 0.5324332747267891, 1.0, 2.0, 0.8476511135062279, 6.911199999999999, 6.9112, 121.94756008, 1821644.925732668, 1821644.925732669, 359792.7555637581], 
processed observation next is [1.0, 0.6956521739130435, 0.6086419753086418, 0.6633333333333334, 1.0, 1.0, 0.4433729461033204, 1.0, 1.0, 0.4433729461033204, 1.0, 1.0, 0.8095638918827849, -8.881784197001253e-17, 0.0, 0.8096049824067558, 0.6505874734759529, 0.6505874734759532, 0.6919091453149194], 
reward next is 0.3081, 
noisyNet noise sample is [array([-0.45731878], dtype=float32), -0.37235838]. 
=============================================
[2019-03-24 08:59:11,009] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-24 08:59:11,013] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 08:59:11,016] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:59:11,017] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 08:59:11,018] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:59:11,018] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 08:59:11,020] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 08:59:11,021] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 08:59:11,020] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:59:11,022] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:59:11,022] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 08:59:11,046] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run100
[2019-03-24 08:59:11,071] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run100
[2019-03-24 08:59:11,099] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run100
[2019-03-24 08:59:11,100] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run100
[2019-03-24 08:59:11,164] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run100
[2019-03-24 08:59:41,965] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026910286]
[2019-03-24 08:59:41,967] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [24.54806444666667, 85.96046698, 1.0, 2.0, 0.5677482355633553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 659012.9110726289, 659012.9110726289, 153189.6663243478]
[2019-03-24 08:59:41,968] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:59:41,972] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 1.5763555e-24 8.5782715e-27 1.5788778e-23 1.0825912e-22], sampled 0.7469748081198819
[2019-03-24 08:59:54,840] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026910286]
[2019-03-24 08:59:54,841] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.68942706666667, 47.72875705000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9528303190667575, 6.911200000000001, 6.9112, 121.9260426156618, 684932.39403145, 684932.3940314496, 158342.1005281389]
[2019-03-24 08:59:54,842] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 08:59:54,846] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 8.9450860e-31 1.2290857e-33 1.8731209e-29 2.0685853e-28], sampled 0.6097331108144184
[2019-03-24 09:00:06,563] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026910286]
[2019-03-24 09:00:06,563] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [29.2, 76.66666666666667, 1.0, 2.0, 0.7494074916710893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 854143.917762706, 854143.917762706, 185713.4197760111]
[2019-03-24 09:00:06,564] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 09:00:06,568] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 3.7082210e-27 9.3707641e-30 4.6674875e-26 4.0025782e-25], sampled 0.9886597586028941
[2019-03-24 09:00:06,569] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 854143.917762706 W.
[2019-03-24 09:00:11,808] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026910286]
[2019-03-24 09:00:11,809] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [24.78333333333333, 78.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8637353686979418, 6.911200000000001, 6.9112, 121.9260426156618, 638057.4717540786, 638057.4717540783, 169669.1179245442]
[2019-03-24 09:00:11,810] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 09:00:11,813] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 4.4071032e-33 3.3128095e-36 1.1141723e-31 1.5031146e-30], sampled 0.5906586975640009
[2019-03-24 09:00:18,652] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026910286]
[2019-03-24 09:00:18,653] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [31.4, 78.0, 1.0, 2.0, 0.9281665963645854, 1.0, 2.0, 0.7774479601587273, 1.0, 2.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.94756008, 2661177.055580489, 2661177.055580489, 496179.7593325124]
[2019-03-24 09:00:18,653] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 09:00:18,656] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 6.5339897e-23 3.6903875e-25 4.4363255e-22 2.5878844e-21], sampled 0.8334223488888417
[2019-03-24 09:00:18,656] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 0, 0, 1] for the demand 2661177.055580489 W.
[2019-03-24 09:00:27,386] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.026910286]
[2019-03-24 09:00:27,387] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [36.0, 44.0, 1.0, 2.0, 0.8316547754211215, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9977734948820727, 6.911199999999997, 6.9112, 121.9260426156618, 1663070.933641438, 1663070.93364144, 342611.8368519451]
[2019-03-24 09:00:27,387] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 09:00:27,389] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 4.3264466e-26 1.2854186e-28 4.3973473e-25 3.2777082e-24], sampled 0.7225806149868893
[2019-03-24 09:00:27,390] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1663070.933641438 W.
[2019-03-24 09:00:53,734] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 09:00:54,095] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 09:00:54,098] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 09:00:54,134] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 09:00:54,251] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 09:00:55,268] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 2475000, evaluation results [2475000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
[2019-03-24 09:00:57,102] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 5.0287466e-20 7.1237339e-23 7.0670708e-19 3.8514274e-19], sum to 1.0000
[2019-03-24 09:00:57,111] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5568
[2019-03-24 09:00:57,117] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1212870.334617706 W.
[2019-03-24 09:00:57,119] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.63333333333334, 85.66666666666667, 1.0, 2.0, 0.3504377824974572, 1.0, 2.0, 0.3504377824974572, 1.0, 1.0, 0.558491090186878, 6.911200000000003, 6.9112, 121.94756008, 1212870.334617706, 1212870.334617705, 276105.1412863202], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5305800.0000, 
sim time next is 5306400.0000, 
raw observation next is [23.8, 85.0, 1.0, 2.0, 0.3375892611956233, 1.0, 2.0, 0.3375892611956233, 1.0, 2.0, 0.5377980530766415, 6.9112, 6.9112, 121.94756008, 1164508.663691882, 1164508.663691882, 270866.5146225198], 
processed observation next is [1.0, 0.43478260869565216, 0.43703703703703706, 0.85, 1.0, 1.0, 0.21141578713764683, 1.0, 1.0, 0.21141578713764683, 1.0, 1.0, 0.42224756634580185, 0.0, 0.0, 0.8096049824067558, 0.4158959513185293, 0.4158959513185293, 0.5208971435048457], 
reward next is 0.4791, 
noisyNet noise sample is [array([2.3620596], dtype=float32), 1.2279699]. 
=============================================
[2019-03-24 09:00:59,870] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.6243031e-26 9.7803236e-30 1.3634661e-26 3.9333603e-25], sum to 1.0000
[2019-03-24 09:00:59,875] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3897
[2019-03-24 09:00:59,880] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 874956.2254443313 W.
[2019-03-24 09:00:59,884] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.33333333333333, 89.16666666666667, 1.0, 2.0, 0.383828672655006, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6110677472939378, 6.911199999999999, 6.9112, 121.9260426156618, 874956.2254443313, 874956.2254443318, 219167.6578710566], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5440200.0000, 
sim time next is 5440800.0000, 
raw observation next is [27.26666666666667, 89.33333333333334, 1.0, 2.0, 0.3822868456351989, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6086131084646044, 6.911199999999999, 6.9112, 121.9260426156618, 871439.5571967582, 871439.5571967587, 218702.2188020641], 
processed observation next is [1.0, 1.0, 0.5654320987654322, 0.8933333333333334, 1.0, 1.0, 0.2646271971847606, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5107663855807554, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3112284132845565, 0.3112284132845567, 0.42058119000396943], 
reward next is 0.5794, 
noisyNet noise sample is [array([0.19341287], dtype=float32), 0.27098155]. 
=============================================
[2019-03-24 09:01:00,535] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 8.1465699e-19 1.4645042e-20 4.6317846e-18 1.9457220e-17], sum to 1.0000
[2019-03-24 09:01:00,542] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0061
[2019-03-24 09:01:00,548] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 814344.5942203723 W.
[2019-03-24 09:01:00,553] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.9, 91.0, 1.0, 2.0, 0.2381690098278812, 1.0, 2.0, 0.2381690098278812, 1.0, 2.0, 0.3791728202691189, 6.911199999999999, 6.9112, 121.94756008, 814344.5942203723, 814344.5942203726, 233469.385303259], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5385600.0000, 
sim time next is 5386200.0000, 
raw observation next is [25.06666666666667, 90.16666666666667, 1.0, 2.0, 0.3821432135464123, 1.0, 2.0, 0.3821432135464123, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 871111.9555055938, 871111.9555055943, 201340.7730441926], 
processed observation next is [1.0, 0.34782608695652173, 0.4839506172839507, 0.9016666666666667, 1.0, 1.0, 0.2644562066028718, 1.0, 1.0, 0.2644562066028718, 0.0, 0.5, -0.25, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.3111114126805692, 0.31111141268056935, 0.387193794315755], 
reward next is 0.6128, 
noisyNet noise sample is [array([-0.61388046], dtype=float32), -0.15404129]. 
=============================================
[2019-03-24 09:01:04,083] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 5.9437937e-32 7.8165724e-33 1.9698099e-29 7.9577014e-27], sum to 1.0000
[2019-03-24 09:01:04,089] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0322
[2019-03-24 09:01:04,097] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 892708.1796857441 W.
[2019-03-24 09:01:04,101] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.3, 84.0, 1.0, 2.0, 0.7832232508755265, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 892708.1796857441, 892708.1796857441, 192504.0999622808], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5432400.0000, 
sim time next is 5433000.0000, 
raw observation next is [28.23333333333333, 84.33333333333333, 1.0, 2.0, 0.2613474797855008, 1.0, 1.0, 0.2613474797855008, 1.0, 1.0, 0.4160736993117156, 6.9112, 6.9112, 121.94756008, 893642.3330277256, 893642.3330277256, 241685.1134972801], 
processed observation next is [1.0, 0.9130434782608695, 0.6012345679012344, 0.8433333333333333, 1.0, 1.0, 0.12065176164940575, 1.0, 0.5, 0.12065176164940575, 1.0, 0.5, 0.2700921241396445, 0.0, 0.0, 0.8096049824067558, 0.31915797608133056, 0.31915797608133056, 0.4647790644178464], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9174551], dtype=float32), 1.3684051]. 
=============================================
[2019-03-24 09:01:04,115] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[49.950893]
 [49.560513]
 [49.438046]
 [48.705418]
 [48.97129 ]], R is [[48.79171753]
 [48.30380249]
 [47.82076645]
 [47.34255981]
 [47.4791832 ]].
[2019-03-24 09:01:08,825] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 3.5612045e-24 1.6400313e-25 3.2593456e-22 2.0156992e-22], sum to 1.0000
[2019-03-24 09:01:08,832] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5909
[2019-03-24 09:01:08,838] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 726409.6389955473 W.
[2019-03-24 09:01:08,841] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.3, 91.0, 1.0, 2.0, 0.3186946324287731, 0.0, 2.0, 0.0, 1.0, 1.0, 0.507372233986178, 6.911199999999999, 6.9112, 121.9260426156618, 726409.6389955473, 726409.6389955478, 200336.9750700833], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5594400.0000, 
sim time next is 5595000.0000, 
raw observation next is [25.33333333333334, 91.16666666666667, 1.0, 2.0, 0.6454295258560693, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 735577.2319975476, 735577.2319975471, 166069.953438202], 
processed observation next is [1.0, 0.782608695652174, 0.49382716049382736, 0.9116666666666667, 1.0, 1.0, 0.5778922926857968, 0.0, 1.0, -0.1904761904761905, 0.0, 0.5, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2627061542848384, 0.26270615428483823, 0.3193652950734654], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0302017], dtype=float32), 0.46675983]. 
=============================================
[2019-03-24 09:01:08,856] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[36.15736 ]
 [35.801258]
 [36.71005 ]
 [36.556236]
 [36.359573]], R is [[36.31830978]
 [35.95512772]
 [35.59557724]
 [35.23962021]
 [35.51120758]].
[2019-03-24 09:01:10,923] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 9.7734963e-23 4.9085534e-25 2.6004114e-22 2.5334789e-20], sum to 1.0000
[2019-03-24 09:01:10,930] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5681
[2019-03-24 09:01:10,936] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1581517.151966297 W.
[2019-03-24 09:01:10,946] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.6, 78.33333333333334, 1.0, 2.0, 0.693465518380481, 1.0, 2.0, 0.693465518380481, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 121.9260426156618, 1581517.151966297, 1581517.151966298, 301699.080407291], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5571600.0000, 
sim time next is 5572200.0000, 
raw observation next is [27.8, 78.16666666666666, 1.0, 2.0, 0.7534495840591764, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9977734948820727, 6.911199999999999, 6.9112, 121.9260426156618, 1573809.788397176, 1573809.788397177, 327172.0301853474], 
processed observation next is [1.0, 0.4782608695652174, 0.5851851851851853, 0.7816666666666666, 1.0, 1.0, 0.7064876000704481, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9972168686025908, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.5620749244275628, 0.5620749244275631, 0.6291769811256681], 
reward next is 0.3708, 
noisyNet noise sample is [array([0.88347065], dtype=float32), 0.010574133]. 
=============================================
[2019-03-24 09:01:11,507] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.9659453e-20 9.5315965e-22 2.5997395e-20 9.6146170e-19], sum to 1.0000
[2019-03-24 09:01:11,512] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4132
[2019-03-24 09:01:11,522] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 824988.747273251 W.
[2019-03-24 09:01:11,526] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.4, 85.33333333333334, 1.0, 2.0, 0.361920566113993, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5761893281834267, 6.911199999999999, 6.9112, 121.9260426156618, 824988.747273251, 824988.7472732514, 212638.5694076219], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5557800.0000, 
sim time next is 5558400.0000, 
raw observation next is [25.4, 85.0, 1.0, 2.0, 0.343770963753197, 0.0, 2.0, 0.0, 1.0, 2.0, 0.547294570133757, 6.911199999999999, 6.9112, 121.9260426156618, 783596.0413554864, 783596.0413554868, 207381.1438095696], 
processed observation next is [1.0, 0.34782608695652173, 0.49629629629629624, 0.85, 1.0, 1.0, 0.21877495684904405, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.43411821266719625, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.27985572905553086, 0.279855729055531, 0.39880989194148], 
reward next is 0.6012, 
noisyNet noise sample is [array([0.9238693], dtype=float32), 0.6451913]. 
=============================================
[2019-03-24 09:01:15,794] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.00000000e+00 2.54745131e-29 1.41710715e-30 1.45828873e-27
 1.00754476e-27], sum to 1.0000
[2019-03-24 09:01:15,803] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3012
[2019-03-24 09:01:15,810] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 793320.2116158738 W.
[2019-03-24 09:01:15,813] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.51666666666667, 81.50000000000001, 1.0, 2.0, 0.6960696845412785, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260426156618, 793320.2116158738, 793320.2116158738, 175402.3889117066], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5656200.0000, 
sim time next is 5656800.0000, 
raw observation next is [27.63333333333334, 81.0, 1.0, 2.0, 0.6978954209067226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 795402.1081714514, 795402.1081714509, 175747.2557238282], 
processed observation next is [0.0, 0.4782608695652174, 0.5790123456790126, 0.81, 1.0, 1.0, 0.6403516915556222, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.25, 8.881784197001253e-17, 0.0, 0.8094621288201359, 0.28407218148980407, 0.2840721814898039, 0.3379754917765927], 
reward next is 0.6620, 
noisyNet noise sample is [array([0.42494705], dtype=float32), 1.637796]. 
=============================================
[2019-03-24 09:01:17,299] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 5.3243240e-25 5.4067822e-27 2.8421021e-23 1.5421855e-23], sum to 1.0000
[2019-03-24 09:01:17,308] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7845
[2019-03-24 09:01:17,322] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1054797.216942762 W.
[2019-03-24 09:01:17,330] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.85, 67.0, 1.0, 2.0, 0.8565144735312384, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 121.9260426156618, 1054797.216942762, 1054797.216942762, 211276.5185191635], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5908200.0000, 
sim time next is 5908800.0000, 
raw observation next is [24.1, 66.0, 1.0, 2.0, 0.317280101979547, 1.0, 1.0, 0.317280101979547, 1.0, 1.0, 0.5139071341496299, 6.9112, 6.9112, 121.94756008, 1148376.255548948, 1148376.255548948, 262019.0849134737], 
processed observation next is [1.0, 0.391304347826087, 0.4481481481481482, 0.66, 1.0, 1.0, 0.18723821664231782, 1.0, 0.5, 0.18723821664231782, 1.0, 0.5, 0.3923839176870373, 0.0, 0.0, 0.8096049824067558, 0.41013437698176713, 0.41013437698176713, 0.5038828556028341], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.64480585], dtype=float32), -0.94181067]. 
=============================================
[2019-03-24 09:01:24,858] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 2.1713031e-34 4.9798313e-38 1.7016713e-33 7.6603078e-31], sum to 1.0000
[2019-03-24 09:01:24,865] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7593
[2019-03-24 09:01:24,874] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.1, 84.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6059522870234145, 6.9112, 6.9112, 121.9260426156618, 449506.6802670975, 449506.6802670975, 130763.0364720993], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5881800.0000, 
sim time next is 5882400.0000, 
raw observation next is [20.0, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6037885376042476, 6.911199999999999, 6.9112, 121.9260426156618, 447672.2012988198, 447672.2012988203, 130404.9410512376], 
processed observation next is [1.0, 0.08695652173913043, 0.2962962962962963, 0.85, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.5047356720053094, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.15988292903529278, 0.15988292903529297, 0.25077873279084156], 
reward next is 0.7492, 
noisyNet noise sample is [array([-0.893505], dtype=float32), 0.782946]. 
=============================================
[2019-03-24 09:01:24,982] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 09:01:24,990] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2152
[2019-03-24 09:01:24,996] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.81666666666666, 77.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8306518416507949, 6.9112, 6.9112, 121.9260426156618, 614851.3761995302, 614851.3761995302, 165062.4927183819], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6043800.0000, 
sim time next is 6044400.0000, 
raw observation next is [24.7, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8282293564352019, 6.9112, 6.9112, 121.9260426156618, 613157.5309905872, 613157.5309905872, 164724.5386300599], 
processed observation next is [1.0, 1.0, 0.4703703703703703, 0.78, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.7852866955440024, 0.0, 0.0, 0.8094621288201359, 0.21898483249663828, 0.21898483249663828, 0.3167779589039613], 
reward next is 0.6832, 
noisyNet noise sample is [array([-1.2003729], dtype=float32), 0.45319924]. 
=============================================
[2019-03-24 09:01:31,214] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.9428675e-31 1.0584994e-34 3.2341284e-30 1.5831007e-29], sum to 1.0000
[2019-03-24 09:01:31,222] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4515
[2019-03-24 09:01:31,228] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.58333333333333, 81.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6906281190749437, 6.911200000000001, 6.9112, 121.9260426156618, 515608.3905253241, 515608.3905253236, 142178.9421344058], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5982600.0000, 
sim time next is 5983200.0000, 
raw observation next is [21.7, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.684606207604965, 6.9112, 6.9112, 121.9260426156618, 511118.7475398093, 511118.7475398093, 141553.000573642], 
processed observation next is [1.0, 0.2608695652173913, 0.3592592592592592, 0.81, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.6057577595062063, 0.0, 0.0, 0.8094621288201359, 0.18254240983564618, 0.18254240983564618, 0.2722173087954654], 
reward next is 0.7278, 
noisyNet noise sample is [array([-0.8367628], dtype=float32), -0.94007957]. 
=============================================
[2019-03-24 09:01:37,134] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.1751257e-26 2.2528592e-27 1.4990079e-24 1.1627751e-24], sum to 1.0000
[2019-03-24 09:01:37,141] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2200
[2019-03-24 09:01:37,148] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1617059.485097183 W.
[2019-03-24 09:01:37,152] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.56666666666667, 60.66666666666667, 1.0, 2.0, 0.7090360570095928, 1.0, 1.0, 0.7090360570095928, 0.0, 1.0, 0.0, 6.9112, 6.9112, 121.9260425076538, 1617059.485097183, 1617059.485097183, 307598.6710331672], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6079200.0000, 
sim time next is 6079800.0000, 
raw observation next is [29.58333333333334, 55.83333333333333, 1.0, 2.0, 0.8446094256007133, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9943713319815398, 6.9112, 6.9112, 121.9260426156289, 1681350.468872617, 1681350.468872617, 344742.2195652169], 
processed observation next is [1.0, 0.34782608695652173, 0.6512345679012348, 0.5583333333333332, 1.0, 1.0, 0.8150112209532301, 0.0, 0.5, -0.1904761904761905, 1.0, 0.5, 0.9929641649769246, 0.0, 0.0, 0.8094621288199175, 0.6004823103116489, 0.6004823103116489, 0.6629658068561863], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6518085], dtype=float32), -0.2569105]. 
=============================================
[2019-03-24 09:01:37,163] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 4.4463948e-27 6.0031198e-28 4.9302658e-25 3.8206567e-25], sum to 1.0000
[2019-03-24 09:01:37,173] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7035
[2019-03-24 09:01:37,179] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1681350.468872617 W.
[2019-03-24 09:01:37,187] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.58333333333334, 55.83333333333333, 1.0, 2.0, 0.8446094256007133, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9943713319815398, 6.9112, 6.9112, 121.9260426156289, 1681350.468872617, 1681350.468872617, 344742.2195652169], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6079800.0000, 
sim time next is 6080400.0000, 
raw observation next is [30.6, 51.0, 1.0, 2.0, 0.4948857337267265, 1.0, 1.0, 0.4948857337267265, 1.0, 2.0, 0.7878742053960885, 6.9112, 6.9112, 121.94756008, 1693059.619901203, 1693059.619901203, 341085.9795232847], 
processed observation next is [1.0, 0.391304347826087, 0.688888888888889, 0.51, 1.0, 1.0, 0.3986734925318173, 1.0, 0.5, 0.3986734925318173, 1.0, 1.0, 0.7348427567451107, 0.0, 0.0, 0.8096049824067558, 0.6046641499647154, 0.6046641499647154, 0.6559345760063168], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6518085], dtype=float32), -0.2569105]. 
=============================================
[2019-03-24 09:01:37,377] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 6.4943167e-27 5.9582437e-28 5.7672727e-26 7.3681053e-25], sum to 1.0000
[2019-03-24 09:01:37,387] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9287
[2019-03-24 09:01:37,389] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.93333333333333, 90.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.908533903127219, 6.9112, 6.9112, 121.9260426156618, 671889.8097120954, 671889.8097120954, 175234.1686343958], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6147600.0000, 
sim time next is 6148200.0000, 
raw observation next is [22.86666666666667, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8998458896283733, 6.911199999999999, 6.9112, 121.9260426156618, 667076.1791723769, 667076.1791723773, 173479.4477264856], 
processed observation next is [1.0, 0.13043478260869565, 0.4024691358024693, 0.9, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8748073620354665, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.23824149256156316, 0.23824149256156332, 0.3336143225509339], 
reward next is 0.6664, 
noisyNet noise sample is [array([0.5537386], dtype=float32), 0.15997195]. 
=============================================
[2019-03-24 09:01:40,422] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1. 0. 0. 0. 0.], sum to 1.0000
[2019-03-24 09:01:40,431] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0662
[2019-03-24 09:01:40,433] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.25, 62.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8882263089829043, 6.911199999999999, 6.9112, 121.9260426156618, 650476.0634750358, 650476.0634750363, 174298.337378682], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6204600.0000, 
sim time next is 6205200.0000, 
raw observation next is [28.13333333333333, 63.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8937849823131383, 6.911199999999999, 6.9112, 121.9260426156618, 654196.3681895522, 654196.3681895526, 175104.5833877102], 
processed observation next is [1.0, 0.8260869565217391, 0.5975308641975308, 0.6333333333333333, 0.0, 1.0, -0.1904761904761905, 0.0, 1.0, -0.1904761904761905, 1.0, 1.0, 0.8672312278914229, -8.881784197001253e-17, 0.0, 0.8094621288201359, 0.2336415600676972, 0.23364156006769735, 0.3367395834379043], 
reward next is 0.6633, 
noisyNet noise sample is [array([-0.7381186], dtype=float32), 1.1015613]. 
=============================================
[2019-03-24 09:01:45,096] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-24 09:01:45,096] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation job starts!
[2019-03-24 09:01:45,097] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation job starts!
[2019-03-24 09:01:45,097] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:01:45,097] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:01:45,098] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation job starts!
[2019-03-24 09:01:45,099] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation job starts!
[2019-03-24 09:01:45,100] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:01:45,101] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation job starts!
[2019-03-24 09:01:45,102] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:01:45,102] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-24 09:01:45,122] EPLUS_ENV_Part3-NA-Bej-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v4-res1/Eplus-env-sub_run101
[2019-03-24 09:01:45,151] EPLUS_ENV_Part3-NA-Bej-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v3-res1/Eplus-env-sub_run101
[2019-03-24 09:01:45,176] EPLUS_ENV_Part3-NA-Bej-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v2-res1/Eplus-env-sub_run101
[2019-03-24 09:01:45,178] EPLUS_ENV_Part3-NA-Bej-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Train-v1-res1/Eplus-env-sub_run101
[2019-03-24 09:01:45,202] EPLUS_ENV_Part3-NA-Bej-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_bej_na/41/Eplus-env-Part3-NA-Bej-Test-v1-res1/Eplus-env-sub_run101
[2019-03-24 09:01:54,306] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.027223699]
[2019-03-24 09:01:54,308] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [17.0, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5884447419635211, 6.9112, 6.9112, 121.9260426156618, 420172.5439037769, 420172.5439037769, 119652.5097802748]
[2019-03-24 09:01:54,310] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 09:01:54,312] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 2.4150910e-37 0.0000000e+00 1.0467857e-35 1.7331358e-34], sampled 0.11664921413631024
[2019-03-24 09:02:11,516] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.027223699]
[2019-03-24 09:02:11,517] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation this: [24.95611284666667, 68.15823797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6990299987130114, 6.9112, 6.9112, 121.9260426156618, 522121.9364866898, 522121.9364866898, 145795.8919387302]
[2019-03-24 09:02:11,519] A3C_EVAL-Part3-NA-Bej-Test-v4 DEBUG:Observation forecast: []
[2019-03-24 09:02:11,522] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Softmax [1.0000000e+00 1.8516379e-36 0.0000000e+00 7.7221404e-35 1.2882182e-33], sampled 0.9717479591995307
[2019-03-24 09:02:17,268] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.027223699]
[2019-03-24 09:02:17,269] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation this: [21.45, 80.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6089314080569007, 6.9112, 6.9112, 121.9260426156618, 453940.3941155483, 453940.3941155483, 132909.1620044761]
[2019-03-24 09:02:17,270] A3C_EVAL-Part3-NA-Bej-Test-v3 DEBUG:Observation forecast: []
[2019-03-24 09:02:17,272] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Softmax [1.0000000e+00 2.4426273e-37 0.0000000e+00 1.0644227e-35 1.7945612e-34], sampled 0.6535315514220634
[2019-03-24 09:02:17,407] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.027223699]
[2019-03-24 09:02:17,408] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation this: [28.93333333333333, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9260666427041785, 6.9112, 6.9112, 121.9260426156618, 672315.9364615526, 672315.9364615526, 180387.1633427321]
[2019-03-24 09:02:17,408] A3C_EVAL-Part3-NA-Bej-Train-v1 DEBUG:Observation forecast: []
[2019-03-24 09:02:17,411] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Softmax [1.0000000e+00 1.7247408e-33 1.4069548e-36 5.0333604e-32 6.5688764e-31], sampled 0.5564517601597522
[2019-03-24 09:02:29,442] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.027223699]
[2019-03-24 09:02:29,444] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation this: [26.0, 75.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8825851819289838, 6.9112, 6.9112, 121.9260426156618, 646669.324895922, 646669.324895922, 173488.0081463997]
[2019-03-24 09:02:29,446] A3C_EVAL-Part3-NA-Bej-Test-v1 DEBUG:Observation forecast: []
[2019-03-24 09:02:29,449] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Softmax [1.0000000e+00 7.6218170e-35 4.4503577e-38 2.6320231e-33 3.7134916e-32], sampled 0.5373721305792407
[2019-03-24 09:02:32,371] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00904925], dtype=float32), 0.027223699]
[2019-03-24 09:02:32,373] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation this: [23.65438712, 76.60038183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7442021175156692, 6.911200000000001, 6.9112, 121.9260426156618, 555530.2527872218, 555530.2527872213, 151469.3976224069]
[2019-03-24 09:02:32,376] A3C_EVAL-Part3-NA-Bej-Test-v2 DEBUG:Observation forecast: []
[2019-03-24 09:02:32,381] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Softmax [1.0000000e+00 4.6531858e-37 0.0000000e+00 1.9754025e-35 3.2131920e-34], sampled 0.47148839117926866
[2019-03-24 09:03:27,733] A3C_EVAL-Part3-NA-Bej-Test-v4 INFO:Evaluation: average rewards by now are 8404.3352 2292930052.2689 697.0000
[2019-03-24 09:03:27,782] A3C_EVAL-Part3-NA-Bej-Test-v1 INFO:Evaluation: average rewards by now are 8560.3296 2258226393.9236 536.0000
[2019-03-24 09:03:27,862] A3C_EVAL-Part3-NA-Bej-Test-v2 INFO:Evaluation: average rewards by now are 8633.8375 2219139301.2698 543.0000
[2019-03-24 09:03:27,912] A3C_EVAL-Part3-NA-Bej-Train-v1 INFO:Evaluation: average rewards by now are 7841.5838 2529739775.4178 831.0000
[2019-03-24 09:03:28,108] A3C_EVAL-Part3-NA-Bej-Test-v3 INFO:Evaluation: average rewards by now are 8364.2563 2339423669.2034 616.0000
[2019-03-24 09:03:29,125] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 2500000, evaluation results [2500000.0, 7841.583789482413, 2529739775.4177794, 831.0, 8560.329577213746, 2258226393.9236007, 536.0, 8633.837517256845, 2219139301.2698236, 543.0, 8364.256289480296, 2339423669.203431, 616.0, 8404.335235826124, 2292930052.2689223, 697.0]
